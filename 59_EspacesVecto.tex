% This is part of Mes notes de mathématique
% Copyright (c) 2011-2015
%   Laurent Claessens, Carlotta Donadello
% See the file fdl-1.3.txt for copying conditions.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Méthode de Gauss pour résoudre des systèmes d'équations linéaires}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


Pour résoudre un système d'équations linéaires, on procède comme suit:
\begin{enumerate}
\item Écrire le système sous forme matricielle. \[\text{p.ex. } \begin{cases} 2x+3y &= 5 \\ x+2y &= 4 \end{cases} \Leftrightarrow \left(\begin{array}{cc|c} 2 & 3 & 5 \\ 1 & 2 & 4 \end{array}\right) \]
\item Se ramener à une matrice avec un maximum de $0$ dans la partie de gauche en utilisant les transformations admissibles:
\begin{enumerate}
\item Remplacer une ligne par elle-même + un multiple d'une autre;
\[\text{p.ex. } \left(\begin{array}{cc|c} 2 & 3 & 5 \\ 1 & 2 & 4 \end{array}\right)  \stackrel{L_1  - 2. L_2 \mapsto L_1'}{\Longrightarrow} \left(\begin{array}{cc|c} 0 & -1 & -3 \\ 1 & 2 & 4 \end{array}\right) \]
\item Remplacer une ligne par un multiple d'elle-même;
\[\text{p.ex. } \left(\begin{array}{cc|c} 0 & -1 & -3 \\ 1 & 2 & 4 \end{array}\right)  \stackrel{-L_1  \mapsto L_1'}{\Longrightarrow} \left(\begin{array}{cc|c} 0 & 1 & 3 \\ 1 & 2 & 4 \end{array}\right) \]
\item Permuter des lignes.
\[\text{p.ex. } \left(\begin{array}{cc|c} 0 & 1 & 3 \\ 1 & 0 & -2 \end{array}\right)  \stackrel{L_1  \mapsto L_2' \text{ et } L_2  \mapsto L_1'}{\Longrightarrow} \left(\begin{array}{cc|c} 1 & 0 & -2 \\ 0 & 1 & 3  \end{array}\right) \]
\end{enumerate}
\item Retransformer la matrice obtenue en système d'équations.
\[\text{p.ex. }  \left(\begin{array}{cc|c} 1 & 0 & -2 \\ 0 & 1 & 3  \end{array}\right) \Leftrightarrow \begin{cases} x &= -2 \\ y &= 3 \end{cases}  \]
\end{enumerate}

\textbf{Remarques :} 
\begin{itemize}
\item Si on obtient une ligne de zéros, on peut l'enlever:
\[\text{p.ex. }  \left(\begin{array}{ccc|c} 3 & 4 & -2 & 2 \\ 4 & -1 & 3 & 0 \\ 0 & 0 & 0 & 0 \end{array}\right) \Leftrightarrow  \left(\begin{array}{ccc|c} 3 & 4 & -2 & 2 \\ 4 & -1 & 3 & 0 \end{array}\right) \]
\item Si on obtient une ligne de zéros suivie d'un nombre non-nul, le système d'équations n'a pas de solution:
\[\text{p.ex. }  \left(\begin{array}{ccc|c} 3 & 4 & -2 & 2 \\ 4 & -1 & 3 & 0 \\ 0 & 0 & 0 & 7 \end{array}\right) \Leftrightarrow  \begin{cases} \cdots \\ \cdots \\ 0x + 0y + 0z = 7 \end{cases} \Rightarrow \textbf{Impossible} \]
\item Si on moins d'équations que d'inconnues, alors il y a une infinité de solutions qui dépendent d'un ou plusieurs paramètres:
\[\text{p.ex. }  \left(\begin{array}{ccc|c} 1 & 0 & -2 & 2 \\ 0 & 1 & 3 & 0 \end{array}\right) \Leftrightarrow  \begin{cases} x - 2z = 2 \\ y + 3z = 0 \end{cases} \Leftrightarrow  \begin{cases} x = 2 + 2\lambda \\ y = -3\lambda \\ z = \lambda \end{cases} \]
\end{itemize}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Orthogonalité}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{proposition}			\label{PropVectsOrthLibres}
	si $v_1,\cdots,v_k$ sont des vecteurs non nuls, orthogonaux deux à deux, alors ces vecteurs forment une famille libre.
\end{proposition}


%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Calcul différentiel dans un espace vectoriel normé}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\label{SecLStKEmc}

Nous développons dans cette section le concept de différentielle de fonction de et vers des espaces vectoriels normés au lieu de \( \eR^n\).

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Différentielle}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}  \label{DefKZXtcIT}
    Soit une application \( f\colon E\to F\) entre deux espaces de Banach. Nous disons que \( f\) est \defe{différentiable}{différentiable!dans un Banach} en \( a\in E\) si il existe une application linéaire continue\footnote{Nous demandons bien que le candidat différentielle soit continue; en dimension infinie ce n'est pas le cas de toutes les fonctions linéaires, comme le montre l'exemple \ref{ExHKsIelG}.} \( T\colon E\to F\) telle que
    \begin{equation}\label{EqIQuRGmO}
        \lim_{h\to 0} \frac{ f(a+h)-f(a)-T(h) }{ \| h \| }=0.
    \end{equation}
\end{definition}

L'application \( a\mapsto T\) est la \defe{différentielle}{différentielle} de \( f\) au point \( a\) et est notée \( df_a\). L'application différentielle
\begin{equation}
    \begin{aligned}
        df\colon E&\to \aL(E,F) \\
        a&\mapsto df_a 
    \end{aligned}
\end{equation}
est également très importante. 

\begin{definition}      \label{DefJYBZooPTsfZx}
Une application \( f\colon E\to F\) est de \defe{classe \( C^1\)}{classe $C^1$} lorsque l'application différentielle \( df\colon E\to \aL(E,F)\) est continue. Voir aussi les définitions \ref{DefPNjMGqy} pour les applications de classe \( C^k\).
\end{definition}

\begin{remark}      \label{RemATQVooDnZBbs}
    L'application norme étant continue, le critère du théorème \ref{ThoWeirstrassRn} est en réalité assez général. Par exemple à partir d'une application différentiable\footnote{Définition \ref{DefKZXtcIT}.} \( f\colon X\to Y\)  nous pouvons considérer la fonction réelle
    \begin{equation}
        a\mapsto \|  df_a   \|
    \end{equation}
    où la norme est la norme opérateur\footnote{Définition \ref{DefNFYUooBZCPTr}.}. Si \( f\) est de classe \( C^1\) alors cette application est continue et donc bornée sur un compact \( K\) de \( X\).
\end{remark}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{(non ?) Différentiabilité des applications linéaires}
%---------------------------------------------------------------------------------------------------------------------------

Si \( E\) et \( F\) sont deux espaces vectoriels nous notons \( \aL(E,F)\)\nomenclature[Y]{\( \aL(E,F)\)}{Les applications linéaires de \( E\) vers \( F\)} l'ensemble des applications linéaires de \( E\) vers \( F\) et \( \cL(E,F)\)\nomenclature[Y]{\( \cL\)}{Les applications linéaires continues de \( E\) vers \( F\)} l'ensemble des applications linéaires continues de \( E\) vers \( F\). Ces espaces seront bien entendu, sauf mention du contraire, toujours munis de la norme opérateur de la définition \ref{DEFooYDFVooSMgvsD}. 

\begin{example}[Une application linéaire non continue]  \label{ExHKsIelG}
    Soit \( V\) l'espace vectoriel normé des suites \emph{finies} de réels muni de la norme usuelle $\| c \|=\sqrt{\sum_{i=0}^{\infty}| c_i |^2}$ où la somme est finie. Nous nommons \( \{ e_k \}_{k\in \eN}\) la base usuelle de cet espace, et nous considérons l'opérateur \( f\colon V\to V\) donnée par \( f(e_k)=ke_k\). C'est évidemment linéaire, mais ce n'est pas continu en zéro. En effet la suite \( u_k=e_k/k\) converge vers \( 0\) alors que \( f(u_k)=e_k\) ne converge pas.
\end{example}

Cet exemple aurait pu également être donnée dans un espace de Hilbert, mais il aurait fallu parler de domaine.
%TODO : le faire, et regarder si Hilbet n'est pas la complétion de cet espace. Référencer à l'endroit qui définit l'espace vectoriel librement engendré. Ici ce serait par N.

%TODO : dire qu'une application bilinéaire sur RxR n'est pas une application linéaire sur R^2

\begin{example}[Une autre application linéaire non continue\cite{GTkeGni}]
    En dimension infinie, une application linéaire n'est pas toujours continue. Soit \( E\) l'espace des polynômes à coefficients réels sur \( \mathopen[ 0 , 1 \mathclose]\) muni de la norme uniforme. L'application de dérivation \( \varphi\colon E\to E\), \( \varphi(P)=P'\) n'est pas continue.

    Pour la voir nous considérons la suite \( P_n=\frac{1}{ n }X^n\). D'une part nous avons \( P_n\to 0\) dans \( E\) parce que \( P_n(x)=\frac{ x^n }{ n }\) avec \( x\in \mathopen[ 0 , 1 \mathclose]\). Mais en même temps nous avons \( \varphi(P_n)=X^{n-1}\) et donc \( \| \varphi(P_n) \|=1\).

    Nous n'avons donc pas \( \lim_{n\to \infty} \varphi(P_n)=\varphi(\lim_{n\to \infty} P_n)\) et l'application \( \varphi\) n'est pas continue en \( 0\). Elle n'est donc continue nulle part par linéarité.

    Nous avons utilisé le critère séquentiel de la continuité, voir la définition \ref{DefENioICV} et la proposition \ref{PropFnContParSuite}.
\end{example}

Nous avons cependant le résultat suivant.
\begin{proposition}[\cite{GKPYTMb} Continue si et seulement si bornée] \label{PropmEJjLE}
    Soient \( E\) et \( F\) des espaces vectoriels normés, et \( u\colon E\to F\) une application linéaire. Alors \( u\) est bornée\footnote{Au sens où \( \| u \|<\infty\) pour la norme opérateur.} si et seulement si elle est continue.
\end{proposition}
\index{opérateur!linéaire!borné}
\index{application!linéaire!bornée}

\begin{proof}
    Nous commençons par supposer que \( u\) est bornée. Pour tout \( x,y\in E\) nous avons
    \begin{equation}
        \| u(x)-u(y) \|=\| u(x-y) \|\leq \| u \|\| x-y \|.
    \end{equation}
    En particulier si \( x_n\stackrel{E}{\longrightarrow}x\) alors
    \begin{equation}
        0\leq \| u(x_n)-u(x) \|\leq \| u \|\| x-x_n \|\to 0
    \end{equation}
    et \( u\) est continue en vertu de la caractérisation séquentielle de la continuité, proposition \ref{PropFnContParSuite}.

Supposons maintenant que \( \| u \|\) ne soit pas borné, c'est à dire que l'ensemble \( \{ \| u(x) \|\tq \| x \|=1 \}\) ne soit pas borné. Alors pour tout \( k\geq 1\) il existe \( x_k\in B(0,1)\) tel que \( \| u(x_k) \|>k\). La suite \( x_k/k\) tend vers zéro parce que \( \| x_k \|=1\), mais \( \| u(x_k) \|\geq 1\) pour tout \( k\). Cela montre que \( u\) n'est pas continue.
\end{proof}

\begin{remark}  \label{RemOAXNooSMTDuN}
Cette proposition permet de retrouver l'exemple \ref{ExHKsIelG} plus simplement. Si \( \{ e_k \}_{k\in \eN}\) est une base d'un espace vectoriel normé formée de vecteurs de norme \( 1\), alors l'opérateur linéaire donné par \( u(e_k)=ke_k\) n'est pas borné et donc pas continu.
\end{remark}

C'est également ce résultat qui montre que le produit scalaire est continu sur un espace de Hilbert par exemple.

\begin{lemma}       \label{LemooXXUGooUqCjmp}
    Si \( f\) est linéaire et différentiable alors \( df_a(u)=f(u)\).
\end{lemma}

\begin{proof}
    En effet la linéarité de \( f\) donne
    \begin{equation}
        f(a+h)-f(a)-f(h)=0
    \end{equation}
    pour tout \( h\). Donc la limite \eqref{EqIQuRGmO} est nulle. Les applications linéaires non continues ne sont donc pas différentiables.
\end{proof}

\begin{lemma}   \label{LemLLvgPQW}
    Une application linéaire continue est de classe \(  C^{\infty}\).
\end{lemma}

\begin{proof}
    Soit \( a\in E\). Étant donné que \( f\) est linéaire et continue, elle est différentiable et
    \begin{equation}
        \begin{aligned}
            df\colon E&\to \cL(E,F) \\
            a&\mapsto f 
        \end{aligned}
    \end{equation}
    est une fonction constante et en particulier continue; nous avons donc \( f\in C^1\). Pour la différentielle seconde nous avons \( d(df)_a=0\) parce que \( df(a+h)-df(a)=f-f=0\). Toutes les différentielles suivantes sont nulles.
\end{proof}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Dérivation en chaine et formule de Leibnitz}
%---------------------------------------------------------------------------------------------------------------------------

\begin{proposition} \label{PropOYtgIua}
    Soient \( f_i\colon U\to F_i\), des fonctions de classe \( C^r\) où \( U\) est ouvert dans l'espace vectoriel normé \( E\) et les \( F_i\) sont des espaces vectoriels normés. Alors l'application
    \begin{equation}
        \begin{aligned}
        f=f_1\times \cdots\times f_n\colon U&\to F_1\times \cdots\times F_n \\
    x&\mapsto \big( f_1(x),\ldots, f_n(x) \big) 
        \end{aligned}
    \end{equation}
    est de classe \( C^r\) et
    \begin{equation}
    d^rf=d^rf_1\times\ldots d^rf_n.
    \end{equation}
\end{proposition}

\begin{proof}
    Soit \( x\in U\) et \( h\in E\). La différentiabilité des fonctions \( f_i\) donne
    \begin{equation}
        f_i(x+h)=f_i(x)+(df_i)_x(h)+\alpha_i(h)
    \end{equation}
    avec \( \lim_{h\to 0} \alpha_i(h)/\| h \|=0\). Par conséquent
    \begin{equation}
        f(x+h)=\big( \ldots, f_i(x)+(df_i)_x(h)+\alpha_i(h),\ldots \big)= \big( \ldots,f_i(x),\ldots \big)+ \big( \ldots,(df_i)_x(h),\ldots \big)+ \big( \ldots,\alpha_i(h),\ldots \big).
    \end{equation}
    Mais la définition \ref{DefFAJgTCE} de la norme dans un espace produit donne
    \begin{equation}
        \lim_{h\to 0} \frac{ \| \big( \alpha_1(h),\ldots, \alpha_n(h) \big) \| }{ \| h \| }=0,
    \end{equation}
    ce qui nous permet de noter \( \alpha(h)=\big( \alpha_1(h),\ldots, \alpha_n(h) \big)\) et avoir \( \lim_{h\to 0} \alpha(h)/\| h \|=0\). Avec tout ça nous avons bien
    \begin{equation}
        f(x+h)=f(x)+\big( (df_1)_x(h)+\ldots +(df_n)_x(h) \big)+\alpha(h),
    \end{equation}
    ce qui signifie que \( f\) est différentiable et
    \begin{equation}
        df_x=\big( df_1,\ldots, df_n \big).
    \end{equation}
\end{proof}

\begin{theorem}[Différentielle de fonctions composées\cite{SNPdukn}]    \label{ThoAGXGuEt}
    Soient \( E\), \( F\) et \( G\) des espaces vectoriels normés, \( U\) ouvert dans \( E\) et \( V\) ouvert dans \( F\). Soient des applications de classe \( C^r\) (\( r\geq 1\))
    \begin{subequations}
        \begin{align}
            f\colon U\to V\\
            g\colon V\to G.
        \end{align}
    \end{subequations}
    Alors l'application \( g\circ f\colon V\to G\) est de classe \( C^r\) et
    \begin{equation}\label{EqHFmezmr}
        d(g\circ f)_x=dg_{f(x)}\circ df_x.
    \end{equation}
\end{theorem}

\begin{proof}
    Nous nous fixons \( x\in U\). La fonction \( f\) est différentiable en \( x\in U\) et \( g\) en \( f(x)\), donc nous pouvons écrire
    \begin{equation}
        f(x+h)=f(x)+df_x(h)+\alpha(h)
    \end{equation}
    et
    \begin{equation}
        g\big( f(x)+u \big)=g\big( f(x) \big)+dg_{f(x)}(u)+\beta(u)
    \end{equation}
    où la fonction \( \alpha\) a la propriété que
    \begin{equation}
        \lim_{h\to 0} \frac{ \| \alpha(h) \| }{ \| h \| }=0;
    \end{equation}
    et la même chose pour \( \beta\). La fonction composée en \( x+h\) s'écrit donc
    \begin{equation}    \label{EqCXcfhfH}
        (g\circ f)(x+h)=g\big( f(x)+df_x(h)+\alpha(h) \big)=g\big( f(x) \big)+dg_{f(x)}\big( df_x(h)+\alpha(h) \big)+\beta\big( df_x(h)+\alpha(h) \big).
    \end{equation}
    Nous montrons que tous les «petits» termes de cette formule peuvent être groupés. D'abord si \( h\) est proche de \( 0\), nous avons
    \begin{equation}
        \frac{ \| df_x(h)+\alpha(h) \| }{ \| h \| }\leq\frac{ \| df_x \|\| h \| }{ \| h \| }+\frac{ \| \alpha(h) \| }{ \| h \| }.
    \end{equation}
    Si \( h\) est petit, le second terme est arbitrairement petit, donc en prenant n'importe que \( M>\| df_x \|\) nous avons
    \begin{equation}
        \frac{ \| df_x(h)+\alpha(h) \| }{ \| h \| }\leq M.
    \end{equation}
    Par ailleurs, nous avons
    \begin{equation}
        \frac{ \| \beta\big( df_x(h)+\alpha(h) \big) \| }{ \| h \| }=\frac{  \| \beta\big( df_x(h)+\alpha(h) \big) \|  }{ \| df_x(h)+\alpha(h) \| }\frac{  \| df_x(h)+\alpha(h) \|  }{ \| h \| }\leq M\frac{  \| \beta\big( df_x(h)+\alpha(h) \big) \|  }{   \| df_x(h)+\alpha(h) \| }.
    \end{equation}
    Vu que la fraction est du type \( \frac{ \beta( f(h)) }{ f(h) }\) avec \( \lim_{h\to 0} f(h)=0\), la fraction tend vers zéro lorsque \( h\to 0\). En posant
    \begin{equation}
        \gamma_1(h)=\beta\big( df_x(h)+\alpha(h) \big)
    \end{equation}
    nous avons \( \lim_{h\to 0} \gamma_1(h)/\| h \|=0\).

    L'autre candidat à être un petit terme dans \eqref{EqCXcfhfH} est traité en utilisant la proposition \ref{PropEDvSQsA} :
    \begin{equation}
        \| dg_{f(x)}\big( \alpha(h) \big) \|\leq \| dg_{f(x)} \|\| \alpha(h) \|.
    \end{equation}
    Donc
    \begin{equation}
        \frac{ \| dg_{f(x)}\big( \alpha(h) \big) \| }{ \| h \| }\leq \| dg_{f(x)} \|\frac{ \| \alpha(h) \| }{ \| h \| },
    \end{equation}
    ce qui nous permet de poser
    \begin{equation}
        \gamma_2(h)=dg_{f(x)}\big( \alpha(h) \big)
    \end{equation}
    avec \( \gamma_2\) qui a la même propriété que \( \gamma_1\). Avec tout cela, en posant \( \gamma=\gamma_1+\gamma_2\) nous récrivons
    \begin{equation}
        (g\circ f)(x+h)=g\big( f(x) \big)+dg_{f(x)}\big( df_x(h) \big)+\gamma(h)
    \end{equation}
    avec \( \lim_{h\to 0} \frac{ \gamma(h) }{ \| h \| }=0\). Tout cela pour dire que
    \begin{equation}
        \lim_{h\to 0} \frac{ (g\circ f)(x+h)-(g\circ f)(x)-\big( dg_{f(x)}\circ df_x \big)(h) }{ \| h \| }=0,
    \end{equation}
    ce qui signifie que 
    \begin{equation}
        d(g\circ f)_x=dg_{f(x)}\circ df_x.
    \end{equation}
    Nous avons donc montré que si \( f\) et \( g\) sont différentiables, alors \( g\circ f\) est différentiable avec différentielle donnée par \eqref{EqHFmezmr}.

    Nous passons à la régularité. Nous supposons maintenant que \( f\) et \( g\) sont de classe \( C^r\) et nous considérons l'application
    \begin{equation}
        \begin{aligned}
            \varphi\colon L(F,G)\times L(E,F)&\to L(E,G) \\
            (A,B)&\mapsto A\circ B. 
        \end{aligned}
    \end{equation}
    Montrons que l'application \( \varphi\) est continue en montrant qu'elle est bornée\footnote{Proposition \ref{PropmEJjLE}.}. Pour cela nous écrivons la norme opérateur
    \begin{equation}
        \| \varphi \|=\sup_{\| (A,B) \|=1}\| \varphi(A,B) \|=\sup_{\| (A,B) \|=1}\| A\circ B \|\leq\sup_{\| (A,B) \|=1}\| A \|\| B \|\leq 1.
    \end{equation}
    Pour ce calcul nous avons utilisé le fait que la norme opérateur soit une norme algébrique (proposition \ref{PropEDvSQsA}) ainsi que la définition \ref{DefFAJgTCE} de la norme sur un espace produit pour la dernière majoration. L'application \( \varphi\) est donc continue et donc \(  C^{\infty}\) par le lemme \ref{LemLLvgPQW}. Nous considérons également l'application
    \begin{equation}
        \begin{aligned}
        \psi\colon U&\to L(F,G)\times L(E,F) \\
        x&\mapsto \big( dg_{f(x)},df_x \big). 
        \end{aligned}
    \end{equation}
    Vu que \( f\) et \( g\) sont \( C^1\), l'application \( \psi\) est continue. Ces deux applications \( \varphi\) et \( \psi\) sont choisies pour avoir
    \begin{equation}
        (\varphi\circ\psi)(x)=\varphi\big( dg_{f(x)},df_x \big)=dg_{f(x)}\circ df_x,
    \end{equation}
    c'est à dire \( \varphi\circ\psi=d(g\circ f)\). Les applications \( \varphi\) et \( \psi\) étant continues, l'application \( d(g\circ f)\) est continue, ce qui prouve que \( g\circ f\) est \( C^1\).

    Si \( f\) et \( g\) sont \( C^r\) alors \( dg\in C^{r-1}\) et \( dg\circ f\in C^{r-1}\) où il ne faut pas se tromper : \( dg\colon F\to L(F,G)\) et \( f\colon U\to F\); la composée est \( dg\circ f\colon x\mapsto dg_{f(x)}\in L(F,G)\). 
    
    Pour la récurrence nous supposons que \( f,g\in C^{r-1}\) implique \( g\circ f\in C^{r-1}\) pour un certain \( r\geq 2\) (parce que nous venons de prouver cela avec \( r=1\) et \( r=2\)). Soient \( f,g\in C^r\) et montrons que \( g\circ f\in C^r\). Par la proposition \ref{PropOYtgIua} nous avons
    \begin{equation}
        \psi=dg\circ f\times df\in C^{r-1},
    \end{equation}
    et donc \( d(g\circ f)=\varphi\circ\psi\in C^{r-1}\), ce qui signifie que \( g\circ f\in C^r\).
\end{proof}

On fixe maintenant une définition largement utilisée dans la suite. 
\begin{definition}      \label{DefAQIQooYqZdya}
	 Soient $U$ et $V$, deux ouverts d'un espace vectoriel normé. Une application $f$ de $U$ dans $V$ est un \defe{difféomorphisme}{difféomorphisme} si elle est bijective, différentiable et dont l'inverse $f^{-1}:V\to U $ est aussi différentiable. 
\end{definition}

\begin{remark}
	Il n'est pas possible d'avoir une application inversible d'un ouvert de $\eR^m$ vers un ouvert de $\eR^n$ si $m\neq n$. Il n'y a donc pas de notion de difféomorphismes entre ouverts de dimensions différentes.
\end{remark}

\begin{lemma}       \label{LemooTJSZooWkuSzv}
    Si \( f\colon U\to V\) est une difféomorphisme\footnote{Définition \ref{DefAQIQooYqZdya}} alors pour tout \( a\in U\), l'application \( df_a\) est inversible et
    \begin{equation}
        (df_a)^{-1}=(df^{-1})_{f(a)}.
    \end{equation}
\end{lemma}

\begin{proof}
    Il suffit d'apercevoir qu'en vertu de la règle de différentiation en chaîne \ref{EqHFmezmr},
    \begin{equation}
        (df_a)(df^{-1})_{f(a)}=f(f\circ f^{-1})_{f(a)}=\id.
    \end{equation}
\end{proof}

\begin{lemma}[Leibnitz pour les formes bilinéaires\cite{SNPdukn}]\label{LemFRdNDCd}
    Si \( B\colon E\times F\to G\) est bilinéaire et continue, elle est \(  C^{\infty}\) et
    \begin{equation}    \label{EqXYJgDBt}
        dB_{(x,y)}(u,v)=B(x,v)+B(u,y).
    \end{equation}
\end{lemma}

\begin{proof}
    D'abord le membre de droite de \eqref{EqXYJgDBt} est une application linéaire et continue, donc c'est un bon candidat à être différentielle. Nous allons prouver que ça l'est, ce qui prouvera la différentiabilité de \( B\). Avec ce candidat, le numérateur de la définition \eqref{EqIQuRGmO} s'écrit dans notre cas
    \begin{equation}
        B\big( (x,y)+(u,v) \big)-B(x,y)-B(x,v)-B(u,y)=B(u,v).
    \end{equation}
    Il reste à voir que 
    \begin{equation}
        \lim_{ (u,v)\to (0,0) } \frac{ B(u,v) }{ \| (u,v) \| }=0
    \end{equation}
    Par l'équation \eqref{EqYLnbRbC} nous avons
    \begin{equation}
        \frac{ \| B(u,v) \| }{ \| (u,v) \| }\leq \frac{ \| B \|\| u \|\| v \| }{ \| u \| }=\| B \|\| v \|
    \end{equation}
    parce que \( \| (u,v) \|\geq \| u \|\). À partir de là il est maintenant clair que
    \begin{equation}
        \lim_{(u,v)\to (0,0)}\frac{ \| B(u,v) \| }{ \| (u,v) \| }=0,
    \end{equation}
    ce qu'il fallait.
\end{proof}

\begin{proposition}[Règle de Leibnitz\cite{SNPdukn}]
    Soient \( E,F_1,F_2\) des espaces vectoriels normés, \( U\) ouvert dans \( E\) et des applications de classe \( C^r\) (\( r\geq 1\))
    \begin{subequations}
        \begin{align}
            f_1\colon U\to F_1\\
            f_2\colon U\to F_2\\
        \end{align}
    \end{subequations}
    et \( B\in\cL(F_1\times F_2,G)\). Alors l'application
    \begin{equation}
        \begin{aligned}
            \varphi\colon U&\to G \\
            x&\mapsto B\big( f_1(x),f_2(x) \big) 
        \end{aligned}
    \end{equation}
    est de classe \( C^r\) et
    \begin{equation}    \label{EqMNGBXWc}
        d\varphi_x(u)=\varphi\big( (df_1)_x(u),f_2(x) \big)+\varphi\big( f_1(x),(df_2)_x(u) \big).
    \end{equation}
\end{proposition}
\index{Leibnitz!applications entre espaces vectoriels normés}

\begin{proof}
    Par hypothèse \( B\) est continue (c'est la définition de l'espace \( \cL\)), et donc \(  C^{\infty}\) par le lemme \ref{LemFRdNDCd}. Par ailleurs la fonction \( f_1\times f_2\) est de classe \( C^r\) parce que \( f_1\) et \( f_2\) le sont et parce que la proposition \ref{PropOYtgIua} le dit. L'application composée \( B\circ(f_1\times f_2)\) est donc également de classe \( C^r\) par le théorème \ref{ThoAGXGuEt}.

    Il ne nous reste donc qu'à prouver la formule \ref{EqMNGBXWc}. En utilisant la différentielle du produit cartésien\footnote{Proposition \ref{PropOYtgIua}.} nous avons
    \begin{equation}
        f\big( B\circ(f_1\times f_2) \big)_x(h)=dB_{(f_1\times f_2)(x)}\big( (df_1)_x(h),(df_2)_x(h) \big).
    \end{equation}
    Nous développons cela en utilisant le lemme \ref{LemFRdNDCd} :
    \begin{subequations}
        \begin{align}
        d\big( B\circ(f_1\times f_2) \big)_x(h)&=dB_{\big( f_1(x),f_2(x) \big)}\big( (df_1)_x(h),(df_2)_x(h) \big)\\
        &=B\big( f_1(x),(df_2)_x(h) \big)+B\big( (df_1)_x(h),f_2(x) \big),
        \end{align}
    \end{subequations}
    comme souhaité.
\end{proof}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Différentielle partielle}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}[Différentielle partielle]    \label{VJM_CtSKT}
    Soient \( E\), \( F\) et \( G\) des espaces vectoriels normés et une fonction \( f\colon E\times F\to G\). Nous définissons sa \defe{différentielle partielle}{différentielle!partielle} sur l'espace \( E\) par
    \begin{equation}
        \begin{aligned}
            d_1f_{(x_0,y_0)}\colon E&\to G \\
            u&\mapsto \Dsdd{ f(x_0+tu,y_0 }{t}{0} .
        \end{aligned}
    \end{equation}
    La différentielle \( d_2\) se définit de la même façon.
\end{definition}

\begin{proposition}[\cite{SNPdukn}] \label{PropLDN_nHWDF}
    Soient \( E_1\), \( E_2\) et \( F\) des espaces vectoriels normés, soit un ouvert \( U\subset E_1\times E_2\) et une fonction \( f\colon U\to F\).
    \begin{enumerate}
        \item   \label{ItemRDD_oPmXVi}
            Si \( f\) est différentiable alors les différentielles partielles existent et
            \begin{subequations}
                \begin{align}
                    d_1f_{(x_0,y_0)}(u)=df_{(x_0,y_0)}(u,0)\\
                    d_2f_{(x_0,y_0)}(v)=df_{(x_0,y_0)}(0,v)
                \end{align}
            \end{subequations}
            où \( u\in E_1\) et \( v\in E_2\).
        \item
            Si \( f\) est différentiable alors
            \begin{equation}
                df_{(x_0,y_0)}(u,v)=d_1f_{(x_,y_0)}(u)+d_2f_{(x_0,y_0)}(v).
            \end{equation}
    \end{enumerate}
\end{proposition}

\begin{proof}
    Nous posons \( \alpha=(x_0,y_0)\in U\) et
    \begin{equation}
        \begin{aligned}
            j_{\alpha}^{(1)}\colon E_1&\to E_1\times E_2 \\
            x&\mapsto (x,y_0). 
        \end{aligned}
    \end{equation}
    C'est une fonction de classe \(  C^{\infty}\) et 
    \begin{equation}
        (dj_{\alpha}^{(1)})_{x_0}(u)=\Dsdd{ j_{\alpha}^{(1)}(x_0+tu) }{t}{0}=\Dsdd{ (x_0+tu,y_0) }{t}{0}=(u,0).
    \end{equation}
    D'autre part 
    \begin{subequations}
        \begin{align}
            (d_1f)_{\alpha}(u)&=\Dsdd{ f(x_0+tu,y_0) }{t}{0}\\
            &=\Dsdd{ (f\circ j_{\alpha}^{(1)})(x_0+tu) }{t}{0}\\
            &=\big( d(f\circ j_{\alpha}^{(1)}) \big)_{x_0}(u).
        \end{align}
    \end{subequations}
    À ce moment nous utilisons la règle des différentielles composées \ref{ThoAGXGuEt} pour dire que
    \begin{equation}
        (d_1f)_{\alpha}(u)=df_{j_{\alpha}^{(1)}(x_0)}\circ (dj_{\alpha}^{(1)})_{x_0}(u)=df_{\alpha}(u,0).
    \end{equation}
    Voila qui prouve déjà le point \ref{ItemRDD_oPmXVi}.

    Pour la suite nous considérons les fonctions 
    \begin{equation}
        \begin{aligned}[]
            P_1(x,y)&=x,&&&J_1(u)&=(u,0),\\
            P_2(x,y)&=y,&&&J_2(v)&=(0,v)
        \end{aligned}
    \end{equation}
    et nous avons l'égalité évidente
    \begin{equation}
        J_1\circ P_1+J_2\circ P_2=\mtu
    \end{equation}
    sur \( E_1\times E_2\). En appliquant \( df_{\alpha}\) à cette dernière égalité, en appliquant à \( (u,v)\) et en utilisant la linéarité de \( df_{\alpha}\) nous trouvons
    \begin{subequations}
        \begin{align}
            df_{\alpha}(u,v)&=df_{\alpha}\big( (J_1\circ P_1)(u,v) \big)+df_{\alpha}\big( (J_2\circ P_2)(u,v) \big)\\
            &=df_{\alpha}(u,0)+df_{\alpha}(0,v)\\
            &=(d_1f)_{\alpha}(u)+(d_2f)_{\alpha}(v)
        \end{align}
    \end{subequations}
    où nous avons utilisé le point \ref{ItemRDD_oPmXVi} pour la dernière égalité.
\end{proof}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Formule des accroissements finis}
%---------------------------------------------------------------------------------------------------------------------------

Il en existe plusieurs formes :
\begin{enumerate}
    \item
        Une version adaptée aux espaces de dimension finie est le théorème \ref{val_medio_2}.
    \item
        Pour les fonctions \( \eR\to \eR\) en le théorème \ref{ThoAccFinis}.
    \item
        Espaces vectoriels normés, théorème \ref{ThoNAKKght}
\end{enumerate}

\begin{proposition} \label{PropDQLhSoy}
    Soient \( a<b\) dans \( \eR\) et deux fonctions
    \begin{subequations}
        \begin{align}
            f\colon \mathopen[ a , b \mathclose]\to E\\
            g\colon \mathopen[ a , b \mathclose]\to \eR
        \end{align}
    \end{subequations}
    continues sur \( \mathopen[ a , b \mathclose]\) et dérivables sur \( \mathopen] a , b \mathclose[\). Si pour tout \( t\in\mathopen] a , b \mathclose[\) nous avons \( \| f'(t) \|\leq g'(t)\) alors
        \begin{equation}
            \| f(b)-f(a) \|\leq g(b)-g(a).
        \end{equation}
\end{proposition}

\begin{proof}
    Soit \( \epsilon>0\) et la fonction
    \begin{equation}
        \begin{aligned}
            \varphi_{\epsilon}\colon \mathopen[ a , b \mathclose]&\to \eR \\
            t&\mapsto \| f(t)-f(a) \|-g(t)-\epsilon t. 
        \end{aligned}
    \end{equation}
    Cela est une fonction continue réelle à variable réelle. En particulier pour tout \( u\in\mathopen] a , b \mathclose[\) la fonction \( \varphi_{\epsilon}\) est continue sur le compact \( \mathopen[ u , b \mathclose]\) et donc y atteint son minimum en un certain point \( c\in\mathopen[ u , b \mathclose]\); c'est le bon vieux théorème de Weierstrass \ref{ThoWeirstrassRn}. Nous commençons par montrer que pour tout \( u\), ledit minimum ne peut être que \( b\). Pour cela nous allons montrer que si \( t\in\mathopen[ u , b [\), alors \( \varphi_{\epsilon}(s)<\varphi_{\epsilon}(t)\) pour un certain \( s>t\). Par continuité si \( s\) est proche de \( t\) nous avons
        \begin{equation}
            \left\|  \frac{ f(s)-f(t) }{ s-t }  \right\|-\frac{ \epsilon }{2}<\| f'(t) \|<g'(t)+\frac{ \epsilon }{2}=\frac{ g(s)-g(t) }{ s-t }+\frac{ \epsilon }{2}.
        \end{equation}
        Ces inégalités proviennent de la limite
        \begin{equation}
            \lim_{s\to t} \frac{ f(s)-f(t) }{ s-t }=f'(t),
        \end{equation}
        donc si \( s\) et \( t\) sont proches,
        \begin{equation}
            \left\| \frac{ f(s)-f(t) }{ s-t }-f'(t) \right\|
        \end{equation}
        est petit. Si \( s>t\) nous pouvons oublier des valeurs absolues et transformer l'inégalité en
        \begin{equation}
            \| f(s)-f(t) \|<g(s)-g(t)+\epsilon(s-t).
        \end{equation}
        Utilisant cela et l'inégalité triangulaire,
        \begin{subequations}
            \begin{align}
                \varphi_{\epsilon}(s)&\leq\| f(s)-f(t) \|+\| f(t)-f(a) \|-g(s)-\epsilon s\\
                &\leq g(s)-g(t)+\epsilon s-\epsilon t+\| f(t)-f(a) \|-g(s)-\epsilon s\\
                &=\varphi_{\epsilon}(t).
            \end{align}
        \end{subequations}
        Donc nous avons bien \( \varphi_{\epsilon}(s)<\varphi_{\epsilon}(t)\) avec l'inégalité stricte. Par conséquent pour tout \( u\in\mathopen] a , b \mathclose[\) nous avons \( \varphi_{\epsilon}(b)<\varphi_{\epsilon}(u)\) et en prenant la limite \( u\to a\) nous avons
        \begin{equation}
            \varphi_{\epsilon}(b)\leq \varphi_{\epsilon}(a).
        \end{equation}
        Cette inégalité donne immédiatement
        \begin{equation}
            \| f(b)-f(a) \|\leq g(b)-g(a)+\epsilon(b-a)
        \end{equation}
         pour tout \( \epsilon>0\) et donc
         \begin{equation}
            \| f(b)-f(a) \|\leq g(b)-g(a).
         \end{equation}
\end{proof}

\begin{theorem}[Théorème des accroissements finis]\label{ThoNAKKght}
    Soient \( E\) et \( F\) des espaces vectoriels normés, \( U \) ouvert dans \( E\) et une application différentiable \( f\colon U\to F\). Pour tout segment \( \mathopen[ a , b \mathclose]\subset U\) nous avons
    \begin{equation}
        \| f(b)-f(a) \|\leq\left( \sup_{x\in\mathopen[ a , b \mathclose]}\| df_x \| \right)\| b-a \|.
    \end{equation}
\end{theorem}
\index{théorème!accroissements finis}


\begin{proof}
    Nous prenons les applications
    \begin{equation}
        \begin{aligned}
            k\colon \mathopen[ 0 , 1 \mathclose]&\to E \\
            t&\mapsto f\big( (1-t)a+tb \big) 
        \end{aligned}
    \end{equation}
    et
    \begin{equation}
        \begin{aligned}
            g\colon \mathopen[ 0 , 1 \mathclose]&\to \eR \\
            t&\mapsto t\sup_{x\in\mathopen[ a , b \mathclose]}\| df_x \|\| b-a \|.
        \end{aligned}
    \end{equation}
    Pour tout \( t\) nous avons \( g'(t)=M\| b-a \|\) où il n'est besoin de dire ce qu'est \( M\). D'un autre côté nous avons aussi
    \begin{equation}
        \begin{aligned}[]
            k'(t)&=\lim_{\epsilon\to 0}\frac{ f\big( (1-t-\epsilon)a+(t+\epsilon)b \big)-f\big( (1-t)a+tb \big) }{ \epsilon }\\
            &=\Dsdd{ f\big( (1-t)a+tb+\epsilon(b-a) \big)  }{\epsilon}{0}\\
            &=df_{(1-t)a+tb}(b-a)
        \end{aligned}
    \end{equation}
    où nous avons utilisé l'hypothèse de différentiabilité de \( f\) sur \( \mathopen[ a , b \mathclose]\) et donc en \( (1-t)a+tb\). Nous avons donc
    \begin{equation}
        \| k'(t) \|\leq \| b-a \|\| df_{(1-t)a+tb} \|\leq M\| b-a \|=g'(t)
    \end{equation}
    La proposition \ref{PropDQLhSoy} est donc utilisable et
    \begin{equation}
        \| k(1)-k(0) \|=g(1)-g(0),
    \end{equation}
    c'est à dire
    \begin{equation}
        \| f(b)-f(a) \|=M\| b-a \|
    \end{equation}
    comme il se doit.
\end{proof}

\begin{proposition} \label{ProFSjmBAt}
    Soient \( E\) et \( F\) des espaces vectoriels normés, \( U \) ouvert dans \( E\) et une application \( f\colon U\to F\). Soient \( a,b\in U\) tels que \( \mathopen[ a , b \mathclose]\subset U\). Nous posons \( u=(b-a)/\| b-a \|\) et nous supposons que pour tout \( x\in\mathopen[ a , b \mathclose]\), la dérivée directionnelle
    \begin{equation}
        \frac{ \partial f }{ \partial u }(x)=\Dsdd{ f(x+tu) }{t}{0}
    \end{equation}
    existe. Nous supposons de plus que \( \frac{ \partial f }{ \partial u }(x)\) est continue en \( x=a\). Alors
    \begin{equation}
        \| f(b)-f(a) \|\leq\left( \sup_{x\in\mathopen[ a , b \mathclose]}\| \frac{ \partial f }{ \partial u }(x) \| \right)\| b-a \|.
    \end{equation}
\end{proposition}

\begin{proof}
    Nous posons évidemment 
    \begin{equation}
        M=\sup_{x\in\mathopen[ a , b \mathclose]}\| \frac{ \partial f }{ \partial u }(x) \| 
    \end{equation}
    et nous considérons les fonctions
    \begin{equation}
        k(t)=f\big( (1-t)a+tb \big)
    \end{equation}
    et
    \begin{equation}
        g(t)=tM\| b-a \|.
    \end{equation}
    Pour alléger les notations nous posons \( x=(1-t)a+tb\) et nous calculons avec un petit changement de variables dans la limite :
    \begin{equation}
        k'(t)=\Dsdd{  f\big( x+\epsilon(b-a) \big)  }{\epsilon}{0}=\| b-a \|\Dsdd{ f\big( x+\frac{ \epsilon }{ \| b-a \| }(b-a) \big) }{\epsilon}{0}=\| b-a \|\frac{ \partial f }{ \partial u }(x),
    \end{equation}
    et donc encore une fois nous avons
    \begin{equation}
        \| k'(t) \|\leq g'(t),
    \end{equation}
    ce qui donne
    \begin{equation}
        \| k(1)-k(0) \|=g(1)-g(0),
    \end{equation}
    c'est à dire
    \begin{equation}
        \| f(b)-f(a) \|\leq \sup_{x\in\mathopen[ a , b \mathclose]}\| \frac{ \partial f }{ \partial u }(x) \|\| b-a \|.
    \end{equation}
\end{proof}

\begin{theorem} \label{ThoOYwdeVt}
    Soient \( E,V\) deux espaces vectoriels normés, une application \( f\colon E\to V\), un point \( a\in E\) tel que pour tout \( u\in E\), la dérivée
    \begin{equation}
        \Dsdd{ f(x+tu) }{t}{0}
    \end{equation}
    existe pour tout \( x\in B(a,r)\) et est continue (par rapport à \( x\)) en \( x=a\). Nous supposons de plus que\quext{Je ne suis pas certain que cette hypothèse soit nécessaire, voir la question \ref{ItemLPrIWZhPg} de la page \pageref{ItemLPrIWZhPg}.}
    \begin{equation}
        \frac{ \partial f }{ \partial u }(a)=0
    \end{equation}
    pour tout \( u\in E\). Alors \( f\) est différentiable en \( a\) et
    \begin{equation}
        df_a=0
    \end{equation}
\end{theorem}

\begin{proof}
    Soit \( \epsilon>0\). Pourvu que \( \| h \|\) soit assez petit pour que \( a+h\in B(a,r)\), la proposition \ref{ProFSjmBAt} nous donne
    \begin{equation}
        \| f(a+h)-f(a) \|\leq \sup_{x\in\mathopen[ a , a+h \mathclose]}\| \frac{ \partial f }{ \partial u }(x) \|  |h |
    \end{equation}
    où \( u=h/\| h \|\). Par continuité de \( \partial_uf(x)\) en \( x=a\) et par le fait que cela vaut \( 0\) en \( x=a\), il existe un \( \delta>0\) tel que si \( \| h \|<\delta\) alors
    \begin{equation}
        \| \frac{ \partial f }{ \partial u }(a+h) \|\leq \epsilon.
    \end{equation}
    Pour de tels \( h\) nous avons
    \begin{equation}
        \| f(a+h)-f(a) \|\leq \epsilon\| h \|,
    \end{equation}
    ce qui prouve que l'application linéaire \( T(u)=0\) convient parfaitement pour faire fonctionner la définition \ref{DefKZXtcIT}.
%
%    Nous ne supposons plus que les dérivées directionnelles de \( f\) sont nulles en \( x=a\). Alors nous posons, pour \( x\in U\),
%    \begin{equation}    \label{EqCUgHXHy}
%        g(x)=f(x)-\Dsdd{ f(a+s(x-a)) }{s}{0}.
%    \end{equation}
%    Le fait que cette fonction soit bien définie est encore un coup de hypothèses sur les dérivées directionnelles de \( f\) qui sont bien définies autour de \( a\). Cette nouvelle fonction \( g\) satisfait à \( \frac{ \partial g }{ \partial v }(a)=0\) pour tout \( v\in E\) parce que
%    \begin{subequations}
%        \begin{align}
%            \frac{ \partial g }{ \partial v }(a)&=\Dsdd{ g(a+tv) }{t}{0}\\
%            &=\Dsdd{ f(a+tv)-\Dsdd{ f\big( a+s(tv) \big) }{s}{0} }{t}{0}\\
%            &=\frac{ \partial f }{ \partial v }(a)-\Dsdd{ t\frac{ \partial f }{ \partial v }(a) }{t}{0}\\
%            &=0.
%        \end{align}
%    \end{subequations}
%    Pour la dérivée par rapport à \( s\) nous avons effectué le changement de variables \( s\to ts\), ce qui explique la présence d'un \( t\) en facteur. La fonction \( g\) est donc différentiable en \( a\).
%
%
% Position 229262367
    % Attention : ce qui suit est faux. Mais il y a peut-être moyen d'adapter.
%\item[Dérivées non nulles]
%
%    Nous allons montrer que la fonction 
%    \begin{equation}
%        l(x)=\Dsdd{ f\big( a+s(x-a) \big) }{t}{0}
%    \end{equation}
%    est différentiable en \( x=a\), de différentielle \( T(u)=l(u+a)\). Cela fournira la différentiabilité de \( f\) parce que \eqref{EqCUgHXHy} donnerait alors \( f\) comme somme de deux fonctions différentiables.
%
%    En premier lieu nous devons montrer que \( T\) ainsi définie est linéaire.
%    
%    Notre but est donc de prouver que
%    \begin{equation}
%        \lim_{h \to 0}\frac{ \| l(x+h)-l(x)-l(h) \| }{ \| h \| }=0.
%    \end{equation}
%    Un premier pas est de calculer
%    \begin{subequations}
%        \begin{align}
%            l(x+h)-l(x)-l(h)&=\lim_{s\to 0}\frac{ f\big( s(x+h) \big)-f(0)-f(sx)+f(0)-f(sh)+f(0) }{ s }\\
%            &=\lim_{s\to 0}\frac{ f\big( s(x+h) \big)-f(sx)-f(sh)+f(0) }{ s }.
%        \end{align}
%    \end{subequations}
%    Ensuite nous étudions le numérateur en utilisant la proposition \ref{ProFSjmBAt}:
%    \begin{subequations}
%        \begin{align}
%            \| f\big( s(x+h) \big)-f(sx)-f(sh)+f(0) \|&\leq  \| f\big( s(x+h) \big)-f(sx)\| + \|f(sh)-f(0) \|  \\
%            &\leq \sup_{z\in\mathopen[ sx , sx+sh \mathclose]}\| \frac{ \partial f }{ \partial h }(z) \|\| sh \|\\
%            &\quad +\sup_{z\in\mathopen[ 0 , sh \mathclose]}\| \frac{ \partial f }{ \partial h }(z) \|\| sh \|.
%        \end{align}
%    \end{subequations}
%    La division par \( s\) se passe bien et nous avons
%    \begin{subequations}
%        \begin{align}
%            \| l(x+h)-l(x)-l(h) \|&\leq \lim_{s\to 0}  \sup_{z\in\mathopen[ sx , sx+sh \mathclose]}\| \frac{ \partial f }{ \partial h }(z) \|\| h \|+ \sup_{z\in\mathopen[ 0 , sh \mathclose]}\| \frac{ \partial f }{ \partial h }(z) \|\| h \|\\
%            &=2\| h \|\| \frac{ \partial f }{ \partial h }(0) \|        \label{SubeqVMMoSDH}\\
%            &=2\| h \|^2\| \frac{ \partial f }{ \partial u }(0) \|
%        \end{align}
%    \end{subequations}
%    où nous avons posé \( u=h/\| h \|\). Pour l'égalité \eqref{SubeqVMMoSDH} nous avons utilisé la continuité de \( \frac{ \partial f }{ \partial h }(z)\) en \( z=0\). Du coup
%    \begin{equation}
%        \lim_{y\to 0} \frac{ \| f(x+h)-f(x)-f(h) \| }{ \| h \| }=\lim_{h\to 0} 2\| h \|\| \frac{ \partial f }{ \partial u }(0) \|=0.
%    \end{equation}
%    Cela prouve que \( l\) est bien différentiable en \( x=0\).
%
%    \end{subproof}
%
\end{proof}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{L'inverse, sa différentielle}
%---------------------------------------------------------------------------------------------------------------------------

Si \( E\) est un espace de Banach, nous sommes intéressé à l'espace \( \GL(E)\) des endomorphismes inversibles de \( E\) sur \( E\). Cet ensemble est métrique par la formule usuelle
\begin{equation}
    \| T \|=\sup_{\| x \|=1}\| T(x) \|_E.
\end{equation}

\begin{theorem}[Inverse dans \( \GL(E)\)\cite{laudenbach2000calcul,SNPdukn}]    \label{ThoCINVBTJ}
    Soient \( E\) et \( F\) des espaces vectoriels normés.
    \begin{enumerate}
        \item
        L'ensemble \( \GL(E)\) est ouvert dans \( \End(E)\).
    \item
        L'application inverse
    \begin{equation}
        \begin{aligned}
        i\colon \GL(E,F)&\to \GL(F,E) \\
        u&\mapsto u^{-1} 
        \end{aligned}
    \end{equation}
    est de classe \( C^{\infty}\) et
    \begin{equation}
        di_{u_0}(h)=-u_0^{-1}\circ h\circ u_0^{-1}
    \end{equation}
    pour tout \( h\in\End(E)\)
    \end{enumerate}
\end{theorem}
\index{différentielle!de $u\mapsto u^{-1}$}

\begin{proof}
Nous supposons que \( \GL(E,F)\) n'est pas vide, sinon ce n'est pas du jeu.
        \begin{subproof}

        \item[Cas de dimension finie]

            Si la dimension de \( E\) et \( F\) est finie, elles doivent être égales, sinon il n'y a pas de fonctions inversibles \( E\to F\). L'ensemble \( \GL(E,F)\) est donc naturellement \( \GL(n,\eR)\). Un élément de \( \eM(n,\eR)\) est dans \( \GL(n,\eR)\) si et seulement si son déterminant est non nul. Le déterminant étant une fonction continue (polynomiale) en les entrées de la matrice, l'ensemble \( \GL(n,\eR)\) est ouvert dans \( \eM(n,\eR)\).

            Même idée pour la régularité de la fonction \( i\colon \GL(n,\eR)\to \GL(n,\eR)\), \( X\mapsto X^{-1}\). Les entrées de \( X^{-1}\) sont les cofacteurs de \( X\) divisé par \( \det(X)\), et donc des polynômes en les entrées de \( X\) divisés par un polynôme qui ne s'annule pas sur \( \GL(n,\eR)\), et donc sur un ouvert autour de \( X\) et de \( X^{-1}\). Bref, tout est \(  C^{\infty}\).

            Le reste de la preuve parle de la dimension infinie.

        \item[Ouvert autour de l'identité]
            
        Nous commençons par prouver que \( B(\mtu,1)\subset \GL(E)\). Pour cela il suffit de remarquer que si \( \| u \|<1\) alors le lemme \ref{PropQAjqUNp} nous donne un inverse de \( (1+u)\) en la personne de \( \sum_{k=0}^{\infty}(-u)^k\).

    \item[Ouvert en général]

        Soit maintenant \( u_0\in\GL(E)\). Si \( \| u \|<\frac{1}{ \| u_0^{-1} \| }\) alors \( \| u_0^{-1}u \|<1\), ce qui signifie que
        \begin{equation}
            \mtu+u_0^{-1}u
        \end{equation}
    est inversible. Mais \( u_0+u=u_0(\mtu+u_0^{-1}u)\), donc \( u_0+u\in\GL(E)\) ce qui signifie que
    \begin{equation}
    B\left( u_0,\frac{1}{ \| u_0^{-1} \| } \right)\subset \GL(E).
    \end{equation}

    \item[Différentielle en l'identité]

    Nous commençons par prouver que \( di_{\mtu}(u)=-u\). Pour cela nous posons 
    \begin{equation}
        \alpha(h)=\sum_{k=2}^{\infty}(-1)^kh^k
    \end{equation}
    et nous calculons
    \begin{equation}
    di_{\mtu}(u)=\Dsdd{ i(\mtu+tu) }{t}{0}=\Dsdd{ \mtu-tu+\alpha(tu) }{t}{0}.
    \end{equation}
    Il suffit de prouver que \( \Dsdd{ \alpha(tu) }{t}{0}=0\) pour conclure que \( di_{\mtu}(u)=-u\). Pour cela, nous remarquons que \( \alpha(0)=0\) et donc que
    \begin{subequations}
        \begin{align}
        \Dsdd{ \alpha(tu) }{t}{0}&=\lim_{t\to 0} \frac{ \alpha(tu)-\alpha(0) }{ t }\\
        &=\lim_{t\to 0} \sum_{k=2}^{\infty}(-1)^k\frac{ (tu)^k }{ t }\\
        &=-\lim_{t\to 0} u\sum_{k=1}^{\infty}(-1)^kt^ku^k.
        \end{align}
    \end{subequations}
    La norme de ce qui est dans la limite est majorée par
    \begin{equation}
    \| u \|\sum_{k=1}^{\infty}\| tu \|^k=\| u \|\left( \frac{1}{ 1-\| tu \| }-1 \right),
    \end{equation}
    et cela tend vers zéro lorsque \( t\to\infty\). Nous avons utilisé la somme \ref{EqRGkBhrX} de la série géométrique. Nous avons bien prouvé que \( di_{\mtu}(u)=-u\).

    \item[Différentielle en général]
    Soit maintenant \( u_0\in\GL(E)\) et \( h\in\End(E)\) tel que \( u_0+h\in \GL(E)\); par le premier point, il suffit de prendre \( \| h \|\) suffisamment petit. Vu que \( u_0+h=u_0(\mtu+u_0^{-1}h)\) nous avons
    \begin{equation}
        (u_0+h)^{-1}=(\mtu+u_0^{-1}h)^{-1}u_0^{-1}.
    \end{equation}
    Nous pouvons donc calculer
    \begin{equation}
        (u_0+h)^{-1}=\big( \mtu-u_0^{-1}h+\alpha(u_0^{-1}h) \big)u_0^{-1}=u_0^{-1}-u_0^{-1}hu_0^{-1}+\alpha(u_0^{-1}h)u_0^{-1},
    \end{equation}
    et ensuite
    \begin{equation}
        di_{u_0}(h)=\Dsdd{ i(u_0+th) }{t}{0}=\Dsdd{ u_0^{-1}-tu_0^{-1}hu_0^{-1}+\alpha(tu_0^{-1}h)u_0^{-1} }{t}{0},
    \end{equation}
    mais nous avons déjà vu que
    \begin{equation}
        \Dsdd{ \alpha(th) }{t}{0}=0,
    \end{equation}
    donc
    \begin{equation}
        di_{u_0}(h)=-u_0^{-1}hu_0^{-1}
    \end{equation}
    Cela donne la différentielle de l'application inverse.

    \item[Continuité de l'inverse]

        L'application \( i\) est continue parce que différentiable.
    \item[L'inverse est \(  C^{\infty}\)]

        Nous allons écrire la fonction inverse comme une composée. Soient les applications
        \begin{equation}
            \begin{aligned}
                B\colon \cL(F,E)\times \cL(F,E)&\to \cL\big( \cL(E,F),\cL(F,E) \big) \\
                B(\psi_1,\psi_2)(A)&= -\psi_1\circ A\circ\psi_2
            \end{aligned}
        \end{equation}
        et
        \begin{equation}
            \begin{aligned}
                \Delta\colon \cL(F,E)&\to \cL(F,E)\times \cL(F,E) \\
                \varphi&\mapsto (\varphi,\varphi) 
            \end{aligned}
        \end{equation}
        Nous avons alors 
        \begin{equation}
            di=B\circ\Delta\circ i.
        \end{equation}
        L'application \( \Delta\) est de classe \(  C^{\infty}\). Nous devons voir que \( B\) l'est aussi. Pour le voir nous commençons par prouver qu'elle est bornée :
        \begin{equation}
            \begin{aligned}[]
                \| B \|&=\sup_{\| \psi_1 \|,\| \psi_2 \|=1}\| B(\psi_1,\psi_2) \|_{\aL\big( L(E,F),L(F,E) \big)}\\
                &=\sup_{  \| \psi_1 \|,\| \psi_2 \|=1 }\sup_{\| A \|=1}\| \psi_1\circ A\circ\psi_2 \|_{L(F,E)}\\
                &\leq \sup_{\| \psi_1 \|,\| \psi_2 \|=1}\sup_{\| A \|=1}\| \psi_1 \|\| A \|\| \psi_2 \|\\
                &\leq 1.
            \end{aligned}
        \end{equation}
        Donc \( B\) est bien bornée et par conséquent continue. Une application bilinéaire continue est \(  C^{\infty}\) par le lemme \ref{LemFRdNDCd}. La décomposition \( di=B\circ \Delta\circ i\) nous donne donc que \( i\in C^{\infty}\) dès que \( i\) est continue, ce que nous avions déjà montré.
        \end{subproof}
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Projection orthogonale}
%---------------------------------------------------------------------------------------------------------------------------

Le théorème suivant n'est pas indispensablissime parce qu'il est le même que le théorème de la projection sur les espaces de Hilbert\footnote{Théorème \ref{ThoProjOrthuzcYkz}}. Cependant la partie existence est plus simple en se limitant au cas de dimension finie.
\begin{theorem}[Théorème de la projection]  \label{ThoWKwosrH}
    Soit \( E\) un espace vectoriel réel ou complexe de dimension finie, \( x\in E\), et \( C\) un sous ensemble fermé convexe de \(E\).
    \begin{enumerate}
        \item
            Les deux conditions suivantes sur \( y\in E\) sont équivalentes:
    \begin{enumerate}
        \item   \label{zzETsfYCSItemi}
            \( \| x-y \|=\inf\{ \| x-z \|\tq z\in C \}\),
        \item\label{zzETsfYCSItemii}
            pour tout \( z\in C\), \( \real\langle x-y, z-y\rangle \leq 0\).
    \end{enumerate}
\item
    Il existe un unique \( y\in E\), noté \( y=\pr_C(x)\) vérifiant ces conditions.
    \end{enumerate}
\end{theorem}
%TODO : il y a sûrement un endroit plus adapté pour mettre ce théorème.

\begin{proof}
    Nous commençons par prouver l'existence et l'unicité d'un élément dans \( C\) vérifiant la première condition. Ensuite nous verrons l'équivalence. 

    \begin{subproof}
        \item[Existence]
        
            Soit \( z_0\in C\) et \( r=\| x-z_0 \|\). La boule fermée \( \overline{ B(x,r) }\) est compacte\footnote{C'est ceci qui ne marche plus en dimension infinie.} et intersecte \( C\). Vu que \( C\) est fermé, l'ensemble \( C'=C\cap\overline{ B(x,r) }\) est compacte. Tous les points qui minimisent la distance entre \( x\) et \( C\) sont dans \( C'\); la fonction 
            \begin{equation}
                \begin{aligned}
                     C'&\to \eR \\
                    z&\mapsto d(x,z) 
                \end{aligned}
            \end{equation}
            est continue sur un compact et donc a un minimum qu'elle atteint\footnote{Théorème \ref{ThoMKKooAbHaro}.}. Un point \( P\) réalisant ce minimum prouve l'existence d'un point vérifiant la première condition.

        \item[Unicité]
            Soient \( y_1\) et \( y_2\), deux éléments de \( C\) minimisant la distance avec \( x\), et soit \( d\) ce minimum. Nous avons par l'identité du parallélogramme \eqref{EqYCLtWfJ} que
            \begin{equation}
                \| y_1-y_2 \|^2=-4\left\| \frac{ y_1+y_2-x }{2} \right\|^2+2\| y_1-x \|^2+2\| y_2-x \|^2\leq -4d+2d+2d=0.
            \end{equation}
            Par conséquent \( y_1=y_2\).

        \item[\ref{zzETsfYCSItemi}\( \Rightarrow\) \ref{zzETsfYCSItemii}]

            Soit \( z\in C\) et \( t\in \mathopen] 0 , 1 \mathclose[\); nous notons \( P=\pr_Cx\). Par convexité le point \( z=ty+(1-t)P\) est dans \( C\), et par conséquent,
                \begin{equation}
                    \| x-P \|^2\leq\| x-tz-(1-t)P \|^2=\| (x-P)-t(z-P) \|^2.
                \end{equation}
                Nous sommes dans un cas \( \| a \|^2\leq | a-b |^2\), qui implique \( 2\real\langle a, b\rangle \leq \| b \|^2\). Dans notre cas,
                \begin{equation}
                    2\real\langle x-P , t(z-P)\rangle \leq t^2\| z-P \|^2.
                \end{equation}
                En divisant par \( t\) et en faisant \( t\to 0\) nous trouvons l'inégalité demandée :
                \begin{equation}
                    2\real\langle x-P, z-P\rangle \leq 0.
                \end{equation}
                
        \item[\ref{zzETsfYCSItemii}\( \Rightarrow\) \ref{zzETsfYCSItemi}]

            Soit un point \( P\in C\) vérifiant 
            \begin{equation}
                \real\langle x-P, z-P\rangle \leq 0
            \end{equation}
            pour tout \( z\in C\). Alors en notant \( a=x-P\) et \( b=P-z\),
            \begin{equation}
                \begin{aligned}[]
                \| x-z \|^2=\| x-P+P-z \|^2&=\| a+b \|^2\\
                &=\| a \|^2+\| b \|^2+2\real\langle a, b\rangle \\
                &=\| a \|^2+\| b \|^2-2\real\langle x-P, z-P\rangle \\
                &\geq \| b \|^2,
                \end{aligned}
            \end{equation}
            ce qu'il fallait.
    \end{subproof}
\end{proof}

