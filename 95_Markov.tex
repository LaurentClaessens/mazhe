% This is part of Mes notes de mathématique
% Copyright (c) 2012-2013,2015
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.

\begin{quote}
    Mets tes deux pieds en canard, c'est la chaîne de Markov qui se prépare.
\end{quote}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Généralités}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Les chaînes de Markov interviennent pour la description des systèmes dont l'évolution future ne dépend que de l'état présent.

\begin{definition}
    Soit \( E\) un ensemble au plus dénombrable et \( (\Omega,\tribF,P)\) un espace probabilisé. Une \defe{chaîne de Markov}{chaîne!de Markov} à valeurs dans \( E\) est une famille \( (X_n)_{n\in\eN}\) de variables aléatoires telles que pour tout \( x_0,\ldots,x_{n+1}\in E\),
    \begin{equation}
        P(X_{n+1}=x_{n+1}|X_n=x_n,\ldots,X_0=x_0)=P(X_{n+1}=x_{n+1}|X_n=x_n).
    \end{equation}
\end{definition}
Pour une chaîne de Markov, il n'est pas important de savoir l'historique pour prédire la futur : \( X_{n+1}\) est seulement déterminé par \( X_n\).

\begin{remark}
    Il existe une théorie des chaînes de Markov à temps continu ou avec \( E\) non dénombrable, mais ce n'est pas au programme.
\end{remark}

Nous notons
\begin{equation}
    p_n(x,y)=P(X_{n+1}=y|X_n=x)
\end{equation}
la \defe{probabilité de transition}{transition!probabilité} de la chaîne à l'instant \( n\). Si cette probabilité ne dépend pas de \( n\), nous disons que la chaîne de Markov est \defe{homogène}{homogène!chaîne de Markov}\index{chaîne!de Markov!homogène}, et nous notons \( p(x,y)\) au lieu de \( p_n(x,y)\). Nous notons \( Q\) la matrice (éventuellement infinie) de transition\index{matrice!de transition}
\begin{equation}
    Q_{xy}=p(x,y).
\end{equation}
Nous avons
\begin{equation}
    \sum_{y\in E}p(x,y)=1
\end{equation}
parce que c'est la somme de toutes les transitions possibles en partant de \( x\). Notons aussi que \( p(x,y)\geq~0\).

\begin{definition}      \label{DefGJEBooZvuIAV}
    Une matrice dont tous les éléments sont positifs ou nuls et donc la somme de toutes les lignes sont \( 1\) est une \defe{matrice stochastique}{matrice!stochastique}.
\end{definition}
Notons que l'ensemble des matrices stochastiques est un fermé dans l'ensemble des matrices.

\begin{lemma}
    Si \( U\) est une matrice stochastique\footnote{Définition \ref{DefGJEBooZvuIAV}.}, alors il existe une chaîne de Markov dont la matrice de transition est \( U\).
\end{lemma}

\begin{remark}
    La somme \( \sum_{x\in E}p(x,y)\) ne vaut pas spécialement \( 1\). Si les états \( x_1\) et \( x_2\) arrivent tous les deux en \( y\) de façon certaine, alors nous avons \( \sum_xp(x,y)\geq 2\). Il n'y a donc pas de limites aux sommes des colonnes.
\end{remark}

\begin{example}
    Nous considérons une fourmi qui se déplace dans un appartement à trois pièces \( A\), \( B\), \( C\). Supposons qu'à chaque minute, elle a une probabilité \( 1/3\) de rester dans la pièce et une probabilité \( 2/3\) de se déplacer. Le plan de l'appartement est
    \begin{equation}
        \xymatrix{%
        A \ar[r]      &  B\ar[r]&C
           }
    \end{equation}
    De la pièce \( A\) est est donc uniquement possible d'aller vers la pièce \( B\); de la \( B\) il est possible d'aller en \( A\) et en \( C\) et de la \( C\) il est uniquement possible d'aller en \( B\).

    La matrice de transition de cette chaîne de Markov est 
    \begin{equation}
        Q=\begin{pmatrix}
            1/3    &   2/3    &   0    \\
            1/3    &   1/3    &   1/3    \\
            0    &   2/3    &   1/3
        \end{pmatrix}
    \end{equation}
\end{example}

\begin{example}
    Si \( N_t\) est un processus de Poisson, alors les variables aléatoires \( X_n=N_n\) forment une chaîne de Markov.
\end{example}
% TODO : donner une raison.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Chaînes de Markov sur un ensemble fini}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
%TODO : il y a des tonnes de résultats à déplacer vers cette section.

Une chaîne de Markov est \defe{finie}{chaîne!de Markov!finie} si l'ensemble \( E\) dans lequel elle prend ses valeurs est fini.

\begin{proposition}[\cite{GMbugcT}]
    Si \( (X_n)\) est une chaîne de Markov irréductible sur un ensemble fini, alors pour tout ensemble \( A\subset E\) nous avons
    \begin{equation}
        P(\tau_A<\infty)=\lim_{n\to \infty} P(\tau_A\leq n)=1
    \end{equation}
    où \( \tau_A=\min\{ k\tq X_k\in A \}\).
\end{proposition}

Les proposition à venir vont montrer que
\begin{enumerate}
    \item
        Toute matrice stochastique admet un état stationnaire, proposition \ref{PropOJumFwe}.
    \item
        Si la chaîne de Markov est irréductible, alors il y a unicité de l'état stationnaire, proposition \ref{PropUMPpOHW}. Mais attention : cela ne veut pas encore dire que la chaîne converge effectivement vers cet état.
    \item
        Si la chaîne est irréductible et apériodique, alors il y a convergence en loi vers l'unique loi invariante, théorème \ref{ThoQSuLZoz}.
\end{enumerate}
%TODO : il faut de preuves à tout ça; c'est dans le document cité. 
%TODO : mettre les définitions utiles au dessus.

\begin{proposition}[\cite{MarkGuy}] \label{PropOJumFwe}
    Toute matrice stochastique admet un état stationnaire.
\end{proposition}

\begin{proposition}[\cite{MarkGuy}]     \label{PropUMPpOHW}
    Soit une chaîne de Markov irréductible finie. Alors il existe une unique loi stationnaire \( \pi\) et de plus nous avons \( \pi_i>0\) pour tout état \( i\) de \( E\).
\end{proposition}

\begin{definition}
    Une chaîne de Markov finie est \defe{régulière}{chaîne!de Markov!régulière} si il existe un \( n\in \eN\) tel que \( P^n\) a uniquement des éléments strictement positifs.
\end{definition}

\begin{theorem}[\cite{GMbugcT}]
    Soit \( P\) la matrice de transition d'une chaîne de Markov régulière sur un ensemble \( E\) de cardinal \( N\). Alors il existe des nombres \( \pi_1,\ldots, \pi_N\) tels que
    \begin{enumerate}
        \item
            \( \pi_i>0\) pour tout \( i=1,\ldots, N\)
        \item
            \( \pi_1+\ldots +\pi_N=1\)
        \item
            \begin{equation}
                \lim_{n\to \infty} P^n=\Pi=\begin{pmatrix}
                     \pi_1   &   \pi_2    &   \ldots    &   \pi_N    \\
                     \vdots   &   \vdots    &       &   \vdots    \\ 
                     \pi_1   &   \pi_2    &   \ldots    &   \pi_N
                 \end{pmatrix}
            \end{equation}
    \end{enumerate}
    De plus le vecteur \( \pi=(\pi_1,\ldots, \pi_N)\) est l'unique solution de 
    \begin{equation}
        \pi P=\pi.
    \end{equation}
\end{theorem}

\begin{proof}
    Si la chaîne n'a qu'un seul état c'est évident parce que la probabilité de transition est toujours \( 1\); fin de l'histoire.

    \begin{subproof}
        \item[Hypothèse]

            Sinon nous supposons que \( P\) n'a que des éléments positifs, quitte à considérer \( P^n\) au lieu de \( P\). Nous notons \( d\) le plus petit élément de \( P\); il vérifie \( d\leq \frac{ 1 }{2}\) parce que la somme des élément d'une ligne de la matrice \( P\) doit être égale à \( 1\).

        \item[Les suites min et max]

            Soit \( x\) un vecteur quelconque (de composantes positives). Nous notons \( m_0=\min\{ x_i \}\) et \( M_0=\max\{ x_i \}\). Étant donné que les éléments du vecteur \( Px\) sont des moyennes pondérées des éléments de \( x\), si nous posons
            \begin{subequations}
                \begin{align}
                    m_k=\min\{ (P^kx)_i \}_{i=1,\ldots, N}\\
                    M_k=\max\{ (P^kx)_i \}_{i=1,\ldots, N},
                \end{align}
            \end{subequations}
            la suite \( (m_k)\) est croissante et la suite \( (M_k)\) est décroissante.

        \item[Stricte croissance et décroissance]

            Si \( M_{k+1}=M_k\), alors toutes les composantes de \( P^kx\) sont égales à \( M_k\) et le théorème est prouvé. Cela est encore une propriété de la moyenne. Même remarque pour la suite \( (m_k)\).

            Nous pouvons donc supposer que la suite \( (m_k)\) est strictement croissante et que la suite \( (M_k)\) est strictement décroissante. Elles sont toutes les deux bornées dans \( \mathopen[ m_0 , M_0 \mathclose]\). Le lemme \ref{LemSuiteCrBorncv} nous donne la convergence.

        \item[Égalité des limites]

            Vu que les éléments de \( P^kx\) ne sont pas tous les mêmes et s'étalent de \( m_k\) à \( M_k\), pour majorer \( M_{k+1}\) nous mettons le plus petit coefficient possible (c'est à dire \( d\)) devant \( m_k\) et nous supposons que toutes les autres composantes sont \( M_k\); nous avons alors
            \begin{equation}
                M_{k+1}\leq dm_k+(1-d)M_k
            \end{equation}
            parce que tous les autres coefficients de la ligne contenant le \( d\) (dans \( P^k\)) sont plus petits ou égaux à \( 1-d\). De la même façon nous avons la minoration
            \begin{equation}
                m_{k+1}\geq dM_k+(1-d)m_k.
            \end{equation}
            En faisant la différence, et en nous souvenant que \( 0<1-2d<1\),
            \begin{equation}
                M_{k+1}-m_k\leq (1-2d)(M_k-m_k),
            \end{equation}
            ce qui signifie que
            \begin{equation}
                M_{k+1}-m_k\leq (1-2d)^k(M_0-m_0),
            \end{equation}
            et donc que les deux limites sont égales.

        \item[Conclusion pour la limite]

            Pour tout vecteur \( x\), la suite \( P^kx\) tend vers un vecteur dont toutes les composantes sont égales. En particulier pour le vecteur \( e_i\) de la base canonique,
            \begin{equation}
                P^ke_i\to\begin{pmatrix}
                    \pi_1    \\ 
                    \vdots    \\ 
                    \pi_1    
                \end{pmatrix}.
            \end{equation}
            Mais \( P^ke_i\) est la \( i\)\ieme\ colonne de la matrice \( P^k\). Cela prouve la convergence annoncée \( P^k\to \Pi\).
    \end{subproof}

    Réglons rapidement le cas des deux autres allégations du théorème. D'abord les matrices \( P^k\) sont toutes des matrices stochastiques; et l'ensemble des matrices stochastiques est fermé, donc la convergence se fait à l'intérieur de l'ensemble des matrices stochastiques. Cela prouve que \( \pi_1+\ldots +\pi_N=1\).

    Ensuite la suite \( (m_k)\) étant strictement croissante et \( m_0\) étant égal à \( 0\) dans le cas de \( e_i\) nous avons toujours \( \pi_i>0\) (strictement).
\end{proof}

\begin{theorem}[\cite{MarkGuy}]     \label{ThoQSuLZoz}
    Si \( (X_n)\) est une chaîne de Markov finie, irréductible et apériodique de loi stationnaire \( \pi\), alors
    \begin{enumerate}
        \item
            La suite de matrices stochastiques \( P^k\) converge vers la matrice
            \begin{equation}
                P^k\to\Pi=\begin{pmatrix}
                    \pi    \\ 
                    \vdots    \\ 
                    \pi    
                \end{pmatrix}.
            \end{equation}
        \item
            Nous avons convergence des variables aléatoires au sens où
            \begin{equation}
                P(X_k=\mu P^k)\to \pi.
            \end{equation}
    \end{enumerate}
\end{theorem}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Marche aléatoire sur \texorpdfstring{$\eZ$}{\( \eZ\)}}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\index{variable aléatoire!Bernoulli!marche aléatoire}

%TODO : dans le fichier markov.pdf de Nils Berglund, il y a des choses intéressantes, dont le fait que l'espérance du temps qu'il faut pour retourner en zéro est infinie.

Soit \( (Y_n)\) une suite de variables aléatoires indépendantes et identiquement distribuées valant \( -1\) avec une probabilité \( p\) et \( 1\) avec une probabilité \( (1-p)\). La loi est
\begin{equation}
    Y_n\sim p\delta_{-1}+(1-p)\delta_{1}.
\end{equation}
Nous considérons la variable aléatoire
\begin{equation}
    X_n=X_0+\sum_{i=1}^nY_i
\end{equation}
où \( X_0\) est une variable aléatoire indépendante des \( Y_i\) à valeurs dans \( \eZ\). Nous vérifions à présent que \( X_n\) est une chaîne de Markov avec comme espace d'états \( E=\eZ\). Nous devons montrer que
\begin{equation}        \label{EqAVoirMarkovMAZ}
    P\big( X_{n+1}=x_{n+1}| X_n=x_n,\ldots,X_0=x_0 \big)=P\big( X_{n+1}=x_{n+1}|X_n=x_n \big).
\end{equation}
Pour ce faire nous allons exprimer tout cela en termes des \( Y_i\) au lieu des \( X_i\). D'abord étant donné que nous avons égalité des événements
\begin{equation}
    \{ X_{n+1}=x_{n+1} \}\cap\{ X_n=x_n,\ldots, X_0=x_0 \}= \{ Y_{n+1}=x_{n+1}-x_n \}\cap\{X_n=x_n,\ldots, X_0=x_0\},
\end{equation}
nous pouvons, en vertu du principe \eqref{EqOVHCWom}, remplacer \( X_{n+1}=x_{n+1}\) par \( Y_{n+1}=x_{n+1}-x_n\) dans le membre de gauche de \eqref{EqAVoirMarkovMAZ}. Nous avons donc déjà
\begin{equation}      
    P\big( X_{n+1}=x_{n+1}| X_n=x_n,\ldots,X_0=x_0 \big)=P\big( \underbrace{Y_{n+1}=x_{n+1}-x_n}_{A}| \underbrace{X_n=x_n,\ldots,X_0=x_0}_{B} \big).
\end{equation}

L'événement \( B\) est égal à l'événement
\begin{equation}
    \{ X_0=x_0,Y_1=x_1-x_0,Y_2=x_2-x_1,\ldots,Y_n=x_n-x_{n-1} \},
\end{equation}
qui n'est autre que l'ensemble
\begin{equation}
    X_0^{-1}(x_0)\cap Y_1^{-1}(x_1-x_0)\cap\ldots\cap Y_{n}^{-1}(x_n-x_{n-1})
\end{equation}
qui est dans la tribu engendrée par les variables aléatoires \( X_0,(Y_i)_{i=1,\ldots,n}\). Le point délicat du raisonnement est de montrer que les événements \( A\) et \( B\) donnés par
\begin{subequations}
    \begin{align}
        A&=\{ Y_{n+1}=x_{n+1}-x_n \}\\
        B&=\{ X_0=x_0 \}\cap\bigcap_{i=1}^n \{ Y_i=x_i-x_{i-1}\}
    \end{align}
\end{subequations}
sont indépendants. Nous ne pouvons pas montrer directement que \( P(A\cap B)=P(A)P(B)\) parce que cela est la formule que nous voulons utiliser pour montrer que la chaîne est de Markov. Nous passons donc par les tribus :
\begin{subequations}        \label{subesqqsABtribsYYXzY}
    \begin{align}
        A&\in\sigma(Y_{n+1})\\
        B&\in\sigma(X_0,Y_1,\ldots,Y_n).
    \end{align}
\end{subequations}
Nous utilisons maintenant l'hypothèse d'indépendance des variables aléatoires \( X_0\) et \( Y_i\) pour conclure que les deux tribus des équations \eqref{subesqqsABtribsYYXzY} sont indépendantes. Les événements \( A\) et \( B\) sont par conséquent indépendants. 

L'événement \( A\) est indépendant de l'événement \( \{ X_n=x_n \}\). Nous avons donc successivement
\begin{subequations}
    \begin{align}
        P\big( X_{n+1}=x_{n+1}| X_n=x_n,\ldots,X_0=x_0 \big)&=P\big( Y_{n+1}=x_{n+1}-x_n| X_n=x_n,\ldots,X_0=x_0 \big)\\
        &=P\big( Y_{n+1}=x_{n+1}-x_n|  Y_i=x_i-x_{i-1},X_0=x_0\big)\\
        &=P(Y_{n+1}=x_{n+1}-x_n)        \label{EqEDQkUcm_c}\\
        &=P(Y_{n+1}=x_{x+1}-x_n|X_n=x_n)    \label{EqEDQkUcm_d}\\
        &=P(Y_{n+1}=x_{n+1}-X_n|X_n=x_n)        \label{EqEDQkUcm_e}\\
        &=P(X_{n+1}=x_{n+1}|X_n=x_n).
    \end{align}
\end{subequations}
Justifications :
\begin{itemize}
    \item \eqref{EqEDQkUcm_c} parce que les tribus $\sigma(Y_{n+1})$ et \( \sigma(Y_i,X_0)\) sont indépendantes.
    \item \eqref{EqEDQkUcm_d} Nous avons
        \begin{equation}
    \{ X_n=x_n \}\in\sigma(X_0,Y_1,\ldots, Y_n)
\end{equation}
tandis que
\begin{equation}
    \{ Y_{n+1}=x_{n+1}-x_n \}\in\sigma(Y_{n+1});
\end{equation}
ce sont donc deux événements issus de tribus indépendantes. Donc conditionner ou non l'événement \( Y_{n+1}=x_{n+1}-x_n\) à l'événement \( X_n=x_n\) ne change rien.
\item \eqref{EqEDQkUcm_e} est encore l'utilisation du fait que \( P(A|B)=P(K|B)\) dès que \( A\cap B=K\cap B\).

\end{itemize}

La chaîne est par conséquent de Markov.

La matrice de transition de cette chaîne de Markov est une matrice infinie «dans tous les sens» :
\begin{equation}
    p(x,y)=\begin{cases}
        p    &   \text{si $y=x-1$}\\
        (1-p)    &    \text{si $y=x+1$}\\
        0    &   \text{sinon}.
    \end{cases}
\end{equation}

\begin{remark}
    La plupart du temps lorsqu'il faut démontrer qu'une chaîne est de Markov, il faut suivre la procédure que nous venons de suivre pour la marche aléatoire sur \( \eZ\).
    \begin{itemize}
        \item Écrire tout en fonction des incréments.
        \item Dire que les incréments conditionnés sont indépendants des incréments qui conditionnent (via les tribus engendrées).
        \item Écrire que la probabilité cherchée est égale à l'événement conditionné dans lequel on a juste remplacé l'incrément par sa valeur.
        \item Conditionner à nouveau par rapport au dernier incrément qui est indépendant.
        \item Changer la valeur du dernier incrément par la variable aléatoire.
    \end{itemize}
    Dans ce raisonnement nous utilisons deux fois le fait que \( P(A|B)=P(K|B)\) si \( A\cap B=K\cap B\).
\end{remark}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Chaînes de Markov homogènes}
%---------------------------------------------------------------------------------------------------------------------------

\begin{proposition}
    Voici quelques propriétés des chaînes de Markov homogènes.
    \begin{enumerate}
        \item
            La probabilité d'une trajectoire donnée est
            \begin{equation}
                P(X_n=x_n,X_{n-1}=x_{n-1},\ldots,X_0=x_0)=p(x_{n-1},x_n)\dots p(x_0,x_1)P(X_0=x_0).
            \end{equation}
        \item
            La probabilité de transition «en \( n\) coups» est donnée par la puissance \( n\)ième de la matrice de transition :
            \begin{equation}
                P(X_n=x_n|X_0=x_0)=Q^n_{x_0,x_n}.
            \end{equation}
        \item
            Si l'espace des états \( E\) est fini, l'espérance d'une fonction bornée \( f\colon E\to \eR\) de l'état est donnée par
            \begin{subequations}
                \begin{align}
                    E\big( f(X_{n+1})|X_n=x_n,\ldots,X_0=x_0 \big)&=E\big( f(X_{n+1})|X_n=x_n \big)\\
                    &=\sum_{y\in E}f(y)p(x_n,y).j
                \end{align}
            \end{subequations}
    \end{enumerate}
\end{proposition}

\begin{proof}
    \begin{enumerate}
        \item
            Étant donné que \( P(A\cap B)=P(A|B)P(B)\), nous avons
            \begin{equation}
                P(X_n=x_n,\ldots,X_0=x_0)=P(X_n=x_n|X_{n-1}=x_{n-1},\ldots,X_0=x_0)P(X_{n-1}=x_{n-1},\ldots,X_0=x_0).
            \end{equation}
            Par la propriété de Markov, le premier facteur est
            \begin{equation}
                P(X_n=x_n|X_{n-1}=x_{n-1})=p(x_{n-1},x_n).
            \end{equation}
            Le reste est une récurrence sur \( n\).

        \item
            Montrons avec \( n=2\). En utilisant les divers points du théorème \ref{ThoBayesEtAutres}, nous avons
            \begin{subequations}
                \begin{align}
                    P(X_2=x_2|X_0=x_0)&=\sum_{y\in E}P(X_2=x_2,X_1=y|X_0=x_0)\\
                    &=\sum_{y\in E}P(X_2=x_2|X_1=y,X_0=x_0)P(X_1=y|X_0=x_0)\\
                    &=\sum_{y\in E}P(X_2=x_2|X_1=y)P(X_1=y|X_0=x_0)\\
                    &=\sum_{y\in E}p(x_2,y)p(y,x_0) \label{subEqyExdyyxz}\\
                    &=Q^2_{x_2,x_0}.
                \end{align}
            \end{subequations}
            Bien entendu ici la notion de produit matriciel doit être comprise de façon formelle lorsque \( E\) est infini.
            \begin{remark}
                Nous avons utilisé l'homogénéité de la chaîne de Markov au moment d'écrire l'expression \eqref{subEqyExdyyxz}. En principe nous aurions dû écrire \( p_2(y,x_2)p_1(x_0,y)\).
            \end{remark}
    \end{enumerate}
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Graphe de transition}
%---------------------------------------------------------------------------------------------------------------------------

Le \defe{graphe de transition}{graphe!de transition (chaîne de Markov)} d'une chaîne de Markov est le graphe dont les sommets sont les éléments de l'espace des états de la chaîne et dont les sommets sont reliés par des arrêtes pondérées par la probabilité de transition correspondante.

\begin{definition}
    Une chaîne de Markov est \defe{irréductible}{irréductible!chaîne de Markov}\index{chaîne!de Markov!irréductible} si pour tout \( x,y\in E\), il existe \( n\) tel que \( p^n(x,y)>0\) où 
    \begin{equation}
        p^n(x,y)=P(X_n=y|X_0=x).
    \end{equation}
    Le nombre \( n\) peut dépendre de \( x\) et \( y\).
\end{definition}

\begin{lemma}
    Une chaîne de Markov homogène est irréductible si et seulement si son graphe de transition est connexe.
\end{lemma}

\begin{proof}
    Pour chaque couple \( (x,y)\in E^2\) nous avons
    \begin{equation}
        \begin{aligned}[]
            p^n(x,y)&=\sum_{z_i\in E}P(X_n=y,X_{n-1}=z_{n-1},\ldots,X_1=z_1,X_0=x)\\
            &=\sum_{z_i}p(z_{n-1},y)p(z_{n-2},z_{n-1})\ldots p(z_1,z_2)p(x,z_1).
        \end{aligned}
    \end{equation}
    La positivité d'un des termes de la somme signifie que le graphe est connexe tandis que la positivité de \( p^n(x,y)\) signifie que la chaîne est irréductible.
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Chaîne de Markov définie par récurrence}
%---------------------------------------------------------------------------------------------------------------------------

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Le cas général}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

\begin{proposition}     \label{PropqiMdHh}
    Soit \( X_0\) une variable aléatoire à valeurs dans $E$, un ensemble au plus dénombrable. Soit \( (Y_n)\) une suite de variables aléatoires réelles indépendantes et identiquement distribuées indépendantes de \( X_0\).

    Soit \( (X_n)\) la suite de variables aléatoires à valeurs dans \( E\) définie par récurrence selon la formule
    \begin{equation}
        X_{n+1}=G(X_n,Y_{n+1})
    \end{equation}
    où \( G\colon E\times \eR\to E\) est une fonction mesurable. Alors \( (X_n)\) est une chaîne de Markov.
\end{proposition}

\begin{proof}
    Soient \( x_0,\ldots, x_{n+1}\) des éléments de \( E\). Nous devons calculer la valeur de
    \begin{equation}
        P(X_{n+1}=x_{n+1}|X_n=x_n,\ldots, X_0=x_0).
    \end{equation}
    Commençons par préciser les espaces sur lesquels nos variable aléatoires sont définies. Nous avons
    \begin{equation}
        X_0\colon \Omega_0\to E
    \end{equation}
    et 
    \begin{equation}
        Y_i\colon \Omega\to \eR.
    \end{equation}
    La variable aléatoire \( X_1\) est donnée par
    \begin{equation}
        \begin{aligned}
            X_1\colon \Omega_0\times \Omega&\to E \\
            (\omega_0,\omega_1)&\mapsto G\big( X_0(\omega_0),Y_1(\omega_1) \big). 
        \end{aligned}
    \end{equation}
    La variable aléatoire \( X_2\) est 
    \begin{equation}
        \begin{aligned}
            X_2\colon \Omega_0\times \Omega^2&\to E \\
            (\omega_0,\omega_1,\omega_2)&\mapsto G\big( X_1(\omega_0,\omega_1),Y_2(\omega_2) \big)\\
                &\quad=G\Big( G\big( X_0(\omega_0),\omega_1 \big),Y_2(\omega_2) \Big)
        \end{aligned}
    \end{equation}
    et ainsi de suite.

    Considérons maintenant l'événement
    \begin{equation}
        \{ X_1=x_1,X_0=x_0 \}\subset \Omega_0\times \Omega.
    \end{equation}
    Il est donné explicitement par
    \begin{subequations}
        \begin{align}
            \{ X_1=x_1,X_0=x_0 \}&=\{ (\omega_0,\omega_1)\tq G\big( X_0(\omega_0),Y_1(\omega_1)=x_1,X_0(\omega_0)=x_0 \big) \}\\
            &=\{ (\omega_0,\omega_1)\tq G\big( x_0,Y_1(\omega_1)=x_1,X_0(\omega_0)=x_0 \big) \}\\
            &=\{ \omega_0\in \Omega_0\tq X_0(\omega_0)=x_0 \}\times \{ \omega_1\in \Omega\tq G\big( x_0,Y_1(\omega_1)=x_1 \big) \}.
        \end{align}
    \end{subequations}
    Le premier terme du produit cartésien est dans \( \sigma(X_0)\), tandis que le second est dans \( \sigma(Y_1)\). Étant donné la définition des tribus produit (définition \ref{DefTribProfGfYTuR}) nous avons
    \begin{equation}
        \{ X_1=x_1,X_0=x_0 \}\in\sigma(X_0,Y_1).
    \end{equation}
    Ce raisonnement se généralise immédiatement et nous trouvons que
    \begin{equation}
        \{ X_n=x_n,\ldots, X_0=x_0 \}\in\sigma(X_0,Y_1,\ldots, Y_n).
    \end{equation}
    Nous sommes donc à calculer
    \begin{subequations}
        \begin{align}
        \diamondsuit&=P(X_{n+1}=x_{n+1}|X_n=X_n,\ldots, X_0=X_0)\\
        &=P\big( \underbrace{G(x_n,Y_{n+1})=x_{n+1}}_{\in\sigma(Y_{n+1})}|\underbrace{X_n=x_n,\ldots, X_0=x_0}_{\in\sigma X_0,Y_1,\ldots, Y_n} \big).
        \end{align}
    \end{subequations}
    Les tribus \( \sigma(Y_{n+1})\) et \( \sigma(X_0,Y_1,\ldots, Y_n)\) étant indépendantes nous avons
    \begin{subequations}
        \begin{align}
            \diamondsuit&=P\big( G(x_n,Y_{n+1})=x_{n+1} \big)\\
            &=P\big( G(x_n,Y_{n+1})=x_{n+1}|X_n=X_n \big)       \label{jdvyUK}\\
            &=P\big( G(X_n,Y_{n+1})=x_{n+1}|X_n=x_n \big)\\
            &=P(X_{n+1}=x_{n+1}|X_n=x_n).
        \end{align}
    \end{subequations}
    Pour \eqref{jdvyUK} nous avons utilisé le fait que \( \sigma(Y_{n+1})\) est indépendante de \( \sigma(X_n)\). Nous avons prouvé que la chaîne était de Markov.
\end{proof}
Les probabilités de transition de la chaîne de Markov définie dans la proposition \ref{PropqiMdHh} sont
\begin{equation}
    P(X_1=y|X_0=x)=P\big( G(X_0,Y_1)=y|X_0=x_0 \big)=P\big( G(x_0,Y_1)=y \big).
\end{equation}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Exemple : la file de réparation de machines à laver}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Nous considérons un magasin de réparation d'électroménager. Durant le jour \( n\), un nombre aléatoire \( Z_{n}\) de machines en panne arrivent au magasin. Une machine est réparée chaque jour (aucune si le magasin est vide). Nous supposons que les \( Z_n\) soient indépendantes et identiquement distribuées, et nous posons \( X_n\), le nombre de machines en magasin le jour \( n\).

La loi d'avancement de \( X_n\) est
\begin{equation}
    X_{n+1}=\begin{cases}
        X_n+Z_n-1    &   \text{si \( X_n\neq 0\)}\\
        Z_n    &    \text{si \( X_n=0\)}.
    \end{cases}
\end{equation}
Cela est une chaîne de Markov en vertu de la proposition \ref{PropqiMdHh}. Ici la fonction est
\begin{equation}
    G(x,y)=x+y-\mtu_{x\neq 0}.
\end{equation}
Les probabilités de transitions sont 
\begin{equation}
    p(x,y)=\begin{cases}
        0    &   \text{si \( x\leq y-2\)}\\
        P(Z=0)    &    \text{si \( x=y-1\)}\\
        P(Z=k)&\text{si \( x=y+k-1\)}
    \end{cases}
\end{equation}
pour \( x\neq 0\).


\Exo{Model-0007}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Classification des états}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Sauf mention expresse du contraire, nous considérons toujours une chaîne de Markov homogène.

\begin{definition}
    Un état \( x\in E\) est \defe{absorbant}{absorbant} pour la chaine \( (X_n)\) si \( p(x,x)=1\).
\end{definition}
Il n'est pas spécialement impossible d'arriver sur un état absorbant, mais il est impossible d'en sortir.

Si \( x\in E\), nous notons
\begin{equation}
    T(x)=\inf\{ k\geq 1\tq X_k=x \},
\end{equation}
le \defe{premier temps d'atteinte}{premier temps d'atteinte} de l'état \( x\). Si \( X_0=x\), alors \( T(x)\) est le \defe{temps de retour}{temps de retour} en \( x\). Si \( p\in \eN\) nous notons
\begin{equation}
    T_p(x)=\inf\{ k\geq 1\tq X_{k+p}=x \}.
\end{equation}
C'est le temps mis pour atteindre \( x\) à partir de l'instant \( p\).

\begin{proposition}
    La loi de la variable aléatoire \( [T_p(x)|X_p=x]\) est la même que celle de la variable aléatoire \( [T(x)|X_0=x]\).
\end{proposition}

\begin{proof}
    Nous devons montrer que 
    \begin{equation}
        P(T_p(x)=k|X_p=x)=P(T(x)=k|X_0=x).
    \end{equation}
    Cela est intuitivement évident du fait qu'une chaîne de Markov soit un processus sans mémoire. Afin de prouver, nous allons sommer sur tous les états intermédiaires possibles :
    \begin{subequations}
        \begin{align}
            P&(T_p(x)=k|X_0=x)=P(X_{p+k}=x,X_{p+k-1}\neq x,\ldots,X_{p+1}\neq x|X_p=x)\\
            &=\sum_{z_i\neq x}P(X_{p+k}=x,X_{p+k-1}=z_{k-1},\ldots,X_{p+1}=z_1|X_p=x)\\
            &=\sum_{z_i}P(X_{p+k}=x,X_{p+k-i}=z_i|X_{p+1}=z_1,X_p=x)\underbrace{P(X_{p+1}=z_1|X_p=x)}_{=p(x,z_1)}\\
            &=\sum_{z_i}P(X_{p+k}=x,X_{p+k-i}=z_i|X_{p+2}=z_2,X_{p+1}=z_1,X_p=x)\\
            &\qquad\underbrace{P(X_{p+2}=z_2|X_{p+1}=z_1,X_p=x)}_{P(X_{p+2}=z_2|X_{p+1}=z_1)=p(z_1,z_2)}p(x,z_1)\\
            &=\ldots\\
            &=\sum_{z_i}p(x,z_1)p(z_1,z_2)\ldots p(z_{k-1},z_{k-1})p(z_{k-1},x).
        \end{align}
    \end{subequations}
    À ce point ci, nous avons éliminé toute référence à \( p\) grâce à l'homogénéité de la chaîne. Nous pouvons refaire le calcul à l'envers pour reconstituer l'expression de départ sans le \( p\) :
    \begin{subequations}
        \begin{align}
         \sum_{z_i}p(x,z_1)p(z_1,z_2)\ldots &p(z_{k-1},z_{k-1})p(z_{k-1},x)\\
         &=P(x_k=x,X_{k-1}\neq x,\ldots,X_1\neq x|X_0=x)\\
         &=P(T(x)=k),
        \end{align}
    \end{subequations}
    ce qu'il fallait obtenir.
\end{proof}

\begin{definition}\label{DefWknULk}
    Un état \( x\) est \defe{récurrent}{récurrent!état}\index{état!récurrent} si \( P(T(x)=\infty|X_0=x)=0\), c'est à dire si la probabilité de ne jamais retourner en $x$ lorsqu'on y est passé est nulle. L'état \( x\) est \defe{transient}{transient!état} ou \defe{transitoire}{transitoire!état}\index{état!transitoire} dans le cas contraire.

    Si \( x\) est un état récurrent, et si \( E\big( T(x)|X_0=x \big)<\infty\), nous disons que \( x\) est \defe{récurrent positif}{récurrent!positif}\index{état!récurrent positif}. Si \( E\big( T(x)|X_0=x \big)=\infty\) alors nous disons que est \defe{récurrent nul}{récurrent!nul}.
\end{definition}

Nous introduisons une variable aléatoire qui compte le nombre de fois que la chaîne de Markov passe par l'état \( x\) :
\begin{equation}    \label{EqDefNxmtuXkn}
    N_x=\sum_{k=0}^{\infty}\mtu_{\{ X_k=x\}}.
\end{equation}
C'est une variable aléatoire à valeurs dans \( \eN\cup\{ \infty \}\).

\begin{proposition} \label{PropEquivEPrecuequiv}
    Les deux propriétés suivantes sont équivalentes à dire que \( x\) est récurrent:
    \begin{enumerate}
        \item
            \( P(N_x<\infty|X_0=x)=0\)
        \item
            \( E(N_x|X_0=x)=\infty\).
    \end{enumerate}
    Les deux propriétés suivantes sont équivalentes à dire que \( x\) est transient :
    \begin{enumerate}
        \item   \label{ItemiMnGpD}
            \( P(N_x<\infty|X_0=x)=1\)
        \item
            \( E(N_x|X_0=x)<\infty\).
    \end{enumerate}
\end{proposition}

\begin{proof}
    En tant que événements, nous avons l'égalité
    \begin{equation}
        N_x<\infty=\bigcup_{n\in\eN}\{\underbrace{ X_n=x,X_{n+k}\neq x\forall k\geq 1}_{F_n} \}.
    \end{equation}
    Nous avons donc 
    \begin{equation}    \label{Eqreprencalculstd}
        P(N_x<\infty|X_0=x)=\sum_{n=0}^{\infty}P(F_n|X_0=x),
    \end{equation}
    et
    \begin{subequations}
        \begin{align}
            P(F_n|X_0=x)&=P(X_{n+k}\neq x, \forall k\geq 1,X_n=x|X_0=x)\\
            &=P(X_{n+k}\neq x,k\geq 1|X_n=x,X_0=x)P(X_n=x|X_0=x)\\
            &=P(X_{n+k}\neq x,k\geq 1|X_n=x)P(X_n=x|X_0=x)  \label{subEqPFnXkneqxii}\\
            &=P(X_k\neq x,k\geq 1|X_0=x)P(X_n=x|X_0=x)  \label{subEqPFnXkneqxi}\\
            &=P(T(x)=\infty|X_0=x)P(X_n=x|X_0=x)    \label{subEqPFnXkneqxiii}
        \end{align}
    \end{subequations}
    Justifications :
    \begin{enumerate}
        \item
            Pour \eqref{subEqPFnXkneqxii}, nous utilisons le fait que la chaîne soit «sans mémoire».
        \item
            Pour \eqref{subEqPFnXkneqxi}, nous utilisons le fait que la chaîne soit homogène.
        \item
            Pour \eqref{subEqPFnXkneqxiii}, l'événement \( X_k\neq x\) pour tout \( k\geq 1\) est exactement l'événement \( T(x)=\infty\).
    \end{enumerate}
    En nous servant de la proposition \ref{PropInversSumIntFub} (théorème de Fubini et mesure de comptage), nous permutons l'espérance et la somme dans l'expression
    \begin{subequations}        \label{EqPEEEntstq}
        \begin{align}
            \sum_{n=0}^{\infty}P(X_n=x|X_0=x)&=\sum_{n=0}^{\infty}E(\mtu_{\{ X_n=x \}}|X_0=x)\\
            &=E\big( \sum_{n=0}^{\infty}\mtu_{\{ X_n=x \}}|X_0=x \big)\\
            &=E(N_x|X_0=x).
        \end{align}
    \end{subequations}
    Voyons ce passage plus en détail. D'abord, en général nous avons
    \begin{equation}
            E(Y|X=x_0)=\int_{\{ X=x_0 \}}Y(\omega)dP(\omega)
            =\int_{\Omega}\mtu_{\{ X=x_0 \}}(\omega)Y(\omega)dP(\omega).
    \end{equation}
    Dans notre cas,
    \begin{equation}
        E\big( \mtu_{\{ X_n=x \}}|X_0=x \big)=\int_{\Omega}\mtu_{X_0=x}(\omega)\mtu_{\{ X_n=x \}}(\omega)dP(\omega).
    \end{equation}
    La fonction qui correspond à la proposiiton \ref{PropInversSumIntFub} est
    \begin{equation}
        f(n,\omega)=f_n(\omega)=\delta_{X_0(\omega),x}\delta_{X_n(\omega),x},
    \end{equation}
    qui est bien une fonction positive et mesurable.

    Nous reprenons à présent le calcul \eqref{Eqreprencalculstd} en remplaçant les éléments par leurs valeurs que nous avons calculées :
    \begin{equation}    \label{EqPnxXzTxarn}
        P(N_x<\infty|X_0=x)=P\big(T(x)=\infty|X_0=x\big)E(N_x|X_0=x).
    \end{equation}
    Si \( x\) est récurrent, nous avons \( P\big( T(x)=\infty|X_0=x \big)=0\), mais la relation \eqref{EqPnxXzTxarn} ne permet pas de conclure que le membre de gauche est nul parce qu'il reste la possibilité que \( E(N_x|X_0=x)=\infty\). Nous devons donc faire un pas en arrière et écrire cette espérance comme la limite des sommes partielles :
    \begin{equation}
        P(N_x<\infty|X_0=x)=\lim_{N\to \infty} \sum_{n=0}^NP\big( T(x)=\infty|X_0=x \big)P(X_n=x|X_0=x)=0
    \end{equation}
    parce que tous les termes de la suite des sommes partielles sont nuls. Nous avons donc bien que \( P(N_x<\infty|X_0=x)=0\). Il s'ensuit immédiatement que \( E(N_x|X_0=x)=1\).

    Nous devons maintenant démontrer l'implication inverse. Supposons que \( P(N_x<\infty|X_0=x)=0\). Dans ce cas nous avons immédiatement \( P(N_x=\infty|X_0=x)=1\) et \( E(N_x|X_0=x)=\infty\). L'équation \eqref{EqPnxXzTxarn} nous indique alors que 
    \begin{equation}
        P\big( T(x)=\infty|X_0=x \big)=0,
    \end{equation}
    c'est à dire que \( x\) est récurrent.
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Chaînes irréductibles}
%---------------------------------------------------------------------------------------------------------------------------

\begin{proposition}     \label{Proptoustanstousrecirrsi}
    Soit \( (X_n)\) une chaîne de Markov irréductible.
    \begin{enumerate}
        \item
            Un état \( x\) est récurrent si et seulement si tous les états sont récurrents.
        \item
            Un état \( x\) est transient si et seulement si tous les états sont transients.
    \end{enumerate}
\end{proposition}

\begin{proof}
    Soient \( x\) et \( y\) des états de la chaîne de Markov. Nous devons tester la valeur de \( P(X_n=y|X_0=y)\). Afin d'exploiter l'hypothèse d'irréductibilité, nous considérons \( r,s\in\eN\) tels que
    \begin{subequations}
        \begin{align}
            p^r(x,y)>0\\
            p^s(y,x)>0
        \end{align}
    \end{subequations}
    et nous calculons majorons en passant par quelques intermédiaires :
    \begin{subequations}
        \begin{align}
            P(X_{n+r+s}=y|X_0=y)&\geq P(X_{n+r+s}=y,X_{n+s}=x,X_s=x|X_0=y)\\
            &=P(X_{n+r+s}=y|X_{n+s}=x,X_s=x,X_0=y)\\
            &\qquad P(X_{n+s}=x|X_s=x,X_0=y)P(X_s=x|X_0=y)\nonumber.
        \end{align}
    \end{subequations}
    Les deux premiers facteurs se calculent en utilisant la propriété de Markov et l'homogénéité de la chaîne. Pour le premier,
    \begin{equation}
        P(X_{n+s}=x|X_s=x,X_0=y)=P(X_{n+s}=x|X_s=x)=P(X_n=x|X_0=x).
    \end{equation}
    Nous avons donc
    \begin{equation}        \label{EqRmuXtG}
        \sum_{n\in\eN}P(X_{n+r+s}=y|X_0=y)\geq p^r(x,y)p^s(y,x)\sum_{n\in\eN}P(X_n=x|X_0=x).
    \end{equation}
    En réutilisant Fubini comme dans l'équation \eqref{EqPEEEntstq}, nous avons
    \begin{equation}
        \sum_{n\in \eN}P(X_{n+r+s}=y|X_0=y)\geq KE(N_x|X_0=x)
    \end{equation}
    où \( K\) est une constante strictement positive, par hypothèse d'irréductibilité de la chaîne de Markov.

    Si \( x\) est un état récurrent, alors le membre de gauche est infini par la proposition \eqref{PropEquivEPrecuequiv} et donc
    \begin{equation}
        \sum_{n\in\eN}P(X_{n+r+s}=y|X_0=y)=\infty.
    \end{equation}
    Aux \( r+s\) premiers termes près (qui ne changent pas la somme), nous avons 
    \begin{equation}
        \sum_{n\in\eN}P(X_n=y|X_0=y)=\infty,
    \end{equation}
    ce qui signifie que \( y\) est récurrent.
\end{proof}

Nous rappelons que \( T(x)\) est le temps que première atteinte de l'état \( x\). Nous notons\nomenclature[M]{\( \pi(x)\)}{lié au temps de retour}
\begin{equation}        \label{EqKyuLYk}
    \pi(x)=\frac{1}{ E\big( T(x)|X_0=x \big) }.
\end{equation}
Étant donné que \( T(x)\) est un entier positif ou nul nous avons \( E\big( T(x)|X_0=x \big)\in\mathopen[ 1 , \infty \mathclose]\) et donc \( \pi(x)\in\mathopen[ 0 , 1 \mathclose]\).

Si \( x\) est un état transient, alors \( T(x)=\infty\) lorsque \( X_0=x\) et donc \( E\big( T(x)|X_0=x \big)=0\) et \( \pi(x)=0\). Si \( x\) est récurrent par contre, \( P\big( T(x)<\infty|X_0=x \big)=1\) et il n'y a pas de garanties sur la valeur de \( E\big( T(x)|X_0=x \big)\).

\begin{corollary}       \label{CorLhpRsk}
    Un état récurrent est récurrent positif si et seulement si \( \pi(x)>0\). Un état récurrent est récurrent nul si et seulement si \( \pi(x)=0\).
\end{corollary}

\begin{proof}
    C'est la formule \eqref{EqKyuLYk}.
\end{proof}

\begin{proposition} \label{PropMrkIrreLoishLCkpjkptXk}
    Soit \( (X_n)\) est une chaîne de Markov irréductible.
    \begin{enumerate}
        \item
            Si \( x\) est un état récurrent, alors \( T(X)<\infty\) presque sûrement.
        \item
            Nous avons une égalité entre les lois
            \begin{equation}    \label{PropMrkIrreLoishLCkpjkptXkItemii}
                \hL\big( X_{k+T(x)}|T(x)<\infty \big)=\hL(X_k|X_0=x).
            \end{equation}
    \end{enumerate}
\end{proposition}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Nombre de visites}
%---------------------------------------------------------------------------------------------------------------------------

La fonction
\begin{equation}
    \frac{1}{ n }\sum_{k=1}^n\mtu_{\{ X_k=x \}}
\end{equation}
est la \defe{fréquence empirique}{fréquence!empirique} de la chaîne de Markov.

Soit \( x\) un état récurrent, c'est à dire que \( P\big( T(x)<\infty|X_0=x \big)=1\). Nous classons les visites de la façon suivante :
\begin{subequations}    \label{SubEqsDefTirectempsretou}
    \begin{align}
        T_1(x)&=T(x)=\inf\{ k\geq 1\tq X_k=x \}\\
        T_2(x)&=\inf\{ k\geq 1\tq X_{T_1(x)+k}=x \}\\
        &\vdots\\
        T_n(x)&=\inf\{ k\geq 1\tq X_{T_{n-1}(x)+k}=x \}
    \end{align}
\end{subequations}
La variable aléatoire \( T_i\) représente le temps entre la visite numéro \( i-1\) et la visite numéro \( i\) (si \( X_0\neq x\), sinon il faut décaler). Nous définissons l'instant la na visite numéro \( n\) :
\begin{equation}
    S_n=\sum_{k=1}^nT_k(x).
\end{equation}

\begin{lemma}
    Les variables aléatoires \( T_i\) sont indépendantes.
\end{lemma}

\begin{proof}
    Nous choisissons \( n\) des \( T_i\) et nous calculons la probabilité
    \begin{equation}
        \spadesuit=P(T_{i_1}=k_1,T_{i_2}=k_2,\ldots,T_{i_n}=k_n)
    \end{equation}
    où nous supposons \( i_1>i_2>\ldots>i_n\). Nous décomposons cette probabilité en sommant sur toute les histoires de la chaîne de Markov compatibles avec les nombres \( k_i\) donnés :
    \begin{equation}
        \spadesuit=\sum_{\substack{\{ z_j \}\\\text{compatibles}}}P(X_j=z_j,j=1,\ldots,N).
    \end{equation}
    Notons qu'ici, le numéro du dernier terme de la somme n'est pas certain parce que tous les \( T_i\) ne sont pas fixés. Nous l'avons noté \( N\), mais en réalité il est différent d'un terme à l'autre de la somme. Il est certain que \( z_N=x\) et \( z_{N-k_1}=x\) et si \( N-k_1<j<N\), alors \( z_j\neq x\). Cela est simplement le fait que nous demandions aux \( z_i\) de respecter les conditions données par les \( k_i\). Nous avons
    \begin{subequations}
        \begin{align}
            \spadesuit&=\sum_{\{ z_j \}} P(X_N=x,X_j=z_j,N-k_1<j<N|X_j=z_j,j\leq N-k_1)P(X_j=z_j,j<N-k_1)\\
            &=\sum_{\{ z_j \}} P(X_N=x,X_j=z_j,N-k_1<j<N|X_{N-k_1}=x)P(X_j=z_j,j<N-k_1)\\
        \end{align}
    \end{subequations}
    Le premier facteur est \( P(T_{i_1}=k_1)\) tandis que le second facteur est précisément \( P(T_{j}=k_j,j>1)\). Nous avons donc montré que
    \begin{equation}
        P(T_{i_1}=k_1,T_{i_2}=k_2,\ldots,T_{i_n}=k_n)=P(T_{i_1}=k_1)P(T_{j}=k_j,j>1),
    \end{equation}
    et donc les \( T_i\) sont indépendants.
\end{proof}

\begin{proposition}     \label{PropjOjDux}
    Si \( (X_n)\) est une chaîne de Markov irréductible et si \( x\in E\) alors
    \begin{equation}        \label{EqPiEndempropropkeu}
        \pi(x)=\lim_{n\to \infty} \frac{1}{ n }\sum_{k=1}^n\mtu_{\{ X_k=x \}}
    \end{equation}
    presque sûrement.
\end{proposition}

\begin{proof}
    Étant donné que la chaîne est irréductible, les états sont soit tous transient soit tous récurrents par la proposition \ref{Proptoustanstousrecirrsi}. Nous commençons par considérer que \( x\) est transient.

    En comparant la définition \eqref{EqDefNxmtuXkn} de \( N_x\) et le membre de droite de \eqref{EqPiEndempropropkeu}, nous avons pour chaque \( n\) l'inégalité
    \begin{equation}    \label{EqkkueusnfracunENx}
        \frac{1}{ n }\sum_{k=1}^n\mtu_{\{ X_k=x \}}\leq\frac{1}{ n }E(N_x).
    \end{equation}
    Dans le cas d'un élément transient, nous avons \( \pi(x)=0\), donc il serait bon de montrer que \( E(N_x)<\infty\), de sorte que prendre la limite \( n\to\infty\) dans \eqref{EqkkueusnfracunENx} donne zéro.

    Nous décomposons le calcul en deux morceaux :
    \begin{equation}
        E(N_x)=E\big( N_x|T(x)=\infty \big)P\big( T(x)=\infty \big)+E\big( N_x|T(x)<\infty \big)P\big( T(x)<\infty \big).
    \end{equation}
    Le fait que le premier terme soit fini découle immédiatement du fait que \( T(x)=\infty\) implique \( X_k\neq x\) pour tout \( k\geq 1\). Dans ce cas l'espérance de \( N_x\) est évidemment finie.

    Pour le second terme nous avons
    \begin{subequations}
        \begin{align}
            E\big( N_x|T(x)<\infty \big)&=E\big( \sum_{k=0}^{\infty}\mtu_{\{ X_k=x \}}|T(x)<\infty \big)\\
            &=\sum_{k=1}^{\infty}E\big( \mtu_{\{ X_k=x \}}|T(x)<\infty \big).
        \end{align}
    \end{subequations}
    Pour inverser la somme et l'espérance, nous avons utilisé le théorème de théorème de Fubini-Tonelli qui est encore valable pour des fonctions qui prennent la valeur \( \infty\). Le fait d'inverser ne signifie pas que ni la somme ni l'intégrale soit finie. D'ailleurs c'est exactement ce que nous sommes en train de déterminer.

    Étant donné que nous voulons seulement savoir si cette somme est finie ou non, nous pouvons nous restreindre à la somme depuis \( k=1\) ou oublier le premier terme. D'autre par nous avons
    \begin{equation}
        \sum_{k=1}^{\infty}\mtu_{\{ X_k=x \}}=\sum_{j=0}^{\infty}\mtu_{\{ X_{j+T(x)}=x \}}
    \end{equation}
    parce que les \( T(x)\) premiers termes sont par définition nuls. Nous regardons donc
    \begin{subequations}
        \begin{align}
            \sum_{j=0}^{\infty}E\big( \mtu_{X_{j+T(x)}=x}|T(x)<\infty \big)&=\sum_{j}P\big( X_{j+T(x)}=x|T(x)<\infty \big)\\
            &=\sum_jP(X_j=x|X_0=x)  \label{subeqsumkPXjXzsezii}\\
            &=\sum_jE\big( \mtu_{\{ X_j=x \}}|X_0=x \big)\\
            &=E\big( \sum_j\mtu_{X_j=x}|X_0=x \big)\\
            &=E(N_x|X_0=x)\\
            &<\infty    &\text{parce que \( x\) est transient.}
        \end{align}
    \end{subequations}
    L'équation \eqref{subeqsumkPXjXzsezii} provient de la proposition \ref{PropMrkIrreLoishLCkpjkptXk} et plus précisément de l'égalité entre les lois \eqref{PropMrkIrreLoishLCkpjkptXkItemii}. Nous avons terminé la preuve dans le cas où \( x\) est transient.

    Nous passons maintenant au cas où \( x\) est récurrent, c'est à dire \( P(T(x)<\infty|X_0=x)=1\). Les variables aléatoires \( T_i\) définies en \eqref{SubEqsDefTirectempsretou} pour \( i\geq 2\) sont indépendantes et identiquement distribuées et
    \begin{equation}
        \hL\big( T_k(x) \big)\sim\hL\big( T(X)|X_0=x \big).
    \end{equation}
    La loi des grands nombres nous indique que
    \begin{subequations}        \label{EqlgnMarkdemked}
        \begin{align}
            \frac{ S_n }{ n }=\frac{ T_1(x) }{ n }+\frac{1}{ n }\sum_{k=2}^nT_k(x)\stackrel{p.s.}{\longrightarrow}& E\big( T_2(x) \big)\\
            &=E\big( T(x)|X_0=x \big).
        \end{align}
    \end{subequations}
    \begin{remark}
        La loi des grands nombres est encore vraie sans l'hypothèse de variables aléatoires dans \( L^1\) pourvu qu'elles soient positives. Alors dans la conclusion de la loi nous devons accepter la possibilité que l'espérance soit infinie.
    \end{remark}
    Nous posons pour \( m\in\eN\)
    \begin{equation}    \label{EqDennmsumjmtu}
        n(m)=\sum_{j=1}^m\mtu_{\{ X_j=x \}}
    \end{equation}
    qui est le nombre de visites de \( x\) avant l'instant \( m\). Nous avons évidemment \( n(m)\leq m\). Mais \( S_n\) est l'instant de la \( n\)ième visite, par conséquent \( S_{n(m)}\) est l'instant de la dernière visite avant le moment \( m\). Pour tout \( m\) nous avons les inégalités 
    \begin{equation}
        S_{n(m)}\leq m<S_{n(m)+1}.
    \end{equation}
    Nous divisons par \( n(m)\) et nous effectuons la limite \( m\to\infty\):
    \begin{equation}    \label{EqdrembSnm}
        \frac{ S_n(m) }{ n(m) }\leq \frac{ m }{ n(m) }\leq\frac{ S_{n(m)}+1 }{ n(m) }
    \end{equation}
    En ce qui concerne la limite de \( n(m)\), nous utilisons la définition \eqref{EqDennmsumjmtu} :
    \begin{equation}
        n(m)\to\sum_{j=1}^{\infty}\mtu_{\{ X_j=x \}}=
    \end{equation}
heur\ldots
     \begin{equation}
         \lim_{m\to \infty}  n(m)=\lim_{m\to \infty} \sum_{n=1}^m\mtu_{\{ X_j=x \}}\stackrel{p.s.}{\longrightarrow}\infty
     \end{equation}
     par la proposition \eqref{PropEquivEPrecuequiv}. Plus précisément, la limite vaut \( N_x\) qui vaut presque sûrement \( \infty\) dans le cas où \( x\) est récurrent. Par ailleurs la loi des grands nombres \eqref{EqlgnMarkdemked} nous enseigne en particulier que
     \begin{equation}
         \frac{ S_{n(m)} }{ n(m) }\stackrel{p.s.}{\longrightarrow} E\big( T(x)|X_0=x \big).
     \end{equation}
     Le terme de droite dans \eqref{EqdrembSnm} se traite de façon usuelle :
     \begin{equation}
         \frac{ S_{n(m)+1} }{ n(m) }=\frac{ S_{n(m)+1} }{ n(m)+1 }\frac{ n(m)+1 }{ n(m) }.
     \end{equation}
     Le dernier facteur tend vers \( 1\) et le tout a pour limite \( E\big( T(x)|X_0=x \big)\). Par conséquent nous avons
     \begin{equation}
         \frac{ m }{ n(m) }\stackrel{p.s.}{\longrightarrow}E\big( T(x)|X_0=x \big)
     \end{equation}
     et 
     \begin{equation}
         \frac{ n(m) }{ n }=\frac{1}{ m }\sum_{j=1}^m\mtu_{\{ X_j=x \}}\to\frac{1}{ E\big( T(x)|X_0=x \big) }=\pi(x).
     \end{equation}
\end{proof}

\begin{lemma}       \label{LembyftKs}
    Soit $(X_k)$ une chaîne de Markov dont l'espace des états est noté $E$. Pour chaque $ x\in E$ nous notons 
    \begin{equation}
        T(x)=\inf\{ k\geq 1\tq X_k=x \}
    \end{equation}
    et
    \begin{equation}
        T_p(x)=\inf\{ k\geq 1\tq X_{k+p}=x \}
    \end{equation}
    Alors nous avons
    \begin{equation}
        P(T_p(x)=k|X_p=y)=P(T(x)=k|X_0=y).
    \end{equation}
\end{lemma}

La proposition suivante nous permet de parler de chaîne de Markov \defe{récurrence positive}{chaîne!de Markov!récurrente positive}.
\begin{proposition}     \label{PropUyLCzp}
    Soit \( (x_n)\) une chaîne de Markov irréductible.
    \begin{enumerate}
        \item
            Un état \( x\) est transient si et seulement si tous les états sont transients.
        \item
            Un état est récurrent positif  si et seulement si tous les états sont récurrents positifs.
    \end{enumerate}
\end{proposition}

\begin{proof}
    Nous rappelons (proposition \ref{PropjOjDux}) que si la chaîne est irréductible
    \begin{equation}        \label{EqZZMqsm}
        \pi(x)=\lim_{n\to \infty} \frac{1}{ n }\sum_{k=1}^n\mtu_{[X_k=x]}       
    \end{equation}
    Notons aussi que
    \begin{equation}
        \sum_{k=1}^N\mtu_{X_k=x}=\begin{cases}
            0    &   \text{si \( N<T(x)\)}\\
            \sum_{k=0}^{N-T(x)}\mtu_{X_{k+T(x)}=x}    &    \text{si \( N>T(x)\)}
        \end{cases}
    \end{equation}
    où dans la seconde ligne nous avons effectué le changement de variable de sommation \( k'=k+T(x)\). Dans la limite \eqref{EqZZMqsm} nous sommes toujours dans le cas où \( N\) est assez grand. Nous pouvons donc écrire
    \begin{equation}
        \pi(x)=\lim_{N\to \infty} \frac{1}{ N }\sum_{k=0}^{N-T(x)}\mtu_{X_{k+T(x)}=x}.
    \end{equation}
    Nous pouvons aussi écrire
    \begin{equation}
        \frac{1}{ N-T(x) } \sum_{k=0}^{N-T(x)}\mtu_{X_{k+T(x)}=x}=\frac{ N }{ N-T(x) }\frac{1}{ N } \sum_{k=0}^{N-T(x)}\mtu_{X_{k+T(x)}=x}.
    \end{equation}
    Dans cette dernière égalité le membre de droite tend vers \( \pi(x)\) et nous avons
    \begin{equation}
        \lim_{N\to \infty} \frac{1}{ N-T(x) } \sum_{k=0}^{N-T(x)}\mtu_{X_{k+T(x)}=x}=\pi(x)
    \end{equation}
    ou encore
    \begin{equation}
        \lim_{N\to \infty} \frac{1}{ N} \sum_{k=0}^{N}\mtu_{X_{k+T(x)}=x}=\pi(x)
    \end{equation}
    Étant donné que $\pi(x)$ est une constante nous avons évidemment $E(\pi(x))=\pi(x)$. Nous pouvons cependant considérer les variables aléatoires
    \begin{equation}
        Z_n=\frac{1}{ n }\sum_{k=1}^n\mtu_{X_{k+T(x)}=x}
    \end{equation}
    et remarquer que $Z_n\stackrel{p.s.}{\longrightarrow} \pi(x)$ avec $0\leq Z_n\leq 1$. Le théorème de la convergence dominée (\ref{ThoConvDomLebVdhsTf}) nous permet d'inverser la limite et l'espérance et écrire
    \begin{subequations}
        \begin{align}
            \pi(x)&=\lim_{n\to \infty} \frac{1}{ n }\sum_{k=1}^nE\big( \mtu_{X_{k+T(x)}=x} \big)\\
            &=\lim_{n\to \infty} \frac{1}{ n }\sum_{k=1}^nP\big( X_{k+T(x)}=x \big).
        \end{align}
    \end{subequations}
    Par le lemme \ref{LembyftKs} nous avons
    \begin{equation}
        P(X_{k+T(x)}=x)=P(X_k=k|X_0=x)
    \end{equation}
    et $\pi(x)$ prend la forme
    \begin{equation}        \label{EqurCteK}
        \pi(x)=\lim_{n\to \infty} \frac{1}{ n }\sum_{k=1}^nP(X_k=x|X_0=x).
    \end{equation}
    
    Soit maintenant un état \( x\) positif récurrent et \( y\), un autre état. Par définition \ref{DefWknULk} et par corollaire \ref{CorLhpRsk} nous avons \( \pi(x)>0\). Nous devons prouver que \( \pi(y)>0\).

    Étant donné que la chaîne est irréductible il existe \( r\) et \( s\) tels que
    \begin{subequations}
        \begin{numcases}{}
            p^r(x,y)=P(X_r=y|X_0=x)>0\\
            p^s(x,y)=P(X_s=x|X_0=y)>0
        \end{numcases}
    \end{subequations}
    Nous reprenons l'équation \eqref{EqRmuXtG} multipliée par \( 1/N\) :
    \begin{equation}
        \frac{1}{ N }\sum_{n=1}^NP(X_{r+s+n=y|X_0=y})\geq \underbrace{p^r(x,y)p^s(y,x)}_{\geq 0}\underbrace{\frac{1}{ N }\sum_{n=1}^NP(X_n=x|X_0=x)}_{\to \pi(x)}
    \end{equation}
    et nous prenons la limite lorsque \( N\to\infty\). À \(r+s\) termes près, nous trouvons à gauche l'expression \eqref{EqurCteK} de \( \pi(y)\). Par conséquent
    \begin{equation}
        \pi(y)\geq\lim_{N\to \infty} \frac{1}{ n }\sum_{n=1}^NP(X_{r+s+n}=y|X_0=y)\geq \alpha\pi(x)
    \end{equation}
    où \( \alpha\) est une constante positive. Le nombre \( \pi(x)\) étant strictement positif par hypothèse nous avons montré que \( \pi(y)>0\), c'est à dire que \( y\) est récurrent positif.
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Mesure invariante}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{definition}
    Une mesure de probabilité \( \mu\) sur l'espace des états \( E\) d'une chaîne de Markov est \defe{invariante}{invariante!mesure!pour une chaîne de Markov} si pour tout \( x\in E\)
    \begin{equation}
        \mu(x)=\sum_{y\in E}p(y,x)\mu(y).
    \end{equation}
\end{definition}
\begin{remark}
    Une mesure invariante est une mesure de probabilité et nous noterons par abus $ \mu(x)$ pour $\mu(\{x\})$. Si \( A\subset E\) nous avons 
    \begin{equation}
        \mu(A)=\sum_{x\in A}\mu(x).
    \end{equation}
\end{remark}

\begin{remark}  \label{RemwcRRFZ}
    Une loi invariante associée à une chaîne de Markov est une loi associée à la matrice de transition de la chaîne, mais pas à la loi de $X_0$. Par conséquent nous pouvons tester si \( \mu\) est une mesure invariante pour une certaine chaîne de Markov $(X_k)$ en considérant la chaîne $(Y_k)$ avec $Y_k=X_k$ pour $k>0$ et $Y_0$ arbitraire.
\end{remark}

L'adjectif \emph{invariant} provient du lemme suivant.
\begin{lemma}       \label{LemUVMwbM}
    Soit \( (X_n)\) une chaîne de Markov telle que \( X_0\sim\mu\) où \( \mu\) est une mesure invariante sur l'espace des états. Alors \( X_k\sim \mu\) pour tout \( k\).
\end{lemma}

\begin{proof}
    Par hypothèse, \( P(X_0=x)=\mu(x)\). Ensuite nous avons
    \begin{subequations}
        \begin{align}
            P(X_1=y)&=\sum_{x\in E}P(X_1=y|X_0=x)P(X_0=x)\\
            &=\sum_xp(x,y)\mu(x)\\
            &=\mu(y).
        \end{align}
    \end{subequations}
    Par conséquent \( X_1\) suit également la loi \( \mu\). Par récurrence tous les états suivent cette même loi.
\end{proof}
Si les états d'une chaîne de Markov ont comme loi une mesure invariante, alors nous disons que la chaîne est \defe{stationnaire}{stationnaire!chaîne de Markov}.

\begin{remark}\label{RemcOEylF}
    Pour une chaîne de Markov stationnaire de loi invariante $\mu$ nous avons
    \begin{equation}
        \mu(x)=\sum_yp(y,x)\mu(y)
    \end{equation}
    et si l'ensemble \( E\) est fini cette équation signifie
    \begin{equation}
        \mu=Q\mu
    \end{equation}
    où \( Q\) est la matrice de transition de la chaîne de Markov.
\end{remark}


\begin{theorem}[Théorème ergodique]
    Une chaîne de Markov irréductible est positive récurrente si et seulement si elle accepte une mesure invariante. Cette mesure est invariante est alors unique et vérifie \( \mu=Q\mu\) où \( Q\) est la matrice de transition.
\end{theorem}

\begin{proof}
    Nous allons seulement prouver le théorème ergodique dans le cas où \( E\) est fini. Soit \( (X_n)\) une chaîne de Markov récurrente positive; nous avons \( \pi(x)>0\) pour tout \( x\in E\). Nous allons montrer que \( \pi\) est une mesure invariante.

    Nous commençons par montrer que
    \begin{equation}
        \sum_{x\in E}\pi(x)=1.
    \end{equation}
    Pour cela nous reprenons la propriété de chaîne irréductible pour écrire
    \begin{equation}
        \pi(x)=\lim_{N\to \infty}\frac{1}{ N }\sum_{k=1}^N\mtu_{X_k=x}
    \end{equation}
    Étant donné que \( E\) est fini nous pouvons sommer sur \( x\in E\) et permuter la somme avec la limite :
    \begin{equation}
        \sum_{x\in E}\pi(x)=\lim_{N\to \infty} \frac{1}{ N }\sum_{k=1}^N\underbrace{\sum_{x\in E}\mtu_{X_k=x}}_{=1}.
    \end{equation}
    Nous nous retrouvons donc avec \( \lim_{N\to \infty} \frac{1}{ N }N=1\). La fonction \( \pi\) définit donc bien une mesure de probabilité sur \( E\).

    Nous montrons à présent que cette mesure est invariante, c'est à dire que
    \begin{equation}
        \pi(x)=\sum_{y\in E}p(y,x)\pi(y).
    \end{equation}
    Pour cela nous utilisons encore le théorème de la convergence dominée pour permuter la limite et l'intégrale dans
    \begin{equation}        \label{EqcKxNcL}
        \pi(x)=E(\pi(x))=\lim_{N\to \infty} \frac{1}{ N }\sum_{k=1}^N\underbrace{E\big( \mtu_{X_k=x} \big)}_{P(X_k=x)}=\lim_{N\to \infty} \frac{1}{ N }\sum_{k=1}^NP(X_{k+1}=x).
    \end{equation}
    La dernière égalité découle du fait que en divisant par \( N\) et en faisant tendre \( N\) vers l'infini, le fait d'enlever un terme à la somme ne change pas la valeur de la limite. Nous pouvons substituer dans \eqref{EqcKxNcL} la valeur
    \begin{equation}
        P(X_{k+1}=x)=\sum_{y\in E}p(y,x)P(X_k=y).
    \end{equation}
    Nous avons alors
    \begin{subequations}
        \begin{align}
            \pi(x)&=\lim_{N\to \infty} \frac{1}{ N }\sum_{k=1}^N\sum_{y\in E}p(y,x)P(X_k=y)\\
            &=\sum_{y\in E}p(y,x)\lim_{N\to \infty} \frac{1}{ N }\sum_{k=1}^NP(X_k=y)\\
            &=\sum_{y\in E}p(y,x)\pi(y),
        \end{align}
    \end{subequations}
    ce qui signifie que \( \pi\) est une mesure invariante. Notons que nous avons encore utilisé le fait que \( E\) soit fini pour permuter avec la limite.

    Il nous reste à montrer l'unicité de la mesure invariante sur la chaîne de Markov. Soit \( \mu\) une mesure invariante pour la chaîne de Markov $(X_k)$. Comme indiqué dans la remarque \ref{RemwcRRFZ} nous pouvons supposer que $X_0$ suit la loi \( \mu\). Par le lemme \ref{LemUVMwbM} nous avons \( P(X_k=x)=\mu(x)\) pour tout \( k\). Par conséquent
    \begin{equation}
        \pi(x)=\lim_{N\to \infty} \frac{1}{ N }\sum_{k=1}^NP(X_k=x)=\mu(x).
    \end{equation}
\end{proof}

\begin{theorem}[loi des grands nombres pour les chaîne de Markov]\index{loi!des grands nombres!pour les chaînes de Markov}
    Soit \( (X_n)\) une chaîne de Markov irréductible acceptant une mesure invariante. Soit \( f\colon E\to \eR\) une fonction dans \( L^1(E,\mu)\). Alors nous avons
    \begin{equation}
        \frac{1}{ N }\sum_{k=1}^Nf(X_k)\stackrel{p.s.}{\longrightarrow}\sum_{x\in E}f(x)\mu(x).
    \end{equation}
\end{theorem}
En ce qui concerne les notations, l'hypothèse \( f\in L^1(E,\mu)\) signifie
\begin{equation}
    \sum_{x\in E}| f(x) |\mu(x)=\int_E| f(x) |d\mu(x)<\infty.
\end{equation}

\begin{proof}
    Nous prouvons le théorème dans le cas où \( E\) est fini. Si nous écrivons
    \begin{equation}
        f(X_k)=\sum_{y\in E}f(y)\mtu_{X_k=y},
    \end{equation}
    alors
    \begin{equation}
        \frac{1}{ N }\sum_{k=1}^Nf(X_k)=\sum_{y\in E}f(y)\frac{1}{ N }\sum_{k=1}^N\mtu_{X_k=y}.
    \end{equation}
    Étant donné que \( E\) est fini nous pouvons permuter les sommes et prendre la limite \( N\to\infty\):
    \begin{equation}
        \lim_{N\to \infty} \frac{1}{ N }\sum_kf(X_k)=\sum_{y\in E}f(y)\lim_{N\to \infty} \frac{1}{ N }\sum_{k=1}^N\mtu_{X_k=y}=\sum_{y\in E}f(y)\pi(y).
    \end{equation}
% TODO : il me semble que je dois encore terminer cette preuve.    
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Convergence vers l'équilibre}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Nous voudrions savoir sous quelles conditions la variable aléatoire \( X_n\) converge en loi vers quelque chose lorsque \( n\to \infty\). Une telle loi limite doit dépendre de la loi initiale\footnote{Lorsque la loi limite ne dépend pas de la loi initiale, nous disons que la chaîne de Markov est ergodique, nous y reviendrons.} comme le montre l'exemple de la chaîne de Markov
\begin{equation}
\xymatrix{%
A\ar@(dl,ul)^1  & C\ar[l]_{1/2}\ar[r]^{1/2} &  B\ar@(dr,ur)_1
   }
\end{equation}
Si \( X_0=C\), alors la loi limite est
\begin{equation}
    \frac{ 1 }{2}(\delta_A+\delta_B).
\end{equation}
Si par contre \( X_0=B\), la loi limite est \(\delta_B\). Notons que la chaîne de Markov proposée ici est irréductible.

Notons qu'il n'y a pas toujours de lois limite comme le montre l'exemple
\begin{equation}
    \xymatrix{%
        A\ar@<1ex>[r]^1  & B\ar@<1ex>[l]^1
       }
\end{equation}
avec \( X_0=A\). La loi en est
\begin{equation}
    X_k=\begin{cases}
        \delta_A    &   \text{si \( k\) est pair}\\
        \delta_B    &    \text{si \( k\) est impair}.
    \end{cases}
\end{equation}

\begin{lemma}
    Si nous avons une loi limite
    \begin{equation}    \label{EqmbQMAY}
        P(X_n=x)\to l(x),
    \end{equation}
    et que la chaîne est irréductible, alors nous avons \( l=\pi\).
\end{lemma}

\begin{proof}
    D'après la proposition \ref{PropjOjDux} nous avons
    \begin{equation}
        \frac{1}{ n }\sum_{k=1}^nP(X_k=x)\to \pi(x).
    \end{equation}
    Par le lemme \ref{LemyGjMqM} sur la moyenne de Cesaro et l'hypothèse \eqref{EqmbQMAY}, nous avons aussi
    \begin{equation}
        \frac{1}{ n }\sum_{k=1}^nP(X_k=x)\to l(x).
    \end{equation}
    Du coup \( \pi(x)=l(x)\).
\end{proof}

\begin{lemma}[\cite{MarkGuy}]
    Si \( \pi\) est une loi stationnaire et si \( x\) est un étant transient, alors \( \pi(x)=0\).
\end{lemma}
Ce lemme (qui peut être prouvé rigoureusement) est principalement dû au fait que la chaîne de Markov ne visite un état transitoire qu'un nombre fini de fois par la proposition \ref{PropEquivEPrecuequiv}\ref{ItemiMnGpD}.

\begin{definition}  \label{DefCxvOaT}
    Un état \( x\in E\) est \defe{apériodique}{état!apériodique}\index{apériodique!état d'une chaîne de Markov} si
    \begin{equation}
        \pgcd\{ n\geq 1\tq p^n(x,x)>0 \}=1.
    \end{equation}
\end{definition}
Mettons que tous les \( n\) tels que \( p^n(x,x)>0\) ont \( 2\) comme diviseur. L'état n'est alors pas apériodique, mais on voit que si \( X_0=x\), alors les états impairs ne peuvent pas être sur \( x\). Cela est une forme de périodicité.

Si un état est apériodique, il existe \( p\) et \( q\) premiers entre eux tels que \( p^p(x,x)\) et \( p^q(x,x)\) sont non nuls. En particulier pour tout \( n\in p\eN+q\eN\), \( P(X_n=x)\neq 0\). Par conséquent la proposition \ref{PropLAbRSE} nous indique qu'à partir d'un certain moment tous les \( X_k\) pourraient être \( x\).

L'état \( C\) de la chaîne de Markov suivante est apériodique :
\begin{equation}
    \xymatrix{%
    A\ar@<0.5ex>[rr]^1  && B\ar@<0.5ex>[ll]^{2/3}\ar[dl]^{1/3}\\
    &C\ar[ul]^1
       }
\end{equation}
En effet \( p^3(C,C)\neq 0\) par le chemin \( C\to A\to B\to C\) tandis que \( p^5(C,C)\neq 0\) également par le chemin \( C\to A\to B\to A\to B\to C\). Or \( \pgcd\{ 3,5 \}=1\).

\begin{proposition}[\cite{MarkGuy}]     \label{PropSaOysS}
    Soit \( (X_n)\), une chaîne de Markov irréductible. Un état \( x\) est apériodique si et seulement si il existe \( N\) tel que
    \begin{equation}
        p^k(x,x)=P(X_k=x|X_0=x)>0
    \end{equation}
    pour tout \( k\geq N\).
\end{proposition}

La proposition suivante va nous permettre de parler de \defe{chaîne apériodique}{chaîne!de Markov!apériodique}
\index{apériodique!chaîne de Markov}.
\begin{proposition}
    Si une chaîne de Markov est irréductible, alors un état est apériodique si et seulement si tous les états sont apériodiques.
\end{proposition}

\begin{proof}
    Soit \( x\) un état apériodique de la chaîne de Markov \( (X_n)_{n\in \eN}\). En vertu de la proposition \ref{PropSaOysS} il existe \( N_x\) tel que \( p^k(x,x)\neq 0\) pour tout \( k\geq N_x\). Soit \( y\in E\). Étant donné que la chaîne est irréductible, il existe \( r\) et \( s\) tels que\( p^r(x,y)>0\) et \( p^s(y,x)>0\). Nous avons
    \begin{equation}
        p^{k+r+s}(y,y)=P(X_{k+r+s}=y|X_0=y)\geq p^s(x,y)P(X_k=x|X_0=x)p^r(y,x).
    \end{equation}
    Si \( k\) est assez grand, cette quantité est strictement positive. Donc il suffit de prendre \( N_y=N_x+r+s\) pour savoir que \( y\) est également apériodique.
\end{proof}

\begin{example}
Quelle est la différence entre une chaîne irréductible et une chaîne apériodique ? Une chaîne est irréductible lorsque aucune sous-chaîne ne peut piéger le système. Pour toute paire d'états \( x,y\in E\), il existe un \( n\) tel qu'il soit possible d'aller de \( x\) à \( y\) en \( n\) pas. Une chaîne est apériodique lorsqu'après un temps suffisamment long, \emph{tous} les états soient possibles en même temps.

Un exemple de chaîne irréductible non apériodique :
\begin{equation}
\xymatrix{%
    A \ar@/^/[r]^-{1}    &   B\ar@/^/[l]^{1}\\
   }
\end{equation}
Cette chaîne est irréductible parce que le graphe est connexe, par contre il n'est pas apériodique parce que si \( X_0=A\) il n'est pas possible d'être dans l'état \( A\) après un nombre impair de pas.

Plus formellement, \( p^n(A,A)=1\) dès que \( n\) est pair; le PGCD de la définition \ref{DefCxvOaT} n'est donc certainement pas \( 1\).
\end{example}

Si \( E\) est fini et si la chaîne de Markov est irréductible, alors en posant \( N=\max_{x\in E}N(x)\), la matrice \( P^k\) a des éléments non nuls sur toute la diagonale pour tout \( k>N\). Ces éléments diagonaux ne sont autre que les \( p^k(x,x)\).

\begin{theorem}[Convergence en loi des chaîne de Markov]
    Si \( (X_n)\) est
    \begin{enumerate}
        \item
            irréductible,
        \item
            récurrente positive,
        \item
            apériodique,
    \end{enumerate}
    alors \( X_n\) converge en loi vers l'unique probabilité invariante \( \pi\) vérifiant
    \begin{equation}
        \pi(x)=\sum_{u\in E}p(y,x)\pi(y)=\frac{1}{ E\big( T(x)|X_0=x \big) }.
    \end{equation}

    Cette convergence est indépendante de la loi de \( X_0\) et on a
    \begin{equation}
        P(X_n=x|X_0=y)\to_{n\to \infty} \pi(x).
    \end{equation}
\end{theorem}
\index{chaîne!de Markov!convergence}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Processus de Galton-Watson}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\label{SecBPmrPdtGalton}
\index{processus!Galton-Watson}
\index{variable aléatoire!suite de variables aléatoire de Bernoulli}

Nous considérons une maladie et notons \( Z_n\) le nombre de malades à l'instant \( n\). Nous posons \( Z_0=1\) et
\begin{equation}        \label{EqBvILKj}
    Z_{n+1}=\begin{cases}
        0    &   \text{si \( Z_n=0\)}\\
        \sum_{i=1}^{Z_n}\xi_i^{(n)}    &    \text{sinon}
    \end{cases}
\end{equation}
où \( \xi_i^{(n)}\) est le nombre de personnes contaminées par le malade \(i\) à l'instant \( n\). Nous supposons que ces variables aléatoires sont indépendantes et identiquement distribuées et admettent un moment d'ordre \( 1\).

L'équation de propagation \ref{EqBvILKj} signifie que nous supposons qu'une personne malade à l'instant \( n\) n'est plus malade à l'instant \( n+1\). Par ailleurs les hypothèses d'indépendance signifient qu'à chaque instant, le nombre de personnes contaminées par le malade \( i\) est indépendant du nombre de personnes contaminées par le malade \( j\). De plus la façon dont la contamination se passe à l'instant \( n\) est indépendant de la façon dont la contamination se passe à l'instant \( m\). Ces hypothèses sont raisonnables tant que le nombre de personnes non contaminées est grand. À partir du moment où presque tout le monde est malade, l'approximation de Galton-Watson ne fonctionne plus.

Nous notons \( \xi\) la loi parente des \( \xi_i^{(n)}\). Ensuite nous considérons 
\begin{subequations}
    \begin{align}
        G(s)=E(s^{\xi})\\
        m=E(\xi)\\
        G_n(s)=E(s^{Z_n}).
    \end{align}
\end{subequations}

    Par le théorème de transfert (proposition \ref{PropintdPintdPXeR}) avec \( f(t)=s^t\). Ce que nous avons est
    \begin{equation}        \label{EqNRtXdC}
        G_n(s)=E\big( f(Z_n) \big)=\int_{\eR}s^xdP_{Z_n}(x)=\sum_{k=0}^{\infty}s^kP(Z_n=k)
    \end{equation}
    où l'intégrale s'est transformée en somme parce que la loi de \( Z_n\) est discrète : \( dP_{Z_n}\) est une somme de masses de Dirac. En particulier nous avons
    \begin{subequations}
        \begin{align}
            G_n(s)&=\sum_{k=0}^{\infty}s^kP(Z_n=k)\\
            G(0)&=P(Z_n=0)
        \end{align}
    \end{subequations}
    et
    \begin{equation}
        \eta=\lim_{n\to \infty} P(Z_n=0)=\lim_{n\to \infty} G_n(0).
    \end{equation}
    D'où l'intérêt d'étudier \( G_n\).

\begin{lemma}       \label{LemezrOiI}
    Pour tout \( n\in \eN^*\) et pour tout \( s\in\mathopen[ 0 , 1 \mathclose]\), nous avons
    \begin{equation}
        G_n(s)=\underbrace{G\circ G\circ\ldots\circ G(s)}_{\text{\( n\) fois}}.
    \end{equation}
\end{lemma}

\begin{proof}
    Pour \( n=1\), nous avons \( Z_1=\xi^{(1)}_1\) et donc
    \begin{equation}
        G_1(s)=E(s^{\xi})=G(s),
    \end{equation}
    comme il se doit.

    Si \( n\neq 1\) nous écrivons
    \begin{subequations}    \label{subEqsxhILKg}
        \begin{align}
            G_n(s)&=E(s^{Z_n})\\
            &=E\left( s^{\sum_{i=1}^{Z_{n-1}}\xi_i^{(n-1)}} \right)\\
            &=E\left( \sum_{k=0}^{\infty}\mtu_{\{ Z_{n-1}=k \}}s^{\sum_{i=1}^k\xi_i^{(n-1)}} \right).
        \end{align}
    \end{subequations}
    À ce niveau, nous voulons permuter la somme et l'espérance. Étant donné que le lemme est facile à vérifier pour \( s=1\), nous supposons \( s<1\). Du coup 
    \begin{equation}
        s^{\sum_{i=1}^k\xi_i^{(n-1)}}<1
    \end{equation}
    et ce qui se trouve dans l'espérance est majoré par
    \begin{equation}
        \sum_{k=0}^{\infty}\mtu_{Z_{n-1}=k}=1.
    \end{equation}
    La fonction constante \( 1\) est intégrable sur \( \Omega\) (ici nous utilisons à fond le fait que l'espace \( \Omega\) soit un espace de probabilité) et nous pouvons utiliser le théorème de convergence dominée de Lebesgue \ref{ThoockMHn} pour permuter la somme et l'intégrale. Nous continuons donc le calcul \eqref{subEqsxhILKg}:
    \begin{equation}
        G_n(s)=\sum_{k=0}^{\infty}E\left(  \mtu_{\{ Z_{n-1}=k \}}s^{\sum_{i=1}^k\xi_i^{(n-1)}}  \right).
    \end{equation}
    La tribu engendrée par la variable aléatoire \( \mtu_{\{ Z_{n-1}=k \}}\) est une fonction des variable aléatoires \( \xi_i^{(m)}\) avec \( m\leq n-2\) tandis que la variable aléatoire \( s^{\sum_{i=1}^k\xi_i^{(n-1)}}\) est une fonction des variable aléatoires \( \xi_{i}^{(n-1)}\). Par conséquent le lemme de regroupement \ref{LemHOjqqw} nous dit que ces variables aléatoires sont indépendantes, donc
    \begin{equation}
        G_n(s)=\sum_{k=0}^{\infty}\underbrace{E\big( \mtu_{\{ Z_{n-1}=k \}} \big)}_{=P(Z_{n-1}=k)}E\big( s^{\sum_{i=1}^{k}\xi_i^{(n-1)}} \big).
    \end{equation}
    Nous avons utilisé le fait que l'espérance d'une fonction indicatrice est la probabilité de l'événement.

    En ce qui concerne la puissance de \( s\), les événements \( \xi_i^{n-1}\) sont indépendants et suivent tous la même loi \( \xi\), donc
    \begin{equation}
        s^{\sum_{i=1}^{k}\xi_i^{(n-1)}}=\prod_{i=1}^ks^{\xi_i^{(n-1)}}
    \end{equation}
    et
    \begin{equation}
        E\big( \prod_{i=1}^ks^{\xi} \big)=E(s^{\xi})^k=G(s)^k.
    \end{equation}
    En mettant tout bout à bout,
    \begin{equation}
        G_n(s)=\sum_{k=1}^{\infty}P(Z_{n-1}=k)G(s)^j=G_{n-1}\big( G(s) \big).
    \end{equation}
\end{proof}

\begin{theorem}  \label{ThoJZnAOA}
    La probabilité d'extinction \( \eta\) est donnée par
    \begin{equation}
        \eta=P\left(\bigcup_{n\geq 1}(Z_n=0)\right)=\lim_{n\to \infty} P(Z_n=0).
    \end{equation}
    Ce nombre est la plus petite solution positive de l'équation \( G(s)=s\).

    De plus la classification des cas est comme suit.
    \begin{enumerate}
        \item
            Si \( P(\xi=0)=0\) alors \( \eta=0\).
        \item
            Si \( P(\xi=0)\neq 0\) alors
            \begin{enumerate}
                \item
                    si \( m\leq 1\) alors \( \eta=1\),
                \item
                    si \( m>1\) alors \( \eta\in\mathopen] 0 , 1 \mathclose[\).
            \end{enumerate}
    \end{enumerate}
\end{theorem}
\index{point fixe}
\index{convolution}
\index{série!entière!processus de Markov}
Le cas \( m<1\) est dit \defe{sous-critique}{Galton-Watson!sous-critique}, le cas \( m=1\) est dit \defe{critique}{critique!Galton-Watson}. Le cas \( m>1\) est dit \defe{sur-critique}{Galton-Watson!sur-critique}.

\begin{proof}
    Commençons par prouver que \( G\) est une fonction continue. En utilisant la théorème de transfert comme pour l'équation \eqref{EqNRtXdC} nous trouvons que
    \begin{equation}    \label{EqQWTBfn}
        G(s)=E(s^{\xi})=\sum_{k=0}^{\infty}p_ks^k
    \end{equation}
    où nous avons noté \( p_k=P(\xi=k)\). Si \( r<1\), alors la suite \( p_kr^k\) est bornée, donc le critère d'Abel (\ref{LemmbWnFI}) nous indique que la série \eqref{EqQWTBfn} converge absolument et la théorie générale des séries entières conclut que la fonction \( G\) est en particulier dérivable terme à terme pour tout \( s\in\mathopen] -1 , 1 \mathclose[\). 

    \begin{subproof}

        \item[Le probabilité d'extinction est un point fixe de \( G\)]

    En utilisant la continuité de \( G\) en \( 0\) nous passons à la limite dans \( G_{n+1}(0)=G\big( G_n(0) \big)\) et nous obtenons
    \begin{equation}
        \eta=G(\eta),
    \end{equation}
    ce qui signifie que la probabilité d'extinction est un point fixe de \( G\).

        \item[\( \eta\) est le plus petit point fixe de \( G\)] 

    Nous démontrons maintenant que \( \eta\) est plus précisément le plus petit point fixe de \( G\) sur \( \mathopen[ 0 , 1 \mathclose]\). Nous allons effectuer cette partie en décomposant selon les valeurs de \( p_0\) et de \( p_1\).

    Au vu de l'écriture \eqref{EqQWTBfn}, si \( p_1=1\) alors \( G(s)=s\) pour tout \( s\in\mathopen[ 0 , 1 \mathclose]\). Mais dans ce cas nous savons par ailleurs que l'extinction est impossible.  Zéro est bien la plus petite solution de \( G(s)=s\).

    Supposons maintenant que \( p_1<1\) et \( p_0+p_1=1\). Alors \( G(s)=p_0+p_1s\) et \( s=1\) est l'unique solution. Mais vu que nous savons que \( \eta\) est solution, c'est que \( \eta=1\) et l'extinction est certaine. 

    Nous passons au cas général : \( p_0+p_1<1\). D'abord nous remarquons que \( s=1\) est solution parce que 
    \begin{equation}
        G(1)=p_0+p_1+\cdots=1.
    \end{equation}
    Remarquons aussi que dans ce cas \( s=0\) n'est plus solution.

    La fonction \( G\) est strictement convexe sur \( \mathopen[ 0 , 1 \mathclose]\) (parce que \( G''>0\)). Cela se voir en effectuant deux dérivations termes à termes (le rayon de convergence de la dérivée est le même que celui de la fonction). Cette stricte convexité entraine que l'équation \( G(s)=s\) a au maximum une autre solution que \( s=1\). Nous nommons \( s_0\) la plus petite solution dans \( \mathopen[ 0 , 1 \mathclose]\). Étant donné que \( G\) est croissante on a
    \begin{equation}
        G(0)\leq G(s_0)=s_0.
    \end{equation}
    En appliquant \( G\) à cette équation nous obtenons \( G\big( G(s_0) \big)\leq G(s_0)=s_0\) et en appliquant \( n\) fois,
    \begin{equation}
        G_n(0)\leq s_0.
    \end{equation}
    En passant à la limite, \( \eta\leq s_0\) mais \( \eta\) étant solution, nous avons \( \eta=s_0\). Nous avons donc prouvé que la probabilité d'extinction \( \eta\) est la plus petite solution de \( G(s)=s\).

\item[Classification des cas]

    Nous devons encore discuter les cas. Si \( P(\xi=0)=0\), alors \( p_0=0\) et \( G(0)=0\), ce qui signifie que \( s_0=\eta=0\) et l'extinction est impossible. 
    
    Nous passons au cas \( p_0\neq 0\). Si \( p_0+p_1=1\), alors \( m=p_1<1\) et nous avions déjà vu que dans le cas \( p_0+p_1=1\), la probabilité d'extinction est \( \eta=1\).

    Il nous reste à traiter le cas \( p_0+p_1<1\). Encore une fois, la courbe \( G\) est strictement convexe sur \( \mathopen[ 0 , 1 \mathclose]\) et elle est en particulier plus grande que sa tangente en \( s=1\), c'est à dire
    \begin{equation}
        G(s)>G'(1)(s-1)+G(1).
    \end{equation}
    Nous savons que \( G(1)=1\). En ce qui concerne \( G'(1)\), nous dérivons encore terme à termes :
    \begin{equation}
        G'(s)=\sum_{k=1}^{\infty}kp_ks^{k-1},
    \end{equation}
    donc
    \begin{equation}
        G'(1)=\sum_{k=1}^{\infty}kp_k=E(\xi)=m.
    \end{equation}
    Ce que nous avons donc est
    \begin{equation}
        G(s)>1+m(s-1).
    \end{equation}
    Nous nous particularisons au cas sous-critique (\( m\leq 1\)). En nous rappelant que \( s-1<0\),
    \begin{equation}
        G(s)>1+(s-1)=s,
    \end{equation}
    donc \( s=1\) est la plus petite solution et effectivement nous avons déjà vu que \( \eta=1\) dans ce cas.

    Si \( m>1\), alors on a
    \begin{equation}
        G(s)>1+m(s-1).
    \end{equation}
    Mais dire \( m>1\) revient à dire \( G'(1)>1\) et donc dans un voisinage de \( s=1\) on a
    \begin{equation}
        \frac{ G(s)-G(1) }{ s-1 }>1,
    \end{equation}
    ce qui implique que
    \begin{equation}
        G(s)<s-1+G(1)=s.
    \end{equation}
    Nous avons donc \( G(s)<s\) dans un voisinage de \( 1\). Mais \( G(0)-0=p_0>0\), donc la fonction \( f(s)=G(s)-s\) est positive en \( 0\) et négative proche de \( s=1\). Le théorème de la valeur intermédiaire nous indique alors qu'il existe un \( s\in \mathopen] 0 , 1 \mathclose[\) tel que \( f(s)=0\), c'est à dire tel que \( G(s)=s\).
    \end{subproof}
\end{proof}
