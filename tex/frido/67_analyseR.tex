% This is part of Le Frido
% Copyright (c) 2006-2024
%   Laurent Claessens, Carlotta Donadello
% See the file fdl-1.3.txt for copying conditions.


%---------------------------------------------------------------------------------------------------------------------------
\subsection{Gradient}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}
	Soit \( f\) une fonction différentiable de \( \eR^m\) dans \( \eR\). On appelle \defe{gradient}{gradient} de \( f\) la fonction \( \nabla f : \eR^m\to \eR^m\)\nomenclature{\( \nabla f\)}{gradient de la fonction \( f\)} de composantes
	\[
		\partial_{1}f,\ldots,\partial_{m}f.
	\]
	Soit \( f\) une fonction de \( \eR^m\) dans \( \eR^n\), \( f(a)=(f_1(a),\ldots,f_n(a))^T\). On appelle \defe{matrice jacobienne}{matrice!jacobienne} de \( f\) la fonction \( J(f) : \eR^m\to \eR^m\times\eR^n\) définie par
	\begin{equation}
		a\mapsto  \begin{pmatrix}
			\partial_{1}f_1(a)  & \ldots & \partial_{m}f_1(a) \\
			\vdots              & \ddots & \vdots             \\
			\partial_{1}f_n (a) & \ldots & \partial_{m}f_n(a) \\
		\end{pmatrix}
	\end{equation}
\end{definition}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Linéarité}
%---------------------------------------------------------------------------------------------------------------------------

La proposition suivante signifie que la différentiation est une opération linéaire sur l'ensemble des fonctions différentiables.
\begin{proposition}		\label{PropDiffLineaire}
	Soient \( f\) et \( g\) deux fonctions de \( U\subset\eR^m\) dans \( \eR^n\) différentiables au point \( a\in U\), et soit \( \lambda\) dans \( \eR\). Alors les fonctions \( f+g\) et \( \lambda f\) sont différentiables au point \( a\) et on a
	\begin{equation}
		\begin{aligned}
			 & d(f+g)(a)=df(a)+dg(a),         \\
			 & d(\lambda f)(a)=\lambda df(a),
		\end{aligned}
	\end{equation}
\end{proposition}
\begin{proof}
	\begin{equation}
		\begin{aligned}
			 & \lim_{h\to 0_m}\frac{\left\|\left(f(a+h)+g(a+h)\right)-\left(f(a)+g(a)\right)-df(a).h-dg(a).h\right\|_n}{\|h\|_m}\leq \\
			 & \lim_{h\to 0_m}\frac{\|f(a+h)-f(a)-df(a).h\|_n}{\|h\|_m}+\lim_{h\to 0_m}\frac{\|g(a+h)-g(a)-dg(a).h\|_n}{\|h\|_m}=0.
		\end{aligned}
	\end{equation}
	De même on démontre la  propriété \( d(\lambda f)(a)=\lambda df(a)\).
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Produit}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Soient \( f\) et \( g\) deux fonctions de \( \eR^m\) dans \( \eR^n\). Nous notons \( f\cdot g\) la fonction de \( \eR^n\) dans \( \eR\) donnée par le produit scalaire point par point, c'est-à-dire
\begin{equation}
	(f\cdot g)(x)=f(x)\cdot g(x)
\end{equation}
pour tout \( x\in\eR^m\). Le point dans le membre de droite est le produit scalaire dans \( \eR^n\). Le cas particulier \( n=1\) revient au produit usuel de fonctions :
\begin{equation}
	(fg)(x)=f(x)g(x).
\end{equation}

\begin{lemma}		\label{LemDiffProsuid}
	Si \( f\) et \( g\) sont des fonctions différentiables sur \( \eR^m\) à valeurs dans \( \eR\), alors la fonction produit \( fg\) est également différentiable et
	\begin{equation}		\label{EqDifffgProd}
		(dfg)_a=g(a)df_a+f(a)dg_a
	\end{equation}
	au sens où pour chaque \( u\) dans \( \eR^m\),
	\begin{equation}
		(dfg)_a(u)=g(a)df_a(u)+f(a)dg_a(u).
	\end{equation}
\end{lemma}

\begin{proof}
	Ce que nous devons faire pour vérifier la formule~\ref{EqDifffgProd}, c'est de vérifier le critère \eqref{EqCritereDefDiff} en remplaçant \( f\) par \( fg\) et \( T(h)\) par \( g(a)df(a).h+f(a)dg(a).h\).

	Ce que nous avons au numérateur est
	\begin{equation}
		\begin{aligned}[]
			\clubsuit & =(fg)(a+h)-(fg)(a)-g(a)df(a).h-f(a)dg(a).h      \\
			          & =f(a+h)g(a+h)-f(a)g(a)-g(a)df(a).h-f(a)dg(a).h.
		\end{aligned}
	\end{equation}
	Maintenant, nous allons faire apparaitre \( \big( f(a+h)-f(a)-df(a) \big)g(a+h)\) en ajoutant et soustrayant ce qu'il faut pour conserver \( \clubsuit\) :
	\begin{equation}
		\begin{aligned}[]
			\clubsuit & =\big( f(a+h)-f(a)-df(a).h \big)g(a+h)   \\
			          & \quad +f(a)g(a+h)+g(a+h)df(a).h          \\
			          & \quad -f(a)g(a)-g(a)df(a).h-f(a)dg(a).h.
		\end{aligned}
	\end{equation}
	Nous mettons maintenant \( f(a)\) et \( df(a).h\) en évidence là où c'est possible :
	\begin{equation}
		\begin{aligned}[]
			\clubsuit & =\big( f(a+h)-f(a)-df(a).h \big)g(a+h)    \\
			          & \quad+f(a)\big( g(a+h)-g(a)-dg(a).h \big) \\
			          & \quad+\big( g(a+h)-g(a) \big)df(a).h.
		\end{aligned}
	\end{equation}
	Nous devons maintenant considérer la limite
	\begin{equation}
		\lim_{h\to 0}\frac{ \| \clubsuit \| }{ \| h \| }.
	\end{equation}
	Étant donné que \( f\) et \( g\) sont différentiables, les deux premiers termes sont nuls :
	\begin{equation}
		\begin{aligned}[]
			\lim_{h\to 0}\frac{ \big( f(a+h)-f(a)-df(a).h \big)}{\| h \|}g(a+h)=0 \\
			\lim_{h\to 0} f(a)\frac{ \big( g(a+h)-g(a)-dg(a).h \big)}{\| h \|}=0.
		\end{aligned}
	\end{equation}
	En ce qui concerne le troisième terme, en utilisant la norme d'une application linéaire, nous avons
	\begin{equation}
		\lim_{h\to 0} \frac{ \| df(a).h \| }{ \| h \| }\leq\sup_{h\in\eR^m}\frac{ \| df(a).h \| }{ \| h \| }=\| df(a) \|,
	\end{equation}
	et par conséquent
	\begin{equation}
		\begin{aligned}[]
			0 & \leq\lim_{h\to 0} \| g(a+h)-g(a) \|\frac{ \| df(a).h \|\| h \| }{ \| h \| } \\
			  & \leq \lim_{h\to 0} \| g(a+h)-g(a) \|\| df(a) \|=0
		\end{aligned}
	\end{equation}
	parce que \( g\) est continue (la limite du premier facteur est nulle tandis que la norme de \( df(a)\) est un nombre constant). Nous avons donc bien prouvé que la formule \eqref{EqDifffgProd} est la différentielle de \( fg\) au point \( a\).
\end{proof}


Ce résultat se généralise pour des fonctions \( f\) et \( g\) de \( \eR^m\) dans \( \eR^n\) dans la proposition suivante qui généralise tout en même temps la proposition \ref{PROPooFKKHooQZGXhE}.
\begin{proposition}
	Soient \( f\) et \( g\) deux fonctions de \( U\subset\eR^m\) dans \( \eR^n\) différentiables au point \( a\in U\). Alors la fonction \( f\cdot g\) est différentiable  au point \( a\) et on a
	\begin{equation}
		d(f\cdot g)(a)=g(a)\cdot df(a)+f(a)\cdot dg(a)
	\end{equation}
	au sens où
	\begin{equation}		\label{Eqdfcdotgexpl}
		d(f\cdot g)_a(u)=g(a)\cdot\big( df_a(u) \big)+f(a)\cdot\big( dg_a(u) \big)
	\end{equation}
	pour tout \( u\in\eR^m\).
\end{proposition}

\begin{proof}
	La preuve du cas \( n=1\) est déjà faite; c'est la formule \eqref{EqDifffgProd}. Pour le cas général \( n\geq 2\), nous passons aux composantes en nous rappelant que
	\begin{equation}
		(f\cdot g)(a)=\sum_{i=1}^nf_i(a)g_i(a)=\sum_{i=1}^n(f_ig_i)(a).
	\end{equation}
	En utilisant la linéarité de la différentiation, nous nous réduisons donc au cas des produits \( f_ig_i\) qui sont des fonctions de \( \eR^m\) dans \( \eR\) :
	\begin{equation}
		\begin{aligned}[]
			d(f\cdot g)(a) & =d\left( \sum_{i=1}^n f_ig_i \right)(a)              \\
			               & =\sum_{i=1}^n\big( df_i(a)g_i(a)+f_i(a)dg_i(a) \big) \\
			               & =g(a)\cdot df(a)+f(a)\cdot dg(a).
		\end{aligned}
	\end{equation}
	Ceci termine la preuve.
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Difficulté d'ordre supérieur}
%---------------------------------------------------------------------------------------------------------------------------

\begin{normaltext}
	Il serait tentant de faire une récurrence sur le lemme \ref{LemDiffProsuid} pour dire que si \( f\) et \( g\) sont de classe \( C^p\), alors le produit \( fg\) est également de classe \( C^p\), parce que la formule de \( d(fg)\) contient des produits de fonctions de classe \( C^p\) et \( C^{p-1}\).

	Le problème est que le lemme \ref{LemDiffProsuid} est énoncé et prouvé pour des fonctions à valeurs dans \( \eR\), alors que déjà la formule
	\begin{equation}
		d(fg)=gdf+fdg
	\end{equation}
	contient le produit de \( g\colon E\to \eR \) par \( df\colon E\to \aL(E,\eR)\). Lorsque nous montons dans les différentielles, la situation empire, et les produits dont sont composés les formules sont réellement à définir\ldots
\end{normaltext}

Oublions un instant les questions de régularité, et calculons sans ménagement, pour voir ce qu'il se passe. Nous considérons un espace vectoriel \( E\) ainsi que des fonctions \( f\colon E\to \eR\) et \( g\colon E \to V\) où \( V\) est un autre espace vectoriel.

Nous avons
\begin{equation}
	d(fg)_a(u)=df_a(u)g(a)+f(a)dg_a(u).
\end{equation}
Les deux termes sont des produits \( \eR\times V\to \eR\). Montons un coup :
\begin{equation}
	d(gdf)_a(u)=\Dsdd{ (gdf)(a+tu) }{t}{0}=\Dsdd{ g(a+tu)df_{a+tu} }{t}{0}=dg_a(u)df_a+g(a)(d^2f)_a(u).
\end{equation}
Un autre pour voir comment ça se passe plus haut :
\begin{equation}
	d(dfdg)_a(u)=\Dsdd{ (dfdg)(a+tu) }{t}{0}=\Dsdd{ df_{a+tu}dg_{a+tu} }{t}{0}=(d^2f)_a(u)dg_a+df_a(d^2g)_a(u).
\end{equation}
Là déjà vous noterez que nous sommes passés par le produit
\begin{equation}
	df_{a+tu}df_{a+tu}
\end{equation}
qui pour chaque \( t\) est un produit \( \aL(E,\eR)\times \aL(E,V)\) que nous n'avons pas réellement défini.

En continuant le calcul ainsi nous trouvons par exemple
\begin{equation}
	\begin{aligned}[]
		(d^3fg)_a(u) & =d^3f_a(u)g(a)+d^2f_adg_a(u)          \\
		             & \quad +d^2f_a(u)dg_a+df_ad^2g_a(u)    \\
		             & \quad +d^2f_a(u)dg_a+df_a(d^2g)_a(u)  \\
		             & \quad +df_a(u)d^2g_a+f(a)(d^3g)_a(u).
	\end{aligned}
\end{equation}
Vous noterez que cette formule contient trois termes que nous aurions eu envie de noter \( d^2fdg\). Or ces trois termes ne sont pas identiques : deux sont \( d^2f_a(u)dg_a\) et un est \( (d^2f)_adg_a(u)\).

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Solution : produit tensoriel}
%---------------------------------------------------------------------------------------------------------------------------

Afin de donner un sens à tous les produits, nous allons passer par les produits tensoriels. Nous avons déjà le théorème \ref{PROPooAWZFooMlhoCN} qui fait pratiquement tout.

\begin{proposition}[\cite{MonCerveau}]      \label{PROPooWNCGooHbmcVb}
	Soient des fonctions \( f\colon \eR^n\to \eR\) et \( g\colon \eR^n\to \eR\) de classe \( C^p\). Alors \( fg\) est de classe \( C^p\).
\end{proposition}

\begin{proof}
	Nous considérons l'application
	\begin{equation}
		\begin{aligned}
			\varphi\colon \eR\otimes \eR & \to \eR   \\
			1\otimes 1                   & \mapsto 1
		\end{aligned}
	\end{equation}
	dont nous avons déjà parlé dans le lemme \ref{LEMooVONEooQpPgcn}. En utilisant la notation \( \tilde\otimes\) de la définition \ref{DEFooMVNDooFWFtRn}, nous avons
	\begin{equation}
		fg=\varphi\circ(f\tilde\otimes g).
	\end{equation}
	La proposition \ref{PROPooAWZFooMlhoCN} nous dit que \( f\tilde\otimes g\colon \eR^n\to \eR\otimes \eR\) est de classe \( C^p\). Vu que \( \varphi\) est un isomorphisme d'espaces vectoriels, la proposition \ref{PROPooRCZOooSgvpSE} nous dit que \( \varphi\circ(f\tilde\otimes g)\) est encore de classe \( C^p\).

	Et voilà.
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Formes bilinéaires}
%---------------------------------------------------------------------------------------------------------------------------

Nous avons aussi une formule importante pour la différentielle des formes bilinéaires.
\begin{lemma}\label{bilin_diff}
	Toute application bilinéaire
	\begin{equation}
		\begin{aligned}
			B\colon \eR^m\times\eR^n & \to \eR^p      \\
			B(a_1,a_2)               & =a_1 \star a_2
		\end{aligned}
	\end{equation}
	est différentiable en tout point \( (a_1,a_2)\) de \( \eR^m\times\eR^n\), et on a
	\[
		dB(a_1,a_2).(h_1,h_2)=h_1\star a_2 + a_1\star h_2.
	\]
\end{lemma}
\begin{proof}
	\begin{equation}
		\begin{aligned}
			 & \frac{\|B(a_1+h_1,a_2+h_2)-B(a_1,a_2)-(h_1\star a_2 + a_1\star h_2)\|_p}{\|(h_1,h_2)\|_{\eR^m\times\eR^n}} =                   \\
			 & = \frac{\|(a_1+h_1)\star(a_2+h_2)-a_1\star a_2-(h_1\star a_2 + a_1\star h_2)\|_p}{\|(h_1,h_2)\|_{\eR^m\times\eR^n}}=\spadesuit
		\end{aligned}
	\end{equation}
	on rajoute et on enlève la quantité \( (a_1+h_1)\star a_2\) dans le numérateur, et on obtient
	\begin{equation}
		\begin{aligned}
			%&= \frac{\|(a_1+h_1)\star(a_2+h_2)-(a_1+h_1)\star a_2 +(a_1+h_1)\star a_2- a_1\star a_2-}{\|(h_1,h_2)\|_{\eR^m\times\eR^n}}\\
			%&\hspace{7cm}\frac{-(h_1\star a_2 + a_1\star h_2)\|_p}{\quad}=\\
			 & \spadesuit= \frac{\|(a_1+h_1)\star h_2+h_1\star a_2-(h_1\star a_2 + a_1\star h_2)\|_p}{\|(h_1,h_2)\|_{\eR^m\times\eR^n}}=      \\
			 & = \frac{\|h_1\star h_2\|_p}{\|(h_1,h_2)\|_{\eR^m\times\eR^n}}\leq C\frac{\|h_1\|_m\|h_2\|_n}{\|(h_1,h_2)\|_{\eR^m\times\eR^n}} \\
			 & \leq C\frac{\|(h_1,h_2)\|^2_{\eR^m\times\eR^n}}{\|(h_1,h_2)\|_{\eR^m\times\eR^n}}= C\|(h_1,h_2)\|_{\eR^m\times\eR^n}.
		\end{aligned}
	\end{equation}
	Si on prend la limite de cette expression pour \( (h_1,h_2)\to (0_m,0_n)\) on obtient \( 0\), donc la preuve est complète. À noter, que dans l'avant-dernier passage on a utilisé la continuité des applications linéaires \( \pr_m:\eR^m\times\eR^n\to \eR^m\) et \( \pr_n: \eR^m\times\eR^n\to \eR^n\) qui à chaque point \( (a_1,a_2)\) de \( \eR^m\times\eR^n\) associent \( a_1\) et \( a_2\) respectivement.
\end{proof}

\begin{proposition}     \label{PropEKLTooSvZjdW}
	Soit \( V\) et \( W\) deux espaces vectoriels et \( \varphi\colon V\to W\) un isomorphisme. Soit \( f\colon \eC\to V\) une application telle que \(\varphi\circ f\colon \eC\to W\) soit différentiable.

	Alors \( f\) est différentiable et \( df=\varphi^{-1}\circ d(\varphi\circ f)\).
\end{proposition}

\begin{proof}
	Si \( T\) est la différentielle de \( \varphi\circ f\) au point \( z\) nous avons
	\begin{subequations}
		\begin{align}
			0 & =\lim_{\substack{h\to 0                                            \\h\in \eC}}\frac{ (\varphi\circ f)(z+h)-(\varphi\circ f)(z)+T(h) }{ h }\\
			  & = \lim_{\substack{h\to 0                                           \\h\in \eC}}\frac{ (\varphi\circ f)(z+h)-(\varphi\circ f)(z)+\varphi\big( (\varphi\circ T)(h) \big) }{ h }\\
			  & = \lim_{\substack{h\to 0                                           \\h\in \eC}}\varphi\left( \frac{ f(z+h)- f(z)+ (\varphi\circ T)(h)  }{ h }\right)\\
			  & =\varphi\lim_{h\to 0} \frac{ f(z+h)-f(z)+\varphi^{-1} T(h) }{ h }.
		\end{align}
	\end{subequations}
	Pour la dernière ligne, nous avons permuté \( \varphi\) avec la limite (parce que \( \varphi\) est continue). Nous avons prouvé que \( f\) est différentiable et que \( df=\varphi^{-1}\circ T=\varphi^{-1}\circ d(\varphi\circ f)\).
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Différentielle de fonction composée}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Une importante règle de différentiation est la règle de différentiation d'une fonction composée (\emph{chain rule} dans les livres anglais et américains). Cette règle généralise la règle de dérivation pour fonctions de \( \eR\) dans \( \eR\).

Cette règle a déjà été donnée dans le théorème \ref{THOooIHPIooIUyPaf}, mais si vous avez seulement envie d'entendre parler de \( \eR^n\), vous pouvez lire le lemme \ref{Def_diff2} suivi de la proposition \ref{PropDiffCompose}.

Le lemme suivant est essentiellement une reformulation du lemme \ref{LEMooYQZZooVybqjK}.
\begin{lemma}\label{Def_diff2}
	Soit \( U\) un ouvert de \( \eR^m\). La fonction \( f: U\to\eR^n\) est différentiable au point \( a\) dans \( U\), si et seulement si il existe une fonction \( \sigma_f: U\times U\to \eR^n\) telle que
	\begin{subequations}		\label{SubEqsDiff2}
		\begin{align}
			\sigma_f(a,a) & =\lim_{x\to a} \sigma_f(a,x)=0                           \\
			f(x)          & =f(a)+T(x-a)+\sigma_f(a,x)\|x-a\|_m,   \label{def_diff2}
		\end{align}
	\end{subequations}
	pour une certaine application linéaire \( T\in\mathcal{L}(\eR^m,\eR^n)\).
\end{lemma}

\begin{proof}
	Si les conditions \eqref{SubEqsDiff2} sont satisfaites alors \( T\) est la différentielle de \( f\) en \( a\). En effet, dans ce cas nous avons
	\begin{equation}
		f(a+h)=f(a)+T(h)+\sigma_f(a,a+h)\| h \|,
	\end{equation}
	et la condition \eqref{EqCritereDefDiff} devient
	\begin{equation}
		\lim_{h\to 0} \frac{ \| \sigma_f(a,a+h) \|\| h \| }{ \| h \| }=\lim_{h\to 0} \| \sigma_f(a,a+h)\| =0
	\end{equation}


	Si \( f\) est différentiable au point \( a\) il suffit de prendre \( T=df(a)\) et
	\[
		\sigma_f(a,x)=\frac{f(x)-f(a)-df(a).(x-a)}{\|x-a\|_m}.
	\]
\end{proof}

\begin{remark}
	La fonction \( \sigma_f(a,x)\| x-a \|_m\) est ce qui avait été appelé \( \epsilon(h)\) sur la figure~\ref{LabelFigDifferentielle}.
\end{remark}

\begin{proposition}		\label{PropDiffCompose}
	Soient \( U\) un ouvert de \( \eR^m\) et \( V\) un ouvert de \( \eR^n\). Soient \( f: U\to V\)  et \( g: V \to \eR^p\) deux fonctions différentiables respectivement au point \( a\) dans \( U\) et \( b=f(a)\) dans \( V\). Alors la fonction composée \( g\circ f: U\to \eR^p \) est différentiable au point \( a\) et
	\begin{equation}	\label{EqDiffCompose}
		d(g\circ f)_a=dg_{f(a)}\circ df_a.
	\end{equation}
\end{proposition}

\begin{proof}
	En tenant compte du lemme~\ref{Def_diff2} on peut écrire
	\begin{subequations}
		\begin{align}
			f(a+h)-f(a) & =df_a(h)+\sigma_f(a,a+h)\|h\|_m, &  & \forall h\in U\setminus \{0\}, \\
			g(b+k)-g(b) & =dg_b(k)+\sigma_g(b,b+k)\|k\|_n, &  & \forall k\in V\setminus \{0\}.
		\end{align}
	\end{subequations}
	On sait que \( f(a)=b\) et que \( f(a+h)\) est  un élément de \( V\) et \( f(a+h)=f(a)+k\) pour \( k=df(a).h+\sigma_f(a,a+h)\|h\|_m\).  Par substitution dans la deuxième équation on obtient
	\begin{equation}
		\begin{aligned}
			g\big(f(a+h)\big) & - g\big(f(a)\big)                                                                                  \\
			                  & =dg_{f(a)}\Big(df_a(h)+\sigma_f(a,a+h)\|h\|_m\Big)                                                 \\
			                  & \quad+\sigma_g\left(f(a), f(a+h)\right)\left\| df_a(h)+\sigma_f(a,a+h)\|h\|_m\right \|_n           \\
			                  & =g\circ f (a+h) - g\circ f (a)                                                                     \\
			                  & = dg_{f(a)}\circ df_a(h)                                                                           \\
			                  & \quad +\|h\|_m\Big[ dg_{f(a)}\sigma_f(a,a+h)                                                       \\
			                  & \quad+\sigma_g\left(f(a), f(a+h)\right)\big\| df_a\frac{h}{\|h\|_m}+\sigma_f(a,a+h)\big \|_n\Big],
		\end{aligned}
	\end{equation}
	donc
	\begin{equation}
		(g\circ f) (a+h) - (g\circ f) (a) = dg_f(a)\circ df_a(h) + S(a,a+h) \|h\|_m
	\end{equation}
	où \( S\) représente le contenu du dernier grand crochet. Il ne reste plus qu'à prouver que \( S(a,a+h)\) est \( o(\|h\|_m)\). En tenant compte du fait que \( \sigma_f(a,a+h)\) et \( \sigma_g\left(f(a), f(a+h)\right)\) sont \( o (\|h\|_m)\),
	\begin{equation}
		\begin{aligned}
			 & \lim_{h\to 0_m} \frac{S(a,a+h)}{\|h\|_m}= \lim_{h\to 0_m}\frac{dg_{f(a)}\sigma_f(a,a+h)}{\|h\|_m}+                              \\
			 & + \lim_{h\to 0_m}\frac{\sigma_g\left(f(a), f(a+h)\right)\left\| df_a\frac{h}{\|h\|_m}+\sigma_f(a,a+h)\right \|_n}{\|h\|_m} = 0.
		\end{aligned}
	\end{equation}
\end{proof}

\begin{remark}
	Note : la formule \eqref{EqDiffCompose} est à comprendre de la façon suivante. Si \( u\in\eR^m\), alors
	\begin{equation}
		d(g\circ f)_a(u)=\underbrace{dg_{f(a)}}_{\in\aL(\eR^n,\eR^p)}\Big( \underbrace{df_a(u)}_{\in\eR^n} \Big)\in\eR^p.
	\end{equation}
\end{remark}

\begin{proposition}[\cite{MonCerveau}]	\label{PROPooYNQYooSjXBfU}
	Soient des espaces vectoriels normés \( V\) et \( W\) munis d'une base\footnote{Par rapport à laquelle seront écrites les dérivées partielles.}. Soient des applications \(s \colon \eR\to V  \) et \(g \colon V\to W  \). Nous supposons que \( s\) est différentiable en \( a\in \eR\) et que \( g\) est différentiable en \( f(a)\). Alors
	\begin{equation}
		(g\circ s)'(a)=\sum_i(\partial_ig)\big( s(a) \big)s'_i(a).
	\end{equation}
	%TODOooMVNMooYggxWx. Prouver ça.
\end{proposition}

\begin{proposition}[\cite{MonCerveau}]	\label{PROPooXAGQooRLMshw}
	Soit une application \(g \colon \eR^k\to \eR  \) de classe \( C^k\). Nous posons
	\begin{equation}
		\begin{aligned}
			h\colon \eR & \to \eR                \\
			t           & \mapsto g(t,\ldots,t).
		\end{aligned}
	\end{equation}
	Alors
	\begin{equation}
		h^{(k)}(t)=\sum_{i_1}\ldots \sum_{i_k}(\partial_{i_1}\ldots \partial_{i_k}g)(t,\ldots,t).
	\end{equation}
\end{proposition}

\begin{proof}
	Nous faisons une récurrence sur \( k\) en posant
	\begin{equation}
		\begin{aligned}
			s\colon \eR & \to \eR^k            \\
			t           & \mapsto (t,\ldots,t)
		\end{aligned}
	\end{equation}
	et en utilisant la proposition \ref{PROPooYNQYooSjXBfU}. Nous avons \( h=g\circ s\) et donc
	\begin{equation}
		h'(t)=\sum_i(\partial_ig)\big( s(t) \big)\underbrace{\frac{ \partial s_i }{ \partial t }(t)}_{=1},
	\end{equation}
	et donc \( h'=\sum_i(\partial_ig)\circ s\).

	Ensuite c'est la récurrence.
\end{proof}

Le lemme suivant sert à prouver les théorèmes \ref{ThoLDpRmXQ} et \ref{ThoUJMhFwU}. Il est fondamentalement la raison de la formule définissant l'intégrale d'une forme sur un chemin (définition \ref{DEFooRMHGooFtMEPB}).
\begin{lemma}[\cite{MonCerveau}]        \label{LEMooKNBVooQSowos}
	Soient un espace vectoriel normé \( F\) de dimension finie, ainsi que \( E\), un espace vectoriel normé. Nous considérons un chemin de classe \( C^1\)
	\begin{equation}
		\gamma\colon \mathopen[ a , b \mathclose]\to E
	\end{equation}
	et une application de classe \( C^1\)
	\begin{equation}
		f\colon E\to F.
	\end{equation}
	Si \( g=f\circ\gamma\), alors
	\begin{equation}
		g'(t)=(df)_{\gamma(t)}\big( \gamma'(t) \big)
	\end{equation}
	pour tout \( t\in \mathopen[ a , b \mathclose]\).
\end{lemma}

\begin{proof}
	Nous écrivons la dérivée de \( g\) de la façon suivante :
	\begin{subequations}        \label{SUBEQSooWKRYooGyVgNl}
		\begin{align}
			g'(t) & =\Dsdd{ g(t+s) }{s}{0}                                                \\
			      & =\Dsdd{ (f\circ \gamma)(t+s) }{s}{0}                                  \\
			      & =d(f\circ \gamma)_t(1) \label{SUBEQooHUZVooWECnVZ}                    \\
			      & =(df)_{\gamma(t)}\big( d\gamma_t(1) \big) \label{SUBEQooOAYLooIzltaY} \\
		\end{align}
	\end{subequations}
	Justifications :
	\begin{itemize}
		\item Pour \eqref{SUBEQooHUZVooWECnVZ} : les formules \eqref{LemdfaSurLesPartielles}. Notez que le \( 1\) à qui s'applique la différentielle de \( f\circ\gamma\) est le vecteur de \( \eR\) qui est multiplié par \( s\) dans l'expression \( (f\circ\gamma)(t+s)\).
		\item
		      Pour \eqref{SUBEQooOAYLooIzltaY} : la différentiation de fonctions composées de la proposition \ref{PropDiffCompose}.
	\end{itemize}
	Mais
	\begin{equation}
		d\gamma_t(1)=\Dsdd{ \gamma(t+s) }{s}{0}=\gamma'(t).
	\end{equation}
	En remettant au bout de \eqref{SUBEQSooWKRYooGyVgNl}, nous obtenons le résultat.
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Fonctions composées}
%---------------------------------------------------------------------------------------------------------------------------

Cette façon de voir la différentielle nous permet de jeter un nouveau regard sur la formule de différentiation des fonctions composées. Soient
\begin{equation}
	\begin{aligned}[]
		f\colon \eR^p & \to \eR^n \\
		g\colon \eR^n & \to \eR,
	\end{aligned}
\end{equation}
et \( h\colon \eR^p\to \eR\) définie par
\begin{equation}
	h(u)=g\big( f(u) \big)=(g\circ f)(u).
\end{equation}
Nous allons noter \( x\) les coordonnées de \( \eR^p\), \( a\) un point de \( \eR^p\) et \( u\), un vecteur de \( \eR^p\) accroché au point \( a\). Pour \( \eR^n\), les notations seront \( y\) pour les coordonnées, \( b\) pour un point de \( \eR^n\) et \( v\), un vecteur «accroché» au point \( b\).

Nous avons
\begin{equation}
	dg_b(v)=\sum_{i=1}^n\frac{ \partial g }{ \partial y_i }(b)dy_i(v).
\end{equation}
Ici \( dy_i(v)\) signifie la \( i\)ème composante de \( v\). C'est simplement \( v_i\). Cette formule étant valable pour tout point \( b\in\eR^n\) et pour tout vecteur \( v\), nous pouvons l'écrire en particulier pour
\begin{subequations}
	\begin{numcases}{}
		b=f(a)\\
		v=df_a(u).
	\end{numcases}
\end{subequations}
Cela donne
\begin{equation}        \label{Eqdgfadfau}
	dg_{f(a)}\big( df_a(u) \big)=\sum_{i=1}^n\frac{ \partial g }{ \partial y_i }\big( f(a) \big)dy_i\big( df_a(u) \big).
\end{equation}
Mais
\begin{equation}
	df_a(u)=\sum_{j=1}^p\frac{ \partial f }{ \partial x_j }(a)dx_j(u),
\end{equation}
donc la \( i\)ème composante de ce vecteur est
\begin{equation}
	\big( df_a(u)\big)_i=\sum_{j=1}^p\frac{ \partial f_i }{ \partial x_j }(a)dx_j(u).
\end{equation}
En remplaçant \( dy_i\big( df_a(u) \big)\) par cela dans l'expression \eqref{Eqdgfadfau}, nous trouvons
\begin{equation}
	dg_{f(a)}\big( df_a(u) \big)=\sum_{i=1}^n\frac{ \partial g }{ \partial y_i }\big( f(a) \big)\sum_{j=1}^p\frac{ \partial f_i }{ \partial x_j }(a)dx_j(u).
\end{equation}
Nous pouvons vérifier que c'est la différentielle de \( g\circ f\) au point \( a\), appliquée au vecteur \( u\). En effet
\begin{equation}
	d(g\circ f)_a(u)=\sum_{j=1}^p\frac{ \partial (g\circ f) }{ \partial x_j }(a)dx_j(u),
\end{equation}
tandis que, par la dérivation de fonctions composées,
\begin{equation}        \label{EqDerCompofg}
	\frac{ \partial (g\circ f) }{ \partial x_j }(a)=\sum_{i=1}^n\frac{ \partial g }{ \partial y_i }\big( f(a) \big)\frac{ \partial f_i }{ \partial x_j }(a).
\end{equation}
Au final, ce que nous avons prouvé est que
\begin{equation}        \label{EQooWSIYooBmsBDU}
	d(g\circ f)_a(u)=dg_{f(a)}\big( df_a(u) \big).
\end{equation}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Autres trucs sur la différentielle}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Différentielle et dérivées partielles}
%---------------------------------------------------------------------------------------------------------------------------

Étant donné que pour tout vecteur \( u\) dans \( \eR^m\) on a \( \partial_uf(a)=\nabla f(a)\cdot u\), le gradient de \( f\) nous donne la direction dans laquelle la croissance de \( f\) est maximale.

La matrice jacobienne calculée au point \( a\) est la matrice associée canoniquement à l'application linéaire \( df_a:\eR^m\to\eR^n\).

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Plan tangent}
%---------------------------------------------------------------------------------------------------------------------------

On a dit au début de cette section que si \( f\) est une fonction de \( \eR^2\) dans \( \eR\) alors le graphe de \( f\) est une surface à deux paramètres et que l'application affine tangente au graphe de \( f\) au point \( (a, f(a))\) est un plan. Maintenant on sait que ce plan est celui d'équation
\begin{equation}
	T_a(x,y)=f(a_1,a_2)+\frac{ \partial f }{ \partial x }(a_1,a_2)(x-a_1)+\frac{ \partial f }{ \partial y }(a_1,a_2)(y-a_2).
\end{equation}
Le plan tangent au graphe de \( f\) au point \( a\) est le graphe de cette fonction \( T_a\).

\begin{proposition}     \label{PROPooJPRUooNOcXPJ}
	Il existe des fonctions différentiables dont les dérivées partielles ne sont pas continues.
\end{proposition}

Retenez que si vous obtenez que les dérivées partielles d'une fonction ne sont pas continues, vous ne pouvez pas immédiatement en conclure que la fonction ne sera pas différentiable.


%---------------------------------------------------------------------------------------------------------------------------
\subsection{Notes idéologiques quant au concept de plan tangent}
%---------------------------------------------------------------------------------------------------------------------------
\label{ssecConceptPlanTag}

Notons \( G\), le graphe d'une fonction \( f\), c'est-à-dire
\begin{equation}
	G=\{ (x,y,z)\in\eR^3\tq z=f(x,y) \}.
\end{equation}
Première affirmation : si \( \gamma\colon \eR\to G\) est une courbe telle que \( \gamma(0)=\big( a,f(a) \big)\), alors \( \gamma'(0)\in\eR^n\) est dans le plan tangent à \( G\) au point \( \big( a,f(a) \big)\).

Plus fort : tous les éléments du plan tangent sont de cette forme.

Le plan tangent à \( G\) en un point \( x\in G\) est donc constitué des vecteurs vitesse de tous les chemins qui passent par \( x\).

Prenons maintenant \( S\), une courbe de niveau de \( G\), c'est-à-dire
\begin{equation}
	S=\{ (x,y)\in\eR^2\tq f(x,y)=C \}.
\end{equation}
Si nous prenons un chemin dans \( G\) qui est, de plus, contraint à \( S\), c'est-à-dire tel que \( \gamma(t)\in S\), alors \( \gamma'(0)\) sera tangent à \( G\) (ça, on le savait déjà), mais en plus, \( \gamma'(0)\) sera tangent à \( S\), ce qui est logique.

La morale est que si vous prenez un chemin qui se ballade dans n'importe quoi, alors la dérivée du chemin sera un vecteur tangent à ce n'importe quoi.

En outre, si \( \gamma(t)\in S\) et \( \gamma(0)=a\), alors
\begin{equation}
	\scal{\nabla f(a)}{\gamma'(0)}=0,
\end{equation}
c'est-à-dire que le vecteur tangent à la courbe de niveau est perpendiculaire au gradient. Cela est intuitivement logique parce que la tangente à la courbe de niveau correspond à la direction de \emph{moins} grande pente.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Gradient et recherche du plan tangent}
%---------------------------------------------------------------------------------------------------------------------------

Nous avons maintenant en main les concepts utiles pour trouver l'équation du plan tangent à une surface.

De la même manière que la tangente à une courbe était la droite de coefficient directeur donné par la dérivée, maintenant, le plan tangent à une surface est le plan dont les vecteurs directeurs sont les dérivées partielles :

La généralisation de l'équation \eqref{EqDiffRapTgDer} est
\begin{equation}        \label{EqDefPlanTag}
	T_a(x)=f(a)+\sum_k\frac{ \partial f }{ \partial x_k }(a)(x-a)_k
\end{equation}

Nous introduisons aussi souvent l'opérateur différentiel abstrait \defe{nabla}{nabla}, noté \( \nabla\) et qui est donné par le vecteur
\begin{equation}
	\nabla=\left( \frac{ \partial  }{ \partial x_1 },\ldots,\frac{ \partial  }{ \partial x_n } \right).
\end{equation}
Les égalités suivantes sont juste des notations, sommes toutes logiques, liées à \( \nabla\) :
\begin{equation}
	\nabla f=\left( \frac{ \partial f }{ \partial x_1 },\ldots,\frac{ \partial f }{ \partial x_n } \right),
\end{equation}
et
\begin{equation}        \label{EqDefGradient}
	\nabla f(a) = \left(\frac{\partial f}{\partial x_1}(a), \frac{\partial f}{\partial x_2}(a), \ldots, \frac{\partial f}{\partial x_n}(a)\right).
\end{equation}
Ce dernier est un élément de \( \eR^n\) : chaque entrée est un nombre réel.

\begin{definition}
	Le vecteur gradient de \( f\) au point \( a\) est le vecteur donné par la formule \eqref{EqDefGradient}.
\end{definition}
La notation \( \nabla\) permet d'écrire la différentielle sous forme un peu plus compacte. En effet, la formule \eqref{EqDiffPartRap} peut être notée
\begin{equation}
	df_a(u)=\scal{\nabla f(a)}{u}.
\end{equation}

En utilisant ce produit scalaire, l'équation \eqref{EqDefPlanTag} peut se réécrire
\begin{equation}
	T_a(x)=f(a)+\sum_i\frac{ \partial f }{ \partial x_i }(a)(x-a)^i=f(a)+\scal{\nabla f(a)}{x-a}.
\end{equation}

Afin d'éviter les confusions, il est souhaitable de bien mettre les parenthèses et noter \( (\nabla f)(a)\) au lieu de \( \nabla f(a)\).


%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Plan tangent en dimension deux}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Le plan \( T_a\) avec \( a=(a_1,a_2)\) a pour équation dans \( \eR^3\):
\begin{equation}        \label{EqPlanTgEnDimDeux}
	z = f(a_1,a_2) + \frac{\partial f}{\partial x}(a_1,a_2)\,(x-a_1)+ \frac{\partial f}{\partial y}(a_1,a_2)\,(y-a_2).
\end{equation}

\begin{definition}
	Soit \( f : \eR^n \to\eR\) une fonction différentiable en un point
	\( a\). Le \emph{plan tangent} au graphe de \( f\) en \( (a,f(a))\) est
	l'ensemble des points
	\begin{equation*}
		\begin{split}
			T_af &= \{ (x,z) \in \eR^n \times \eR \tq z = f(a) + d f_a (x-a)\}\\
			&= \{ (x,z) \in \eR^n \times \eR \tq z = f(a) + \scalprod{\nabla f(a)}{x-a}\}
		\end{split}
	\end{equation*}
\end{definition}


\begin{example}\label{EXOooMWGTooLZpgxM}\label{exo0035}

	Étudiez la continuité, la dérivabilité et la continuité de la dérivée de chacune des fonctions suivantes:
	\begin{enumerate}
		\item $x \mapsto \left\{ \begin{array}{ll} 0 & \mbox{si } x \not= 0 \\ 1 & \mbox{sinon} \end{array} \right.  $
		\item $x \mapsto \left\{ \begin{array}{ll} \sin(\frac{1}{x}) & \mbox{si } x \not= 0 \\ 0 & \mbox{sinon} \end{array} \right.  $
		\item $x \mapsto \left\{ \begin{array}{ll} x \sin(\frac{1}{x}) & \mbox{si } x \not= 0 \\ 0 & \mbox{sinon} \end{array} \right. $
		      \item\label{Item0035d} $x \mapsto \left\{ \begin{array}{ll} x^2 \sin(\frac{1}{x}) & \mbox{si } x \not= 0 \\ 0 & \mbox{sinon} \end{array} \right.  $
	\end{enumerate}

	Dans ces exercices, les fonctions données sont dérivables et à dérivée
	continue sur $\eR_0$ car pour $a \in \eR_0$, il existe toujours une
	boule autour de $a$ dans laquelle la fonction est composée de
	fonctions dérivables ($\sin$, $\frac 1x$, $\ldots$). L'intérêt de
	l'exercice est donc d'établir (ou réfuter) la continuité et la
	dérivabilité en $0$.

	\begin{enumerate}

		\item
		      Notons $f$ cette fonction. $f$ n'est pas continue en $0$ car
		      \begin{equation*}
			      \limite[x \neq 0] x 0 f(x) = \limite[x \neq 0] x 0 0 = 0 \neq f(0)
		      \end{equation*}
		      En particulier $f$ n'est pas dérivable en $0$ (et donc la continuité
		      de sa dérivée n'a pas de sens en $0$).

		\item
		      Dans ce cas-ci, la limite « restreinte »
		      \begin{equation*}
			      \limite[x \neq 0] x 0 f(x) = \limite[x \neq 0] x 0 \sin\left(\frac 1 x\right)
		      \end{equation*}
		      n'existe pas puisque, par exemple, pour la suite de terme général
		      \begin{equation*}
			      x_k = \frac 1 {\frac \pi 2 + 2k \pi}
		      \end{equation*}
		      on a bien $\limite k \infty x_k = 0$ mais
		      \begin{equation*}
			      \limite k \infty f(x_k) = 1 \neq f(0)
		      \end{equation*}
		      puisque pour tout $k \in \eN$, $f(x_k) = 1$. Donc la fonction n'est pas continue.

		\item
		      Montrons que la fonction, notée $f$, est continue en $0$. Pour tout $x$ réel, nous avons
		      \begin{equation*}
			      0 \leq \abs{f(x)} = \abs x \abs{\sin \left(\frac 1 x\right)} \leq
			      \abs x
		      \end{equation*}
		      ce qui montre que $\limite x 0 f(x) = 0$ par la règle de l'étau.

		      Par ailleurs, $f$ n'est pas dérivable en $0$ car la limite
		      \begin{equation*}
			      \limite[x \neq 0] x 0 \frac{f(x) - f(0)}{x-0} = \limite[x\neq 0] x 0 \sin\left(\frac{1}{x}\right)
		      \end{equation*}
		      n'existe pas, comme on l'a vu précédemment.

		\item
		      Montrons que cette fonction, notée $f$, est
		      dérivable en $0$ (ce qui prouvera qu'elle y est continue). Calculons
		      \begin{equation*}
			      \limite[x \neq 0] x 0 \frac{f(x)}{x} = \limite[x\neq 0] x 0 x \sin
			      \left(
			      \frac 1 x
			      \right) = 0
		      \end{equation*}
		      où la dernière égalité a été montrée à l'exercice précédent. Nous
		      avons donc $f^\prime(0) = 0$.

		      Par ailleurs, en utilisant les règles de calcul usuelles sur les
		      dérivées, nous obtenons pour $x \neq 0$
		      \begin{equation*}
			      f^\prime(x) = \sin
			      \left(
			      \frac 1 x
			      \right) - \frac 1 x \cos
			      \left(
			      \frac 1 x
			      \right)
		      \end{equation*}
		      qui est une fonction ne possédant pas de limite en $0$ puisque, par exemple,
		      si $x_k$ est tel que
		      \begin{equation*}
			      \frac 1{x_k} = \frac\pi4 + 2k\pi
		      \end{equation*}
		      alors la suite $(x_k)_{k\in\eN}$ tend vers $0$, mais $f^\prime(x_k)$ tend vers $+\infty$ lorsque $k \rightarrow +\infty$. La dérivée n'est donc pas continue en zéro.

	\end{enumerate}

\end{example}



\begin{example}     \label{EXooELTHooDdJyJE}
	Dessiner les courbes de niveaux des fonctions suivantes. Représenter ensuite leur graphe dans l'espace. Donner l'équation du plan tangent en l'origine.
	\begin{enumerate}
		\item 			$f(x,y) = \sqrt{x^2+y^2}$.
		\item 			$f(x,y) = \sqrt{1-x^2-y^2}$.
		      \item\label{Item0041}	$f(x,y) = (x^2+y^2)^2-8xy$.
	\end{enumerate}
	Les courbes de niveau de l'exercice \ref{Item0041} sont  les \emph{ovales de Cassini}; en particulier, la courbe de niveau 0 est la \emph{lemniscate de Bernouilli}.

	\begin{enumerate}
		\item
		      $f(x)=\sqrt{x^2+y^2}$. Les courbes de niveau $f(x)=C$ sont des cercles (sauf $f(x)=0$ qui se réduit à un point). Les sections horizontales étant des cercles, et le rayon de ces cercles augmentant linéairement, le graphe est une cône. Nous pouvons nous en convaincre en vérifiant par exemple que la droite $t\mapsto(t,0,t)$ est bien entièrement contenue dans $z=f(x,y)$.

		      Afin de déterminer la différentielle, nous calculons les dérivées partielles
		      \begin{equation}		\label{EqDerrPaert0041x}
			      \frac{ \partial f }{ \partial x }=\frac{1}{ 2 }(x^2+y^2)^{-1/2}\cdot 2x=\frac{ x }{ \sqrt{x^2+y^2} },
		      \end{equation}
		      et
		      \begin{equation}		\label{EqDerrPart0041y}
			      \frac{ \partial f }{ \partial y }=\frac{ y }{ \sqrt{x^2+y^2} }.
		      \end{equation}

		      Pour le plan tangent, nous essayons d'utiliser la formule  \eqref{EqPlanTgEnDimDeux}. Pour cela, nous devons trouver les dérivées partielles en zéro.

		      Il est vite vu que la formule \eqref{EqDerrPaert0041x} n'a pas de limite pour $(x,y)\to(0,0)$. Ceci \emph{ne prouve pas} que la différentielle de $f$ n'existe pas en $(0,0)$. L'existence de la différentielle implique la continuité de la fonction, et non de la différentielle elle-même. En effet, une différentielle peut exister en un point sans qu'elle soit la limite de la différentielle aux autres points. Nous avons vu par exemple, dans l'exercice \ref{exo0035}\ref{Item0035d}, un exemple de fonction dérivable\footnote{Pour rappel, en dimension un, la dérivée est \emph{exactement} la notion de différentielle.} en $0$, mais dont la dérivée n'est pas continue en zéro.

		      Il ne suffit donc pas de calculer les limites de \ref{EqDerrPaert0041x} et de \ref{EqDerrPart0041y} pour trouver la différentielle de $f$ en $(0,0)$. Il n'est par contre pas très compliqué de remarquer que les dérivées partielles n'existent pas en $(0,0)$, par exemple parce que
		      \begin{equation}
			      \lim_{t\to 0}\frac{ f(t,0)-f(0,0) }{ t }
		      \end{equation}
		      n'existe pas pour cause de limite différente pour $t>0$ et $t<0$. Il n'y a donc pas de plan tangent.  Ceci est conforme à l'intuition : il n'y a pas de plan tangent à un cône en son sommet.

		      Nous pouvons faire une petite vérification du fait que le graphe est bien un cône : la droite reliant $(0,0,0)$ à $(x,y,\sqrt{x^2+y^2})$ est entièrement contenue dans le graphe de $f$. En effet si nous posons
		      \begin{equation}
			      \gamma(t)=(tx,ty,t\sqrt{x^2+y^2}),
		      \end{equation}
		      pour tout $t$, nous avons $\gamma_z(t)=f\big( \gamma_x(t)^2+\gamma_y(t)^2 \big)$.



		\item
		      $f(x,y)=\sqrt{1-x^2-y^2}$. Les courbes de niveau $f(x,y)=C$ n'existent que pour $C\leq 1$, et ce sont des cercles
		      \begin{equation}
			      x^2+y^2=1-C.
		      \end{equation}
		      Cette fois, le graphe est une coupole de sphère. Nous allons en effet vérifier que l'arc de cercle centré en $(0,0,0)$ joignant se sommet $(0,0,1)$ à $(1,0,0)$ dans le plan $y=0$ est entièrement contenu dans le graphe de $f$. La symétrie de $f$ sous les rotations dans le plan $x-y$ fait le reste. L'arc de cercle en question est le chemin
		      \begin{equation}
			      \gamma(t)=\big( 1-t,0,\sqrt{1-(1-t)^2} \big).
		      \end{equation}
		      Chaque point de ce chemin vérifie bien la relation
		      \begin{equation}
			      f\big( \gamma_x(t),\gamma_y(t) \big)=\gamma_z(t).
		      \end{equation}

		      Le plan tangent à la coupole de sphère en $(0,0,1)$ est évidemment horizontal. Nous nous attendons donc à trouver que la différentielle de $f$ en $(0,0)$ est nulle. Simple calcul :
		      \begin{equation}
			      \frac{ \partial f }{ \partial x }(x,y)=\frac{ 1 }{2}\frac{ -2x }{ \sqrt{1-x^2-y^2} },
		      \end{equation}
		      et
		      \begin{equation}
			      \frac{ \partial f }{ \partial y }(x,y)=\frac{ 1 }{2}\frac{ -2y }{ \sqrt{1-x^2-y^2} }.
		      \end{equation}
		      Évaluées en $(0,0)$, ce deux dérivées partielles sont nulles. Donc \emph{si la différentielle existe} en $(0,0)$, elle sera nulle (voir l'expression \eqref{EqDiffPartRap}). Afin de voir qu'elle existe, il faut juste montrer que $df_{(0,0)}(x,y)=0$ fonctionne dans la définition \ref{DefDifferentiellePta}.

		\item
		      $f(x,y)=(x^2+y^2)^2-8xy$. La courbe de niveau zéro, en coordonnées polaires est donnée par
		      \begin{equation}
			      r=2\sqrt{\sin(2\theta)}.
		      \end{equation}
		      Les dérivées partielles sont données par
		      \begin{equation}
			      \begin{aligned}[]
				      \frac{ \partial f }{ \partial x }(x,y) & =4(x^2+y^2)x-8y \\
				      \frac{ \partial f }{ \partial y }(x,y) & =4(x^2+y^2)y-8x
			      \end{aligned}
		      \end{equation}

	\end{enumerate}
\end{example}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Plan tangent en dimension trois}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Nous avons vu que, de la même façon qu'en deux dimensions nous avions l'approximation \eqref{Eqfxsimesfa} d'une fonction par sa tangente, en trois dimensions nous avons l'approximation suivante d'une fonction de deux variables :
\begin{equation}
	f(x,y)\simeq f(a,b)+\frac{ \partial f }{ \partial x }(a,b)(x-a)+\frac{ \partial f }{ \partial y }(a,b)(y-b)
\end{equation}
lorsque \( (x,y)\) n'est pas trop loin de \( (a,b)\). Cela signifie que le graphe de \( f\) ressemble au graphe de la fonction \( T_{(a,b)}\) donnée par
\begin{equation}
	T_{(a,b)}(x,y)=f(a,b)+\frac{ \partial f }{ \partial x }(a,b)(x-a)+\frac{ \partial f }{ \partial y }(a,b)(x-a).
\end{equation}
En notations compactes :
\begin{equation}
	T_p(x)=f(p)+\nabla f(p)\cdot (x-p).
\end{equation}
Le graphe de la fonction \( T_p\) sera le \defe{plan tangent}{plan!tangent} au graphe de \( f\) au point \( p\). L'équation du plan tangent sera donc
\begin{equation}
	z-f(p)=\nabla f(p)\cdot (x-p).
\end{equation}

\begin{remark}
	Lorsque nous utilisons la notation vectorielle, la lettre «\( x\)» désigne le vecteur \( (x,y)\). Il faut être attentif. Dans un cas \( x\) est un vecteur dans l'autre c'est une composante d'un vecteur.
\end{remark}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Jacobienne}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\subsection{Rappels et définitions}

Dans cette section nous considérons des fonctions \( f : D \to \eR^m\)
où \( D \subset \eR^n\), et un point \( a \in \Int D\) où \( f\) est
différentiable.
\begin{remark}
	La définition de continuité (resp. différentiabilité) pour une
	fonction à valeurs vectorielles est celle introduite précédemment,
	et on remarque que pour avoir la continuité
	(resp. différentiabilité) de \( f\) en un point, il faut et il suffit
	que chacunes des composantes de \( f = (f_1,\ldots, f_m)\), vues
	séparément comme fonctions à \( n\) variables et à valeurs réelles,
	soient continues (resp. différentiables) en ce point.
\end{remark}

\begin{definition}
	La \defe{jacobienne}{matrice!jacobienne} de \( f\) en \( a\) est la matrice de l'application linéaire donnée par la différentielle. Elle a de nombreuses notations
	\begin{equation}
		J_f(a) = \frac{ \partial (f_1,\ldots, f_m) }{ \partial x_1,\ldots, x_m }=
		\begin{pmatrix}
			\pder {f_1} {x_1}(a) & \ldots & \pder {f_1} {x_n}(a) \\
			\vdots               &        & \vdots               \\
			\pder {f_m} {x_1}(a) & \ldots & \pder {f_m} {x_n}(a)
		\end{pmatrix}
	\end{equation}
	Autrement dit, c'est la matrice composée de l'ensemble des dérivées partielles de \( f\). Le \defe{jacobien}{jacobien} de \( f\) au point \( a\) est le déterminant de cette matrice.

	Si \( m = 1\), cette matrice ne contient qu'une ligne ; c'est donc un vecteur appelé le \defe{gradient}{gradient} de \( f\) au point \( a\) et noté \( \nabla f(a)\).
\end{definition}

\begin{remark}
	\begin{enumerate}
		\item Si la fonction est supposée différentiable, calculer la
		      jacobienne revient à connaitre la différentielle. En effet, par
		      linéarité de la différentielle et par définition des dérivées
		      partielles, nous avons
		      \begin{equation*}
			      d f_a (u) =%
			      \begin{pmatrix}
				      \pder {f_1} {x_1}(a) & \ldots & \pder {f_1} {x_n}(a) \\
				      \vdots               &        & \vdots               \\
				      \pder {f_m} {x_1}(a) & \ldots & \pder {f_m} {x_n}(a)
			      \end{pmatrix}
			      \begin{pmatrix}u_1\\\vdots\\u_n\end{pmatrix}
		      \end{equation*}
		      où \( u = (u_1, \ldots, u_n)\) et où le membre de droite est un
		      produit matriciel

		\item Remarquons que la jacobienne peut exister en un point donné
		      sans que la fonction soit différentiable en ce point !
	\end{enumerate}
\end{remark}


\begin{normaltext}      \label{NORMooKBJVooDDDmOa}
	Le théorème de différentiation de fonctions composées \ref{PropDiffCompose} peut également se lire au niveau des matrices jacobiennes. La matrice jacobienne de \( g\circ f\) au point \( a\) est le produit matriciel des matrices jacobiennes de \( g\) et de \( f\). Plus précisément, nous avons
	\begin{equation}
		J_{g\circ f}(a)=J_g\big( f(a) \big)J_f(a).
	\end{equation}
	Remarquez que nous considérons la matrice jacobienne de \( g\) au point \( f(a)\).

	Dans le cas particulier où \( m=1\) et \( f\) est une fonction d'un intervalle \( I\) dans \( \eR^n\), dérivable au point \( a\), on trouve que la fonction composée \( g\circ f\) est dérivable au point \( a\) si \( g\) est différentiable, et alors
	\[
		(g\circ f)'(a)= dg\left(f(a)\right).f'(a).
	\]
	En fait, pour les fonctions d'une seule variable la dérivabilité coïncide avec la différentiabilité.
\end{normaltext}
