% This is part of Mes notes de mathématique
% Copyright (c) 2008-2021
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Intervalles}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{definition}[Intervalle]
    Une partie \( I\) de \( \eR\) est un \defe{intervalle}{intervalle} si pour tout \( a,b\in I\) nous avons \( t\in I\) dès que \( a\leq t\leq b\).

    Un intervalle est \defe{ouvert}{intervalle!ouvert} s'il est de la forme \( \mathopen] a , b \mathclose[\) avec éventuellement \( a=-\infty\) ou \( b=+\infty\). Un intervalle est \defe{fermé}{intervalle!fermé} s'il est de la forme \( \mathopen[ a , b \mathclose]\) ou \( \mathopen] -\infty , b \mathclose]\) ou \( \mathopen[ a , +\infty [\) avec \( a,b\in \eR\).
\end{definition}

\begin{remark}
  L'ensemble $\eR$ ne contient pas $-\infty$ et $-\infty$. L'intervalle $[-\infty, 5]$ par exemple, n'est pas une partie de $\eR$.
\end{remark}

\begin{example}
    \begin{enumerate}
        \item
        Les ensembles \( \mathopen] 3 , 7 \mathclose[\) et \( \mathopen] -\infty , \pi \mathclose[\) sont des intervalles ouverts.
        \item
            Les ensembles \( \mathopen[ 10 , 15 \mathclose]\) et \( \mathopen[ -1 , +\infty [\) sont des intervalles fermés.
        \item
        L'ensemble \( \mathopen] -4 , -2 \mathclose[\cup\mathopen] 2 , 9 \mathclose[\) n'est pas un intervalle (il y a un «trou» entre \(- 2\) et \( 2\)).
        \item
            L'ensemble \( \eR\) lui-même est un intervalle; par convention, il est à la fois ouvert et fermé.
    \end{enumerate}
Un intervalle peut n'être ni ouvert ni fermé; par exemple \( \mathopen] 4 , 8 \mathclose]\). Cet intervalle est «ouvert en \( 4\) et fermé en \( 8\)» .
\end{example}

\begin{definition}[Fonction, domaine, image, graphe]
  Soient $X$ et $Y$ deux ensembles. Une \defe{fonction}{fonction} $f$ définie sur $X$ et à valeurs dans $Y$ est une correspondence qui associe à chaque élément $x$ dans $X$ {\bf au plus} un élément $y$ dans $Y$. On écrit $y= f(x)$.
  \begin{itemize}
  \item La partie de $X$ qui contient tous les $x$ sur lesquels $f$ peut opérer est dite \defe{domaine}{domaine} de $f$. Le domaine de $f$ est indiqué par $\Dom f$.
  \item L'élément de $y\in Y$ associé par $f$ à un élément $x\in \Dom f$ (c'est-à-dire $f(x) = y$)  est appellé \defe{image}{image} de $x$ par $f$. L'\defe{image}{fonction!image} de la fonction $f$ est la partie de $Y$ qui contient les images de tous les éléments de $\Dom f$. L'image de $f$ est indiquée par $\Im f$.
  \item Le \defe{graphe}{graphe} de $f$ est l'ensemble de toutes les couples $(x, f(x))$ pour $x\in \Dom f$. Le graphe de $f$ est une partie de l'ensemble noté $X\times Y$ et il est indiqué par $\Graph f$. Dans ce cours $X = \eR$ et $Y = \eR$, donc le graphe de $f$ est contenu dans le plan cartésien.
  \end{itemize}
\end{definition}

\begin{definition}[Fonction croissante, décroissante et monotone]
    Soit \( f\colon \eR\to \eR\) une fonction définie sur un intervalle \( I\subset \eR\).
    \begin{enumerate}
        \item
            Le fonction \( f\) est \defe{croissante}{fonction!croissante} sur \( I\) si pour tout \( x<y\) dans \( I\) nous avons \( f(x)\leq f(y)\). Elle est \emph{strictement} croissante si \( f(x)<f(y)\) dès que \( x<y\).
        \item
            Le fonction \( f\) est \defe{décroissante}{fonction!décroissante} sur \( I\) si pour tout \( x<y\) dans \( I\) nous avons \( f(x)\geq f(y)\). Elle est \emph{strictement} décroissante si \( f(x)>f(y)\) dès que \( x<y\).
        \item
            La fonction \( f\) est dite \defe{monotone}{fonction!monotone} sur \( I\) si elle est soit croissante soit décroissante sur \( I\).
    \end{enumerate}
\end{definition}

\begin{example}
    La fonction \( x\mapsto x^2\) est décroissante sur l'intervalle \( \mathopen] -\infty , 0 \mathclose]\) et croissante sur l'intervalle \( \mathopen[ 0 , \infty \mathclose[\). Elle n'est par contre ni croissante ni décroissante sur l'intervalle \( \mathopen[ -4 , 3 \mathclose]\).
\end{example}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Application réciproque}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Définitions}
%---------------------------------------------------------------------------------------------------------------------------

Les définitions d'injection, surjection, bijection et d'application réciproque sont les définitions~\ref{DEFooBFCQooPyKvRK} et~\ref{DEFooTRGYooRxORpY}.

\begin{example}     \label{EXooCWYHooLEciVj}
    \begin{enumerate}
        \item
            La fonction \( x\mapsto x^2\) n'est pas une bijection de \( \eR\) vers \( \eR\) parce qu'il n'existe aucun \( x\) tel que \( x^2=-1\).
        \item
            La fonction
            \begin{equation}
                \begin{aligned}
                    f\colon \mathopen[ 0 , +\infty [&\to \mathopen[ 0 , +\infty [ \\
                    x&\mapsto x^2
                \end{aligned}
            \end{equation}
            est une bijection. Notez que c'est la même fonction que celle de l'exemple précédent. Seul l'intervalle sur laquelle nous nous plaçons a changé.
        \item
            La fonction
            \begin{equation}
                \begin{aligned}
                    f\colon \eR&\to \mathopen[ 0 , \infty \mathclose[ \\
                    x&\mapsto x^2
                \end{aligned}
            \end{equation}
            n'est pas une bijections parce qu'il existe plusieurs \( x\) pour lesquels \( f(x)=4\).
        \item
            Nous verrons un peu plus tard (\ref{PROPooXQYFooPxoEHE}) que l'application
            \begin{equation}
                \begin{aligned}
                    f\colon \mathopen[ 0 , \infty \mathclose[\to \mathopen[ 0 , \infty \mathclose[\\
                    x&\mapsto x^2
                \end{aligned}
            \end{equation}
            est une bijection.
    \end{enumerate}
    En conclusion : il est très important de préciser les domaines des fonctions considérées.
\end{example}

\begin{remark}
    Dire que la fonction \( f\colon I\to J\) est bijective, c'est dire que l'équation \( f(x)=y\) d'inconnue \( x\) peut être résolue de façon univoque pour tout \( y\in J\).
\end{remark}

\begin{remark}
  Toute fonction strictement monotone sur un intervalle $I$ est injective.
\end{remark}

\begin{example}
    Trouvons la fonction réciproque de la fonction affine \( f\colon \eR\to \eR\), \( x\mapsto 3x-2\). Si \( y\in \eR\) le nombre \( f^{-1}(y)\) est la valeur de \( x\) pour laquelle \( f(x)=y\). Il s'agit donc de résoudre
    \begin{equation}
        3x-2=y
    \end{equation}
    par rapport à \( x\). La solution est \( x=\frac{ y+2 }{ 3 }\) et donc nous écrivons
    \begin{equation}
        f^{-1}(y)=\frac{ y+2 }{ 3 }.
    \end{equation}
    Notons que dans les calculs, il est plus simple d'écrire «\( y\)» que «\( x\)» la variable de la fonction réciproque. Il est néanmoins (très) recommandé de nommer «\( x\)» la variable dans la réponse finale. Dans notre cas nous concluons donc
    \begin{equation}
        f^{-1}(x)=\frac{ x+2 }{ 3 }.
    \end{equation}
\end{example}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Graphe de la fonction réciproque}
%---------------------------------------------------------------------------------------------------------------------------

Par définition le graphe de la fonction \( f\) est l'ensemble des points de la forme \( (x,y)\) vérifiant \( y=f(x)\). Afin de déterminer le graphe de la bijection réciproque nous pouvons faire le raisonnement suivant.

        Le point \( (x_0,y_0)\) est sur le graphe de \( f\)

\noindent\( \Leftrightarrow\)

        La relation \( f(x_0)=y_0\) est vérifiée

\noindent\( \Leftrightarrow\)

        La relation \( x_0=f^{-1}(y_0)\) est vérifiée

\noindent\( \Leftrightarrow\)

        Le point \( (y_0,x_0)\) est sur le graphe de \( f^{-1}\).

\begin{Aretenir}
    Dans un repère orthonormal, le graphe de la bijection réciproque est obtenu à partir du graphe de \( f\) en effectuant une symétrie par rapport à la droite d'équation \( y=x\).
\end{Aretenir}

Le dessin suivant montre le cas de la courbe de la fonction carré comparé à celle de la racine carrée.
\begin{center}
   \input{auto/pictures_tex/Fig_CELooGVvzMc.pstricks}
\end{center}


%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Topologie sur l'ensemble des réels}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\label{SECooGKHYooMwHQaD}

Nous allons à présent donner la topologie sur \( \eR\) et ainsi résoudre les questions laissées en suspens lors de la construction des réels, voir~\ref{NormooHRDZooRGGtCd}.


Afin de pouvoir étudier la topologie des espaces métriques, il faut savoir quelques propriétés des réels parce que nous allons étudier la fonction distance qui est une fonction continue à valeurs dans les réels.

La valeur absolue de la définition~\ref{DefKCGBooLRNdJf}\ref{ItemooWUGSooRSRvYC} permet de définir une norme sur \( \eR\).
\begin{lemma}       \label{LEMooBNAPooBTtXnX}
    L'application
    \begin{equation}
         x\mapsto | x |
    \end{equation}
    est une norme\footnote{Définition \ref{DefNorme}.} sur $\eR$.
\end{lemma}

\begin{proof}
  Grâce au lemme \ref{LemooANTJooYxQZDw} et à la remarque \ref{RemooJCAUooKkuglX}, on a, pour tous \(x,\ y,\ \lambda \in \eR \):
\begin{enumerate}
\item $| x |=0$ implique $x=0$,
\item $| \lambda x |=| \lambda | |x |$,
\item $| x+y |\leq | x |+| y |$,
\end{enumerate}
et donc, les conditions de la définition \ref{DefNorme} sont immédiatement vérifiées.
\end{proof}

\begin{definition}[Topologie sur \( \eR\) et sur \( \eQ\)]      \label{DEFooNYGIooVGHSIA}
    Le lemme \ref{LEMooBNAPooBTtXnX} donne une norme sur \( \eR\) et \( \eQ\) à partir de la valeur absolue. La définition \ref{ThoORdLYUu} donne alors une structure d'espace topologique. Hors cas rarissimes qui seront signalés, nous utiliserons toujours cette topologie sur \( \eR\) et sur \( \eQ\).

\end{definition}

\begin{proposition}     \label{PropooUHNZooOUYIkn}
    Les rationnels sont denses dans les réels\footnote{Pour les topologies usuelles données en la définition \ref{DEFooNYGIooVGHSIA}.}.
\end{proposition}
\index{densité!de \( \eQ\) dans \( \eR\)}

\begin{proof}
    Soient \( r\in \eR\) et \( \epsilon\in \eR^+\). Nous devons prouver l'existence d'un rationnel dans \( B(x,\epsilon)\). Le lemme~\ref{LemooHLHTooTyCZYL} dit qu'il existe un rationnel dans \( \mathopen] x-\epsilon/2 , x+\epsilon/2 \mathclose[\) et donc dans \( B(x,\epsilon)\).
\end{proof}

\begin{proposition}[\cite{MonCerveau}] \label{PropSLCUooUFgiSR}
    Quel que soit le réel \( r\), il existe une suite croissante de rationnels convergente vers \( r\).
\end{proposition}

\begin{proof}
    Soient \( x\in \eR\) et \( \delta\in \eR\); vu que \( x-\delta\) et \( x\) sont des réels, le lemme~\ref{LemooHLHTooTyCZYL} donne un élément \( x_{\delta}\in \eQ \) tel que
    \begin{equation}
        x-\delta<x_{\delta}<x.
    \end{equation}
    Il suffit alors de pêcher parmi ces \( x_{\delta}\) pour trouver une suite croissante, et on montrera que cette suite converge vers \( x \).

    Soit \( x_0\) un rationnel plus petit que \( x\). Nous posons \( \delta_0=x-x_0\) et ensuite :
    \begin{subequations}
        \begin{numcases}{}
            \delta_i=x-x_i\\
            x_{i+1}=x_{\delta_i/2} \in \eQ.
        \end{numcases}
    \end{subequations}
    Ainsi nous avons pour tout \( i\) les inégalités
    \begin{equation}
        x_i=x-\delta_i<x-\frac{ \delta_i }{ 2 }<x_{i+1}<x.
    \end{equation}
    La suite \( (x_i) \) est donc une suite de rationnels, croissante et toujours plus petite que \( x\). Mais nous avons à chaque étape \( \delta_{i+1}<\frac{ \delta_i }{ 2 }\), ce qui implique que la suite des  \( \delta_i \) converge vers \( 0 \). Soit \( \epsilon>0\). Il existe \( k_0\) tel que pour tout \( k > k_0 \), \( \delta_k<\epsilon\). Pour un tel \( k \), nous avons alors
    \begin{equation}
        x_{k+1}\in B(x,\frac{ \delta_k }{ 2 })\subset B(x,\epsilon).
    \end{equation}
Tous les \( x_k \), pour \( k > k_0 + 1 \), sont tels que \( |x - x_k| < \epsilon \): la suite des \( x_k \) converge donc vers \( x \).
\end{proof}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Compacité pour les réels}
%---------------------------------------------------------------------------------------------------------------------------

Pour la définition générale d'un compact, c'est \ref{DefJJVsEqs}.

\begin{proposition}     \label{PROPooBFSAooKSugMj}
    Les parties compactes de \( \eR\) sont fermées et bornées.
\end{proposition}

\begin{proof}
Prouvons d'abord qu'un ensemble compact est borné. Pour cela, supposons que $K$ est un compact non borné vers le haut\footnote{Nous laissons à titre d'exercice le cas où $K$ est borné par le haut et pas par le bas.}. Donc il existe une suite infinie de nombres strictement croissante $x_1<x_2<\ldots$ tels que $x_i\in K$. Prenons n'importe quel recouvrement ouvert de la partie de $K$ plus petite ou égale à $x_1$, et complétons ce recouvrement par les ouverts $\mO_i=]x_{i-1},x_i[$. Le tout forme bien un recouvrement de $K$ par des ouverts.

Il n'y a cependant pas moyen d'en tirer un sous recouvrement fini parce que si on ne prend qu'un nombre fini parmi les $\mO_i$, on en aura fatalement un maximum, disons $\mO_k$. Dans ce cas, les points $x_{k+1}$, $x_{k+1}$,\ldots ne seront pas dans le choix fini d'ouverts.

Cela prouve que $K$ doit être borné.

Pour prouver que $K$ est fermé, nous allons prouver que le complémentaire est ouvert. Et pour cela, nous allons prouver que si le complémentaire n'est pas ouvert, alors nous pouvons construire un recouvrement de $K$ dont on ne peut pas extraire de sous recouvrement fini.

Si $\eR\setminus K$ n'est pas ouvert, il possède un point, disons $x$, tel que tout voisinage de $x$ intersecte $K$. Soit $B(x,\epsilon_1)$, un de ces voisinages, et prenons $k_1\in K\cap B(x,\epsilon_1)$. Ensuite, nous prenons $\epsilon_2$ tel que $k_1$ n'est pas dans $B(x,\epsilon_1)$, et nous choisissons $k_2\in K\cap B(x,\epsilon_2)$. De cette manière, nous construisons une suite de $k_i\in K$ tous différents et de plus en plus proches de $x$. Prenons un recouvrement quelconque par des ouverts de la partie de $K$ qui n'est pas dans $B(x,\epsilon_1)$. Les nombres $k_i$ ne sont pas dans ce recouvrement.

Nous ajoutons à ce recouvrement les ensembles $\mO=]k_i,k_{i+1}[$. Le tout forme un recouvrement (infini) par des ouverts dont il n'y a pas moyen de tirer un sous recouvrement fini, pour exactement la même raison que la première fois.
\end{proof}

\begin{theorem}[Borel-Lebesgue]   \label{ThoBOrelLebesgue}
    Un intervalle de \( \eR\) est compact si et seulement si il est de la forme \( \mathopen[ a , b \mathclose]\).
\end{theorem}

\begin{proof}
    Tous les intervalles de \( \eR\) sont listés dans la proposition \ref{PROPooHPMWooQJXCAS}. Un compact est fermé et borné (proposition \ref{PROPooBFSAooKSugMj}). Donc les intervalles dont une borne est \( \pm\infty\) ne sont pas compacts. Parmi les intervalles \( \mathopen] a , b \mathclose[\), \( \mathopen] a , b \mathclose]\), \( \mathopen[ a , b \mathclose[\) et \( \mathopen[ a , b \mathclose]\), seul le dernier est fermé. Nous avons prouvé que si un intervalle est compact, alors il est de la forme \( \mathopen[ a , b \mathclose]\). 

    Nous prouvons à présent l'implication inverse : tous les intervalles de la forme \( \mathopen[ a , b \mathclose]\) sont compacts.

    Soit $\Omega$, un recouvrement du segment $[a,b]$ par des ouverts, c'est-à-dire que
    \begin{equation}
        [a,b]\subseteq\bigcup_{\mO\in\Omega}\mO.
    \end{equation}
    Nous notons par $M$ le sous-ensemble de $[a,b]$ des points $m$ tels que l'intervalle $[a,m]$ peut être recouvert par un sous-ensemble fini de $\Omega$. C'est-à-dire que $M$ est le sous-ensemble de $[a,b]$ sur lequel le théorème est vrai. Le but est maintenant de prouver que $M=[a,b]$.
    \begin{description}
        \item[$M$ est non vide] En effet, $a\in M$ parce que il existe un ouvert $\mO\in\Omega$ tel que $a\in\mO$. Donc $\mO$ tout seul recouvre l'intervalle $[a,a]$.
        \item[$M$ est un intervalle] Soient $m_1$, $m_2\in M$. Le but est de montrer que si $m'\in[m_1,m_2]$, alors $m'\in M$. Il y a un sous recouvrement fini de l'intervalle $[a,m_2]$ (par définition de $m_2\in M$). Ce sous recouvrement fini recouvre évidemment aussi $[a,m']$ parce que $[a,m']\subseteq [a,m_2]$, donc $m'\in M$.
        \item[$M$ est une ensemble ouvert] Soit $m\in M$. Le but est de prouver qu'il y a un ouvert autour de $m$ qui est contenu dans $M$. Mettons que $\Omega'$ soit un sous recouvrement fini qui contienne l'intervalle $[a,m]$. Dans ce cas, on a un ouvert $\mO\in\Omega'$ tel que $m\in\mO$. Tous les points de $\mO$ sont dans $M$, vu qu'ils sont tous recouverts par $\Omega'$. Donc $\mO$ est un voisinage de $m$ contenu dans $M$.
        \item[$M$ est un ensemble fermé] $M$ est un intervalle qui commence en $a$, en contenant $a$, et qui finit on ne sait pas encore où. Il est donc soit de la forme $[a,m]$, soit de la forme $[a,m[$. Nous allons montrer que $M$ est de la première forme en démontrant que $M$ contient son supremum $s$. Ce supremum est un élément de $[a,b]$, et donc il est contenu dans un des ouverts de $\Omega$. Disons $s\in\mO_s$. Soit $c$, un élément de $\mO_s$ strictement plus petit que $c$; étant donné que $s$ est supremum de $M$, cet élément $c$ est dans $M$, et donc on a un sous recouvrement fini $\Omega'$ qui recouvre $[a,c]$. Maintenant, le sous recouvrement constitué de $\Omega'$ et de $\mO_s$ est fini et recouvre $[a,s]$.
    \end{description}
    Nous pouvons maintenant conclure : le seul intervalle non vide de $[a,b]$ qui soit à la fois ouvert et fermé est $[a,b]$ lui-même (proposition \ref{PropHSjJcIr}), ce qui prouve que $M=[a,b]$, 
    et donc que $[a,b]$ est compact\footnote{Si vous n'aimez pas le coup du fermé et ouvert, le lemme \ref{LemOACGWxV} donne une autre preuve.}.
\end{proof}


\begin{lemma}[\cite{JUwQXOF}]\label{LemOACGWxV}
    Si \( a<b\in \eR\) alors le segment \( \mathopen[ a , b \mathclose]\) est compact\footnote{Définition~\ref{DefJJVsEqs}}.
\end{lemma}
\index{compact!intervalle \( \mathopen[ a , b \mathclose]\)}

\begin{proof}
    Soit \( \{ \mO_i \}_{i\in I}\) un recouvrement de \( \mathopen[ a , b \mathclose]\) par des ouverts. Nous posons
    \begin{equation}
        M=\{ x\in\mathopen[ a , b \mathclose]\tq \mathopen[ a , x \mathclose] \text{ admet un sous-recouvrement fini extrait de } \{ \mO_i \}_{i\in I} \}.
    \end{equation}
    Notre but est de prouver que \( b\in M\).
    \begin{subproof}

    \item[\( a\) est dans \( M\)]

        Le point \( a\) est naturellement dans un des \( \mO_i\). L'intervalle \( \mathopen[ a , a \mathclose]\) est donc recouvert par un seul des \( \mO_i\).

    \item[\( M\) est un intervalle]

        Soient \( m\in M\) et \( m'\in\mathopen[ a , m [\). Le sous-recouvrement fini qui recouvre \( \mathopen[ a , m \mathclose]\) recouvre a fortiori \( \mathopen[ a , m' \mathclose]\).

    \item[Les trois possibilités restantes]
        À ce niveau de la preuve, il reste trois possibilités pour \( M\) soit il est de la forme \( \mathopen[ a , c \mathclose]\) ou \( \mathopen[ a , c [\) avec \( c<b\), soit il est de la forme \( \mathopen[ a , b \mathclose]\). Nous allons maintenant éliminer les deux premiers cas.

    \item[Ce que \( M\) n'est pas]

        D'abord \( M\) n'est pas de la forme \( \mathopen[ a , c [\) avec \( c<b\). Par l'absurde, commençons par considérer \( \mO_{i_0}\) un ouvert du recouvrement qui contient \( c\); choisissons  \(m \in \mO_{i_0}\) tel que \( m<c\). Alors \( m \in M \), et, si nous joignons \( \mO_{i_0}\) à un recouvrement fini de \( \mathopen[ a , m \mathclose]\) alors nous avons un recouvrement fini de \( \mathopen[ a , c \mathclose]\). On en déduit \( c\in M\).

        Ensuite \( M\) n'est pas de la forme \( \mathopen[ a , c \mathclose]\) avec \( c<b\). En effet si on a un recouvrement fini de \( \mathopen[ a , c \mathclose]\) par des ouverts, alors un de ces ouverts contient \( c\) et donc contient des éléments de \( \mathopen[ a , b \mathclose]\) plus grands que \( c\).
    \end{subproof}
    Nous déduisons que \( M=\mathopen[ a , b \mathclose]\) et qu'il est possible d'extraire un sous-recouvrement fini recouvrant \( \mathopen[ a , b \mathclose]\).
\end{proof}

\begin{lemma}[\cite{MonCerveau}]\label{LemCKBooXkwkte}
    Si \( K_1\) et \( K_2\) sont des compacts dans \( \eR\) alors \( K_1\times K_2\) est compact dans \( \eR^2\).
\end{lemma}

\begin{proof}
    Soit \( \{ \mO_i \}_{i\in I}\) un recouvrement de \( K_1\times K_2\) par des ouverts; grâce au lemme~\ref{LemOWVooZKndbI} nous pouvons supposer que ce sont des carrés. Pour chaque \( x\in K_1\), l'ensemble \( \{ x \}\times K_2\) est compact et donc recouvert par un nombre fini des \( \mO_i\). Soit \( R_x\) un ensemble fini des \( \mO_i\) recouvrant \( \{ x \}\times K_2\).

    Vu que \( R_x\) est une collection finie de carrés nous pouvons considérer \( m_x\), le minimum des rayons. L'ensemble \( K_1\) est recouvert par les boules \( B(x,m_x)\) et il existe donc une collection finie de \( \{ x_i \}_{i\in A}\) tels que \( B(x_i,m_{x_i})\) recouvre \( K_1\).

    Alors \( \{ R_{x_i} \}_{i\in A}\) recouvre \( K_1\times K_2\) parce que \( R_{x_i}\) recouvre l'ensemble \( B(x_i,m_{x_i})\times \{ K_2 \}\).
\end{proof}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Conséquence: les fermés bornés sont compacts}
%---------------------------------------------------------------------------------------------------------------------------

\begin{theorem}[Théorème de Borel-Lebesgue] \label{ThoXTEooxFmdI}
    Une partie d'un espace vectoriel normé réel de dimension finie est compacte si et seulement si elle est fermée et bornée.
\end{theorem}
\index{théorème!Borel-Lebesgue}
\index{compact!fermé et borné}

\begin{proof}
    Sens direct.
    \begin{subproof}
    \item[Compact implique borné]
        En effet si \( K\) est non borné dans \( E\) alors \( K\) contient une suite \( (x_n)\) avec \( \| x_n \|>n\). Les boules \( B_i(x_i,\frac{ 1 }{3})\) sont disjointes. On pose \( \mO_0=\complement\bigcup_i\overline{ B(x_i,\frac{1}{ 5 }) }\), qui est ouvert comme complément d'un fermé. Pour \( i\geq 1\) nous posons \( \mO_i=B(x_i,\frac{1}{ 4 })\). Nous avons
        \begin{equation}
            K\subset\bigcup_{i\in \eN}\mO_i
        \end{equation}
        mais vu que \( x_i\) est uniquement dans \( \mO_i\), nous ne pouvons pas extraire de sous-recouvrement fini.
    \item[Compact implique fermé]
        Cela est la proposition~\ref{PropUCUknHx}.
    \end{subproof}
    Sens réciproque.
    \begin{subproof}
    \item[Un intervalle fermé et borné est compact dans \( \eR\)]
        C'est le lemme~\ref{LemOACGWxV}.
    \item[Un produit de segments est compact]
        Le produit de deux compacts de \( \eR\) est un compact dans \( \eR^2\) par le lemme~\ref{LemCKBooXkwkte}.
    \item[Un fermé et borné est compact]
        Soit \( K\) fermé et borné. Vu que \( K\) est borné, il est contenu dans un produit de segments. L'ensemble \( K\) est donc compact parce que fermé dans un compact, lemme~\ref{LemnAeACf}.
    \end{subproof}
\end{proof}

\begin{example}[Compacité de la boule unité]
    La boule unité fermée \( \overline{ B(0,1) }\) d'un espace vectoriel normé de dimension finie est compacte parce que fermée et bornée. En dimension infinie, cela n'est plus le cas. Certes la boule unité est encore fermée et bornée, mais elle n'est plus compacte. En effet nous allons donner un recouvrement par des ouverts duquel il ne sera pas possible d'extraire un sous-recouvrement fini.

    Autour de chacune des extrémités des vecteurs de base, nous considérons la boule \( A_i=B(e_i,\frac{1}{ 3 })\). Ensuite aussi l'ouvert
    \begin{equation}
        B(0,1)\setminus\bigcup_i\overline{ B(e_i,\frac{1}{ 4 })}.
    \end{equation}
    Le tout recouvre \( B(0,1)\) mais toutes les premières boules sont nécessaires.
\end{example}
\index{compact!boule unité}

Le théorème de Bolzano-Weierstrass \ref{THOooRDYOooJHLfGq} nous permettra de prouver plus simplement la non compacité en dimension infinie. Voir l'exemple~\ref{ExEFYooTILPDk}.


%---------------------------------------------------------------------------------------------------------------------------
\subsection{Suites et limites dans les réels}
%---------------------------------------------------------------------------------------------------------------------------

\subsubsection{Limites, convergence}
%////////////////////////////////

Dans le cas de suites réelles, nous avons la caractérisation suivante qui est souvent donnée comme une définition lorsque seule la topologie sur \( \eR\) est considérée.
\begin{proposition}[Limite d'une suite numérique]	\label{PropLimiteSuiteNum}
	La suite $(x_n)$ est convergente si et seulement s'il existe un réel $\ell$ tel que
	\begin{equation}		\label{EqDefLimSuite}
		\forall \epsilon>0,\,\exists N\in\eN\tq\forall n\geq N,\,| x_n-\ell |<\epsilon.
	\end{equation}
	Dans ce cas, le nombre $\ell$ est la limite de la suite $(x_n)$.
\end{proposition}
\index{convergence!suite numérique}
\index{limite!suite numérique}

\begin{propositionDef}		\label{PROPooOSXCooJWXkWH}
    Une suite $(x_n)$ dans un espace vectoriel normé $V$ est convergente\footnote{Définition \ref{DefXSnbhZX}.} si et seulement si il existe un élément $\ell\in V$ tel que
	\begin{equation}
		\forall \varepsilon>0,\,\exists N\in\eN\tq n\geq N\Rightarrow \| x_n-l \|<\varepsilon.
	\end{equation}
	Dans ce cas, $\ell$ est la limite de la suite $(x_n)$.
\end{propositionDef}
    \index{convergence!dans un espace vectoriel normé}

\begin{proof}
    En deux parties.
    \begin{subproof}
        \item[Sens direct]
            Si \( x_n\to \ell\) et si \( \epsilon>0\) il existe \( N_{\epsilon}\) tel que pour tout \( n\geq N\) nous avons \( x_n\in B(\ell,\epsilon)\) (parce que cette boule est un ouvert contenant \( \ell\)). Vue la définition d'une boule, cette condition s'écrit bien \( \| x_n-\ell \|<\epsilon\).

        \item[Sens inverse]

            Dans l'autre sens, soit \( \mO\) un ouvert contenant \( \ell\). Par définition de la topologie, il existe \( \epsilon>0\) tel que \( B(\ell,\epsilon)\subset \mO\). La condition \eqref{EqDefLimSuite} nous assure qu'il existe \( N_{\epsilon} \) tel que pour tout \( n\geq N_{\epsilon}\) nous ayons
            \begin{equation}
             x_n\in B(\ell,\epsilon)\subset\mO,
             \end{equation}
            ce qui assure que la suite \( (x_n)\) converge vers \( \ell\) pour la topologie métrique de \( V\).
    \end{subproof}
\end{proof}

Une façon équivalente d'exprimer le critère \eqref{EqDefLimSuite} est de dire que pour tout $\epsilon$ positif, il existe un rang $N\in\eR$ tel que l'intervalle $\mathopen[ \ell-\epsilon , \ell+\epsilon \mathclose]$ contient tous les termes $x_n$ au-delà de $N$.

Il est à noter que le rang $N$ dont il est question dans la définition de suite convergente dépend de~$\epsilon$.

\begin{definition}      \label{DEFooHNCTooMlQUvx}
    Nous disons qu'une suite réelle $(x_n)$ converge\footnote{Voir la définition~\ref{PropLimiteSuiteNum} pour plus de détail.} vers $\ell$ lorsque pour tout $\varepsilon$, il existe un $N$ tel que
    \begin{equation}
        n>N\Rightarrow | x_n-\ell |\leq\varepsilon.
    \end{equation}
\end{definition}

Le concept fondamental de cette définition est la notion de valeur absolue qui permet de donner la «distance» entre deux réels. Dans un espace vectoriel normé quelconque, cette notion est généralisée par la distance associée à la norme (définition~\ref{DefNorme}). Nous pouvons donc facilement définir le concept de convergence d'une suite dans un espace vectoriel normé.

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Opérations sur les limites}
%---------------------------------------------------------------------------------------------------------------------------

\begin{proposition}[\cite{MonCerveau}]     \label{PROPooIQOAooJPMoDD}
    Soient des suites à valeurs réelles \( (a_i)\) et \( (b_j)\) si elles sont convergentes, alors la suite \( ab\) est convergente et
    \begin{equation}
        \big( \lim_ia_i \big)\big( \lim_jb_j \big)=\lim_i(a_ib_i).
    \end{equation}
\end{proposition}

\begin{proof}
    Nous nommons \( a\) et \( b\) les limites des suites \( (a_i)\) et \( (b_j)\). Soit \( \epsilon>0\) ainsi que \( i\in \eN\). Nous avons la majoration
    \begin{subequations}
        \begin{align}
            | a_ib_i-ab |&\leq | a_ib_i-a_ib |+| a_ib-ab |\\
            &\leq | a_i | |b_i-b |+b| a_i-a |.
        \end{align}
    \end{subequations}
    Vu que la suite \( (a_i)\) est convergente, elle est bornée. Nous pouvons donc majorer \( | a_i |\) par \( R>0\) qui ne dépend pas de \( i\). Soit \( \eta>0\) tel que \( (R+b)\eta<\epsilon\). Alors en prenant \( i\) assez grand pour que \( | b_i-b |<\eta\) et \( | a_i-a |<\eta\), nous avons bien
    \begin{equation}
        | a_ib_i-ab |\leq (R+b)\eta<\epsilon.
    \end{equation}
\end{proof}

\begin{proposition}     \label{PROPooICZMooGfLdPc}
    Soient des suites \( (x_n)\) et \( (y_n)\) dans un espace vectoriel normé \( V\). Si \( x_n\stackrel{V}{\longrightarrow}x\) et \( y_n\stackrel{V}{\longrightarrow}y\), alors
    \begin{equation}
        x_n+y_n\stackrel{V}{\longrightarrow}x+y.
    \end{equation}
\end{proposition}

\begin{proof}
    Soit \( \epsilon>0\). Nous considérons \( N\) tel que si \( n\geq N\), alors \( \| x_n-x \|\leq \epsilon\) et \( \| y_n-y \|\leq \epsilon\). En utilisant l'inégalité \ref{DefNorme}\ref{ItemDefNormeiii},
    \begin{equation}
        \| x_y+y_n-(x+y) \|\leq \| x_n-x \|+\| y_n-y \|\leq 2\epsilon.
    \end{equation}
    Donc la suite \( (x_n+y_n)\) converge vers \( x+y\).
\end{proof}

 
\subsection{Exemples}
%//////////////////////////

\begin{example}
	Quelques suites usuelles.
	\begin{enumerate}
		\item
			La suite $x_n=\frac{1}{ n }$ converge vers $0$.
		\item
			La suite $x_n=(-1)^n$ ne converge pas.
	\end{enumerate}
\end{example}

Deux limites pour voir comment ça fonctionne.
\begin{lemma}
    Si \( r>1\) nous avons :
    \begin{enumerate}
        \item
            \( \lim_{n\to \infty} r^n=\infty\).
        \item
            \( \lim_{n\to \infty} \frac{ r^n }{ n }=\infty\).
    \end{enumerate}
\end{lemma}

\begin{proof}
    Vu que \( r>1\) nous pouvons écrire \( r=1+\delta\) avec \( \delta>0\). La formule du binôme de Newton \eqref{EqNewtonB} nous donne
    \begin{equation}
        (1+\delta)^n=\sum_{k=0}^n{k\choose n}\delta^k>{1\choose n}\delta=n\delta.
    \end{equation}
    La proposition \ref{ThoooKJTTooCaxEny} (\( \eR\) est archimédien) nous indique que \( n\delta\) est arbitrairement grand lorsque \( n\) est grand, quelle que soit \( \delta>0\). Cela finit la preuve de la première limite.

    Pour la seconde, nous posons \( a_n=\frac{ r^n }{ n }\). Nous avons
    \begin{equation}
        \frac{ a_{n+1} }{ a_n }=\frac{ n }{ n+1 }r.
    \end{equation}
    Vu que \( \frac{ n }{ n+1 }\to 1\), la suite \( \frac{ n }{ n+1 }r\) tend vers \( r>0\), et en particulier pour tout \( \delta>0\) tel que \( r>1+\delta\), il existe \( N\in \eN\) tel que, pour tout \( n > N \),
    \begin{equation}
        \frac{ n }{ n+1 }r>1+\delta.
    \end{equation}
    Soit maintenant \( k\in \eN\). En utilisant un produit télescopique,
    \begin{equation}
        a_{N+k}=a_N\frac{ a_{N+1} }{ a_N }\frac{ a_{N+2} }{ a_{N+1} }\cdots\frac{ a_{N+k} }{ a_{N+k-1} }>a_N(1+\delta)^{k-1}.
    \end{equation}
    Or \( (1+\delta)^{k-1}\) tend vers \( \infty\) lorsque \( k\to \infty\) par le premier point. Donc nous avons \( \lim_{n\to \infty} r^n/n=\infty\).
\end{proof}


\begin{definition}      \label{DEFooEWRTooKgShmT}
    Nous disons que deux suites \( (u_n)\) et \( (v_n)\) sont \defe{équivalentes}{equivalence@équivalence!de suites} s'il existe une fonction \( \alpha\colon \eN\to \eR\) telle que
    \begin{enumerate}
        \item
            pour tout \( n\) à partir d'un certain rang, \( u_n=v_n\alpha(n)\)
        \item
            \( \alpha(n)\to 1\).
    \end{enumerate}
\end{definition}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Suites croissantes et bornées}
%---------------------------------------------------------------------------------------------------------------------------

Une suite est dite \defe{contenue}{} dans un ensemble $A$ si $x_n\in A$ pour tout $n$. Une suite est \defe{bornée supérieurement}{bornée!suite} s'il existe un $M$ tel que $x_n\leq M$ pour tout $n$. De la même manière, la suite est bornée inférieurement s'il existe un $m$ tel que $x_n\geq m$ pour tout $n$.

Le lemme suivant est souvent utilisé pour prouver qu'une suite est convergente.
\begin{lemma}		\label{LemSuiteCrBorncv}
	Une suite croissante et bornée supérieurement converge. Une suite décroissante bornée inférieurement est convergente.
\end{lemma}

Une erreur courante est de croire que la borne est la limite : le lemme n'affirme pas ça. Par contre il est vrai que la borne donne \ldots hum \ldots une borne inférieure (ou supérieure) pour la limite.

\begin{theorem}[Bolzano-Weierstrass, thème \ref{THEMEooQQBHooLcqoKB}]     \label{THOooRDYOooJHLfGq}
    Toute suite contenue dans un compact admet une sous-suite convergente.
\end{theorem}

\begin{proof}
    Nous faisons la preuve par l'absurde en supposant que \( (x_k)\) n'admette pas de sous-suite convergente. Soit \( a\in K\); aucune sous-suite de \( (x_k)\) ne converge vers \( a\). En particulier, il existe un voisinage ouvert \( \mO_a\) de \( a\) et une partie finie \( I_a\) de \( \eN\) tel que \( x_k\in \mO_a\) seulement pour \( k\in I_a\).

    Les ouverts \( \mO_a\) recouvrent \( K\); nous pouvons en extraire un sous-recouvrement fini (c'est la définition \ref{DefJJVsEqs} de la compactié). Nous avons donc des points \( a_1,\ldots, a_n\) tels que 
    \begin{equation}
        K\subset \bigcup_{i=1}^n\mO_{a_i}
    \end{equation}
    et tels que pour chaque \( \mO_{a_i}\), nous avons \( x_k\in \mO_{a_i}\) seulement pour \( k\in I_{a_i}\). Bien entendu, toute la suite est dans \( K\) et donc dans l'union.

    En conclusion, nous avons \( \eN=\bigcup_{i=1}^n I_{a_i}\), ce qui prouve que \( \eN\) est un ensemble fini. Contradiction avec la proposition \ref{PROPooBYKCooGDkfWy} qui dit que \( \eN\) est infini.
\end{proof}

% Inutile de replacer cette proposition plus loin : on en a besoin pour démontrer Weierstrass. Quitte à maintenir, il faut réénoncer pour un espace vectoriel normé et prouver.
\begin{proposition}		\label{PropCvRpComposante}
	Une suite $(x_n)$ dans $\eR^m$ est convergente dans $\eR^m$ si et seulement si les suites de chaque composante sont convergentes dans $\eR$. Dans ce cas nous avons
	 \begin{equation}
		 \lim x_n=\Big( \lim(x_n)_1,\lim (x_n)_2,\ldots,\lim (x_n)_m \Big)
	 \end{equation}
	 où $(x_n)_k$ dénote la $k$-ième composante de $(x_n)$.
\end{proposition}

\begin{example}
	La suite $x_n=\big( \frac{1}{ n },1-\frac{1}{ n } \big)$ converge vers $(0,1)$ dans $\eR^2$. En effet, en utilisant la proposition~\ref{PropCvRpComposante}, nous devons calculer séparément les limites
	\begin{equation}
		\begin{aligned}[]
			\lim\frac{1}{ n }&=0\\
			\lim\big( 1-\frac{1}{ n } \big)&=1.
		\end{aligned}
	\end{equation}
\end{example}

\begin{example}
	Étant donné que la suite $(-1)^n$ n'est pas convergente, la suite $x_n=\big( (-1)^n,\frac{1}{ n } \big)$ n'est pas convergente dans $\eR^2$.
\end{example}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Suites adjacentes}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}[\cite{ooZZNWooSIipwW}]       \label{DEFooDMZLooDtNPmu}
    Les suites \( (a_n)\) et \( (b_n)\) sont \defe{adjacentes}{suites adjacentes} si l'une est croissante, l'autre décroissante et si \( a_n-b_n\to 0\).
\end{definition}

\begin{theorem}[Théorème des suites adjaentes]      \label{THOooZJWLooAtGMxD}
    Nous considérons des suites adjacentes \( (a_n)\) et \( (b_n)\) avec \( (a_n)\) croissante et \( (b_n)\) décroissante. Alors
    \begin{enumerate}
        \item
            \( b_n\geq a_n\) pour tout \( n\),
        \item
            \( a_n\leq b_q\) pour tout \( n\) et \( q\). C'est-à-dire que toute la suite \( a\) est plus petite que toute la suite \( b\).
        \item
            les suites \( a\) et \( b\) sont convergentes,
        \item
            les suites \( a\) et \( b\) convergent vers la même limite, notée \( \ell\),
        \item
            nous avons \( a_n\leq \ell\leq b_n\) pour tout \( n\).
    \end{enumerate}
\end{theorem}

\begin{proof}
    La suite \( n\mapsto b_n-a_n\) est décroissante parce que \( b_n-a_n\geq b_{n+1}-a_{n+1}\). Comme en plus \( b_a-a_n\to 0\) nous avons
    \begin{equation}
        b_n-a_n\geq 0
    \end{equation}
    pour tout \( n\in \eN\). De plus \( a_n\leq b_0\) pour tout \( n\) parce que si \( a_N>b_0\) alors, \( b\) étant décroissante, \( a_N>b_0\geq b_N\) qui est contraire à ce que nous venons de prouver. La suite \( a\) étant croissante et majorée, elle est convergente\footnote{Proposition \ref{LemSuiteCrBorncv}.}; notons \( \ell\) sa limite.

    La suite \( b\) peut maintenant être écrite par
    \begin{equation}
        b_n=(b_n-a_n)+a_n
    \end{equation}
    qui est une somme de deux suites convergentes. Elle est donc convergente et sa limite est la somme des limites\footnote{Proposition \ref{PROPooICZMooGfLdPc}.}, donc
    \begin{equation}
        \lim_{n\to \infty} b_n=\lim_{n\to \infty} (b_n-a_n)+a_n=0+\ell=\ell.
    \end{equation}
    Voila. Donc les suites \( a\) et \( b\) convergent et ont la même limite.

    Pour tout \( n,q\in \eN\) nous avons l'inégalité \( a_n\leq b_q\). En prenant la limite \( n\to \infty\) nous trouvons
    \begin{equation}
        \ell\leq b_q
    \end{equation}
    pour tout \( q\). Et de la même façon, \( b_n\geq a_q\) donne \( \ell\geq a_q\). L'un avec l'autre donne
    \begin{equation}
        a_q\leq \ell\leq b_q
    \end{equation}
    pour tout \( q\in \eN\).
\end{proof}

\begin{proposition}[\cite{ooXFPIooCLUvzV}]      \label{PROPooXOOCooGMqJNe}
    Soit une suite \( (a_n)\) dans \( \eR\).  Nous supposons que les suites extraites \( (a_{2n})\) et \( (a_{2n+1})\) convergent vers la même limite notée \( \ell\).

    Alors \( a_n\to \ell\).
\end{proposition}

\begin{proof}
    Soit \( \epsilon>0\). Il existe \( N_1\) tel que \( | a_{2n}-\ell |\leq \epsilon\) dès que \( n\geq N_1\). Il existe également \( N_2\) dès que \( | a_{2n+1}-\ell |\leq \epsilon\) dès que \( n\geq N_2\).

    Nous posons \( N=\max\{ 2N_1,2N_2+2 \}\) et nous avons, pour tout \( n\geq N\) :
    \begin{equation}
        | a_n-\ell |\leq \epsilon,
    \end{equation}
    c'est-à-dire que \( a\to \ell\).
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Limite supérieure et inférieure}
%---------------------------------------------------------------------------------------------------------------------------

\begin{lemmaDef}      \label{ooMVZAooVVCOnP}
    Soit \( (a_n)\) une suite dans \( \bar \eR\). Les limites suivantes existent dans \( \bar \eR\)
    \begin{equation}
        \limsup_{n\to\infty}a_n=\lim_{n\to \infty}\big( \sup_{k\geq n}a_k \big)
    \end{equation}
    et
    \begin{equation}
        \liminf_{n\to \infty}a_n=\lim_{n\to\infty}\big( \inf_{k\geq n}a_k \big).
    \end{equation}
    Elles sont nommées \defe{limite supérieure}{limite!supérieure} et la \defe{limite inférieure}{limite!inférieure} de la suite \( (a_k)\).
\end{lemmaDef}
\nomenclature[Y]{\( \limsup a_n\)}{limite supérieure}
\nomenclature[Y]{\( \liminf a_n\)}{limite inférieure}

\begin{proof}
    Pour la limite supérieure, l'ensemble des \( k\geq n\) est de plus en plus petit lorsque \( n\) grandit. Donc les ensembles \( A_n=\{ a_k\tq k\geq n \}\) sont emboîtés et la suite \( n\to \sup A_n\) est une suite décroissante. Elle a donc une limite dans \( \bar \eR\).
\end{proof}

\begin{normaltext}      \label{ooEEQJooRMFzVR}
    En ce qui concerne les suites d'ensembles, utiles en théorie des probabilités, nous définissons de même. Si les \( A_n\) sont des parties de \( \Omega\), nous définissons la \defe{limite supérieure}{limite!supérieure} et la \defe{limite inférieure}{limite!inférieure} de la suite \( A_n\) par
\begin{equation}
    \limsup_{n\to\infty}A_n=\bigcap_{n\geq 1}\bigcup_{k\geq n}A_k
\end{equation}
et
\begin{equation}
    \liminf_{n\to\infty}A_n=\bigcup_{n\geq 1}\bigcap_{k\geq n}A_k
\end{equation}

Nous avons
\begin{equation}
    \limsup A_n=\{ \omega\in\Omega\tq \omega\in A_n\text{pour une infinité de } n \}.
\end{equation}
\end{normaltext}

\begin{lemma}     \label{ooAQTEooYDBovS}
    Nous avons les formules pratiques suivantes :
    \begin{subequations}
        \begin{align}
            \limsup a_n&=\inf_{n\geq 1}\big( \sup_{k\geq n}a_k \big)\\
            \liminf a_n&=\sup_{n\geq 1}\big( \inf_{k\geq n}a_k \big).
        \end{align}
    \end{subequations}
\end{lemma}

\begin{proof}
    La suite \( n\mapsto \sup_{k\geq n}a_k\) est une suite décroissante, donc la limite est l'infimum. Même argument pour l'autre.
\end{proof}

\begin{lemma}       \label{ooIQIKooXWwAmM}
    La suite \( (a_n)\) dans \( \eR\) converge si et seulement si
    \begin{equation}
        \limsup a_n=\liminf a_n.
    \end{equation}
    Dans ce cas, \( \lim a_n=\limsup a_n=\liminf a_n\).
\end{lemma}

\begin{proof}
    Nous commençons par supposer que \( \limsup a_n=\liminf a_n=l\), et nous prouvons que \( \lim a_n\) existe et vaut \( l\). Soit \( \epsilon>0\). Il existe \( N\) tel que si \( n\geq N\) nous avons
    \begin{equation}
        \big| \sup_{k\geq n}a_k-l \big|<\epsilon
    \end{equation}
    et
    \begin{equation}
        \big| \inf_{k\geq n}a_k-l \big|<\epsilon.
    \end{equation}
    Pour tout \( k\geq N\) nous avons alors \( a_k\leq l+\epsilon\) et \( a_k\geq l-\epsilon\). Cela donne \( a_n\in B(l,\epsilon)\), c'est-à-dire \( a_k\to l\) par la proposition~\ref{PropLimiteSuiteNum}.

    Dans l'autre sens, nous supposons que \( \lim_n a_n=l\) et nous prouvons que les limites supérieures et inférieures sont toutes deux égales à \( l\). Soit \( \epsilon>0\) et \( N_{\epsilon}\) tel que \( | a_n-l |<\epsilon\) pour tout \( n\geq N_{\epsilon}\). Si \( n\geq N_{\epsilon}\) nous avons
    \begin{equation}
        \big| \sup_{k\geq n}a_k-l \big|\leq \epsilon
    \end{equation}
    et donc la limite de \( \sup_{k\geq n}a_k\) lorsque \( n\to \infty\) est bien \(l\).
\end{proof}

\begin{lemma}
    Soit une suite \( (a_i)\) dans \( \eR\). Il existe \( N\in \eN\) tel que pour tout \( i\geq N\),
    \begin{equation}
        x_i\leq \limsup_i(a_i).
    \end{equation}
\end{lemma}

\begin{proof}
    Soit \( M\) un nombre tel que pour tout \( N\), il existe \( k\geq N\) tel que \( x_k>M\). Dans ce cas, pour tout \( N\) nous avons
    \begin{equation}
        \sup_{i\geq N}(a_i)\geq M
    \end{equation}
    et donc
    \begin{equation}
        \limsup_n(a_n)=\lim_{N\to \infty}\sup_{i\geq N}(a_i)\geq M.
    \end{equation}
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Ouverts, voisinage, topologie}
%---------------------------------------------------------------------------------------------------------------------------

Lorsque $x\in E$, nous rappelons qu'un voisinage\footnote{Définition~\ref{DEFVoisinageooGHZCooLRcpXY}.} de $x$ est n'importe quel sous-ensemble de $E$ qui contient une boule ouverte centrée en $x$. La proposition \ref{ThoPartieOUvpartouv} nous dit qu'un ensemble est ouvert s'il contient un voisinage de chacun de ses points. Au passage, rappelons que l'ensemble vide est ouvert.

Pour rappel, la remarque \ref{RemQDRooKnwKk}\ref{ITEMooUIHJooXAFaIz} dit que l'ensemble des boules ouvertes d'un espace métrique génère la topologie de l'espace.

Nous rappelons qu'une partie $A$ d'un espace métrique est dite bornée\footnote{Définition~\ref{DefEnsembleBorne}.} s'il existe une boule\footnote{À titre d'exercice, convainquez-vous que l'on peut dire boule \emph{ouverte} ou \emph{fermée} au choix sans changer la définition.} qui contient $A$.

Mais revenons à \( \eR \)\dots
\begin{lemma}  \label{LemSupOuvPas}
    Une partie ouverte de \( \eR\) ne contient pas son supremum.
\end{lemma}

\begin{proof}
Soit $\mO$, un ensemble ouvert et $s$, son supremum. Si $s$ était dans $\mO$, on aurait un voisinage $B=B(s,r)$ de $s$ contenu dans $\mO$. Le point $s+r/2$ est alors à la fois dans $\mO$ et plus grand que $s$, ce qui contredit le fait que $s$ soit un supremum de $\mO$.
\end{proof}

Par le même genre de raisonnements, on montre que l'union et l'intersection de deux ouverts sont encore des ouverts.

\begin{remark}
L'intersection d'une \emph{infinité} d'ouverts n'est pas spécialement un ouvert comme le montre l'exemple suivant :
\[
  \mO_i=]1,2+\frac{ 1 }{ i }[.
\]
Tous les ensembles $\mO_i$ contiennent le point $2$ qui est donc dans l'intersection. Mais quel que soit le $\epsilon>0$ que l'on choisisse, le point $2+\epsilon$ n'est pas dans $\mO_{(1/\epsilon)+1}$. Donc aucun point au-delà de $2$ n'est dans l'intersection, ce qui prouve que $2$ ne possède pas de voisinages contenus dans $\bigcap_{i=1}^{\infty}\mO_i$.
\end{remark}

\begin{proposition}     \label{PROPooANIOooIJHelX}
    Quelles que soient les parties $A$ et $B$ de $\eR$, nous avons
    \begin{equation}
        \sup(A\cap B)\leq\sup A\leq\sup(A\cup B).
    \end{equation}
\end{proposition}

\begin{proof}
    En deux parties.
    \begin{subproof}
        \item[$ \sup(A\cap B)\leq \sup(A)$ ]
            Soit \( s=\sup(A)\). En particulier, \( s\) est un majorant de \( A\). Si \( x\in A\cap B\), alors \( x\in A\) et \( s\geq x\). Donc \( s\) est également un majorant de \( A\cap B\). Le lemme \ref{LEMooSSVKooDPhSkq} conclu que \( s\geq \sup(A\cap B)\).    

        \item[$ \sup(A)\leq \sup(A\cup B)$ ]
            Soit \( s=\sup(A\cup B)\). Par définition, \( s\) est un majorant de \( A\cup B\). À fortiori, \( s\) est un majorant de \( A\) et donc est plus grand ou égal à \( \sup(A)\).
    \end{subproof}
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Intervalles et connexité}
%---------------------------------------------------------------------------------------------------------------------------

Nous allons déterminer tous les sous-ensembles connexes\footnote{Définition~\ref{DefIRKNooJJlmiD}.} de $\eR$. Pour cela nous relisons d'abord la notion d'intervalle donnée en~\ref{DefEYAooMYYTz} ainsi que la proposition \ref{PROPooHPMWooQJXCAS} qui liste tous les intervalles de \( \eR\). La partie \( I\subset \eR\) est un intervalle si pour tout \( a,b\in I\), tout nombre entre \( a\) et \( b\) est également dans \( I\). Cette définition englobe tous les exemples connus d'intervalles ouverts, fermés avec ou sans infini : $[a,b]$, $[a,b[$, $]-\infty,a]$, \ldots L'ensemble \( \eR\) lui-même est un intervalle.

Si \( I\) est un intervalle, les nombres \( \inf(I)\) et \( \sup(I)\)\footnote{Qui existent par la proposition~\ref{DefSupeA}, quitte à poser \( \pm\infty\) comme infimum et supremum lorsque \( I\) n'est pas borné.} sont les \defe{extrémités}{extrémité!d'un intervalle} de \( I\).

\begin{definition}      \label{DefLISOooDHLQrl}
	Étant donnés deux points $a$ et $b$ dans $\eR^p$ on appelle \defe{segment}{segment!dans $\eR^p$} d'extrémités $a$ et $b$, et on note $[a,b]$, l'image de $[0,1]$ par l'application $s: [0,1]\to \eR^p$, $s(t)= (1-t)a+tb$.  On pose $]a,b[=s\left(]0,1[\right)$, et  $]a,b]=s\left(]0,1]\right)$.
\end{definition}
Il faut observer que le segment $[a,b]$ est une courbe orientée : certes en tant que ensembles, $[a,b]=[b,a]$, mais si nous regardons la fonction de $t$ correspondante à $[b,a]$, nous voyons qu'elle va dans le sens inverse de celle qui correspond à $[a,b]$. Nous approfondirons ces questions lorsque nous parlerons d'arcs paramétrés autour de la section~\ref{SecArcGeometrique}.

Le segment $[b,a]$ est l'image de l'application $r\colon [0,1]\to \eR^p$ donnée par $r(t)=(1-t)b+ta$.

\begin{proposition} \label{PropInterssiConn}
    Une partie de $\eR$ est connexe si et seulement si c'est un intervalle\footnote{Définition \ref{DefEYAooMYYTz}.}.
\end{proposition}
\index{connexité!et intervalles}

\begin{proof}
    La preuve est en deux parties. D'abord nous démontrons que si un sous-ensemble de $\eR$ est connexe, alors c'est un intervalle; et ensuite nous démontrons que tout intervalle est connexe.

    Afin de prouver qu'un ensemble connexe est toujours un intervalle, nous allons prouver que si un ensemble n'est pas un intervalle, alors il n'est pas connexe. Prenons $A$, une partie de $\eR$ qui n'est pas un intervalle. Il existe donc $a$, $b\in A$ et un $x_0$ entre $a$ et $b$ qui n'est pas dans $A$. Comme le but est de prouver que $A$ n'est pas connexe, il faut couper $A$ en deux ouverts disjoints. L'élément $x_0$ qui n'est pas dans $A$ est le bon candidat pour effectuer cette coupure. Prenons $M$, un majorant de $A$ et $m$, un minorant de $A$, et définissons
    \begin{align*}
        \mO_1&=]m,x_0[\\
        \mO_2&=]x_0,M[.
    \end{align*}
    Si $A$ n'a pas de minorant, nous remplaçons la définition de $\mO_1$ par $]-\infty,x_0[$, et si $A$ n'a pas de majorant, nous remplaçons la définition de $\mO_2$ par $]x_0,\infty[$. Dans tous les cas, ce sont deux ensembles ouverts dont l'union recouvre tout $A$. En effet, $\mO_1\cup \mO_2$ contient tous les nombres entre un minorant de $A$ et un majorant sauf $x_0$, mais on sait que $x_0$ n'est pas dans $A$. Cela prouve que $A$ n'est pas connexe.

    Jusqu'à présent nous avons prouvé que si un ensemble n'est pas un intervalle, alors il ne peut pas être connexe. Pour remettre les choses à l'endroit, prenons un ensemble connexe, et demandons-nous s'il peut être autre chose qu'un intervalle ? La réponse est \emph{non} parce que s'il était autre chose, il ne serait pas connexe.

    Prouvons à présent que tout intervalle est connexe. Pour cela, nous refaisons le coup de la contraposée. Nous allons donc prendre une partie $A$ de $\eR$, supposer qu'elle n'est pas connexe et puis prouver qu'elle n'est alors pas un intervalle. Nous avons deux ouverts disjoints $\mO_1$ et $\mO_2$ tels que $A\subset \mO_1\cup \mO_2$. Notons \( A_1 = A \cap \mO_1 \) et  \( A_2 = A \cap \mO_2 \); et prenons $a\in A_1$ et $b\in A_2$. Pour fixer les idées, on suppose que $a<b$. Maintenant, le jeu est de montrer qu'il existe une point $x_0$ entre $a$ et $b$ qui ne soit pas dans $A$ (cela montrerait que $A$ n'est pas un intervalle). Nous allons prouver que c'est le cas du point
    \[
      x_0=\sup\{ x\in\mO_1\tq x<b \}.
    \]
    Étant donné que l'ensemble $\mA=\{ x\in\mO_1\tq x<b \}$ est ouvert\footnote{C'est l'intersection entre l'ouvert $\mO_1$ et l'ouvert $\{x\tq x<b \}$.}, le point $x_0$ n'est pas dans l'ensemble par le lemme~\ref{LemSupOuvPas}. Nous avons donc
    \begin{itemize}
        \item soit $x_0$ n'est pas dans $\mO_1$,
        \item soit $x_0\leq b$,
        \item soit les deux en même temps.
    \end{itemize}
    Nous allons montrer qu'un tel $x_0$ ne peut pas être dans $A$. D'abord, remarquons que $\sup\mA\leq\sup\mO$ parce que $\mA$ est une intersection de $\mO$ avec quelque chose. Ensuite, il n'est pas possible que $x_0$ soit dans $\mO_2$ parce que tout élément de $\mO_2$ possède un voisinage contenu dans $\mO_2$. Un point de $\mO_2$ est donc toujours strictement plus grand que le supremum de $\mO_1$.

    Maintenant, remarque que si $x_0\leq b$, alors $x_0=b$, sinon $b$ serait un majorant de $\mA$ plus petit que $x_0$, ce qui n'est pas possible vu que $x_0$ est le supremum de $\mA$ et donc le plus petit majorant. Oui mais si $x_0=b$, c'est que $x_0\in\mO_2$, ce qu'on vient de montrer être impossible. Nous voilà déjà débarrassé des deuxièmes et troisièmes possibilités.

    Si la première possibilité est vraie, alors $x_0$ n'est pas dans $A$ parce qu'on a aussi prouvé que $x_0\notin\mO_2$. Or n'être ni dans $\mO_1$ ni dans $\mO_2$ implique de ne pas être dans $A$. Ce point $x_0=\sup\mA$ est donc hors de $A$.

    Oui, mais comme $a\in\mA$, on a obligatoirement que $x_0\geq a$. Mais par construction, on a aussi que $x_0\leq b$ (ici, l'inégalité est même stricte, mais ce n'est pas important). Donc
    \[
      a\leq x_0\leq b
    \]
    avec $a$, $b\in A$, et $x_0\notin A$. Cela finit de prouver que $A$ n'est pas un intervalle.
\end{proof}

\begin{theorem}[Théorème des bornes atteintes]\label{ThoMKKooAbHaro}
    Une fonction à valeurs réelles continue sur un compact est bornée et atteint ses bornes.

	C'est-à-dire qu'il existe $x_0\in K$ tel que $f(x_0)=\inf\{ f(x)\tq x\in K \}$ ainsi que $x_1$ tel que $f(x_1)=\sup\{ f(x)\tq x\in K \}$.
\end{theorem}
\index{compact!et fonction continue}

\begin{proof}
    Soient un espace topologique compact \( K\) et une fonction continue \( f\colon K\to \eR\). Alors le théorème~\ref{ThoImCompCotComp} indique que \( f(K)\) est compact. Par conséquent \( f(K)\) est un fermé borné de \( \eR\) par le théorème de Borel-Lebesgue~\ref{ThoXTEooxFmdI}. Vu que \( f(K)\) est borné, la fonction \( f\) est bornée.

    De plus \( f(K)\) étant fermé, son infimum est un minimum et son supremum est un maximum : il existe \( x\in K\) tel que \( f(x)=\sup f(K)\) et il existe \( y\in K\) tel que \( f(y)=\inf f(K)\).
\end{proof}

Le théorème suivant est essentiellement inutile pour les raisons suivantes :
\begin{itemize}
    \item 
        Il est un cas particulier du théorème~\ref{ThoBWFTXAZNH} qui donne pour tout espace métrique, l'équivalence entre la compacité et la compacité séquentielle.
    \item
        Il est un cas particulier du théorème \ref{THOooRDYOooJHLfGq} qui le donne pour tous les espaces compacts.
    \item
        Il utilise le cas particulier de \( \eR\), qui n'est pas démontré directement dans le Frido.
\end{itemize}
Bref, nous ne le laissons que pour le lecteur qui n'aurait pas en tête d'autres définitions de «compact» à part «fermé borné».

% Pour les raisons invoquées, il ne fait pas faire de références vers ce théorème. Le label ici ne sert qu'à le mettre dans l'index thématique.
\begin{theorem}[Théorème de Bolzano-Weierstrass]		\label{ThoBolzanoWeierstrassRn}
	Toute suite contenue dans un compact de \( \eR^m\) admet une sous-suite convergente.
\end{theorem}

\begin{proof}
    Nous rappelons qu'une partie compacte de \( \eR^n\) est fermée et bornée par le théorème de Borel-Lebesgue~\ref{ThoXTEooxFmdI}.

    Soit $(x_n)$ une suite contenue dans une partie bornée de $\eR^m$. Considérons $(a_n)$, la suite réelle des premières composantes des éléments de $(x_n)$ : pour chaque $n\in\eN$, le nombre $a_n$ est la première composante de $x_n$. Étant donné que la suite $(x_n)$ est bornée, il existe un $M$ tel que $\| x_n \|<M$. La croissance de la fonction racine carrée donne
	\begin{equation}
        | a_n |\leq\| x_n \|\leq M.
	\end{equation}
    La suite $(a_n)$ est donc une suite réelle bornée et donc contient une sous-suite convergente par le théorème correspondant dans \( \eR\) :  \ref{ThoBWFTXAZNH}. Soit $a_{I_1}$ une sous-suite convergente de $(a_n)$. Nous considérons maintenant $x_{I_1}$, c'est-à-dire la suite de départ dont on a enlevé tous les éléments qu'il faut pour qu'elle converge en ce qui concerne la première composante.

	Si nous considérons la suite $b_{I_1}$ des \emph{secondes} composantes de $x_{I_1}$, nous en extrayons, de la même façon que précédemment, une sous-suite convergente, c'est-à-dire que nous avons un $I_2\subset I_1$ tel que $b_{I_2}$ est convergent. Notons que $a_{I_2}$ est une sous-suite de la (sous) suite convergente $x_{I_1}$, et donc $a_{I_2}$ est encore convergente.

	En continuant ainsi, nous construisons une sous-sous-sous-suite $x_{I_3}$ telle que la suite des \emph{troisièmes} composantes est convergente. Lorsque nous avons effectué cette procédure $m$ fois, la suite $x_{I_m}$ est une suite dont toutes les composantes convergent, et donc est une suite convergente par la proposition~\ref{PropCvRpComposante}.

	Le tableau suivant donne un petit schéma de la façon dont nous procédons. Les $\bullet$ sont les éléments de la suite que nous gardons, et les $\times$ sont ceux que nous «jetons».
	\begin{equation}
		\begin{array}{lccccccccccc}
			x_{\eN}	&	\bullet&\bullet&\bullet&\bullet&\bullet&\bullet&\bullet&\bullet&\bullet&\bullet&\ldots\\
			x_{I_1}	&	\times&\bullet&\bullet&\times&\bullet&\times&\times&\bullet&\bullet&\bullet&\ldots\\
			x_{I_2}	&	\times&\bullet&\times&\times&\bullet&\times&\times&\bullet&\bullet&\times&\ldots\\
			\vdots\\
			x_{I_m}	&	\times&\times&\times&\times&\bullet&\times&\times&\times&\bullet&\times&\ldots
		\end{array}
	\end{equation}
	La première ligne, $x_{\eN}$, est la suite de départ.
\end{proof}

\begin{corollary}   \label{CorFHbMqGGyi}
    Si un suite est croissante et bornée alors elle est convergente.
\end{corollary}

\begin{proof}
    Nous nommons \( (x_n)\) la suite et nous prenons un majorant \( M\). Toute la suite est alors contenue dans le compact \( \mathopen[ x_0 , M \mathclose]\), ce qui donne une sous-suite \( (x_{\alpha(n)})\) convergente par le théorème de Bolzano-Weierstrass~\ref{THOooRDYOooJHLfGq}. Si \( \ell\) est la limite de cette sous-suite alors nous avons \( \ell\geq x_n\) pour tout \( n\).

    Pour tout \( \epsilon>0\) il existe \( K\) tel que si \( n>K\) alors \( | \ell-x_{\alpha(n)} |<\epsilon\). Vu que \( \ell\) majore la suite nous avons même
    \begin{equation}
        x_{\alpha(n)}+\epsilon>\ell.
    \end{equation}
    Vu que la suite est croissante pour tout \( m>\alpha(K)\) nous avons \( x_m+\epsilon>l\), ce qui signifie \( | x_m-\ell |<\epsilon\).
\end{proof}
Nous aurons une version pour les fonctions croissantes et bornées en la proposition~\ref{PropMTmBYeU}.

La proposition suivante dit que la notion d'ensemble non dénombrable ne prend pas réellement de force entre \( \eR\) et \( \eR^n\) : il n'y a pas moyen de caser \( \eR\) dans \( \eR^n\) de façon à ce qu'il y tienne à son aise.

\begin{proposition}
    Une partie non dénombrable de \( \eR^n\) possède un point d'accumulation\footnote{Définition \ref{DEFooGHUUooZKTJRi}.}.
\end{proposition}

\begin{proof}
    Soit une partie \( A\subset \eR^n\) sans point d'accumulation. Nous allons prouver que \( A\) est dénombrable.

    Soient les compacts \( K_n=\overline{ B(0,n) }\). La partie \( A\cap K_n\) est finie; sinon elle aurait une partie en bijection avec \( \eN\) (proposition~\ref{PROPooUIPAooCUEFme}) et donc une suite. Or une suite dans un compact possède un point d'accumulation par le théorème~\ref{THOooRDYOooJHLfGq}.

    Donc tous les \( A\cap K_n\) sont finis. Vu que \( A=\bigcup_nA\cap K_n\), l'ensemble \( A\) est une réunion dénombrable d'ensembles finis. Il est donc dénombrable.
\end{proof}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Recouvrement par des intervalles ouverts}
%---------------------------------------------------------------------------------------------------------------------------

Soit un ensemble \( E\) et un ensemble \( \mA\) de parties de \( E\). Soit \( A\in \mA\). Nous aimerions savoir quelles sont les éléments de \( \mA\) qui sont atteignables en partant de \( A\) et en ne «sautant» que d'intersection en intersection.

Nous notons \( \mA=\{ B_i \}_{i\in I}\) où \( I\) est un ensemble d'indices (un ensemble quelconque).
\begin{subequations}
    \begin{align}
        s_1(A)&=\{  i\in I\tq B_i\cap A\neq \emptyset   \}\\
        \sigma_1(A)&=\bigcup_{B\in s_1(A)}B.
    \end{align}
\end{subequations}
Et ensuite :
\begin{subequations}
    \begin{align}
        s_{k+1}(A)&=\{ i\in I\tq B_i\cap \sigma_k(A)\neq \emptyset \}\\
        \sigma_{k+1}(A)&=\bigcup_{B\in s_{k+1}(A)}B
    \end{align}
\end{subequations}

\begin{lemma}
    Soient un intervalle \( A\) de \( \eR\) et \( \mA=\{ I_i \}_{i=1,\ldots, N}\) un recouvrement de \( A\) par des intervalles ouverts. Si \( I_1\cap A\neq \emptyset\) alors
    \begin{enumerate}
        \item
            \( \sigma_{N}=\sigma_{N+1}\)
        \item
            \( A\subset \sigma_N(I_1)\).
    \end{enumerate}
\end{lemma}

\begin{proof}
    Si \( \sigma_{k+1}=\sigma_k\), alors tous les \( \sigma_{k+l}\) sont identiques. De plus si \( \sigma_{k+1}\neq \sigma_k\), alors \( \sigma_{k+1}\) contient au moins un élément de plus que \( \sigma_k\). Donc \( \Card(\sigma_k)\geq k\) et en particulier \( N\leq \Card(\sigma_N)\leq N\). Cela prouve le premier point.

    L'ensemble \( \sigma_N(I_1)\) est une union d'ouverts et est donc un ouvert. Quitte à renuméroter nous écrivons
    \begin{equation}
        \sigma_N(I_1)=I_1\cup \ldots \cup I_n.
    \end{equation}
    L'ensemble 
    \begin{equation}
        \tau=\bigcup_{k=n+1}^NI_k
    \end{equation}
    est ouvert et est disjoint de \( \sigma_N(I_1)\) parce que si \( I_l\) ($I_l\geq n+1$) intersectait \( \sigma_N(I_1)\), nous aurions \( l\in s_{N+1}\) ou encore \( I_l\subset \sigma_{N+1}\setminus\sigma_N\).

    Donc \( \tau\) et \( \sigma_N\) sont deux ouverts disjoints qui recouvrent \( A\). Vu que \( A\) est un intervalle, il est connexe\footnote{Définition \ref{DefIRKNooJJlmiD} et proposition \ref{PropInterssiConn}.}. Donc soit \( A\subset \tau\) soit \( A\subset \sigma_N\). Comme \( I_1\cap A\neq \emptyset\) nous sommes dans le cas \( A\subset \sigma_N\).
\end{proof}

\begin{lemma}       \label{LEMooGHPTooKgFvGb}
    Soit \( x\in \eR\). Si \( \mA=\{ I_s \}_{s\in S}\) est un ensemble d'intervalles contenant \( x\), alors \( I=\bigcup_{s\in S}I_s\) est un intervalle\footnote{Définition \ref{DefEYAooMYYTz}.}.
\end{lemma}

\begin{proof}
    Soient \( a,b\in I \) (nous supposons \( a<b\)). Nous devons prouver que \( \mathopen[ a , b \mathclose]\subset I\). Pour cela nous considérons \( y\in \mathopen[ a , b \mathclose]\); il y a deux possibilités : soit \( y<x\) soit \( y>x\) (si \( y=x\) alors \( y\in I_s\)). 

    Si \( y<x\), alors \( a\leq y<x\) et donc \( y=\in I_s\). Si \( y>x\), alors \( x<y\leq b\) et \( y\in I_t\).
\end{proof}

\begin{proposition}[\cite{BIBooVUFIooNEETXD,BIBooFEKBooFhPatO}]     \index{intervalle}
    Un ouvert de \( \eR\) peut s'écrire comme union au plus dénombrable d'intervalles ouverts disjoints.

    Plus précisément, si \( \mO\) est un ouvert de \( \eR\), il existe un ensemble \( \mF=\{ I_s \}_{s\in S}\) où
    \begin{enumerate}
        \item
            Chaque \( I_s\) est un intervalle ouvert contenu dans \( \mO\),
        \item
            Pour \( s,t\in S\), si \( I_s\neq I_t\), alors \( I_s\cap I_t=\emptyset\).
        \item
            \( S\) est dénombrable,
    \end{enumerate}
\end{proposition}

\begin{proof}
    Pour \( x\in \mO\), nous définissons \( J_x\) comme étant l'union de tous les intervalles ouverts contenus dans \( \mO\) et contenant \( x\). Les $J_x$ ne sont pas vides parce qu'ils contiennent toujours une boule centrée en \( x\)\footnote{C'est la définition \ref{EqGDVVooDZfwSf} de la topologie métrique.}.
    
    En tant que union d'intervalles, \( J_x\) est un intervalle par le lemme \ref{LEMooGHPTooKgFvGb}. De plus, \( J_x\) est ouvert parce que toute union d'ouverts est ouverte.

    Nous notons \( \mA\) l'ensemble des intervalles ouverts contenus dans \( \mO\), et
    \begin{equation}
        \mA_x=\{ I\in\mA\tq x\in I \}.
    \end{equation}

    \begin{subproof}
        \item[Si \( y\in J_x\), alors \( J_x=J_y\)]
            Vu que \( y\in J_x\), nous pouvons considérer \( J=\in \mA_x\cap \mA_y\). Nous avons
            \begin{equation}
                J_y=\bigcup_{I\in\mA_y}I\subset \bigcup_{I\in \mA_y}\underbrace{(I\cup J)}_{\in\mA_x}\subset \bigcup_{I\in\mA_x}I=J_x.
            \end{equation}
            L'inclusion dans l'autre sens s'obtient en écrivant la même chose en remplaçant \( x\) par \( y\) et vice-versa.
        \item[Les \( J_x\) sont disjoints]
            Nous prouvons à présent que pour \( x,y\in mO\), nous avons \( J_x=J_y \) ou \( J_x\cap J_y=\emptyset\). En effet si \( a\in J_x\cap J_y\), alors \( J_a=J_x\) et \( J_a=J-y\). Donc \( J_x=J_y\).
        \item[Dénombrable]
            C'est le moment d'écrire $\mF=\{ J_x \}_{x\in \mO}$. Vu que tout intervalle contient au moins un rationnel (proposition \ref{PropooUHNZooOUYIkn}), nous avons aussi
            \begin{equation}
                \mF=\{ J_x \}_{x\in \mO}=\{ J_q \}_{q\in \eQ\cap\mO}.   
            \end{equation}
            Cet ensemble \( \mF\) vérifie les conditions demandées.
    \end{subproof}
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Connexité par arcs}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}      \label{DEFooOXVCooBizpgK}
    Une partie $A$ d'un espace topologique est \defe{connexe par arcs}{connexe par arc} si pour tout $ a,b \in A$, il existe une application continue $\gamma\colon \mathopen[ 0 , 1 \mathclose]\to A$ telle que \( \gamma(0)=a\) et \( \gamma(1)=b\).
\end{definition}

\begin{normaltext}
    Un exemple d'ensemble connexe mais pas connexe par arcs est donné par la proposition \ref{PROPooVXDNooPZYKPr}. L'idée de cet exemple est de construire un ensemble en deux parties reliées par un chemin de longueur infinie.

    Un espoir fou nous prend alors de croire que nous pouvons produire un exemple plus simple avec \( \eR\cup\{ \infty \}\) parce que, dans cet ensemble, \( 1\) et \( \infty\) sont reliés par un chemin de longueur infinie. La proposition \ref{PROPooLOQVooULDhZz} nous montrera que non.
\end{normaltext}


%TODOooAMMAooCrYxvK : mettre dans l'ordre dans ceci :
\input{212_topologie}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Des exemples}
%---------------------------------------------------------------------------------------------------------------------------


\begin{example}
    Nous étudions l'exemple suivant :
    \begin{equation}
        A_1 = \{ (x, y ) \in \eR^2 \; | \; 2y^2+4y+2<x\leq \sqrt{4- y^2},\, y\in [-1.5, 0.5[ \}.
    \end{equation}

 On commence par tracer la parabole $x=2y^2+4y+2$, la circonférence $x^2+y^2=4$ et les droites $y=-1.5$ et $y=1/2$. On voit tout de suite que l'aire délimitée par les quatre courbes est donnée par l'union de deux parties. Dans la première $\sqrt{4- y^2}\leq x\leq 2y^2+4y+2$, $y\in [0,0.5]$ et dans l'autre $2y^2+4y+2\leq x\leq \sqrt{4- y^2}$, $y\in [-1.5, 0]$. L'ensemble $A_1$ est contenu dans la deuxième, \ref{LabelFigLAfWmaN}. L'intérieur de $A_1$ est donné par $\Int(A_1) = \{ (x, y ) \in \eR^2 \; | \; 2y^2+4y+2<x< \sqrt{4- y^2},\, y\in ]-1.5, 0[ \}$, et sa frontière est l'union de 3 morceaux de courbe $\ell_1$, $\ell_2$, $\ell_3$:
      \begin{equation}
        \begin{aligned}
          &\ell_1=\{(x,y)\, |\, x=2y^2+4y+2,\, y\in [-1.5, 0] \}\\
          &\ell_2=\{(x,y)\, |\, x=\sqrt{4-y^2},\, y\in [-1.5, 0] \}\\
          &\ell_3=\{(x,y)\, |\, x\in [0.5, \sqrt{7/4}]\, y=-1.5 \}.
        \end{aligned}
      \end{equation}

%The result is on figure \ref{LabelFigLAfWmaN}. % From file LAfWmaN
\newcommand{\CaptionFigLAfWmaN}{}
\input{auto/pictures_tex/Fig_LAfWmaN.pstricks}
\end{example}

\begin{example}
    Nous étudions
    \begin{equation}
A_3 = \eN \times \eQ = \{ (x, y ) \in \eR^2 \; | \; x \in \eN , y \in \eQ \}.
    \end{equation}
    L'ensemble $A_3$ n'est pas ouvert, ni fermé, ni borné dans la topologie de $\eR^2$. En fait, comme on a vu dans les exercices du cours, $\eQ$ a intérieur vide et sa fermeture est $\eR$. L'ensemble $\eN$, par contre est fermé et non borné. On peut remarquer que tous les points de $\eN$ sont points isolés. La fermeture de $A_3$ est alors $\eN\times \eR$ et son intérieur est vide. On peut dessiner la fermeture de cet ensemble comme une famille de droites verticales $x=n$, pour tout $n$ dans $\eN$.
\end{example}


\begin{example}
    Nous étudions l'ensemble
    \begin{equation}
 A_3 = \{ ( t , 2t ) \in \eR^2 \; | \; t \in [0, 1] \; \}.
    \end{equation}

			L'ensemble $A_3$ est un petit segment de droite. Son intérieur est vide parce que toute boule centrée en un point de la droite intersecte l'extérieur de la droite. Son adhérence et sa frontière sont $A_3$ lui-même parce que nous considérons les valeurs de $t$ dans $\mathopen[ 0 , 1 \mathclose]$ qui est un intervalle fermé. Si l'intervalle avait été ouvert, l'adhérence et la frontière auraient été trouvés en fermant :
			\begin{equation}
                \overline{ \{ (t,2t)\tqs t\in\mathopen[ 0 , 1 [\, \}}=\{ (t,2t)\tqs t\in\mathopen[ 0 , 1 ] \}
			\end{equation}
			Étant donné que son adhérence est égal à lui-même, cet ensemble est fermé (et donc pas ouvert). Il est également borné parce qu'il est contenu dans une boule de rayon $3$.
\end{example}

\begin{example}
    Nous étudions l'ensemble
    \begin{equation}
        A_4 = \eQ \times \eQ = \{ (x, y ) \in \eR^2 \; | \; x \in \eQ , y \in \eQ \}.
    \end{equation}
			Dans $\eR$ nous savons que $\bar\eQ=\eR$, $\Int(\eQ)=\emptyset$ et $\partial\eQ=\eR$ parce que toute boule centrée en un rationnel contient un irrationnel, et inversement, toute boule centrée en un irrationnel contient un rationnel. Dans $\eR^2$ nous avons le même phénomène parce dans la boule $B\big( (p,q),r \big)$ avec $(p,q)\in\eQ\times\eQ$, se trouvent en particulier les points de la forme $(p,x)$ avec $x\in B(q,r)\subset\eR$. Évidement, certains de ces $x$ ne sont pas dans $\eQ$ et par conséquent, la boule $B\big( (p,q),r \big)$ contient les points $(p,x)\notin\eQ\times\eQ$.

			De la même manière, si $(x,y)$ est un point de $\eR^2$, dans toute boule centrée en $(x,y)$, il y aura un élément de $\eQ^2$.

			Par conséquent, $\Int(\eQ\times\eQ)=\emptyset$, $\overline{ \eQ\times\eQ }=\eR\times\eR$ et $\partial(\eQ\times\eQ)=\eR^2$.

			Il n'est ni ouvert ni fermé (parce qu'il n'est égal ni à son intérieur ni à sa fermeture). Il n'est pas borné non plus parce qu'il existe des nombres rationnels arbitrairement grands.
\end{example}



\begin{example}
    Nous étudions l'ensemble
    \begin{equation}
        A_5 = \{ (x, y ) \in \eR^2 \; | \; x \in ]0, 1[, \sin \frac 1x < y < 3 \}.
    \end{equation}

			La fonction $x\mapsto\sin(\frac{1}{ x })$ est une des fonctions dont le graphe doit être connu. La figure \ref{LabelFigAdhIntFrTrois} montre la situation. Comme d'habitude, il est fortement recommandé de refaire le dessin soi-même.
\newcommand{\CaptionFigAdhIntFrTrois}{Les points qui dont sur l'axe vertical entre $0$ et $3$ sont sur la frontière, mais pas dans l'ensemble $A_5$.}
\input{auto/pictures_tex/Fig_AdhIntFrTrois.pstricks}

			L'ensemble $A_5$ est ouvert parce que les conditions $x\in\mathopen] 0 , 1 \mathclose[$ et $\sin\frac{1}{ x }<y<3$ sont des conditions «ouvertes» au sens où si un point les vérifient, alors on peut trouver une boule dans lequel ces conditions restent vérifiées. Cela prouve que $\Int(A_5)=A_5$.

			La fermeture de $A_5$ contient en outre les points tels que $\sin\frac{1}{ x }=y$ entre $x=0$ et $x=1$ (les bornes étant incluses) ainsi que les points des trois segments de droites suivants:
			\begin{equation}
				\begin{aligned}[]
					\{ (0,y)\tqs y\in\mathopen[ -1 , 3 \mathclose] \}\\
					\{ (x,3)\tqs x\in\mathopen[ 0 , 1 \mathclose] \}\\
					\{ (1,y)\tqs y\in\mathopen[ \sin(1) , 3 \mathclose] \}.
				\end{aligned}
			\end{equation}

			La frontière est composée de ces trois segments et du graphe de la fonction $\sin\frac{1}{ x }$ entre $0$ et $1$.

			L'ensemble $A_5$ est borné parce qu'il est contenu par exemple dans la boule centrée en $(0,0)$ et de rayon $10$. Il est ouvert et donc pas fermé.
\end{example}


\begin{example}\label{ItemexoEspVectoNorme0003iv}
    Nous étudions l'ensemble
    \begin{equation}
        A_6 = \bigcup _{ n \in \eN_0} \{ ( \frac 1n, y ) \; | \; y \in [0,1] \; \}.
    \end{equation}

			L'ensemble $A_6$ est une union infinie de segments de droites verticaux, voir figure \ref{LabelFigAdhIntFrSix}
\newcommand{\CaptionFigAdhIntFrSix}{Le segment sur l'axe vertical entre $y=0$ et $y=1$ fait partie de l'adhérence et de la frontière, mais pas de l'ensemble $A_6$ lui-même.}
\input{auto/pictures_tex/Fig_AdhIntFrSix.pstricks}
				L'intérieur est vide parce qu'autour de tout réel de la forme $\frac{1}{ n }$, il y a un réel qui n'est pas de cette forme. En ce qui concerne la frontière et l'adhérence, il s'agit de l'union de tous ces segments plus le segment en $x=0$.

			En effet, la boule de rayon $r$ autour du point $(0,y)$ le point $(\frac{1}{ n },y)$ avec $n$ assez grand pour que $\frac{1}{ n }<r$.
\end{example}


%---------------------------------------------------------------------------------------------------------------------------
\subsection{Topologie de la droite réelle complétée}
%---------------------------------------------------------------------------------------------------------------------------
\label{SUBSECooKRRUooSlZSmM}

Nous introduisons l'ensemble \( \bar\eR=\eR\cup\{ \pm\infty \}\). À présent les symboles \( +\infty\) et \( -\infty\) n'ont aucune signification particulière; il s'agit seulement de deux éléments que nous ajoutons à \( \eR\) pour former un ensemble que nous notons \( \bar \eR\).

Pas plus tard qu'immédiatement nous leur donnons une signification en définissant une topologie sur \( \bar\eR\). Les ouverts sur \( \bar \eR\) sont
\begin{enumerate}
    \item
        tous les ouverts de \( \eR\),
    \item
        les intervalles de la forme \( \mathopen] -\infty , a \mathclose[\) pour tous les \( a\in \eR\),
    \item
        les intervalles de la forme \( \mathopen] a , +\infty \mathclose[\) pour tous les \( a\in \eR\),
    \item
        la topologie engendrée par toutes ces parties de \( \bar \eR\).
\end{enumerate}

Par construction, les boules de \( \eR\) et les intervalles \( \mathopen] -\infty , a \mathclose[\) et \( \mathopen] a , +\infty \mathclose[\) forment une base de topologie pour \( \bar \eR\).

Si \( f\) est une fonction \( f\colon \eR\to \eR\), que signifie \( \lim_{x\to \infty} f(x)\) ? Il s'agit de considérer la fonction élargie
\begin{equation}
    \begin{aligned}
        \tilde f\colon \bar \eR&\to \bar\eR \\
        x&\mapsto \begin{cases}
            f(x)    &   \text{si } x\in \eR\\
            0    &    \text{si } x=\pm\infty.
        \end{cases}
    \end{aligned}
\end{equation}
Ensuite, c'est la définition topologie usuelle de la limite. Notons que les limites en \( a\) ne dépendent pas de la valeur effective de \( f\) en \( a\), donc le prolongement par \( 0\) est sans conséquences. Nous pouvions tout aussi bien prolonger par \( 4\).

Le même raisonnement tient pour donner un sens à \( \lim_{x\to a} f(x)=\pm \infty\).

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Quelques mots à propos de la droite réelle complétée} 
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}
    La \defe{droite réelle complétée}{droite réelle complétée} est l'ensemble \( \eR\cup\{ \pm \infty \}\) où \( \pm\infty\) sont deux nouveaux éléments. Nous la notons \( \overline{ \eR }\) pour des raisons que nous verrons à peine plus bas.
\end{definition}

Cette définition ne servirait à rien si nous n'y mettions pas une topologie pour positionner les éléments \( \pm\infty\) par rapport à ceux qui existaient déjà dans \( \eR\).

\begin{definition}[Topologie sur \( \bar\eR\)]
La topologie sur \(\bar \eR\) est celle sur \( \eR\) à laquelle nous ajoutons les voisinages de \( \pm\infty\) de la façon suivante. Une partie \( V\) de \( \bar \eR\) est un voisinage de \( +\infty\) s'il existe \( m>0\) tel que \( \mathopen] m , +\infty \mathclose]\subset V\).
\end{definition}

Le lemme suivant justifie la notation \( \overline{ \eR }\) pour la droite réelle complétée\footnote{Mais ne justifie pas le qualificatif «complété» parce que l'espace métrique \( \eR\) était déjà complet.}.
\begin{lemma}       \label{LEMooPZXHooEEXsTC}
    L'adhérence\footnote{Définition \ref{DEFooSVWMooLpAVZR}.} de \( \eR\) dans \( \overline{ \eR }\) est \( \overline{ \eR }\).
\end{lemma}

\begin{proof}
    Il suffit de prouver que \( +\infty\) et \( -\infty\) sont dans l'adhérence de \( \eR\). Nous le faisons pour \( +\infty\). Ce n'est pas très compliqué : si \( A\) est un ouvert contenant \( +\infty\), il contient une partie de la forme \( \mathopen] a , +\infty \mathclose]\), et donc contient des éléments de \( \eR\).
\end{proof}

Pour la suite nous utilisons la notation (pratique en probabilité)
\begin{equation}
    \{ f<a \}=\{ x\in S\tq f(x)<a \}.
\end{equation}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Limite pointée ou épointée ?}
%---------------------------------------------------------------------------------------------------------------------------
\label{SUBSECooVHKCooYRFgrb}

Si vous êtes dans l'enseignement en France\footnote{En particulier si vous voulez passer l'agrégation.}, vous devriez lire ceci à propos de limite pointée. Dans tous les autres cas, la limite pointée est une notion qui ne vous intéresse à priori pas.

\begin{definition}[\cite{ooCNVFooHdbArS}]
    Soient $X$ et $Y$ deux espaces topologiques, $A$ une partie de $X$, $f$ une application de $A$ dans $Y$, $a$ un point de $X$ adhérent à $A$ et \(\ell \) un point de $Y$. On dit que \( \ell\) est une \defe{limite pointée}{limite pointée} de $f$ au point $a$ si pour tout voisinage $V$ de \( \ell\), il existe un voisinage $W$ de a tel que pour tout point $x$ de $W\cap A$, l'image $f(x)$ appartient à $V$.
\end{definition}

La notion de limite pointée ne diffère de la limite que du fait que pour calculer la limite pointée en \( a\), nous tenons compte des valeurs de \( f\) sur \emph{tout} le voisinage de \( a\), y compris le point \( a\) lui-même.

Le choix entre la limite pointée ou épointée a été discuté en de nombreuses occasions \cite{BIBooKNWHooBRoxme,BIBooNUKAooVMqppa,BIBooDILKooUcmUVD,BIBooJDPPooVONaQV}.

\begin{enumerate}
    \item       \label{ITEMooXSRLooMVwIHU}
        Dans la majorité des cas, la limite pointée donne le même résultat que la limite parce que, fondamentalement, si nous voulons calculer une limite de \( f\) au point \( a\), c'est que \( f\) n'est pas définie en \( a\). C'est en particulier toujours le cas pour les limites en l'infini ou les limites définissant les dérivées.
    \item
        La limite pointée est un peu plus simple au départ.
    \item
        La limite épointée est un peu plus riche. Par exemple si on dit « la limite de \( f\) en \( a\) existe » , ça donne une régularité pour \( f\) autour de \( 0\) que la limite pointée ne parvient pas à exprimer.
    \item
        La limite pointée n'est connue qu'en France.
\end{enumerate}

Le point \ref{ITEMooXSRLooMVwIHU} est le plus important parce qu'il explique pourquoi il y a moyen de finir l'agrégation, et même de faire de la recherche en ne tombant jamais sur un cas où la différence est importante.

\begin{example}
    La fonction \( f\) donnée par
    \begin{equation}
        f(x)=\begin{cases}
            0    &   \text{si } x\neq 0\\
            4    &    \text{si }x=0
        \end{cases}
    \end{equation}
    a une limite épointée pour \( x\to 0\) qui vaut \( 0\). Elle n'a par contre pas de limite pointée en \( 0\).

    Cette fonction est l'exemple-type de différence entre limite usuelle et limite pointée.
\end{example}

\begin{example}
    Si vous voulez un cas dans lequel la différence se voit de façon macroscopique, aller lire le lemme \ref{LEMooYLIHooFBQyzC}, sa démonstration et l'exemple \ref{EXooHSYNooBZhDbE}.
\end{example}

Dans le Frido, nous choisissons de prendre la limite épointée comme définition de limite. Nous donnons ici quelques raisons pour ce choix.

\begin{enumerate}
    \item
       C'est la définition unanimement acceptée dans la communauté mathématique hors France.
   \item
       La limite pointée ne donne à peu près rien de nouveau par rapport à la continuité.
       
       Ce que le concept de limite apporte est la possibilité d'étudier le comportement de \( f\) pour les points «proches» de \( a\), sans regarder la valeur en \( a\) lui-même. Si l'idée est de regarder le comportement «proche» de \( a\) y compris au point \( a\) lui-même, c'est la notion de continuité qui fait le travail.

       Donc les contextes dans lesquels le concept de limite est intéressant sont justement les contextes dans lesquels la fonction étudiée n'existe pas au point étudié. Dans ce cas, les limites pointées et épointées coïncident.
\end{enumerate}

Que devez-vous faire ?
\begin{description}
    \item[Enseignement en France] La notion de limite pointée est celle nommée «limite» dans les programmes, et ce que nous nommons ici «limite» est nommé «limite épointée». Peut-être pour induire en erreur tout le reste de la planète ?
    \item[Recherche] Si vous faites de la recherche où que ce soit y compris en France, la seule définition de limite est la limite dite «épointée», celle qui sera toujours utilisée dans le Frido.
    \item[Doctorat] Vous commencez un doctorat en math, et vous avez vu la limite pointée comme seule définition de limite durant vos études ? Oubliez-la. Ou alors attendez-vous à vous à de sérieux quiproquos lorsque vous discuterez de mathématique avec des étrangers. 

        Disons clairement que si vous utilisez la limite pointée devant des non Français, ils se diront juste que vous devriez relire vos cours de base. Et si vous leur expliquez, il y a de bonnes chance qu'ils ne vous croient pas.
\end{description}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Le théorème de composition}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Une des raisons fréquentes pour utiliser la limite pointée est que le théorème de composition est plus simple\cite{BIBooDILKooUcmUVD}.

Le voici avec des limites pointées. Pour faire la différence, j'adopte la notation \( {LP}\) pour la limite pointée et \( {LE}\) pour la limite épointée.
\begin{proposition}     \label{PROPooCQZZooMiZfQE}
    Soient \( f\) et \( g\) des fonctions \( \eR\to \eR\). Si \( {LP}_{x\to a}g(x)=\ell\) et si \( {LP}_{y\to \ell}f(y)=b\), alors
    \begin{equation}
        {LP}_{x\to a} (f\circ g)(x)={LP}_{y\to \ell} f(y)=b.
    \end{equation}
\end{proposition}

\begin{proof}
    Soit \( \epsilon>0\). L'hypothèse de limite pour \( f\) donne \( \eta>0\) tel que 
    \begin{equation}        \label{EQooLWGIooLqKThy}
        | y-\ell |<\eta \Rightarrow | f(y)-b |<\epsilon.
    \end{equation}

    Soit \( \delta>0\) tel que \( | x-a |<\delta\) implique \( | g(x)-\ell |<\eta\).

    Avec tout ça, si \( | x-a |<\delta\) nous avons \( | g(x)-\ell |<\eta\) et en appliquant l'implication \eqref{EQooLWGIooLqKThy} à \( y=g(x)\) nous trouvons \( | f\big( g(x) \big)-b |<\epsilon\).
\end{proof}

Avant d'énoncer et de démontrer le résultat correspondant pour les limites épointées, nous avons besoin d'un lemme, pour comprendre la différence d'hypothèse.

\begin{lemma}
    Si \( {LP}_{x\to a}f(x)=b\) alors il y a deux possibilités : 
    \begin{enumerate}
        \item
            Soit \( f\) est définie en \( a\) et alors \( f\) y est continue,
        \item 
            soit \( f\) n'est pas définie en \( a\) et alors poser \( f(a)=b\) donne un prolongement continu.
    \end{enumerate}
\end{lemma}

\begin{proposition}     \label{PROPooNWCMooCaDMex}
    Soient \( f\) et \( g\) des fonctions \( \eR\to \eR\). Nous supposons \( {LE}_{x\to a}g(x)=\ell\) et que \( f\) admette le prolongement continu \(b\) en \( \ell\)\footnote{Cette hypothèse est équivalente à dire que \( f\) a une limite pointée \( b\) en \( \ell\), c'est-à-dire la même hypothèse que dans la proposition \ref{PROPooNWCMooCaDMex}.} Alors
    \begin{equation}
        {LE}_{x\to a}(f\circ g)(x)=b.
    \end{equation}
\end{proposition}
Bon. Woaw. La différence est énorme.

\begin{proof}
    Soit \( \epsilon>0\). Par hypothèse de prolongement continu, il existe \( \eta>0\) tel que
    \begin{equation}
        | t-\ell |<\eta\Rightarrow | f(y)-b |<\epsilon.
    \end{equation}
    Soit \( \delta>0\) tel que
    \begin{equation}
        0<| x-a |<\delta\Rightarrow | g(x)-\ell |\leq \eta.
    \end{equation}
    Avec ce \( \delta\) nous avons que \( | 0<| x-a |<\delta |\) implique \( | f\big( g(x) \big)-b |<\epsilon\).
\end{proof}

Cela est surement une raison de présenter la limite pointée chez les petits. Mais ce n'est pas une raison pour les grands, que du contraire. L'énoncé de la proposition \ref{PROPooCQZZooMiZfQE} est à peine plus compliquée que celui de \ref{PROPooCQZZooMiZfQE}, mais elle dit un peu plus alors que la démonstration est la même.

Donc non, la proposition \ref{PROPooNWCMooCaDMex} n'ajoute pas d'hypothèse par rapport à \ref{PROPooCQZZooMiZfQE}. Au contraire, elle en enlève : la proposition \ref{PROPooNWCMooCaDMex} demande pour \( g\) une limite épointée au lieu d'une limite pointée. En ce qui concerne \( f\), les hypothèses sont les mêmes. La proposition \ref{PROPooNWCMooCaDMex} concerne une classe de fonctions un peu plus grande.

Au final, la proposition «épointée» \ref{PROPooNWCMooCaDMex} est un poil plus compliquée, mais elle a une hypothèse un peu plus faible et une conclusion un peu plus faible (existence d'une limite pointée). Bref, il s'agit d'un résultat différent. Mais comme maintenant nous sommes grands, nous sommes prêts à avoir des énoncés plus compliquée pour avoir des résultats plus complets.

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Et les filtres ?}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Si vous ne savez pas ce qu'est un filtre, vous pouvez sauter ces paragraphes. Sinon, vous pouvez vous dire que le débat «limite pointée» contre «limite épointée» n'a aucun sens parce que de toutes façons, la bonne façon de définir une limite passe par des filtres.

Alors le mieux est de se demander comment on construit, à partir de la notion de filtre, le nombre \( \lim_{x\to a} f(a)\) ?

Pas de bol, ça dépend du filtre choisi. Le premier filtre auquel on pense pour trouver une définition raisonnable de la limite de \( f(x)\) quand \( x\to a\) est le filtre des voisinages de \( a\). La notion de limite associée est la limite pointée. En ce sens la limite pointée est plus naturelle que la limite épointée. Cependant «naturel» signifie souvent «le premier qui nous tombe sous la main», ce qui ne signifie pas spécialement «le plus intéressant à utiliser».

La notion de limite épointée est la limite associée au filtre des voisinages épointés. Ce n'est, certes, pas le premier filtre qui nous tombe sous la main, mais il est, au moins dans le cadre de l'étude des fonctions sur \( \eR^n\), le plus efficace; celui qui donne le plus de nouvelles informations par rapport à la continuité.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Continuité}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

La définition de fonction continue est la définition~\ref{DefOLNtrxB}. Dans le cas d'une fonction \( f\colon \eR\to \eR\), elle devient ceci.
\begin{proposition}      \label{PROPooVNGEooPwbxXP}
    La fonction \( f\colon \eR\to \eR\) est \defe{continue en $a$}{continue sur \( \eR\)} si et seulement si
    \begin{equation}
        \forall \epsilon>0,\exists \delta\text{ tel que } \big(| x-a |\leq\delta\big)\Rightarrow | f(x)-f(a) |\leq \epsilon.
    \end{equation}
\end{proposition}

Nous allons maintenant étudier quelques conséquences de la continuité sur \( \eR\).

\begin{enumerate}
\item D'abord on voit que la continuité n'a été définie qu'en un point. On peut dire que la fonction $f$ est continue \emph{en tel point donné}, mais nous n'avons pas dit ce qu'est une fonction continue \emph{dans son ensemble}.

\item
    Le théorème \ref{ThoESCaraB} nous précise que si $I$ est un intervalle de $\eR$, la fonction $f$ est continue sur $I$ si et seulement si elle est continue en chaque point de $I$.

\item Comme la définition de $f$ continue en $a$ fait intervenir $f(x)$ pour tous les $x$ pas trop loin de $a$, il faut au moins déjà que $f$ soit définie sur ces $x$. En d'autres termes, dire que $f$ est continue en $a$ demande que $f$ existe sur un intervalle autour de $a$.

Ceci couplé à la définition précédente laisse penser qu'il est surtout intéressant d'étudier les fonctions qui sont continues sur un intervalle.

\item L'intuition comme quoi une fonction continue doit pouvoir être tracée sans lever la main correspond aux fonctions continues sur des intervalles. Au moins sur l'intervalle où elle est continue, elle est traçable en un morceau.
\end{enumerate}

\begin{example}
    Il est très possible d'être continue en un seul point. Par exemple la fonction
    \begin{equation}
        f(x)=x(1-\mtu_{\eQ}(x))
    \end{equation}
    où \( \mtu_{\eQ}\) est la fonction indicatrice de \( \eQ\) dans \( \eR\).
\end{example}

\begin{proposition}     \label{PROPooUBUAooNIxjfg}
    Si \( f\colon \eR\to \eR\) est continue au point \( a\in \eR\) et si \( f(a)\neq 0\), alors il existe un voisinage de \( a\) sur lequel \( f\) ne s'annule pas.
\end{proposition}

\begin{proof}
    Si \( f \) s'annulait sur tout voisinage de \( a\) (mais pas ne \( a\) lui-même), nous aurions, pour tout \( n\) un réel
    \begin{equation}
        x_n\in B\big( a,\frac{1}{ n } \big)\setminus\{ a \}
    \end{equation}
    tel que \( f(x_n)=0\). Cela donnerait une suite \( x_n\to a\) avec \( f(x_n)\to 0\), ce qui contredit la continuité de \( f\) en \( a\) en vertu de la proposition \ref{PropFnContParSuite}\ref{ItemWJHIooMdugfu} sur la continuité séquentielle en un point.
\end{proof}

Notons que ce résultat se généralise beaucoup : si \( f\) est continue et pas égale à \( r\) en \( a\), alors elle continue à n'être pas égale à \( r\) dans un voisinage de \( a\).

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Opération sur la continuité}
%---------------------------------------------------------------------------------------------------------------------------

Nous allons démontrer maintenant une série de petits résultats qui permettent de simplifier la démonstration de la continuité de fonctions.
\begin{theorem}
Si la fonction $f$ est continue au point $a$, alors la fonction $\lambda f$ est également continue en $a$.
\end{theorem}

\begin{proof}
Soit $\epsilon>0$. Nous avons besoin d'un $\delta>0$ tel que pour chaque $x$ à moins de $\delta$ de $a$, la fonction $\lambda f$ soit à moins de $\epsilon$ de $(\lambda f)(a)=\lambda f(a)$. Étant donné que la fonction $f$ est continue en $a$, on sait déjà qu'il existe un $\delta_1$ (nous notons $\delta_1$ afin de ne pas confondre ce nombre dont on est sûr de l'existence avec le $\delta$ que nous sommes en train de chercher) tel que
\[
  (| x-a |\leq \delta_1)\Rightarrow | f(x)-f(a) |\leq \epsilon_1.
\]
Hélas, ce $\delta_1$ n'est pas celui qu'il faut faut parce que nous travaillons avec $\lambda f$ au lieu de $f$, ce qui fait qu'au lieu d'avoir $| f(x)-f(a) |$, nous avons $| \lambda f(x)-\lambda f(a) |=| \lambda |\cdot | f(x)-f(a) |$.  Ce que $\delta_1$ fait avec $(\lambda f)$, c'est
\[
  (| x-a |\leq\delta_1)\Rightarrow  | (\lambda f)(x)- (\lambda f)(a)|\leq | \lambda |\epsilon_1.
\]
Ce que nous apprend la continuité de $f$, c'est que pour chaque choix de $\epsilon_1$, on a un $\delta_1$ qui fait cette implication. Comme cela est vrai pour chaque choix de $\epsilon_1$, essayons avec $\epsilon_1=\epsilon/| \lambda |$ pour voir ce que ça donne. Nous avons donc un $\delta_1$ qui fait
\[
  (| x-a |\leq\delta_1)\Rightarrow  | (\lambda f)(x)- (\lambda f)(a)|\leq | \lambda |\epsilon_1=\epsilon.
\]
Ce $\delta_1$ est celui qu'on cherchait.
\end{proof}

\begin{theorem}
Si $f$ et $g$ sont deux fonctions continues en $a$, alors la fonction $f+g$ est également continue en $a$.
\end{theorem}

\begin{proof}
La continuité des fonctions $f$ et $g$ au point $a$ fait en sorte que pour tout choix de $\epsilon_1$ et $\epsilon_2$, il existe $\delta_1$ et $\delta_2$ tels que
\[
  (| x-a |\leq \delta_1)\Rightarrow | f(x)-f(a) |\leq \epsilon_1.
\]
et
\[
  (| x-a |\leq \delta_2)\Rightarrow | g(x)-g(a) |\leq \epsilon_2.
\]
La quantité que nous souhaitons analyser est $| f(x)+g(x)-f(a)-g(a) |$. Tout le jeu de la démonstration de la continuité est de triturer cette expression pour en tirer quelque chose en termes de $\epsilon_1$ et $\epsilon_2$. Si nous supposons avoir pris $| x-a |$ plus petit en même temps que $\delta_1$ et que $\delta_2$, nous avons
\[
| f(x)+g(x)-f(a)-g(a) |\leq| f(x)-g(x) |+| g(x)-g(a) |\leq\epsilon_1+\epsilon_2
\]
en utilisant la formule générale $| a+b |\leq | a |+| b |$. Maintenant si on choisit $\epsilon_1$ et $\epsilon_2$ tels que $\epsilon_1+\epsilon_2<\epsilon$, et les $\delta_1$, $\delta_2$ correspondants, on a
\[
| f(x)+g(x)-f(a)-g(a) |\leq\epsilon,
\]
pourvu que $| x-a |$ soit plus petit que $\delta_1$ et $\delta_2$. Le bon $\delta$ à prendre est donc le minimum de $\delta_1$ et $\delta_2$ qui eux-mêmes sont donnés par un choix de $\epsilon_1$ et $\epsilon_2$ tels que $\epsilon_1+\epsilon_2\leq\epsilon$.
\end{proof}

Pour résumer ces deux théorèmes, on dit que si $f$ et $g$ sont continues en $a$, alors la fonction $\alpha f+\beta g$ est également continue en $a$ pour tout $\alpha$, $\beta\in\eR$.

Parmi les propriétés immédiates de la continuité d'une fonction, nous avons ceci qui est souvent bien utile.

\begin{corollary}   \label{CorNNPYooMbaYZg}
Si la fonction $f$ est continue en $a$ et si $f(a)>0$, alors $f$ est positive sur un intervalle autour de $a$.
\end{corollary}

\begin{proof}
Prenons $\epsilon<f(a)$ et voyons\footnote{ici, nous insistons sur le fait que nous prenons $\epsilon$ \emph{strictement} plus petit que $f(a)$.} ce que la continuité de $f$ en $a$ nous offre : il existe un $\delta$ tel que
\[
  (| x-a |\leq \delta)\Rightarrow | f(x)-f(a) |\leq\epsilon < f(a).
\]
Nous en retenons que sur un intervalle (de largeur $\delta$), nous avons $| f(x)-f(a) |\leq f(a)$. Par hypothèse, $f(a)>0$, donc si $f(x)<0$, alors la différence $f(x)-f(a)$ donne un nombre encore plus négatif que $-f(a)$, c'est-à-dire que $| f(x)-f(a) |>f(a)$, ce qui est contraire à ce que nous venons de démontrer. D'où la conclusion que $f(x)>0$.
\end{proof}

\subsection{La fonction la moins continue du monde}
%--------------------------------------------------

Parmi les exemples un peu sales de fonctions non continues, il y a celle-ci :
\[
  \chi_{\eQ}(x)=
\begin{cases}
    1 \text{ si }x\in\eQ\\
    0 \text{ sinon.}
\end{cases}
\]
Par exemple, $\chi_{\eQ}(0)=1$, et\footnote{Pour prouver que $\sqrt{2}$ n'est pas rationnel, c'est pas trop compliqué, mais pour prouver que $\pi$ ne l'est pas non plus, il faudra encore manger de la soupe.} $\chi_{\eQ}(\pi)=\chi_{\eQ}(\sqrt{2})=0$. Malgré que $\chi_{\eQ}(0)=1$, il n'existe \emph{aucun} voisinage de $1$ sur lequel la fonction reste proche de $1$, parce que tout voisinage va contenir au moins un irrationnel. À chaque millimètre, cette fonction fait une infinité de bonds !

Cette fonction n'est donc continue nulle part.

À partir de là, nous pouvons construire la fonction suivante qui n'est continue qu'en un point :
\[
  f(x)=x\chi_{\eQ}(x)=
\begin{cases}
x\text{ si }x\in\eQ\\
0\text{ sinon.}
\end{cases}
\]
Cette fonction est continue en zéro. En effet, prenons $\delta>0$; il nous faut un $\epsilon$ tel que $| x |\leq\epsilon$ implique $f(x)\leq \delta$ parce que $f(0)=0$. Bon ben prendre simplement $\epsilon=\delta$ nous contente. Cette fonction est donc très facilement continue en zéro.

Et pourtant, dès que l'on s'écarte un tant soit peu de zéro, elle fait des bons une infinité de fois par millionième de millimètre ! Cette fonction est donc la plus discontinue du monde en tous les points saut un (zéro) où elle est une fonction continue !

\subsection{Approche topologique}
%--------------------------------

Nous avons vu que sur tout ensemble métrique, nous pouvons définir ce qu'est un ouvert : c'est un ensemble qui contient une boule ouverte autour de chacun de ses points. Quand on est dans un ensemble ouvert, on peut toujours un peu se déplacer sans sortir de l'ensemble.

Le théorème suivant est une très importante caractérisation des fonctions continues (de $\eR$ dans $\eR$) en termes de topologie, c'est-à-dire en termes d'ouverts.

\begin{theorem}     \label{ThoContInvOuvert}
Si $I$ est un intervalle ouvert contenu dans $\dom f$, alors $f$ est continue sur $I$ si et seulement si pour tout ouvert $\mO$ dans $\eR$, l'image inverse $f|_I^{^{-1}}(\mO)$ est ouvert.
\end{theorem}

Par abus de langage, nous exprimons souvent cette condition par « une fonction est continue si et seulement si l'image inverse de tout ouvert est un ouvert ».

\begin{proof}

Dans un premier temps, nous allons transformer le critère de continuité en termes de boules ouvertes, et ensuite, nous passerons à la démonstration proprement dite. Le critère de continuité de $f$ au point $x$ dit que
\begin{equation}        \label{EqDEfCOntAn}
  \forall \delta>0,\exists\,\epsilon>0\text{ tel que }\big( | x-a |< \epsilon \big)\Rightarrow| f(x)-f(a) |<\delta.
\end{equation}
Cette condition peut être exprimée sous la forme suivante :
\[
  \forall \delta>0,\exists\epsilon\text{ tel que } a\in B(x,\epsilon)\Rightarrow f(a)\in B\big( f(x),\delta \big),
\]
ou encore
\begin{equation}        \label{EqRedefContBoules}
  \forall \delta>0,\exists\epsilon\text{ tel que } f\big( B(x,\epsilon) \big)\subset B\big( f(x),\delta \big).
\end{equation}
Jusque ici, nous n'avons fait que du jeu de notations. Nous avons exprimé en termes de topologie des inégalités analytiques. La condition \eqref{EqRedefContBoules} est le plus souvent utilisée comme définition de la continuité d'une fonction en \( x\), lorsque le contexte ne demande pas de définitions plus générales. Si tel est le choix, il faut pouvoir retrouver \eqref{EqDEfCOntAn} à partir de \eqref{EqRedefContBoules}.

Passons maintenant à la démonstration proprement dite du théorème.

D'abord, supposons que $f$ est continue sur $I$, et prenons $\mO$, un ouvert quelconque. Le but est de prouver que $f|_I^{-1}(\mO)$ est ouvert. Pour cela, nous prenons un point $x_0\in f|_I^{-1}(\mO)$ et nous allons trouver un ouvert autour ce point contenu dans $f|_I^{-1}(\mO)$. Nous écrivons $y_0=f(x_0)$. évidemment, $y_0\in\mO$, donc on a une boule autour de $y_0$ qui est contenue dans $\mO$, soit donc $\delta>0$ tel que
\[
  B(y_0,\delta)\subset\mO.
\]
Par hypothèse, $f$ est continue en $x_0$, et nous pouvons donc y appliquer le critère \eqref{EqRedefContBoules}. Il existe donc $\epsilon>0$ tel que
\[
  f\big( B(x_0,\epsilon) \big)\subset B\big( f(x_0),\delta \big)\subset\mO.
\]
Cela prouve que $B(x_0,\epsilon)\subset f|_I^{-1}(\mO)$.

Dans l'autre sens, maintenant. Nous prenons $x_0\in I$ et nous voulons prouver que $f$ est continue en $x_0$, c'est-à-dire que pour tout $\delta$ nous cherchons un $\epsilon$ tel que $f\big( B(x_0,\epsilon) \big)\subset B\big( f(x_0),\delta \big)$. Oui, mais $B\big( f(x_0),\delta \big)$ est ouverte, donc par hypothèse, $f|_I^{-1}\Big( B\big( f(x_0),\delta \big) \Big)$ est ouvert, inclus dans $I$ et contient $x_0$. Donc il existe un $\epsilon$ tel que
\[
  B(x_0,\epsilon)\subset f|_I^{-1}\Big( B\big( f(x_0),\delta \big) \Big),
\]
et donc tel que
\[
  f\big( B(x_0,\epsilon) \big)\subset B\big( f(x_0),\delta \big),
\]
ce qu'il fallait prouver.
\end{proof}

\begin{lemma}   \label{LemConncontconn}
L'image d'un ensemble connexe par une fonction continue est connexe.
\end{lemma}

\begin{proof}
Nous allons encore faire la contraposée. Soit $A$ une partie de $\eR$ telle que $f(A)$ ne soit pas connexe. Nous allons prouver que $A$ elle-même n'est pas connexe. Dire que $f(A)$ n'est pas connexe, c'est dire qu'il existe $\mO_1$ et $\mO_2$, deux ouverts disjoints qui recouvrent $f(A)$. Je prétends que $f^{-1}(\mO_1)$ et $f^{-1}(\mO_2)$ sont ouverts, disjoints et qu'ils recouvrent $A$.
\begin{itemize}
\item Ces deux ensembles sont ouverts parce qu'ils sont images inverses d'ouverts par une fonction continue (théorème~\ref{ThoContInvOuvert}).
\item Si $x\in f^{-1}(\mO_1)\cap f^{-1}(\mO_2)$, alors $f(x)\in \mO_1\cap\mO_2$, ce qui contredirait le fait que $\mO_1$ et $\mO_2$ sont disjoints. Il n'y a donc pas d'éléments dans l'intersection de $f^{-1}(\mO_1)$ et de $f^{-1}(\mO_2)$.
\item Si $f^{-1}(\mO_1)$ et $f^{-1}(\mO_2)$ ne recouvrent pas $A$, il existe un $x$ dans $A$ qui n'est dans aucun des deux. Dans ce cas, $f(x)$ est dans $f(A)$, mais n'est ni dans $\mO_1$, ni dans $\mO_2$, ce qui contredirait le fait que ces deux derniers recouvrent $f(A)$.
\end{itemize}
Nous déduisons que $A$ n'est pas connexe. Et donc le lemme.
\end{proof}

\begin{theorem}[Théorème des valeurs intermédiaires]        \label{ThoValInter}
    Soit $f$, une fonction continue sur $[a,b]$, et supposons que $f(a)<f(b)$. Alors pour tout $y$ tel que $f(a)\leq y\leq f(b)$, il existe un \( x\in\mathopen[ a , b \mathclose]\) tel que $f(x)=y$.
\end{theorem}
\index{connexité!théorème des valeurs intermédiaires}
\index{théorème!valeurs intermédiaires}

\begin{proof}
Nous savons que $[a,b]$ est connexe parce que c'est un intervalle (proposition~\ref{PropInterssiConn}). Donc $f\big( [a,b] \big)$ est connexe (lemme~\ref{LemConncontconn}) et donc est un intervalle (à nouveau la proposition~\ref{PropInterssiConn}). Étant donné que $f\big( [a,b] \big)$ est un intervalle, il contient toutes les valeurs intermédiaires entre n'importe quels deux de ses éléments. En particulier toutes les valeurs intermédiaires entre $f(a)$ et $f(b)$.
\end{proof}

\begin{corollary}       \label{CorImInterInter}
L'image d'un intervalle par une fonction continue est un intervalle.
\end{corollary}

\begin{proof}
Soient \( I\) un intervalle, \( \alpha<\beta\in f(I)\) et \( \gamma\in\mathopen] \alpha , \beta \mathclose[\). Nous considérons \(a,b\in I\) tels que \( \alpha=f(a)\) et \( \beta=f(b)\). Par le théorème des valeurs intermédiaires \ref{ThoValInter}, il existe \( t\in\mathopen] a , b \mathclose[\) tel que \( f(t)=\gamma\). Par conséquent \( \gamma\in f(I)\).
\end{proof}

\begin{corollaryDef}[Existence de la racine carrée]     \label{DEFooGQTYooORuvQb}
    Si \( x\geq 0\) alors il existe un unique \( y\geq 0\) tel que \( y^2=x\). Ce nombre est noté \( \sqrt{x}\) et est nommé \defe{racine carrée}{racine carrée} de \( x\).
\end{corollaryDef}

\begin{proof}
    La fonction \( f\colon t\mapsto t^2\) est continue et strictement croissante. Nous avons \( f(0)=0\) et\footnote{Faites deux cas suivant \( x\geq 1\) ou non si vous le voulez, moi je prends \( x+1\).} \( f(x+1)>x\). Donc le théorème des valeurs intermédiaires~\ref{ThoValInter} nous assure qu'il existe un unique \( y\in\mathopen[ 0 , x+1 \mathclose]\) tel que \( f(y)=x\).
\end{proof}

\subsection{Continuité de la racine carrée, invitation à la topologie induite}
%-----------------------------------------

Pourquoi nous intéresser particulièrement à cette fonction ? Parce qu'elle a une sale condition d'existence : son domaine de définition n'est pas ouvert. Or dans tous les théorèmes de continuité d'approche topologique que nous avons vus, nous avons donné des conditions \emph{pour tout ouvert}. Nous nous attendons donc a avoir des difficultés avec la continuité de $\sqrt{x}$ en zéro.

Prenons $I$, n'importe quel intervalle ouvert dans $\eR^+$, et voyons que la fonction\footnote{La racine carré est définie en \ref{DEFooGQTYooORuvQb}.}
\begin{equation}
\begin{aligned}
 f\colon \eR^+&\to \eR^+ \\
   x&\mapsto \sqrt{x}
\end{aligned}
\end{equation}
est continue sur $I$. Remarque déjà que si $I$ est un ouvert dans $\eR^+$, il ne peut pas contenir zéro. Avant de nous lancer dans notre propos, nous prouvons un lemme qui fera tout le travail\footnote{C'est toujours ingrat d'être un lemme : on fait tout le travail et c'est toujours le théorème qui est nommé.}.

\begin{lemma}
Soit $\mO$, un ouvert dans $\eR^+$. Alors $\mO^2=\{ x^2\tq x\in\mO \}$ est également ouvert .
\end{lemma}

\begin{proof}
Un élément de $\mO^2$ s'écrit sous la forme $x^2$ pour un certain $x\in\mO$. Le but est de trouver un ouvert autour de $x^2$ qui soit contenu dans $\mO^2$. Étant donné que $\mO$ est ouvert, on a une boule centrée en $x$ contenue dans $\mO$. Nous appelons $\delta$ le rayon de cette boule :
\[
  B(x,\delta)\subset\mO.
\]
Étant donné que cet ensemble est connexe, nous savons par le lemme~\ref{LemConncontconn} que $B(x,\delta)^2$ est également connexe (parce que la fonction $x\mapsto x^2$ est continue). Son plus grand élément est $(x+\delta)^2=x^2+\delta^2+2x\delta>x^2+\delta^2$, et son plus petit élément est $(x-\delta)^2=x^2+\delta^2-2x\delta$.

Ce qui serait pas mal, c'est que ces deux bornes entourent $x^2$; de cette façon elles définiraient un ouvert autour de $x^2$ qui soit dans $\mO^2$. Hélas, c'est pas gagné que $x^2+\delta^2-2x\delta$ soit plus petit que $x^2$.

Heureusement, en fait c'est vrai parce que d'une part, du fait que $\mO\subset\eR^+$, on a $x>0$, et d'autre part, pour que $\mO$ soit positif, il faut que $\delta<x$. Donc on a évidemment que $\delta<2x$, et donc que
\[
  x^2+\delta^2-2x\delta=x^2+\delta\underbrace{(\delta-2x)}_{<0}<x^2.
\]
Donc nous avons fini : l'ensemble
\[
  B(x,\delta)^2=]x^2+\delta^2-2x\delta,x^2+\delta^2+2x\delta[\subset\mO^2
\]
est un intervalle qui contient $x^2$, et donc qui contient une boule ouverte centrée en~$x^2$.

\end{proof}

Maintenant nous pouvons nous attaquer à la continuité de la racine carrée sur tout ouvert positif en utilisant le théorème~\ref{ThoContInvOuvert}. Soit $\mO$ n'importe quel ouvert de $\eR$, et prouvons que $f|_I^{-1}(\mO)$ est ouvert. Par définition,
\begin{equation}
  f|_I^{-1}(\mO)=\{ x\in I\tq \sqrt{x}\in\mO \}.
\end{equation}
Maintenant c'est un tout petit effort que de remarquer que $f|_I^{-1}(\mO)=\mO^2\cap I$. De là, on a gagné parce que $\mO^2$ et $I$ sont des ouverts. Or l'intersection de deux ouverts est ouvert.

Nous n'en avons pas fini avec la fonction $\sqrt{x}$. Nous avons la continuité de la racine carrée pour tous les réels strictement positifs. Il reste à pouvoir dire que la fonction est continue en zéro malgré qu'elle ne soit pas définie sur un ouvert autour de zéro.

Il est possible de dire que la racine carrée est continue en $0$, malgré qu'elle ne soit pas définie sur un ouvert autour de $0$\ldots en tout cas pas un ouvert au sens que tu as en tête. Nous allons rentabiliser un bon coup notre travail sur les espaces métriques.

Nous pouvons définir la notion de boule ouverte sur n'importe quel espace métrique $A$ en disant que
\[
  B(x,r)=\{ y\in A\tq d(x,y)<r \}.
\]
\begin{definition}      \label{DefContMetrique}
Soit $f\colon A\to B$, une application entre deux espaces métriques. Nous disons que $f$ est \defe{continue}{continue!sur espace métrique} au point $a\in A$ si $\forall \delta>0$, $\exists\epsilon>0$ tel que
\begin{equation}
  f\big( B(a,\epsilon) \big)\subset B\big( f(a),\delta \big).
\end{equation}
\end{definition}
Tu reconnais évidemment la condition \eqref{EqRedefContBoules}. Nous l'avons juste recopiée. Tu remarqueras cependant que cette définition généralise immensément la continuité que l'on avait travaillé à propos des fonctions de $\eR$ vers $\eR$. Maintenant tu peux prendre n'importe quel espace métrique et c'est bon.

Nous n'allons pas faire un tour complet des conséquences et exemples de cette définition. Au lieu de cela, nous allons juste montrer en quoi cette définition règle le problème de la continuité de la racine carrée en zéro.

La fonction que nous regardons est
\begin{equation}
\begin{aligned}
f \colon \eR^+&\to \eR^+ \\
   x&\mapsto \sqrt{x}.
\end{aligned}
\end{equation}
Mais cette fois, nous ne la voyons pas comme étant une fonction dont le domaine est une partie de $\eR$, mais comme fonction dont le domaine est $\eR^+$ vu comme un espace métrique en soi. Quelles sont les boules ouvertes dans $\eR^+$ autour de zéro ? Réponse : la boule ouverte de rayon $r$ autour de zéro dans $\eR^+$ est :
\[
  B(0,r)_{\eR^+}=\{ x\in\eR^+\tq d(x,0)<r \}=[0,r[.
\]
Cet intervalle est un ouvert. Aussi incroyable que cela puisse paraitre !

Testons la continuité de la racine carrée en zéro dans ce contexte. Il s'agit de prendre $A=\eR^+$, $B=\eR^+$ et $a=0$ dans la définition~\ref{DefContMetrique}. Nous avons que $B(\sqrt{0},\delta)=B(0,\delta)=[0,\delta[$ pour la topologie de $\eR^+$.

Il s'agit maintenant de trouver un $\epsilon$ tel que $f\big( B(0,\epsilon) \big)\subset [0,\delta[$. Par définition, nous avons que
\[
  f\big( B(0,\epsilon) \big)=[0,\sqrt{\epsilon}[,
\]
le problème revient dont à trouver $\epsilon$ tel que $\sqrt{\epsilon}\leq\delta$. Prendre $\epsilon<\delta^2$ fait l'affaire.

Donc voilà. Au sens de la topologie induite\footnote{Définition \ref{DefVLrgWDB}.}, de \( \eR\) vers $\eR^+$, nous pouvons dire que la fonction racine carrée est partout continue.

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Second degré}
%---------------------------------------------------------------------------------------------------------------------------

Nous résolvons à présent le polynôme du second degré.
\begin{proposition}[\cite{BIBooYVBZooOrTJTr}]       \label{PROPooEZIKooKjJroH}
    Soit la fonction
    \begin{equation}
        \begin{aligned}
            f\colon \eR&\to \eR \\
            x&\mapsto ax^2+bx+c 
        \end{aligned}
    \end{equation}
    avec \( a\neq 0\). Nous notons \( \Delta=b^2-4ac\).

    \begin{enumerate}
        \item       \label{ITEMooMKUSooWwNTba}
            Nous avons la formule
            \begin{equation}        \label{EQooFKPOooAbIhCx}
                f(x)=a\big( x+\frac{ b }{ 2a } \big)^2+c-\frac{ b^2 }{ 4a }.
            \end{equation}
        \item       \label{ITEMooHQTBooZuaPAs}
            Si \( a>0\), alors \( f\) a un minimum global en \( x_m=-b/2a\).
        \item       \label{ITEMooQMXVooWsqiXz}
            Si \( a<0\), alors \( f\) a un maximum global en \( x_M=-b/2a\).
        \item       \label{ITEMooMAMHooNWZVQI}
            Si \( \Delta<0\) alors \( f\) ne possède pas de racines réelles.
        \item       \label{ITEMooKUUJooTsIHhI}
            Si \( \Delta=0\), alors \( f\) possède une unique racine \( x_0=-b/2a\).
        \item       \label{ITEMooQZGFooEGhMkX}
            Si \( \Delta>0\) alors \( f\) possède exactement deux racines distinctes données par
            \begin{equation}        \label{EQooGHDPooVkqINr}
                \begin{aligned}[]
                    x_1&=\frac{ -b+\sqrt{ \Delta } }{ 2a }&x_2&=\frac{ -b-\sqrt{ \Delta } }{ 2a }.
                \end{aligned}
            \end{equation}
    \end{enumerate}
\end{proposition}

\begin{proof}
    En plusieurs parties.
    \begin{subproof}
    \item[Pour \ref{ITEMooMKUSooWwNTba}]
        C'est un calcul immédiat.
    \item[Pour \ref{ITEMooHQTBooZuaPAs}]
        Nous partons de la formule du point \ref{ITEMooMKUSooWwNTba}. Vu que \( c-\frac{ b^2 }{ 4a }\) est constant, minimiser \( f\) revient à minimiser \( x\mapsto \big( x+\frac{ b }{ 2a } \big)^2\). Comme cette dernière fonction est toujours positive, elle a un minimum global là où elle est nulle, c'est à dire en \( x_m=-b/2a\).
    \item[Pour \ref{ITEMooQMXVooWsqiXz}]
        Idem que pour \ref{ITEMooHQTBooZuaPAs}.
    \end{subproof}
    Pour la suite nous effectuons quelque manipulations à partir de \eqref{EQooFKPOooAbIhCx}. Nous avons \( f(x)=0\) lorsque
    \begin{equation}        \label{EQooRHNGooVsKRNt}
        (x+\frac{ b }{ 2a })^2=\frac{ b^2-4ac }{ 4a^2 }.
    \end{equation}
    \begin{subproof}
    \item[Pour \ref{ITEMooMAMHooNWZVQI}]
        À gauche de \eqref{EQooRHNGooVsKRNt} nous avons un nombre toujours positif ou nul. À droite, \( 4a^2>0\). Donc si \( b^2-4ac<0\), l'égalité est impossible et il n'y a pas de \( x\) vérifiant \( f(x)=0\).
    \item[Pour \ref{ITEMooKUUJooTsIHhI}]
        Si \( b^2-4ac=0\), alors la condition \eqref{EQooRHNGooVsKRNt} devient
        \begin{equation}
            \left( x+\frac{ b }{ 2a } \right)^2=0,
        \end{equation}
        et donc \( x=-b/2a\) est l'unique solution.
    \item[Pour \ref{ITEMooQZGFooEGhMkX}]
        Si \( b^2-4ac>0\), nous pouvons prendre la racine carré\footnote{Définition \ref{DEFooGQTYooORuvQb}.} des deux côtés de \eqref{EQooRHNGooVsKRNt}, et la condition devient
        \begin{equation}
            x+\frac{ b }{ 2a }=\pm\sqrt{ \frac{ b^2-4ac }{ 4a^2 } }, 
        \end{equation}
        ce qui donne
        \begin{equation}
            x=\frac{ -b\pm\sqrt{ b^2-4ac } }{ 2a }.
        \end{equation}
        Ce sont là les deux seuls candidats pour vérifier \( f(x)=0\). 

        Un calcul direct montre que
        \begin{equation}
            f\left( \frac{ -b+\sqrt{ b^2-4ac } }{ 2a } \right)=0
        \end{equation}
        et que
        \begin{equation}
            f\left( \frac{ -b-\sqrt{ b^2-4ac } }{ 2a } \right)=0.
        \end{equation}
        Donc ce sont bien des racines de \( f\) et ce sont les seules. Notez aussi qu'elles sont distinctes parce que \( \Delta\neq 0\).
    \end{subproof}
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Formes bilinéaires et quadratiques}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Plus à propos de formes bilinéaires dans le thème \ref{THEMEooOAJKooEvcCVn}.

\begin{definition}[\cite{ooUQBZooCAKfrE}]      \label{DEFooEEQGooNiPjHz}
    Soient trois espaces vectoriels \( E,F\) et \( V\) sur le même corps commutatif \( \eK\). Une application \( b\colon E\times F\to V\) est \defe{bilinéaire}{application bilinéaire} si elle est séparément linéaire en ses deux variables, c'est-à-dire si
    \begin{enumerate}
        \item 
            \( b(u_1+u_2,v)=b(u_1,v)+b(u_2,v)\),
        \item
            \( b(u,v_1+v_2)=b(u,v_1)+b(u,v_2)\)
        \item
            \( b(\lambda u,v)=b(u,\lambda v)=\lambda b(u,v)\)
    \end{enumerate}
    pour tout \( u,u_1,u_2\in E\), \( v,v_1,v_2\in F\) et pour tout \( \lambda\in \eK\).

    Dans le cas \( E=F\) et \( V=\eK\), nous parlons de \defe{forme bilinéaire}{forme!bilinéaire} sur \( E\).

    Nous parlons de forme bilinéaire \defe{symétrique}{forme bilinéaire symétrique} si de plus \( b(u,v)=b(v,u)\).
\end{definition}

\begin{normaltext}
    Une application bilinéaire \( E\times E\to \eK\) n'est pas une application linéaire; la distinction est importante. La linéarité est
    \begin{equation}
        b(\lambda u,\lambda v)= b\big( \lambda(u,v) \big)=\lambda b(u,v)
    \end{equation}
    et la bilinéarité est
    \begin{equation}
        b(\lambda u,v)=b(u,\lambda v)=\lambda b(u,v).
    \end{equation}
    En réalité la seule forme qui soit à la fois linéaire et bilinéaire est la forme identiquement nulle : la condition
    \begin{equation}
        b(\lambda u,\lambda v)=\lambda^2b(u,v)=\lambda b(u,v)
    \end{equation}
    pour tout \( \lambda\in \eK\) implique \( b(u,v)=0\).
\end{normaltext}

\begin{example}[\cite{BIBooJMSXooYUADgm}]
    L'application
    \begin{equation}
        \begin{aligned}
            b\colon \eM(n,\eK)\times \eM(n,\eK)&\to \eK \\
            (A,B)&\mapsto \trace(AB) 
        \end{aligned}
    \end{equation}
    est une forme bilinéaire symétrique.

    La vérification est un calcul :
    \begin{equation}
        \trace(BA)=\sum_{i}(BA)_{ii}=\sum_{ik}B_{ik}A_{ki}=\sum_{ik}A_{ki}A_{ik}=\sum_k(AB)_{kk}=\trace(AB).
    \end{equation}
\end{example}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Produit scalaire, produit hermitien}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{definition}[Application bilinéaire définie positive, thème~\ref{THEMEooYEVLooWotqMY}]      \label{DEFooJIAQooZkBtTy}
    Si $b$ est une application bilinéaire\footnote{Définition~\ref{DEFooEEQGooNiPjHz}.} sur un espace vectoriel \( E\) nous disons qu'elle est
    \begin{enumerate}
        \item
            \defe{définie positive}{application!définie positive} si $b(x,x)\geq 0$ pour tout $x\in E$ et $b(x,x)=0$ si et seulement si $x=0$.
        \item
            \defe{semi-définie positive}{application!semi-définie positive} si $b(x,x)\geq 0$ pour tout $x\in E$. Nous dirons aussi parfois qu'elle est simplement «positive».
        \end{enumerate}
\end{definition}
Cela est évidemment à lier à la définition~\ref{DefAWAooCMPuVM} et à la proposition \ref{PROPooUAAFooEGVDRC} : une application bilinéaire est définie positive si et seulement si sa matrice symétrique associée l'est.

\begin{definition}\label{DefVJIeTFj}
    Un \defe{produit scalaire}{produit!scalaire!en général} sur un espace vectoriel réel est une forme bilinéaire\footnote{Définition~\ref{DEFooEEQGooNiPjHz}.} symétrique strictement définie positive\footnote{Définition~\ref{DEFooJIAQooZkBtTy}.}.
\end{definition}

La définition suivante est utile pour celles qui veulent faire de la relativité\footnote{Voir le théorème \ref{THOooYHDWooWxVovH} qui établit les transformations de Lorentz.}.
\begin{definition}      \label{DEFooLPBGooXLxubc}
    Un \defe{produit pseudo-scalaire}{produit pseudo-scalaire} sur un espace vectoriel réel est une forme bilinéaire et symétrique.
\end{definition}

Vu que nous allons voir un pâté d'espaces avec des produits scalaires, nous leur donnons un nom.
\begin{definition}\label{DefLZMcvfj} 
    Un espace vectoriel \defe{euclidien}{euclidien!espace} est un espace vectoriel de dimension finie muni d'un produit scalaire (définition~\ref{DefVJIeTFj}).
\end{definition}
Avouez que c'est drôle qu'un espace vectoriel est euclidien lorsqu'il possède une \emph{multiplication} alors qu'un anneau est euclidien lorsqu'il possède une \emph{division} (voir la définition~\ref{DefAXitWRL}). C'est pas très profond, mais si ça peut vous servir de moyen mnémotechnique\ldots

\begin{definition}[\cite{ooJUXBooVrwvfP}]  \label{DefMZQxmQ}
    Soit \( E\) est un espace vectoriel sur \( \eC\). Une application \( \langle ., .\rangle \colon E\times E\to \eC\) est \defe{sesquilinéaire à droite}{sesquilinéaire} si pour tout \( x,y\in E\) et pour tout \( \lambda\in \eC\),
    \begin{enumerate}
        \item
            \( \langle \lambda x, y\rangle =\lambda\langle x,y, \rangle =\langle x, \bar\lambda y\rangle \),
        \item
            \( \langle x+y, z\rangle =\langle x, y\rangle+\langle y, z\rangle  \),
        \item
            \( \langle x, y+z\rangle =\langle x, y\rangle +\langle x, z\rangle \).
    \end{enumerate}
    Cette forme est \defe{hermitienne}{hermitienne} si de plus
    \begin{equation}
        \langle x, y\rangle =\overline{ \langle y, x\rangle  }.
    \end{equation}
    Un \defe{produit hermitien}{produit hermitien} est une forme hermitienne strictement définie positive, c'est-à-dire telle que \( \langle x, x\rangle \geq 0\) pour tout \( x\in E\) et \( \langle x, x\rangle =0\) si et seulement si \( x=0\).
\end{definition}

\begin{example}
    L'ensemble \( E=\eC^n\) vu comme espace vectoriel de dimension \( n\) sur \( \eC\)  est muni d'une forme sesquilinéaire
    \begin{equation}    \label{EqFormSesqQrjyPH}
        \langle x, y\rangle =\sum_{k=1}^nx_k\bar y_k
    \end{equation}
    pour tout \( x,y\in\eC^n\). Cela est un espace vectoriel hermitien.
\end{example}


La proposition suivante est une version plus «pragmatique» de la proposition \ref{PropXrTDIi}.
\begin{proposition}[\cite{BIBooGTTEooGCUNkM}]       \label{PROPooNITTooCYcrrT}
    Soient un espace euclidien\footnote{Qui possède un produit scalaire, définition \ref{DefLZMcvfj}.} de dimension finie \( V\) ainsi qu'un sous-espace \( M\). Nous posons
    \begin{equation}
        M^{\perp}=\{ x\in V\tq x\cdot y=0\forall y\in M \}.
    \end{equation}
    Alors \( M\oplus M^{\perp}=V\).
\end{proposition}

\begin{proof}
    D'abord si \( x\in M\cap M^{\perp}\), alors \( x\cdot x=0\) et donc \( x=0\). Donc nous avons déjà \( M\cap M^{\perp}=\{ 0 \}\). Nous considérons une base \( \{b_1,\ldots, b_k\}\) de \( M\), et nous définissons l'application linéaire
    \begin{equation}
        \begin{aligned}
            f\colon V&\to \eR^k \\
            x&\mapsto (x\cdot b_1,\ldots, x\cdot b_k). 
        \end{aligned}
    \end{equation}
    Nous avons que \( M^{\perp}=\ker(f)\). Le théorème du rang \ref{ThoGkkffA} nous indique que
    \begin{equation}
        \dim(V)=\dim\big( \ker(f) \big)+\dim\big( \Image(f) \big)\leq \dim(M^{\perp})+k=\dim(M^{\perp})+\dim(M).
    \end{equation}
    Une justification : vu que \( f\) prend ses valeurs dans \( \eR^k\), la dimension de son image est majorée par \( k\).

    Nous en déduisons que 
    \begin{equation}
        \dim(M)+\dim(M^{\perp})\geq\dim(V),
    \end{equation}
    et la proposition \ref{PROPooCASNooEqisqa} nous permet de conclure que \( M\oplus M^{\perp}=V\).
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Norme, produit scalaire et Cauchy-Schwarz (cas réel)}
%---------------------------------------------------------------------------------------------------------------------------

Dans la suite, le produit scalaire de \( x\) et \( y\) pourra être noté indifféremment par \( x\cdot y\), \( \langle x, y\rangle \) ou \( b(x,y)\) lorsque une forme bilinéaire est donnée.

Nous rappelons au passage que les espaces vectoriels réels sont susceptibles de recevoir un produit scalaire, alors que les espaces vectoriels complexes sont susceptibles de recevoir un produit hermitien. Bien que de nombreux résultats soient identiques ou très similaires, ces deux notions sont à ne pas confondre.

Nous commençons par prouver qu'un produit scalaire étant donné, nous pouvons définir une norme par la formule \( \| x \|^2=\langle x, x\rangle \). Pour cela nous aurons besoin de l'inégalité de Cauchy-Schwarz.

\begin{theorem}[Inégalité de Cauchy-Schwarz, cas réel]      \label{ThoAYfEHG}
    Soit un espace vectoriel muni d'un produit scalaire \( (x,y)\mapsto x\cdot y\). En posant\footnote{Attention à la notation : pour l'instant nous ne savons pas que c'est une norme. Ce sera justifié dans la proposition~\ref{PropEQRooQXazLz}.}
    \begin{equation}
        \| x \|=\sqrt{ x\cdot x },
    \end{equation}
    nous avons
    \begin{equation}        \label{EQooZDSHooWPcryG}
		| x\cdot y |\leq \| x \|\| y \|.
	\end{equation}
    Nous avons une égalité si et seulement si \( x\) et \( y\) sont multiples l'un de l'autre.
\end{theorem}
\index{Cauchy-Schwarz}
\index{inégalité!Cauchy-Schwarz}

\begin{proof}
	Étant donné que les deux membres de l'inéquation sont positifs, nous allons travailler en passant au carré afin d'éviter les racines carrés dans le second membre.

	Nous considérons le polynôme
	\begin{equation}
		P(t)=\| x+ty \|^2=(x+ty)\cdot(x+ty)=x\cdot x+x\cdot ty+ty\cdot x+t^2y\cdot y.
	\end{equation}
    En utilisant la bilinéarité (pour sortir les \( t\)) et la symétrique du produit scalaire, puis en ordonnant les termes selon les puissances de $t$,
	\begin{equation}
		P(t)=\| y \|^2t^2+2(x\cdot y)t+\| x \|^2.
	\end{equation}
    Cela est un polynôme du second degré en $t$ dont le signe est toujours positif (ou nul). Par la proposition \ref{PROPooEZIKooKjJroH} nous en déduisons que le fameux \( b^2-4ac\) doit être négatif ou nul. Nous avons donc
	\begin{equation}
		\Delta=4(x\cdot y)^2-4\| x \|^2\| y \|^2\leq 0,
	\end{equation}
	ce qui donne immédiatement
	\begin{equation}
		(x\cdot y)^2\leq\| x \|^2\| y \|^2.
	\end{equation}

    En ce qui concerne le cas d'égalité, si nous avons \( x\cdot y=\| x \|\| y \|\), alors le discriminant \( \Delta\) ci-dessus est nul et le polynôme \( P\) admet une racine double \( t_0\). Pour cette valeur nous avons
    \begin{equation}
        P(t_0)=| x+t_0y |=0,
    \end{equation}
    ce qui implique \( x+t_0y=0\) et donc que \( x\) et \( y\) sont liés.
\end{proof}

La proposition suivante montre que toute norme dérivant d'un produit scalaire vérifie l'identité du parallélogramme. Ce résultat sert souvent à prouver que des normes ne dérivent pas d'un produit scalaire. C'est le cas de la norme \( N(x,y)=| x |+| y |\) du lemme \ref{LEMooRWJYooOIJkZc} ainsi que du théorème de Weinersmith \ref{THOooCCMBooGulxkQ}.
\begin{proposition}[Norme dérivant d'un produit scalaire] \label{PropEQRooQXazLz}
    Si \( x,y\mapsto x\cdot y\) est un produit scalaire sur un espace vectoriel réel \( E\). Nous posons \( \| x \|=\sqrt{x\cdot x}\). Alors
    \begin{enumerate}
        \item
            L'opération \( \| . \|\) est une norme\footnote{Définition \ref{DefNorme}.}.
        \item
            Cette norme vérifie l'identité du parallélogramme :
            \begin{equation}        \label{EqYCLtWfJ}
                \| x-y \|^2+\| x+y \|^2=2\| x \|^2+2\| y \|^2.
            \end{equation}
    \end{enumerate}
\end{proposition}

\begin{proof}
    En deux parties.
    \begin{subproof}
        \item[C'est une norme]
            Nous allons nous contenter de prouver l'inégalité triangulaire. Si \( x,y\in E\) nous avons
            \begin{equation}
                \| x+y \|=\sqrt{\| x \|^2+\| y \|^2+2x\cdot y}.
            \end{equation}
            Par l'inégalité de Cauchy-Schwarz, théorème~\ref{ThoAYfEHG} nous avons aussi
            \begin{equation}
                2x\cdot y\leq 2\| x \|\| y \|.
            \end{equation}
            Nous pouvons donc majorer ce qui est dans la racine carrée :
            \begin{equation}
                \| x \|^2+\| y \|^2+2x\cdot y\leq \| x \|^2+\| y \|^2+2\| x \|\| y \|=\big( \| x \|+\| y \| \big)^2.
            \end{equation}
            En remettant les bouts ensemble,
            \begin{equation}
                \| x+y \|  =\sqrt{\| x \|^2+\| y \|^2+2x\cdot y}  \leq \sqrt{\big( \| x \|+\| y \| \big)^2}=\| x \|+\| y \|.
            \end{equation}

        \item[Inégalité du parallélogramme]
            Cette assertion est seulement un calcul :
            \begin{equation}
                \begin{aligned}[]
                    \| x-y \|^2+\| x+y \|^2&=(x-y)\cdot (x-y)+(x+y)\cdot(x+y)\\
                    &=x\cdot x-x\cdot y-y\cdot x+y\cdot y\\
                    &\quad +x\cdot x+x\cdot y+y\cdot x+y\cdot y\\
                    &=2x\cdot x+2y\cdot y\\
                    &=2\| x \|^2+2\| y \|^2.
                \end{aligned}
            \end{equation}
    \end{subproof}
\end{proof}

\begin{normaltext}
    Un produit scalaire fourni donc toujours une norme et donc une topologie. Il ne faudrait cependant pas croire que toute norme dérive d'un produit scalaire, même pas en dimension finie. Et ce, malgré l'équivalence de toutes les normes du théorème~\ref{ThoNormesEquiv} dont vous avez déjà peut-être entendu parler.
\end{normaltext}


L'intérêt du lemme suivant sera apparent en \ref{NORMooNKBCooKziIjx}.
\begin{lemma}   \label{LEMooRWJYooOIJkZc}
    Sur \( \eR^2\), l'application \( N(x,y)=| x |+| y |\) est une norme\footnote{Définition \ref{DefNorme}.} qui ne dérive pas d'un produit scalaire\footnote{La norme d'un produit scalaire est la proposition  \ref{PropEQRooQXazLz}.}.
\end{lemma}

\begin{proof}
    Nous commençons par montrer que \( N\) est une norme. Il faut vérifier les trois conditions de la définition \ref{DefNorme}.
    \begin{enumerate}
        \item
            Il faut utiliser le lemme \ref{LemooANTJooYxQZDw}\ref{ItemooNVDIooSuiSoB} dans les deux sens. Si \( (x,y)=(0,0)\), alors évidemment \( N(x,y)=0\). Dans l'autre sens, si \( N(x,y)=0\) nous avons
            \begin{equation}
                0=| x |+| y |\geq | x |.
            \end{equation}
            Donc \( | x |\leq 0\), mais comme \( | x |\geq 0\), nous avons \( | x |=0\) et donc \( x=0\). Le même raisonnement tient pour \( y\).
        \item
            En tenant compte du fait que \( | \lambda x |=| \lambda | |x |\), nous avons
            \begin{equation}
                N\big( \lambda(x,y) \big)=N(\lambda x,\lambda y)=| \lambda | |x |+| \lambda | |y |=| \lambda |(| x |+| y |)=| \lambda |N(x,y).
            \end{equation}
        \item
            Nous avons le calcul
            \begin{subequations}
                \begin{align}
                    N\big( (x,y)+(a,b) \big)&=N(x+a,y+b)\\
                    &=| x+a |+| y+b |\\
                    &\leq | x |+| a |+| y |+| b |       \label{SUBEQooIXKWooTNQFnu}\\
                    &=N(x,y)+N(a,b)
                \end{align}
            \end{subequations}
            Justification : pour \eqref{SUBEQooIXKWooTNQFnu} nous avons utilité \( | a+b |\leq | a |+| b |\), du lemme \ref{LemooANTJooYxQZDw}.
    \end{enumerate}
    Pour voir qu'elle ne dérive pas d'un produit scalaire, nous montrons qu'elle ne vérifie pas l'identité du parallélogramme de la proposition \ref{PropEQRooQXazLz}.

    Voici un petit bout de code qui nous permet de ne pas faire de recherches à la main :
    \lstinputlisting{tex/sage/sageSnip018.sage}

    Il est vite vu qu'avec \( v=(-1,1)\) et \( w=(1,1)\), l'identité du parallélogramme n'est pas vérifiée.
\end{proof}

\begin{lemma}[\cite{KXjFWKA}]   \label{LemLPOHUme}
    Soit \( V\) un espace vectoriel muni d'un produit scalaire et de la norme associée. Si \( x,y\in V\) satisfont à \( \| x+y \|=\| x \|+\| y \|\), alors il existe \( \lambda\geq 0\) tel que \( x=\lambda y\).
\end{lemma}

\begin{proof}
    Quitte à raisonner avec \( x/\| x \|\) et \( y/\| y \|\), nous supposons que \( \| x \|=\| y \|=1\). Dans ce cas l'hypothèse signifie que \( \| x+y \|^2=4\). D'autre part en écrivant la norme en termes de produit scalaire,
    \begin{equation}
        \| x+y \|^2=\| x \|^2+\| y \|^2+2\langle x, y\rangle ,
    \end{equation}
    ce qui nous mène à affirmer que \( \langle x, y\rangle =1=\| x \|\| y \|\). Nous sommes donc dans le cas d'égalité de l'inégalité de Cauchy-Schwarz\footnote{Théorème~\ref{ThoAYfEHG}.}, ce qui nous donne un \( \lambda\) tel que \( x=\lambda y\). Étant donné que \( \| x \|=\| y \|=1\) nous avons obligatoirement \( \lambda=\pm 1\), mais si \( \lambda=-1\) alors \( \langle x, y\rangle =-1\), ce qui est le contraire de ce qu'on a prétendu plus haut. Par souci de cohérence, nous allons donc croire que \( \lambda=1\).
\end{proof}

\begin{proposition}[\cite{BIBooFJROooLckBUN}]			\label{PropVectsOrthLibres}
	si $v_1,\cdots,v_k$ sont des vecteurs non nuls, orthogonaux deux à deux, alors ces vecteurs forment une famille libre.
\end{proposition}

\begin{proof}
    Soit une compbinaison linéaire nulle des \( v_i\) : \( \sum_{i=1}^k\lambda_iv_i=0\). Nous multiplions scalairement par \( v_k\) :
    \begin{equation}
        0=\sum_i\lambda_iv_k\cdot v_i=\sum_i\lambda_i\delta_{ki}\| v_i \|^2=\lambda_k\| v_k \|^2.
    \end{equation}
    Donc \( \lambda_k=0\).
\end{proof}

\begin{lemma}       \label{LEMooYXJZooWKRFRu}
    Une isométrie d'un espace euclidien fixe l'origine.
\end{lemma}

\begin{proof}
    Soit une isométrie \( f\) d'un espace euclidien : \( f(x)\cdot f(y)=x\cdot y\) pour tout \( x,y\in E\). En particulier pour \( x=0\) nous avons
    \begin{equation}
        f(0)\cdot f(y)=0
    \end{equation}
    pour tout \( y\). Vu que \( f\) est une bijection, nous avons \( f(0)\cdot x=0\) pour tout \( x\). Comme le produit scalaire est non dégénéré cela implique que \( f(0)=0\).
\end{proof}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Cauchy-Schwarz etc. cas complexe}
%---------------------------------------------------------------------------------------------------------------------------

\begin{theorem}[Inégalité de Cauchy-Schwarz, cas complexe\cite{HilbertLi}]      \label{THOooSUCBooFnpkaF}
     Soit un espace vectoriel complexe muni d'un produit hermitien \( \langle ., .\rangle \). Alors pour tout vecteurs \( x,y\) nous avons
     \begin{equation}
         | \langle x, y\rangle  |\leq \| x \|\| y \|
     \end{equation}
     où nous avons posé \( \| x \|=\sqrt{ \langle x, x\rangle  }\).
\end{theorem}

\begin{proof}
    Si \( \langle x, y\rangle =0\), le résultat est évident; nous supposons que non. Nous posons
    \begin{equation}
        \theta=\frac{ \langle x, y\rangle  }{ | \langle x, y\rangle  | }.
    \end{equation}
    C'est un élément de \( \eC\) de norme \( 1\). Nous avons
    \begin{equation}
        \langle \frac{1}{ \theta }x, y\rangle =\frac{ | \langle x, y\rangle  | }{ \langle x, y\rangle  }\langle x, y\rangle =| \langle x, y\rangle  |\geq 0
    \end{equation}
    où le symbole «\( \geq\)» signifie «est réel et positif». Nous posons \( x'=\frac{1}{ \theta }x\) et nous considérons \( t\in \eR\). Remarquons que \( \| x' \|^2=\| x \|^2\) :
    \begin{equation}
        \| x' \|^2=\langle x', x'\rangle =\frac{1}{ \theta\bar\theta }\langle x, x\rangle =\| x \|^2
    \end{equation}
    parce que \( | \theta |=1\).

    En utilisant le fait que \( \langle a, b\rangle +\langle b, a\rangle =\real(\langle a, b\rangle )\) nous avons :
    \begin{subequations}
        \begin{align}
            0\leq \| x'+ty \|^2&=\| x' \|^2+t\langle x', y\rangle +t\langle y, x'\rangle +t^2\| y \|^2\\
            &=\| y \|^2t^2+2\real(\langle x', y\rangle )t+\| x' \|^2.
        \end{align}
    \end{subequations}
    Cela est un polynôme de degré \( 2\) en \( t\) qui n'est jamais strictement négatif. Autrement dit, il a au maximum une seule racine, ce qui signifie que son discriminant est négatif ou nul :
    \begin{equation}
        \real(\langle x', y\rangle )^2-\| y \|^2\| x' \|^2\leq 0.
    \end{equation}
    Mais nous avons choisi \( x'\) de telle sorte que \( \langle x', y\rangle =| \langle x, y\rangle  |\in \eR\) et \( \| x' \|^2=\| x \|^2\); nous avons donc
    \begin{equation}
        | \langle x, y\rangle  |^2\leq \| x \|^2\| y \|^2,
    \end{equation}
    comme il se devait.
\end{proof}

\begin{proposition}[Identité du parallélogramme\cite{BIBooXLLGooAFwpyU}]       \label{PROPooSSYJooHAXAnC}
    Soit une espace vectoriel complexe \( E\) muni d'un produit hermitien \( \langle ., .\rangle \). Nous posons \( \| x \|=\sqrt{ \langle x, x\rangle  }\). Nous avons
    \begin{enumerate}
        \item
            \( \| . \|\) est une norme.
        \item
            Elle vérifie l'identité du parallélogramme :
            \begin{equation}
                \| x+y \|^2+\| x-y \|^2=2\| x \|^2+2\| b \|^2
            \end{equation}
            pour tout \( x,y\in E\).
    \end{enumerate}
\end{proposition}

\begin{proof}
    En ce qui concerne le fait que \( \| . \|\) soit une norme, tout est essentiellement dans la définition \ref{DefMZQxmQ} d'un produit hermitien. Voyons tout de même l'inégalité triangulaire. Nous avons :
    \begin{subequations}
        \begin{align}
            \| x+y \|^2&=\langle x+y, x+y\rangle\\
            &=\| x \|^2+\| y \|^2+\langle x, y\rangle +\langle y, x\rangle\\
            &=\| x \|^2+\| y \|^2+2\Re\big( \langle x, y\rangle  \big)\\
            &\leq\| x \|^2+\| y \|^2+2|\Re\big( \langle x, y\rangle  \big)|\\
            &\leq\| x \|^2+\| y \|^2+2| \langle x, y\rangle  |\\
            &\leq \| x \|^2+\| y \|^2+2\| x \|\| y \|\label{SUBEQooQGQBooMRJcUc}\\
            &=\big( \| x \|+\| y \| \big)^2.
        \end{align}
    \end{subequations}
    Pour \eqref{SUBEQooQGQBooMRJcUc} nous avons utilisé Cauchy-Schwarz \ref{THOooSUCBooFnpkaF}.
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Projection et orthogonalité}
%---------------------------------------------------------------------------------------------------------------------------

La définition du produit scalaire dans \( \eR^n\) est \ref{PROPooSKVRooDGVCYj} et le lien avec la matrice d'une application linéaire est la proposition \ref{PROPooZKWXooWmEzoA}.

\begin{remark}
    Outre l'orthogonalité, le produit scalaire permet de savoir l'angle entre deux vecteurs à travers la définition~\ref{DEFooSVDZooPWHwFQ}. D'autres interprétations géométriques du déterminant sont listées dans le thème~\ref{THMooUXJMooOroxbI}.
\end{remark}

Nous sommes maintenant en mesure de déterminer, pour deux vecteurs quelconques $u$ et $v$, la projection orthogonale de $u$ sur $v$. Ce sera le vecteur $\bar u$ parallèle à $v$ tel que $u-\bar u$ est orthogonal à $v$. Nous avons donc
\begin{equation}
    \bar u=\lambda v
\end{equation}
et
\begin{equation}
    (u-\lambda v)\cdot v=0.
\end{equation}
La seconde équation donne $u\cdot v-\lambda v\cdot v=0$, ce qui fournit $\lambda$ en fonction de $u$ et $v$ :
\begin{equation}
    \lambda=\frac{ u\cdot v }{ \| v \|^2 }.
\end{equation}
Nous avons par conséquent
\begin{equation}
    \bar u=\frac{ u\cdot v }{ \| v \|^2 }v.
\end{equation}
Armés de cette interprétation graphique du produit scalaire, nous comprenons pourquoi nous disons que deux vecteurs sont orthogonaux lorsque leur produit scalaire est nul.

Nous pouvons maintenant savoir quel est le coefficient directeur d'une droite orthogonale à une droite donnée. En effet, supposons que la première droite soit parallèle au vecteur $X$ et la seconde au vecteur $Y$. Les droites seront perpendiculaires si $X\cdot Y=0$, c'est-à-dire si
\begin{equation}
	\begin{pmatrix}
		x_1	\\
		y_1
	\end{pmatrix}\cdot\begin{pmatrix}
		y_1	\\
		y_2
	\end{pmatrix}=0.
\end{equation}
Cette équation se développe en
\begin{equation}		\label{Eqxuyukljsca}
	x_1y_1=-x_2y_2.
\end{equation}
Le coefficient directeur de la première droite est $\frac{ x_2 }{ x_1 }$. Isolons cette quantité dans l'équation \eqref{Eqxuyukljsca} :
\begin{equation}
	\frac{ x_2 }{ x_1 }=-\frac{ y_1 }{ y_2 }.
\end{equation}
Donc le coefficient directeur de la première est l'inverse et l'opposé du coefficient directeur de la seconde.

\begin{example}
	Soit la droite $d\equiv y=2x+3$. Le coefficient directeur de cette droite est $2$. Donc le coefficient directeur d'une droite perpendiculaires doit être $-\frac{ 1 }{ 2 }$.
\end{example}

\begin{proof}[Preuve alternative]
	La preuve peut également être donnée en ne faisant pas référence au produit scalaire. Il suffit d'écrire toutes les quantités en termes des coordonnées de $X$ et $Y$. Si nous posons
	\begin{equation}
		\begin{aligned}[]
			X&=\begin{pmatrix}
				x_1	\\
				x_2	\\
				x_2
			\end{pmatrix},
			&Y&=\begin{pmatrix}
				y_1	\\
				y_2	\\
				y_3
			\end{pmatrix},
		\end{aligned}
	\end{equation}
	l'inégalité à prouver devient
	\begin{equation}
		(x_1y_1+x_2y_2+x_3y_3)^2\leq (x_1^2+x_2^2+x_3^2)(y_1^2+y_2^2+y_3^2).
	\end{equation}
	Nous considérons la fonction
	\begin{equation}
		\varphi(t)=(x_1+ty_1)^2+(x_2+ty_2)^2+(x_3+ty_3)^2
	\end{equation}
	En tant que norme, cette fonction est évidemment positive pour tout $t$. En regroupant les termes de chaque puissance de $t$, nous avons
	\begin{equation}
		\varphi(t)=(y_1^2+y_2^2+y_3^2)t^2+2(x_1y_1+x_2y_2+x_3y_3)t+(x_1^2+x_2^2+x_3^2).
	\end{equation}
    Cela est un polynôme du second degré en $t$. Par conséquent le discriminant doit être négatif\footnote{Proposition \ref{PROPooEZIKooKjJroH}.}. Nous avons donc
	\begin{equation}
		4(x_1y_1+x_2y_2+x_3y_3)^2-(x_1^2+x_2^2+x_3^2)(y_1^2+y_2^2+y_3^2)\leq 0.
	\end{equation}
	La thèse en découle aussitôt.
\end{proof}

\begin{proposition}     \label{PROPooVSVMooZrqxdc}
	La norme euclidienne a les propriétés suivantes :
	\begin{enumerate}
		\item
			Pour tout vecteur $X$ et réel $\lambda$,  $\| \lambda X \|=| \lambda |\| X \|$. Attention à ne pas oublier la valeur absolue !
		\item
			Pour tout vecteurs $X$ et $Y$, $\| X+Y \|\leq \| X \|+\| Y \|$.
	\end{enumerate}
\end{proposition}

\begin{proof}
    Pour le second point, nous avons les inégalités suivantes :
	\begin{subequations}
		\begin{align}
			\| X+Y \|^2&=\| X \|^2+\| Y \|^2+2X\cdot Y\\
			&\leq\| X \|^2+\| Y \|^2+2|X\cdot Y|\\
			&\leq\| X \|^2+\| Y \|^2+2\| X \|\| Y \|\\
			&=\big( \| X \|+\| Y \| \big)^2
		\end{align}
	\end{subequations}
    Nous avons utilisé d'abord la majoration $| x |\geq x$ qui est évidente pour tout nombre $x$; et ensuite l'inégalité de Cauchy-Schwarz~\ref{ThoAYfEHG}.
\end{proof}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Théorème de Pythagore}
%---------------------------------------------------------------------------------------------------------------------------

Nous allons donner une preuve du théorème de Pythagore.

\begin{theorem}[Pythagone\cite{MonCerveau}]     \label{THOooHXHWooCpcDan}
    Soient un espace euclidien\footnote{Définition \ref{DefLZMcvfj}.} \( E\) ainsi que trois points \( a,b,c\in E\) formant un triangle rectangle en \( a\), c'est à dire tel que
    \begin{equation}        \label{EQooRAWAooBxlBcZ}
        (b-a)\cdot (a-c)=0
    \end{equation}
    Alors
    \begin{equation}
        \| b-c \|^2=\| b-a \|^2+\| a-c \|^2.
    \end{equation}
\end{theorem}

\begin{proof}
    D'abord pour développons l'hypothèse \eqref{EQooRAWAooBxlBcZ}:
    \begin{equation}
        b\cdot a-b\cdot c-\| a \|^2+a\cdot c=0,
    \end{equation}
    et nous isolons un bout qui va nous servir plus tard:
    \begin{equation}        \label{EQooWPWZooLjlVJk}
        b\cdot a+a\cdot c=b\cdot c+\| a \|^2.
    \end{equation}
    
    Maintenant nous calculons un peu :
    \begin{subequations}
        \begin{align}
            \| b-a \|^2+\| a-c \|^2&=\| b \|^2-2b\cdot a+\| a \|^2+\| a \|-2a\cdot c+\| c \|^2\\
            &=2\| a \|^2+\| b \|^2+\| c \|^2-2(b\cdot c+\| a \|^2)      \label{SUBEQooHCWXooQHpGTO}\\
            &=\| b \|^2+\| c \|^2-2b\cdot c\\
            &=\| b-c \|^2.
        \end{align}
    \end{subequations}
    Pour \eqref{SUBEQooHCWXooQHpGTO}, nous avons substitué \eqref{EQooWPWZooLjlVJk}.
\end{proof}

\begin{normaltext}
    Je profite de l'occasion pour montrer mon scepticisme quant aux preuves de Pythagore basées sur différents pliages et découpages des carrés construits sur les côtés du triangle.

    Si, comme ici, nous considérons la géométrie dans \( \eR^2\) muni de son produit scalaire, alors le théorème \ref{THOooHXHWooCpcDan} est le théorème de Pythagore et il n'est pas loin d'être la définition de la distance entre deux points. Ce serait exactement la définition pour le triangle \( A=(0,0)\), \( B=(a,0)\), \( C=(a,b)\).

    Pour autant que je le sache, la géométrie dans «le plan» (celle du collège) ne définit pas «longueur» et «aire». Donc bon \ldots Il y a peut-être un moyen de s'en sortir, mais je ne le connais pas.

    Bref, soit on se met d'accord sur les définition (et dans ce cas je serais étonné qu'il existe une démonstration de Pythagore très différente de ce qu'on a ici), soit il faudrait se calmer avec les soit-disant preuves du théorème de Pythagore.
\end{normaltext}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Produit vectoriel}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}      \label{DEFooTNTNooRjhuJZ}
	Soient $u$ et $v$, deux vecteurs de $\eR^3$. Le \defe{produit vectoriel}{produit!vectoriel} de $u$ et $v$ est le vecteur $u\times v$ défini par
    \begin{equation}        \label{EQooCUJRooFuFPaZ}
		u\times v=\det\begin{pmatrix}
			e_1	&	e_2	&	e_3	\\
			u_1	&	u_2	&	u_3	\\
			v_1	&	v_2	&	v_3
		\end{pmatrix}
    \end{equation}
	où les vecteurs $e_1$, $e_2$ et $e_3$ sont les vecteurs de la base canonique de $\eR^3$.
\end{definition}

\begin{lemma}
    Le produit vectoriel \( u\times v\) est également exprimé par
    \begin{subequations}        \label{EQSooOWGZooNYruoy}
        \begin{align}
            u\times v&=(u_2v_3-u_3v_2)e_1+(u_3v_1-u_1v_3)e_2+(u_1v_2-u_2v_1)e_3     \label{SEBEQooVROKooRpUOIr}\\
                &=\sum_{i,j,k}\epsilon_{ijk}v_iw_je_k
        \end{align}
    \end{subequations}
    où $\epsilon_{ijk}$ est défini par $\epsilon_{xyz}=1$ et ensuite $\epsilon_{ijk}$ est $1$ ou $-1$ suivant que la permutation des $x$, $y$ et $z$ est paire ou impaire. C'est-à-dire que \( \epsilon_{ijk}\) est la signature de la permutation qui amène \( (1,2,3)\) sur \( (i,j,k)\).
\end{lemma}

\begin{proof}
    Il s'agit seulement de développer explicitement le déterminant \eqref{EQooCUJRooFuFPaZ}.
\end{proof}

\begin{normaltext}
    Mettons que \( a\times b=v\). En calculant le même produit vectoriel dans la base \( f_i=-e_i\), les composantes de \( a\) et \( b\) changent de signe et la formule \eqref{EQSooOWGZooNYruoy} dit que le produit vectoriel ne change pas. On serait tenté d'écrire, dans la base \( \{ f_i \}\)
    \begin{equation}
        (-a)\times (-b)=v,
    \end{equation}
    tout en pleurant parce que dans la base des \( f_i\), le vecteur \( v\) devient \( -v\).

    Il a des personnes que cela tracasse tellement qu'on entend parler de «le produit vectoriel est une pseudo-vecteur sous \( \SO(2)\)». Les physiciens en théorie quantique des champs --pourtant la plus plaisante des matières-- sont terribles sur ce sujet.

    Il suffit d'être clair. Le produit vectoriel n'est défini que sur \( \eR^3\), et est définit par sa formule dans la base canonique, point barre. Si vous avez des vecteurs \( a\) et \( b\) dont vous connaissez les composantes dans une autre base, vous devez calculer les composantes dans la base canonique, utiliser la formule pour trouver les composantes de \( a\times b\) dans la base canonique. Ensuite, si ça vous chante, vous pouvez calculer à nouveau les composantes de \( a\times b\) dans une autre base.

    Tout cela pour dire que le produit vectoriel n'est pas une opération très généralisable. Il est possible, pour sembler plus intrinsèque, de tenter cette définition : le produit vectoriel \( a\times b\) est le vecteur perpendiculaire à \( a\) et \( b\), de longueur égale à l'aire du parallélogramme construit sur \( a\) et \( b\).

    Cette «définition» a plusieurs inconvénients.
    \begin{itemize}
        \item Elle demande quand même un produit scalaire et des aires; bref, elle demande une structure métrique,
        \item Elle ne donne pas le sens. En effet, dans \( \eR^3\), il y a deux vecteurs de longueur donnée perpendiculaires à \( a\) et \( b\). Il faut donc préciser le sens. Cela revient à donner une orientation et donc, fondamentalement, à choisir une base.
    \end{itemize}
    
    Bref, on retiendra que le produit vectoriel est une opération accrochée à \( \eR^3\) et à sa base canonique.
\end{normaltext}

\begin{lemmaDef}
    Nous avons l'égalité suivante pour tout \( u,v,w\in \eR^3\) :
    \begin{equation}        \label{EQooKJYUooSQgfXU}
        (u\times v)\cdot w=\det\begin{pmatrix}
                u_1	&	u_2	&	u_3	\\
                v_1	&	v_2	&	v_3	\\
                w_1	&	w_2	&	w_3
        \end{pmatrix}.
    \end{equation}
    Le résultat est nommé le \defe{produit mixte}{produit!mixte} de trois vecteurs de \( \eR^3\).
\end{lemmaDef}

\begin{normaltext}
    Nous avons donné un nom à la combinaison \( (u\times v)\cdot w\). J'imagine que vous voyez pourquoi nous ne considérons pas la combinaison $(u\cdot v)\times w$.
\end{normaltext}

Le lemme suivant donne un moyen compliqué et peu pratique de calculer la valeur absolue du produit mixte. La formule \eqref{EQooWZUQooYydphW} ne sera utilisée que pour faire le lien entre un jacobien et un élément de volume en dimension trois lorsque nous verrons les intégrales sur des variétés. Voir l'équation \eqref{EQooYIJSooHtkXfu}. 

\begin{lemma}[\cite{MonCerveau}]        \label{LEMooSMWNooCmEZeY}
    Le produit mixte peut également être exprimé par
    \begin{equation}        \label{EQooWZUQooYydphW}
           |(u\times v)\cdot w|^2=\det\begin{pmatrix}
            \| u \|^2    &   u\cdot v    &   u\cdot w    \\
            v\cdot u    &   \| v \|^2    &   v\cdot w    \\
            w\cdot u    &   w\cdot v    &   \| w \|^2
        \end{pmatrix}.
    \end{equation}
\end{lemma}

\begin{proof}
    Si nous notons 
    \begin{equation}
        a= \begin{pmatrix}
                u_1	&	u_2	&	u_3	\\
                v_1	&	v_2	&	v_3	\\
                w_1	&	w_2	&	w_3
        \end{pmatrix},
    \end{equation}
    il faut simplement remarquer que
    \begin{equation}
           \begin{pmatrix}
            \| u \|^2    &   u\cdot v    &   u\cdot w    \\
            v\cdot u    &   \| v \|^2    &   v\cdot w    \\
            w\cdot u    &   w\cdot v    &   \| w \|^2
        \end{pmatrix}=aa^t.
    \end{equation}
    Donc au niveau des déterminants, en utilisant les propositions \ref{PROPooHQNPooIfPEDH} et le lemme \ref{LEMooCEQYooYAbctZ} nous avons
    \begin{equation}
           \det\begin{pmatrix}
            \| u \|^2    &   u\cdot v    &   u\cdot w    \\
            v\cdot u    &   \| v \|^2    &   v\cdot w    \\
            w\cdot u    &   w\cdot v    &   \| w \|^2
        \end{pmatrix}=\det(aa^t)=\det(a)\det(a^t)=\det(a)^2.
    \end{equation}
    Et maintenant, par définition, \( \det(a)=(u\times w)\cdot w\). Donc le résultat annoncé.
\end{proof}

\begin{proposition}		 \label{PropScalMixtLin}
	Les applications produit scalaire, vectoriel et mixte sont multilinéaires. Spécifiquement, nous avons les propriétés suivantes.
	\begin{enumerate}
		\item
			Les applications produit scalaire et vectoriel sont bilinéaires. C'est-à-dire que pour tout vecteurs $a$, $b$, $c$ et pour tout nombre $\alpha$ et $\beta$ nous avons
    \begin{equation}
        \begin{aligned}[]
            a\times (\alpha b +\beta c)&=\alpha(a\times b)+\beta(a\times c)\\
            (\alpha a+\beta b)\times c&=\alpha(a\times c)+\beta(b\times c).
        \end{aligned}
    \end{equation}

        \item
            Le produit mixte est trilinéaire.
		\item
			Le produit vectoriel est antisymétrique, c'est-à-dire $u\times v=-v\times u$.
		\item
			Nous avons $u\times v=0$ si et seulement si $u$ et $v$ sont colinéaires, c'est-à-dire si et seulement si l'équation $\alpha u+\beta v=0$ a une solution différente de la solution triviale $(\alpha,\beta)=(0,0)$.
		\end{enumerate}
\end{proposition}

\begin{proposition}[Identité de Lagrange\cite{ooHFUZooGakvHi}]     \label{PROPooMXAIooJureOD}
    Si \( x,y\in \eR^n\), alors
    \begin{equation}
        \| x \|^2\| y \|^2-(x\cdot y)^2=\sum_j\sum_{i<j}(x_iy_j-x_jy_i)^2.
    \end{equation}
    Et si \( n=3\) alors
    \begin{equation}
        \| x\times y \|=\| y \|^2\| y \|^2-(x\cdot y)^2.
    \end{equation}
\end{proposition}

\begin{proof}
    C'est un calcul. D'abord nous avons
    \begin{equation}
        \| x \|^2\| y \|^2-(x\cdot y)^2=\sum_ix_i^2\sum_jy_j^2-\big( \sum_k x_ky_k  \big)^2=\sum_{ij}x_i^2y_j^2-\sum_{kl}x_ky_kx_ly_l.
    \end{equation}
    Ensuite nous coupons les sommes de la façon suivante
    \begin{equation}
        \sum_{ij}=\sum_j\sum_{i<j}+\sum_j(i=j)+\sum_j\sum_{i>j}
    \end{equation}
    pour obtenir
    \begin{equation}
        \begin{aligned}[]
            \| x \|^2\| y \|^2-(x\cdot y)^2&=\sum_j\sum_{i<j}x_i^2y_j^2+\sum_jx_j^2y_j^2+\sum_j\sum_{i>j}x_i^2y_j^2\\
                &\quad-\sum_l\sum_{k<l}x_ky_kx_ly_l-\sum_kx_k^2y_k^2-\sum_l\sum_{k>l}x_ky_kx_ly_l.
        \end{aligned}
    \end{equation}
    Il y a deux termes qui se simplifient. Notez que si \( A_{kl}\) est symétrique en \( kl\) nous avons
    \begin{equation}
        \sum_l\sum_{k<l}A_{kl}=\sum_k\sum_{l<k}A_{lk}=\sum_k\sum_{l<k}A_{kl}.
    \end{equation}
    La première égalité était seulement un renommage des indices. Le coup des indices symétriques est justement ce qu'il se passe dans les deux termes en\( x_ky_kx_ly_l\), donc nous les regroupons :
    \begin{subequations}
        \begin{align}
            \| x \|^2\| y \|^2-(x\cdot y)^2&=\sum_j\big( \sum_{i<j}x_i^2x_j^2+\sum_{i>j}x_i^2y_j^2-2\sum_{i>j}x_iy_ix_jy_j \big)\\
            &=\sum_j\sum_{i<j}(x_i^2y_j^2+x_j^2y_i^2-2x_iy_ix_jy_j)\\
            &=\sum_j\sum_{i<j}(x_iy_j-x_jy_i)^2.
        \end{align}
    \end{subequations}
    Voila qui prouve la première formule. Pour la seconde, il faut seulement poser \( n=3\) et écrire les sommes explicitement.

    \begin{itemize}
        \item 
    Pour \( j=1\), la somme sur \( i\) est \( \sum_{i<1}\), c'est-à-dire aucun termes.
\item
    Pour \( j=2\), il y a seulement \( i=1\), donc le terme \( (x_1y_2-x_2y_1)^2\).

\item
    Pour \( j=3\), il y a les termes \( i=1\) et \( i=2\), donc les termes \( (x_1y_3-x_3y_1)^2+(x_2y_3-x_3y_2)^2\).
    \end{itemize}
    Ces trois termes collectés sont justement les composants (au carré) de \( x\times y\) données dans la formule \eqref{SEBEQooVROKooRpUOIr}.
\end{proof}

Les trois vecteurs de base $e_x$, $e_y$ et $e_y$ ont des produits vectoriels faciles à retenir :
\begin{equation}
    \begin{aligned}[]
        e_x\times e_y&=e_z\\
        e_y\times e_z&=e_x\\
        e_z\times e_x&=e_y
    \end{aligned}
\end{equation}

Les deux formules suivantes, qui mêlent le produit scalaire et le produit vectoriel, sont souvent utiles en analyse vectorielle :
\begin{equation}
	\begin{aligned}[]
		(u\times v)\cdot w&=u\cdot(v\times w)\\
		(u\times v)\times w&=-(v\cdot w)u+(u\cdot w)v		\label{EqFormExpluxxx}
	\end{aligned}
\end{equation}
pour tout vecteurs $u$, $v$ et $w$ dans $\eR^3$. Nous les admettons sans démonstration. La seconde formule est parfois appelée \defe{formule d'expulsion}{formule!d'expulsion (produit vectoriel)}.

\begin{example}
    Calculons le produit vectoriel $v\times w$ avec
    \begin{equation}
        \begin{aligned}[]
            v&=\begin{pmatrix}
                3    \\
                -1    \\
                1
            \end{pmatrix}&w=\begin{pmatrix}
                1    \\
                2    \\
                -1
            \end{pmatrix}.
        \end{aligned}
    \end{equation}
    Les vecteurs s'écrivent sous la forme $v=3e_x-e_y+e_z$ et $w=e_x+2e_y-e_z$. Le produit vectoriel s'écrit
    \begin{equation}
        \begin{aligned}[]
            (3e_x-e_y+e_z)\times (e_x+2e_y-e_z)&=6e_x\times e_y-3e_x\times e_z\\
                                &\quad -e_y\times e_x + e_y\times e_z\\
                                &\quad + e_z\times e_x + 2e_z\times e_y\\
                                &=6e_z+3e_y+e_z+e_x+e_y-2e_x\\
                                &=-e_x+4e_y+7e_z.
        \end{aligned}
    \end{equation}
\end{example}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Produit mixte}
%---------------------------------------------------------------------------------------------------------------------------

Si $a$, $b$ et $c$ sont trois vecteurs, leur \defe{produit mixte}{produit!mixte} est le nombre $a\cdot(b\times c)$. En écrivant le produit vectoriel sous forme de somme de trois déterminants $2\times 2$, nous avons
\begin{equation}
    \begin{aligned}[]
        a\cdot& (b\times c)\\&=(a_1e_x+a_2e_y+a_3e_z)\cdot\left(
        \begin{vmatrix}
            b_2    &   b_3    \\
            c_2    &   c_3
        \end{vmatrix}e_x-\begin{vmatrix}
            b_1    &   b_3    \\
            c_1    &   c_3
        \end{vmatrix}e_y+\begin{vmatrix}
            b_1    &   b_2    \\
            c_1    &   c_2
        \end{vmatrix}\right)\\
        &=a_1\begin{vmatrix}
            b_2    &   b_3    \\
            c_2    &   c_3
        \end{vmatrix}-a_2\begin{vmatrix}
            b_1    &   b_3    \\
            c_1    &   c_3
        \end{vmatrix}+a_3\begin{vmatrix}
            b_1    &   b_2    \\
            c_1    &   c_2
        \end{vmatrix}\\
        &=\begin{vmatrix}
            a_1    &   a_2    &   a_3    \\
            b_1    &   b_2    &   b_3    \\
            c_1    &   c_2    &   c_3
        \end{vmatrix}.
    \end{aligned}
\end{equation}
Le produit mixte s'écrit donc sous forme d'un déterminant. Nous retenons cette formule:
\begin{equation}        \label{EqProduitMixteDet}
    a\cdot (b\times c)=\begin{vmatrix}
        a_1    &   a_2    &   a_3    \\
        b_1    &   b_2    &   b_3    \\
        c_1    &   c_2    &   c_3
    \end{vmatrix}.
\end{equation}

Un grand intérêt du produit vectoriel est qu'il fournit un vecteur qui est simultanément perpendiculaire aux deux vecteurs donnés.
\begin{proposition}     \label{PROPooTUVKooOQXKKl}
    Le produit vectoriel\footnote{Définition \ref{DEFooTNTNooRjhuJZ}.} $a\times b$ est un vecteur orthogonal à $a$ et $b$.
\end{proposition}

\begin{proof}
    Vérifions que $a\perp (a\times b)$. Pour cela, nous calculons $a\cdot (a\times b)$, c'est-à-dire le produit mixte
    \begin{equation}
        a\cdot(a\times b)=\begin{vmatrix}
            a_1    &   a_2    &   a_3    \\
            a_1    &   a_2    &   a_3    \\
            b_1    &   b_2    &   b_3
        \end{vmatrix}=0.
    \end{equation}
    L'annulation de ce déterminant est due au fait que deux de ses lignes sont égales.
\end{proof}

Ces résultats admettent une intéressante généralisation.
\begin{lemma}       \label{LEMooFRWKooVloCSM}
    Soit \( X\in \eR^n\) ainsi que \( v_1,\ldots, v_{n-1}\in \eR^n\). Alors
    \begin{enumerate}
        \item
            Nous avons
            \begin{equation}        \label{EQooMQNPooRHHBjz}
                \det(X,v_1,\ldots, v_{n-1})=X\cdot
                \det\begin{pmatrix}
                     e_1   &   \ldots    &   e_n    \\
                        &   v_1    &       \\
                        &   \vdots    &       \\
                        &   v_{n-1}    &
                 \end{pmatrix}
            \end{equation}
        \item
            Le vecteur
            \begin{equation}
                \det\begin{pmatrix}
                     e_1   &   \ldots    &   e_n    \\
                        &   v_1    &       \\
                        &   \vdots    &       \\
                        &   v_{n-1}    &
                 \end{pmatrix}
            \end{equation}
            est orthogonal à tous les \( v_i\).
    \end{enumerate}
\end{lemma}

\begin{proof}
    Vu que les deux côtés de \eqref{EQooMQNPooRHHBjz} vus comme fonctions de \( X\), sont des applications linéaires de \( \eR^n\) dans \( \eR\), il suffit de vérifier l'égalité sur une base.

    Nous posons \( \tau_i\colon \eR^n\to \eR^{n-1}\),
    \begin{equation}
        \tau_i(v)_k=\begin{cases}
            v_k    &   \text{si } k<i\\
            v_{k+1}    &    \text{si } k\geq i\text{.}
        \end{cases}
    \end{equation}
    et nous avons d'une part
    \begin{equation}
        e_k\cdot
                \det
                \begin{pmatrix}
                     e_1   &   \ldots    &   e_n    \\
                        &   v_1    &       \\
                        &   \vdots    &       \\
                        &   v_{n-1}    &
                 \end{pmatrix}
                 =\det\begin{pmatrix}
                     \tau_kv_1   \\
                     \vdots   \\
                     \tau_kv_{n-1}
                 \end{pmatrix}
            \end{equation}
     et d'autre part,
     \begin{equation}
         \det(e_k,v_1,\ldots, v_{n-1})=\det
         \begin{pmatrix}
             0&&&\\
             \vdots&&&\\
             1&v_1&\cdots&v_{n-1}\\
             \vdots&&&\\
             0&&&
         \end{pmatrix}=\det(\tau_k v_1,\ldots, \tau_k v_{n-1}).
     \end{equation}
     La première assertion est démontrée.

     En ce qui concerne la seconde, il suffit d'appliquer la première et se souvenir qu'un déterminant est nul lorsque deux lignes sont égales\footnote{Corolaire \ref{CORooAZFCooSYINvBl}.}. En effet :
     \begin{equation}
         v_k\cdot \det
                \begin{pmatrix}
                     e_1   &   \ldots    &   e_n    \\
                        &   v_1    &       \\
                        &   \vdots    &       \\
                        &   v_{n-1}    &
                 \end{pmatrix}
                 =
                 \det(v_k,v_1,\ldots, v_n)=0.
     \end{equation}
\end{proof}



%---------------------------------------------------------------------------------------------------------------------------
\subsection{Procédé de Gram-Schmidt}
%---------------------------------------------------------------------------------------------------------------------------

\begin{proposition}[Procédé de Gram-Schmidt]    \label{PropUMtEqkb}
    Un espace euclidien possède une base orthonormée.
\end{proposition}
\index{espace!euclidien}
\index{Gram-Schmidt}

\begin{proof}
    Soit \( E\) un espace euclidien et \( \{ v_1,\ldots, v_n \}\), une base quelconque de \( E\). Nous posons d'abord
    \begin{equation}
        \begin{aligned}[]
            f_1&=v_1,&e_1&=\frac{ f_1 }{ \| f_1 \| }.
        \end{aligned}
    \end{equation}
    Ensuite
    \begin{equation}
        \begin{aligned}[]
            f_2&=v_2-\langle v_2, e_1\rangle e_1,&e_2&=\frac{ f_2 }{ \| f_2 \| }.
        \end{aligned}
    \end{equation}
    Notons que \( \{ e_1,e_2 \}\) est une base de \( \Span\{ v_1,v_2 \}\). De plus elle est orthogonale :
    \begin{equation}
        \langle e_1, f_2\rangle =\langle e_1, v_2\rangle -\langle v_2, e_1\rangle \underbrace{\langle e_1, e_1\rangle}_{=1} =0.
    \end{equation}
    Le fait que \( \| e_1 \|=\| e_2 \|=1\) est par construction. Nous avons donc donné une base orthonormée de \( \Span\{ v_1,v_2 \}\).

    Nous continuons par récurrence en posant
    \begin{equation}
        \begin{aligned}[]
            f_k&=v_k-\sum_{i=1}^{k-1}\langle v_k, e_i\rangle e_i,&e_k&=\frac{ f_k }{ \| f_k \| }.
        \end{aligned}
    \end{equation}
    Pour tout \( j<k\) nous avons
    \begin{equation}
        \langle e_j, f_k\rangle =\langle e_j, v_k\rangle -\sum_{i=1}^{k-1}\langle v_k, e_i\rangle \underbrace{\langle e_i, e_j\rangle}_{=\delta_{ij}} =0
    \end{equation}
\end{proof}
Cet algorithme de Gram-Schmidt nous donne non seulement l'existence de bases orthonormée pour tout espace euclidien, mais aussi le moyen d'en construire à partir de n'importe quelle base.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Approximations}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Le lemme suivant est surtout intéressant en dimension infinie.
\begin{lemma}
    Soit un espace vectoriel normé \( V\) et un sous-espace vectoriel dense \( A\). Soit \( v\in V\); il existe une suite \( (v_n)\) dans \( A\) telle que \( v_n\stackrel{V}{\longrightarrow}v\) et \( \| v_n \|\leq \| v \|\) pour tout \( n\).
\end{lemma}

\begin{proof}
    Vu que \( A\) est dense, il existe une suite \( a_n\) dans \( A\) telle que \( a_n\to v\). Ensuite il suffit de poser
    \begin{equation}
        v_n=\frac{ n }{ n+1 }\frac{ \| v \| }{ \| a_n \| }a_n.
    \end{equation}
    Par construction nous avons toujours
    \begin{equation}
        \| v_n \|=\frac{ n }{ n+1 }\| v \|\leq \| v \|.
    \end{equation}
    Et de plus, la norme étant continue\footnote{Où dans le calcul suivant nous utilisons la continuité de la norme ? Posez-vous la question.},
    \begin{equation}
        \lim_{n\to \infty} v_n=\lim_{n\to \infty} \frac{ n }{ n+1 }\lim_{n\to \infty} \frac{ \| v \| }{ \| v_n \| }\lim_{n\to \infty} v_n=v.
    \end{equation}

    Le fait que \( v_n\) soit dans \( A\) est dû au fait que \( A\) soit vectoriel.
\end{proof}

\begin{proposition}     \label{PROPooVEMGooYKhMFy}
    Soit un espace vectoriel normé \( V\) et un sous-espace vectoriel dense \( A\). Soit \( v\in V\); pour tout \( a\in \eR\) nous avons
    \begin{equation}
        \sup\{ | v\cdot a |\tq a\in A\text{ et }\| a \|\leq \lambda \}=\lambda\| v \|.
    \end{equation}
\end{proposition}

\begin{proof}
    D'abord pour tout \( a\in A\) vérifiant \( \| a \|\leq \lambda\) l'inégalité de Cauchy-Schwarz~\ref{ThoAYfEHG} donne
    \begin{equation}
        | v\cdot a |\leq \| v \|\| a \|\leq \lambda\| v \|.
    \end{equation}
    Donc le supremum dont on parle est majoré par \( \lambda\| v \|\).

    Il nous faut l'inégalité dans l'autre sens. Par densité nous pouvons choisir une suite \( v_n\in A\) tel que \( v_n\to v\). Ensuite nous posons
    \begin{equation}
        a_n=\frac{ \lambda }{ \| v_n \| }v_n.
    \end{equation}
    Nous avons \( \| a_n \|=\lambda\) pour tout \( n\) et
    \begin{equation}
        | v\cdot a_n |=\frac{ \lambda }{ \| v_n \| }| v\cdot v_n |,
    \end{equation}
    et en passant à la limite,
    \begin{equation}
        \lim_{n\to \infty} | v\cdot a_n |=\frac{ \lambda }{ \| v \| }\| v\cdot v \|=\lambda\| v \|.
    \end{equation}
    Donc l'ensemble sur lequel nous prenons le supremum contient une suite convergente vers \( \lambda\| v \|\). Le supremum est donc au moins aussi grand que cela.
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Quelques exemples de normes sur \texorpdfstring{$\eR^n$}{Rn}}
%---------------------------------------------------------------------------------------------------------------------------

Il est possible de définir de nombreuses normes sur $\eR^n$. Citons-en quelques-unes.

\begin{propositionDef}      \label{PROPooCLZRooIRxCnZ}
    Les formules suivantes définissent des normes sur \( \eR^n\).
    \begin{enumerate}
        \item
    Les normes $\| . \|_{L^p}$ ($p\in\eN$) sont définies de la façon suivante :
    \begin{equation}		\label{EqDeformeLp}
        \| x \|_{L^p}=\Big( \sum_{i=1}^n| x_i |^p\Big)^{1/p},
    \end{equation}
    pour tout $x=(x_1,\ldots,x_n)\in\eR^n$.
\item
    La norme $L^2$ est la \defe{norme euclidienne}{norme!euclidienne}.
\item
    Nous définissons également la \defe{norme supremum}{norme!supremum} par
    \begin{equation}
	    \| x \|_{\infty}=\max_i| x_i |.
    \end{equation}
    \end{enumerate}
\end{propositionDef}

\begin{proof}
    Point par point\quext{Preuve non terminée}.
    \begin{enumerate}
        \item
            Le cas \( p=1\) est déjà fait dans le lemme \ref{LEMooRWJYooOIJkZc}.
        \item
    Le fait que \( x\mapsto\| x \|_{L^2}\) soit une norme provient de la propriété suivante :
    \begin{equation}
        \sqrt{ (a+b)^2 }\leq \sqrt{ a^2 }+\sqrt{ b^2 },
    \end{equation}
    laquelle se démontre en passant au carré :
    \begin{equation}        \label{EQooRYNYooTzZpPz}
        (a+b)^2=a^2+b^2+2ab\leq a^2+b^2+2| ab |=\big( \sqrt{ a^2 }+\sqrt{ b^2 } \big)^2.
    \end{equation}
\item
    \end{enumerate}
\end{proof}

Parmi ces normes, celles qui seront le plus souvent utilisées dans ces notes sont
\begin{equation}
	\begin{aligned}[]
		\| x \|_{L^1}&=\sum_{i=1}^n| x_i |,\\
		\| x \|_{L^2}&=\Big( \sum_{i=1}^n| x_i |^2 \Big)^{1/2}.
	\end{aligned}
\end{equation}

\newcommand{\CaptionFigDistanceEuclide}{La \emph{norme} euclidienne induit la \emph{distance} euclidienne. D'où son nom. Le point $C$ est construit aux coordonnées $(A_x,B_y)$.}
\input{auto/pictures_tex/Fig_DistanceEuclide.pstricks}

Soient $A=(A_x,A_y)$ et $B=(B_x,B_y)$ deux éléments de $\eR^2$. La distance\footnote{Ne pas confondre «distance» et «norme».} euclidienne entre $A$ et $B$ est donnée par $\| A-B \|_2$. En effet, sur la figure~\ref{LabelFigDistanceEuclide}, la distance entre les points $A$ et $B$ est donnée par
\begin{equation}
	| AB |^2=| AC |^2+| CB |^2=| A_x-B_x |^2+| A_y-B_y |^2,
\end{equation}
par conséquent,
\begin{equation}
	| AB |=\sqrt{| A_x-B_x |^2+| A_y-B_y |^2}=\| A-B \|_2.
\end{equation}

\begin{remark}
	Si $A$, $B$ et $C$ sont trois points dans le plan $\eR^2$, alors l'inégalité triangulaire $| AB |\leq| AC |+| CB |$ est précisément la propriété~\ref{ItemDefNormeiii} de la norme (définition~\ref{DefNorme}). En effet l'inégalité triangulaire s'exprime de la façon suivante en termes de la norme $\| . \|_2$ :
	\begin{equation}	\label{EqNDeuxAmBNNdd}
		\| A-B \|_2\leq \| A-C \|_2+\| C-B \|_2.
	\end{equation}
	En notant $u=A-C$ et $v=C-B$, l'équation \eqref{EqNDeuxAmBNNdd} devient exactement la propriété de définition de la norme :
	\begin{equation}
		\| u+v \|_2\leq \| u \|_2+\| v \|_2.
	\end{equation}
	Ceci explique pourquoi cette propriété des normes est appelée «inégalité triangulaire».
\end{remark}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Équivalence des normes}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\label{normes_equiv}

Au premier coup d'œil, les notions dont nous parlons dans ce chapitre ont l'air très générales. Nous prenons en effet n'importe quel espace vectoriel $V$ de dimension finie, et nous le munissons de n'importe quelle norme (rien que dans $\eR^m$ nous en avons défini une infinité par l'équation \eqref{EqDeformeLp}). À partir de ces données, nous définissons les boules, la topologie, l'adhérence, etc.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{En dimension finie}
%---------------------------------------------------------------------------------------------------------------------------

Dans $\eR^n$, les normes $\| . \|_{L^1}$, $\| . \|_{L^2}$ et $\| . \|_{\infty}$ ne sont pas égales. Cependant elles ne sont pas complètement indépendantes au sens où l'on sent bien que si un vecteur sera grand pour une norme, il sera également grand pour les autres normes; les normes «vont dans le même sens». Cette notion est précisée par le concept de norme équivalente.

\begin{definition}		\label{DefEquivNorm}
    Deux normes $N_1$ et $N_2$ sur $\eR^m$ sont \defe{\wikipedia{fr}{Norme_équivalente}{équivalentes}}{equivalence@équivalence!norme}\index{norme!équivalence}\index{équivalence!de norme} s'il existe deux nombres réels strictement positifs $k_1$ et $k_2$ tels que
	\begin{equation}
		k_1N_1(x)\leq N_2(x)\leq k_2 N_1(x),
	\end{equation}
	pour tout $x$ dans $\eR^m$. Dans ce cas nous écrivons que $N_1\sim N_2$.
\end{definition}

\begin{lemma}       \label{LEMooHAITooWdtLAN}
    La définition de norme équivalentes donne une relation d'équivalence (définition~\ref{DefHoJzMp}) sur l'ensemble des normes existantes sur $\eR^m$.
\end{lemma}

\begin{proposition} \label{PropLJEJooMOWPNi}
    Pour \( \eR^N\), nous avons les équivalences de normes $\| . \|_{L^1}\sim\| . \|_{L^2}$, $\| . \|_{L^1}\sim\| . \|_{\infty}$ et $\| . \|_{L^2}\sim\| . \|_{\infty}$. Plus précisément nous avons les inégalités\footnote{Les racines carrés sont définies en \ref{DEFooGQTYooORuvQb}.}
    \begin{enumerate}
        \item\label{ItemABSGooQODmLNi}
           $ \| x \|_2\leq \| x \|_1\leq\sqrt{n}\| x \|_2$
        \item\label{ItemABSGooQODmLNii}
            $\| x \|_{\infty}\leq \| x \|_1\leq n \| x \|_{\infty}$
        \item\label{ItemABSGooQODmLNiii}
            $\| x \|_{\infty}\leq \| x \|_2\leq \sqrt{n}\| x \|_{\infty}$
    \end{enumerate}
\end{proposition}


\begin{proof}
    En mettant au carré la première inégalité nous voyons que nous devons vérifier l'inégalité
    \begin{equation}
        | x_1 |^2+\cdots+| x_n |^2\leq\big( | x_1 |+\cdots+| x_n | \big)^2
    \end{equation}
    qui est vraie parce que le membre de droite est égal au carré de chaque terme plus les double produits. La seconde inégalité provient de l'inégalité de Cauchy-Schwarz (théorème~\ref{ThoAYfEHG}) sur les vecteurs
    \begin{equation}
        \begin{aligned}[]
            v&=\begin{pmatrix}
                1/n    \\
                \vdots    \\
                1/n
            \end{pmatrix},
            &w&=\begin{pmatrix}
                | x_1 |    \\
                \vdots    \\
                | x_n |
            \end{pmatrix}.
        \end{aligned}
    \end{equation}
    Nous trouvons
    \begin{equation}
        \frac{1}{ n }\sum_i| x_i |\leq\sqrt{n\cdot\frac{1}{ n^2 }}\sqrt{\sum_i| x_i |^2},
    \end{equation}
    et par conséquent
    \begin{equation}
        \sum_i| x_i |\leq\sqrt{n}\| x \|_2.
    \end{equation}

    La première inégalité de~\ref{ItemABSGooQODmLNiii} se démontre en remarquant que si \( a\) et \( b\) sont positifs, \( a\leq\sqrt{a^2+b}\). En appliquant cela à \( a=\max_i| x_i |\), nous avons
    \begin{equation}
        \max_i| x_i |\leq\sqrt{ | x_1 |^2+\cdots+| x_n |^2  }
    \end{equation}
    parce que \( \max_i| x_i |\) est évidemment un des termes de la somme. Pour la seconde inégalité de~\ref{ItemABSGooQODmLNiii}, nous avons
    \begin{equation}
        \sqrt{\sum_k| x_k |^2}\leq\left( \sum_k\max_i| x_i |^2 \right)^{1/2}=\sqrt{n}\| x \|_{\infty}.
    \end{equation}
    Pour obtenir cette inégalité, nous avons remplacé tous les termes \( | x_k |\) par le maximum.
\end{proof}

Pour les autres normes \( \| . \|_p\), il y a des inégalités dans \ref{THOooPPDPooJxTYIy} et \ref{CORooMBQMooWBAIIH}; voir aussi le thème \ref{THEMEooUJVXooZdlmHj}.

En réalité, toutes les normes \( \| . \|_{L^p}\) et \( \| . \|_{\infty}\) sont équivalentes et, plus généralement, nous avons le résultat suivant, très étonnant à première vue, et en réalité assez difficile à prouver :
\begin{theorem}[\cite{TrenchRealAnalisys}]		\label{ThoNormesEquiv}
	Sur un espace vectoriel de dimension finie, toutes les normes sont équivalentes.
\end{theorem}
% TODO : la preuve est à la page 583 de Trench.

\begin{corollary}       \label{CORooBRDYooLmGJDE}
    Soit \( V\) un espace vectoriel de dimension finie et \( \| . \|_1\), \( \| . \|_2\) deux normes sur \( V\). Alors l'identité \( \id\colon V\to V\) est un isomorphisme d'espace topologique \( (V,\| . \|_1)\to (V,\| . \|_2)\).

    De plus les ouverts sont les mêmes : une partie de \( V\) est ouverte dans \( (V,\| . \|_1)\) si et seulement si elle est ouverte dans \( (V,\| . \|_2)\).
\end{corollary}

\begin{normaltext}      \label{NORMooNKBCooKziIjx}
    Le lemme \ref{LEMooRWJYooOIJkZc} donnera une norme sur \( \eR^2\) qui ne dérive pas d'un produit scalaire. Vu que toutes les normes sur \( \eR^2\) produisent la même topologie (c'est le corolaire~\ref{CORooBRDYooLmGJDE}), il y a parfaitement moyen pour deux espaces vectoriels topologiques d'être isomorphes alors que l'un a une norme dérivant d'un produit scalaire et l'autre non.
\end{normaltext}

\begin{normaltext}
    Le théorème d'équivalence de norme sera utilisé pour montrer que l'ensemble des formes quadratiques non dégénérées de signature \( (p,q)\) est ouvert dans l'ensemble des formes quadratiques, proposition~\ref{PropNPbnsMd}. Plus généralement il est utilisé à chaque fois que l'on fait de la topologie sur les espaces de matrices en identifiant \( \eM(n,\eR)\) à \( \eR^{n^2}\), pour se rassurer en se disant que ce qu'on fait ne dépend pas de la norme choisie.

    Voir aussi ce qu'on en fait en \ref{NORMooDAZZooDiGFoW} pour démontrer la différentiabilité à partir des dérivées partielles.
\end{normaltext}

\begin{proposition}[\cite{MonCerveau}] \label{PROPooNTCFooEcwZwt}
    Soit un espace vectoriel \( V\) de dimension finie sur \( \eC\). Pour une base \( B= \{ e_i \}\) de \( V\) nous définissons
    \begin{equation}        \label{EQooEGXVooLASQIC}
        \| \sum_kv_ke_k \|_B= \sqrt{ \sum_k| v_k |^2 }.
    \end{equation}
    \begin{enumerate}
        \item
            La formule \eqref{EQooEGXVooLASQIC} définit une norme sur \( V\).
        \item
            Si \( B\) et \( B'\) sont des bases de \( V\), alors les topologies induites par le norme \( \| . \|_B\) et \( \| . \|_{B'}\) sont égales.
    \end{enumerate}
\end{proposition}

\begin{proof}
    Nous commençons par fixer une base \( B=\{ e_i \}_{i=1,\ldots, n}\) de \( V\). Cette base nous permet de définir
    \begin{equation}
        \begin{aligned}
            \varphi\colon V&\to \eC^n \\
            \sum_kv_ke_k&\mapsto (v_1,\ldots, v_n). 
        \end{aligned}
    \end{equation}
    Cette application linéaire permet d'écrire
    \begin{equation}
        \| v \|_V=\| \varphi(v) \|_{\eC^n}.
    \end{equation}
    À partir de là, la vérification des propriétés de la définition \ref{DefNorme} est immédiate. Par exemple :
    \begin{equation}
        \| v+w \|=\| \varphi(v+w) \|=\| \varphi(v)+\varphi(w) \|\leq \| \varphi(v) \|+\| \varphi(w) \|=\| v \|+\| w \|.
    \end{equation}

    En ce qui concerne la seconde assertion, c'est le théorème \ref{ThoNormesEquiv}.
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Contre-exemple en dimension infinie}
%---------------------------------------------------------------------------------------------------------------------------
\label{SubSecPOlynomesCE}

Lorsque nous considérons des espaces vectoriels de dimension infinie, les choses ne sons plus aussi simples. Nous voyons ici sur l'exemple de l'espace des polynômes que le théorème~\ref{ThoNormesEquiv} n'est plus valable si on enlève l'hypothèse de dimension finie.

On considère l'ensemble des fonctions polynomiales à coefficients réels sur  l'intervalle $[0,1]$.
\begin{equation}
\mathcal{P}_\eR([0,1])=\{p:[0,1]\to \eR\,|\, p : x\mapsto a_0+a_1 x +a_2 x^2 + \ldots, \, a_i\in\eR,\,\forall i\in \eN\}.
\end{equation}
Cet ensemble, muni des opérations usuelles de somme entre polynômes et multiplications par les scalaires, est un espace vectoriel.

Sur $\mathcal{P}(\eR)$ on définit les normes suivantes
\begin{equation}
\begin{aligned}
&\|p\|_\infty=\sup_{x\in[0,1]}\{p(x)\},\\
&\|p\|_1 =\int_0^1|p(x)|\, dx,\\
&\|p\|_2 =\left(\int_0^1|p(x)|^2\, dx\right)^{1/2}.\\
\end{aligned}
\end{equation}
Les inégalités suivantes sont  immédiates
\begin{equation}
\begin{aligned}
&\|p\|_1 =\int_0^1|p(x)|\, dx\leq \|p\|_\infty,\\
&\|p\|_2 =\left(\int_0^1|p(x)|^2\, dx\right)^{1/2}\leq \|p\|_\infty,\\
\end{aligned}
\end{equation}
mais la norme $\|\cdot\|_\infty$ n'est  équivalente ni à $\|\cdot\|_1$, ni à $\|\cdot\|_2$. Soit $p_k(x)= x^k$. Alors
\begin{equation}
\begin{aligned}
&\|p_k\|_\infty=1,\\
&\|p_k\|_1 =\int_0^1x^k\, dx=  \frac{1}{k+1},\\
&\|p_k\|_2 =\left(\int_0^1x^{2k}\, dx\right)^{1/2}=\sqrt{\frac{1}{2k+1}}.
\end{aligned}
\end{equation}
Pour $k\to \infty$ les normes $\|p_k\|_1$, $\|p_k\|_2$ tendent vers zéro, alors que la norme $\|p_k\|_\infty$ est constante, donc les normes ne sont pas équivalentes parce que il n'existe pas un nombre positif $m$ tel que
\begin{equation}
\begin{aligned}
& m \|p_k\|_\infty\leq \|p_k\|_1 ,\\
& m \|p_k\|_\infty\leq \|p_k\|_2 ,\\
\end{aligned}
\end{equation}
uniformément pour tout $k$ dans $\eN$.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Limite de fonctions}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Définition}
%---------------------------------------------------------------------------------------------------------------------------

La définition générale de la limite est~\ref{DefYNVoWBx}. Dans le cas de fonctions \( \eR\to \eR\), elle peut s'écrire de façon plus efficace. La proposition suivante montre comment fonctionne la limite pour une fonction définie sur tout \( \eR\).

\begin{proposition}[Caractérisation de la limite]       \label{PropAJQQooQQClfp}
	Soit une fonction $f\colon \eR\to \eR$ définie sur \( \eR\) et $a\in \eR$. La fonction \( f\) admet la limite \( \ell\) pour \( x\to a\) si et seulement si il existe un réel $\ell$ tel que pour tout \( \epsilon>0\), il existe un \( \delta>0\) tel que
	\begin{equation}\label{EqDefLimiteFonction}
		0<| x-a |<\delta\Rightarrow| f(x)-\ell |<\varepsilon.
	\end{equation}
\end{proposition}

\begin{proof}
    Il s'agit de montrer l'équivalence avec la définition~\ref{DefYNVoWBx}. Nous allons faire un usage intensif de la remarque~\ref{RemQDRooKnwKk}\ref{ITEMooUIHJooXAFaJa}.
    \begin{subproof}
    \item[Sens direct]
        Soient \( \epsilon>0\) et \( V=B(\ell,\epsilon)\). Alors il existe un voisinage \( W\) de \( a\) dans \( \eR\) tel que
        \begin{equation}
            f\big( W\setminus\{ a \} \big)\subset V.
        \end{equation}
        Soit \( \delta\) tel que \( B(a,\delta)\subset W\). Nous avons encore
        \begin{equation}
            f\big( B(a,\delta)\setminus\{ a \} \big)\subset V.
        \end{equation}
        Soit maintenant \( x\in \eR\) tel que $0<| x-a |<\delta$. Cela signifie \( x\in B(a,\delta)\setminus\{ a \}\). Pour un tel \( x\) nous avons donc \( f(x)\in B(\ell,\epsilon)\), c'est-à-dire \( | f(x)-\ell |<\epsilon\).
    \item[Dans l'autre sens]
        Soient un voisinage \( V\) de \( \ell\) et \( \epsilon>0\) tel que \( B(\ell,\epsilon)\subset V\). Nous considérons \( \delta\) tel que \( 0<| x-a |<\delta\) implique \( | f(x)-\ell |<\epsilon\).

        Avec tout cela nous posons \( W=B(x,\delta)\), et nous avons
        \begin{equation}
            f\big( W\setminus\{ a \} \big)\subset B(\ell,\alpha)\subset V.
        \end{equation}
    \end{subproof}
\end{proof}

Si aucun nombre $\ell$ ne vérifie la condition de la définition, alors on dit que la fonction n'admet pas de limite en $a$. Lorsque $f$ possède la limite $\ell$ en $a$, nous notons
\begin{equation}
	\lim_{x\to a} f(x)=\ell.
\end{equation}

La proposition suivante a déjà été démontrée dans la proposition~\ref{PropFObayrf}. Nous en donnons ici une démonstration adaptée au cas \( \eR\to \eR\).

\begin{proposition}
	Soit une fonction $f\colon D\to \eR$. Si $a$ est un point d'accumulation de $D$ et s'il existe une limite de $f$ en $a$, alors il en existe une seule.
\end{proposition}


\begin{proof}
    Nous prouvons qu'il ne peut pas exister deux nombres $\ell\neq\ell'$ vérifiant tout les deux la condition \eqref{EqDefLimiteFonction}.

	Soient $\ell$ et $\ell'$ deux limites de $f$ au point $a$. Par définition, pour tout $\varepsilon$ nous avons des nombres $\delta$ et $\delta'$ tels que
	\begin{equation}	\label{EqsContf2307Right}
		\begin{aligned}[]
			| x-a |<\delta&\Rightarrow \big| f(x)-\ell \big|<\varepsilon\\
			| x-a |<\delta'&\Rightarrow \big| f(x)-\ell' \big|<\varepsilon
		\end{aligned}
	\end{equation}
	Pour fixer les idées, supposons que $\delta<\delta'$ (le cas $\delta\geq\delta'$ se traite de la même manière).

	Étant donné que $a$ est un point d'accumulation du domaine $D$ de $f$, il existe un $x\in D$ tel que $| x-a |<\delta$. Évidemment, nous avons aussi $| x-a |<\delta'$. Les conditions \eqref{EqsContf2307Right} signifient alors que ce $x$ vérifie en même temps
	\begin{equation}
		| f(x)-\ell |<\varepsilon,
	\end{equation}
	et
	\begin{equation}
		| f(x)-\ell' |<\varepsilon.
	\end{equation}
	Afin de prouver que $\ell=\ell'$, nous allons maintenant calculer $| \ell-\ell' |$ et montrer que cette distance est plus petite que tout nombre. Nous avons (voir remarque~\ref{RemTechniqueIneqs})
	\begin{equation}	\label{EqInesq2307ellellepr}
		| \ell-\ell' |=| \ell-f(x)+f(x)-\ell' |\leq | \ell-f(x) |+| f(x)-\ell' |<\varepsilon+\varepsilon.
	\end{equation}
	En résumé, pour tout $\varepsilon>0$ nous avons
	\begin{equation}
		| \ell-\ell' |<2\varepsilon,
	\end{equation}
	et donc $| \ell-\ell' |=0$, ce qui signifie que $\ell=\ell'$.
\end{proof}

\begin{remark}		\label{RemTechniqueIneqs}
	Les inégalités \eqref{EqInesq2307ellellepr} utilisent deux techniques très classiques en analyse qu'il convient d'avoir bien compris. La première est de faire
	\begin{equation}
		| A-B |=| A-C+C-B |.
	\end{equation}
	Il s'agit d'ajouter $-C+C$ dans la norme. Évidemment, cela ne change rien.

	La seconde technique est l'inégalité
	\begin{equation}
		| A+B |\leq| A |+| B |.
	\end{equation}
\end{remark}

\begin{example}
	Considérons la fonction $f(x)=2x$, et calculons la limite $\lim_{x\to 3} f(x)$. Vu que $f(3)=6$, nous nous attendons à avoir $\ell=6$. C'est ce que nous allons prouver maintenant. Pour chaque $\varepsilon>0$ nous devons trouver un $\delta>0$ tel que $| x-3 |<\delta$ implique $| f(x)-6 |<\varepsilon$. En remplaçant $f(x)$ par sa valeur en fonction de $x$ et avec quelques manipulations nous trouvons :
	\begin{equation}
		\begin{aligned}[]
			| f(x)-6 |&<\varepsilon\\
			| 2x-6 |&<\varepsilon\\
			2| x-3 |&<\varepsilon\\
			| x-3 |&<\frac{ \varepsilon }{2}
		\end{aligned}
	\end{equation}
	Donc dès que $| x-3 |<\frac{ \varepsilon }{2}$, nous avons $| f(x)-6 |<\varepsilon$. Nous posons donc $\delta=\frac{ \varepsilon }{2}$.

	Plus généralement, nous avons $\lim_{x\to a} f(x)=2a$, et cela se prouve en étudiant $| f(x)-2a |$ exactement de la même manière.
\end{example}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Quelques règles de calcul}
%---------------------------------------------------------------------------------------------------------------------------


En plus d'être linéaire, la limite possède les deux propriétés suivantes.
\begin{proposition}     \label{PROPooDQFIooMMwxxJ}
	Si $f$ et $g$ sont deux fonctions qui admettent une limite en $a$, alors
	\begin{equation}
		\lim_{x\to a} (fg)(x)=\lim_{x\to a} f(x)\cdot\lim_{x\to a} g(x).
	\end{equation}
	Si de plus $\lim_{x\to a} g(x)\neq 0$, alors
	\begin{equation}
		\lim_{x\to a} \frac{ f(x) }{ g(x) }=\frac{ \lim_{x\to a} f(x) }{ \lim_{x\to a} g(x) }.
	\end{equation}
\end{proposition}

\begin{theorem}     \label{ThoLimLinMul}
    Si
    \begin{equation} \label{Eqhypmullimlin}
      \lim_{x\to a}f(x)=b,
    \end{equation}
    alors
    \begin{equation} \label{Eqbutmultlim}
      \lim_{x\to a}(\lambda f)(x)=\lambda b
    \end{equation}
    pour n'importe quel $\lambda\in\eR$.
\end{theorem}

\begin{proof}
Soit $\epsilon>0$. Afin de prouver la propriété \eqref{Eqbutmultlim}, il faut trouver un $\delta$ tel que pour tout $x$ dans $[a-\delta,a+\delta]$, on ait $| (\lambda f)(x)- \lambda b |\leq\epsilon$. Cette dernière inégalité est équivalente à $|\lambda|| f(x)-b |\leq\epsilon$. Nous devons donc trouver un $\delta$ tel que
\begin{equation}
| f(x)-b |\leq\frac{ \epsilon }{ | \lambda | }.
\end{equation}
soit vraie pour tout $x$ dans $[a-\delta,a+\delta]$. Mais l'hypothèse \eqref{Eqhypmullimlin} dit précisément qu'il existe un $\delta$ tel que pour tout $x$ dans $[a-\delta,a+\delta]$ on ait cette inégalité.
\end{proof}

\begin{theorem}     \label{ThoLimLin}
    Si
    \begin{subequations}
    \begin{align}
        \lim_{x\to a}f(x)&=b_1\\
        \lim_{x\to a}g(x)&=b_2,
    \end{align}
    \end{subequations}
    alors
    \begin{equation}
        \lim_{x\to a}(f+g)(x)=b_1+b_2.
    \end{equation}
\end{theorem}

\begin{proof}
    Soit $\epsilon>0$. Par hypothèse, il existe $\delta_1$ tel que
    \begin{equation}    \label{Eqfbunepsdeux}
      | f(x)-b_1 |\leq \frac{ \epsilon }{ 2 }
    \end{equation}
    dès que $| x-a |\leq\delta_1$. Il existe aussi $\delta_2$ tel que
    \begin{equation}    \label{Eqgbdeuxepsdeux}
      | g(x)-b_2 |\leq \frac{ \epsilon }{ 2 }.
    \end{equation}
    dès que $| x-a |\leq \delta_2$. Tu notes l'astuce de prendre $\epsilon/2$ dans la définition de limite pour $f$ et $g$. Maintenant, ce qu'on voudrait c'est un $\delta$ tel que l'on ait $| (f+g)(x)-(b_1+b_2) |\leq \epsilon$ dès que $| x-a |\leq \delta$. Moi je dit que $\delta=\min\{ \delta_1,\delta_2 \}$ fonctionne. En effet, en utilisant l'inégalité $| a+b |\leq | a |+| b |$, nous trouvons :
    \begin{align}
    | (f+g)(x)-(b_1+b_2) |=| (f(x)-b_1)+(g(x)-b_2) |
            \leq | f(x)-b_1 |+| g(x)-b_2 |.     \label{Eqfplusgfbun}
    \end{align}
    Comme on suppose que $| x-a |\leq\delta$, on a évidemment $| x-a |\leq\delta_1$, et donc l'équation \eqref{Eqfbunepsdeux} tient. Mais si $| x-a |\leq\delta$, on a aussi $| x-a |\leq\delta_2$, et donc l'équation  \eqref{Eqfbunepsdeux} tient également. Chacun des deux termes de \eqref{Eqfplusgfbun} est donc plus petits que $\epsilon/2$, et donc le tout est plus petit que $\epsilon$, ce qu'il fallait montrer.
\end{proof}

\begin{proposition}     \label{PROPooVLBWooVttvFK}
    La limite est linéaire : pour pour toutes fonctions $f$ et $g$ admettant une limite en $a$ et pour tout réels $\lambda$ et $\mu$.
    \begin{equation}
        \lim_{x\to a} (\lambda f+\mu g)(x)=\lambda\lim_{x\to a} f(x)+\mu\lim_{x\to a} g(x).
    \end{equation}
\end{proposition}

\begin{proof}
    Il s'agit seulement des deux propriétés des théorèmes \ref{ThoLimLinMul} et \ref{ThoLimLin}.
\end{proof}

\begin{lemma}       \label{LEMooYJGLooVBaglB}
    Soient un espace vectoriel normé \( V\) ainsi qu'une fonction \( f\colon \eR\to V\) telle que \( \lim_{t\to 0} f(t)=v\). Alors pour tout \( \lambda\in \eR\) nous avons
    \begin{equation}
        \lim_{t\to 0} f(\lambda t)=v.
    \end{equation}
\end{lemma}

\begin{proof}
    Nous utilisons la caractérisation \eqref{PropAJQQooQQClfp} de la limite. Soit \( \epsilon>0\). Soit \( \delta>0\) tel que \( \| f(t)-v \|<\epsilon\) pour tout \( | t |<\delta\). Nous considérons alors \( \delta'=\delta/| \lambda |\).

    Si \( | t |<\delta'\), alors \( | \lambda t |<\delta\) et nous avons bien \( \| f(\lambda t)-v \|<\epsilon\).
\end{proof}

\begin{proposition}[\cite{TrenchRealAnalisys}]      \label{PROPooOUPNooTrClHw}
    Soient des fonctions \( f,g\colon \eR\to \eR\) telles que \( \lim_{x\to a} f(x)=\ell\) et \( \lim_{x\to a} g(x)=\ell'\neq 0\). Alors
    \begin{equation}
        \lim_{x\to a} \frac{ f(x) }{ g(x) }=\frac{ \ell }{ \ell' }.
    \end{equation}
\end{proposition}

\begin{proof}
    Nous avons :
    \begin{equation}
        \left| \frac{ f(x) }{ g(x) }-\frac{ \ell }{ \ell' } \right| =\frac{ | \ell'f(x)-g(x)\ell | }{ |g(x)\ell| }.
    \end{equation}
    Soit \( s\), un minorant de \( | g(x) |\) sur un voisinage de \( a\); vu que la limite en \( a\) est \( \ell'\neq 0\), nous pouvons prendre par exemple \( s=\ell'/2\) : \( | g(x) |>\ell'/2\) sur \( B(a,\delta)\) dès que \( \delta\) est assez petit. Nous considérons \( x\in B(a,\delta)\). Avec cela nous avons :
    \begin{subequations}
        \begin{align}
            \left| \frac{ f(x) }{ g(x) }-\frac{ \ell }{ \ell' } \right| &=\frac{ | \ell'f(x)-g(x)\ell | }{ |g(x)\ell| }\\
            &\leq \frac{ 2 }{ | \ell'} |\left( \frac{ | \ell'f(x)-g(x)\ell | }{ | \ell' | } \right) \\
            &\leq \frac{ 2 }{ | \ell' |^2 }\big( | \ell'f(x)-\ell\ell' |+| \ell\ell'-g(x)\ell | \big)\\
            &=\frac{ 2 }{ | \ell' |^2 }\big( | \ell' | |f(x)-\ell |+| \ell | |\ell'-g(x) | \big).
        \end{align}
    \end{subequations}
    Soient \( \epsilon>0\) et \( \delta\) tel que \( | f(x)-\ell |<\epsilon\) et \( | g(x)-\ell' |<\epsilon\) pour tout \( x\in B(a,\delta)\). Avec cela nous avons
    \begin{equation}
        \left| \frac{ f(x) }{ g(x) }-\frac{ \ell }{ \ell' } \right| \leq\frac{ 2 }{ | \ell' |^2\big( | \ell' |+| \ell | \big) }\epsilon.
    \end{equation}
    D'où la limite attendue.
\end{proof}

\begin{lemma}       \label{LemLimMajorableVois}
    Si $\lim_{x\to a}f(x)=b$ avec $a$, $b\in\eR$, alors il existe un $\delta>0$ et un $M>0$ tels que
    \[
        (| x-a |\leq\delta)\Rightarrow | f(x) |\leq M.
    \]
\end{lemma}

Ce que signifie ce lemme, c'est que quand la fonction $f$ admet une limite finie en un point, alors il est possible de majorer la fonction sur un intervalle autour du point.

\begin{proof}
    Cela va être démontré par l'absurde. Supposons qu'il n'existe pas de $\delta$ ni de $M$ qui vérifient la condition. Dans ce cas, pour tout $\delta$ et pour tout $M$, il existe un $x$ tel que $| x-a |\leq\delta$ et $| f(x) |> M$. Cela est valable pour tout $M$, donc prenons par exemple $b+1000$. Donc
    \begin{equation}
    \forall\delta>0,\exists x\text{ tel que } | x-a |\leq\delta\text{ et }| f(x) |>b+1000.
    \end{equation}
    Cela signifie qu'aucun $\delta$ ne peut convenir dans la définition de $\lim_{x\to a}f(x)=b$, ce qui contredit les hypothèses.
\end{proof}

Dans le même ordre d'idée, on peut prouver que si la limite de la fonction en un point est positive, alors elle est positive autour ce ce point. Plus précisément, nous avons la
\begin{proposition} \label{PropoLimPosFPos}
    Si $f$ est une fonction telle que $\lim_{x\to a}f(x)>0$, alors il existe un voisinage de $a$ sur lequel $f$ est positive.
\end{proposition}

\begin{proof}
    Supposons que $\lim_{x\to a}f(x)=y_0$. Par la définition de la limite fait que si pour tout $x$ dans un voisinage autour de $a$, on ait $| f(x)-a |<\epsilon$. Cela est valable pour tout $\epsilon$, pourvu que le voisinage soit assez petit. Si je choisis un voisinage pour lequel $| f(x)-a |<\frac{ y_0 }{ 2 }$, alors sur ce voisinage, $f$ est positive.
\end{proof}

\begin{theorem}     \label{Tholimfgabab}
    Si
    \begin{align}
        \lim_{x\to a}f(x)&=b_1&\text{et}&&\lim_{x\to a}g(x)=b_2,
    \end{align}
    alors
    \begin{equation}
        \lim_{x\to a}(fg)(x)=b_1b_2.
    \end{equation}
\end{theorem}

\begin{proof}
    Soit $\epsilon>0$, et tentons de trouver un $\delta$ tel que $| f(x)g(x)-b_1b_2 |\leq \epsilon$ dès que $| x-a |\leq \delta$. Nous avons
    \begin{equation}    \label{EqfgbunbdeuxMin}
    \begin{split}
    | f(x)g(x)-b_1b_2 |&=|  f(x)g(x)-b_1b_2 +f(x)b_2-f(x)b_2 |\\
            &=\left|   f(x)\big( g(x)-b_2 \big)+b_2\big( f(x)-b_1 \big)    \right|\\
            &\leq \left|  f(x)\big( g(x)-b_2 \big)  \right|+\left|  b_2\big( f(x)-b_1 \big)    \right|\\
            &= | f(x) | | g(x)-b_2  |+| b_2 | |f(x)-b_1 |.
    \end{split}
    \end{equation}
    À la première ligne se trouve la subtilité de la démonstration : on ajoute et on enlève\footnote{Comme exercice, tu peux essayer de refaire la démonstration en ajoutant et enlevant $g(x)b_1$ à la place.} $f(x)b_2$. Maintenant nous savons par le lemme~\ref{LemLimMajorableVois} que pour un certain $\delta_1$, la quantité $| f(x) |$ peut être majoré par un certain $M$ dès que $| x-a |\leq \delta_1$. Prenons donc un tel $\delta_1$ et supposons que $| x-a |\leq \delta_1$. Nous savons aussi que pour n'importe quel choix de $\epsilon_2$ et $\epsilon_3$, il existe des nombres $\delta_2$ et $\delta_3$ tels que $| f(x)-b_1 |\leq \epsilon_2$ et $| g(x)-b_1 |\leq \epsilon_3$ dès que $| x-a |\leq\delta_2$ et $| x-a |\leq\delta_3$. Dans ces conditions, la dernière expression \eqref{EqfgbunbdeuxMin} se réduit à
    \begin{equation}
    | f(x)g(x)-b_1b_2 |\leq M\epsilon_2+| b_2 |\epsilon_3.
    \end{equation}
    Pour terminer la preuve, il suffit de choisir $\epsilon_2$ et $\epsilon_3$ tels que $M\epsilon_2+| b_2 |\epsilon_3\leq\epsilon$, et puis prendre $\delta=\min\{ \delta_1,\delta_2,\delta_3 \}$.

    Remettons les choses dans l'ordre. L'on se donne $\epsilon$ au départ. La première chose est de trouver un $\delta_1$ qui permet de majorer $|f(x)|$ par $M$ selon le lemme~\ref{LemLimMajorableVois}, et puis choisissons $\epsilon_2$ et $\epsilon_3$ tels que $M\epsilon_2+| b_2 |\epsilon_3\leq\epsilon$. Ensuite nous prenons, en vertu des hypothèses de limites pour $f$ et $g$, les nombres $\delta_2$ et $\delta_3$ tels que $| f(x)-b_1 |\leq \epsilon_2$ et $| g(x)-b_2 |\leq \epsilon_3$ dès que $| x-a |\leq \delta_2$ et $| x-a |\leq \delta_3$.

    Si avec tout ça on prend $\delta=\min\{ \delta_1,\delta_2,\delta_3 \}$, alors la majoration et les deux inégalités sont valables en même temps et au final
    \[
      | f(x)g(x)-b_1b_2 |\leq M\epsilon_2+b_2\epsilon_3\leq \epsilon,
    \]
    ce qu'il fallait prouver.

\end{proof}

À l'aide de ces petits résultats, nous pouvons déjà calculer pas mal de limites. Nous pouvons déjà par exemple calculer les limites de tous les polynômes en tous les nombres réels. En effet, nous savons la limite de la fonction $f(x)=x$. La fonction $x\mapsto x^2$ n'est rien d'autre que le produit de $f$ par elle-même. Donc
\[
  \lim_{x\to a}x^2=\big( \lim_{x\to a}x\big)\cdot\big( \lim_{x\to a}x \big)=a^2.
\]
De la même façon, nous trouvons facilement que
\begin{equation}
 \lim_{x\to a}x^n=a^n.
\end{equation}


%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Limite en l'infini}
%---------------------------------------------------------------------------------------------------------------------------

Non, sur \( \eR\) nous n'allons pas ajouter \( \infty\) avec la topologie d'Alexandrov de la définition \ref{PROPooHNOZooPSzKIN}. Nous n'allons pas considérer \( \hat \eR=\eR\cup\{ \infty \}\).

\begin{definition}[Droite réelle achevée\cite{ooDZRQooPpOXhY}]       \label{DEFooRUyiBSUooALDDOa}
    Nous considérons l'ensemble
    \begin{equation}
        \bar \eR=\eR\cup\{ +\infty,-\infty \}
    \end{equation}
    où \( +\infty\) et \( -\infty\) ne sont pas des éléments de \( \eR\).

    Nous mettons sur \( \bar\eR\) la relation d'ordre en prenant celle de \( \eR\) à laquelle nous ajoutons les règles
    \begin{enumerate}
        \item
            \( -\infty<x\) pour tout \( x\in\eR\cup\{ +\infty \}\)
        \item
            \( +\infty>x\) pour tout \( x\in \eR\cup\{-\infty  \}\).
    \end{enumerate}

    Nous mettons une topologie sur \( \bar\eR\) en donnant la base\footnote{Base de topologie, définition \ref{DEFooLEHPooIlNmpi}.} suivante :
    \begin{itemize}
        \item \( \mathopen] a , b \mathclose[\),
        \item \( \mathopen] a , +\infty \mathclose]\),
        \item \( \mathopen[ -\infty , b \mathclose[\)
    \end{itemize}
    pour tout réels \( a\) et \( b\).
\end{definition}

\begin{normaltext}
    En principe, la notation «\( \infty\)» est réservée à l'infini du compactifié d'Alexandrov\footnote{Le compactifié d'Alexandrov \( \hat \eR\), définition \ref{PROPooHNOZooPSzKIN}.}, et pour les infinis de la droite réelle achevée, il faudrait bien écrire «\( +\infty\)» et «\( -\infty\)». Cependant, nous allons souvent écrire \( \lim_{x\to \infty} \) au lieu de \( \lim_{x\to +\infty} \).
\end{normaltext}

\begin{lemma}[\cite{MonCerveau}]
    La topologie sur \( \eR\) induite de celle sur \( \bar \eR\) est la topologie usuelle.
\end{lemma}

\begin{proof}
    Nous notons \( \tau_{\eR}\) la topologie de \( \eR\), \( \tau_{\bar \eR}\) celle de \( \bar \eR\) et \( \tau_i\) celle induite de \( \bar \eR\) sur \( \eR\). Nous devons prouver que \( \tau_i=\tau_{\eR}\).
    
    \begin{subproof}
        \item[\( \tau_i\subset\tau_{\eR}\)]
            Un élément de \( \tau_i\) est de la forme \( \mO=\eR\cap A\) où \( A\) est un élément de \( \tau_{\bar \eR}\). Vu que \( A\) est un ouvert de \( \bar \eR\), il est une réunion d'éléments de la base de topologie\footnote{C'est la proposition \ref{DEFooLEHPooIlNmpi} qui dit ça.}; donc \( A=\bigcup_{i\in I}A_i\) où les \( A_i\) sont des trois types listés dans la définition \ref{DEFooRUyiBSUooALDDOa}.
            \begin{enumerate}
                \item
                Si \( A_i=\mathopen] a , b \mathclose[\) alors \( \eR\cap A=\mathopen] a , b \mathclose[\) est un ouvert de \( \eR\).
            \item Si \( A_i=\mathopen] a , +\infty \mathclose]\), alors \( \eR\cap A_i=\mathopen] a , +\infty \mathclose[\) est un ouvert de \( \eR\).
                \item Si \( A_i=\mathopen[ -\infty , b \mathclose[\), même chose.
            \end{enumerate}
            Donc \( \eR\cap A=\bigcup_{i\in I}(\eR\cap A_i)\) est une union d'ouverts de \( \eR\).
        \item[\( \tau_{\eR}\subset\tau_i\)]
        Vu que les \( \mathopen] a , b \mathclose[\) est une base de topologie de \( \eR\), l'ensemble \( \tau_i\) contient une base de topologie de \( \eR\) et donc contient tout \( \tau_{\eR}\).
    \end{subproof}
\end{proof}

\begin{proposition}[\cite{MonCerveau}]
    Soit une suite \( (x_k)\) dans \( \bar \eR=\eR\cup\{ \pm\infty \}\). Nous avons \( x_k\stackrel{\bar \eR}{\longrightarrow}+\infty\) si et seulement si pour tout \( M>0\) il existe un \( N>0\) tel que \( n\geq N\) implique \( x_n>M\).
\end{proposition}

\begin{proof}
    En deux parties.
    \begin{subproof}
        \item[\( \Rightarrow\)]
            Pour tout voisinage \( A\) de \( +\infty\), il existe un \( N\) tel que \( n\geq N\) implique \( x_n\in A\). Soit donc le voisinage \( \mathopen] M , +\infty \mathclose]\), et le \( N\) correspondant. Nous avons alors, pour tout \( n\geq N\), \( x_n\in \mathopen] M , +\infty \mathclose]\) et donc \( x_n\geq M\).
        \item[\( \Leftarrow\)]
        Soit un ouvert \( A\) contenant \( +\infty\). Nous avons \( A=\bigcup_{i\in I} A_i\) où les \( A_i\) sont des trois types listés dans la définition \ref{DEFooRUyiBSUooALDDOa}. Vu que \( +\infty\in A\), pour au moins un des \( i\) nous avons \( A_i=\mathopen] a , +\infty \mathclose[\).

            Prenons \( N\) tel que \( n\geq N\) implique \( x_n>a\). Alors pour \( n\geq N\) nous avons \( x_n\in A\).
    \end{subproof}
\end{proof}

\begin{lemma}       \label{LEMooFCIXooJuHFqk}
    Nous considérons l'espace topologique de la droite réelle achevée\footnote{Définition \ref{DEFooRUyiBSUooALDDOa}.} \( \bar \eR\). Si \( n\geq 1\) nous avons 
    \begin{equation}        \label{EQooRRFEooLYcuRP}
        \lim_{x\to +\infty} x^n = +\infty
    \end{equation}
    et
    \begin{equation}
        \lim_{x\to +\infty} \frac{1}{ x^n }=0.
    \end{equation}
\end{lemma}

\begin{proof}
    Si \( V\) est un voisinage de \( +\infty\), alors nous devons montrer qu'il existe un voisinage \( W\) de \( +\infty\) tel que \( x^n\in V\) pour tout \( x\in W\).   

    Un ouvert est une union d'éléments de la base de topologie\footnote{C'est la définition \ref{DEFooLEHPooIlNmpi}.}. Nous voyons que \( V\) contient au moins une partie de la forme \( \mathopen] R , +\infty \mathclose]\). Nous supposons que \( R>1\).

    Si \( x>R>1\), alors nous avons \( x^n>x\) et donc
    \begin{equation}
        x^n> x>R,
    \end{equation}
    ce qui signifie \( x\in V\).

    En prenant \( W=\mathopen] R , +\infty \mathclose]\), nous avons bien \( W^n\subset V\). Cela prouve \eqref{EQooRRFEooLYcuRP}.

    En ce qui concerne la seconde limite, la démonstration est du même type. Remarquez seulement que vous n'avez pas formellement le droit d'utiliser la proposition \ref{PROPooOUPNooTrClHw} en invoquant \( \frac{1}{ +\infty }=0\).
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Limite en des nombres}
%---------------------------------------------------------------------------------------------------------------------------

Nous posons la définition suivante.
\begin{definition}      \label{DefInfNombre}
Lorsque $a\in\eR$, on dit que la fonction $f$ \defe{tend vers l'infini quand $x$ tend vers $a$}{} si
\[
  \forall M\in\eR,\exists \delta\tq (| x-a |\leq \delta )\Rightarrow f(x)\geq M\text{ quand }x\in\dom f.
\]
\end{definition}
Cela signifie que l'on demande que dès que $x$ est assez proche de $a$ (c'est-à-dire dès que $| x-a |\leq\delta$), alors $f(x)$ est plus grand que $M$, et que l'on peut trouver un $\delta$ qui fait ça pour n'importe quel $M$. Une autre façon de le dire est que pour toute hauteur $M$, on peut trouver un intervalle de largeur $\delta$ autour de $a$\footnote{C'est-à-dire un intervalle de la forme $[a-\delta,a+\delta]$.} tel que sur cet intervalle, la fonction $f$ est toujours plus grande que $M$.

Montrons sur un dessin pourquoi je disais que la fonction $x\to 1/x$ n'est pas de ce type.


Le problème est qu'il n'existe par exemple aucun intervalle autour de $0$ sur lequel $f$ serait toujours plus grande que $10$. En effet n'importe quel intervalle autour de $0$ contient au moins un nombre négatif. Or quand $x$ est négatif, $f$ n'est certainement pas plus grande que $10$. Nous y reviendrons.

Pour l'instant, montrons que la fonction $f(x)=1/x^2$ est une fonction qui vérifie la définition~\ref{DefInfNombre}.  Avant de prendre n'importe quel $M$, prenons par exemple $100$. Nous avons besoin d'un intervalle autour de zéro sur lequel $f$ est toujours plus grande que $100$. C'est vite vu que $f(0.1)=f(-0.1)=100$, donc l'intervalle $[-\frac{ 1 }{ 10 },\frac{1}{ 10 }]$ est le bon. Partout dans cet intervalle, $f$ est plus grande que $100$. Partout ? Ben non : en $x=0$, la fonction n'est même pas définie, donc c'est un peu dur de dire qu'elle est plus grande que $100$. C'est pour cela que nous avons ajouté la condition « quand $x\in\dom f$ » dans la définition de la limite.

Prenons maintenant un $M\in\eR$ arbitraire, et trouvons un intervalle autour de $0$ sur lequel $f$ est toujours plus grande que $M$. La réponse est évidemment l'intervalle de largeur $1/\sqrt{M}$, c'est-à-dire
\[
  \left[ -\frac{ 1 }{ \sqrt{M} },\frac{ 1 }{ \sqrt{M} } \right].
\]

\subsection{Limites quand tout va bien}
%--------------------------------------

D'abord définissons ce qu'on entend par la limite d'une fonction en un point quand il n'y a aucun infini en jeu.
\begin{definition}      \label{DefLimPointSansInfini}
 On dit que la fonction $f$ \defe{tend vers $b$ quand $x$ tend vers $a$}{} si
\[
  \forall \epsilon>0,\exists\delta\tq (| x-a |\leq\delta)\Rightarrow | f(x)-b |\leq \epsilon\text{ quand }x\in\dom f.
\]
Dans ce cas, nous notons
\begin{equation}
\lim_{x\to a}f(x)=b.
\end{equation}
\end{definition}

Commençons par un exemple très simple : prouvons que $\lim_{x\to 0}x=0$. C'est donc $a=b=0$ dans la définition. Prenons $\epsilon>0$, et trouvons un intervalle autour de zéro tel que partout dans l'intervalle, $x\leq \epsilon$. Bon ben c'est clair que $\delta=\epsilon$ fonctionne.

Plus compliqué maintenant, mais toujours sans surprises.

\begin{proposition}
\[
  \lim_{x\to 0}x^2=0.
\]

\end{proposition}

\begin{proof}
Soit $\epsilon>0$. On veut un intervalle de largeur $\delta$ autour de zéro tel que $x^2$ soit plus petit que $\epsilon$ sur cet intervalle. Cette fois-ci, le $\delta$ qui fonctionne est $\delta=\sqrt{\epsilon}$. En effet un élément de l'intervalle $[-\delta,\delta]$ est un $r$ de valeur absolue plus petite ou égale à $\delta$ :
\[
| r |\leq\delta=\sqrt{\epsilon}.
\]
En prenant le carré de cette inégalité on a :
\[
  r^2\leq\epsilon,
\]
ce qu'il fallait prouver.
\end{proof}

Calculer et prouver des valeurs de limites, mêmes très simples, devient vite de l'arrachage de cheveux à essayer de trouver le bon $\delta$ en fonction de $\epsilon$ si on n'a pas quelques théorèmes généraux. Heureusement nous en avons déjà quelques uns : \ref{PROPooVLBWooVttvFK}, \ref{PROPooDQFIooMMwxxJ}, \ref{ThoLimLinMul}, \ref{ThoLimLin}, \ref{PROPooOUPNooTrClHw}.

\begin{proposition}[\cite{MonCerveau}]      \label{PROPooWXBAooAEweSF}
    Soit \( f\colon \eR^2\to \eR\) une application continue dont la variable \( y\) varie dans un compact \( I\) de \( \eR\). Alors la fonction
    \begin{equation}
        \begin{aligned}
            d\colon \eR&\to \eR \\
            x&\mapsto \sup_{y\in I} f(x,y)
        \end{aligned}
    \end{equation}
    est continue.
\end{proposition}

\begin{proof}
    Soit \( x_0\) fixé. Prouvons que \( d\) est continue en \( x_0\). Nous notons \( y_0\) la valeur de \( y\) qui réalise le maximum (par le théorème~\ref{ThoMKKooAbHaro} et le fait que les fonctions projection soient continues, lemme~\ref{LEMooHAODooYSPmvH}). Soit aussi \( \epsilon>0\) tellement fixé que même avec un tourne vis hydraulique, il ne bougerait pas. Nous considérons \( \delta\) tel que si \( \| (x,y)-(x_0,y_0) \|\leq \delta\) alors \( \| f(x,y)-f(x_0,y_0) \|<\epsilon\).

    Si \( | x-x_0 |<\delta\) alors pour \( y\) assez proche de \( y_0\) nous avons \( \| (x,y)-(x_0,y_0) \|\leq \delta\), et donc \( \| f(x,y)-f(x_0,y_0) \|\leq \epsilon \). Cela montre qu'il existe \( \delta\) tel que \( | x-x_0 |\leq \delta\) implique \( d(x)\geq d(x_0)-\epsilon\).

    Nous devons encore trouver un \( \delta\) tel que si \( | x-x_0 |\leq \delta\) alors \( d(x)\leq d(x_0)+\epsilon\). Supposons que non. Alors pour tout \( \delta\) il existe un \( x\) tel que \( | x-x_0 |\leq \delta\) et \( d(x)> d(x_0)+\epsilon\). Cela nous donne une suite \( x_i\to x_0\).

    Pour chaque \( x_i\) nous notons \( y_i\) la valeur de \( y\) qui réalise le supremum correspondant. La suite \( (y_i)\) étant contenue dans un compact nous supposons prendre une sous-suite de \( (x_i)\) telle que la suite \( (y_i)\) converge. Nous nommons \( a\) la limite (et non \( y_0\) parce que nous ne savons pas si \( y_i\to y_0\)). Pour chaque \( i\) nous avons
    \begin{equation}
        f(x_i,y_i)>\sup_{y\in I}f(x_0,y)+\epsilon.
    \end{equation}
    En prenant la limite et en utilisant la continuité de \( f\),
    \begin{equation}
        f(x_0,a)>\sup_{y\in I} f(x_0,y)+\epsilon,
    \end{equation}
    ce qui est impossible.
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Limites de fonctions}
%---------------------------------------------------------------------------------------------------------------------------

Tentons de comprendre ce que signifie qu'un nombre $\ell$ \emph{ne soit pas} la limite de $f$ lorsque $x\to a$. Il s'agit d'inverser la condition de la proposition \ref{PropHOCWooSzrMjl}\ref{ITEMooSHKNooStKGKH}. Le nombre $\ell$ n'est pas une limite de $f$ pour $x\to a$ lorsque
\begin{equation}		\label{EqCaractNonLim}
	\exists\varepsilon>0\tq\,\forall\delta>0,\,\exists x\tq 0<\| x-a \|<\delta\text{ et }\| f(x)-\ell \|>\varepsilon,
\end{equation}
c'est-à-dire qu'il existe un certain seuil $\varepsilon$ tel qu'on a beau s'approcher aussi proche qu'on veut de $a$ (distance $\delta$), on trouvera toujours un $x$ tel que $f(x)$ n'est pas $\varepsilon$-proche de $\ell$.

\begin{lemma}[Unicité de la limite]
	Si $\ell$ et $\ell'$ sont deux limites de $f(x)$ lorsque $x$ tend vers $a$, alors $\ell=\ell'$.
\end{lemma}

\begin{proof}
	Soit $\varepsilon>0$. Nous considérons $\delta$ tel que $\| f(x)-\ell \|<\varepsilon$ pour tout $x$ tel que $\| x-a \|<\delta$. De la même manière, nous prenons $\delta'$ tel que $\| x-a \|<\delta'$ implique $\| f(x)-\ell' \|<\varepsilon$. Pour les $x$ tels que $\| x-a \|$ est plus petit que $\delta$ et $\delta'$ en même temps, nous avons
	\begin{equation}
		\| \ell-\ell' \|=\| \ell-f(x)+f(x)-\ell' \|\leq\| \ell-f(x) \|+\| f(x)-\ell' \|<2\varepsilon,
	\end{equation}
	et donc $\| \ell-\ell' \|=0$ parce que c'est plus petit que $2\varepsilon$ pour tout $\varepsilon$.
\end{proof}

\begin{proposition}[\cite{MonCerveau}]  \label{PROPooKPOXooEHIXJs}
    Soient un espace vectoriel normé \( (V,\| . \|)\) et \( a\in V\). Soient encore un voisinage \( A\) de \( a\) et deux fonctions \( f,g\colon A\setminus \{ a \}\to \eR\) qui admettent une limite en \( a\). 

    Si \( f(x)\leq g(x)\) pour tout \( x\in A\setminus \{ a \}\) alors 
    \begin{equation}
        \lim_{x\to a} f(x)\leq \lim_{x\to a}f(x).
    \end{equation}
\end{proposition}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Limite à gauche et à droite}
%---------------------------------------------------------------------------------------------------------------------------

Si \( a\) est à l'intérieur du domaine de \( f\), nous savons ce que signifie \( \lim_{x\to a} f(x)\). Nous donnons également une définition des limites à gauche et à droite.

\begin{definition}
    Soient \( D\subset \eR\) et une fonction \( f\colon D\to \eR\). Si \( a\in \Adh(D)\) nous définissons la \defe{limite à droite}{limite à droite} de \( f\) en \( a\) par
    \begin{equation}        \label{EQooQKHLooMoSXVe}
        \lim_{x\to a^+} f(x)=\lim_{x\to a} \tilde f(x)
    \end{equation}
    où \( \tilde f\) est la fonction \( f\) restreinte à \( D\cap\{ x\tq x>a \}\). La limite \eqref{EQooQKHLooMoSXVe} est souvent écrite sous la forme condensée
    \begin{equation}
        \lim_{\substack{x\to a\\x>a}}f(x).
    \end{equation}
    Pour la limite à gauche c'est un peu la même chose :
    \begin{equation}
        \lim_{x\to a^-} f(x)=\lim_{\substack{x\to a\\x<a}}f(x).
    \end{equation}
\end{definition}

\begin{lemma}       \label{LEMooXJMFooCkzoVi}
Soient \( D\subset \eR\) et une fonction \( f\colon D\to \eR\). Si \( a\in \Adh(D)\) nous avons \( \lim_{x\to a^+} f(x)=\ell\) si et seulement si pour tout \( \epsilon>0\), il existe \( \delta>0\) tel que  \( x\in\mathopen] a , a+\delta \mathclose[\cap D\) implique \( f(x)\in B(\ell,\epsilon)\).
\end{lemma}

\begin{proof}
    Nous avons les équivalences entre les faits suivants, en utilisant la définition \ref{DefYNVoWBx} de la limite :
    \begin{enumerate}
        \item
            \( \lim_{x\to a^+} f(x)=\ell\)
        \item
            \( \lim_{x\to a} \tilde f(x)=\ell\)
        \item
            Pour tout \( \epsilon>0\), il existe \( \delta>0\) tel que si \( x\in B(a,\delta)\cap D\cap\{ x>a \}\) alors \( f(x)\in B(\ell,\epsilon)\)
        \item
        Pour tout \( \epsilon>0\), il existe \( \delta>0\) tel que si \( x\in \mathopen] a , a+\delta \mathclose[\cap D\) alors \( f(x)\in B(\ell,\epsilon)\)
    \end{enumerate}
\end{proof}

\begin{proposition}[\cite{ooOMWZooZvUFiG}]      \label{PROPooGDDJooDCmydE}
    Soit une fonction \( f\colon D\to \eR\) où \( D\) est une partie de \( \eR\). Si \( a\in \Adh(D)\) alors la limite \( \lim_{x\to a} f(x)\) existe si et seulement si les limites à gauche et à droite existent et sont égales. Dans ce cas nous avons égalité :
    \begin{equation}
        \lim_{x\to a} f(x)=\lim_{x\to a^+} f(x)=\lim_{x\to a^-} f(x).
    \end{equation}
\end{proposition}

\begin{proof}
    En deux parties.
    \begin{subproof}
        \item[\( \Rightarrow\)]
        Nous disons que \( \lim_{x\to a} f(x)=\ell\). Si \( V\) est un voisinage de \( \ell\), il existe un voisinage \( U\) de \( a\) tel que \( f\big( U\cap D\setminus \{ a \} \big)\subset V\). En particulier il existe un \( \delta>0\) tel que si \( x\in \mathopen] a , a+\delta \mathclose[\cap D\), alors \( | f(x)-\ell |<\epsilon\). Cela est la limite à droite (lemme \ref{LEMooXJMFooCkzoVi}).
        \item[\( \Leftarrow\)]
        Soit \( \epsilon>0\). Par la limite à droite, il existe \( \delta_1>0\) tel que \( f\big( \mathopen] a , a+\delta_1 \mathclose[\cap D \big)\subset B(\ell,\epsilon)\). La la limite à gauche, il existe \( \delta_2\) tel que \( f\big( \mathopen] a-\delta , a \mathclose[\cap D \big)\subset B(\ell,\epsilon)\)

            En prenant \( \delta=\min\{ \delta_1,\delta_2 \}\) nous avons bien \( f\big( B(a,\delta)\cap D\setminus\{ a \} \big)\subset B(\ell,\epsilon)\) comme le demande la définition de la limite.
    \end{subproof}
\end{proof}

\begin{normaltext}
    Quelques remarques à propos de la proposition \ref{PROPooGDDJooDCmydE}.
    \begin{enumerate}
        \item
    Cette proposition ne se généralise pas aux dimensions supérieures. Dans \( \eR^2\) par exemple, il ne faudrait pas croire que si les limites suivant toutes les directions existent alors la limite existe.
\item
    Cette proposition est souvent utilisée pour calculer des limites dans lesquelles arrivent des valeurs absolues. Par exemple durant la démonstration de la proposition \ref{PROPooCNDHooKRwils}.
    \end{enumerate}
\end{normaltext}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Limite en compactifié d'Alexandrov}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Nous considérons l'espace topologique localement compact \( \eR\), et son compactifié d'Alexandrov défini en \ref{PROPooHNOZooPSzKIN}. Nous avons donc un point supplémentaire noté \( \infty\). Ce point n'est ni du côté des grands nombres positifs, ni du côté des grands nombres négatifs. Il n'est ni \( +\infty\) ni \( -\infty\).

\begin{proposition}
    Dans cet espace topologique \( \hat \eR=\eR\cup\{ \infty \}\),
    \begin{equation}
        \lim_{x\to 0} \frac{1}{ x }=\infty.
    \end{equation}
\end{proposition}

\begin{proof}
    Soit un voisinage \( V\) de \( \infty\) dans \( \hat \eR\). Il s'écrit \( V=K^c\cup\{ \infty \}\) pour un certain compact de \( \eR\). Le théorème \ref{ThoXTEooxFmdI} nous assure que \( K\) est borné. Donc il existe \( R>0\) tel que \( K\subset B(0,R)\). Pour \( x\in B(0,1/R)\) nous avons
    \begin{equation}
        | \frac{1}{ x } |>R,
    \end{equation}
    et donc \( 1/x\in K^c\). Donc aussi \( \frac{1}{ x }\in V\).
\end{proof}

De la même façon, dans \( \eC\cup\{ \infty \}\) nous avons
\begin{equation}
    \lim_{z\to 0} \frac{1}{ z }=\infty.
\end{equation}

\begin{normaltext}
    Je vous laisse deviner la topologie à considérer sur \( \bar \eR=\eR\cup\{ +\infty,-\infty \}\). Dans cet espace topologique la limite \( \lim_{x\to 0} \frac{1}{ x }\) n'existe pas.
\end{normaltext}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Prolongement par continuité}
%---------------------------------------------------------------------------------------------------------------------------

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Discussion avec mon ordinateur}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Voici un extrait de ce peut donner Sage. Nous lui donnons la fonction
\begin{equation}    \label{EqyEHTBZ}
    f(x)=\frac{ x+4 }{ 3x^2+10x-8 }.
\end{equation}
Cette fonction est faite exprès pour que le dénominateur s'annule en \( -4\). En fait \( 3x^2+10x-8=(x+4)(3x-2)\), et la fraction peut se simplifier en
\begin{equation}
    f(x)=\frac{1}{ 3x-2 }.
\end{equation}
Et avec cela nous écririons \( f(-4)=-\frac{1}{ 14 }\). Voyons comment cela passe dans Sage.

\begin{verbatim}
----------------------------------------------------------------------
| Sage Version 5.2, Release Date: 2012-07-25                         |
| Type "notebook()" for the browser-based notebook interface.        |
| Type "help()" for help.                                            |
----------------------------------------------------------------------
sage: f(x)=(x+4)/(3*x**2+10*x-8)
sage: f(-4)
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
ValueError: power::eval(): division by zero
\end{verbatim}
Il produit donc une erreur de division par zéro. Cela n'est pas étonnant. Pourtant si on lui demande, il est capable de simplifier. En effet :
\begin{verbatim}
sage: f.simplify_full()
x |--> 1/(3*x - 2)
sage: f.simplify_full()(-4)
-1/14
\end{verbatim}

Nous considérons la question suivante : étant donné une fonction \( f\) définie sur \( I\setminus\{ x_0 \}\), est-il possible de définir \( f\) en \( x_0\) de telles façon à ce qu'elle soit continue ?

\begin{example}
    La fonction
    \begin{equation}
        \begin{aligned}
            f\colon \eR\setminus\{ 0 \}&\to \eR \\
            x&\mapsto \frac{1}{ x }
        \end{aligned}
    \end{equation}
    n'est pas définie pour \( x=0\) et il n'y a pas moyen de définir \( f(0)\) de telle sorte que \( f\) soit continue parce que \( \lim_{x\to 0} \frac{1}{ x }\) n'existe pas.
\end{example}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Limite et prolongement}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Reprenons l'exemple de la fonction \eqref{EqyEHTBZ} que mon ordinateur refusait de calculer en zéro :
\begin{equation}
f(x)=\frac{ x+4 }{ 3x^2+10x-8 }=\frac{ x+4 }{ (x+4)\left( x-\frac{ 2 }{ 3 } \right) }.
\end{equation}
Cette fonction a une condition d'existence en $x=-4$. Et pourtant, tant que $x\neq 4$, cela a un sens de simplifier les $(x+4)$ et d'écrire
\[
  f(x)=\frac{ 1 }{ x-\frac{ 2 }{ 3 } }=\frac{ 3 }{ 3x-2 }.
\]
Étant donné que pour toute valeur de $x$ différente de $-4$, la fonction $f$ s'exprime de cette façon, nous avons que
\[
  \lim_{x\to -4}f(x)=\lim_{x\to -4}\left(\frac{ 3 }{ 3x-2 }\right).
\]
Oui, mais la fonction\footnote{Cette fonction $g$ n'est pas $f$ parce que $g$ a en plus l'avantage d'être définie en $-4$.} $g(x)=3/(3x-2)$ est continue en $-4$ et donc sa limite vaut sa valeur. Nous en déduisons que
\[
  \lim_{x\to -4}f(x)=-\frac{ 3 }{ 14 }.
\]
Que dire maintenant de la fonction ainsi définie ?
\begin{equation}
\tilde f(x)=
\begin{cases}
f(x)&\text{si }x\neq -4\\
-3/14&\text{si }x=-4.
\end{cases}
\end{equation}
Cette fonction est continue en $-4$ parce qu'elle y est égale à sa limite. Les étapes suivies pour obtenir ce résultat sont :
\begin{itemize}
\item Repérer un point où la fonction n'existe pas,
\item calculer la limite de la fonction en ce point, et en particulier vérifier que cette limite existe, ce qui n'est pas toujours le cas,
\item définir une nouvelle fonction qui vaut partout la même chose que la fonction originale, sauf au point considéré où l'on met la valeur de la limite.
\end{itemize}
C'est ce qu'on appelle \defe{prolonger la fonction par continuité}{prolongement!par continuité} parce que la fonction résultante est continue. La prolongation de $f$ par continuité est donc en général définie par
\begin{equation}
\tilde f(x)=
\begin{cases}
f(x)            &\text{si }f(x)\\
\lim_{y\to x}f(y)   &\text{si }f(x)
\end{cases}
\end{equation}
Dans le cas que nous regardions,
\[
    f(x)=\frac{ x+4 }{ 3x^2+10x-8 },
\]
le prolongement par continuité est donné par
\begin{equation}
\tilde f =\frac{ 3 }{ 3x-2 }.
\end{equation}
Remarquons que cette fonction n'est toujours pas définie en $x=2/3$.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Prolongement par continuité}
%---------------------------------------------------------------------------------------------------------------------------

\begin{propositionDef}[Prolongement par continuité]
    Soit \( f\colon I\setminus\{ x_0 \}\to \eR\) telle que \( \lim_{x\to x_{0}} f(x)=\ell\in \eR\). La fonction
    \begin{equation}
        \begin{aligned}
            \tilde f\colon I&\to \eR \\
            \tilde f(x)&=\begin{cases}
                f(x)    &   \text{si } x\neq x_0\\
                \ell    &    \text{si } x=x_0
            \end{cases}
        \end{aligned}
    \end{equation}
    est une fonction continue sur \( I\) et est appelée le \defe{prolongement par continuité}{prolongement!par continuité} de \( f\) en \( x_0\).
\end{propositionDef}
Vous noterez que dans cet énoncé nous demandons \( \ell\in \eR\). Les cas \( \ell=\pm\infty\) sont donc exclus.

\begin{normaltext}
    Le lemme~\ref{LEMooUAFBooAwiXxj} donnera un autre gros morceau de prolongement par continuité. Là, ce ne sera pas juste une valeur qui manquera, mais carrément la majorité des valeurs; mais par contre, ce ne sera pas vraiment de la prolongation par continuité, mais de la prolongation par Cauchy-continuité.
\end{normaltext}

\begin{example}
    La fonction
    \begin{equation}
        \begin{aligned}
            f\colon \eR\setminus\{ -3,2 \}&\to \eR \\
            x&\mapsto  \frac{ x^2+2x-3 }{ (x+3)(x-2) }
        \end{aligned}
    \end{equation}
    admet pour limite \( \lim_{x\to -3} f(x)=\frac{ 4 }{ 5 }\). Son prolongement par continuité en \( x=-3\) est donné par
    \begin{equation}
        \tilde f(x)=\frac{ x-1 }{ x-2 }.
    \end{equation}
    Notons que les fonctions \( f\) et \( \tilde f\) ne sont pas identiques : l'une est définie pour \( x=-3\) et l'autre pas. Lorsqu'on fait le calcul
    \begin{equation}
        \frac{ x^2+2x-3 }{ (x+3)(x-2) }=\frac{ (x-1)(x+3) }{ (x+3)(x-2) }=\frac{ x-1 }{ x-2 },
    \end{equation}
    la simplification n'est pas du tout un acte anodin. Le dernier signe «\( =\)» est discutable parce que les deux dernières expressions ne sont pas égales pour tout \( x\); elles ne sont égales «que» pour les \( x\) pour lesquels les deux expressions existent.
\end{example}

Les fonctions trigonométriques donneront quelques exemples intéressants de prolongements par continuité. Voir l'exemple~\ref{ExQWHooGddTLE}. Et une avec la fonction logarithme dans l'exemple~\ref{EXooAGEOooQdQkrS}.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Théorème de la bijection}
%---------------------------------------------------------------------------------------------------------------------------

\begin{proposition} \label{PropOARooUuCaYT}
    Une fonction monotone et surjective d'un intervalle $I$ sur un autre intervalle $J$ est continue sur $I$.
\end{proposition}

\begin{proposition}
    Soient \( f\colon I\to J\) une bijection et \( f^{-1}\colon J\to I\) sa réciproque. Alors pour tout \( x_0\in I\) nous avons
    \begin{equation}    \label{EqHQRooNmLYbF}
        f^{-1}\big( f(x_0) \big)=x_0
    \end{equation}
    et pour tout \( y_0\in J\) nous avons
    \begin{equation}    \label{EqIYTooQPvZDr}
        f\big( f^{-1}(y_0) \big)=y_0.
    \end{equation}
\end{proposition}

\begin{proof}
    Nous prouvons la relation \eqref{EqHQRooNmLYbF} et nous laissons \eqref{EqIYTooQPvZDr} comme exercice au lecteur.

    Soit \( x_0\in I\). Posons \( y_0=f(x_0)\). La définition de l'application réciproque est que pour \( y\in J\), \( f^{-1}(y)\) est l'unique élément \( x\) de \( I\) tel que \( f(x)=y\). Donc \( f^{-1}(y_0)\) est l'unique élément de \( I\) dont l'image est \( y_0\). C'est donc \( x_0\) et nous avons \( f^{-1}(y_0)=x_0\), c'est-à-dire
    \begin{equation}
        f^{-1}\big( f(x_0) \big)=x_0.
    \end{equation}
\end{proof}

\begin{theorem}[Théorème de la bijection] \label{ThoKBRooQKXThd}
    Soit $I$ un intervalle et $f$ une fonction continue et strictement monotone de $I$ dans \( \eR\). Nous avons alors :
    \begin{enumerate}
        \item
            $f(I)$ est un intervalle de \( \eR\) ;
        \item       \label{ITEMooMAWXooZXmVwA}
            La fonction \( f\colon I\to f(I)\) est bijective
        \item
            La fonction \( f^{-1}\colon f(I)\to I\) est strictement monotone de même sens que $f$ ;
        \item \label{ItemEJZooKuFoeFiv}
            La fonction \( f\colon I\to f(I)\) est un homéomorphisme, c'est-à-dire que \( f^{-1}\colon f(I)\to I\) est continue.
    \end{enumerate}
\end{theorem}

\begin{proof}

    Prouvons les choses point par point.

    \begin{enumerate}
    \item

        Supposons pour fixer les idées que \( f\) est monotone croissante\footnote{Traitez en tant qu'exercice le cas où $ f$ est décroissante.}.

        Soient \( a< b\) dans \( f(I)\). Par définition il existe \( x_1,x_2\in I\) tels que \( a=f(x_1)\) et \( b=f(x_2)\). La fonction \( f\) est continue sur l'intervalle \( \mathopen[ x_1 , x_2 \mathclose]\) et vérifie \( f(x_1)<f(x_2)\). Donc le théorème des valeurs intermédiaires~\ref{ThoValInter} nous dit que pour tout \( t\) dans \( \mathopen[ f(x_2) , f(x_2) \mathclose]\), il existe un \( x_0\in\mathopen[ x_1 , x_2 \mathclose]\) tel que \( f(x_0)=t\). Cela montre que toutes les valeurs intermédiaires entre \( a\) et \( b\) sont atteintes par \( f\) et donc que \( f(I)\) est un intervalle.

    \item

    Nous prouvons maintenant que \( f\) est bijective en prouvant séparément qu'elle est surjective et injective.

    \begin{subproof}

        \item[\( f\) est surjective]

            Une fonction est toujours surjective depuis un intervalle \( I\) vers l'ensemble \(\Im f \).

        \item[\( f\) est injective]

            Soit \( x\neq y\) dans \( I\); pour fixer les idées nous supposons que \( x<y\). La stricte monotonie de \( f\) implique que \( f(x)<f(y)\) ou que \( f(x)>f(y)\). Dans tous les cas \( f(x)\neq f(y)\).

    \end{subproof}

    La fonction \( f\) est donc bijective.

\item

    Comme d'accoutumée nous supposons que \( f\) est croissante. Soient \( y_1<y_2\) dans \( f(I)\); nous devons prouver que \( f^{-1}(y_1)\leq f^{-1}(y_2)\). Pour cela nous considérons les nombres \( x_1,x_2\in I\) tels que \( f(x_1)=y_1\) et \( f(x_2)=y_2\). Nous allons en prouver la contraposée en supposant que \( f^{-1}(y_1)>f^{-1}(y_2)\). En appliquant \( f\) (qui est croissante) à cette dernière inégalité il vient
    \begin{equation}
        f\big( f^{-1}(y_1) \big)\geq f\big( f^{-1}(y_2) \big),
    \end{equation}
    ce qui signifie
    \begin{equation}
        y_1\geq y_2
    \end{equation}
    par l'équation \eqref{EqIYTooQPvZDr}.

\item

    La fonction \( f^{-1}\colon f(I)\to I\) est une fonction monotone et surjective, donc continue par la proposition~\ref{PropOARooUuCaYT}.

    \end{enumerate}
\end{proof}

\begin{example}
    La fonction
    \begin{equation}
        \begin{aligned}
            f\colon \mathopen[ 2 , 3 \mathclose]&\to \mathopen[ 4 , 9 \mathclose] \\
            x&\mapsto x^2
        \end{aligned}
    \end{equation}
    est une bijection. Sa réciproque est la fonction
    \begin{equation}
        \begin{aligned}
            f^{-1}\colon \mathopen[ 4 , 9 \mathclose]&\to \mathopen[ 2 , 3 \mathclose] \\
            x&\mapsto \sqrt{x}.
        \end{aligned}
    \end{equation}
\end{example}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Limite et continuité}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\label{SecLimiteFontion}

Voir les remarques dans l'index thématique~\ref{THEMEooGVCCooHBrNNd} pour comprendre la place et la portée de ce qui va venir à propos de limite et de continuité.

\begin{theorem}[Limite et continuité]           \label{ThoLimCont}
La fonction $f$ est continue au point $a$ si et seulement si $\lim_{x\to a}f(x)=f(a)$.
\end{theorem}

\begin{proof}
    Nous commençons par supposer que $f$ est continue en $a$, et nous prouvons que $\lim_{x\to a}f(x)=a$. Soit $\epsilon>0$; ce qu'il nous faut c'est un $\delta$ tel que $| x-a |\leq\delta$ implique $| f(x)-f(a) |\leq\epsilon$. La caractérisation \ref{PROPooVNGEooPwbxXP} de la continuité donne l'existence d'un $\delta$ comme il nous faut.

    Dans l'autre sens, c'est-à-dire prouver que $f$ est continue au point $a$ sous l'hypothèse que $\lim_{x\to a}f(x)=f(a)$, la preuve se fait de la même façon.
\end{proof}

Nous en déduisons que si nous voulons gagner quelque chose à parler de limites, il faut prendre des fonctions non continues. En effet, si une fonction est continue en un point, la limite ne donne aucune nouvelle information que la valeur de la fonction elle-même en ce point.

Prenons une fonction qui fait un saut. Pour se fixer les idées, prenons celle-ci :
\begin{equation}    \label{EqnCtOEL}
f(x)=
\begin{cases}
2x&\text{si }x\in]\infty,2[\\
x/2&\text{si }x\in[2,\infty[
\end{cases}
\end{equation}
Essayons de trouver la limite de cette fonction lorsque $x$ tend vers $2$. Étant donné que $f$ n'est pas continue en $2$, nous savons déjà que $\lim_{x\to 2}f(x)\neq f(2)$. Donc ce n'est pas $1$. Cette limite ne peut pas valoir $4$ non plus parce que si je prends n'importe quel $\epsilon$, la valeur de $f(2+\epsilon)$ est très proche de $2$, et donc ne peut pas s'approcher de $4$. En fait, tu peux facilement vérifier que \emph{aucun nombre ne vérifie la condition de limite pour $f$ en $2$}. Nous disons que la limite n'existe pas.

Il ne faudrait pas en déduire trop vite que si une fonction n'est pas continue en \( a\), alors la limite \( x\to a\) n'existe pas. Ce que dit le théorème~\ref{ThoLimCont} est que si une fonction n'est pas continue en \( a\), alors sa limite (si elle existe) ne vaut pas \( f(a)\).

\begin{example}[Un exemple de continuité Thème~\ref{THEMEooGVCCooHBrNNd}]     \label{EXooKREUooLeuIlv}
    Soit la fonction
    \begin{equation}        \label{EQooSYSWooSGsUfR}
        f(x)=\begin{cases}
            x    &   \text{si } x\neq 0\\
            4    &    \text{si } x=0.
        \end{cases}
    \end{equation}
    Cette fonction n'est pas continue en \( x=0\), et pourtant la limite existe : \( \lim_{x\to 0} f(x)=0\). Faisons cela en détail pour nous assurer de ce qu'il se passe.

    Considérons l'ouvert \( \mathopen] 3 , 5 \mathclose[\). L'image réciproque de cet ouvert par \( f\) est la partie \( \mathopen] 3 , 5 \mathclose[\cup\{ 0 \}\) qui n'est pas ouvert. Donc la fonction \( f\) n'est pas continue comme fonction \( \eR\to \eR\).

    Considérons pour comprendre la restriction \( f\colon \mathopen[ -1 , 1 \mathclose]\to \eR\). L'image inverse de \( \mathopen] 3 , 5 \mathclose[\) par cette fonction est \( \{ 0 \}\) qui n'est pas un ouvert.

    Plus généralement tant qu'on considère des restrictions de \( f\) sur des parties contenant un voisinage de \( 0\), la fonction ne peut pas être continue\footnote{Les plus acharnés se demanderont ce qu'il se passe pour la restriction de \( f\) à la partie \( \{ 0 \}\) munie de la topologie induite de $\eR$.}.

    Voyons ce qui en est de la continuité ponctuelle de \( f\) en \( x=0\). La définition~\ref{DefOLNtrxB} est celle de la continuité en un point; elle dit que \( f\) sera continue en \( 0\) si \( f(0)=4\) est une limite de \( f\). Nous voila parti vers la définition~\ref{DefYNVoWBx}.

Soit le voisinage \( V=\mathopen] 3 , 5 \mathclose[\) de \( f(0)\). Quel que soit le voisinage \( W\) de \( 0\) dans \( \eR\), il existe un \( \epsilon>0\) tel que \( W\subset B(0,\epsilon)\). Nous avons alors
    \begin{equation}
        f\big( W\setminus \{ a \} \big)\subset f\big( B(0,\epsilon)\setminus\{ 0 \} \big).
    \end{equation}
    Mais le nombre \( \epsilon/2\) fait partie de \( f\big( B(0,\epsilon)\setminus\{ 0 \} \big)\) et n'est pas dans \( V\). Donc \( f(0)\) n'est pas une limite de \( f\) en zéro. Cette fonction n'est donc pas continue en zéro.
\end{example}

\begin{example}[Même exemple, limite]
    Nous avons vu que, pour la fonction \eqref{EQooSYSWooSGsUfR}, le nombre \( 4\) n'est pas une limite de \( f\) en zéro. Nous montrons à présent que \( 0\) est une limite (et même la seule par la proposition~\ref{PropFObayrf} que nous ne rappellerons plus à chaque fois) de \( f\).

    Montrons que \( 0\) est une limite de \( f\) en zéro, c'est-à-dire que \( \lim_{x\to 0} f(x)=0\).

    Nous suivant la définition~\ref{DefYNVoWBx}. Soit un voisinage \( V\) de \( 0\) dans \( \eR\). Il existe \( \delta\) tel que \( B(0,\delta)\subset V\). En posant \( \epsilon=\delta\) et en définissant \( W=B(0,\epsilon)\) nous avons
    \begin{equation}
        f\big( B(0,\epsilon)\setminus\{ 0 \} \big)=B(0,\epsilon)\setminus\{ 0 \}\subset  B(0,\delta)\subset V.
    \end{equation}
    Donc \( 0\) est une limite de \( f\) en zéro.
\end{example}

Nous avons déjà vu par le corolaire~\ref{CorFHbMqGGyi} qu'une suite croissante et bornée était convergente. Il en va de même pour les fonctions.
\begin{proposition}[\cite{MonCerveau}] \label{PropMTmBYeU}
    Si la fonction réelle \( f\colon I=\mathopen[ a , b [\to \eR\) est croissante et bornée, alors la limite
    \begin{equation}
        \lim_{x\to b} f(x)
    \end{equation}
    existe et est finie.
\end{proposition}

\begin{proof}
    Commençons par prouver que si \( (x_n)\) est une suite dans \( I\) convergent vers \( b\), alors \( f(x_n)\) est une suite convergente. Dans un second temps nous allons prouver que si \( (x_n)\) et \( (x'_n)\) sont deux suites qui convergent vers \( b\), alors les suites convergentes \( f(x_n)\) et \( f(x'_n)\) convergent vers la même limite. Alors le critère séquentiel de la limite d'une fonction conclura (proposition~\ref{PROPooJYOOooZWocoq}).

    Nous pouvons extraire de \( x_n\) une sous-suite croissante \( (x_{\alpha(n)})\). Alors la suite \( f\big( x_{\alpha(n)} \big)\) est une suite croissante et majorée, donc convergente par le corolaire~\ref{CorFHbMqGGyi}\footnote{En gros nous sommes en train de dire que toute la théorie des fonctions convexes est un vulgaire corolaire de Bolzano-Weierstrass.}. Nommons \( \ell\) la limite et montrons qu'elle est aussi limite de \( f\) sur la suite originale.

    Pour tout \( \epsilon>0\), il existe \( K\) tel que si \( n>K\) alors \( \big| f\big( x_{\alpha(n)} \big)-\ell \big|<\epsilon\). Soit \( K'\) tel que pour tout \( n>K'\) nous ayons \( x_n>x_{\alpha(K')}\). Cela est possible parce que la suite est bornée par \( b\) et converge vers \( b\) : il suffit de prendre \( K'\) de telle sorte que \( | x_n-b |\leq | x_{\alpha(n)}-b |\). Si \( n>K'\) alors \( x_n>x_{\alpha(K)}\) et
    \begin{equation}
        f(x_n)\geq f(x_{\alpha(n)})\geq \ell-\epsilon;
    \end{equation}
    en résumé si \( n>K\) alors \( | f(x_n)-\ell |<\epsilon\). Cela prouve que \( f(x_n)\to\ell\).

    Soit maintenant une autre suite \( (x'_n)\) qui converge également vers \( b\). Comme nous venons de le voir la suite \( f(x'_n)\) est convergente et nous nommons \( \ell'\) la limite. Si nous considérons \( (x''_n)\) la suite «alternée» (\( x_1,x'_1,x_2,x'_2,\cdots\)) alors nous avons encore une suite qui converge vers \( b\) et donc \( f(x''_n)\to \ell'\).

    Mais étant donné que \( f(x_n)\) et \( f(x'_n)\) sont des sous-suites, elles doivent converger vers la même valeur. Donc \( \ell=\ell'=\ell''\).
\end{proof}

%TODO : écrire un truc sur la limite à gauche et la limite pour la topologie induite.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Règles simples de calcul}
%---------------------------------------------------------------------------------------------------------------------------

Les opérations simples passent à la limite, sauf la division pour laquelle il faut faire attention au dénominateur.
\begin{proposition}     \label{PropOpsSimplesLimites}
    Soient \( f\) et \( g\) deux fonctions telles que \( \lim_{x\to a} f(x)=\alpha\) et \( \lim_{x\to a} g(x)=\beta\). Alors
    \begin{enumerate}
        \item
            \( \lim_{x\to a} f(x)+g(x)=\alpha+\beta\),
        \item
            \( \lim_{x\to a} f(x)g(x)=\alpha\beta\),
        \item
            s'il existe un voisinage de \( a\) sur lequel \( g\) ne s'annule pas, alors \( \lim_{x\to a} \frac{ f(x) }{ g(x) }=\frac{ \alpha }{ \beta }\).
    \end{enumerate}
\end{proposition}

Le résultat suivant est pratique pour le calcul des limites.
\begin{proposition}     \label{PropChmVarLim}
Quand la limite existe, nous avons
\[
  \lim_{x\to a}f(x)=\lim_{\epsilon\to 0}f(a+\epsilon),
\]
ce qui correspond à un «changement de variables» dans la limite.
\end{proposition}

\begin{proof}
Si $A=\lim_{x\to a}f(x)$, par définition,
\begin{equation}        \label{EqCondFaplusespLim}
\forall\epsilon'>0,\,\exists\delta\text{ tel que }| x-a |\leq\delta\Rightarrow| f(x)-A |\leq\epsilon'.
\end{equation}
La seule subtilité de la démonstration est de remarquer que si $| x-a |\leq\delta$, alors $x$ peut être écrit sous la forme $x=a+\epsilon$ pour un certain $| \epsilon |\leq\delta$. En remplaçant $x$ par $a+\epsilon$ dans la condition~\ref{EqCondFaplusespLim}, nous trouvons
\begin{equation}
\forall\epsilon'>0,\,\exists\delta\text{ tel que }| \epsilon |\leq\delta\Rightarrow| f(x+\epsilon)-A |\leq\epsilon',
\end{equation}
ce qui signifie exactement que $\lim_{\epsilon\to 0}f(x+\epsilon)=A$.
\end{proof}

Il y a une petite différence de point de vue entre $\lim_{x\to a}f(x)$ et $\lim_{\epsilon\to 0}f(a+\epsilon)$. Dans le premier cas, on considère $f(x)$, et on regarde ce qu'il se passe quand $x$ se rapproche de $a$, tandis que dans le second, on considère $f(a)$, et on regarde ce qu'il se passe quand on s'éloigne un tout petit peu de $a$. Dans un cas, on s'approche très près de $a$, et dans l'autre on s'en éloigne un tout petit peu. Le contenu de la proposition~\ref{PropChmVarLim} est de dire que ces deux points de vue sont équivalents.

% Il y a des techniques de calcul de limites décrites sur le site
% http://bernard.gault.free.fr/terminale/limites/limite.html

\begin{proposition}[\cite{MonCerveau}]      \label{PROPooLOQVooULDhZz}
    L'ensemble \( \eR\cup\{ \infty \}\) muni de la topologie de la compactification en un point\footnote{Définition \ref{PROPooHNOZooPSzKIN}.} est connexe par arcs.
\end{proposition}

\begin{proof}
    Nous allons montrer que le chemin
    \begin{equation}
        \begin{aligned}
            \gamma\colon \mathopen[ 0 , 1 \mathclose]&\to \mathopen[ 0 , \infty \mathclose] \\
            x&\mapsto \begin{cases}
                \frac{1}{ x }    &   \text{si } x\neq 0\\
                \infty    &    \text{si } x=0
            \end{cases}
        \end{aligned}
    \end{equation}
    est continu au sens de la définition \ref{DefOLNtrxB}\ref{ITEMooEHGWooDdITRV} (qui est le seul sens possible au mot «continu»).

    Soit un ouvert \( \mO\) dans \( \eR\cup\{ \infty \}\). Si cet ouvert ne contient pas \( \infty\), alors \( \gamma^{-1}(\mO)\) est ouvert dans \( \eR\) parce que la fonction \( x\mapsto 1/x\) est continue\footnote{Voir par exemple la proposition \ref{PropOpsSimplesLimites}.}.

    Si \( \infty\in\mO\), alors \( \mO=\{ \infty \}\cup \mO'\) où \( \mO'\) est un ouvert de \( \eR\) ayant la propriété que \( \eR\setminus \mO'\) est compact.

    Nous avons \( \gamma^{-1}(\mO)=\{ 0 \}\cup\gamma^{-1}(\mO')\). Le fait est que \( \gamma^{-1}(\mO')\) est ouvert de \( \eR\) contenu dans \( \mathopen[ 0 , 1 \mathclose]\).

Vu que le complémentaire de \( \mO'\) est compact, il existe \( a\in \eR\) tel que \( \mathopen] a , \infty \mathclose[\subset \mO'\). Donc \( \mO'=\mathopen] a , \infty \mathclose[\cup\mO''\) où \( \mO''\) est un ouvert.

    Nous avons :
    \begin{subequations}
        \begin{align}
        \gamma^{-1}(\mO)&=\{ \gamma^{-1}(\infty) \}\cup \gamma^{-1}\big( \mathopen] a , \infty \mathclose[ \big)\cup \gamma^{-1}(\mO'')\\
        &=\{ 0 \}\cup\mathopen] 0 , \frac{1}{  a } \mathclose[\cup\gamma^{-1}(\mO'')\\
            &=\mathopen[ 0 , \frac{1}{ a } \mathclose[\cup\gamma^{-1}(\mO'').
        \end{align}
    \end{subequations}
    Vous noterez le point essentiel où la topologie de la compactification agit : vu que \( \{0\}\) n'est pas un ouvert de \( \mathopen[ 0 , 1 \mathclose]\), nous devons nous assurer que la partie \( \gamma^{-1}(\mO')\) vienne se coller à \( \{0\}\) pour compléter en un ouvert.

    L'ensemble \( \gamma^{-1}(\mO'')\) est un ouvert de \( \eR\) contenu dans \( \mathopen[ 0 , 1 \mathclose]\). Nous avons donc
    \begin{equation}
    \gamma^{-1}(\mO)=\Big( \mathopen] -1 , \frac{1}{ a } \mathclose[\cup\gamma^{-1}(\mO'') \Big)\cap \mathopen[ 0 , 1 \mathclose].
    \end{equation}
    Cela est un ouvert de \( \mathopen[ 0 , 1 \mathclose]\) par définition de la topologie induite\footnote{Définition \ref{DefVLrgWDB}.}.
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Prolongement des rationnels vers les réels}
%---------------------------------------------------------------------------------------------------------------------------

Si \( f\colon \eQ\to \eR\) est une fonction continue pour la topologie induite, est-ce qu'on peut la prolonger en une fonction continue sur \( \eR\) ? La réponse est hélas non.

\begin{example}[\cite{BIBooOFHOooWZGRPw}]       \label{EXooWZNCooQkKdtJ}
    Vu que \( \sqrt{ 2 }\) est irrationnel\footnote{Proposition \ref{PropooRJMSooPrdeJb}. Le fait que $\sqrt{ 2 }$ existe dans \( \eR\) est la proposition \ref{PROPooUHKFooVKmpte}.}, ceci définit bien une fonction sur \( \eQ\) :
    \begin{equation}
        \begin{aligned}
            f\colon \eQ&\to \eR \\
            q&\mapsto \begin{cases}
                0    &   \text{si } q<\sqrt{ 2 }\\
                1    &    \text{si }q>\sqrt{ 2 }.
            \end{cases}
        \end{aligned}
    \end{equation}
    Cela est une fonction continue sur \( \eQ\). En effet, soient \( q\in \eQ\) et \( \epsilon>0\). Nous prenons \( \delta>0\) tel que \( \sqrt{ 2 }\) ne soit pas dans \( B(q,\delta)\). Alors si \( p\in B_{\eQ}(q,\delta)\) nous avons \( f(q)=f(p)\) et donc 
    \begin{equation}
        | f(p)-f(q) |<\epsilon.
    \end{equation}

    Il n'est cependant pas possible de la prolonger en une fonction continue sur \( \eR\).
\end{example}

Pour qu'une fonction sur \( \eQ\) puisse être prolongée en une fonction continue sur \( \eR\), il faut un peu plus que la continuité. Il fait la Cauchy-continuité que nous définissons pas plus tard qu'immédiatement.

\begin{definition}[\cite{BIBooOFHOooWZGRPw}]        \label{DEFooXXOGooXblyKP}
    Soient \( X\) et \( Y\) deux espaces métriques. Une application \( f\colon X\to Y\) est dite \defe{Cauchy-continue}{Cauchy-continue} si pour toute suite de Cauchy \( (x_n)\) dans \( X\), la suite \( \big( f(x_n) \big)\) est de Cauchy dans \( Y\).
\end{definition}

En terme de prolongement continu, nous avons ce lemme qui demande à une fonction d'être Cauchy continue. Vous pouvez comparer avec le principe de prolongement analytique \ref{ThoAVBCewB} qui donne un énoncé similaire pour un prolongement analytique.
\begin{lemma}[\cite{MonCerveau, BIBooUNVDooGfFtGp,BIBooERJSooURHjMX}]        \label{LEMooUAFBooAwiXxj}
    Soit une fonction Cauchy continue \footnote{Définition \ref{DEFooXXOGooXblyKP}; nous en avons discuté dans l'exemple~\ref{EXooWZNCooQkKdtJ}.} \( f\colon \eQ\to \eR\).
    \begin{enumerate}
        \item
            La limite \( \lim_{q\to x} f(q)\) existe pour tout \( x\in \eR\).
        \item
            Il existe un unique prolongement continu \( \tilde f\colon \eR\to \eR\).
        \item
            Ce prolongement est donné par
            \begin{equation}
            \tilde f(x)=\begin{cases}
                f(x)    &   \text{si } x\in \eQ\\
                \lim_{q\to x} f(q)    &    \text{sinon }
            \end{cases}
        \end{equation}
    \end{enumerate}
\end{lemma}

\begin{proof}
    Imprégniez vous bien de la la définition~\ref{DefYNVoWBx} de la limite avant de commencer.

    \begin{subproof}

    \item[Unicité]

        Prouvons rapidement l'unicité avant l'existence parce que c'est facile.

        L'unicité du prolongement est la proposition~\ref{PropCJGIooZNpnGF} à propos de fonctions continues égales sur une partie denses. La densité de \( \eQ\) dans \( \eR\), si vous la cherchez est la proposition~\ref{PropooUHNZooOUYIkn}.

        \item[Candidat limite]
        Soit \( x\in \eR\). Vu que \( x\in \bar \eQ\), nous pouvons chercher à savoir si \( \lim_{q\to x} f(q) \) existe. Si elle existe, elle sera unique.

        Soit une suite \( (q_i)\) d'éléments de \( \eQ\) qui converge vers \( x\) dans \( \eR\) (i.e. pour la topologie de \( \eR\)). Les nombres réels \( f(q_i)\) forment une suite dans \( \eR\). La suite \( (q_i)\) étant convergente, elle est de Cauchy\footnote{Théorème \ref{THOooNULFooYUqQYo}\ref{ITEMooUUFCooIVtGgz}.}.

        Vu que \( f\) est supposée Cauchy-continue, la suite \(\big( f(q_i) \big)\) est de Cauchy dans \( \eR\), et elle est donc convergente.
    \item[C'est bien la limite]

        Nous prouvons à présent que le nombre réel \( \lim_{i\to \infty} f(q_i)\) (dont l'existence vient d'être prouvée) vérifie bien la définition de la limite \( \lim_{q\to x}f(q)\).

        Soit un voisinage \( V\) de \( \lim f(q_i)\) dans \( \eR\). Nous devons trouver un voisinage \( W\) de \( x\) dans \( \eR\) tel que
        \begin{equation}
            f\big( W\cap\eQ\setminus\{ x \} \big)\subset V.
        \end{equation}
        Pour cela nous considérons \( \epsilon>0\) tel que \( B\big( \lim f(q_i),\epsilon \big)\subset V\). Vu que \( f\) est continue sur \( \eQ\), il existe \( \delta\) tel que
        \begin{equation}
            | p-q |<2\delta\Rightarrow\,| f(p)-f(q) |<\epsilon.
        \end{equation}
        Nous posons \( W=B(x,\delta)\).

        Soit \( q\in W\cap\eQ\setminus\{ x \}\). Nous nous proposons de majorer la quantité $| f(q)-\lim f(q_i) |$ par un multiple de \( \epsilon\).

        Pour cela nous considérons \( k\) suffisamment grand pour que \( | f(q_k)-\lim f(q_i)  |<\epsilon\). Et de plus, vu que \( q_i\to x\) nous considérons \( k\) suffisamment grand pour que \( | q_k-x |<\delta\). L'indice \( k\) est choisi pour vérifier les deux conditions en même temps.

        Nous écrivons alors la majoration suivante :
        \begin{equation}
                | f(q)-\lim f(q_i) |\leq | f(q)-f(q_k) |+| f(q_k)+\lim f(q_i) |.
        \end{equation}
        Le second terme est majoré par \( \epsilon\). Pour le premier terme, \( q\in B(x,\delta)\) et \( q_k\in B(x,\delta)\), donc \( | q-q_k |\leq 2\delta\), ce qui implique \( | f(q)-f(q_k) |<\epsilon\).

        Au final, \( | f(q)-\lim f(q_i) |\leq 2\epsilon\). En reprenant tout le travail avec \( \epsilon/2\) au lieu de \( \epsilon\) nous trouvons \( f(q)\in B\big( \lim f(q_i),\epsilon \big)\subset V\).

    \item[Intermède]

        Jusqu'à présent, nous avons prouvé que
        \begin{equation}        \label{EQooUJJKooTYRNDo}
            \lim_{q\to x} f(q)
        \end{equation}
        existe et vaut
        \begin{equation}        \label{EQooNSYCooTmECjs}
            \lim f(q_i)
        \end{equation}
        lorsque \( (q_{i})\) est une suite quelconque de rationnels qui converge vers \( x\). Nous l'écrivons pour la référentier plus tard :
        \begin{equation}        \label{EQooSGCMooKtpVMy}
            \lim_{q\to x} f(q)=\lim f(q_i).
        \end{equation}
        La limite \eqref{EQooUJJKooTYRNDo} est une limit de fonction définie sur \( \eQ\subset \eR\) en un pour adhérent à l'ensemble de définition de \( f\). La limite \eqref{EQooNSYCooTmECjs} est une limite usuelle d'une suite dans \( \eR\).

    \item[Le prolongement]

        Nous posons
        \begin{equation}
            \tilde f(x)=\begin{cases}
                f(x)    &   \text{si } x\in \eQ\\
                \lim_{q\to x} f(q)    &    \text{sinon }
            \end{cases}
        \end{equation}
        et nous allons prouver que \( \tilde f\) est une fonction continue sur \( \eR\).

    \item[Continuité]

        Soit \( a\in \eR\); nous allons montrer la continuité de \( \tilde f\) en \( a\). Nous fixonx bien entendu \( \epsilon>0\), et nous nous acharnons à majorer la quantité \( | \tilde f(x)-\tilde f(a) |\).

        Vu que \( f\) est continue sur \( \eQ\) nous considérons \( \delta'\) tel que (dans \( \eQ\)) \( 0<| q-q' |<\delta'\) implique \( | f(q)-f(q') |<\epsilon\).

        \begin{subproof}
            \item[\( a\in \eQ\), \( x\in \eQ\)]
                Alors \( \tilde f(x)=f(x)\) et \( \tilde f(a)=f(a)\). Par la continuité de \( f\) sur \( \eQ\), il existe un \( \delta\) tel que \( 0<| x-a |<\delta\) implique \( | f(x)-f(a) |<\epsilon\).

            \item[\( a\in \eQ\), \( x\) irrationnel]

                Nous considérons une suite de rationnels \( q_k\to x\) (vous penserez à l'utilisation du lemme \ref{LemooRTGFooYVstwS}). Nous avons la majoration
                \begin{equation}        \label{EQooPDEMooHlwTcm}
                    | \tilde f(x)-\tilde f(a) |=| \lim_{q\to x} f(q)-f(a) |\leq | \lim_{q\to x} f(q)-f(q_k) |+| f(q_k)-f(a) |.
                \end{equation}
                Nous considérons \( \delta<\delta'\) et \( k\) suffisament grand pour que \( | q_k-x |<\delta'-\delta\). Avec ces choix,
                \begin{equation}
                    | q_k-a |\leq | q_k-x |+| x-a |\leq \delta'.
                \end{equation}
                Enfin nous prenons également \( k\) suffisament grand pour avoir \( | \lim_{q\to x} f(q)-f(q_k) |\leq \epsilon\).

                Les inégalités \eqref{EQooPDEMooHlwTcm} peuvent alors être prolongées pour avoir
                \begin{equation}
                    | \tilde f(x)-\tilde f(a) |\leq 2\epsilon.
                \end{equation}
                
            \item[\( a\) irrationnel, \( x\in \eQ\)]

                Nous faisons encore la majoration
                \begin{equation}
                    | \tilde f(x)-\tilde f(a) |=| f(x)-\lim_{q\to a} f(q) |\leq | f(x)-f(q_k) |+| f(q_k)-\lim_{q\to a} f(a) |.
                \end{equation}
                Nous prenons \( \delta<\delta'/2\) et nous choisissons \( k\) assez grand pour que \( | q_k-a |<\delta'/2\). De ces choix il ressort que
                \begin{equation}
                    | q_k-x |\leq | q_k-a |+| a-x |\leq \frac{ \delta' }{2}+\frac{ \delta' }{2}\leq \delta'.
                \end{equation}
                Donc \( | f(x)-f(q_k) |<\epsilon\). De plus, pour \( k\) assez grand, \( | f(q_k)-\lim_{q\to a} f(q) |\leq \epsilon\).

            \item[\( a\) et \( x\) irrationnels]

                Nous avons
                \begin{equation}
                    | \tilde f(x)-\tilde f(a) |=| \lim_{q\to x} f(q)-\lim_{r\to a} f(r) |,
                \end{equation}
                et nous considérons des suites de rationnels \( q_k\to x\) et \( r_i\to a\). De plus nous considérons \( \delta<\delta'/4\), et \( k,i\) suffisament grands pour avoir \( | q_k-x |\leq \delta'/4\) et \( | r_i-a |<\delta'/4\). Avec tout cela nous avons
                \begin{equation}
                    | q_k-r_i |\leq | q_k-x |+| x-a |+| a-r_i |\leq 3\delta'/4<\delta'.
                \end{equation}
                Enfin, en choisissant \( i\) et \( k\) de telle sorte à avoir \( | \lim_{q\to x} f(q)-f(q_k) |\leq \epsilon\) et \( | f(r_i)-\lim_{r\to a} f(r) |<\epsilon\) nous avons les majorations
                \begin{subequations}
                    \begin{align}
                        | \tilde f(x)-\tilde f(a) |&=| \lim_{q\to x} f(q)-\lim_{r\to a} f(r) |\\
                        &\leq | \lim_{q\to x} f(x)-f(q_k) |+| f(q_k)-f(r_i) |+| f(r_i)-\lim_{r\to q} f(r) |\\
                        &\leq 3\epsilon.
                    \end{align}
                \end{subequations}
        \end{subproof}

    \end{subproof}
\end{proof}

\begin{proposition}     \label{PROPooXWHYooFiVYfi}
    Soient des fonctions continues \( f,g\colon \eR\to \eR\). Si \( f\) et \( g\) sont égales sur \( \eQ\), alors elles sont égales sur \( \eR\).
\end{proposition}

\begin{proof}
    Sinon nous pouvons utiliser les propriétés fondamentales des réels et de la continuité. Soit \( x\in \eR\); nous voulons montrer que \( f(x)=g(x)\). En prenant par exemple le lemme \ref{LemooRTGFooYVstwS}, il existe une suite \( q_i\) de rationnels telle que \( q_i\stackrel{\eR}{\longrightarrow}x\). 
    
    Par ailleurs, \( f\) et \( g\) sont continues sur \( \eR\) et donc en chaque point de \( \eR\) (théorème \ref{ThoESCaraB}). Par la caractérisation séquentielle \ref{PropFnContParSuite} de la continuité, nous avons
    \begin{equation}
        f(x)=\lim_{i\to \infty} f(q_i)=\lim_{i\to \infty} g(q_i)=g(x).
    \end{equation}
\end{proof}

\begin{proposition}[\cite{MonCerveau}]      \label{PROPooTNIAooNAJDzL}
    Soit une fonction strictement croissante \( f\colon \eQ\to \eR\). Alors la prolongation continue \( \tilde f\colon \eR\to \eR\) est également strictement croissante.
\end{proposition}

\begin{proof}
    Soient \( x,y\in \eR\) avec \( x<y\). Notons \( d=y-x\). Nous considérons des suites de rationnels \( x_k\to x\) et \( y_l\to y\) telles que pour tout \( k\), \( x_k\in B(x,d/3)\) et \( y_k\in B(y,d/3)\). En particulier, \( x_k<y_l\) pour tout \( k\) et \( l\).

    Soient des rationnels \( q\) et \( q'\) tels que pour tout \( k\),
    \begin{equation}
        x_k<q<q'<y_k.
    \end{equation}
    Pour trouver de tels rationnels, il suffit de les chercher dans \( \mathopen] x+\frac{ d }{ 3 } , y-\frac{ d }{ 3 } \mathclose[\). Cet intervalle étant de longueur \( d/3\), il contient des rationnels.

    Vue la croissance de \( f\) sur \( \eQ\), nous avons, pour tout \( k\) :
    \begin{equation}
        f(x_k)<f(q)<f(q')<f(y_k),
    \end{equation}
    et à la limite :
    \begin{equation}
        \tilde f(x)\leq f(q)<f(q')\leq \tilde f(y).
    \end{equation}
    Notez que les inégalités strictes se changent en inégalités larges au passage à la limite. D'où l'utilisé de prendre \emph{deux} rationnels entre \( x_k\) et \( y_k\) pour maintenir une inégalité stricte entre \(\tilde f(x)\) et \( \tilde f(y)\).
\end{proof}

