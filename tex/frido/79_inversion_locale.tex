% This is part of Mes notes de mathématique
% Copyright (c) 2006-2019
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Trucs et astuces de calcul d'intégrales}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\label{SECooKSOFooEVKDLh}

Afin d'alléger le texte de calculs parfois un peu longs, nous regroupons ici les intégrales à une variable que nous devons utiliser dans les autres parties du cours.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Quelques intégrales «usuelles»}
%---------------------------------------------------------------------------------------------------------------------------

\begin{enumerate}
	\item	\label{ItemIntegrali}
		L'intégrale
		\begin{equation}
			\boxed{I=\int x\ln(x)dx=\frac{ x^2 }{2}\big( \ln(x)-\frac{ 1 }{2} \big)}
		\end{equation}
		se fait par partie en posant
		\begin{equation}
			\begin{aligned}[]
				u&=\ln(x),		& dv&=x\,dx\\
				du&=\frac{1}{ x }\,dx,	& v&=\frac{ x^2 }{2},
			\end{aligned}
		\end{equation}
		et ensuite
		\begin{equation}
			I=\ln(x)\frac{ x^2 }{2}-\int\frac{ x }{2}=\frac{ x^2 }{2}\big( \ln(x)-\frac{ 1 }{2} \big).
		\end{equation}

	\item
		L'intégrale
		\begin{equation}
			\boxed{I=\int x\ln(x^2)dx=x^2\ln(x)-\frac{ x^2 }{2}.}
		\end{equation}
		En utilisant le fait que $\ln(u^2)=2\ln(u)$, nous retombons sur une intégrale du type~\ref{ItemIntegrali} :
		\begin{equation}
			I=x^2\ln(x)-\frac{ x^2 }{2}.
		\end{equation}
	\item
		L'intégrale
		\begin{equation}		\label{EqTrucIntxlnxsqpun}
			\boxed{I=\int x\ln(1+x^2)dx=\frac{ 1 }{2}\ln(x^2+1)(x^2+1)-x^2-\frac{ 1 }{2}}
		\end{equation}
		se traite en posant $v=1+x^2$ de telle sorte à avoir $dx=\frac{ dv }{ 2x }$ et donc
		\begin{equation}
			I=\frac{ 1 }{2}\ln(x^2+1)(x^2+1)-x^2-\frac{ 1 }{2}.
		\end{equation}

	\item
		L'intégrale
		\begin{equation}
			I=\int \cos(\theta)\sin(\theta)\ln\left( 1+\frac{1}{ \cos^2(\theta) } \right)\,d\theta
		\end{equation}
		demande le changement de variable $u=\cos(\theta)$, $d\theta=-\frac{ du }{ \sin(\theta) }$. Nous tombons sur l'intégrale
		\begin{equation}
			I=-\int u\ln\left( \frac{ 1+u^2 }{ u^2 } \right)=-\int u\ln(1+u^2)+\int u\ln(u^2),
		\end{equation}
		qui sont deux intégrales déjà faites. Nous trouvons
		\begin{equation}
			I=-\frac{ 1 }{2}\ln\left( \frac{ \sin^2(\theta)-1 }{ \sin^2(\theta)-2 } \right)\sin^2(\theta)-\ln\big( \sin^2(\theta)-2 \big)+\frac{ 1 }{2}\ln\big( \sin^2(\theta)-1 \big)
		\end{equation}

	\item
		L'intégrale
		\begin{equation}
			\boxed{\int \frac{ r^3 }{ 1+r^2 }dr=\frac{ r^2 }{2}-\frac{ 1 }{2}\ln(r^2+1).}
		\end{equation}
		commence par faire la division euclidienne de $r^3$ par $r^2+1$; ce que nous trouvons est $r^3=(r^2+1)r-r$. Il reste à intégrer
		\begin{equation}
			\int \frac{ r^3 }{ 1+r^2 }dr=\int r\,dr-\int\frac{ r }{ 1+r^2 }dr.
		\end{equation}
		La fonction dans la seconde intégrale est $\frac{ r }{ 1+r^2 }=\frac{ 1 }{2}\frac{ f'(r) }{ f(r) }$ où $f(r)=1+r^2$, et donc $\int \frac{ r }{ 1+r^2 }=\frac{ 1 }{2}\ln(1+r^2)$. Au final,
		\begin{equation}
			I=\frac{ 1 }{2}r^2-\frac{ 1 }{2}\ln(r^2+1).
		\end{equation}


	\item
		L'intégrale
		\begin{equation}	\label{EqTrucIntsxcxdx}
			\boxed{I=\int \cos(\theta)\sin(\theta)d\theta=\frac{ \sin^2(\theta) }{ 2 }}
		\end{equation}
		se traite par le changement de variable $u=\sin(\theta)$, $du=\cos(\theta)d\theta$, et donc
		\begin{equation}
			\int\cos(\theta)\sin(\theta)d\theta=\int udu=\frac{ u^2 }{2}=\frac{ \sin^2(\theta) }{ 2 }.
		\end{equation}
	\item
		L'intégrale
		\begin{equation}	\label{EqTrucsIntsqrtAplusu}
			\boxed{\int\sqrt{1+x^2}dx=\frac{ x }{2}\sqrt{1+x^2}+\frac{ 1 }{2}\arcsinh(x)}
		\end{equation}
		s'obtient en effectuant le changement de variable $u=\sinh(\xi)$.

    \item
        L'intégrale
        \begin{equation}        \label{EqTrucIntcossqsinsq}
            \boxed{ \int\cos^2(x)\sin^2(x)dx=\frac{ x }{ 8 }-\frac{ \sin(4x) }{ 32 } }
        \end{equation}
        s'obtient à coups de formules de trigonométrie. D'abord, $\sin(t)\cos(t)=\frac{ 1 }{2}\sin^2(2t)$ fait en sorte que la fonction à intégrer devient
        \begin{equation}
            f(x)=\frac{1}{ 4 }\sin^2(x).
        \end{equation}
        Ensuite nous utilisons le fait que $\sin^2(t)=(1-\cos(2t))/2$ pour transformer la formule à intégrer en
        \begin{equation}
            f(x)=\frac{ 1-\cos(4x) }{ 8 }.
        \end{equation}
        Cela s'intègre facilement en posant $u=4x$, et le résultat est
        \begin{equation}
            \int f(x)dx=\frac{ x }{ 8 }-\frac{ \sin(4x) }{ 32 }.
        \end{equation}

    \item

        La fonction
        \begin{equation}
            \sinc(x)=\frac{ \sin(x) }{ x }
        \end{equation}
        est le \defe{sinus cardinal}{sinus cardinal} de \( x\). Nous allons montrer que
        \begin{equation}    \label{EqKNOmLEd}
            \boxed{  \int_0^{\infty}\big| \sinc(x) \big|dx=\infty  }.
        \end{equation}
        D'abord nous avons
        \begin{equation}
            \int_{(n-1)\pi}^{n\pi}\frac{ \big| \sin(t) \big| }{ t }dt\geq \int_{(n-1)\pi}^{n\pi}\frac{ \big| \sin(t) \big| }{ n\pi }dt,
        \end{equation}
        mais par périodicité,
        \begin{equation}
            \int_{(n-1)\pi}^{n\pi}\big| \sin(t) \big|dt=\int_0^{\pi}\sin(t)dt=2.
        \end{equation}
        Par conséquent
        \begin{equation}
            \int_0^{n\pi}\big| \sinc(t) \big|dt\geq \frac{ 2 }{ \pi }\sum_{k=1}^n\frac{1}{ k },
        \end{equation}
        ce qui diverge lorsque \( n\to \infty\).

    \item
        Les intégrales, pour \( \epsilon>0\),
        \begin{equation}        \label{EQooNCVIooWqbbrH}
            \boxed{ \int_0^{\infty}\cos(kx) e^{-\epsilon x}dx=\frac{ \epsilon }{ k^2+\epsilon^2 } }
        \end{equation}
        et
        \begin{equation}        \label{EQooSAYUooSatbGc}
            \boxed{  \int_0^{\infty}\sin(kx) e^{-\epsilon x}dx=\frac{ k }{ k^2+\epsilon^2 }     }
        \end{equation}
        se calculent deux fois par partie. Nous posons
        \begin{subequations}
            \begin{align}
                I&=\int_0^{\infty}\cos(kx) e^{-\epsilon x}dx\\
                J&=\int_0^{\infty}\sin(kx) e^{-\epsilon x}dx.
            \end{align}
        \end{subequations}
        L'intégrale \( I\) s'effectue par partie en posant \( u=\cos(kx)\) et \( v'= e^{-\epsilon x}\). Un peu de calcul montre que
        \begin{equation}
            I=\frac{1}{ \epsilon }-\frac{ k }{ \epsilon }J.
        \end{equation}
        Par ailleurs l'intégrale \( J\) se fait également par partie pour obtenir
        \begin{equation}
            J=\frac{ k }{ \epsilon }I.
        \end{equation}
        En résolvant pour \( I\) et \( J\) les deux équations déduites, nous trouvons
        \begin{subequations}
            \begin{align}
                I&=\frac{ \epsilon }{ k^2+\epsilon^2 }\\
                J&=\frac{ k }{ k^2+\epsilon^2 }.
            \end{align}
        \end{subequations}
\end{enumerate}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Reformer un carré au dénominateur}
%---------------------------------------------------------------------------------------------------------------------------
\label{subsecCarreDenoPar}

Lorsqu'on a un second degré au dénominateur, le bon plan est de reformer un carré parfait. Par exemple :
\begin{equation}
	x^2+2x+2=(x+1)^2+1.
\end{equation}
Ensuite, le changement de variable $t=x+1$ est pratique parce que cela donne $t^2+1$ au dénominateur.

Cherchons
\begin{equation}
	I=\int \frac{ 1-x }{ x^2+2x+2 }dx=\int\frac{ 1-x }{ (x+1)^2+1 }dx=\int\frac{ 1-(t-1) }{ t^2+1 }
\end{equation}
où nous avons fait le changement de variable $t=x+1$, $dt=dx$. L'intégrale se coupe maintenant en deux parties :
\begin{equation}
	I=\int\frac{ -t }{ t^2+1 }+\int \frac{ 2 }{ t^2+1 }.
\end{equation}
La seconde est dans les formulaires et vaut
\begin{equation}
	2\arctan(t)=2\arctan(x+1),
\end{equation}
tandis que la première est presque de la forme $f'/f$ :
\begin{equation}
	\int\frac{ t }{ t^2+1 }=\frac{ 1 }{2}\int \frac{ 2t }{ t^2+1 }=\frac{ 1 }{2}\ln(t^1+1)=\frac{ 1 }{2}\ln(u^2+2u+2).
\end{equation}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Décomposition en fractions simples}
%---------------------------------------------------------------------------------------------------------------------------

La décomposition en fractions simples décrite en~\ref{SUBSECooSIYXooDDHUdD} permet d'intégrer des fractions rationnelles. Elle peut parfois être évitée par la méthode de Rothstein-Trager que nous expliquerons dans \ref{subSecBCRYooRVjFpS}.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Algorithme du gradient à pas optimal}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Une idée pour trouver un minimum à une fonction est de prendre un point \( p\) au hasard, calculer le gradient \(\nabla f(p) \) et suivre la direction \(-\nabla f(p)\) tant que ça descend. Une fois qu'on est «dans le creux», recalculer le gradient et continuer ainsi.

Nous allons détailler cet algorithme dans un cas très particulier d'une matrice \( A\) symétrique et strictement définie positive.
\begin{itemize}
    \item Dans la proposition~\ref{PROPooYRLDooTwzfWU} nous montrons que résoudre le système linéaire \( Ax=-b\) est équivalent à minimiser une certaine fonction.
    \item La proposition~\ref{PropSOOooGoMOxG} donnera une méthode itérative pour trouver ce minimum.
\end{itemize}

\begin{definition}  \label{DefQXPooYSygGP}
    Si \( X\) est un espace vectoriel normé et \( f\colon X\to \eR\cup\{ \pm\infty \}\) nous disons que \( f\) est \defe{coercive}{coercive} sur le domaine non borné \( P\) de \( X\) si pour tout \( M\in \eR\), l'ensemble
    \begin{equation}
        \{ x\in P\tq f(x)\leq M \}
    \end{equation}
    est borné.
\end{definition}
En langage imagé la coercivité de \( f\) s'exprime par la limite
\begin{equation}
    \lim_{\substack{\| x \|\to \infty\\x\in P}}f(x)=+\infty.
\end{equation}


Nous rappelons que \( S^{++}(n,\eR)\) est l'ensemble des matrices symétriques strictement définies positives définies en~\ref{NORMooAJLHooQhwpvr}.
\begin{proposition}     \label{PROPooYRLDooTwzfWU}
    Soit \( A\in S^{++}(n,\eR)\) et \( b\in \eR^n\). Nous considérons l'application
    \begin{equation}
        \begin{aligned}
            f\colon \eR^n&\to \eR \\
            x&\mapsto \frac{ 1 }{2}\langle Ax, x\rangle +\langle b, x\rangle .
        \end{aligned}
    \end{equation}
    Alors :
    \begin{enumerate}
        \item
            Il existe un unique \( \bar x\in \eR^n\) tel que \( A\bar x=-b\).
        \item
            Il existe un unique \( x^*\in \eR^n\) minimisant \( f\).
        \item
            Ils sont égaux : \( \bar x=x^*\).
    \end{enumerate}
\end{proposition}

\begin{proof}

    Une matrice symétrique strictement définie positive est inversible, entre autres parce qu'elle se diagonalise par des matrices orthogonales (qui sont inversibles) et que la matrice diagonalisée est de déterminant non nul : tous les éléments diagonaux sont strictement positifs. Voir le théorème spectral symétrique~\ref{ThoeTMXla}.

    D'où l'unicité du \( \bar x\) résolvant le système \( Ax=-b\) pour n'importe quel \( b\).

    \begin{subproof}
    \item[\( f\) est strictement convexe]

        La fonction \( f\) s'écrit
    \begin{equation}
        f(x)=\frac{ 1 }{2}\sum_{kl}A_{kl}x_lx_k+\sum_kb_kx_k.
    \end{equation}
    Elle est de classe \( C^2\) sans problèmes, et il est vite vu que \( \frac{ \partial^2f }{ \partial x_i\partial x_j }=A_{ij}\), c'est-à-dire que \( A\) est la matrice hessienne de \( f\). Cette matrice étant strictement définie positive par hypothèse, la fonction \( f\) est strictement convexe par le corollaire~\ref{CORooMBQMooWBAIIH}\ref{ITEMooDGISooPlRLOd}.

\item[\( f\) est coercive]
    Montrons à présent que \( f\) est coercive. Nous avons :
    \begin{subequations}
        \begin{align}
            | f(x) |&=\big| \frac{ 1 }{2}\langle Ax, x\rangle +\langle b, x\rangle  \big|\\
            &\geq\frac{ 1 }{2}| \langle Ax, x\rangle  |-| \langle b, x\rangle  |\\
            &\geq\frac{ 1 }{2}\lambda_{max}\| x \|^2-\| b \|\| x \|
        \end{align}
    \end{subequations}
    Pour la dernière ligne nous avons nommé \( \lambda_{max}\) la plus grande valeur propre de \( A\) et utilisé Cauchy-Schwarz pour le second terme. Nous avons donc bien \( | f(x) |\to \infty\) lorsque \( \| x \|\to\infty\) et la fonction \( f\) est coercive.
    \end{subproof}

    Soit \( M\) une valeur atteinte par \( f\). L'ensemble
    \begin{equation}
        \{ x\in \eR^n\tq f(x)\leq M \}
    \end{equation}
    est fermé (parce que \( f\) est continue) et borné parce que \( f\) est coercive. Cela est donc compact\footnote{Théorème~\ref{ThoXTEooxFmdI}} et \( f\) atteint un minimum qui sera forcément dedans. Cela est pour l'existence d'un minimum.

    Pour l'unicité du minimum nous invoquons la convexité : si \( \bar x_1\) et \( \bar x_2\) sont deux points réalisant le minimum de \( f\), alors
    \begin{equation}
        f\left( \frac{ \bar x_1+\bar x_2 }{2} \right)<\frac{ 1 }{2}f(\bar x_1)+\frac{ 1 }{2}f(\bar x_2)=f(\bar x_1),
    \end{equation}
    ce qui contredit la minimalité de \( f(\bar x_1)\).

    Nous devons maintenant prouver que \( \bar x\) vérifie l'équation \( A\bar x=-b\). Vu que \( \bar x\) est minimum local de \( f\) qui est une fonction de classe \( C^2\), le théorème des minima locaux~\ref{PropUQRooPgJsuz} nous indique que \( \bar x\) est solution de \( \nabla f(x)=0\). Calculons un peu cela avec la formule
    \begin{equation}
        df_x(u)=\Dsdd{ f(x+tu) }{t}{0}=\frac{ 1 }{2}\big( \langle Ax, u\rangle +\langle Au, x\rangle  \big)+\langle b, u\rangle =\langle Ax, u\rangle +\langle b, u\rangle =\langle Ax+b, u\rangle .
    \end{equation}
    Donc demander \( df_x(u)=0\) pour tout \( u\) demande \( Ax+b=0\).
\end{proof}

\begin{proposition}[Gradient à pas optimal] \label{PropSOOooGoMOxG}
    Soit \( A\in S^{++}(n,\eR)\) (\( A\) est une matrice symétrique strictement définie positive) et \( b\in \eR^n\). Nous considérons l'application
    \begin{equation}
        \begin{aligned}
            f\colon \eR^n&\to \eR \\
            x&\mapsto \frac{ 1 }{2}\langle Ax, x\rangle +\langle b, x\rangle .
        \end{aligned}
    \end{equation}
    Soit \( x_0\in \eR^n\). Nous définissons la suite \( (x_k)\) par
    \begin{equation}
        x_{k+1}=x_k+t_kd_k
    \end{equation}
    où
    \begin{itemize}
        \item
    \( d_k=-(\nabla f)(x_k)\)
\item
    \( t_k\) est la valeur minimisant la fonction \( t\mapsto f(x_k+td_k)\) sur \( \eR\).
    \end{itemize}

    Alors pour tout \( k\geq 0\) nous avons
    \begin{equation}
        \| x_k-\bar x \|\leq K \left( \frac{ c_2(A)-1 }{ c_2(A)+1 } \right)^k
    \end{equation}
    où \( c_2(A)=\frac{ \lambda_{max} }{ \lambda_{min} }\) est le rapport ente la plus grande et la plus petite valeur propre\quext{Cela est certainement très lié au conditionnement de la matrice \( A\), voir la proposition~\ref{PROPooNUAUooIbVgcN}.} de la matrice \( A\) et \( \bar x\) est l'unique élément de \( \eR^n\) à minimiser \( f\).
\end{proposition}

\begin{proof}
    Décomposition en plusieurs points.
    \begin{subproof}
    \item[Existence de \( \bar x\)]
        Le fait que \( \bar x\) existe et soit unique est la proposition~\ref{PROPooYRLDooTwzfWU}.
    \item[Si \( (\nabla f)(x_k)=0\)]
    D'abord si \( \nabla f(x_k)=0\), c'est que \( x_{k+1}=x_k\) et l'algorithme est terminé : la suite est stationnaire. Pour dire que c'est gagné, nous devons prouver que \( x_k=\bar x\). Pour cela nous écrivons (à partir de maintenant «\( x_k\)» est la \( k\)\ieme composante de \( x\) qui est une variable, et non le \( x_k\) de la suite)
    \begin{equation}
        f(x)=\frac{ 1 }{2}\sum_{kl}A_{kl}x_lx_k+\sum_{k}b_kx_k
    \end{equation}
    et nous calculons \( \frac{ \partial f }{ \partial x_i }(a)\) en tenant compte du fait que \( \frac{ \partial x_k }{ \partial x_i }=\delta_{ki}\). Le résultat est que \( (\partial_if)(a)=(Ax+b)_i\) et donc que
    \begin{equation}
        (\nabla f)(a)=Aa+b.
    \end{equation}
    Vu que \( A\) est inversible (symétrique définie positive), il existe un unique \( a\in \eR^n\) qui vérifie cette relation. Par la proposition~\ref{PROPooYRLDooTwzfWU}, cet élément est le minimum \( \bar x\).

    Cela pour dire que si \( a\in \eR^n\) vérifie \( (\nabla f)(a)=0\) alors \( a=\bar x\). Nous supposons donc à partir de maintenant que \( \nabla f(x_k)\neq 0\) pour tout \( k\).
        \item[\( t_k\) est bien défini]

            Pour \( t\in \eR\) nous avons
            \begin{equation}    \label{EqKEHooYaazQi}
                f(x_k+td_k)=f(x_k)+\frac{ 1 }{2}t^2\langle Ad_k, d_k\rangle +t\langle \underbrace{Ax_k+b}_{=-d_k}, d_k\rangle=\frac{ 1 }{2}t^2\langle Ad_k, d_k\rangle -t_k\| d_k \|^2 +f(x_k).
            \end{equation}
            qui est un polynôme du second degré en \( t\). Le coefficient de \( t^2\) est \( \frac{ 1 }{2}\langle Ad_k, d_k\rangle >0\) parce que \( d_k\neq 0\) et \( A\) est strictement définie positive. Par conséquent la fonction \( t\mapsto f(x_k+td_k)\) admet bien un unique minimum. Nous pouvons même calculer \( t_k\) parce que l'on connaît pas cœur le sommet d'une parabole :
            \begin{equation}    \label{EqVWJooWmDSER}
                t_k=-\frac{ \langle Ax_k+b, d_k\rangle  }{ \langle Ad_k, d_k\rangle  }=\frac{ \| d_k \|^2 }{ \langle Ad_k, d_k\rangle  }
            \end{equation}
            parce que \( d_k=-\nabla f(x_k)=-(Ax_k+b)\).

        \item[La valeur de \( d_{k+1}\)]

            Par définition, \( d_{k+1}=-\nabla f(x_{k+1})=-(Ax_{k+1}+b)\). Mais \( x_{k+1}=x_k+t_kd_k\), donc
            \begin{equation}
                d_{k+1}=-Ax_k-t_kAd_k-b=d_k-t_kAd_k
            \end{equation}
            parce que \( -Ax_k-b=d_k\).

            Par ailleurs, \( \langle d_{k+1}, d_k\rangle =0\) parce que
            \begin{equation}
                \langle d_{k+1}, d_k\rangle =\langle d_k, d_k\rangle -t_k\langle d_k, Ad_k\rangle =\| d_k \|^2-\frac{ \| d_k \|^2 }{ \langle Ad_k, d_k\rangle  }\langle d_k, Ad_k\rangle =0
            \end{equation}
            où nous avons utilisé la valeur \eqref{EqVWJooWmDSER} de \( t_k\).

        \item[Calcul de \( f(x_{k+1})\)]

            Nous repartons de \eqref{EqKEHooYaazQi} où nous substituons la valeur \eqref{EqVWJooWmDSER} de \( t_k\) :
            \begin{equation}
                f(x_{k+1})=f(x_k)+\frac{ 1 }{2}\frac{ \| d_k \|^4 }{ \langle Ad_k, d_k\rangle  }-\frac{ \| d_k \|^4 }{ \langle Ad_k, d_k\rangle  }=f(x_k)-\frac{ 1 }{2}\frac{ \| d_k \|^4 }{ \langle Ad_k, d_k\rangle  }.
            \end{equation}

        \item[Encore du calcul \ldots]

            Vu que le produit \( \langle Ad_k, d_k\rangle \) arrive tout le temps, nous allons étudier \( \langle A^{-1}d_k, d_k\rangle \). Le truc malin est d'essayer d'exprimer ça en termes de \( \bar x\) et \( \bar f=f(\bar x)\). Pour cela nous calculons \( f(\bar x)\) :
            \begin{equation}
                \bar f=f(\bar x)=f(-A^{-1} b)=-\frac{ 1 }{2}\langle b, A^{-1}b\rangle .
            \end{equation}
            Ayant cela en tête nous pouvons calculer :
            \begin{subequations}
                \begin{align}
                    \langle A^{-1}d_k, d_k\rangle &=\langle A^{-1}(Ax_k+b), Ax_k+b\rangle \\
                    &=\langle x_k, Ax_k\rangle +\langle A^{-1}b, Ax_k\rangle +\langle b, x_k\rangle+\underbrace{\langle A^{-1}b, b\rangle}_{-2\bar f} \\
                    &=\langle x_k, Ax_k\rangle +2\langle x_k, b\rangle  -2\bar f \label{subeqVIIooVzZlRc}\\
                    &=2\big( f(x_k)-\bar f \big)
                \end{align}
            \end{subequations}
            où nous avons utilisé le fait que \( \langle x, Ay\rangle =\langle Ax, y\rangle \) parce que \( A\) est symétrique.

        \item[Erreur sur la valeur du minimum]

            Nous voulons à présent estimer la différence \( f(x_{k+1})-\bar f\). Pour cela nous mettons en facteur \( f(x_k)-\bar f\) dans \( f(x_{k+1}-\bar f)\); et d'ailleurs c'est pour cela que nous avons calculé \( \langle A^{-1}d_k, d_k\rangle \) : parce que ça fait intervenir \( f(x_k)-\bar f\).
            \begin{subequations}
                \begin{align}
                    f(x_{k+1})-\bar f&=f(x_k)-\frac{ 1 }{2}\frac{ \| d_k \|^4 }{ \langle Ad_k, d_k\rangle  }-\bar f\\
                    &=\big( f(x_k)-\bar f \big)\left( 1-\frac{ 1 }{2}\frac{ \| d_k \|^{4} }{ \langle Ad_k, d_k\rangle \big( f(x_k)-\bar f \big) } \right)\\
                    &=\big( f(x_k)-\bar f \big)\left( 1-\frac{ \| d_k \|^{4} }{ \langle Ad_k, d_k\rangle \langle A^{-1}d_k, d_k\rangle  } \right).\label{subeqGFDooRAwAJk}
                \end{align}
            \end{subequations}
            Nous traitons le dénominateur à l'aide de l'inégalité de Kantorovitch~\ref{PropMNUooFbYkug}. Nous avons
            \begin{equation}
                \frac{ \| d_k \|^4 }{ \langle Ad_k, d_k\rangle \langle A^{-1}d_k, d_k\rangle  }\geq \frac{ \| d_k \|^4 }{ \frac{1}{ 4 }\left( \sqrt{c_2(A)}+\frac{1}{ \sqrt{c_2(A)} } \right)^2\| d_k \|^4 }=\frac{ 4c_2(A) }{ (c_2(A)+1)^2 }.
            \end{equation}
            Mettre cela dans \eqref{subeqGFDooRAwAJk} est un calcul d'addition de fractions :
            \begin{equation}
                f(x_{k+1})-\bar f\leq \big( f(x_k)-\bar f \big)\left( \frac{ c_2(A)-1 }{ c_2(A)+1 } \right)^2.
            \end{equation}
            Par récurrence nous avons alors
            \begin{equation}    \label{eqANKooNPfCFj}
                f(x_k)-\bar f\leq \big( f(x_0)-\bar f \big)\left( \frac{ c_2(A)-1 }{ c_2(A)+1 } \right)^{2k}.
            \end{equation}
            Notons qu'il n'y a pas de valeurs absolues parce que \( \bar f\) étant le minimum de \( f\), les deux côtés de l'inégalité sont automatiquement positifs.

        \item[Erreur sur la position du minimum]

            Nous voulons à présent étudier la norme de \( x_k-\bar x\). Pour cela nous l'écrivons directement avec la définition de \( f\) en nous souvenant que \( b=-A\bar x\) :
            \begin{subequations}
                \begin{align}
                    f(x_k)-\bar f&=\frac{ 1 }{2}\langle Ax_k, x_k\rangle +\langle A\bar x, x_k\rangle +\frac{ 1 }{2}\langle A\bar x, \bar x\rangle +\langle A\bar x, \bar x\rangle \\
                    &=\frac{ 1 }{2}\langle Ax_k, x_k\rangle -\langle A\bar x, x_k\rangle +\frac{ 1 }{2}\langle A\bar x, \bar x\rangle \\
                    &=\frac{ 1 }{2}\langle Ax_k, x_k\rangle -\frac{ 1 }{2}\langle A\bar x, x_k\rangle-\frac{ 1 }{2}\langle A\bar x, x_k\rangle +\frac{ 1 }{2}\langle A\bar x, \bar x\rangle \\
                    &=\frac{ 1 }{2}\Big( \langle A(x_k-\bar x), x_k\rangle +\langle A\bar x, \bar x-x_k\rangle  \Big)\\
                    &=\frac{ 1 }{2}\Big( \langle A(x_k-\bar x), (x_k-\bar x)\rangle  \Big)
                \end{align}
            \end{subequations}
            où à la dernière ligne nous avons fait \( \langle A\bar x, \bar x-x_k\rangle =\langle \bar x, A(\bar x-x_k)\rangle \) en vertu de la symétrie de \( A\).

            Les produits de la forme \( \langle Ay, y\rangle \) sont majorés par \( \lambda_{min}\| y \|^2\) parce que \( \lambda_{min}\) est la plus grande valeur propre de \( A\). Dans notre cas,
            \begin{equation}    \label{EqVMRooUMXjig}
                f(x_k)-\bar f\geq \frac{ 1 }{2}\lambda_{min}\| x_k-\bar x \|^2
            \end{equation}

        \item[Conclusion]

            En combinant les inéquations \eqref{EqVMRooUMXjig} et \eqref{eqANKooNPfCFj} nous trouvons
            \begin{equation}
                \frac{ 1 }{2}\lambda_{min}\| x_k-\bar x \|^2\leq f(x_k)-\bar f\leq \big( f(x_0)-\bar f \big)\left( \frac{ c_2(A)-1 }{ c_2(A)+1 } \right)^{2k},
            \end{equation}
            c'est-à-dire
            \begin{equation}
                \| x_k-\bar x \|\leq \sqrt{\frac{ 2\big( f(x_0)-\bar f \big) }{ \lambda_{min} +1}}^{2k}.
            \end{equation}
    \end{subproof}
\end{proof}

Notons que lorsque \( c_2(A)\) est proche de \( 1\) la méthode converge rapidement. Par contre si \( c_2(A)\) est proche de zéro, la méthode converge lentement.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Formes quadratiques, signature, et lemme de Morse}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{normaltext}      \label{NORMooHSWKooLtUbRl}
    Soit \( (E,\| . \|_E)\) un espace vectoriel réel normé de dimension finie \( n\). L'ensemble des formes quadratiques réelles\footnote{Définition~\ref{DefBSIoouvuKR}.} sur \( E\) est vu comme l'ensemble des matrices symétriques \( S_n(\eR)\); il sera noté \( Q(E)\) et le sous-ensemble des formes quadratiques non dégénérées est \( S_n(\eR)\cap\GL(n,\eR)\) qui sera noté \( \Omega(E)\)\nomenclature[B]{\( \Omega(E)\)}{formes quadratiques non dégénérées}. Nous rappelons que la correspondance est donnée de la façon suivante. 
    
    Si \( A\in S_n(\eR)\), la forme quadratique associée est \( q_A\) donnée par le produit scalaire \( q_A(x)=x\cdot Ax\).
\end{normaltext}

\begin{normaltext}      \label{NORMooQZFLooYnILtn}
Nous noterons encore \( Q^+(E)\)\nomenclature[B]{\( Q^+(E)\)}{formes quadratiques positives} les formes quadratiques positives sur \( E\) et \( Q^{++}(E)\)\nomenclature[B]{\( Q^{++}(E)\)}{formes quadratiques strictement définies positives} les formes quadratiques strictement définies positives sur \( E\).
\end{normaltext}

Sur \( Q(E)\) nous mettons la norme
\begin{equation}
    N(q)=\sup_{\| x \|_E=1}| q(x) |,
\end{equation}
qui du point de vue de \( S_n(\eR)\) est
\begin{equation}    \label{EqDOgBNAg}
    N(A)=\sup_{\| x \|_E=1}| x^tAx |.
\end{equation}
Notons que à droite, c'est la valeur absolue usuelle sur \( \eR\).

Nous savons par le théorème de Sylvester (théorème~\ref{ThoQFVsBCk}) que dans \( \eM(n,\eR)\), toute matrice symétrique de signature \( (p,q)\) est semblable à la matrice
\begin{equation}
    \mtu_{p,q}=\begin{pmatrix}
        \mtu_p    &       &       \\
        &   \mtu_{p}    &       \\
        &       &   0_{n-p-q}
    \end{pmatrix}.
\end{equation}
Donc deux matrices de \( S_n\) sont semblables si et seulement si elles ont la même signature (même si elles ne sont pas de rang maximum, cela soit dit au passage). Si nous notons \( S_n^{p,q}(\eR)\)\nomenclature[B]{\( S_n^{p,q}(\eR)\)}{matrices symétriques réelles de signature \( (p,q)\)} l'ensemble des matrices réelles symétriques de signature \( (p,q)\), alors
\begin{equation}
    S_n^{p,q}(\eR)=\{ P^tAP\tq P\in \GL(n,\eR) \}
\end{equation}
où \( A\) est une quelconque ce ces matrices.

Nous voudrions en savoir plus sur ces ensembles. En particulier nous aimerions savoir si la signature est une notion «stable» au sens où ces ensembles seraient ouverts dans \( S_n\). Pour cela nous considérons l'action de \( \GL(n,\eR)\) sur \( S_n\) définie par
\begin{equation}
    \begin{aligned}
        \alpha\colon \GL(n,\eR)\times S_n(\eR)&\to S_n(\eR) \\
        (P,A)&\mapsto P^tAP
    \end{aligned}
\end{equation}
faite exprès pour que les orbites de cette action soient les ensembles \( S_n^{p,q}(\eR)\).

La proposition suivante montre que lorsque \( p+q=n\), c'est-à-dire lorsqu'on parle de matrices de rang maximum, les ensembles \( S_n^{p,q}(\eR)\) sont ouverts, c'est-à-dire que la signature d'une forme quadratique est une propriété «stable» par petite variations des éléments de matrice. Notons tout de suite que si le rang n'est pas maximum, le théorème de Sylvester dit qu'elle est semblable à une matrice diagonale avec des zéros sur la diagonale; en modifiant un peu ces zéros, on peut modifier évidemment la signature.
\begin{proposition}[\cite{KXjFWKA}] \label{PropNPbnsMd}
    Soit \( (E,\| . \|_{E})\) un espace vectoriel normé de dimension finie. Alors
    \begin{enumerate}
        \item
            les formes quadratiques non dégénérées forment un ouvert dans l'ensemble des formes quadratiques,
        \item
            les ensembles \( S_n^{p,q}(\eR)\) avec \( p+q=n\) sont ouverts dans \( S_n(\eR)\),
        \item   \label{ItemGOhRIiViii}
            les composantes connexes de \( \Omega(E)\) sont les \( S_n^{p,q}(\eR)\) avec \( p+q=n\),
        \item   \label{ItemGOhRIiViv}
            les \( S_n^{p,q}(\eR)\) non dégénérés sont connexes par arc.
    \end{enumerate}
\end{proposition}
\index{connexité!signature d'une forme quadratique}
\index{matrice!symétrique!réelle}
\index{forme!quadratique}

\begin{proof}
    Cette preuve est donnée du point de vue des matrices. La différence entre le point~\ref{ItemGOhRIiViii} et~\ref{ItemGOhRIiViv} est que dans le premier nous prouvons la connexité de \( S_n^{p,q}(\eR)\) à partir de la connexité de \( \GL^+(n,\eR)\), tandis que dans le second nous prouvons la connexité par arc de \( S_n^{p,q}(\eR)\) à partir de la connexité par arc de \( \GL^+(n,\eR)\). Bien entendu le second implique le premier.
    \begin{enumerate}
        \item
            Il s'agit simplement de remarquer que \( Q(E)=S_n(\eR)\), que \( \Omega(E)=S_n(\eR)\cap\GL(n,\eR)\) et que le déterminant est une fonction continue sur \( \eM(n,\eR)\).
        \item
            Soit \( A_0\in S_n^{p,q}(\eR)\). Le théorème de Sylvester~\ref{ThoQFVsBCk} nous donne une matrice inversible \( P\) telle que \( P^tA_0P=\mtu_{p,q}\). Nous allons montrer qu'il existe un voisinage \( \mU\) de \( \mtu_{p,q}\) contenu dans \( S_n^{p,q}(\eR)\). À partir de là, l'ensemble \( (P^{-1})^t\mU P^{-1}\) sera un voisinage de \( A_0\) contenu dans \( S_n^{p,q}(\eR)\).

            Nous considérons les espaces vectoriels
            \begin{subequations}
                \begin{align}
                    F&=\Span\{ e_1,\ldots, e_p \}\\
                    G&=\Span\{ e_{p+1},\ldots, e_n \}
                \end{align}
            \end{subequations}
            La norme euclidienne \( \| . \|_p\) sur \( F\) est équivalente à la norme \( | . |_E\) par le théorème~\ref{ThoNormesEquiv}. Donc il existe une constante \( k_1>0\) telle que pour tout \( x\in F\),
            \begin{equation}    \label{EqMViCjJJ}
                \| x \|_p\geq k_1\| x \|_E.
            \end{equation}
            De la même façon sur \( G\), il existe une constante \( k_2>0\) telle que
            \begin{equation}    \label{EqSFwOcDw}
                \| x \|_q\geq k_2\| x \|_E.
            \end{equation}
            Si nous posons \( k=\min\{ k_1^2,k_2^2 \}\), alors nous avons
            \begin{subequations}
                \begin{align}
                    \forall x\in F,\quad &\| x \|_p^2\geq k_1^2\| x \|_E^2\geq k\| x \|_E^2\\
                    \forall x\in G,\quad &\| x \|_q^2\geq k_2^2\| x \|_E^2\geq k\| x \|_E^2.
                \end{align}
            \end{subequations}

            Soit une matrice \( A\in S_n(\eR)\) telle que \( N(A-\mtu_{p,q})<k\), c'est-à-dire que \( A\) est dans un voisinage de \( \mtu_{p,q}\) pour la norme sur \( S_n(\eR)\) donné par \eqref{EqDOgBNAg}. Si \( x\) est non nul dans \( E\), nous avons
            \begin{equation}
                \big| x^t(A-\mtu_{p,q})x \big|\leq N(\mtu_{p,q}-A)\| x \|^2\leq k\| x \|^2.
            \end{equation}
            En déballant la valeur absolue, cela signifie que
            \begin{equation}
                -k\| x \|_E^2\leq x^t(A-\mtu_{p,q})x\leq k\| x \|^2.
            \end{equation}
            Si \( x\in F\), alors la première inéquation et \eqref{EqMViCjJJ} donnent
            \begin{equation}
                x^tAx\geq \| x \|_p^2-k\| x \|_E^2>0
            \end{equation}
            Si \( x\in G\), alors la seconde inéquation et \eqref{EqSFwOcDw} donnent
            \begin{equation}
                x^tAx\leq  k\| x \|_E^2-\| x \|_q^2<0.
            \end{equation}

            Nous avons donc montré que \( x\mapsto x^tAx\) est positive sur \( F\) et négative sur \( G\), ce qui prouve que \( A\) est bien de signature \( (p,q)\) et appartient donc à \( S_n^{p,q}(\eR)\). Autrement dit nous avons
            \begin{equation}
                B(\mtu_{p,q},k)\subset S_n^{p,q}(\eR).
            \end{equation}

        \item
            Cette partie de la preuve provient essentiellement de \cite{VKqpMYL}, et fonctionne pour tous les \( S_n^{p,q}(\eR)\), même pour ceux qui ne sont pas de rang maximum.

            Soit \( A\in S_n^{p,q}(\eR)\). Nous savons que \( \GL(n,\eR)\) a deux composantes connexes (proposition~\ref{PROPooBIYQooWLndSW}). Vu que l'application
            \begin{equation}
                \begin{aligned}
                    \alpha\colon \GL(n,\eR)&\to S_n \\
                    P&\mapsto P^tAP
                \end{aligned}
            \end{equation}
            est continue, l'image d'un connexe de \( \GL(n,\eR)\) par \( \alpha\) est connexe (proposition~\ref{PropGWMVzqb}). En particulier, \( \alpha\big( \GL^{\pm}(n,\eR) \big)\) sont deux connexes et nous savons que \( S_n^{p,q}(\eR)\) a au plus ces deux composantes connexes.

            Notre but est maintenant de trouver une intersection entre les parties \( \alpha\big( \GL^+(n,\eR) \big)\) et \( \alpha\big( \GL^-(n,\eR) \big)\)\quext{À ce point, il me semble que \cite{VKqpMYL} fait erreur parce que la matrice \( -\mtu_n\) est de déterminant \( 1\) lorsque \( n\) est pair. L'argument donné ici provient de \cite{KXjFWKA}}. Soit par le théorème de Sylvester, soit par le théorème de diagonalisation des matrices symétriques réelles~\ref{ThoeTMXla}, il existe une matrice \( P\in \GL(n,\eR)\) diagonalisant \( A\). En suivant la remarque~\ref{RemGKDZfxu}, et en notant \( Q\) la matrice obtenue à partir de \( P\) en changeant le signe de sa première ligne, nous avons
            \begin{equation}
                \alpha(Q)=Q^tAQ=P^tAP=\alpha(P).
            \end{equation}
            Or si \( P\in \GL^+(n,\eR)\), alors \( Q\in \GL^-(n,\eR)\) et inversement. Donc nous avons trouvé une intersection entre \( \alpha\big( \GL^+(n,\eR) \big)\) et \( \alpha\big( \GL^-(n,\eR) \big)\).

        \item

            Soient \( A\) et \( B\) dans \( S_n^{p,q}(\eR)\cap\GL(n,\eR)\). Par le théorème de Sylvester, il existe \( P\) et \( Q\) dans \( \GL(n,\eR)\) telles que \( A=P^t\mtu_{p,q}P\) et \( B=Q^t\mtu_{p,q}Q\). Par la remarque~\ref{RemGKDZfxu} nous pouvons choisir \( P\) et \( Q\) dans \( \GL^+(n,\eR)\). Ce dernier groupe étant connexe par arc, il existe un chemin
            \begin{equation}
                    \gamma\colon \mathopen[ 0 , 1 \mathclose]\to \GL^+(n,\eR)
            \end{equation}
            tel que \( \gamma(0)=P\) et \( \gamma(1)=Q\). Alors le chemin
            \begin{equation}
                s\mapsto \gamma(s)^t\mtu_{p,q}\gamma(s)
            \end{equation}
            est un chemin continu dans \( S_n^{p,q}(\eR)\) joignant \( A\) à \( B\).
    \end{enumerate}
\end{proof}
% TODO : prouver la connexité par arc de GL^+(n,\eR) et mettre une référence ici.

Nous savons déjà de la proposition~\ref{PropNPbnsMd} que les ensembles \( S_n^{p,q}(\eR)\) (pas spécialement de rang maximum) sont ouverts dans \( S_n(\eR)\). Le lemme suivant nous donne une précision à ce sujet, dans le cas des matrices de rang maximum, en disant que la matrice qui donne la similitude entre \( A_0\) et \( A\) est localement un \( C^1\)-difféomorphisme de \( A\).
\begin{lemma}   \label{LemWLCvLXe}
    Soit \( A_0\in \Omega(\eR^n)= S_n\cap\GL(n,\eR)\), une matrice symétrique inversible. Alors il existe un voisinage \( V\) de \( A_0\) dans \( S_n\) et une application \( \phi\colon V\to \GL(n,\eR)\) qui
    \begin{enumerate}
        \item
            est de classe \( C^1\),
        \item
            est telle que pour tout \( A\in V\), \( \varphi(A)^t A_0\phi(A)=A\).
    \end{enumerate}
\end{lemma}
\index{groupe!\( \GL(n,\eR)\)}
\index{forme!quadratique}
\index{matrice!symétrique}
\index{matrice!semblables}

\begin{proof}
    Nous considérons l'application
    \begin{equation}
        \begin{aligned}
            \varphi\colon \eM(n,\eR)&\to S_n \\
            M&\mapsto M^tA_0M.
        \end{aligned}
    \end{equation}
    Étant donné que les composantes de \( \varphi(M)\) sont des polynômes en les entrées de \( M\), cette application est de classe \( C^1\) -- et même plus. Soit maintenant \( H\in \eM(n,\eR)\) et calculons \( d\varphi_{\mtu}(H)\) par la formule \eqref{EqOWQSoMA} :
    \begin{subequations}
        \begin{align}
            d\varphi_{\mtu}(H)&=\Dsdd{ \varphi(\mtu+tH) }{t}{0}\\
            &=\Dsdd{ (\mtu+tH^t)A_0(\mtu+tH) }{t}{0}\\
            &=\Dsdd{ A_0+tA_0H+tH^tA_0+t^2H^tA_0H }{t}{0}\\
            &=A_0H+H^tA_0.
        \end{align}
    \end{subequations}
    Donc
    \begin{equation}
        d\varphi_{\mtu}(H)=(A_0H)+(A_0H)^t.
    \end{equation}
    Par conséquent
    \begin{equation}
        \ker(d\varphi_{\mtu})=\{ H\in \eM(n,\eR)\tq A_0H\text{ est antisymétrique} \},
    \end{equation}
    et si nous posons
    \begin{equation}
        F=\{ H\in \eM(n,\eR)\tq A_0H\text{ est symétrique} \}
    \end{equation}
    nous avons
    \begin{equation}
        \eM(n,\eR)=F\oplus\ker(d\varphi_{\mtu})
    \end{equation}
    parce que toute matrice peur être décomposée de façon unique en partir symétrique et antisymétrique. De plus l'application
    \begin{equation}    \label{EqGTBusDm}
        \begin{aligned}
            f\colon F&\to S_n \\
            H&\mapsto A_0H
        \end{aligned}
    \end{equation}
    est une bijection linéaire. D'abord \( A_0H=0\) implique \( H=0\) parce que \( A_0\) est inversible, et ensuite si \( X\in S_n\), alors \( X=A_0A_0^{-1}X\), ce qui prouve que \( X\) est l'image par \( f\) de \( A_0^{-1}X\) et donc que \( f\) est surjective.

    Maintenant nous considérons la restriction \( \psi=\varphi_{|_F}\), \( \psi\colon F\to S_n\). Remarquons que \( \mtu\in F\) parce que \( A_0\in S_n\). L'application \( d\psi_{\mtu}\) est une bijection. En effet d'abord
    \begin{equation}
        d(\varphi_{|_F})_{\mtu}=(d\varphi_{\mtu})_{|_F},
    \end{equation}
    ce qui prouve que
    \begin{equation}
        \ker(d\psi_{\mtu})=\ker(d\varphi_{\mtu})\cap F=\{ 0 \},
    \end{equation}
    ce qui prouve que \( d\psi_{\mtu}\) est injective. Pour montrer que \( d\psi_{\mtu}\) est surjective, il suffit de mentionner le fait que \( \dim F=\dim S_n\) du fait que l'application \eqref{EqGTBusDm} est une bijection linéaire.

    Nous pouvons utiliser le théorème d'inversion locale (théorème~\ref{ThoXWpzqCn}) et conclure qu'il existe un voisinage ouvert \( U\) de \( \mtu\) dans \( F\) tel que \( \psi\) soit un difféomorphisme \( C^1\) entre \( U\) et \( V=\psi(U)\). Vu que \( \GL(n,\eR)\) est ouvert dans \( \eM(n,\eR)\), nous pouvons prendre \( U\cap \GL(n,\eR)\) et donc supposer que \( U\subset \GL(n,\eR)\).

    Pour tout \( A\in V\), il existe une unique \( M\in U\) telle que \( \psi(M)=A\), c'est-à-dire telle que \( A=M^tA_0M\). Cette matrice \( M\) est \( \psi^{-1}(A)\) et est une matrice inversible. Bref, nous posons
    \begin{equation}
        \begin{aligned}
            \phi\colon V&\to \GL(n,\eR) \\
            A&\mapsto \psi^{-1}(A),
        \end{aligned}
    \end{equation}
    et ce \( \phi\) est de classe \( C^1\) sur \( V\) parce que c'est ce que dit le théorème d'inversion locale. Cette application répond à la question parce que \( V\) est un voisinage de \( \varphi(\mtu)=A_0\) et pour tout \( A\in V\) nous avons
    \begin{equation}
        \phi(A)^tA_0\phi(A)=\varphi^{-1}(A)^tA_0\varphi^{-1}(A)=A.
    \end{equation}
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Lemme de Morse}
%---------------------------------------------------------------------------------------------------------------------------

\begin{lemma}[Lemme de Morse]     \label{LemNQAmCLo}
    Soit \( f\in C^3(\mU,\eR)\) où \( \mU\) est un ouvert de \( \eR^n\) contenant \( 0\). Nous supposons que \( df_0=0\) et que \( d^2f_0\) est non dégénérée\footnote{En tant qu'application bilinéaire.} et de signature \( (p,n-p)\). Alors il existe un \( C^1\)-difféomorphisme \( \varphi\) entre deux voisinages de \( 0\) dans \( \eR^n\) tel que
    \begin{enumerate}
        \item
            \( \varphi(0)=0\),
        \item
            si \( \varphi(x)=u\) alors
            \begin{equation}
                f(x)-f(0)=u_1^2+\cdots +u_p^2-u_{p+1}^2-\ldots-u_n^2.
            \end{equation}
    \end{enumerate}
    Une autre façon de dire est qu'il existe un \( C^1\)-difféomorphisme local \( \psi\) tel que
    \begin{equation}
        (f\circ\psi)(x)-f(0)=x_1^2+\cdots +x_p^2-x_{p+1}^2-\ldots-x_n^2.
    \end{equation}
\end{lemma}
\index{lemme!de Morse}
\index{développement!Taylor}
\index{application!différentiable}
\index{forme!quadratique}
\index{théorème!inversion locale!utilisation}
\index{action de groupe!sur des matrices}
\index{extremum}

\begin{proof}
    Nous allons noter \( Hf\) la matrice hessienne de \( f\), c'est-à-dire \( Hf_a=d^2f_a\in\aL^{(2)}(\eR^n,\eR)\). Écrivons la formule de Taylor avec reste intégral (proposition~\ref{PropAXaSClx} avec \( p=0\) et \( m=2\)) :
    \begin{equation}
        f(x)-f(0)=\underbrace{df_0(x)}_{=0}+\int_0^1(1-t)\underbrace{d^2f_{tx}(x,x)}_{x^t(Hf)_{tx}x=\langle Hf_{tx}x, x\rangle }dt=x^tQ(x)x
    \end{equation}
    avec
    \begin{equation}
        Q(x)=\int_0^1(1-t)(Hf)_{tx}dt
    \end{equation}
    qui est une intégrale dans \( \aL^{(2)}(\eR^n,\eR)\). Nous prouvons à présent que \( Q\) est de classe \( C^1\) en utilisant le résultat de différentiabilité sous l'intégrale~\ref{PropAOZkDsh}. Pour cela nous passons aux composantes (de la matrice) et nous considérons
    \begin{equation}
        \begin{aligned}
            h_{kl}\colon U\times\mathopen[ 0 , 1 \mathclose]&\to \eR \\
            h_{kl}(x,t)&=(1-t)\frac{ \partial^2f  }{ \partial x_k\partial x_l }(tx).
        \end{aligned}
    \end{equation}
    Étant donné que \( f\) est de classe \( C^3\), la dérivée de \( h_{kl}\) par rapport à \( x_i\) ne pose pas de problèmes :
    \begin{equation}
        \frac{ \partial h_{kl} }{ \partial x_i }=t(t-1)\frac{ \partial^3f  }{ \partial x_i\partial x_k\partial x_l }(tx),
    \end{equation}
    qui est encore continue à la fois en \( t\) et en \( x\). La proposition~\ref{PropAOZkDsh} nous montre à présent que
    \begin{equation}
        Q_{kl}(x)=\int_0^1(1-t)h_{kl}(tx)dt
    \end{equation}
    est une fonction \( C^1\). Étant donné que les composantes de \( Q\) sont \( C^1\), la fonction \( Q\) est également \( C^1\).

    Nous avons \( Q(0)=\frac{ 1 }{2}(Hf)_0\in S_n\cap \GL(n,\eR)\), d'abord parce que \( f\) est \( C^2\) (et donc la matrice hessienne est symétrique), ensuite par hypothèse \( d^2f_0\) est non dégénérée.
    %TODO : prouver que la matrice hessienne est symétrique lorsque f est C^2 (ou vérifier que c'est déjà fait), et référentier ici.

    À partir de là, le lemme~\ref{LemWLCvLXe} donne un voisinage \( V\) de \( Q(0)\) dans \( S_n\) et une application \( \phi\) de classe \( C^1\)
    \begin{equation}
            \phi\colon V\to \GL(n,\eR) \\
    \end{equation}
    telle que pour tout \( A\in V\),
    \begin{equation}
        \phi(A)^tQ(0)\phi(A)=A.
    \end{equation}
    Si on pose \( M=\phi\circ Q\), et si \( x\) est dans un voisinage de zéro, \( Q\) étant continue nous avons \( Q(x)\in V\) et donc
    \begin{equation}
        Q(x)=M(x)^tQ(0)M(x).
    \end{equation}
    Notons que l'application \( \eM\colon \eR\to \GL(n,\eR)\) est de classe \( C^1\) parce que \( Q\) et \( \phi\) le sont.

    Nous avons
    \begin{equation}
        f(x)-f(0)=x^tQ(x)x=x^tM(x)^tQ(0)M(x)x=y(x)^tQ(0)y(x)
    \end{equation}
    où \( y(x)=M(x)x=(\phi\circ Q)(x)x\) est encore une fonction de classe \( C^1\) parce que la multiplication est une application \(  C^{\infty}\).

    D'un autre côté le théorème de Sylvester~\ref{ThoQFVsBCk} nous donne une matrice inversible \( P\) telle que
    \begin{equation}
        Q(0)=P^t\begin{pmatrix}
            \mtu_p    &       \\
            &   -\mtu_{n-p}
        \end{pmatrix}P.
    \end{equation}
    Et nous posons enfin \( u=\varphi(x)=Py(x)\) qui est toujours de classe \( C^1\) et qui donne
    \begin{subequations}
        \begin{align}
            f(x)-f(0)&=y^tQ(0)y\\
            &=y^tP^t\begin{pmatrix}
                \mtu    &       \\
                    &   -\mtu
            \end{pmatrix}Py\\
            &=u^t\begin{pmatrix}
                \mtu    &       \\
                    &   -\mtu
            \end{pmatrix}u\\
            &=u_1^2+\cdots +u_p^2-u_{p+1}^2-\ldots -u_n^2.
        \end{align}
    \end{subequations}

    Nous devons maintenant montrer que, quitte à réduire son domaine à un ouvert plus petit, \( \varphi\) est un \( C^1\)-difféomorphisme. Dans la chaine qui donne \( \varphi\), seule l'application
    \begin{equation}
        \begin{aligned}
            g\colon U\subset \eR^n&\to \eR^n \\
            x&\mapsto M(x)x
        \end{aligned}
    \end{equation}
    est sujette à caution. Nous allons appliquer le théorème d'inversion locale. Nous savons que \( g\) est de classe \( C^1\) et donc différentiable; calculons la différentielle en utilisant la formule \eqref{EqOWQSoMA} :
    \begin{equation}
        dg_0(x)=\Dsdd{ g(tx) }{t}{0}=\Dsdd{ tM(tx)x }{t}{0}=M(0)x.
    \end{equation}
    Note que nous avons utilisé la règle de Leibnitz pour la dérivée d'un produit, mais le second terme s'est annulé. Donc \( dg_0=M(0)\in \GL(n,\eR)\) et \( g\) est localement un \( C^1\)-difféomorphisme.

    Il suffit de restreindre \( \varphi\) au domaine sur lequel \( g\) est un \( C^1\)-difféomorphisme pour que \( \varphi\) devienne lui-même un \( C^1\)-difféomorphisme.

\end{proof}

\begin{definition}
    Un point \( a\) est un \defe{point critique}{point critique!définition} de la fonction différentiable \( f\) si \( df_a=0\).
\end{definition}

\begin{corollary}[\cite{XPautfO}]
    Les points critiques non dégénérés d'une fonction \( C^3\) sont isolés.
\end{corollary}

\begin{proof}
    Soit \( a\) un point critique non dégénéré. Par le lemme de Morse~\ref{LemNQAmCLo}, il existe un \( C^1\)-difféomorphisme \( \psi\) et un entier \( p\) tel que
    \begin{equation}
        (f\circ \psi)(x)=x_1^2+\cdots +x_p^2-x_{p+1}^2-\ldots -x_n^2+f(a)
    \end{equation}
    sur un voisinage \( \mU\) de \( a\). Vue la formule générale \( df_x(u)=\nabla f(x)\cdot u\), si \( x\) est un point critique de \( f\), alors \( \nabla f(x)=0\). Dans notre cas, les points critiques de \( f\circ \psi\) dans \( \mU\) doivent vérifier \( x_i=0\) pour tout \( i\), et donc \( x=a\).

    Nous devons nous assurer que la fonction \( f\) elle-même n'a pas de points critiques dans \( \mU\). Pour cela nous utilisons la formule générale de dérivation de fonction composée :
    \begin{equation}
        \nabla(f\circ\psi)(x)=\sum_k \frac{ \partial f }{ \partial y_k }\big( g(x) \big)\nabla g_k(x).
    \end{equation}
    Si \( \psi(x)\) est une point critique de \( f\), alors le membre de droite est le vecteur nul parce que tous les \( \partial_kf\big( \psi(x) \big)\) sont nuls. Par conséquent le membre de gauche est également nul, et \( x\) est un point critique de \( f\circ\psi\). Or nous venons de voir que \( f\circ\psi\) n'a pas de points critiques dans \( \mU\).

    Donc \( f\) n'a pas de points critiques dans un voisinage d'un point critique non dégénéré.
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Ellipsoïde de John-Loewner}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

C'est le moment de relire les conventions de notations données en \ref{NORMooHSWKooLtUbRl} et \ref{NORMooQZFLooYnILtn} ainsi que la définition \ref{DefBSIoouvuKR} d'une forme quadratique.

Soit \( q\) une forme quadratique sur \( \eR^n\) ainsi que \( \mB\) une base orthonormée de \( \eR^n\) dans laquelle la matrice de  \( q\) est diagonale. Dans cette base, la forme \( q\) est donnée par la proposition~\ref{PropFWYooQXfcVY} :
\begin{equation}
    q(x)=\sum_i\lambda_ix_i
\end{equation}
où les \( \lambda_i\) sont les valeurs propres de \( q\).

Plus généralement nous notons \( mat_{\mB}(q)\)\nomenclature[A]{\( mat_{\mB}(q)\)}{matrice de \( q\) dans la base \( \mB\)} la matrice de \( q\) dans la base \( \mB\) de \( \eR^n\).

\begin{proposition} \label{PropOXWooYrDKpw}
    Soit \( \mB\) une base orthonormée de \( \eR^n\) et l'application\footnote{L'ensemble \( Q(E)\) est l'ensemble des formes quadratiques sur \( E\).}
    \begin{equation}
        \begin{aligned}
            D\colon Q(\eR^n)&\to \eR \\
            q&\mapsto \det\big( mat_{\mB}(q) \big) .
        \end{aligned}
    \end{equation}
    Alors :
    \begin{enumerate}
        \item
            La valeur et \( D\) ne dépend pas du choix de la base orthonormée \( \mB\).
        \item
            La fonction \( D\) est donnée par la formule \( D(q)=\prod_i\lambda_i\) où les \( \lambda_i\) sont les valeurs propres de \( q\).
        \item
            La fonction \( D\) est continue.
    \end{enumerate}
\end{proposition}

\begin{proof}
    Soit \( q\) une forme quadratique sur \( \eR^n\). Nous considérons \( \mB\) une base de diagonalisation de \( q\) :
    \begin{equation}
        q(x)=\sum_i\lambda_ix_i
    \end{equation}
    où les \( x_i\) sont les composantes de \( x\) dans la base \( \mB\). Par définition, la matrice \( mat_{\mB}(q)\) est la matrice diagonale contenant les valeurs propres de \( q\).

    Nous considérons aussi \( \mB_1\), une autre base orthonormées de \( \eR^n\). Nous notons \( S=mat_{\mB_1}(q)\); étant symétrique, cette matrice se diagonalise par une matrice orthogonale : il existe \( P\in\gO(n,\eR)\) telle que
    \begin{equation}
        S=P mat_{\mB}(q)P^t;
    \end{equation}
    donc \( \det(S)=\det(PP^t)\det\big( \diag(\lambda_1,\ldots, \lambda_n) \big)=\lambda_1\ldots\lambda_n\). Ceci prouve en même temps que \( D\) ne dépend pas du choix de la base et que sa valeur est le produit des valeurs propres.

    Passons à la continuité. L'application déterminant \( \det\colon S_n(\eR^n)\to \eR\) est continue car polynôme en les composantes. D'autre par l'application \( mat_{\mB}\colon Q(\eR^n)\to S_n(\eR)\) est continue par la proposition~\ref{PropFSXooRUMzdb}. L'application  \( D\) étant la composée de deux applications continues, elle est continue.
\end{proof}

\begin{lemma}[Volume d'un ellipsoïde\cite{KXjFWKA, MonCerveau}]       \label{LEMooLSTOooZiEOdx}
    Soit une forme quadratique strictement définie positive \( q\) sur \( \eR^n\). Nous considérons l'ellipsoïde
    \begin{equation}
        \ellE=\{ x\in \eR^n\tq q(x)\leq r^2 \}
    \end{equation}
    pour un certain \( r>0\).

    Alors le volume de \( \ellE\) est donné par
    \begin{equation}
        V_q=\frac{ V_0 r^n }{ \sqrt{ D(q) } }
    \end{equation}
    où \( V_0\) est une constante\footnote{C'est le volume de la boule unité dans \( \eR^n\) et ce n'est pas tout à fait évident à calculer \cite{ooVLVAooXWmUVB}.} et \( D\) est l'application de la proposition \ref{PropOXWooYrDKpw}.
\end{lemma}

\begin{proof}
    Vu que la matrice de \( q\) est symétrique, elle est diagonalisable par une matrice orthogonale (théorème \ref{ThoeTMXla}). Autrement dit, il existe une base orthonormée \( \mB=\{ e_1,\ldots, e_n \}\) de \( \eR^n\) telle que
    \begin{equation}    \label{EqELBooQLPQUj}
        q(x)=\sum_{i=1}^na_ix_i^2
    \end{equation}
    où \( x_i=\langle e_i, x\rangle \) et les \( a_i\) sont tous strictement positifs. 

    A priori nous devrions calculer
    \begin{equation}
        \int_{\ellE}dx,
    \end{equation}
    mais nous effectuons le changement de variable\footnote{Théorème \ref{THOooUMIWooZUtUSg}.} associé à la matrice qui diagonalise \( q\) et nous devons simplement calculer
    \begin{equation}
        V_q=\int_{\sum_ia_ix_i^2<r^2}dx
    \end{equation}
    parce que le jacobien de ce changement de variable est \( 1\) (déterminant d'une matrice orthogonale).

    Tout cela pour dire que nous nommons \( \ellE_q\) l'ellipsoïde associée à la forme quadratique \( q\) et \( V_q\) son volume que nous allons maintenant calculer\footnote{Le volume ne change pas si nous écrivons l'inégalité stricte au lieu de large dans le domaine d'intégration; nous le faisons pour avoir un domaine ouvert.} :
    \begin{equation}
        V_q=\int_{\sum_ia_ix_i^2<r^2}dx
    \end{equation}
    Cette intégrale est écrite de façon plus simple en utilisant le \( C^1\)-difféomorphisme
    \begin{equation}
        \begin{aligned}
            \varphi\colon \ellE_q&\to B(0,1) \\
            x&\mapsto \frac{1}{  r }\Big( x_1\sqrt{a_1},\ldots, x_n\sqrt{a_n} \Big).
        \end{aligned}
    \end{equation}
    Le fait que \( \varphi\) prenne bien ses valeurs dans \( B(0,1)\) est un simple calcul : si \( x\in\ellE_q\), alors
    \begin{equation}
        \sum_i\varphi(x)_i^2=\frac{1}{ r^2 }\sum_ia_ix_i^2=\frac{1}{ r^2 }q(x)<1.
    \end{equation}
    Cela nous permet d'utiliser le théorème de changement de variables~\ref{THOooUMIWooZUtUSg} :
    \begin{equation}
        V_q=\int_{\sum_ia_ix_i^2<r^2}dx=\frac{r^n}{ \sqrt{a_1\ldots a_n} }\int_{B(0,1)}dx.
    \end{equation}
    La dernière intégrale est le volume de la boule unité dans \( \eR^n\) et nous la notons \( V_0\). La proposition~\ref{PropOXWooYrDKpw} nous permet d'écrire \(V_q\) sous la forme
    \begin{equation}
        V_q=\frac{ V_0 r^n}{ \sqrt{D(q)} }.
    \end{equation}
\end{proof}

\begin{normaltext}
    Le théorème suivant dit en substance que si \( K\) est compact, alors il existe un unique ellipsoïde de volume minimal centré en l'origine et contenant \( K\). Il faut se rendre compte que l'ellipsoïde n'est pas celui que l'on croirait intuitivement parce que la contrainte \emph{centrée en l'origine} est forte. Si \( K=\overline{ B\big( (4,0), 1 \big) }\), alors l'ellipsoïde donnée n'est pas du tout \( K\) lui-même comme on pourrait s'y attendre. Ce serait probablement quelque chose comme la boule centrée en \( (0,0)\) et de rayon \( 5\)\quext{Je ne sais pas très bien si il y a moyen de faire mieux. Ce serait sans doute un bon exercice; faites-moi savoir si vous avez la réponse.}.

    Ce que l'on voudrait est un ellipsoïde qui soit centrée où il faut pour que le volume soit minimal. Nous verrons que c'est possible en la proposition \ref{PROPooVIDPooOGrRJh}, mais qu'alors l'unicité est moins évidente (voir la remarque dans \cite{ooJWHFooGQQhUW}). Si vous voulez en entendre parler, vous pouvez lire \cite{ooASOAooNwZFKS,ooWLGRooFScSaM}.
\end{normaltext}

\begin{proposition}[Ellipsoïde de John-Loewner\cite{KXjFWKA}]   \label{PropJYVooRMaPok}
    Soit \( K\) compact dans \( \eR^n\) et d'intérieur non vide. Il existe une unique ellipsoïde\footnote{Définition~\ref{DefOEPooqfXsE}.} (pleine) centrée en l'origine de volume minimal contenant \( K\).
\end{proposition}
\index{déterminant!utilisation}
\index{extrema!volume d'un ellipsoïde}
\index{convexité!utilisation}
\index{compacité!utilisation}

\begin{proof}
    Nous subdivisons la preuve en plusieurs parties.
    \begin{subproof}
        \item[Volume de l'ellipsoïde]
            Soit \( \ellE\) un ellipsoïde centré en l'origine. La proposition~\ref{PropWDRooQdJiIr} et son corollaire~\ref{CorKGJooOmcBzh} nous indiquent que
            \begin{equation}
                \ellE=\{ x\in \eR^n\tq q(x)\leq 1 \}
            \end{equation}
            pour une certaine forme quadratique strictement définie positive \( q\). Le lemme \ref{LEMooLSTOooZiEOdx} nous donne alors le volume de \( \ellE\) par
            \begin{equation}
                V_q=\frac{ V_0 }{ \sqrt{ D(q) } }
            \end{equation}
            où \( V_0\) est une constante.
        \item[Existence de l'ellipsoïde]

            Nous voulons trouver un ellipsoïde contenant \( K\) de volume minimal, c'est-à-dire une forme quadratique \( q\in Q^{++}(\eR^n)\) telle que
            \begin{itemize}
                \item \( D(q)\) soit maximal
                \item \( q(x)\leq 1\) pour tout \( x\in K\).
            \end{itemize}
            Nous considérons l'ensemble des candidats semi-définis positifs.
            \begin{equation}
                A=\{ q\in Q^+\tq q(x)\leq 1\forall x\in K \}.
            \end{equation}
            Nous allons montrer que \( A\) est convexe, compact et non vide dans \( Q(\eR^n)\); il aura ainsi un maximum de la fonction continue \( D\) définie sur \( Q(\eR^n)\). Nous montrerons ensuite que le maximum est dans \( Q^{++}\). L'unicité sera prouvée à part.

            \begin{subproof}
            \item[Non vide]
                L'ensemble \( K\) est compact et donc borné par \( M>0\). La forme quadratique \( q\colon x\mapsto \| x \|^2/M^2\) est dans \( A\) parce que si \( x\in K\) alors
                \begin{equation}
                    q(x)=\frac{ \| x \|^2 }{ M^2 }\leq 1.
                \end{equation}
            \item[Convexe]
                Soient \( q,q'\in A\) et \( \lambda\in\mathopen[ 0 , 1 \mathclose]\). Nous avons encore \( \lambda q+(1-\lambda)q'\in Q^+\) parce que
                \begin{equation}
                    \lambda q(x)+(1-\lambda)q'(x)\geq 0
                \end{equation}
                dès que \( q(x)\geq 0\) et \( q'(x)\geq 0\).
            D'autre part si \( x\in K\) nous avons
            \begin{equation}
                \lambda q(x)+(1-\lambda)q'(x)\leq \lambda+(1-\lambda)=1.
            \end{equation}
            Donc \( \lambda q+(1-\lambda)q'\in A\).

        \item[Fermé]

            Pour rappel, la topologie de \( Q(\eR^n)\) est celle de la norme \eqref{EqZYBooZysmVh}. Nous considérons une suite \( (q_n)\) dans \( A\) convergeant vers \( q\in Q(\eR^n)\) et nous allons prouver que \( q\in A\), de sorte que la caractérisation séquentielle de la fermeture (proposition~\ref{PropLFBXIjt}) conclue que \( A\) est fermé. En nommant \( e_x\) le vecteur unitaire dans la direction \( x\) nous avons
            \begin{equation}
                \big| q(x) \big|=\big| \| x \|^2q(e_x) \big|\leq \| x \|^2N(q),
            \end{equation}
            de sorte que notre histoire de suite convergente  donne pour tout \( x\) :
            \begin{equation}
                \big| q_n(x)-q(x) \big|\leq \| x \|^2N(q_n-q)\to 0.
            \end{equation}
            Vu que \( q_n(x)\geq 0\) pour tout \( n\), nous devons aussi avoir \( q(x)\geq 0\) et donc \( q\in Q^+\) (semi-définie positive). De la même manière si \( x\in K\) alors \( q_n(x)\leq 1\) pour tout \( n\) et donc \( q(x)\leq 1\). Par conséquent \( q\in A\) et \( A\) est fermé.

        \item[Borné]

            La partie \( K\) de \( \eR^n\) est borné et d'intérieur non vide, donc il existe \( a\in K\) et \( r>0\) tel que \( \overline{ B(a,r) }\subset K\). Si par ailleurs \( q\in A\) et \( x\in\overline{ B(0,r) }\) nous avons \( a+x\in K\) et donc \( q(a+x)\leq 1\). De plus \( q(-a)=q(a)\leq 1\), donc
            \begin{equation}
                \sqrt{q(x)}=\sqrt{q\big( x+a-a \big)}\leq \sqrt{q(x+a)}+\sqrt{q(-a)}\leq 2
            \end{equation}
            par l'inégalité de Minkowski~\ref{PropACHooLtsMUL}. Cela prouve que si \( x\in\overline{ B(0,r) }\) alors \( q(x)\leq 4\). Si par contre \( x\in\overline{ B(0,1) }\) alors \( rx\in\overline{ B(0,r) } \) et
            \begin{equation}
                0\leq q(x)=\frac{1}{ r^2 }q(rx)\leq \frac{ 4 }{ r^2 },
            \end{equation}
            ce qui prouve que \( N(q)\leq \frac{ 4 }{ r^2 }\) et que \( A\) est borné.


            \end{subproof}

            L'ensemble \( A\) est compact parce que fermé et borné, théorème de Borel-Lebesgue~\ref{ThoXTEooxFmdI}. L'application continue \( D\colon Q(\eR^n)\to \eR\) de la proposition~\ref{PropOXWooYrDKpw} admet donc un maximum sur le compact \( A\). Soit \( q_0\) ce maximum.

            Nous montrons que \( q_0\in Q^{++}(\eR^d)\). Nous savons que l'application \( f\colon x\mapsto \frac{ \| x \|^2 }{ M^2 }\) est dans \( A\) et que \( D(f)>0\). Vu que \( q_0\) est maximale pour \( D\), nous avons
            \begin{equation}
                D(q_0)\geq D(f)>0.
            \end{equation}
            Donc \( q_0\in Q^{++}\).

        \item[Unicité]

            S'il existe une autre ellipsoïde de même volume que celle associée à la forme quadratique \( q_0\), nous avons une forme quadratique \( q\in Q^{++}\) telle que \( q(x)\leq 1\) pour tout \( x\in K\). C'est-à-dire que nous avons \( q_0,q\in A\) tels que \( D(q_0)=D(q)\).

            Nous considérons la base canonique \( \mB_c\) de \( \eR^n\) et nous posons \( S=mat_{\mB_c}(q)\), \( S_0=mat_{\mB_c}(q_0)\). Étant donné que \( A\) est convexe, \( (q_0+q)/2\in A\) et nous allons prouver que cet élément de \( A\) contredit la maximalité de \( q_0\). En effet
            \begin{equation}
                D\left( \frac{ q+q_0 }{ 2 }\right)=\det\left( \frac{ S+S_0 }{2} \right)
            \end{equation}
            Nous allons utiliser le lemme~\ref{LemXOUooQsigHs} qui dit que le déterminant est log-concave sous la forme de l'équation \eqref{EqSPKooHFZvmB} avec \( \alpha=\beta=\frac{ 1 }{2}\) :
            \begin{equation}    \label{eqBHJooYEUDPC}
                D\left( \frac{ q+q_0 }{ 2 }\right)=\det\left( \frac{ S+S_0 }{2} \right)>\sqrt{\det(S)}\sqrt{\det(S_0)}=\det(S_0)=D(q_0).
            \end{equation}
            Nous avons utilisé le fait que \( D(q_0)=D(q)\) qui signifie que \( \det(S_0)=\det(S)\). L'inéquation \eqref{eqBHJooYEUDPC} contredit la maximalité de \( D(q_0)\) et donne donc l'unicité.
    \end{subproof}
\end{proof}

Dans la proposition suivante nous oublions l'unicité, mais nous démontrons qu'il existe un ellipsoïde de volume minimal parmi les ellipsoïdes centrées où l'on veut et non seulement en zéro. La source de cette proposition est \cite{MonCerveau}, et comme toujours avec cette source, vous devez regarder à la fois l'énoncé et la preuve avec un oeil encore plus prudent que d'habitude.
\begin{proposition}[\cite{MonCerveau}]      \label{PROPooVIDPooOGrRJh}
    Soit un compact d'intérieur non vide \( K\) dans \( \eR^n\). Il existe un ellipsoïde de volume minimal contenant \( K\).
\end{proposition}

\begin{proof}
    Au lieu de considérer le compact \( K\) et de chercher où centrer l'ellipsoïde afin qu'elle puisse contenir \( K\) en un volume minimal, nous allons chercher comment translater \( K\) pour qu'un ellipsoïde centré en zéro puisse contenir l'image translétée de \( K \) en un volume minimal.

    Pour \( a\in \eR^n\), nous notons \( \ellE_a\) la plus petite ellipsoïde centrée en \( 0\) contenant \( K+a\) (translation de \( K\) par le vecteur \( a\)). Elle est bien définie par la proposition \ref{PropJYVooRMaPok}. Notre jeu est maintenant d'étudier la fonction\footnote{ Notons que cette fonction est bien définie, même sans la partie unicité de \ref{PropJYVooRMaPok} parce que même si \( \ellE_a\) n'était pas bien définie, son volume, lui, est bien défini.}
    \begin{equation}
        \begin{aligned}
            f\colon \eR^n&\to \eR^+ \\
            a&\mapsto \volume(\ellE_a). 
        \end{aligned}
    \end{equation}
    Nous allons montrer que \( f\) est continue et qu'elle peut être restreinte à un compact sans risque de rater un minimum.

    \begin{subproof}
        \item[À propos de forme quadratique]
            Nous notons \( q\) la forme quadratique de l'ellipsoïde \( \ellE_0\) et \( A\) sa matrice symétrique associée. Si \( x\in K+h\) nous avons, pour un certain \( k\in K\) :
            \begin{subequations}
                \begin{align}
                    q(x)&=q(k+h)\\
                    &=\langle k+h, A(k+h)\rangle \\
                    &=\langle k,Ak, \rangle +\langle k,Ahx, \rangle +\langle h, Ak\rangle +\langle h, Ah\rangle.
                \end{align}
            \end{subequations}
            En tenant compte du fait que \( A=A^t\) nous avons aussi \( \langle k, Ah\rangle =\langle h, Ak\rangle \) et donc
            \begin{equation}
                q(x)=2\langle k, Ah\rangle +q(h).
            \end{equation}
            En ce qui concerne la norme, pour tout \( x\in K+h\) nous avons donc la majoration
            \begin{subequations}
                \begin{align}
                | q(x) |&\leq 1+2\| k \|\| Ah \|+q(h)\\
                &\leq 1+2| K |\| Ah \|+q(h)
                \end{align}
            \end{subequations}
            où nous avons noté \( | K |=\sup_{k\in K}\| k \|\). Vu que \( q(x)\) est en fait toujours positif nous pouvons oublier la valeur absolue à gauche et conclure que \( K+h\) est contenu dans l'ellipsoïde
            \begin{equation}
                \ellF_1=\{ x\in \eR^n\tq q(x)\leq 1+2| K |\| Ah \|+q(h) \}.
            \end{equation}

        \item[Volumes]

            Nous avons donc \( \volume(\ellE_h)\leq \volume(\ellF_1)\). En reprenant la formule du lemme \ref{LEMooLSTOooZiEOdx} pour le volume de l'ellipsoïde nous avons la majoration
            \begin{equation}
                \volume(\ellE_h)\leq \volume(\ellE_0)\big( 1+2| K |\| Ah \|+q(h) \big)^n.
            \end{equation}
            Autrement dit, en ce qui concerne notre fonction \( f\):
            \begin{equation}        \label{EQooLVZCooJVxVNx}
                f(h)\leq f(0)\big( 1+2| K |\| Ah \|+q(h) \big)^n.
            \end{equation}
            
            Nous pouvons faire le même raisonnement en partant de \( K+h\) et en voyant comment modifier le rayon de \( \ellE_h\) pour que \( \ellE_0\) y rentre. Autrement dit, nous refaisons le raisonnement en posant \( K'=K+h\) et en étudiant \( K'-h\). Si \( q_1\) est la forme quadratique de \( \ellE_h\) et si \( A_1\) est sa matrice symétrique,
            \begin{equation}
                \volume(\ellE_0)\leq \volume(\ellE_h)\big( 1+2| K+h |\| A_1h \|+q_1(h) \big)^n
            \end{equation}
            En termes de \( f\):
            \begin{equation}        \label{EQooRHWNooDisTvn}
                f(0)\leq f(h) \big( 1+2| K+h |\| A_1h \|+q_1(h) \big)^n
            \end{equation}
        \item[Encadrement]

            Les majoration \eqref{EQooLVZCooJVxVNx} et \eqref{EQooRHWNooDisTvn} nous permettent de créer un encadrement pour \( f(h)\). En effet, en écrivant \eqref{EQooRHWNooDisTvn} et en continuant la majoration en remplaçant \( f(h)\) par \eqref{EQooLVZCooJVxVNx}, nous obtenons
            \begin{equation}
                \begin{aligned}[]
                    f(0)\leq f(h) \big( 1&+2| K+h |\| A_1h \|+q_1(h) \big)^n\\
                    &\leq f(0)\big( 1+2| K |\| Ah \|+q(h) \big)^n \big( 1+2| K+h |\| A_1h \|+q_1(h) \big)^n.
                \end{aligned}
            \end{equation}
            Vu que nous avons dans l'idée de prendre des \( h\) petits (en norme) et que les parenthèses tendent vers \( 1\) lorsque \( h\) est petit, nous pouvons supposer qu'elles sont non nulles et allègrement les passer au dénominateur. Nous divisons donc tout par le coefficient de \( f(h)\):
            \begin{equation}
                \frac{ f(0) }{  \big( 1+2| K+h |\| A_1h \|+q_1(h) \big)^n }\leq f(h)\leq f(0)  \big( 1+2| K |\| Ah \|+q(h) \big)^n
            \end{equation}
            Nous utilisons la règle de l'étau\footnote{Théorème \ref{ThoRegleEtau}.} pour conclure que
            \begin{equation}        \label{EQooCMAQooMkkEVR}
                \lim_{h\to 0} \volume(\ellE_h)=\volume(\ellE_0).
            \end{equation}
        \item[Continuité]
            Si \( a\in \eR^n\) nous pouvons appliquer la limite \eqref{EQooCMAQooMkkEVR} pour l'ellipsoïde \( \ellE_a\) au lieu de \( \ellE_0\), c'est-à-dire en partant du compact \( K+a\) au lieu de \( K\). Cela donne
            \begin{equation}
                \lim_{h\to 0} \volume(\ellE_{a+h})=\volume(\ellE_a).
            \end{equation}
            Donc \( f\) est continue sur \( \eR^n\).

        \item[Compact]

            Nous avons en hypothèse que \( K\) est d'intérieur non vide. Il existe donc \( a\in K\) et \( r>0\) tel que \( B(a,r)\subset K\). Soit l'hyperplan affine \( H\) passant par \( a\) et perpendiculaire à \( a\). Nous notons \( S=H\cap B(a,r)\). Nous avons évidemment \( S\subset K\) et donc \( S\subset \ellE_0\). Vu que l'ellipsoïde \( \ellE_0\) est convexe et contient \( K\), tout le cône de base \( S\) et de hauteur \( a\) est dans \( \ellE_0\).

            Sans rentrer dans le détails du calcul du volume de ce cône, son volume tend vers l'infini si \( a\) tend vers l'infini\footnote{Topologie du complété en un point, j'imagine que vous voyez de quoi il en retourne. Sinon c'est la définition \ref{PROPooHNOZooPSzKIN}, et il faut sans doute adapter le lemme \ref{LEMooERABooQjLBzW} au cas de \( \eR^n\) pour tout faire dans les règles.}

            Nous avons donc une majoration
            \begin{equation}
                \volume(\ellE_h)\geq \text{volume du cône de base } S\text{ et de hauteur } a+h.
            \end{equation}
            Dès que ce volume est plus grand que \( \volume(\ellE_0)\), il est impossible que \( \volume(\ellE_h)\leq \volume(\ellE_0)\). Soit \( R>0\) tel que pour tout \( \| h \|\geq R\), le volume du cône soit plus grand que \( \volume(\ellE_0)\). Le minimum de \( f\) est certainement dans \( B(0,R)\) parce que au moins
            \begin{equation}
                \volume(\ellE_0)\in f\big( B(0,R) \big).
            \end{equation}

        \item[Minimum]

            Nous considérons la fonction
            \begin{equation}
                \begin{aligned}
                    f\colon \overline{ B(0,R) }&\to \eR^+ \\
                    h&\mapsto \volume(\ellE_h). 
                \end{aligned}
            \end{equation}
            Elle est continue sur un compact, et le théorème de Weierstrass \ref{ThoWeirstrassRn} nous dit alors qu'elle atteint son minimum. Il n'y a cependant pas unicité de la valeurs de \( h\) pour laquelle \( f(h)\) est minimum.

        \item[Envoi]

            Soit \( s\in \eR^n\) tel que \( f(s)\) soit minimal. Cela signifie que parmi tous les ellipsoïdes centrés en zéro et contenant des ensembles de la forme \( K+h\), le plus petit est celui qui contient \( K+s\). Soit \( \ellE_s\) cet ellipsoïde.

            Je prétend que \( \ellE_s-s\) est le plus petit ellipsoïde contenant \( K\), tout centres confondus. En effet, si \( \ellF\) est un ellipsoïde centré en \( a\) et contenant \( K\), alors \( \ellF-a\) est un ellipsoïde centré en zéro et contenant \( K-a\). Nous avons alors
            \begin{equation}
                \volume(\ellF-a)\geq \volume(\ellE_s)=\volume(\ellE_s-s).
            \end{equation}
            L'invariance de la mesure par translation est le théorème \ref{THOooTMWHooThsDHj}.
    \end{subproof}
\end{proof}
