% This is part of Mes notes de mathématique
% Copyright (c) 2008-2025
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Parties libres, génératrices, bases et dimension}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Nous avons déjà défini (dans~\ref{DEFooKHWZooIfxdNc}) un espace vectoriel comme étant un module sur un corps commutatif. En explicitant un peu, cela donne ceci\cite{ooQLVLooEUrNLS}.

Un espace vectoriel sur le corps \( \eK\) est un ensemble \( E\) muni de deux opérations :
\begin{itemize}
	\item une loi de composition interne \( +\colon E\times E\to E\),
	\item une loi de composition externe \( \cdot\colon \eK\times E\to E\)
\end{itemize}
telles que
\begin{enumerate}
	\item
	      \( (E,+)\) soit un groupe abélien,
	\item
	      pour tout \( u,v\in E\) et pour tout \( k,k'\in \eK\),
	      \begin{enumerate}
		      \item
		            \( k(u+v)=(ku)+(kv)\)
		      \item
		            \( (kk')u=k(k'u)\)
		      \item
		            \( (k+k')u=(ku)+(k'u)\)
		      \item
		            \( 1u=u\)
	      \end{enumerate}
	      où \( 1\) est le neutre de \( \eK\) et où nous avons directement adopté la notation \( ku\) pour \( k\cdot u\).
\end{enumerate}
Si \( u\in E\), nous notons \( -u\) l'inverse de \( u\) dans le groupe \( (E,+)\).

\begin{definition}[Partie libre]		\label{DEFooDLHWooAvfhgc}
	Si \( E\) est un espace vectoriel, une partie \( A\) de \( E\) est \defe{libre}{libre!partie} si pour tout choix d'un nombre fini d'éléments \( \{ u_i \}_{i=1,\ldots, n}\) de \( A\), l'égalité
	\begin{equation}
		a_1 u_1+\cdots +a_nu_n=0
	\end{equation}
	implique \( a_i=0\) pour tout \( i\) (ici les \( a_i\) sont dans le corps de base).
\end{definition}

\begin{remark}
	Notons que le vecteur nul n'est dans aucune partie libre, ne fût-ce que parce que \( a0=0\) n'implique pas \( a=0\).
\end{remark}

Si \( A\) est une partie de l'espace vectoriel \( E\), nous notons \( \Span(A)\)\nomenclature[A]{\( \Span(A)\)}{l'ensemble des combinaisons linéaires finies d'éléments de \( A\)} l'ensemble des combinaisons linéaires finies d'éléments de \( A\). Les coefficients de ces combinaisons linéaires sont dans le corps de base \( \eK\).

\begin{definition}[Partie génératrice]
	Une partie \( B\) d'un espace vectoriel \( E\) est \defe{génératrice}{partie!génératrice} si \( \Span(B)=E\).
\end{definition}

\begin{remark}
	Ces définitions demandent des commentaires en dimension infinie\footnote{Nous n'avons pas encore défini le concept de dimension, mais nous nous adressons \randomGender{au lecteur trop pressé}{à la lectrice trop pressée}.}.

	\begin{enumerate}
		\item
		      Tout élément peut être écrit comme combinaison linéaire finie d'une partie génératrice. Cela ne signifie pas que nous pouvons extraire une partie finie qui convient pour tous les éléments à la fois. Lorsque l'espace est de dimension infinie, ceci est particulièrement important.
		\item
		      La définition séparée de liberté dans le cas des parties infinies a son importance lorsqu'on parle d'espaces vectoriels de dimension infinie (en dimension finie, aucune partie infinie n'est libre) parce que cela fera une différence entre une base algébrique et une base hilbertienne par exemple.
	\end{enumerate}
\end{remark}

\begin{definition}[Base]        \label{DEFooNGDSooEDAwTh}
	Une \defe{base}{base} de l'espace vectoriel \( E\) est une partie à la fois génératrice et libre.
\end{definition}

\begin{normaltext}		\label{NORMooJGRNooAKtvWt}
	Supposons que la partie \( \{ u_1,u_2,u_2 \}\) soit une base d'un espace vectoriel \( E\). Un ensemble étant quelque chose de non ordonné, la partie \( \{ u_3,u_2,u_1 \}\) est la même, et \( \{ u_1,u_1,u_2,u_2,u_3,u_4 \}\) est encore la même.

	Lorsque l'ordre dans lequel nous numérotons les vecteurs d'une base est important (par exemple pour écrire explicitement la matrice d'une application linéaire), nous devrions écrire \( (u_1,u_2,u_3)\). Nous pourrions définir le concept de \emph{base ordonnée} en disant qu'une base ordonnée de \( E\) est une application \(u \colon I\to E  \) où \( I\) est un ensemble totalement ordonné et telle que \( u(I)\) soit une base de \( E\).

	À partir de là, il ne serait plus autorisé de dire «la matrice de \( f\) dans une base». Il faudrait dire «la matrice de \( f\) dans une base ordonnée». Dans ce contexte, une matrice pour une application linéaire d'un espace réel serait une application \( I\times I\to \eR\).

	Bref, tout ça pour dire qu'il y a clairement des incohérences de notations à ce niveau dans le Frido. Il sera souvent écrit \( \{ u_1,u_2 \}\) au lieu de \( (u_1, u_2)\) ou, mieux, \(u \colon I\to \eR  \), et il sera souvent dit «base» au lieu de «base ordonnée».
\end{normaltext}

Nous prouvons à présent que tout élément non nul d'un espace vectoriel possédant une base\footnote{Nous n'avons pas démontré que tout espace vectoriel possède une base. Donc à notre niveau, il est possible que ce théorème soit sans objet pour beaucoup d'espaces.} se décompose de façon unique en combinaison linéaire finie d'éléments d'une base.
\begin{proposition}[\cite{MonCerveau}]      \label{PROPooEIQIooXfWDDV}
	Soient un espace vectoriel \( E\) sur \( \eK\) muni d'une base \( \{ e_i \}_{i\in I}\). Si \( v\in E\), alors il existe un unique couple \( (J, c)\) où
	\begin{enumerate}
		\item
		      \( J\) est une partie finie de \( I\);
		\item
		      \( c\colon J\to \eK\) est une application
		\item
		      \( v=\sum_{j\in J}c(j)e_j\).
	\end{enumerate}
	Les éléments \( c(i)\) seront notés \( v_i\) et sont les composantes de \( v\) dans la base. Sous-entendu, on prolonge \( c\) de \( J\)  vers \( I\) par zéro sur \( I\setminus J\).
\end{proposition}

\begin{proof}
	Soit un espace vectoriel \( E\) et une base \( \{ e_i \}_{i\in I}\) où \( I\) est un ensemble à priori quelconque. Soit \( v\in E\). Puisque \( E=\Span\{ e_i \}_{i\in I}\), il existe une partie finie \( J\) de \( I\) et des coefficients \( \{ v_j \}_{j\in J}\) dans \( \eK\) tels que
	\begin{equation}
		v=\sum_{j\in J}v_je_j.
	\end{equation}
	Cela donne l'existence.

	En ce qui concerne l'unicité, soient \( J \) et \( K\) des parties finies de \( I\) et des coefficients \( \{ v_j \}_{j\in J}\) et \( \{ w_{k} \}_{k\in K}\) tels que
	\begin{equation}        \label{EQooFKNEooICnVPP}
		v=\sum_{j\in J}v_je_j=\sum_{k\in K}w_{k}e_{k}.
	\end{equation}
	Nous posons \( L=J\cup K\). Remarquez que les unions suivantes sont des unions disjointes :
	\begin{subequations}
		\begin{align}
			L & =(J\setminus K)\cup (J\cap K)\cup (K\setminus J) \\
			J & =(J\setminus K)\cup (J\cap K)                    \\
			K & =(K\cap J)\cup(K\setminus J).
		\end{align}
	\end{subequations}
	Écrivons \( 0=v-v\) en utilisant les expressions de \( v\) de \eqref{EQooFKNEooICnVPP} et en décomposant les sommes :
	\begin{subequations}
		\begin{align}
			0 & =\sum_{j\in J}v_je_j-\sum_{k\in K}w_ke_k                                                                           \\
			  & =\sum_{j\in J\setminus K}v_je_j+\sum_{j\in J\cap K}v_je_j-\sum_{k\in K\cap J}w_ke_k-\sum_{k\in K\setminus J}w_ke_k \\
			  & =\sum_{j\in J\setminus K}v_je_j+\sum_{j\in J\cap K}(v_j-w_j)e_j-\sum_{k\in K\setminus J}w_ke_k.
		\end{align}
	\end{subequations}
	Là-dessus, nous posons
	\begin{equation}
		\alpha_l=\begin{cases}
			v_l     & \text{si } l\in J\setminus K \\
			v_l-w_l & \text{si } l\in J\cap K      \\
			-w_l    & \text{si }l\in K\setminus J.
		\end{cases}
	\end{equation}
	Nous avons alors
	\begin{equation}        \label{EQooCTWRooZKvaup}
		\sum_{l\in L}\alpha_le_l=0.
	\end{equation}
	Vu que \( \{ e_i \}_{i\in I}\) est libre, la partie \( \{ e_l \}_{l\in L}\) est également libre. Donc l'équation \eqref{EQooCTWRooZKvaup} implique que \( \alpha_l=0\) pour tout \( l\in L\).

	Nous devons prouver que
	\begin{equation}
		\{ j\in J \tq v_j\neq 0 \}=\{ k\in K\tq w_k\neq 0 \}
	\end{equation}
	et que pour \( l\) dans cet ensemble, \( v_l=w_l\).

	Soit \( j\in J\); il y a deux possibilités : soit \( j\in J\setminus K\), soit \( j\in J\cap K\). Dans le premier cas nous avons déjà vu que \( \alpha_j=v_j=0\). Dans le second cas, \( \alpha_j=v_j-w_j=0\), c'est-à-dire \( v_j=w_j\).

	Donc \( j\in J\) vérifiant \( v_j\neq 0\) implique \( j\in J\cap K\) et l'égalité des coefficients. Idem avec \( k\in K\) tel que \( w_k\neq 0\) implique \( k\in J\cap K\).
\end{proof}

\begin{lemma}[\cite{MonCerveau}]        \label{LEMooDJSIooYcsvhO}
	Soit un espace vectoriel admettant des bases. Un endomorphisme est une bijection si et seulement si il change toute base en une base.
\end{lemma}

\begin{proof}
	En deux parties. Soit un espace vectoriel \( E\) possédant des bases et un endomorphisme \( f\colon E\to E\).
	\begin{subproof}
		\spitem[Si \( f\) est bijective]
		Soit une base \( \{ v_i \}_{i\in I}\); nous devons voir que \( \{ f(v_i) \}_{i\in I}\) est une base.
		\begin{subproof}
			\spitem[Libre]
			Si \( J\) est une partie finie de \( I\) et si les \( \lambda_j\) sont des scalaires tels que \( \sum_{j\in J}\lambda_jf(v_j)=0\), alors
			\begin{equation}
				0=\sum_{j\in J}\lambda_jf(v_j)=f\big( \sum_{j\in J}\lambda_jv_j \big).
			\end{equation}
			Mais comme \( f\) est bijective, cela implique que \( \sum_{j\in J}\lambda_jv_j=0\). En retour, parce que \( \{ v_i \}\) est une base, cela implique que \( \lambda_j=0\) pour tout \( j\).

			\spitem[Générateur]
			Soit \( x\in E\). Puisque \( f\) est bijective, il existe un unique \( y\in E\) tel que \( x=f(y)\). Comme \( \{ v_i \}_{i\in I}\) est une base, il existe une partie finie \( J\subset I\) et des scalaires \( \{ \lambda_j \}_{j\in J}\) tels que
			\begin{equation}
				y=\sum_{j\in J}\lambda_jv_j.
			\end{equation}
			Nous avons alors
			\begin{equation}
				x=f(y)=\sum_{j\in J}\lambda_jf(v_j),
			\end{equation}
			qui montre que \( \{ f(v_i) \}_{i\in I}\) est bien génératrice de \( E\)
		\end{subproof}
		\spitem[Si \( f\) change les bases en bases]
		Soit un endomorphisme changeant toute base en une base. Nous devons prouver qu'il est bijectif.
		\begin{subproof}
			\spitem[Injective]
			Nous considérons une base \( \{ v_i \}_{i\in I}\). La partie \( \{ f(v_i) \}_{i\in I}\) est par hypothèse également une base.

			Soient \( x,y\in E\) tels que \( f(x)=f(y)\). Il existe \( J\) et \( K\) finis dans \( I\) qui permettent de décomposer \( x\) et \( y\) respectivement dans la base \( \{ f(v_i) \}_{i\in I}\). Quitte à poser \( J'=J\cup K\), nous supposons que \( J\) suffit\footnote{Nous utilisons le fait que l'union de deux parties finies d'un ensemble est finie (lemme \ref{LEMooVFPNooVmdUXY}\ref{ITEMooCCWOooYwgGBp}).}. Il existe donc des scalaires \( \{ \lambda_j \}_{j\in J}\) et \( \{ \mu_j \}_{j\in J}\) tels que \( x=\sum_{j\in J}\lambda_jf(v_j)\) et \( y=\sum_{j\in J}\mu_jf(v_j)\).

			La relation \( f(x)=f(y)\) donne immédiatement, par la linéarité de \( f\),
			\begin{equation}
				\sum_{j\in J}(\lambda_j-\mu_j)f(v_j)=0.
			\end{equation}
			Du fait que \( \{ f(v_i) \}_{i\in I}\) soit une base, nous déduisons que \( \lambda_j-\mu_j=0\) pour tout \( j\). Donc \( x=y\), et \( f\) est injective.

			\spitem[Surjective]
			Soit \( x\in E\). Puisque \( \{ f(v_i) \}_{i\in I}\) est une base, il existe des scalaires \( \lambda_j\) tels que
			\begin{equation}
				x=\sum_{j\in J}\lambda_jf(v_j)=f\big( \sum_{j\in J}\lambda_jv_j \big).
			\end{equation}
			Donc \( f\) est surjective.
		\end{subproof}
	\end{subproof}
\end{proof}

\begin{proposition}[\cite{MonCerveau}]	\label{PROPooVJFNooSbkzTF}
	Soit un espace vectoriel \( E\). Soit une partie \( B\subset E\) telle que tout élément de \( E\) puisse être écrit de façon unique comme combinaison linéaire d'un nombre fini d'éléments de \( B\). Alors \( B\) est une base.
	%TODOooMZHZooSzkRVM
\end{proposition}


\begin{lemma}[\cite{MonCerveau}]        \label{LEMooRWQHooIxrQek}
	Bases dans \( \eR^n\).
	\begin{enumerate}
		\item       \label{ITEMooKWULooCTmOqM}
		      Si \( v\) et \( w\) ne sont pas colinéaire dans \( \eR^2\), alors \( \{ v,w \}\) est une base de \( \eR^2\).
		\item
		      Toute partie libre de \( \eR^n\) contenant \( n\) élément est une base.
	\end{enumerate}
	%TODOooMIXAooBFGsgE. Prouver ça, et déplacer là où \( \eR^n\) est défini.
\end{lemma}

\begin{definition}
	Un espace vectoriel est \defe{de type fini}{type!fini!espace vectoriel} si il contient une partie génératrice finie.
\end{definition}
Nous verrons dans les résultats qui suivent que cette définition est en réalité inutile parce qu'un espace vectoriel sera de type fini si et seulement si il est de dimension finie.

\begin{lemma}       \label{LemytHnlD}
	Si \( E\) a une famille génératrice de cardinal \( n\), alors toute famille de \( n+1\) éléments est liée.
\end{lemma}

\begin{proof}
	Nous procédons par récurrence sur \( n\). Pour \( n=1\), nous avons \( E=\Span(e)\) et donc si \( v_1,v_2\in E\) nous avons \( v_1=\lambda_1 e\), \( v_2=\lambda_2e\) pour certains éléments non nuls \( \lambda_1,\lambda_2\) du corps de base. Nous avons donc \( \lambda_2v_1-\lambda_1v_2=0\). Cela prouve que \( \{ v_1,v_2 \}\) est liée.

	Supposons maintenant que le résultat soit vrai pour \( k<n\), c'est-à-dire que pour tout espace vectoriel contenant une partie génératrice de cardinal \( k<n\), les parties de \( k+1\) éléments sont liées. Soit maintenant un espace vectoriel muni d'une partie génératrice \( G=\{ e_1,\ldots, e_n \}\) de \( n\) éléments, et montrons que toute partie \( V=\{ v_1,\ldots, v_{n+1} \}\) contenant \( n+1\) éléments est liée. Dans nos notations nous supposons que les \( e_i\) sont des vecteurs distincts et les \( v_i\) également. Nous les supposons également tous non nuls. Étant donné que \( \{ e_i \}\) est génératrice nous pouvons définir les nombres \( \lambda_{i,k}\) par
	\begin{equation}
		v_i=\sum_{k=1}^n\lambda_{i,k}e_k
	\end{equation}
	Puisque
	\begin{equation}
		v_{n+1}=\sum_{k=1}^n\lambda_{n+1,k}e_k\neq 0,
	\end{equation}
	quitte à changer la numérotation des \( e_i\), nous pouvons supposer que \( \lambda_{n+1,n}\neq 0\). Nous considérons les vecteurs
	\begin{equation}
		w_i=\lambda_{n+1,n}v_i-\lambda_{i,n}v_{n+1}.
	\end{equation}
	En calculant un peu,
	\begin{subequations}
		\begin{align}
			w_i & =\lambda_{n+1,n}\sum_{k=1}^n\lambda_{i,k}e_k-\lambda_{i,n}\sum_{k=1}^n\lambda_{n+1,k}e_k  \\
			    & =\sum_{k=1}^{n-1}\big( \lambda_{n+1,n}\lambda_{i,k}-\lambda_{i,n}\lambda_{n+1,k} \big)e_k
		\end{align}
	\end{subequations}
	parce que les termes en \( e_n\) se sont simplifiés. Donc la famille \( \{ w_1,\ldots, w_n \}\) est une famille de \( n\) vecteurs dans l'espace vectoriel \( \Span\{ e_1,\ldots, e_{n-1} \}\); elle est donc liée par l'hypothèse de récurrence. Il existe donc des nombres \( \alpha_1,\ldots, \alpha_n\in \eK\) non tous nuls, tels que
	\begin{equation}        \label{EqOQGGoU}
		0=\sum_{i=1}^n\alpha_iw_i=\sum_{i=1}^n\alpha_i\lambda_{n+1,n}v_i - \sum_{i=1}^n\alpha_i\lambda_{i,n} v_{n+1}.
	\end{equation}
	Vu que \( \lambda_{n+1,n}\neq 0\) et que, parmi les \( \alpha_i\), au moins un est non nul, nous avons au moins un des produits \( \alpha_i\lambda_{n+1,n}\) qui est non nul. Par conséquent \eqref{EqOQGGoU} est une combinaison linéaire nulle non triviale des vecteurs de \( \{ v_1,\ldots, v_{n+1} \}\). Cette partie est donc liée.
\end{proof}

\begin{lemma}   \label{LemkUfzHl}
	Soient \( L\) une partie libre et \( G\) une partie génératrice d'un espace vectoriel \( E\). Si l'ensemble des parties libres \( L'\) telles que \( L\subset L'\subset G\) possède un élément maximum\footnote{Encore une fois, à part quelques cas triviaux, il n'est pas clair à ce point que ce maximum existe.}, alors cet élément est une base.
\end{lemma}
Qu'entend-on par «maximale» ? La partie \( B\) candidate, doit être libre, contenir \( L\), être contenue dans \( G\) et de plus avoir la propriété que \( \forall x\in G\setminus B\), la partie \( B\cup\{ x \}\) est liée.

\begin{proof}
	D'abord si \( G\) est une base, alors toutes les parties de \( G\) sont libres et le maximum est \( B=G\). Dans ce cas le résultat est évident. Nous supposons donc que \( G\) est liée.

	La partie \( B=\{ b_1,\ldots, b_l \}\) est libre parce qu'on l'a prise parmi les libres. Montrons que \( B\) est génératrice. Soit \( x\in G\setminus B\); par hypothèse de maximalité, \( B\cup\{ x \}\) est liée, c'est-à-dire qu'il existe des nombres \( \lambda_i\), \( \lambda_x\) non tous nuls tels que
	\begin{equation}    \label{EqxfkevM}
		\sum_{i=1}^l\lambda_ib_i+\lambda_xx=0.
	\end{equation}
	Si \( \lambda_x=0\) alors un de \( \lambda_i\) doit être non nul et l'équation \eqref{EqxfkevM} devient une combinaison linéaire nulle non triviale des \( b_i\), ce qui est impossible parce que \( B\) est libre. Donc \( \lambda_x\neq 0\) et
	\begin{equation}
		x=-\frac{1}{ \lambda_x }\sum_{i=1}^l\lambda_ib_i.
	\end{equation}
	Donc tous les éléments de \( G\setminus B\) sont des combinaisons linéaires des éléments de \( B\), et par conséquent, \( G\) étant génératrice, tous les éléments de \( E\) sont combinaisons linéaires d'éléments de \( B\).
\end{proof}

\begin{theorem}[Théorème de la base incomplète] \label{ThonmnWKs}
	Soit \( E\) un espace vectoriel de type fini sur le corps \( \eK\).
	\begin{enumerate}
		\item     \label{ItemBazxTZ}
		      Si \( L\) est une partie libre et si \( G\) est une partie génératrice contenant \( L\), alors il existe une base \( B\) telle que \( L\subset B\subset G\).
		\item     \label{ITEMooFVJXooGzzpOu}
		      Toute partie libre peut être étendue en une base.
		\item     \label{ITEMooFBUAooSSZxgx}
		      Toutes les bases sont finies et ont même cardinal.
		\item       \label{ITEMooJIJSooGuJMdt}
		      Si \( V\) est un sous-espace vectoriel de \( E\), et si \( L\) est une base de \( V\), alors il existe une base de \( E\) qui contient \( L\).
	\end{enumerate}
\end{theorem}
\index{théorème!base incomplète}

\begin{proof}
	Point par point.
	\begin{enumerate}
		\item
		      Comme \( E\) est de type fini, il admet une partie génératrice \( G\) de cardinal fini \( n\). Donc une partie libre est de cardinal au plus \( n\) par le lemme~\ref{LemytHnlD}. Soit \( L\), une partie libre contenue dans \( G\) (ça existe : par exemple \( L=\emptyset\)). La partie \( B\) maximalement libre contenue dans \( G\) et contenant \( L\) est une base par le lemme~\ref{LemkUfzHl}.
		\item
		      Notons que puisque \( E\) lui-même est générateur, le point~\ref{ItemBazxTZ} implique que toute partie libre peut être étendue en une base.
		\item
		      Soient \( B\) et \( B'\), deux bases. En particulier \( B\) est génératrice et \( B'\) est libre, donc le lemme~\ref{LemytHnlD} indique que \( \Card(B')\leq \Card(B)\). Par symétrie on a l'inégalité inverse. Donc \( \Card(B)=\Card(B')\).
		\item
		      La partie \( L\) étant une base de \( V\), elle est en particulier libre dans \( E\). Par le point \ref{ITEMooFVJXooGzzpOu}, \( L\) peut être étendue en une base.
	\end{enumerate}
\end{proof}

\begin{remark}      \label{REMooYGJEooEcZQKa}
	Le théorème de la base incomplète~\ref{ThonmnWKs}\ref{ITEMooFVJXooGzzpOu} est ce qui permet de construire une base d'un espace vectoriel en «commençant par» une base d'un sous-espace. En effet si \( H\) est un sous-espace de \( E\), alors une base de \( H\) est une partie libre de \( E\) et donc, peut être étendue en une base de \( E\).
\end{remark}

\begin{definition}      \label{DEFooWRLKooArTpgh}
	La \defe{dimension}{dimension} d'un espace vectoriel de type fini est le cardinal\footnote{Définition \ref{PROPooJLGKooDCcnWi}.} d'une\footnote{Le théorème de la base incomplète~\ref{ThonmnWKs}\ref{ITEMooFBUAooSSZxgx} montre que cette définition ne souffre d'aucune ambiguïté.} de ses bases.
\end{definition}
\index{dimension!définition}

Il existe une infinité de bases de \( \eR^m\). On peut démontrer que le cardinal de toute base de \( \eR^m\) est \( m\), c'est-à-dire que toute base de \( \eR^m\) possède exactement \( m\) éléments.

\begin{example}
	La base de \defe{canonique}{canonique!base}\index{base canonique de \( \eR^m\)} de \( \eR^m\) est la partie \( \{e_1,\ldots, e_m\}\), où le vecteur \( e_j\) est
	\begin{equation}\nonumber
		e_j=
		\begin{array}{cc}
			\begin{pmatrix}
				0 \\\vdots\\0\\1\\ 0\\\vdots\\0
			\end{pmatrix} &
			\begin{matrix}
				\quad \\\quad\\\leftarrow\textrm{j-ème} \quad\\\quad\\\quad\\
			\end{matrix}
		\end{array}.
	\end{equation}
	La composante numéro \( j\) de \( e_i\) est \( 1\) si \( i=j\) et \( 0\) si \( i\neq j\). Cela s'écrit \( (e_i)_j=\delta_{i,j}\) où \( \delta\) est le \defe{symbole de Kronecker}{Kronecker!symbole} défini par
	\begin{equation}
		\delta_{i,j}=\begin{cases}
			1 & \text{si }i=j     \\
			0 & \text{si }i\neq j
		\end{cases}
	\end{equation}
	Les éléments de la base canonique de \( \eR^m\) peuvent donc être écrits \( e_i=\sum_{k=1}^m\delta_{i,k}e_k\).
\end{example}

Le théorème suivant est essentiellement une reformulation du théorème~\ref{ThonmnWKs}.
\begin{theorem} \label{ThoMGQZooIgrXjy}
	Soit \( E\) un espace vectoriel de dimension finie et \( \{ e_i \}_{i\in I}\) une partie génératrice de \( E\).

	\begin{enumerate}
		\item       \label{ITEMooTZUDooFEgymQ}
		      Il existe \( J\subset I\) tel que \( \{ e_i \}_{i\in J}\) est une base. Autrement dit : de toute partie génératrice nous pouvons extraire une base.
		\item       \label{ITEMooCJQGooXwjsfm}
		      Soit \( \{ f_1,\ldots, f_l \}\) une partie libre. Alors nous pouvons la compléter en utilisant des éléments \( e_i\). C'est-à-dire qu'il existe \( J\subset I\) tel que \( \{ f_k \}\cup\{ e_i \}_{i\in J}\) soit une base.
	\end{enumerate}
\end{theorem}

\begin{proof}
	En deux parties.
	\begin{subproof}
		\spitem[Pour \ref{ITEMooTZUDooFEgymQ}]
		%-----------------------------------------------------------
		C'est le théorème \ref{ThonmnWKs}\ref{ItemBazxTZ}. La partie \( \{ e_{i_0} \}\) est libre et la partie \( \{ e_i \}_{i\in I}\) est génératrice. Donc il existe une base \( B\) telle que \( \{ e_{i_0} \}\subset B\subset\{ e_i \}_{i\in I}\). Si \( B=\{ e_i \}_{i\in J}\), alors \( J\) est fini\footnote{Sauf si \( I\) est choisi de façon traitresse. Il se peut que \( e_{i_1}=e_{i_2}\) avec \( i_1\neq i_2\).} parce que toutes les bases d'un espace vectoriel de dimension finie ont le même nombre d'éléments.

		\spitem[Pour \ref{ITEMooCJQGooXwjsfm}]
		%-----------------------------------------------------------
		Utiliser le théorème \ref{ThonmnWKs}\ref{ITEMooJIJSooGuJMdt} avec \( V=\Span\{ f_1,\ldots,f_l \}\).
	\end{subproof}
\end{proof}

\begin{proposition}     \label{PROPooVEVCooHkrldw}
	Si \( E\) est un espace vectoriel de dimension finie \( n\), alors
	\begin{enumerate}
		\item       \label{ITEMooZNLDooBISkJyBS}
		      toute partie contenant \( n+1\) éléments est liée.
		\item       \label{ITEMooSGGCooOUsuBs}
		      toute partie libre contenant \( n\) éléments est une base,
		\item
		      toute partie génératrice contenant \( n\) éléments est une base.
	\end{enumerate}
\end{proposition}

\begin{proof}
	Soit une partie \( M\) contenant \( n+1\) éléments. L'espace \( E\) possède une partie génératrice contenant \( n\) éléments (n'importe quelle base). Donc \( M\) est liée par le lemme \ref{LemytHnlD}.

	Une partie libre contenant \( n\) éléments peut être étendue en une base; si ladite extension est non triviale (c'est-à-dire qu'on ajoute vraiment au moins un élément) une telle base contiendra une partie de \( n+1\) éléments qui serait liée par le lemme~\ref{LemytHnlD}.

	Pour la dernière assertion, soit une partie génératrice \( \{ v_i \}_{i\in I}\) où \( I\) contient \( n\) éléments. Par le théorème \ref{ThoMGQZooIgrXjy}\ref{ITEMooTZUDooFEgymQ} nous pouvons en extraire une base : il existe \( J\subset I\) tel que \( \{ v_j \}_{j\in J}\) soit une base. Si l'inclusion \( J\subset I\) était stricte, alors la base \( \{ v_j \}_{j\in J}\) contiendrait moins de \( n\) éléments, ce qui serait en contradiction avec le théorème \ref{ThonmnWKs}\ref{ITEMooFBUAooSSZxgx}.
\end{proof}

\begin{definition}\label{DefCodimension}
	Soit \( F\) un sous-espace vectoriel de l'espace vectoriel \( E\). La \defe{codimension}{codimension} de \( F\) dans \( E\) est
	\begin{equation}
		\codim_E(F)=\dim(E/F).
	\end{equation}
\end{definition}

\begin{lemma}		\label{LEMooGNDPooAhvIek}
	L'ensemble \( \eQ^n\) est un \( \eQ\)-espace vectoriel de dimension \( n\).
\end{lemma}

\begin{propositionDef}[Supplémentaire vectoriel\cite{MonCerveau}]	\label{PROPooRKOVooBFRCKq}
	Soit un espace vectoriel \( V\) et un sous-espace vectoriel \( V_1\) dans \( V\). Il existe un sous-espace vectoriel \( V_2\) de \( V\) tel que
	\begin{enumerate}
		\item
		      \( V_1\cap V_2=\{ 0 \}\),
		\item
		      pour tout \( x\in V\), il existe un unique \( (x_1,x_2)\in V_1\times V_2\) satisfaisant \( x=x_1+x_2\).
	\end{enumerate}

	Une telle partie \( V_2\) est dite \defe{supplémentaire}{supplémentaire} de \( V_1\) et on écrit parfois \( V=V_1\oplus V_2\)\footnote{Mais c'est un léger abus parce que \( V_1\oplus V_2\) est formellement \( V_1\times V_2\) (définition \ref{DEFooJKAWooKkkkwm}).}.
\end{propositionDef}

\begin{proof}
	La partie \( V_1\) est un sous-espace vectoriel. Il possède donc une base \(\mB_1= \{ u_1,\ldots,u_l \}\). Le théorème de la base incomplète \ref{ThonmnWKs}\ref{ITEMooFBUAooSSZxgx} dit qu'il existe \( \{ v_1,\ldots,v_k \}\) tels que \( \mB=\{ u_1,\ldots,u_l,v_1,\ldots,v_k \}\) soit une base de \( V\).

	Nous posons alors \( V_2=\Span\{ v_1,\ldots,v_k \}\).
	\begin{subproof}
		\spitem[\( V_1\cap V_2=\{ 0 \}\)]
		%-----------------------------------------------------------
		Soit \( x\in V_1\cap V_2\). Étant donné que \( x\in V_1\), il existe des \( a_i\) tels que \( x=\sum_ia_iu_i\), et étant donné que \( x\in V_2\) il existe des \( b_j \) tels que \( x=\sum_jb_jv_j\). Nous avons donc \( \sum_ia_iu_i-\sum_jb_jv_j=0\) en tant que combinaison linéaire nulle d'éléments d'une base, les coefficients sont nuls\footnote{C'est la définition \ref{DEFooDLHWooAvfhgc} d'une partie libre.} : \( a_i=0\) et \( b_j=0\) pour tout \( i\) et \( j\). Donc \( x=0\).

		\spitem[Décomposition : existence]
		%-----------------------------------------------------------
		Si \( x\in V\), il y a une décomposition dans la base \( \mB\) : \( x=\sum_{i=1}^la_iu_i+  \sum_{j=1}^kb_jv_j\). En posant \( x_1=\sum_ia_iu_i\) et \( x_2=\sum_jb_jv_j\), nous avons bien \( x=x_1+x_2\) avec \( x_1\in V_1\) et \( x_2\in V_2\).

		\spitem[Décomposition : unicité]
		%-----------------------------------------------------------
		Supposons \( x=x_1+x_2=y_1+y_2\) avec \( x_1,y_1\in V_1\) et \( x_2,y_2\in V_2\). Nous avons les décompositions \( x_1=\sum_ia_iu_i\), \( x_2=\sum_jb_jv_j\), \( y_1=\sum_ia'_iu_i\) et \( y_2=\sum_jb_j'v_j\). L'égalité \( x_1+x_2=y_1+y_2\) donne
		\begin{equation}
			\sum_i(a_i-a'_i)u_i+\sum_j(b_j-b'_j)v_j=0.
		\end{equation}
		Combinaison linéaire nulle d'éléments d'une base. Les coefficients son nuls, et donc \( a_i-a'_i=0\) et \( b_j-b'_j=0\). Nous en déduisons \( x_1=y_1\) et \( x_2=y_2\).
	\end{subproof}
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Et en dimension infinie}
%---------------------------------------------------------------------------------------------------------------------------

Dans ZFC, en dimension infinie, il existe aussi une base pour tout espace vectoriel ainsi qu'un théorème de la base incomplète. Nous ne parlerons pas de ce qu'il se passe lorsque nous ne considérons que ZF\footnote{Si vous ne savez pas ce que signifient les sigles «ZF» et «ZFC» vous ne devriez pas être en train de lire ceci, et encore moins penser à le resservir à un jury d'agrégation.}.

\begin{lemma}[\cite{ooXEFKooHikcdE}]        \label{LEMooSSRXooIyfgNz}
	Soient un \( \eK\)-espace vectoriel \( E\) et un sous-espace vectoriel \( V\) de \( E\). Soient encore deux sous-espaces vectoriels \( W_1\) et \( W_2\) tels que
	\begin{enumerate}
		\item
		      \( V\cap W_1=\{ 0 \}\);
		\item
		      \( V+W_2=E\).
	\end{enumerate}
	Alors il existe un supplémentaire\footnote{Définition \ref{PROPooRKOVooBFRCKq}.} \( W\) de \( V\) tel que \( W_1\subset W\subset W_2\).
\end{lemma}

Juste une remarque : dans le Frido le symbole «\( \subset\)» ne signifie pas une inclusion stricte.

\begin{proof}
	Nous utilisons le lemme de Zorn.
	\begin{subproof}
		\spitem[Un gros ensemble]
		Soit
		\begin{equation}
			\mA=\Big\{   S\subset E\tq \begin{cases}
				S    \text{ est un sous-espace vectoriel de \( E\) } \\
				W_1\subset S\subset W_2                              \\
				S\cap V=\{ 0 \}
			\end{cases}\Big\}
		\end{equation}
		\spitem[Non vide]
		% -------------------------------------------------------------------------------------------- 
		Puisque \( W_1\in \mA\), cet ensemble n'est pas vide.
		\spitem[Ordre]
		% -------------------------------------------------------------------------------------------- 
		L'ensemble \( \mA\) est partiellement ordonné pour l'inclusion.

		\spitem[\( \mA\) est inductif]
		Nous prouvons maintenant que \( \mA\) est inductif\footnote{Définition~\ref{DefGHDfyyz}.}. Pour cela, soit une partie \( \mA'\) totalement ordonnée et \( U=\bigcup_{A\in \mA'}A\).

		Alors, la partie \( U\) est un sous-espace vectoriel de \( E\). En effet si \( x,y\in U\), alors il existe \( A_1,A_2\in\mA'\) tels que \( x\in A_1\) et \( y\in A_2\). Comme \( \mA'\) est totalement ordonné, l'un des ensembles parmi \( A_1\) et \( A_2\) est inclus dans l'autre. Sans perdre de généralité, disons \( A_1\subset A_2\). Alors les opérations s'effectuent dans \( A_2 \) : nous avons \( x,y\in A_2\), et donc \( \lambda x\in A_2\subset U\) ainsi que \( x+y\in A_2\subset U\).

		De plus, \( U \) contient \( W_1 \), et est contenu dans \( W_2\). Ainsi, \( U\in \mA\) et majore \( \mA'\) pour l'inclusion. En bref, \( \mA\) est bien inductif.

		\spitem[Utilisation de Zorn]
		Le lemme de Zorn~\ref{LemUEGjJBc} nous donne alors un élément maximal \( W\) de \( \mA\). Cet élément vérifie
		\begin{enumerate}
			\item
			      \( W\cap V=\{ 0 \}\),
			\item
			      \( W_1\subset W\subset W_2\),
			\item
			      pour tout \( W'\in\mA\), nous avons \( W'\subset W\) par maximalité de \( W\).
		\end{enumerate}

		\spitem[Supplémentaire]
		Montrons que ce \( W\) est un supplémentaire de \( V\). Soit \( x\in E\). Le but est de trouver une décomposition de \( x\) en somme d'un élément de \( W\) et un de \( V\). Comme \( V+W_2=E\), nous avons \( v\in V\) et \( w_2\in W_2\) tels que
		\begin{equation}
			x=v+w_2.
		\end{equation}
		Si \( w_2\in W\) alors c'est fini. Sinon \ldots

		Soit \( X=\Span\{ W,w_2 \}\). Vu que \( X\) contient strictement \( W\) et que \( W\) est maximum dans \( \mA\), la partie \( X\) n'est pas un élément de \( \mA\). Comme \( X\) est un sous-espace vectoriel de \( E\) tel que \( W_1\subset X\subset W_2\), la seule possibilité pour que \( X\) ne soit pas dans \( \mA\) est que \( X\cap V\neq \{ 0 \}\). Soit donc \( y\neq 0\) dans \( X\cap V\). Par définition de \( X\),
		\begin{equation}      \label{EqDecompo55:296}
			y=w'+\lambda w_2
		\end{equation}
		pour \( w'\in W\), \( w_2\in W_2\) et \( \lambda\in \eK\). Nous avons \( \lambda\neq 0\), sinon nous aurions \( y\in W\cap V \) et donc \(y = 0 \) puisque \( W \) est dans \( \mA \). La décomposition \eqref{EqDecompo55:296} permet alors d'écrire \( w_2=(y-w')/\lambda\) et finalement
		\begin{equation}
			x=v+\frac{1}{ \lambda }(y-w')=\underbrace{v+\frac{1}{ \lambda }y}_{\in V}-\underbrace{\frac{1}{ \lambda }w'}_{\in W}.
		\end{equation}
		La somme d'espaces vectoriels \( E=V+W\) est donc établie.
	\end{subproof}
\end{proof}

\begin{corollary}
	Tout sous-espace vectoriel d'un espace vectoriel possède un supplémentaire.
\end{corollary}

\begin{proof}
	Soit un espace vectoriel \( E\) ainsi qu'un sous-espace vectoriel \( V\). Si \( V=E\) nous sommes O.K. Sinon nous considérons \( v\in E\setminus V\) et nous posons \( W_1=\eK v\) et \( W_2=E\).

	Vu que \( V\) et \( W_1\) sont des espaces vectoriels, nous avons \( V\cap W_1=\{ 0 \}\), et puisque \( W_2=E\), nous avons \( V+W_2=E\). Le lemme~\ref{LEMooSSRXooIyfgNz} nous donne alors un supplémentaire de \( V\).
\end{proof}

\begin{proposition}[Base incomplète]        \label{PROPooHDCEooMhDjPi}
	Tout espace vectoriel (non réduit à \( \{ 0 \}\)) possède une base.
\end{proposition}

\begin{proof}
	Soit \( \mA\) l'ensemble des familles libres de \( E\). Il n'est pas vide parce que \( \{ v \}\) en est une dès que \( v\) est non nul dans \( E\). Rapidement :
	\begin{itemize}
		\item l'ensemble \( \mA\) est ordonné pour l'inclusion,
		\item si \( \mA'\) est une partie totalement ordonnée, l'union est un majorant,
		\item donc \( \mA\) est inductif,
		\item soit un maximum \( F\) de \( \mA\).
	\end{itemize}
	La partie \( F\) est libre parce qu'elle est dans \( \mA\). Elle est génératrice parce que si \( v\) n'est pas dans \( \Span(F)\) alors la partie \( F\cup\{ v \}\) est encore libre, et majore strictement \( F\) pour l'inclusion, ce qui n'est pas possible.

	Donc \( F\) est une base de \( E\).
\end{proof}

\begin{theorem}[Base incomplète, dimension quelconque]      \label{THOooOQLQooHqEeDK}
	Soit une partie \( \{ e_i \}_{i\in I}\) génératrice de l'espace vectoriel \( E\) (ici, \( I\) est un ensemble quelconque\footnote{Un cas d'utilisation intéressant est de poser \( I=E\) et \( e_i=i\). Pensez-y.}). Soit \( I_0\subset I\) tel que \( \{ e_i \}_{i\in I_0}\) soit libre.

	Alors il existe \( I_1\) tel que \( I_0\subset I_1\subset I\) tel que \( \{ e_i \}_{i\in I_1}\) soit une base de \( E\).
\end{theorem}

Note : une telle partie \( I_0\) existe en prenant un singleton. Mais l'existence n'est pas le sujet ici.

\begin{proof}
	Soit \( \mA\) l'ensemble des parties \( J\) de \( I\) telles que \( I_0\subset J\subset I\) et telles que \( \{ e_i \}_{i\in J}\) soit libre.

	Encore une fois, \( \mA\) est inductif pour l'ordre partiel donné par l'inclusion. Soit \( J\) un élément maximum par le lemme de Zorn \ref{LemUEGjJBc}. Puisque \( J\in\mA\), la partie \( \{ e_i \}_{i\in J}\) est libre. Mais elle est également génératrice parce que si \( e_k\) n'est pas dedans, \( J\) ne serait pas maximum, étant majorée par \( J\cup\{ k \}\).

	Donc \( \{ e_i \}_{i\in J}\) engendre tous les \( e_i\) avec \( i\in I\) et donc, tous les éléments de \( E\).
\end{proof}

\begin{proposition}[\cite{MonCerveau}]	\label{PROPooTSRCooOfTEmO}
	L'ensemble des parties libres d'un espace vectoriel, muni de l'ordre de l'inclusion, est inductif\footnote{Définition \ref{DefGHDfyyz}.}.
\end{proposition}

\begin{proof}
	Soit un espace vectoriel \( V\). Soit un ensemble totalement ordonnée \( \mL=\{ L_i \}_{i\in I}\) de parties libres de \( V\). Nous posons \( L=\bigcup_{i\in I}L_i\). Nous prouvons que \( L\) est libre, de telle sorte que ce soit un maximum de \( \mL\).

	Soient \( x_1,\ldots,x_n\in L\). Il existe une partie finie \( I_0\subset I\) telle que \( x_1,\ldots,x_n\in \bigcup_{i\in I_0}L_i\). Mais toute partie finie d'un ensemble totalement ordonné a un maximum (lemme \ref{LEMooPCRFooXRGrUr}). Donc il existe \( i_0\in I_0\)  tel que \( x_1,\ldots,n_n\in L_{i_0}\). Vu que \( L_{0}\) est libre et que \( \{ x_1,\ldots,n_n \}\subset L_{i_0}\), la partie \( \{ x_1,\ldots,x_n \}\) est libre.
\end{proof}

\begin{normaltext}[\cite{BIBooZFPUooIiywbk}]        \label{NORMooREVQooEFJWta}
	Une preuve alternative du théorème de la base incomplète serait de dire que l'ensemble des parties libres est inductif (proposition \ref{PROPooTSRCooOfTEmO}). De ce fait, la proposition \ref{PROPooFOETooWYLOeq} permet de dire que toute partie libre peut être complétée en une base.
\end{normaltext}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Espace librement engendré}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}[\cite{ooGNYOooGZKGba}]       \label{DEFooCPNIooNxsYMY}
	Soient un ensemble \( S\) et un corps \(\eK \). L'espace vectoriel \defe{librement engendré}{librement engendré} sur \( S\), noté \( F_{\eK}(S)\) est l'ensemble des applications \( S\to \eK\) qui sont non-nulles en un nombre fini de points de \( S\).

	Autrement dit, \( \sigma\colon S\to \eK\) est dans \( F_{\eK}(S) \) si \( \{ x\in S\tq \sigma(x)\neq 0 \}\) est fini\footnote{Parce que nous l'aimons bien, nous ne résistons pas à faire un renvoi vers la définition \ref{DefEOZLooUMCzZR}.}.
\end{definition}

Le lemme suivant donne tout son sens à l'expression «librement» engendré. Il dit que \( F_{\eK}(S)\) possède une base indexée par \( S\) lui-même.
\begin{lemma}       \label{LEMooLOPAooUNQVku}
	L'ensemble des applications \( \delta_s\) données par
	\begin{equation}
		\begin{aligned}
			\delta_s\colon S & \to \eK                    \\
			t                & \mapsto \begin{cases}
				                           1 & \text{si } t=s \\
				                           0 & \text{sinon }
			                           \end{cases}
		\end{aligned}
	\end{equation}
	avec \( s\in S\) forment une base\footnote{Définition \ref{DEFooNGDSooEDAwTh}.} de \( F_{\eK}(S)\).
\end{lemma}

\begin{proof}
	Pour prouver que les \( \delta_s\) sont générateurs, nous considérons \( g\colon S\to \eK\) non nul sur la partie finie \( \{ s_i \}_{i\in I}\) de \( S\). Alors nous avons
	\begin{equation}
		g=\sum_{i\in I}g(s_i)\delta_{s_i}.
	\end{equation}

	Pour prouver que les \( \delta_s\) forment une partie libre, nous supposons avoir \( \lambda_i\in \eK\) tels que
	\begin{equation}
		g=\sum_{i\in I}\lambda_i\delta_{s_i}=0
	\end{equation}
	Soit \( j\in I\). Nous avons
	\begin{equation}
		0=f(s_j)=\sum_{i\in I}\lambda_i \underbrace{\delta_{s_i}(s_j)}_{=\delta_{i,j}}=\lambda_j.
	\end{equation}
	Donc les coefficients \( \lambda_i\) sont tous nuls, et nous avons prouvé que la partie est libre.
\end{proof}

Il est parfois pratique d'écrire les éléments de \( F_{\eK}(S)\) comme sommes «formelles» d'éléments de \( S\). Cela va encore lorsque \( S\) est un ensemble n'ayant aucune somme bien définie.

Mais attention : si \( S=\eR\), l'élément \( 4+7\) de \( F_{\eR}(\eR)\) n'est pas \( 11\). L'élément \( 11\) de \( F_{\eR}(\eR)\) est un élément complètement différent. Bref, il n'est pas judicieux d'écrire les éléments de \( F_{\eK}(S)\) comme des combinaisons linéaires d'éléments de \( S\). Pour \( x\in S\) il vaut mieux écrire explicitement \( \delta_x\) que \( x\). La somme \( \delta_x+\delta_y\) est parfaitement bien définie dans l'ensemble des applications de \( S\) vers \( \eK\).

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Applications linéaires}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Le lien entre matrice et applications linéaires est la définition \ref{DEFooJVOAooUgGKme} et toutes les propriétés qui s'en suivent.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Définition}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}      \label{DEFooULVAooXJuRmr}
	Soient des espaces vectoriels \( E \) et \( F\) sur le corps \( \eK\). Soit un sous-corps \( \eL\) de \( \eK\). Une application \( T\colon E\to F\) est dite \( \eL\)-\defe{linéaire}{linéaire!application} si
	\begin{itemize}
		\item \( T(x+y)=T(x)+T(y)\) pour tout \( x\) et \( y\) dans \( E\),
		\item \( T(\lambda x)=\lambda T(x)\) pour tout \( \lambda\) dans \( \eK\) et \( x\) dans \( E\).
	\end{itemize}
	Nous noterons \( \aL_{\eL}(E,F)\) l'espace des applications \( \eL\)-linéaires de \( E\) vers \( F\).
\end{definition}
Si vous avez bien suivi, les égalités dans la définition~\ref{DEFooULVAooXJuRmr} sont des égalités dans \( F\).

\begin{normaltext}
	Le plus souvent, si \( E\) est un espace vectoriel sur \(\eK \), alors nous ne considérerons que les applications \( \eK\)-linéaires. Autrement dit, nous écrirons le plus souvent simplement \( \aL(E,F)\) sans préciser le corps.

	Il pourra pourtant arriver que, pour un espace vectoriel sur \( \eC\), nous considérions les applications seulement \( \eR\)-linéaires. Ce sera le cas dans le lemme \ref{LEMooBZHIooSQJSnM}.
\end{normaltext}

\begin{lemmaDef} \label{DefDQRooVGbzSm}
	L'ensemble de toutes les applications linéaires de \( E\) vers \( F\) est noté \( \aL(E,F)\)\nomenclature{\( \aL(E,F)\)}{Ensemble des applications linéaires de \( E\) dans \( F\)} et devient un espace vectoriel sur \( \eK\) avec les définitions suivantes :
	\begin{enumerate}
		\item
		      \( (T_1+T_2)(x)=T_1(x)+T_2(x)\),
		\item
		      \( (\lambda T)(x)=\lambda T(x)\).
	\end{enumerate}
\end{lemmaDef}

\begin{example}     \label{EXooMAWMooEaNWpl}
	Pour tout \( b\) dans \( \eR\) la fonction \( T_b(x)= bx\) est une application linéaire de \( \eR\) dans \( \eR\). En effet,
	\begin{itemize}
		\item  \( T_b(x+y)= b(x+y)= bx + by = T_b(x)+T_b(y)\),
		\item \( T_b(ax)=b(ax)= abx = a T_b(x)\).
	\end{itemize}
	De la même façon on peut montrer que la fonction \( T_{\lambda}\) définie par \( T_{\lambda}(x)=\lambda x\) est une application linéaire de \( \eR^m\) dans \( \eR^m\) pour tout \( \lambda\) dans \( \eR\) et \( m\) dans \( \eN\).
\end{example}

\begin{example}     \label{ex_affine}
	Soit \( m\in\eN\). On fixe \( \lambda\) dans \( \eR\) et \( v\) dans \( \eR^m\). L'application \( U_{\lambda}\) de \( \eR^m\) dans \( \eR^m\) définie par \( U_{\lambda}(x)=\lambda x+v\) n'est pas une application linéaire lorsque \( v \neq 0 \), parce que si \( a \) est un réel différent de \(0 \) et \( 1 \), alors \( av \neq v \), d'où
	\[
		U_{\lambda}(ax)=\lambda(ax)+v\neq a(\lambda x+v) =a U_{\lambda}(x).
	\]
\end{example}

\begin{example}     \label{exampleT_A}
	Soit \( A\) une matrice fixée de \( \eM(m\times n, \eR)\). La fonction \( T_A\colon \eR^m\to \eR^n\) définie par \( T_A(x)=Ax\) est une application linéaire. En effet,
	\begin{itemize}
		\item \( T_A(x+y) = A(x+y)= Ax + Ay = T_A(x)+T_A(y)\),
		\item \( T_A(ax)  = A(ax) = a(Ax)   = a T_A(x)\).
	\end{itemize}
\end{example}

\begin{lemma}       \label{LEMooLGEHooVEEoiU}
	Si une application linéaire est inversible, alors son inverse est linéaire.
\end{lemma}

\begin{proof}
	Soient une application linéaire inversible \( f\colon E\to F\), ainsi que \( x,y\in E\). Nous avons
	\begin{equation}
		f\big( f^{-1}(x)+f^{-1}(y) \big)=f\big( f^{-1}(x) \big)+f\big( f^{-1}(y) \big)=x+y=f\big( f^{-1}(x+y) \big).
	\end{equation}
	En prenant \( f^{-1}\) des deux côtés, nous trouvons
	\begin{equation}
		f^{-1}(x)+f^{-1}(y)=f^{-1}(x+y).
	\end{equation}
	De même :
	\begin{equation}
		f\big( \lambda f^{-1}(x) \big)=\lambda f\big( f^{-1}(x) \big)=\lambda x=f\big( f^{-1}(\lambda x) \big),
	\end{equation}
	ce qui nous donne \( \lambda f^{-1}(x)=f^{-1}(\lambda x)\).
\end{proof}


\begin{definition}[Quelques ensembles d'applications linéaires]       \label{DEFooOAOGooKuJSup}
	Soient \( E\) et \( F\) des espaces vectoriels.
	\begin{itemize}
		\item
		      L'ensemble des applications linéaires de \( E\) vers \( F\) est noté \( \aL(E,F)\), comme déjà dit en \ref{DefDQRooVGbzSm}.
		\item Une application linéaire \( E\to E\) est un \defe{endomorphisme}{endomorphisme} de \( E\). L'ensemble des endomorphismes de \( E\) est noté \( \End(E)\)\nomenclature[B]{\( \End(E)\)}{les endomorphismes de \( E\)}.
		\item Un endomorphisme bijectif est un \defe{automorphisme}{automorphisme!d'espace vectoriel}. L'ensemble des automorphismes de \( E\) est noté \( \Aut(E)\)\nomenclature[B]{\( \Aut(E)\)}{automorphisme de l'espace vectoriel \( E\)}.
		\item
		      Une application linéaire bijective \( E\to F\) est un \defe{isomorphisme}{isomorphisme!espaces vectoriels} d'espace vectoriel. L'ensemble des isomorphismes de \( E\to F\) est noté\footnote{Le fait d'utiliser une notation similaire à celle des matrices inversibles n'est pas anodine: le lecteur en est sans doute conscient.} \( \GL(E,F)\). C'est un groupe par le lemme \ref{LEMooLGEHooVEEoiU}.
	\end{itemize}
\end{definition}

\begin{remark}
	Les ensembles définis en~\ref{DEFooOAOGooKuJSup} concernent la structure d'espace vectoriel seulement. Lorsque nous verrons la notion d'espace vectoriel normé, nous demanderons de plus, la continuité, laquelle n'est pas automatique en dimension infinie. Voir aussi les définitions~\ref{DEFooTLQUooJvknvi}.
\end{remark}

\begin{definition}
	Si \( E\) est un espace vectoriel, si \( X\) est un espace vectoriel, et si \( f\colon X\to E\) est une application, le \defe{noyau}{noyau!vers un espace vectoriel} de \( f\) est le noyau de \( f\) lorsque \( E\) est vu comme un groupe pour l'addition\footnote{Définition \ref{DEFooWBIYooGNRYOp}.}, c'est-à-dire la partie
	\begin{equation}
		\ker(f)=\{ x\in X\tq f(x)=0 \}.
	\end{equation}
\end{definition}

\begin{proposition}     \label{PROPooRLLPooKYzsJp}
	Le noyau d'une application linéaire est un sous-espace vectoriel.
\end{proposition}

\begin{proof}
	Soit une application linéaire \( f\colon E\to F\). Si \( x,y\in \ker(f)\) et si \( \lambda\in \eK\) alors
	\begin{equation}
		f(x+y)=f(x)+f(y)=0+0=0,
	\end{equation}
	donc \( x+y\in \ker(f)\), et
	\begin{equation}
		f(\lambda x)=\lambda f(x)=0,
	\end{equation}
	donc \( \lambda x\in \ker(f)\).
\end{proof}

\begin{lemma}[\cite{MonCerveau}]        \label{LEMooIQJMooJWRbub}
	Soit une application linéaire \( f\colon V\to W\). Si \( b\in W\) et si \( m\in f^{-1}(b)\), alors
	\begin{equation}
		f^{-1}(b)-m=\ker(f).
	\end{equation}
\end{lemma}

\begin{proof}
	Si \( x\in f^{-1}(b)-m\), il existe \( \alpha\in f^{-1}(b)\) tel que \( x=\alpha-m\). Alors
	\begin{equation}
		f(x)=f(\alpha)-f(m)=b-b=0.
	\end{equation}

	Pour l'inclusion dans l'autre sens, si \( z\in \ker(f)\), alors \( z=(z+m)-m\) avec \( z+m\in f^{-1}(b)\) parce que
	\begin{equation}
		f(z+m)=f(z)+f(m)=0+b=b=.
	\end{equation}
\end{proof}

\begin{proposition}
	Si \( E\) et \( F\) sont des espaces vectoriels de dimension \( n\) et si \( \{ e_i \}_{i=1,\ldots, n}\) et \( \{ f_i \}_{i=1,\ldots, n}\) sont des bases respectivement de \( E\) et \( F\), alors il existe une unique application linéaire \( T\colon E\to F\) telle que \( T(e_i)=f_i\) pour tout \( i\).
\end{proposition}

\begin{proof}
	En deux parties.\begin{subproof}
		\spitem[Existence]
		Soit \( v\in E\). Vu que \( \{ e_i \}\) est une base, \( v\) se décompose de façon unique en \( v=\sum_iv_ie_i\). Alors la définition
		\begin{equation}
			T(v)=\sum_iv_if_i
		\end{equation}
		est une bonne définition et satisfait aux exigences.
		\spitem[Unicité]
		Soient \( T\) et \( U\) satisfaisant aux exigences. Alors pour tout \( i\) nous avons \( T(e_i)=U(e_i)\). Si \( v\in E\) s'écrit de la forme \( v=\sum_iv_ie_i\) alors la linéarité impose \( T(v)=\sum_iv_iT(e_i)=\sum_iv_iU(e_i)=U(v)\). Donc \( T = U\).
	\end{subproof}
\end{proof}

\begin{lemma}[\cite{MonCerveau}]       \label{LEMooJXFIooKDzRWR}
	Soient des espaces vectoriels \( V\) et \( W\) de dimension finie. Soient des bases \( \{e_i\}\) de \( V\) et \( \{f_{\alpha}\}\) de \( W\). Nous posons
	\begin{equation}
		\begin{aligned}
			\varphi_{i\alpha}\colon V & \to W                 \\
			v                         & \mapsto v_if_{\alpha}
		\end{aligned}
	\end{equation}
	où \( v_i\) est défini par la décomposition (unique) \( v=\sum_iv_ie_i\).

	Alors :
	\begin{enumerate}
		\item
		      La partie \( \{\varphi_{i\alpha}\} \) est une base de \( \aL(V,W)\).
		\item       \label{ITEMooPMLWooNbTyJI}
		      Au niveau des dimensions : \( \dim\big( \aL(V,W) \big)=\dim(V)\dim(W)\).
	\end{enumerate}
\end{lemma}

\begin{proof}
	Il faut prouver que \( \{\varphi_{i\alpha}\}\) est libre et générateur.

	\begin{subproof}
		\spitem[Générateur]
		Soit une application linéaire \( b\colon V\to W\). En décomposant \( b(v)\) dans la base \( \{f_{\alpha}\}\), nous définissons \( b_{\alpha}\colon V\to \eK\) par
		\begin{equation}
			b(v)=\sum_{\alpha}b_{\alpha}(v)f_{\alpha}.
		\end{equation}
		Nous posons \( b_{\alpha i}=b_{\alpha}(e_i)\). Ainsi,
		\begin{equation}
			b(v)=\sum_{\alpha}v_ib_{\alpha i}f_{\alpha}=\sum_{\alpha i}b_{\alpha i}\varphi_{i\alpha}(v).
		\end{equation}
		Donc \( b\) peut être écrit comme combinaison linéaire des \( \varphi_{i\alpha}\).

		\spitem[Libre]
		Supposons que \( \sum_{i\alpha}a_{i\alpha}\varphi_{i\alpha}=0\) pour certains coefficients \( a_{i\alpha}\in \eK\). Nous avons, pour tout \( v\in V\) :
		\begin{equation}
			0=\sum_{i\alpha}a_{i\alpha}\varphi_{i\alpha}(v)=\sum_{i\alpha}a_{i\alpha}v_if_{\alpha},
		\end{equation}
		mais comme les \( f_{\alpha}\) forment une base, chaque terme de la somme sur \( \alpha\) est nul :
		\begin{equation}
			\sum_ia_{i\alpha}v_i=0.
		\end{equation}
		Et comme cela est valable pour tout \( v\) et donc, pour tout choix de \( v_i\), nous avons \( a_{i\alpha}=0\) pour tout \( i\) et pour tout \( \alpha\).
	\end{subproof}
	La formule de dimension est simplement la cardinalité de la base trouvée; c'est la définition \ref{DEFooWRLKooArTpgh}.
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Linéarité et bases}
%---------------------------------------------------------------------------------------------------------------------------

\begin{proposition}[\cite{ooZLSSooMYdbEz}]
	Soient deux espaces vectoriels \( E\) et \( F\). Une application linéaire\footnote{Définition \ref{DEFooULVAooXJuRmr}.} \( f\colon E\to F\) est injective si et seulement si \( \ker(f)=\{ 0 \}\).
\end{proposition}

\begin{proof}
	Nous supposons que \( f\) est injective. Si \( x\in\ker(f)\), alors \( f(x)=0\). Or \( f\) est linéaire, donc \( f(0)=0\). Nous avons donc \( f(x)=f(0)\) et donc \( x=0\) parce que \( f\) est injective.

	Dans l'autre sens, soient \( x,y\) tels que \( f(x)=f(y)\). Par linéarité de \( f\) nous avons \( f(x-y)=0\), et donc \( x-y=0\) parce que \( \ker(f)=\{0\}\). Donc \( x=y\) et \( f\) est injective.
\end{proof}

\begin{proposition}[\cite{ooZLSSooMYdbEz}]      \label{PROPooZFKZooBGLSex}
	Soit \( f\in \aL(E,F)\) où \( E\) et \( F\) sont deux espaces vectoriels.
	\begin{enumerate}
		\item   \label{ITEMooPPMEooIaZqtm}
		      Si \( f\) est injective et si \( \{v_i\}_{i\in I}\) est libre, alors \( \{f(v_i)\}_{i\in I}\) est libre.
		\item   \label{ITEMooOZSPooQBrDGi}
		      Si \( f\) est surjective et si \( \{v_i\}_{i\in I}\) est génératrice, alors \( \{f(v_i)\}_{i\in I}\) est génératrice.
		\item   \label{ITEMooOIEYooIfdFnv}
		      Si \( f\) est une bijection, alors l'image d'une base par \( f\) est une base.
	\end{enumerate}
\end{proposition}

\begin{proof}
	En trois parties.
	\begin{subproof}
		\spitem[\ref{ITEMooPPMEooIaZqtm}]
		Nous devons montrer que \( \{f(v_j)\}_{j\in J}\) est libre pour tout \( J\) fini dans \( I\). Soit donc une partie finie \( J\subset I\) et des scalaires\footnote{Des éléments du corps de base \( \eK\).} tels que \( \sum_{j\in J}\lambda_jf(v_j)=0\). La linéarité de \( f\) donne\footnote{Voir les propriétés de la définition \ref{DEFooULVAooXJuRmr}.}
		\begin{equation}
			f\big( \sum_{j\in J}\lambda_jv_j \big)=0.
		\end{equation}
		Par injectivité de \( f\) nous avons alors \( \sum_j\lambda_jv_j=0\). Comme les \( v_j\) eux-même forment une partie libre, nous avons \( \lambda_j=0\) pour tout \( j\in J\).

		\spitem[\ref{ITEMooOZSPooQBrDGi}]
		Soit \( y\in F\). Puisque \( f\) est surjective, il existe \( x\in E\) tel que \( f(x)=y\). Étant donné que \( \{v_i\}_{i\in I}\) est générateur, il existe une partie finie \( J\subset I\) et des scalaires \( \lambda_j\in \eK\) tels que
		\begin{equation}
			x=\sum_{j\in J}\lambda_jv_j.
		\end{equation}
		En appliquant \( f\) aux deux côtés, et en tenant compte de la linéarité de \( f\),
		\begin{equation}
			y=f(x)=\sum_{j\in J}\lambda_jf(v_j),
		\end{equation}
		ce qui prouve que \( y\) est une combinaison linéaire des \( f(v_j)\).

		\spitem[\ref{ITEMooOIEYooIfdFnv}]
		Une base est à la fois libre et génératrice et une bijection est à la fois injective et surjective. Les deux premiers points permettent de conclure.
	\end{subproof}
\end{proof}

\begin{corollary}[\cite{MonCerveau}]        \label{CORooXIPKooWThOsr}
	Si \( E\) et \( F\) sont des espaces vectoriels isomorphes de dimensions finies. Alors leurs dimensions sont égales.
\end{corollary}

\begin{proof}
	Puisque \( E\) et \( F\) sont isomorphes, il existe une bijection \( f\colon E\to F\). Par la proposition \ref{PROPooZFKZooBGLSex}\ref{ITEMooOIEYooIfdFnv}, l'image d'une base de \( E\) est une base de \( F\). Donc les espaces \( E\) et \( F\) ont des bases contenant le même nombre d'éléments.
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Rang}
%---------------------------------------------------------------------------------------------------------------------------

La proposition~\ref{DefALUAooSPcmyK} et le théorème~\ref{ThoGkkffA} sont valables également en dimension infinie; ce sera une des rares incursions en dimension infinie de ce chapitre.
\begin{propositionDef}\label{DefALUAooSPcmyK}
	L'image d'une application linéaire est un espace vectoriel. La dimension de cet espace est le \defe{rang}{rang} de ladite application linéaire.
\end{propositionDef}

\begin{proof}
	Soit une application linéaire \( f\colon E\to F\). Nous considérons \( v,w\) dans l'image de \( f\) ainsi que \( \lambda\) dans le corps de base commun à \( E\) et \( F\).

	Soient \( v_0\in E\) et \( w_0\in E\) tels que \( v=f(v_0)\) et \( w=f(w_0)\). Alors \( v+w=f(v_0+w_0)\) et \( \lambda v=f(\lambda v_0)\). Donc l'image est bien un espace vectoriel.
\end{proof}

\begin{theorem}[Théorème du rang]       \label{ThoGkkffA}
	Soient \( E\) et \( F\) deux espaces vectoriels (de dimensions finies ou non) et soit \( f\colon E\to F\) une application linéaire.

	Si \( (u_s)_{s\in S}\) est une base de \( \ker(f)\) et si \( \big( f(v_t) \big)_{t\in T}\) est une base de \( \Image(f)\) alors
	\begin{equation}
		(u_s)_{s\in s}\cup (v_t)_{t\in T}
	\end{equation}
	est une base de \( E\).

	En dimension finie, nous avons en plus la formule suivante :
	\begin{equation}     \label{EQooUEOQooLySRiE}
		\rank(f)+\dim(\ker f)=\dim E,
	\end{equation}
	c'est-à-dire que le rang\footnote{Définition~\ref{DefALUAooSPcmyK}.} de \( f\) est égal à la codimension\footnote{Définition~\ref{DefCodimension}.} du noyau.
\end{theorem}
\index{théorème!du rang}

\begin{proof}
	Nous devons montrer que
	\begin{equation}
		(u_s)_{s\in S}\cup (v_t)_{t\in T}
	\end{equation}
	est libre et générateur.

	Soit \( x\in E\). Nous définissons les nombres \( x_t\) par la décomposition de \( f(x)\) dans la base \( \big( f(v_t) \big)\) :
	\begin{equation}
		f(x)=\sum_{t\in T}x_tf(v_t).
	\end{equation}
	Ensuite le vecteur \( x-\sum_tx_tv_t\) est dans le noyau de \( f\), par conséquent nous le décomposons dans la base \( (u_s)\) :
	\begin{equation}
		x-\sum_tx_tv_t=\sum_{s\in S} x_su_s.
	\end{equation}
	Par conséquent
	\begin{equation}
		x=\sum_sx_su_s+\sum_tx_tv_t.
	\end{equation}

	En ce qui concerne la liberté nous écrivons
	\begin{equation}
		\sum_tx_tv_t+\sum_sx_su_s=0.
	\end{equation}
	En appliquant \( f\) nous trouvons que
	\begin{equation}
		\sum_tx_tf(v_t)=0
	\end{equation}
	et donc que les \( x_t\) doivent être nuls. Nous restons avec \( \sum_sx_su_s=0\) qui à son tour implique que \( x_s=0\).
\end{proof}
Un exemple d'utilisation de ce théorème en dimension infinie sera donné dans le cadre du théorème de Fréchet-Riesz, théorème~\ref{ThoQgTovL}.
\ifbool{isGiulietta}{Il existe une généralisation du théorème du rang pour les variétés différentiables en le théorème \ref{THOooSWKVooTJQsXc}.}{}

\begin{proposition}[\cite{ooDSTAooKgSyCN}]      \label{PROPooQCIXooHIyPPq}
	Soit \( E\), un espace vectoriel de dimension finie sur le corps \( \eK\). Soient \( V\) et \( W\) des sous-espaces vectoriels de \( E\). Alors
	\begin{equation}
		\dim(V+W)=\dim(V)+\dim(W)-\dim(V\cap W).
	\end{equation}
\end{proposition}

\begin{proof}
	Nous considérons l'application
	\begin{equation}
		\begin{aligned}
			\varphi\colon V\times W & \to E        \\
			(x,y)                   & \mapsto x+y.
		\end{aligned}
	\end{equation}
	C'est une application linéaire dont l'image est \( V+W\). Nous avons donc, pour commencer
	\begin{equation}
		\dim(V+W)=\dim\big( \Image(\varphi) \big).
	\end{equation}
	Nous appliquons à présent le théorème du rang \ref{ThoGkkffA} à l'application \( \varphi\) :
	\begin{subequations}
		\begin{align}
			\dim(V+W) & =\dim\big( \Image(\varphi) \big)                \\
			          & =\dim(V\times W)- \dim\big( \ker(\varphi) \big) \\
			          & =\dim(V)+\dim(W)-\dim\big( \ker(\varphi) \big).
		\end{align}
	\end{subequations}
	Nous devons maintenant étudier \( \ker(\varphi)\). D'abord, \( (v,w)\in V\times W\) appartient à \( \ker(\varphi)\) si et seulement si \( v+w=0\). Nous avons donc
	\begin{equation}
		\ker(\varphi)=\{ (x,-x)\tq x\in V\cap W \}.
	\end{equation}
	Nous montrons à partir de cela que \( \dim\big( \ker(\varphi) \big)=\dim(V\cap W)\) en montrant que l'application
	\begin{equation}
		\begin{aligned}
			\psi\colon V\cap W & \to \ker(\varphi) \\
			x                  & \mapsto (x,-x)
		\end{aligned}
	\end{equation}
	est un isomorphisme d'espaces vectoriels. D'abord \( \psi\) est injective parce que si \( \psi(x)=\psi(y)\), alors \( (x,-x)=(y,-y)\) et donc \( x=y\). Ensuite, \( \psi\) est surjective parce qu'un élément générique de \( \ker(\varphi)\) est \( (x,-x)=\psi(x)\) avec \( x\in V\cap W\). L'application \( \psi\) étant un isomorphisme d'espaces vectoriels, nous avons bien \( \dim\big( \ker(\varphi) \big)=\dim(V\cap W)\).
\end{proof}

\begin{corollary}       \label{CORooCCXHooALmxKk}
	Soient deux espaces vectoriels \( E\) et \( F\) de même dimension finie\footnote{Les deux mots sont importants : les dimensions doivent être égales et finies.}. Pour une application linéaire \( f\colon E\to F\), les trois conditions suivantes sont équivalentes :
	\begin{enumerate}
		\item
		      \( f\) est injective;
		\item
		      \( f\) est surjective;
		\item
		      \( f\) est bijective.
	\end{enumerate}
\end{corollary}

\begin{proof}
	Si \( f\colon E\to E\) est surjective, alors \( \rank(f)=\dim(E)\), ce qui donne, par le théorème du rang~\ref{ThoGkkffA}, \( \dim\big( \ker(f) \big)=0\), c'est-à-dire que \( f\) est injectif.

	De la même façon, si \( f\) est injective, alors \( \dim\big( \ker(f) \big)=0\), ce qui donne \( \rank(f)=\dim(E)\) ou encore que \( f\) est surjective.
\end{proof}

\begin{example}
	Le corolaire \ref{CORooCCXHooALmxKk} n'est pas correct en dimension infinie. Par exemple en prenant \( f(e_1)=f(e_2)=e_1\) et ensuite \( f(e_k)=e_{k-1}\) pour tout \( k\geq 2\). Cette application est surjective mais pas injective.
\end{example}



\begin{lemma}[\cite{MonCerveau}]	\label{LEMooNNDDooKXdqud}
	Soit un espace vectoriel \( E\). Si \(p \colon E\to E  \) est un projecteur\footnote{Définition \ref{DEFooZACWooWydFDp}.} vérifiant \( p(E)=E\), alors \( p=\id\).
\end{lemma}

\begin{proof}
	L'hypothèse est que \( p\) est surjective. Le corolaire \ref{CORooCCXHooALmxKk} dit que \( p\) est alors bijective et donc inversible. En partant de \( p^2(x)=p(x)\) et en appliquant \( p^{-1}\) est deux côtés nous trouvons \( p(x)=x\). Donc \( p=\id\).
\end{proof}

\begin{proposition}[\cite{MonCerveau}]	\label{PROPooKUAVooCbjDcR}
	Soient des espaces vectoriels de dimension finie \( V\) et \( W\) vérifiant \( \dim(V)>\dim(W)\). Si \(f \colon V\to W  \) est une application linéaire, alors \( \dim\big( \ker(f) \big)\geq \dim(V)-\dim(W)\).
\end{proposition}

\begin{proof}
	Il s'agit d'une conséquence du théorème du rang \eqref{EQooUEOQooLySRiE}. Vu que \( \rank(f)\leq \dim(W)\), nous avons
	\begin{equation}
		\dim\big( \ker(f) \big)=\dim(V)-\rank(f)\geq \dim(V)-\dim(W).
	\end{equation}
\end{proof}


Une conséquence du théorème du rang est que les endomorphismes ont un inverse à gauche et à droite égaux (lorsqu'ils existent). En résumé, ce que le corolaire \ref{CORooNFJLooJtzFwN} dit est que si \( AB=\mtu\), alors \( BA=\mtu\).
\begin{corollary}           \label{CORooNFJLooJtzFwN}
	Soit un endomorphisme \( f\) d'un espace vectoriel de dimension finie. Si \( f\) admet un inverse à gauche, alors
	\begin{enumerate}
		\item
		      \( f\) est bijective,
		\item
		      \( f\) admet également un inverse à droite,
		\item
		      les inverses à gauche et à droite sont égaux.
	\end{enumerate}
	Tout cela tient également en remplaçant «gauche» par «droite».
\end{corollary}

\begin{proof}
	Soit \( g\), un inverse à gauche de \( f\) : \( gf=\id\). Cela implique que \( f\) est injective et que \( g\) est surjective, et donc qu'elles sont toutes deux bijectives par le corolaire~\ref{CORooCCXHooALmxKk}. Puisque \( f\) est bijective, elle admet également un inverse à droite, soit \( h\). Nous avons : \( gf=\id\) et \( fh=\id\).

	Alors \( gfh=h\) parce que \( gf=\id\), mais également \( gfh=g\) parce que \( fh=\id\). Donc \( g=h\).\footnote{C'est le même argument que celui employé pour la preuve du lemme~\ref{LEMooECDMooCkWxXf}~\ref{ITEMooOIWTooYqmMPP}, à ceci près que nous devions montrer l'existence de l'inverse à droite.}
\end{proof}
C'est ce corolaire qui nous permet d'écrire \( f^{-1}\) sans plus de précisions dès que \( f\) est une bijection.

\begin{example}[Pas en dimension infinie]
	Tout cela ne fonctionne pas en dimension infinie. Par exemple avec une base \( \{ e_k \}_{k\in \eN}\) nous pouvons considérer l'opérateur
	\begin{equation}
		f(e_k)=e_{k+1}.
	\end{equation}
	Il est injectif, mais pas surjectif. Si on pose
	\begin{equation}
		g(e_k)=\begin{cases}
			e_{k-1} & \text{si } k\geq 1 \\
			0       & \text{si } k=0
		\end{cases}
	\end{equation}
	alors nous avons \( gf=\id\), mais pas \( fg=\id\) parce que ce \( (fg)(e_0)=0\).
\end{example}

\begin{lemma}       \label{LEMooRZDTooEuLTrO}
	Si \( E\) et \( F\) sont des espaces vectoriels et si \( f\colon E\to F\) est une application linéaire inversible, alors son inverse est également linéaire.
\end{lemma}

\begin{proof}
	Nous avons \( f^{-1}(x+y)=f^{-1}(x)+f^{-1}(y)\). En effet,
	\begin{equation}
		f\big( f^{-1}(x)+f^{-1}(y) \big)=f\big( f^{-1}(x) \big)+f\big( f^{-1}(y) \big)=x+y.
	\end{equation}
	De la même façon,
	\begin{equation}
		f\big( \lambda f^{-1}(x) \big)=\lambda x,
	\end{equation}
	donc \( f^{-1}(\lambda x)=\lambda f^{-1}(x)\).
\end{proof}

\begin{proposition}     \label{PROPooHLUYooNsDgbn}
	Soient un espace vectoriel \( E\) de dimension finie, un endomorphisme \( f\colon E\to E\) et une partie \( \{v_i\}_{i\in I}\) tel que \( \{f(v_i)\}_{i\in I}\) soit une base.

	Alors \( \{v_i\}_{i\in I}\) est une base.
\end{proposition}

\begin{proof}
	Soit \( x\in E\). Il existe une partie finie \( J\subset I\) et des scalaires \( \lambda_j\) tels que
	\begin{equation}
		x=\sum_j\lambda_jf(v_j)=f\big( \sum_j\lambda_jv_j \big),
	\end{equation}
	ce qui prouve que \( f\) est surjective. Le corolaire \ref{CORooCCXHooALmxKk} nous dit alors que \( f\) est une bijection. L'application inverse est également linéaire par le lemme \ref{LEMooRZDTooEuLTrO}.

	Une application linéaire bijective (comme \( f^{-1}\)) transforme une base en une base par la proposition \ref{PROPooZFKZooBGLSex}. Donc
	\begin{equation}
		f^{-1}\big( \{f(v_i)\} \big)
	\end{equation}
	est une base.
\end{proof}

\begin{proposition}     \label{PROPooADESooATJSrH}
	Soit un espace vectoriel \( E\) de dimension finie et deux applications linéaires \( f,g\colon E\to E\) telles que \( g\circ f=\id\). Alors \( f\) et \( g\) sont bijectives.
\end{proposition}

\begin{proof}
	En plusieurs étapes
	\begin{subproof}
		\spitem[\( f\) est injective]
		Si \( f(x)=f(y)\), alors en appliquant \( g\) nous avons
		\begin{equation}
			g\big( f(x) \big)=g\big( f(y) \big),
		\end{equation}
		ce qui donne \( x=y\).
		\spitem[\( f\) est surjective]
		C'est maintenant le corolaire \ref{CORooCCXHooALmxKk}.
		\spitem[\( g\) est surjective]
		Pour tout \( x\in E\) nous avons \( g\big( f(x) \big)=x\). Donc l'image de \( f(E)\) par \( g\) est \( E\).
		\spitem[\( g\) est injective]
		C'est maintenant le corolaire \ref{CORooCCXHooALmxKk}.
	\end{subproof}
\end{proof}

\begin{lemma}[\cite{ooEPEFooQiPESf}]        \label{LEMooDAACooElDsYb}
	Soit une application linéaire \( f\colon E\to F\).
	\begin{enumerate}
		\item       \label{ITEMooEZEWooZGoqsZ}
		      L'application \( f\) est injective si et seulement si il existe \( g\colon F\to E\) telle que \( g\circ f=\id|_E\).
		\item
		      L'application \( f\) est surjective si et seulement si il existe \( g\colon F\to E\) telle que \( f\circ g=\id|_F\).
	\end{enumerate}
\end{lemma}

\begin{proof}
	Nous démontrons séparément les deux affirmations.
	\begin{enumerate}
		\item
		      Si \( f\) est injective, alors \( f\colon E\to \Image(f)\) est un isomorphisme. Si \( V\) est un supplémentaire de \( \Image(f)\) dans \( F\) (c'est-à-dire \( F=\Image(f)\oplus V\)) alors nous pouvons poser \( g(x+v)=f^{-1}(x)\) où \( x+v\) est la décomposition (unique) d'un élément de \( F\) en \( x\in\Image(f)\) et \( v\in V\). Avec cela nous avons bien \( g\circ f=\id\).

		      Réciproquement, si il existe \( g\colon F\to E\) telle que \( g\circ f=\id\) alors \( f\colon E\to E\) doit être injective. Parce que si \( f(x)=0\) avec \( x\neq 0\) alors \( (g\circ f)(x)=0\neq x\).
		\item
		      Si \( f\) est surjective nous pouvons choisir des éléments \( x_1,\ldots, x_p\) dans \( E\) tels que \( \{ f(x_i) \}\) soit une base de \( F\). Ensuite nous définissons
		      \begin{equation}
			      \begin{aligned}
				      g\colon F         & \to E                   \\
				      \sum_k a_k f(x_k) & \mapsto \sum_k a_k x_k.
			      \end{aligned}
		      \end{equation}
		      Cela donne \(  f\circ g=\id|_F\) parce que si \( v\in F\) alors \( v=\sum_kv_kf(x_k)\) avec \( v_k\in \eK\), et nous avons
		      \begin{equation}
			      (f\circ g)(v)=\sum_k v_k (f\circ g) \left(f(x_k)\right)
			      =f\left( \sum_k v_k x_k \right)
			      =\sum_k v_k f(x_k) = v.
		      \end{equation}

		      Réciproquement, si il existe \( g\colon F\to E\) tel que \( f\circ g=\id\) alors \( f\) doit être surjective, parce que
		      \begin{equation}
			      F=\Image(f\circ g)=f\big( \Image(g) \big)\subset \Image(f).
		      \end{equation}
	\end{enumerate}
\end{proof}
