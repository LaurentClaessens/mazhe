% Copyright (c) 2008-2019
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Espace des fonctions continues}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{definition}
    Soit \( I\), un intervalle de \( \eR\). L'\defe{oscillation}{oscillation!d'une fonction} sur \( I\) est le nombre
    \begin{equation}
        \omega_f(I)=\sup_{x\in I}f(x)-\inf_{x\in I}f(x).
    \end{equation}
\end{definition}
    Pour chaque \( x\) fixé, la fonction
    \begin{equation}
        x\mapsto \omega_f\big( B(x,\delta) \big)
    \end{equation}
    est une fonction positive, croissante et a donc une limite (pour \( \delta\to 0\)). Nous notons \( \omega_f(x)\) cette limite qui est l'\defe{oscillation}{oscillation!d'une fonction en un point} de \( f\) en ce point. Une propriété immédiate est que \( f\) est continue en \( x_0\) si et seulement si \( \omega_f(x_0)=0\).

    \begin{lemma}       \label{LemuaPbtQ}
    L'ensemble des points de discontinuité d'une fonction \( f\colon \eR\to \eR\) est une réunion dénombrable de fermés.
\end{lemma}

\begin{proof}
    Soit \( D\) l'ensemble des points de discontinuité de \( f\). Nous avons
    \begin{equation}
        D=\bigcup_{n=1}^{\infty}\{ x\tq \omega_f(x)\geq \frac{1}{ n } \}.
    \end{equation}
    Il nous suffit donc de montrer que pour tout \( \epsilon\), l'ensemble
    \begin{equation}
        \{ x\tq \omega_f(x)<\epsilon \}
    \end{equation}
    est ouvert. Soit en effet \( x_0\) dans cet ensemble. Il existe \( \delta\) tel que \( \omega_f\big( B(x_0,\delta) \big)<\epsilon\). Si \( x\in B(x_0,\delta)\), alors si on choisit \( \delta'\) tel que \( B(x,\delta')\subset B(x_0,\delta)\), nous avons \( \omega_f\big( B(x,\delta') \big)<\epsilon\), ce qui justifie que \( \omega_f(x)<\epsilon\) et donc que \( x\) est également dans l'ensemble considéré.
\end{proof}

\begin{theorem}
    L'ensemble des points de discontinuité d'une limite simple de fonctions continues est de première catégorie.
\end{theorem}

\begin{proof}
    Soit \( (f_n)\) une suite de fonctions qui converge simplement vers \( f\). Nous devons écrire l'ensemble des points de discontinuité de \( f\) comme une union dénombrable d'ensembles tels que sur tout intervalle \( I\), aucun de ces ensembles n'est dense. Nous savons déjà par le lemme~\ref{LemuaPbtQ} que l'ensemble des points de discontinuité  de \( f\) est donné par
    \begin{equation}
        D=\bigcup_{n=1}^{\infty}\{ x\tq \omega_f(x)\geq \frac{1}{  n } \}.
    \end{equation}
    Nous essayons donc de prouver que pour tout \( \epsilon\), l'ensemble
    \begin{equation}
        F=\{ x\tq \omega_f(x)\geq \epsilon \}
    \end{equation}
    est nulle part dense. Soit
    \begin{equation}
        E_n=\bigcap_{i,j>n}\{ x\tq | f_i(x)-f_j(x) |<\epsilon \}.
    \end{equation}
    Nous montrons que cet ensemble est fermé en étudiant le complémentaire. Soit \( x\notin E_n\); alors il existe un couple \( (i,j)\) tel que
    \begin{equation}
        | f_i(x)-f_j(x) |>\epsilon.
    \end{equation}
    Par continuité, cette inégalité reste valide dans un voisinage de \( x\). Donc il existe un voisinage de \( x\) contenu dans \( \complement E_n\) et \( E_n\) est donc fermé.

    De plus nous avons \( E_n\subset E_{n+1}\) et \( \bigcup_nE_n=\eR\). Ce dernier point est dû au fait que pour tout \( x\), il existe \( N\) tel que \( i,j>N\) implique \( | f_i(x)-f_j(x) |\leq \epsilon\). Cela est l'expression du fait que la suite \( \big( f_n(x) \big)_{n\in \eN}\) est de Cauchy.

    Soit \( I\), un intervalle fermé de \( \eR\). Nous voulons trouver un intervalle \( J\subset I\) sur lequel \( f\) est continue. Nous écrivons \( I\) sous la forme
    \begin{equation}
        I=\bigcup_{n=1}^{\infty}(E_n\cap I).
    \end{equation}
    Tous les ensembles \( J_n=E_n\cap I\) ne peuvent être nulle part dense en même temps (à cause du théorème de Baire~\ref{ThoQGalIO}). Il existe donc un \( n\) tel que \( J_n\) contienne un ouvert \( J\). Le but est de montrer que \( f\) est continue sur \( J\). Pour ce faire, nous n'allons pas simplement majorer \( | f(x)-f(x_0) |\) par \( \epsilon\) lorsque \( | x-x_0 |\) est petit. Nous allons majorer l'oscillation de \( f\) sur \( B(x_0,\delta)\) lorsque \( \delta\) est petit. Pour cela nous prenons \( x_0\) et \( x\) dans \( J\) et nous écrivons
    \begin{equation}
        | f(x)-f(x_0) |\leq | f(x)-f_n(x) |+| f_n(x)-f_n(x_0) |.
    \end{equation}
    À ce niveau nous rappelons que \( n\) est fixé par le choix de \( J\), dans lequel \( \epsilon\) est déjà inclus. Nous choisissons évidemment \( | x-x_0 |\leq \delta\) de telle sorte que le second terme soit plus petit que \( \epsilon\) en vertu de la continuité de \( f_n\). Pour le premier terme, pour tout \( i,j\geq n\) nous avons
    \begin{equation}
        | f_i(x)-f_j(x) |<\epsilon.
    \end{equation}
    Si nous posons \( j=n\) et \( i\to\infty\), en tenant compte du fait que \( f_i\to f\) simplement,
    \begin{equation}
        | f(x)-f_n(x) |\leq \epsilon.
    \end{equation}
    Nous avons donc obtenu \( | f(x)-f_n(x_0) |\leq 2\epsilon\). Cela signifie que dans un voisinage de rayon \( \delta\) autour de \( x_0\), les valeurs extrêmes prises par \( f(x) \) sont \( f_n(x_0)\pm 4\epsilon\). Nous avons donc prouvé que pour tout \( \epsilon\), il existe \( \delta\) tel que
    \begin{equation}
        \omega_f\big( \mathopen[ x_0-\delta , x_0+\delta \mathclose] \big)\leq 4\epsilon.
    \end{equation}
    De là nous concluons que
    \begin{equation}
        \lim_{\delta\to 0}\omega_f\big( \mathopen[ x_0-\delta , x_0+\delta \mathclose] \big)=0,
    \end{equation}
    ce qui signifie que \( f\) est continue en \( x_0\).
\end{proof}

\begin{example}
    Une fonction discontinue sur \( \eQ\) et continue ailleurs. La fonction
    \begin{equation}
        f(x)=\begin{cases}
            0    &   \text{si } x\notin \eQ\\
            \frac{1}{ q }    &    \text{si } x=p/q
        \end{cases}
    \end{equation}
    où par «\( x=p/q\)» nous entendons que \( p/q\) est la fraction irréductible.

    Cette fonction est discontinue sur \( \eQ\) parce que si \( q\in \eQ\) alors \( f(q)\neq 0\) alors que dans tous voisinage de \( q\) il existe un irrationnel sur qui la fonction vaudra zéro.

    Montrons que \( f\) est continue sur les irrationnels. Si \( x_0\notin \eQ\) alors \( f(x_0)=0\). Mais si on prend un voisinage suffisamment petit de \( x_0\), nous pouvons nous arranger pour que tous les rationnels aient un dénominateur arbitrairement grand. En effet si nous nous fixons un premier rayon \( r_0>0\) alors il existe un nombre fini de fractions de la forme \( 1\), \( \frac{ k }{2}\), \( \frac{ k }{ 3 }\),\ldots, \( \frac{ k }{ N }\) dans \( B(x_0,r_0)\). Il suffit maintenant de choisir \( 0<r\leq r_0\) tel que ces fractions soient toutes hors de \( B(x_0,r)\). Dans cette boule nous avons \( f<\frac{1}{ N }\). Du coup \( f\) est continue en \( x_0\).
\end{example}

\begin{definition}[Point périodique\cite{TMCHooOaTrJL}]
    Soit \( f\colon I\to I\) une application d'un ensemble \( I\) dans lui-même. Si \( x\in I\) vérifie \( f^n(x)=x\) et \( f^k(x)\neq x\) pour \( k=1,\ldots, n-1\) alors on dit que \( x\) est un point \( n\)-périodique.
\end{definition}

\begin{lemma}       \label{LemAONBooGZBuYt}
    Soit \( I\) un segment\footnote{définition~\ref{DefLISOooDHLQrl}. Un segment est un intervalle fermé borné.} de \( \eR\) et une fonction continue \( f\colon I\to I\). Si \( K\) est un segment fermé avec \( K\subset f(I)\) alors il existe un segment fermé \( L\subset I\) tel que \( K=f(L)\).
\end{lemma}

\begin{proof}
    Mentionnons immédiatement que \( f\) est continue sur \( I\) qui est compact\footnote{Par le lemme~\ref{LemOACGWxV}.}. Par conséquent tous les nombres dont nous allons parler sont finis parce que \( f\) est bornée par le théorème~\ref{ThoMKKooAbHaro}.

    Soit \( K=\mathopen[ \alpha , \beta \mathclose]\). Si \( \alpha=\beta\) alors le segment \( L=\{ a \}\) convient. Nous supposons donc que \( \alpha\neq \beta\) et nous considérons \( a,b\in I\) tels que \( \alpha=f(a)\) et \( \beta=f(b)\). Vu que \( a\neq b\) nous supposons \( a<b\) (le cas \( a>b\) se traite de façon similaire).

    Nous posons
    \begin{equation}
        A=\{ x\in\mathopen[ a , b \mathclose]\tq f(x)=\alpha \}.
    \end{equation}
    C'est un ensemble borné par \( a\) et \( b\). De plus il est fermé; ce dernier point n'est pas tout à fait évident parce que \( f\) n'est pas définit sur \( \eR\) mais sur \( I\) qui est fermé, le corollaire~\ref{CorNNPYooMbaYZg} n'est donc pas immédiatement utilisable. Prouvons donc que \( Z=\{ x\in \eR\tq f(x)=\alpha \}\) est fermé. Si \( x_0\) est hors de \( Z\) alors soit \( x_0\) est dans \( I\) soit il est hors de \( I\). Dans ce second cas, le complémentaire de \( I\) étant ouvert, on a un voisinage de \( x_0\) hors de \( I\) et par conséquent hors de \( Z\). Si au contraire \( x_0\in I\) alors il y a (encore) deux cas : soit \( x_0\in\Int(I)\) soit \( x_0\) est sur le bord de \( I\). Dans le premier cas, le théorème des valeurs intermédiaires\footnote{Théorème~\ref{ThoValInter}.} fonctionne. Pour le second cas, nous supposons \( x_0=\max(I)\) (le cas \( x_0=\min(I)\) est similaire). Le théorème des valeurs intermédiaires dit que sur \( \mathopen[ x_0-\epsilon , x_0 \mathclose]\), \( f\neq \alpha\) et en même temps, sur \( \mathopen] x_0 , x_0+\epsilon \mathclose]\), nous sommes en dehors du domaine. Au final \( \{ f(x)=\alpha \}\) est fermé et \( A\) est alors fermé en tant que intersection de deux fermés.

    L'ensemble \( A\) étant non vide (\( a\in A\)), il possède donc un maximum que nous nommons \( u\) :
    \begin{equation}
        u=\max(A).
    \end{equation}
    Nous posons aussi
    \begin{equation}
        B=\{ x\in \mathopen[ u , b \mathclose]\tq f(x)=\beta \}
    \end{equation}
    qui est encore fermé, borné et non vide. Nous pouvons donc définir
    \begin{equation}
        v=\min(B).
    \end{equation}
    Nous prouvons maintenant que \( f\big( \mathopen[ u , v \mathclose] \big)=\mathopen[ \alpha , \beta \mathclose]\). D'abord \( f\big( \mathopen[ u , v \mathclose] \big)\) est un intervalle compact\footnote{Corollaire~\ref{CorImInterInter} et théorème~\ref{ThoImCompCotComp}.} contenant \( f(u)=\alpha\) et \( f(v)=\beta\). Par conséquent \( \mathopen[ \alpha , \beta \mathclose]\subset f\big( \mathopen[ u , v \mathclose] \big)\). Pour l'inclusion inverse supposons \( t\in \mathopen[ u , v \mathclose]\) tel que \( f(t)>\beta\). Vu que \( f(a)=\alpha\) et \( \alpha<\beta\) le théorème des valeurs intermédiaires il existe \( t_0\in \mathopen[ a , t \mathclose]\) tel que \( f(t_0)=\beta\). Cela donne \( t_0<v\) et donc contredit la minimalité de \( v\) dans \( B\). Nous en déduisons que \( f\big( \mathopen[ u , v \mathclose] \big)\) ne contient aucun élément plus grand que \( \beta\). Même jeu pour montrer que ça ne contient aucun élément plus petit que \( \alpha\).

    En définitive, le segment \( L=\mathopen[ u , v \mathclose]\) fonctionne.
\end{proof}

Lorsque \( I_2\subset f(I_1)\) nous notons \( I_1\to I_2\) ou, si une ambiguïté est à craindre, \( I_1\stackrel{f}{\longrightarrow}I_2\). Cette flèche se lit «recouvre».
\begin{lemma}[\cite{PAXrsMn,TMCHooOaTrJL}]      \label{LemSSPXooMkwzjb}
    Soient les segments \( I_0,\ldots, I_{n-1}\) tels que nous ayons le cycle
    \begin{equation}
        I_0\to I_1\to\ldots\to I_{n-1}\to I_0.
    \end{equation}
    Alors \( f^n\) admet un point fixe \( x_0\in I_0\) tel que \( f^k(x_0)\in I_k\) pour tout \( k=0,\ldots, n-1\).
\end{lemma}

\begin{proof}
    Nous prouvons les cas \( n=1\) et \( n=2\) séparément.
    \begin{subproof}
    \item[\( n=1\)]
        Nous avons \( I_0\to I_0\), c'est-à-dire que $I_0\subset f(I_0)$. Si \( I_0=\mathopen[ a , b \mathclose]\) alors nous posons \( a=f(\alpha)\) et \( b=f(\beta)\) pour certains \( \alpha,\beta\in I_0\). Nous posons ensuite \( g(x)=f(x)-x\).

        Dans un premier temps, \( g(\alpha)=a-\alpha\leq 0\) parce que \( a=\in(I_0)\) et \( \alpha\in I_0\). Pour la même raison, \( g(\beta)=b-\beta\geq 0\). Le théorème des valeurs intermédiaires donne alors \( t_0\in \mathopen[ \alpha , \beta \mathclose]\subset I_0\) tel que \( g(t_0)=0\). Nous avons donc \( f(t_0)=t_0\).
    \item[\( n=2\)]
        Nous avons \( I_0\to I_1\to I_0\). Vu que \( I_1\subset f(I_0)\), le lemme~\ref{LemAONBooGZBuYt} donne un segment \( J_1\subset I_0\) tel que \( f(J_1)=I_1\). Mézalors
        \begin{equation}
            J_1\subset I_0\subset f(I_1)=f^2(J_1).
        \end{equation}
        Nous avons donc \( J_1\stackrel{f^2}{\longrightarrow}J_1\) et par le cas \( n=1\) traité plus haut, la fonction \( f^2 \) a un point fixe \( x_0\) dans \( J_1\). De plus
        \begin{equation}
            f(x_0)\in f(J_1)=I_1,
        \end{equation}
        le point \( x_0\) est donc bien celui que nous cherchions.
    \item
        Cas général. Nous avons
        \begin{equation}
            I_0\to I_1\to\ldots\to I_{n-1}\to I_0.
        \end{equation}
        Vu que \( I_1\subset f(I_0)\), il existe \( J_1\subset I_0\) tel que \( f(J_1)=I_1\). Mais
        \begin{equation}
            I_2\subset f(I_1)=f^2(J_1),
        \end{equation}
        donc il existe \( J_2\subset J_1\) tel que \( I_2=f^2(J_2)\). En procédant encore longtemps ainsi nous construisons les ensembles \( J_1,\ldots, J_{n-1}\) tels que
        \begin{equation}
            J_{n-1}\subset J_{n-2}\subset\ldots\subset J_1\subset J_0
        \end{equation}
        tels que \( I_k=f^k(J_k)\) pour tout \( k=1,\ldots, n-1\). La dernière de ces inclusions est \( I_{n-1}=f^{n-1}(J_{n-1})\), mais \( I_{n-1}\to I_0\), c'est-à-dire que
        \begin{equation}
            I_0\subset f(I_{n-1})=f^n(J_{n-1}),
        \end{equation}
        et il existe \( J_n\subset J_{n-1}\) tel que \( I_0\subset f^n(J_n)\). Mais comme \( J_n\subset J_0\) nous avons en particulier \( J_n\subset f^n(J_n)\).

        Cela donne un point fixe \( x_0\in J_n\) pour \( f^n\). Par construction nous avons \( J_n\subset J_{n-1}\subset\ldots\subset J_1\subset J_0\) et donc \( x_0\in J_k\) pour tout \( k\). En  particulier
        \begin{equation}
            f^k(x_0)\in f^k(J_k)=I_k
        \end{equation}
        pour tout \( k\).
    \end{subproof}
\end{proof}

\begin{theorem}[Théorème de Sarkowski\cite{PAXrsMn,TMCHooOaTrJL}]
    Soit \( I\), un segment de \( \eR\) et une application continue \( f\colon I\to I\). Si \( f\) admet un point \( 3\)-périodique, alors \( f\) admet des points \( n\)-périodiques pour tout \( n\geq 1\).
\end{theorem}

\begin{proof}
    Soit \( a\in I\) un point \( 3\)-périodique pour \( f\) et notons \( b=f(a)\), \( c=f(b)\). Les points \( b\) et \( c\) sont également des points \( 3\)-périodiques. Quitte à renommer, nous pouvons supposer que \( a\) est le plus petit des trois. Il reste deux possibilités : \( a<b<c\) et \( a<c<b\). Nous traitons d'abord le premier cas.

    Supposons \( a<b<c\). Nous posons \( I_0=\mathopen[ a , b \mathclose]\) et \( I_1=\mathopen[ b , c \mathclose]\). Nous avons immédiatement \( I_1\subset f(I_0)\) et comme \( f(b)=c\) et \( f(c)=a\), \( f(I_1)\) recouvre \( \mathopen[ a , c \mathclose]\) et donc recouvre en même temps \( I_1\) et \( I_2\). Nous avons donc \( I_0\to I_1\), \( I_1\to I_0\) et \( I_1\to I_1\).
    \begin{subproof}
    \item[Un point \( 1\)-périodique]
        Nous avons \( I_1\to I_1\) qui prouve que \( f\) a un point fixe dans \( I_1\). C'est le cas \( n=1\) du lemme~\ref{LemSSPXooMkwzjb}. Voilà un point \( 1\)-périodique.
    \item[Un point \( 2\)-périodique]
        Nous avons \( I_0\to I_1\to I_0\). Par conséquent, le lemme~\ref{LemSSPXooMkwzjb} dit que \( f^2\) a un point fixe \( x_0\in I_0\) tel que \( f(x_0)\in I_1\). Montrons que \( f(x_0)\neq x_0\). Pour avoir \( x_0=f(x_0)\), il faudrait \( x_0\in I_0\cap I_1=\{ b \}\). Mais \( b\) est un point \( 3\)-périodique, donc ne vérifiant certainement pas \( f^2(b)=b\). Nous en déduisons que \( f(x_0)\neq x_0\) et donc que \( x_0\) est \( 2\)-périodique.
    \item[Un point \( 3\)-périodique]
        On en a par hypothèse.
    \item[Un point \( n\)-périodique pour \( n\geq 4\)]
        Nous avons le cyle
        \begin{equation}
            I_0\to \underbrace{I_1\to I_1\to\ldots\to I_1}_{\text{n-1} fois}\to I_0.
        \end{equation}
        Le lemme donne alors un point fixe \( x\in I_0\) pour \( f^n\) tel que \( f^k(x)\in I_1\) pour \( k=1,\ldots, n-1\). Est-ce possible que \( x=b\) ? Non parce que \( f^2(b)=a\in I_0\) alors que \( f^2(x)\in I_1\). Mais \( I_0\cap I_1=\{ b \}\).

        Par conséquent la relation \( f^k(x)\in I_1\) exclu d'avoir \( f^k(x)=x\), et le point \( x\) est bien \( n\)-périodique.
    \end{subproof}

    Passons au cas \( a<c<b\). Alors nous posons \( I_0=\mathopen[ a , c \mathclose]\) et \( I_1=\mathopen[ c , b \mathclose]\). Encore une fois \( f(I_0)\) contient \( a\) et \( b\), donc \( I_0\to I_0\) et \( I_0\to I_1\). Mais en même temps \( f(I_1)\) contient \( a\) et \( c\), donc \( I_1\to I_0\).

    Nous pouvons donc refaire comme dans le premier cas, en inversant les rôles de \( I_0\) et \( I_1\). En particulier nous pouvons considérer le cycle
    \begin{equation}
        I_1\to I_0\to I_0\to\ldots\to I_0\to I_1.
    \end{equation}
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Uniforme continuité}		\label{SecUnifContinue}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{definition}
	Une partie $A\subset\eR^m$ est dite \defe{bornée}{bornée!partie de $\eR^m$} s'il existe un $M>0$ tel que $A\subset B(0,M)$. Le \defe{diamètre}{diamètre} de la partie $A$ est\nomenclature[T]{$\Diam(A)$}{Diamètre de la partie $A$} le nombre
	\begin{equation}
		\Diam(A)=\sup_{x,y\in A}\| x-y \|\in\mathopen[ 0 , \infty \mathclose].
	\end{equation}
\end{definition}
Lorsque $A$ est borné, il existe un $M$ tel que $\| x \|\leq M$ pour tout $x\in A$.

\begin{lemma}
	Si $A$ est une partie non vide de $\eR^m$, alors $\Diam(A)=\Diam(\bar A)$.
\end{lemma}
Nous n'allons pas donner de démonstrations de ce lemme.


Si $(x_n)$ est une suite et $I$ est un sous-ensemble infini de $\eN$, nous désignons par $x_I$ la suite des éléments $x_n$ tels que $n\in I$. Par exemple la suite $x_{\eN}$ est la suite elle-même, la suite $x_{2\eN}$ est la suite obtenue en ne prenant que les éléments d'indice pair.

Les suites $x_I$ ainsi construites sont dites des \defe{sous-suites}{sous-suite} de la suite $(x_n)$.


Pour une fonction $f\colon D\subset\eR^m\to \eR$, la continuité au point $a$ signifie que pour tout $\varepsilon>0$,
\begin{equation}
	\exists\delta>0\tq 0<\| x-a \|<\delta\Rightarrow | f(x)-f(a) |<\varepsilon.
\end{equation}
Le $\delta$ qu'il faut choisir dépend évidemment de $\varepsilon$, mais il dépend en général aussi du point $a$ où l'on veut tester la continuité. C'est-à-dire que, étant donné un $\varepsilon>0$, nous pouvons trouver un $\delta$ qui fonctionne pour certains points, mais qui ne fonctionne pas pour d'autres points.

Il peut cependant également arriver qu'un même $\delta$ fonctionne pour tous les points du domaine. Dans ce cas, nous disons que la fonction est uniformément continue sur le domaine.

\begin{definition}
	Une fonction $f\colon D\subset\eR^m\to \eR$ est dite \defe{uniformément continue}{continue!uniformément} sur $D$ si
	\begin{equation}	\label{EqConditionUnifCont}
		\forall\varepsilon>0,\,\exists\delta>0\tq\,\forall x,y\in D,\,\| x-y \|\leq\delta \Rightarrow| f(x)-f(a) |<\varepsilon.
	\end{equation}
\end{definition}

Il est intéressant de voir ce que signifie le fait de \emph{ne pas} être uniformément continue sur un domaine $D$. Il s'agit essentiellement de retourner tous les quantificateurs de la condition \eqref{EqConditionUnifCont} :
\begin{equation}	\label{EqConditionPasUnifCont}
	\exists\varepsilon>0\tq\forall\delta>0,\,\exists x,y\in D\tq \| x-y \|<\delta\text{ et }\big| f(x)-f(y) \big|>\varepsilon.
\end{equation}
Dans cette condition, les points $x$ et $y$ peuvent être fonction du $\delta$. L'important est que pour tout $\delta$, on puisse trouver deux points $\delta$-proches dont les images par $f$ ne soient pas $\varepsilon$-proches.

\begin{example}
	Prenons la fonction $f(x)=\frac{1}{ x }$, et demandons nous pour quel $\delta$ nous sommes sûr d'avoir
	\begin{equation}
		| f(a+\delta)-f(a) |=\left| \frac{1}{ a+\delta }-\frac{1}{ a } \right| <\varepsilon.
	\end{equation}
	Pour simplifier, nous supposons que $a>0$. Nous calculons
	\begin{equation}
		\begin{aligned}[]
			\frac{ 1 }{ a }-\frac{1}{ a+\delta }&<	\varepsilon\\
			\frac{ \delta }{ a(a+\delta) }&<\varepsilon\\
			\delta&<\varepsilon a^2+\varepsilon a\delta\\
			\delta(1-\varepsilon a)&<\varepsilon a^2\\
			\delta&<\frac{ \varepsilon a^2 }{ 1-\varepsilon a }.
		\end{aligned}
	\end{equation}
	Notons que, à $\varepsilon$ fixé, plus $a$ est petit, plus il faut choisir $\delta$ petit. La fonction $x\mapsto\frac{1}{ x }$ n'est donc pas uniformément continue. Cela correspond au fait que, proche de zéro, la fonction monte très vite. Une fonction uniformément continue sera une fonction qui ne montera jamais très vite.
\end{example}

\begin{proposition}
	Quelques propriétés des fonctions uniformément continues.
	\begin{enumerate}
		\item
			Toute application uniformément continue est continue;
		\item
			la composée de deux fonctions uniformément continues est uniformément continue;
	\end{enumerate}
\end{proposition}
Nous verrons qu'une application lipschitzienne est uniformément continue (proposition~\ref{PROPooVZSAooUneOQK}).

Une fonction peut être uniformément continue sur un domaine et pas sur un autre. Le théorème suivant donne une importante indication à ce sujet.
\begin{theorem}[Heine]\index{théorème!Heine}\index{Heine (théorème)}		\label{ThoHeineContinueCompact}
    Soit \( K\) un compact de \( \eR^n\). Une fonction continue \( f\colon \eR^n\to \eR^m\) est uniformément continue sur \( K\).
\end{theorem}

La démonstration qui suit est valable pour une fonction \( f\colon \eR^n\to \eR^m\) et utilise le fait que le produit cartésien de compacts est compact. Dans le cas de fonctions sur \( \eR\), nous pouvons modifier la démonstration pour ne pas utiliser ce résultat; voir plus bas.
%TODO : trouver où se trouve la preuve du produit de compacts et la référentier ici.
\begin{proof}
	Nous allons prouver ce théorème par l'absurde. Nous commençons par écrire la condition \eqref{EqConditionPasUnifCont} qui exprime que $f$ n'est pas uniformément continue sur le compact \( K\) :
	\begin{equation}
		\exists\varepsilon>0\tq\forall\delta>0,\,\exists x,y\in K\tqs \| x-y \|<\delta\text{ et }\big| f(x)-f(y) \big|>\varepsilon.
	\end{equation}
	En particulier (en prenant $\delta=\frac{1}{ n }$ pour tout $n$), pour chaque $n$ nous pouvons trouver $x_n$ et $y_n$ dans $K$ qui vérifient simultanément les deux conditions suivantes :
	\begin{subequations}
		\begin{numcases}{}
			\| x_n-y_n \|<\frac{1}{ n }\\
			\big| f(x_n)-f(y_n) \big|>\varepsilon.	\label{EqCond3107fxfyepsppt}
		\end{numcases}
	\end{subequations}
    Nous insistons que c'est le même $\varepsilon$ pour chaque $n$. L'ensemble $K$ étant compact, l'ensemble \( K\times K \) est compact (théorème~\ref{THOIYmxXuu}) et nous pouvons trouver une sous-suite convergente \emph{du couple} \( (x_n,y_n)\) dans \( K\times K\). Quitte à passer à ces sous-suites, nous  nous supposons que \( (x_n,y_n)\) converge dans \( K\times K\) et en particulier que les suites $(x_n)$ et $(y_n)$ sont convergentes. Étant donné que pour chaque $n$ elles vérifient $\| x_n-y_n \|<\frac{1}{ n }$, les limites sont égales :
	\begin{equation}
		\lim x_n=\lim y_n=x.
	\end{equation}
	L'ensemble $K$ étant fermé, la limite $x$ est dans $K$. Par continuité de $f$, nous avons finalement
	\begin{equation}
		\lim f(x_n)=\lim f(y_n)=f(x),
	\end{equation}
	mais alors
	\begin{equation}
		\lim_{n\to\infty}\big| f(x_n)-f(y_n) \big|=0,
	\end{equation}
	ce qui est en contradiction avec le choix \eqref{EqCond3107fxfyepsppt}.

	Tout ceci prouve que $f(K)$ est bornée supérieurement et que $f$ atteint son supremum (qui est donc un maximum). Le fait que $f(K)$ soit borné inférieurement se prouve en considérant la fonction $-f$ au lieu de $f$.

\end{proof}

\begin{remark}
    Nous pouvons ne pas utiliser le fait que le produit de compacts est compact. Cela est particulièrement commode lorsqu'on considère des fonctions de \( \eR\) dans \( \eR\) parce que dans ce cadre nous ne pouvons pas supposer connue la notion de produit d'espace topologiques.

    Pour choisir les sous-suites \( (x_n)\) et \( (y_n)\), il suffit de prendre une sous-suite convergente de \( (x_n)\) et d'invoquer le fait que \( \| x_n-y_n \|\leq \frac{1}{ n }\). Les suites \( (x_n)\) et \( (y_n)\) étant adjacentes\footnote{Définition \ref{DEFooDMZLooDtNPmu}.}, la convergence de \( (x_n)\) implique la convergence de \( (y_n)\) vers la même limite.

    Il est donc un peu superflus de parler de la convergence du couple \( (x_n,y_n)\).
\end{remark}

\begin{proposition}[Heine\cite{ooNDDIooKLdIWH}]     \label{PROPooBWUFooYhMlDp}
    Toute application continue d'un espace métrique compact dans un espace métrique quelconque est uniformément continue.
\end{proposition}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Fonctions sur un compact}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Par le théorème des valeurs intermédiaires \ref{ThoValInter}, l'image d'un intervalle par une fonction continue est un intervalle, et nous avons l'importante propriété suivante des fonctions continues sur un compact.

Le théorème suivant est un cas particulier du théorème~\ref{ThoMKKooAbHaro}.
\begin{theorem}
    Si $f$ est une fonction continue sur l'intervalle compact $[a,b]$. Alors $f$ est bornée sur $[a,b]$ et elle atteint ses bornes.
\end{theorem}

\begin{proof}
    Étant donné que $[a,b]$ est un intervalle compact, son image est également un intervalle compact, et donc est de la forme $[m,M]$. Ceci découle du théorème~\ref{ThoImCompCotComp} et le corollaire~\ref{CorImInterInter}. Le maximum de $f$ sur $[a,b]$ est la borne $M$ qui est bien dans l'image (parce que $[m,M]$ est fermé). Idem pour le minimum $m$.
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Polynômes}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

L'algèbre des polynômes sur un anneau est définie en \ref{DefRGOooGIVzkx}. Si \( P\in A[X]\) et si \( \alpha\in A\) nous avons également défini l'évaluation de \( P\) en \( \alpha\); c'est la définition \ref{DEFooOSWQooHYYwVE}. Dans le cadre de l'analyse, lorsque nous considérons des polynômes, nous allons complètement confondre le polynôme avec la fonction qu'il définit.

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Polynômes sur les réels}
%---------------------------------------------------------------------------------------------------------------------------

\begin{proposition}     \label{PROPooJKYJooFqbQMr}
    Tout polynôme à coefficients réels de degré impair possède une racine réelle.
\end{proposition}

\begin{proof}
    Nous mettons le plus haut degré en facteur :
    \begin{equation}
        P(x)=\sum_{k=0}^na_kx^k=x^n\sum_{k=0}^n\frac{ a_k }{ x^{n-k} }.
    \end{equation}
    Le terme \( k=0\) vaut \( a_nx^n\) tandis que les autres sont de la forme (à coefficient près) \( \frac{1}{ x^l }\) pour un \( l\geq 1\). Lorsque \( x\to \infty\), chacun de ces termes s'annule (lemme \ref{LEMooFCIXooJuHFqk}). Nous avons donc
    \begin{equation}
        \lim_{x\to \infty} P(x)=+\infty,
    \end{equation}
    et de même, \( n\) étant impair, \( \lim_{x\to -\infty} P(x)=-\infty\). Le théorème des valeurs intermédiaires \ref{ThoValInter} nous donne alors l'existence d'un réel sur lequel \( P\) s'annule.
\end{proof}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Polynômes sur les complexes}
%---------------------------------------------------------------------------------------------------------------------------

Nous allons parler de comportement asymptotique de polynômes définis sur \( \eC\). La topologique que nous considérons est celle de la compactification en un point décrite en \ref{PROPooHNOZooPSzKIN}.

Le lemme suivant donne une caractérisation de la limite en l'infini dans le compactifié \( \hat \eC\). Dans beaucoup de cas, cette caractérisation est prise comme la définition de la limite. Hélas, dans le Frido nous sommes des extrémistes et nous ne parvenons pas à dire le mot «limite» si il n'y a pas une topologie.
\begin{lemma}[\cite{MonCerveau}]        \label{LEMooERABooQjLBzW}
    Nous considérons la compatification en un point d'Alexandrov\footnote{Définition \ref{PROPooHNOZooPSzKIN}.}. Soit une fonction \( f\colon \eC\to \eC\). Nous avons \( \lim_{z\to \infty} f(z)=\infty\) si et seulement si pour tout \( M>0\), il existe \( R>0\) tel que \( | z |>R\) implique \( | f(z) |>M\).
\end{lemma}

\begin{proof}
    Souvenons-nous que, en général\footnote{Définition \ref{DefYNVoWBx}.}, nous avons
    \begin{equation}
        \lim_{x\to a} f(x)=b
    \end{equation}
    si pour tout voisinage \( V\) de \( b\), il existe un voisinage \( W\) de \( a\) tel que \( z\in W\setminus\{ a \}\) implique \( f(z)\in V\).

    Précisons encore un point de notation. Si \( K\) est une partie de \( \eC\), nous notons \( K^c\) son complémentaire dans \( \eC\), pas dans \( \hat  \eC\).

    Ceci étant dit, nous passons à la preuve.
    \begin{subproof}
        \item[Sens direct]
            Nous supposons que \( \lim_{z\to \infty} f(z)=\infty\). Soit \( M>0\); nous considérons le voisinage \( V=\overline{ B(0,M) }^c\cup\{ \infty \}\). Par définition de la limite, il existe un voisinage \( W\) de \( \infty\) tel que \( z\in W\Rightarrow f(z)\in V\setminus\{ \infty \}=\overline{ B(0,M) }^c\). Ce voisinage est de la forme \( K^c\cup\{ \infty \}\). Vu que \( K\) est compact, il est borné et il existe \( R>0\) tel que \( K\subset B(0,R)\).

            Avec tout cela nous avons la chaîne suivante d'implications :
            \begin{equation}
                | z |>R\Rightarrow z\in K^c\Rightarrow z\in W\Rightarrow f(z)\in V\setminus\{ \infty \}=\overline{ B(0,M) }^c\Rightarrow | f(z) |>M.
            \end{equation}
            C'est bien la propriété que nous voulions.
        \item[Sens réciproque]
            Soit un voisinage \( V\) de \( \infty\). Nous avons \( V=K^c\cup\{ \infty \}\) où \( K\) est compact dans \( \eC\). Il existe \( M>0\) tel que \( K\subset B(0,M)\).

            Par hypothèse, il existe \( R\) tel que \( | z |>R\Rightarrow | f(z) |>M\). Soit \( W=\overline{ B(0,R) }^c\cup\{ \infty \}\). Nous avons la chaîne
            \begin{equation}
                z\in W\Rightarrow| z |>R\Rightarrow| f(z) |>M\Rightarrow f(z)\in K^c\Rightarrow f(z)\in V.
            \end{equation}
    \end{subproof}
\end{proof}

\begin{proposition}[\cite{MonCerveau}]     \label{PROPooPWVWooGuftxZ}
    Soit le polynôme
    \begin{equation}
        \begin{aligned}
            P\colon \eC&\to \eC \\
            z&\mapsto \sum_{i=0}^na_iz^i 
        \end{aligned}
    \end{equation}
    où nous sous-entendons que \( a_n\neq 0\). La fonction \( z\mapsto | P(z) |\) est équivalente\footnote{Définition \ref{DEFooWDSAooKXZsZY}.} en l'infini à la fonction
    \begin{equation}
        \begin{aligned}
            w\colon \eC&\to \eR^+ \\
            z&\mapsto | a_nz^n |. 
        \end{aligned}
    \end{equation}
\end{proposition}

\begin{proof}
    Nous voudrions prouver qu'il existe une fonction \( \alpha\colon \eC\to \eR\) telle que \( \lim_{z\to \infty} \alpha(z)=0\) et
    \begin{equation}        \label{EQooGXWZooDJZNzE}
        | \sum_{i=0}^na_iz^i |=\big( 1+\alpha(z) \big)| a_nz^n |.
    \end{equation}
    Nous trouvons une telle fonction en isolant simplement \( \alpha(z)\) de cette égalité. Nous trouvons
    \begin{equation}
        \alpha(z)=\big| \sum_{i=0}^n\frac{ a_i }{ a_n }z^{i-n} \big|-1.
    \end{equation}
    Elle vérifie immédiatement \eqref{EQooGXWZooDJZNzE}. Le point qui fait intervenir la topologie de  est de vérifier que \( \lim_{z\to \infty} \alpha(z)=0\). Le terme \( i=0\) de la somme vaut \( 1\). Il suffit donc de montrer que pour \( i\neq 0\) nous avons
    \begin{equation}
        \lim_{z\to \infty} \frac{1}{ z^{n-i} }=0.
    \end{equation}
    Soit \( \epsilon>0\). Nous devons prouver qu'il existe un voisinage \( V\) de \( \infty\) dans \( \hat \eC\) tel que
    \begin{equation}
        | \frac{1}{ z^{n-i} }-0 |\leq \epsilon
    \end{equation}
    pour tout \( z\in V\).
    
    En utilisant la proposition \ref{PROPooXLARooYSDCsF} nous avons déjà
    \begin{equation}
        | \frac{1}{ z^{n-i} } |=\frac{1}{ | z^{n-i} | }=\frac{1}{ | z |^{n-i} }.
    \end{equation}
    Soit \( R>0\) tel que \( \frac{1}{ R }<\epsilon\). Nous considérons le voisinage \( \{ | z |>R \}\cup \{ \infty \}\) de \( \infty\). Dans ce voisinage, nous avons
    \begin{equation}
        \frac{1}{ | z |^{n-i} }\leq \frac{1}{ | z | }\leq \frac{1}{ R }<\epsilon.
    \end{equation}
    Et voila.
\end{proof}

Le lemme suivant parle de polynôme sur \( \eC\). Vous pouvez l'adapter à \( \hat \eR\) et \( \bar \eR\).
\begin{lemma}       \label{LEMooYZVGooXZvBAc}
    Si \( P\colon \eC\to \eC\) est un polynôme, alors \( | P |\) atteint une borne inférieure globale.
\end{lemma}

\begin{proof}
    Nous savons, par l'équivalence prouvée dans la proposition \ref{PROPooPWVWooGuftxZ} que \( \lim_{z\to \infty} P(z)=\infty\). Soit \( a>0\) dans \( \eR\). Par le lemme \ref{LEMooERABooQjLBzW} il existe un \( R>a\) tel que \( | z |>R\Rightarrow | f(z) |>| f(a) |\).

    La fonction \( | P |\) est continue sur le compact \( \overline{ B(0,R) }\). Soit \( z_0\) le point de minimum\footnote{Théorème de Weierstrass \ref{ThoWeirstrassRn}.} de \( | P |\) sur \( \overline{ B(0,R) }\).

    Nous devons prouver que \( z_0\) donne même un minimum global. Vu que \( a\in\overline{ B(0,R) }\) nous avons
    \begin{equation}
        | f(z_0) |\leq | f(a) |.
    \end{equation}
    Si \( z\in \overline{ B(0,R) }^c\), nous avons
    \begin{equation}
        | f(z) |>| f(a) |\geq | f(z_0) |.
    \end{equation}
    Donc ce \( z_0\) est un minimum sur \( B(0,R)\) et sur \( \overline{ B(0,R) }^c\). Bref, un minimum global.
\end{proof}

\begin{lemma}       \label{LEMooTTOYooXaukuH}
    Soit le polynôme
    \begin{equation}
        \begin{aligned}
            P\colon \eC&\to \eC \\
            z&\mapsto \sum_{i=0}^na_iz^i. 
        \end{aligned}
    \end{equation}
    La fonction \( P\) est équivalente à \( a_0+a_1z\) en \( z=0\).
\end{lemma}

\begin{proof}
    En posant \( g(z)=a_0+a_1z\), nous devons trouver une fonction \( \alpha\) telle que
    \begin{equation}        \label{EQooZFJBooVAYVBv}
        P(z)=\big( 1+\alpha(z) \big)g(z).
    \end{equation}
    Si \( a_0\neq 0\), il existe un voisinage de \( z=0\) sur lequel la fonction
    \begin{equation}        \label{EQooVCOVooAKWJxF}
        \alpha(z)=\frac{ z^2\sum_{i=2}^na_iz^{i-2} }{ a_0+a_1z }
    \end{equation}
    existe. Il n'y a aucun problème à ce que \( \alpha(z)\to 0\) pour \( z\to 0\)\footnote{En remarquant toutefois que c'est une limite à deux dimensions. Sachez la définir.}, et un simple calcul\footnote{En fait, la formule \eqref{EQooVCOVooAKWJxF} est obtenue en isolant \( \alpha(z)\) dans \eqref{EQooZFJBooVAYVBv}.} donne \eqref{EQooVCOVooAKWJxF}.

    Si par contre \( a_0=0\), nous faisons le calcul intermédiaire suivant :
    \begin{equation}
        \alpha(z)g(z)=P(z)-g(z)=z^2\sum_{i=2}^na_iz^{i-2},
    \end{equation}
    et donc, en isolant \( \alpha(z)\) et en simplifiant par \( z\), nous voyons que la fonction \( \alpha\) définie par
    \begin{equation}
        \alpha(z)=\frac{z}{ a_1 }\sum_{i=2}^na_iz^{i-2}
    \end{equation}
    fonctionne.
\end{proof}

\begin{proposition}[\cite{ooRIPVooMlBiAH,MonCerveau}]       \label{PROPooLBBLooQwEiHr}
    Soient \( a,b\in \eR\).
    \begin{enumerate}
        \item       \label{ITEMooSPSWooKLtqzZ}
            L'équation \( z^2=a+bi\) a une solution dans \( \eC\).
        \item       \label{ITEMooQOJDooWjfGXv}
            Pour tout \( l\), l'équation \( z^{2^l}=a+bi\) a une solution dans \( \eC\).
    \end{enumerate}
    Nous ne disons pas que ces solutions sont uniques\footnote{Comme vous en conviendrez en pensant à \( z^2=1\) qui a déjà les solutions \( 1\) et \( -1\).}.
\end{proposition}

\begin{proof}
    Pour prouver \ref{ITEMooSPSWooKLtqzZ}, l'équation \( z^2=a+bi\) a pour solution \( \pm\xi\) où
        \begin{equation}
            \xi=\sqrt{ \frac{ 1 }{2}a+\frac{ 1 }{2}\sqrt{ a^2+b^2 } }+i\signe(b)\sqrt{ -\frac{ 1 }{2}a+\frac{ 1 }{2}\sqrt{ a^2+b^2 } }.
        \end{equation}
        Nous n'avons en fait pas besoin de montrer que \( \pm\xi\) sont toutes deux des solutions, ni que ce sont les seules. Un calcul direct montre que \( \xi^2=a+bi\) et nous sommes content.

    Pour \ref{ITEMooQOJDooWjfGXv}, nous faisons une récurrence sur \( l\). Nous savons que
        \begin{equation}
            z^{2^{k+1}}=(z^{2^k})^2.
        \end{equation}
        Soit \( \xi\in \eC\) tel que \( \xi^{2^k}=a+bi\); un tel \( \xi\) existe par hypothèse de récurrence. Alors si \( z\) est tel que \( z^2=\xi\), nous avons 
        \begin{equation}
            z^{2^{k+1}}=a+bi.
        \end{equation}
\end{proof}

Le théorème de d'Alembert possède de nombreuses démonstrations. En voici une qui à ma connaissance est celle demandant le moins d'analyse; une démonstration à base de théorie de Galois peut être trouvée dans \cite{rqrNyg,ooPSLMooAVODjn}. Si vous lisez ces lignes pour savoir qu'un polynôme de degré \( n\) possède au \emph{maximum} \( n\) racines, ce n'est pas ici qu'il faut regarder, mais le corollaire \ref{CORooUGJGooBofWLr}.
\begin{theorem}[d'Alembert\cite{ooRIPVooMlBiAH}]   \label{THOooIRJYooBiHRyW}
    Tout polynôme non constant à coefficients complexes admet au moins une racine complexe.
\end{theorem}

\begin{proof}
    Nous effectuons une preuve tout à la fois par l'absurde et par récurrence en supposant que le polynôme
    \begin{equation}
        \begin{aligned}
            f\colon \eC&\to \eC \\
            z&\mapsto z^n+a_1z^{n-1}+\ldots+a_n 
        \end{aligned}
    \end{equation}
    n'a pas de racines dans \( \eC\), et que \( n\) soit le plus petit entier pour lequel un tel polynôme existe. Nous notons
    \begin{equation}
        n=2^km
    \end{equation}
    où \( m\) est impair.

    Le lemme \ref{LEMooYZVGooXZvBAc} donne un point \( z_0\) qui réalise le minimum global de \( | f |\) sur $\eC$. Nous posons \( g(z)=f(z_0+z)\) et nous définissons ses coefficients \( A_i\) par
    \begin{equation}
        g(z)=\sum_{i=0}^nA_iz^i.
    \end{equation}
    Nous avons \( A_n=1\) et \( | A_0 |=| f(z_0) |\). Soit \( A_r\) le premier à être non nul parmi les \( A_1\), \( A_2\), \ldots.
    \begin{subproof}
        \item[Si \( r<n\)]
            Par hypothèse de récurrence, il existe \( \xi\in \eC\) tel que \( \xi^r=-A_1/A_r\). Nous avons
            \begin{equation}
                g(t\xi)=A_0+\frac{ -A_rt^rA_0 }{ A_r }+t^{r+1}\sum_{i=r+1}^nA_i\xi^it^{i-r-1}.
            \end{equation}
            En notant \( P(t)\) le dernier polynôme, nous pouvons écrire cela sous forme compacte :
            \begin{equation}
                g(t\xi)=A_0-t^rA_0+t^{r+1}P(t).
            \end{equation}
            Vu que
            \begin{equation}
                \lim_{t\to 0} \frac{ t^{r+1}P(t) }{ t^r| A_0 | }=\lim_{t\to 0} tP(t)=0,
            \end{equation}
            il existe \( t_0>0\) tel que
            \begin{equation}
                | t_0^{r+1}P(t_0) |<| A_0t_0r |.
            \end{equation}
            Nous choisissons de plus \( t_0<1\), de telle sorte que \( 1-t^r>0\). Avec cela nous avons
            \begin{equation}
                | g(t\xi) |\leq | A_0 |(1-t^r)+| t^{r+1}P(t) |=| A_0 |\underbrace{-t^r| A_0 |+| t^{r+1}P(t) |}_{<0}<| A_0 |.
            \end{equation}
            Or \( | A_0 |\) était un minimum global de \( | g |\). Contradiction.

        \item[Si \( r=n\)]

            Dans ce cas,
            \begin{equation}
                g(z)=f(z_0+z)=A_0+z^n,
            \end{equation}
            et nous rappelons que \( n=2^km\) où \( m\) est impair. Nous allons trouver une contradiction dans les quatre cas \( \real{A_0}>0\), \( \real(A_0)<0\), \( \imag(A_0)>0\) et \( \imag(A_0)<0\). Bien entendu ces cas se recouvrent largement, mais en toute généralité, nous avons besoin des quatre.
            \begin{subproof}
                \item[Si \( \real(A_0)>0\)]
                    La proposition \ref{PROPooLBBLooQwEiHr} nous permet de considérer \( v\in \eC\) tel que \( v^{2^k}=-1\). Nous avons alors
                    \begin{equation}
                        g(tv)=A_0+(tv)^n=A_0+t^n(v^{2^k})^m=A_0+t^n(-1)^m=A_0-t^n
                    \end{equation}
                    parce que \( m\) est impair. Nous avons \( \imag\big( g(tv) \big)=\imag(A_0)\). Si \( t\) est assez petit pour que \( t^n<| \real(A_0) |\) nous avons aussi \( |\real\big( g(tv) \big)|<| \real(A_0) |\). Donc
                    \begin{equation}
                        | g(tv) |^2=| \real\big( g(tv) \big) |^2+| \real\big( g(tv) \big) |^2<| \real(A_0) |^2+| \imag(A_0) |^2=| A_0 |^2.
                    \end{equation}
                    Donc \( | g(tv) |<| A_0 |\). Contradiction.
                \item[Si \( \real(A_0)<0\)]
                    Nous prenons \( v=1\), et même histoire.
                \item[Si \( \imag(A_0)<0\)]
                    Nous prenons \( w\in \eC\) tel que
                    \begin{equation}
                        w^{2^k}=i(-1)^{\frac{ 1 }{2}(m-1)}.
                    \end{equation}
                    Là, il y a un peu d'arrachage de cheveux pour bien voir les cas. La difficulté est que les puissances de \( i\) alternent entre \( 1\), \( -1\), \( i\) et \( -i\). Vu que \( m\) est impair, nous avons un \( l\) tel que \( m=2l+1\). Nous subdivisons les cas \( l\) pair et \( l\) impair.
                    \begin{subproof}
                        \item[Si \( l\) est pair]
                            Alors d'une part \( \frac{ 1 }{2}(m-1)=l\) est pair et donc 
                            \begin{equation}
                                (-1)^{\frac{ 1 }{2}(m-1)}=1.
                            \end{equation}
                            Et d'autre part, \( i^{2l+1}=(-1)^li=i\). En tout,
                            \begin{equation}
                                i^m(-1)^{\frac{ 1 }{2}(m-1)}=i.
                            \end{equation}
                        \item[Si \( l\) est impair]
                            Alors \( \frac{ 1 }{2}(m-1)=l\) et \( (-1)^{\frac{ 1 }{2}(m-1)}=-1\). Mais en même temps, \( i^{2l+1}=-i\), ce qui donne encore une fois
                            \begin{equation}
                                i^m(-1)^{\frac{ 1 }{2}(m-1)}=i.
                            \end{equation}
                    \end{subproof}
                    Bref, que \( l\) soit pair ou impair, nous avons \( i^m(-1)^{\frac{ 1 }{2}(m-1)}=i\).
            \end{subproof}
            Nous avons donc \( \real\big( g(tw) \big)=\real(A_0)\) et \( \imag\big( g(tw) \big)<\imag(A_0)\). Encore contradiction.
                \item[Si \( \imag(A_0)=0\)]
                    Même chose que ce que nous venons de faire, mais avec
                    \begin{equation}
                        w^{2^k}=-i(-1)^{\frac{ 1 }{2}(m-1)}.
                    \end{equation}
    \end{subproof}
\end{proof}

\begin{corollary}
    Le corps $\eC$ est algébriquement clos.
\end{corollary}

\begin{corollary}[\cite{MonCerveau}]       \label{CORooKKNWooWEQukb}
    Tout polynôme de degré \( 3\) à coefficients réels possède au moins une racine réelle.
\end{corollary}

\begin{proof}
    Soient les racines \( \lambda_1\), \( \lambda_2\) et \( \lambda_3\) du polynôme en question. Toutes trois sont dans \( \eC\). Supposons que \( \lambda_1\) ne soit pas réelle. Alors \( \lambda_2\) ou \( \lambda_3\) doit être égale à \( \bar\lambda_1\). Disons \( \lambda_2\). Nous avons donc les racines \( \lambda_1\), \( \bar\lambda_1\) et \( \lambda_3\). Le polynôme se factorise alors en
    \begin{equation}        \label{EQooELMMooNbpBgg}
        a(X-\lambda_1)(X-\bar\lambda_1)(X-\lambda_3).
    \end{equation}
    Le coefficient \( a\) doit être réel parce qu'il est le coefficient du terme en \( X^3\) (réel par hypothèse). Si \( \lambda_3\) n'est pas réel, alors ce polynôme ne peut pas avoir des coefficients réels. Entre autres parce que terme indépendant est \( a| \lambda_1 |^2\lambda_3\), qui est réel si et seulement si \( \lambda_3\) est réel\footnote{Notez l'utilisation du lemme~\ref{LEMooONLNooXLNbtB}.}.
\end{proof}
Tant que vous y êtes, vous pouvez voir que le polynôme \eqref{EQooELMMooNbpBgg} est à coefficient réels si et seulement si \( a\in \eR\) et \( \lambda_3\in \eR\).

\begin{example}     \label{EXooIPLOooSNfiWg}
    Toute application linéaire \( \eR^3\to \eR^3\) a un vecteur propre. En effet si \( R\colon \eR^3\to \eR^3\) est linéaire, son polynôme caractéristique \( \chi_R\) est de degré \( 3\). Le corollaire \ref{CORooKKNWooWEQukb} indique qu'un tel polynôme possède au moins une racine réelle.
    Une telle racine est une valeur propre de \( R\) par le théorème \ref{ThoWDGooQUGSTL}.
\end{example}

\begin{definition}
    Si \( \lambda\in\eK\) est une racine de \( \chi_u\), l'ordre de l'annulation est la \defe{multiplicité algébrique}{multiplicité!valeur propre!algébrique} de la valeur propre \( \lambda\) de \( u\). À ne pas confondre avec la \defe{multiplicité géométrique}{multiplicité!valeur propre!géométrique} qui sera la dimension de l'espace propre.
\end{definition}

\begin{proposition}
    Un polynôme irréductible à coefficients réels est soit de degré un soit de degré \( 2\) avec un discriminant négatif.
\end{proposition}

\begin{proof}
    Soit un polynôme \( P\) à coefficients réels de degré plus grand que \( 1\). Alors le théorème de d'Alembert-Gauss (théorème~\ref{THOooIRJYooBiHRyW}) implique l'existence d'une racine \( \alpha \in \eC \). Si $\alpha$ est un réel, $P$ est réductible. Si \( \alpha\) n'est pas réel, alors conjugué complexe \( \bar \alpha\) est également une racine. Par conséquent les polynômes \( (X-\alpha)\) et \( (X-\bar \alpha)\) divisent \( P\) dans \( \eC[X]. \).

    Ces deux polynômes sont premiers entre eux parce que
    \begin{equation}
        a(X-\alpha)+b(X-\bar \alpha)=0
    \end{equation}
    implique \( a=b=0\). Par conséquent le produit
    \begin{equation}
        X^2-(\alpha+\bar \alpha)X+\alpha\bar\alpha
    \end{equation}
    divise également \( P\). Ce dernier est un polynôme à coefficients réels de degré \( 2\). Donc tout polynôme de degré \( 3\) ou plus est réductible.
\end{proof}

\begin{proposition}     \label{PROPooLXGSooXmVcVG}
    Si \( E\) est un espace vectoriel sur \( \eC\), tout endomorphisme possède au moins une valeur propre.
\end{proposition}

\begin{proof}
    Soit un endomorphisme \( u\) sur \( E\). Le théorème \ref{ThoWDGooQUGSTL} dit que \( \lambda\in \eC\) est une valeur propre si et seulement si \( \lambda\) est une racine du polynôme caractéristique \( \chi_u\). Or ce polynôme possède au moins une racine dans \( \eC\) par le théorème de d'Alembert \ref{THOooIRJYooBiHRyW}.
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Dérivée : exemples introductifs}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%---------------------------------------------------------------------------------------------------------------------------
\subsection{La vitesse}
%---------------------------------------------------------------------------------------------------------------------------

Lorsqu'un mobile se déplace à une vitesse variable, nous obtenons la \emph{vitesse instantanée} en calculant une vitesse moyenne sur des intervalles de plus en plus petits. Si le mobile a un mouvement donné par $x(t)$, la vitesse moyenne entre $t=2$ et $t=5$ sera
\[
  v_{\text{moy}}(2\to 5)=\frac{ x(5)-x(2) }{ 5-2 }.
\]
Plus généralement, la vitesse moyenne entre $2$ et $2+\Delta t$ est donnée par
\[
  v_{\text{moy}}(2\to 2+\Delta t)=\frac{ x(2+\Delta t)-x(2) }{ \Delta t }.
\]
Cela est une fonction de $\Delta t$. Oui, mais je te rappelle qu'on a dans l'idée de calculer une vitesse instantanée, c'est-à-dire de voir ce que vaut la vitesse moyenne sur un intervalle très {\small très} {\footnotesize très} {\scriptsize très} {\tiny petit}. La notion de limite semble toute indiquée pour décrire mathématiquement l'idée physique de vitesse instantanée.

Nous allons dire que la vitesse instantanée d'un mobile est la limite quand $\Delta t$ tend vers zéro de sa vitesse moyenne sur l'intervalle de temps $\Delta t$, ou en formule :
\begin{equation}		\label{Eqvinstlimite}
	v(t_0)=\lim_{\Delta t\to 0}\frac{ x(t_0)-x(t_0+\Delta t) }{ \Delta t }.
\end{equation}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{La tangente à une courbe}
%---------------------------------------------------------------------------------------------------------------------------

Passons maintenant à tout autre chose, mais toujours dans l'utilisation de la notion de limite pour résoudre des problèmes intéressants. Comment trouver l'équation de la tangente à la courbe $y=f(x)$ au point $(x_0,f(x_0))$ ?

Essayons de trouver la tangente au point $P$ donné de la courbe donnée à la figure~\ref{LabelFigTangenteQuestion}.

\newcommand{\CaptionFigTangenteQuestion}{Comment trouver la tangente à la courbe au point $P$ ?}
\input{auto/pictures_tex/Fig_TangenteQuestion.pstricks}

La tangente est la droite qui touche la courbe en un seul point sans la traverser. Afin de la construire, nous allons dessiner des droites qui touchent la courbe en $P$ et un autre point $Q$, et nous allons voir ce qu'il se passe quand $Q$ est très proche de $P$. Cela donnera une droite qui, certes, touchera la courbe en deux points, mais en deux points \emph{tellement proches que c'est comme si c'étaient les mêmes}. Tu sens que la notion de limite va encore venir.

%Pour rappel cette figure TangenteDetail est générée par phystricksRechercheTangente.py
\newcommand{\CaptionFigTangenteDetail}{Traçons d'abord une corde entre le point $P$ et un point $Q$ un peu plus loin.}
\input{auto/pictures_tex/Fig_TangenteDetail.pstricks}

Nous avons placé le point, sur la figure~\ref{LabelFigTangenteDetail}, le point $P$ en $a$ et le point $Q$ un peu plus loin $x$. En d'autres termes leurs coordonnées sont
\begin{align}
	P=\big(a,f(a)\big)&& Q=\big(x,f(x)\big).
\end{align}
Comme tu devrais le savoir sans même regarder la figure~\ref{LabelFigTangenteDetail}, le coefficient directeur de la droite qui passe par ces deux points est donné par
\begin{equation}
	\frac{ f(x)-f(a) }{ x-a },
\end{equation}
et bang ! Encore le même rapport que celui qu'on avait trouvé à l'équation \eqref{Eqvinstlimite} en parlant de vitesses. Si tu regardes la figure~\ref{LabelFigLesSubFigures}, tu verras que réellement en faisant tendre $x$ vers $a$ on obtient la tangente.

\newcommand{\CaptionFigLesSubFigures}{Recherche de la tangente par approximations successives.}
\input{auto/pictures_tex/Fig_LesSubFigures.pstricks}
%See also the subfigure~\ref{LabelFigLesSubFiguressssubZ}
%See also the subfigure~\ref{LabelFigLesSubFiguressssubO}
%See also the subfigure~\ref{LabelFigLesSubFiguressssubT}
%See also the subfigure~\ref{LabelFigLesSubFiguressssubTh}
%See also the subfigure~\ref{LabelFigLesSubFiguressssubF}
%See also the subfigure~\ref{LabelFigLesSubFiguressssubFi}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{L'aire en dessous d'une courbe}		\label{SubSecAirePrimInto}
%---------------------------------------------------------------------------------------------------------------------------

Encore un exemple. Nous voudrions bien pouvoir calculer l'aire en dessous d'une courbe. Nous notons $S_f(x)$ l'aire en dessous de la fonction $f$ entre l'abscisse $0$ et $x$, c'est-à-dire l'aire bleue de la figure~\ref{LabelFigNOCGooYRHLCn}. % From file NOCGooYRHLCn
\newcommand{\CaptionFigNOCGooYRHLCn}{L'aire en dessous d'une courbe. Le rectangle rouge d'aire $f(x)\Delta x$ approxime l'augmentation de l'aire lorsqu'on passe de $x$ à $x+\Delta x$.}
\input{auto/pictures_tex/Fig_NOCGooYRHLCn.pstricks}

Si la fonction $f$ est continue et que $\Delta x$ est assez petit, la fonction ne varie pas beaucoup entre $x$ et $x+\Delta x$. L'augmentation de surface entre $x$ et $x+\Delta x$ peut donc être approximée par le rectangle de surface $f(x)\Delta x$. Ce que nous avons donc, c'est que quand $\Delta x$ est très petit,
\begin{equation}
	S_f(x+\Delta x)-S_f(x)=f(x)\Delta x,
\end{equation}
c'est-à-dire
\begin{equation}
	f(x)=\lim_{\Delta x\to 0}\frac{  S_f(x+\Delta x)-S_f(x)}{ \Delta x }.
\end{equation}
Donc, la fonction $f$ est la dérivée de la fonction qui représente l'aire en dessous de $f$. Calculer des surfaces revient donc au travail inverse de calculer des dérivées.

Nous avons déjà vu que calculer la dérivée d'une fonction n'est pas très compliqué. Aussi étonnant que cela puisse paraitre, il se fait que le processus inverse est très compliqué : il est en général extrêmement difficile (et même souvent impossible) de trouver une fonction dont la dérivée est une fonction donnée.

Une fonction dont la dérivée est la fonction $f$ s'appelle une \defe{primitive}{primitive} de $f$, et la fonction qui donne l'aire en dessous de la fonction $f$ entre l'abscisse $0$ et $x$ est notée
\begin{equation}
	S_f(x)=\int_0^xf(t)dt.
\end{equation}
Nous pouvons nous demander si, pour une fonction $f$ donnée, il existe une ou plusieurs primitives, c'est-à-dire s'il existe une ou plusieurs fonctions $F$ telles que $F'=f$. La réponse viendra\ldots
%TODO : faire la référence

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Dérivation de fonctions réelles}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\label{seccontetderiv}

On considère dans la suite une fonction $f : A \to \eR$, où $a \in A \subset \eR$ ; cependant, les notions de continuité et de dérivabilité se généralisent immédiatement au cas de fonctions à valeurs vectorielles ; la notion de continuité se généralise au cas des fonctions à plusieurs variables (la notion de dérivabilité est remplacée par celle de différentiabilité dans ce cadre).

\begin{definition}      \label{DEFooOYFZooFWmcAB}
    La fonction $f$ est \defe{dérivable}{dérivable} en \( a\) si $a \in
  \operatorname{int} A$ et si
  \begin{equation*}
    \lim_{x\to a} \frac{f(x)-f(a)}{x-a}
  \end{equation*}
  existe. On note alors cette quantité $f'(a)$, c'est le nombre
  dérivé de $f$ en $a$. La \defe{fonction dérivée}{fonction dérivée} de $f$ est
  \begin{equation}
      \begin{aligned}
          f'\colon A'&\to \eR \\
          a&\mapsto f(a)
      \end{aligned}
  \end{equation}
  définie sur l'ensemble noté $A'$ des points $a$ où $f$ est dérivable.
\end{definition}

\begin{example}
      Montrons que la fonction $f : \eR \to \eR : x\mapsto x$ est continue et dérivable. Exceptionnellement (bien qu'on sache que la dérivabilité implique la continuité), montrons ces deux assertions séparément.
      \begin{description}
      \item[Continuité] Pour prouver la continuité au point $a \in \eR$ nous devons montrer que
     \begin{equation}
       \limite x a x = a
     \end{equation}
     c'est-à-dire
     \begin{equation}
       \forall \epsilon > 0, \exists \delta > 0 :  \forall x \in \eR \abs{x-a} <
       \delta \Rightarrow \abs{x-a} < \epsilon
     \end{equation}
     ce qui est clair en prenant $\delta = \epsilon$.

      \item[Dérivabilité] Soit $a \in \eR$. Calculons la limite du quotient différentiel
        \begin{equation}
          \limite[x\neq a]{x}{a} \frac{x-a}{x-a} = \limite[x\neq a]x a 1 = 1
        \end{equation}
        ce qui prouve que $f$ est dérivable et que sa dérivée vaut $1$ en
        tout point $a$ de $\eR$.
      \end{description}

     On a donc montré que la fonction $x \mapsto x$ est continue, dérivable, et que sa dérivée vaut $1$ en tout point $a$ de son domaine.

\end{example}

\begin{proposition} \label{PropSFyxOWF}
    Une fonction dérivable sur un intervalle est continue sur cet intervalle.
\end{proposition}

\begin{proof}
    Soit \( I\) un intervalle sur lequel la fonction \( f\) est dérivable, et soit \( x_0\in I\). Nous allons prouver la continuité de \( f\) en \( x_0\). Le fait que la limite
    \begin{equation}
        f'(x_0)=\lim_{h\to 0} \frac{ f(x_0+h)-f(x_0) }{ h }
    \end{equation}
    existe implique a fortiori que
    \begin{equation}
        \lim_{h\to 0} f(x_0+h)-f(x_0)=0.
    \end{equation}
    Cela signifie la continuité de \( f\) en vertu du critère~\ref{ThoLimCont}.
\end{proof}

\begin{theorem} \label{THOooFFOZooCYGets}
  Toute fonction dérivable en un point est continue en ce point.
\end{theorem}

\begin{proof}
    Soient \( f\colon \eR\to \eR\) et \( a\in \eR\). Nous supposons que \( f\) n'est pas continue en \( a\) et nous allons en déduire qu'elle n'est pas non plus dérivable en \( a\). Pour cela nous considérons le lien entre limite et continuité donné dans le théorème \ref{ThoLimCont}. Nier que \( f\) est continue en \( a\) revient à dire qu'il existe un voisinage \( V\) de \( f(a)\) tel que
    \begin{equation}
        \forall r>0,\,\exists \epsilon<r \tq f(a+\epsilon)\notin V.
    \end{equation}
    Si \( B\big( f(a),R \big)\subset V\)\footnote{Existence par la définition de la topologie métrique \ref{ThoORdLYUu}.}, et si \( r=1/n\), nous construisons une suite \( \epsilon_n\to 0\) telle que
    \begin{equation}
        | f(a+\epsilon_n)-f(a) |>R.
    \end{equation}
    Avec cela nous avons
    \begin{equation}
        \frac{ | f(a+\epsilon_n)-f(a) | }{ \epsilon_n }>\frac{ R }{ \epsilon_n }\to \infty.
    \end{equation}
    Donc la fonction \( f\) ne peut pas être dérivable en \( a\).
\end{proof}

\begin{remark}
     La réciproque du théorème précédent n'est pas vraie : il existent bien des fonctions qui sont continues à un point $x_0$ mais qui ne sont pas dérivables en $x_0$. La fonction valeur absolue, $x\mapsto |x|$, par exemple est continue sur tout $\eR$ mais elle n'est pas dérivable en $0$.
\end{remark}

Si \( f\) est une fonction dérivable, il peut arriver que la fonction dérivée \( f'\) soit elle-même dérivable. Dans ce cas nous notons \( f''\) ou \( f^{(2)}\) la dérivée de la fonction \( f'\). Cette fonction $f''$ est la \defe{dérivée seconde}{dérivée!seconde} de \( f\). Elle peut encore être dérivable; dans ce cas nous notons \( f^{(3)}\) sa dérivée, et ainsi de suite. Nous définissons \( f^{(n)}=(f^{(n-1)})'\) la dérivée \( n\)\ieme de \( f\). Nous posons évidemment $f^{(0)}=f$.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Exemples}
%---------------------------------------------------------------------------------------------------------------------------

\begin{example}
    Commençons par la fonction $f(x)=x$. Dans ce cas nous avons
    \begin{equation}
        \frac{ f(x)-f(a) }{ x-a }=\frac{ x-a }{ x-a }=1.
    \end{equation}
    La dérivée est donc $1$.
\end{example}

\begin{proposition}
    La dérivé de la fonction $x\mapsto x$ vaut $1$, en notations compactes : $(x)'=1$.
\end{proposition}

\begin{proof}
    D'après la définition de la dérivée, si $f(x)=x$, nous avons
    \begin{equation}
        f(x)=\lim_{\epsilon\to 0}\frac{ (x+\epsilon) -x }{\epsilon} =\lim_{\epsilon\to 0}\frac{ \epsilon }{\epsilon} =1,
    \end{equation}
    et c'est déjà fini.
\end{proof}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{La fonction carré}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Prenons ensuite $f(x)=x^2$. En utilisant le produit remarquable $(x^2-a^2)=(x-a)(x+a)$ nous trouvons
\begin{equation}
	\frac{ f(x)-f(a) }{ x-a }=x+a.
\end{equation}
Lorsque $x\to a$, cela devient $2a$. Nous avons par conséquent
\begin{equation}
	f'(x)=2x.
\end{equation}

\begin{lemma}           \label{LemDeccCarr}
    Si $f(x)=x^2$, alors $f'(x)=2x$.
\end{lemma}

\begin{proof}
    Utilisons la définition, et remplaçons $f$ par sa valeur :
    \begin{subequations}
        \begin{align}
            f'(x)   &=\lim_{\epsilon\to 0}\frac{ f(x+\epsilon)-f(x) }{ \epsilon }\\
                &=\lim_{\epsilon\to 0}\frac{ (x+\epsilon)^2-x^2 }{ \epsilon }\\
                &=\lim_{\epsilon\to 0}\frac{ x^2+2x\epsilon+\epsilon^2-x^2 }{ \epsilon }\\
                &=\lim_{\epsilon\to 0}\frac{\epsilon(2x+\epsilon)}{ \epsilon }\\
                &=\lim_{\epsilon\to 0}(2x+\epsilon)\\
                &=2x,
        \end{align}
    \end{subequations}
    ce qu'il fallait prouver.
\end{proof}


%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{La fonction racine carré}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Considérons maintenant la fonction $f(x)=\sqrt{x}$. Nous avons
\begin{equation}
	\begin{aligned}[]
		\frac{ f(x)-f(a) }{ x-a }&=\frac{ \sqrt{x}-\sqrt{a} }{ x-a }\\
		&=\frac{ (\sqrt{x}-\sqrt{a})(\sqrt{x}+\sqrt{x}) }{ (x-a)(\sqrt{x}+\sqrt{x}) }\\
		&=\frac{1}{ \sqrt{x}+\sqrt{x} }.
	\end{aligned}
\end{equation}
Lorsque $x\to 0$, nous obtenons
\begin{equation}
	f'(a)=\frac{1}{ 2\sqrt{a} }.
\end{equation}
Notons que la dérivée de $f(x)=\sqrt{x}$ n'existe pas en $x=0$. En effet elle serait donnée par le quotient
\begin{equation}
	f'(0)=\lim_{x\to 0} \frac{ \sqrt{x}-\sqrt{0} }{ x }=\lim_{x\to 0} \frac{ \sqrt{x} }{ x }=\lim_{x\to 0} \frac{1}{ \sqrt{x} }.
\end{equation}
Mais si $x$ devient très petit, la dernière fraction tend vers l'infini.

%--------------------------------------------------------------------------------------------------------------------------
\subsection[Interprétation géométrique : tangente]{Interprétation géométrique de la dérivée : tangente}
%--------------------------------------------------------------------------------------------------------------------------

Considérons le \defe{graphe}{graphe} de la fonction $f$ sur $I$, c'est-à-dire l'ensemble
\begin{equation}
	\big\{ \big( x,f(x) \big)\tq x\in I \big\}.
\end{equation}
Le nombre
\begin{equation}
	\frac{ f(x)-f(a) }{ x-a }
\end{equation}
est la pente de la droite qui joint les points $\big( x,f(x) \big)$ et $\big( a,f(a) \big)$, voir la figure ~\ref{LabelFigGWOYooRxHKSm}. % From file GWOYooRxHKSm
\newcommand{\CaptionFigGWOYooRxHKSm}{Le coefficient directeur de la corde entre $a$ et $x$.}
\input{auto/pictures_tex/Fig_GWOYooRxHKSm.pstricks}

Étant donné que $f'(a)$ est le coefficient directeur de la tangente au point $\big( a,f(a) \big)$, l'équation de la tangente est
\begin{equation}		\label{EqTgfaen}
	y-f(a)=f'(a)(x-a).
\end{equation}

%--------------------------------------------------------------------------------------------------------------------------
\subsection[Interprétation géométrique : approximation affine]{Interprétation géométrique de la dérivée : approximation affine}
%--------------------------------------------------------------------------------------------------------------------------

Le fait que la fonction $f$ soit dérivable au point $a\in I$ signifie que
\begin{equation}
	\lim_{x\to a} \frac{ f(x)-f(a) }{ x-a }=\ell
\end{equation}
pour un certain nombre $\ell$. Cela peut être récrit sous la forme
\begin{equation}
	\lim_{x\to a} \frac{ f(x)-f(a) }{ x-a }-\ell=0,
\end{equation}
ou encore
\begin{equation}
	\lim_{x\to a} \frac{ f(x)-f(a)-\ell(x-a) }{ x-a }=0.
\end{equation}
Introduisons la fonction
\begin{equation}
	\alpha(t)=\frac{ f(a+t)-f(a)-t\ell }{ t }.
\end{equation}
Cette fonction est faite exprès pour que
\begin{equation}		\label{EqIntermsaxaama}
	\alpha(x-a)=\frac{ f(x)-f(a)-\ell(x-a) }{ x-a };
\end{equation}
par conséquent $\lim_{x\to a} \alpha(x-a)=0$. Nous récrivons l'équation \eqref{EqIntermsaxaama} sous la forme
\begin{equation}        \label{EqCodeDerviffxam}
	f(x)-f(a)-\ell(x-a)=(x-a)\alpha(x-a).
\end{equation}
Le second membre tend vers zéro lorsque $x$ tend vers $a$ avec une «vitesse au carré» : c'est le produit de deux facteurs tous deux tendant vers zéro. Si $x$ n'est pas très loin de $a$, il n'est donc pas une mauvaise approximation de dire
\begin{equation}
	f(x)-f(a)-\ell(x-a)\simeq 0,
\end{equation}
c'est-à-dire
\begin{equation}		\label{Eqfxsimesfa}
	f(x)\simeq f(a)+f'(a)(x-a).
\end{equation}
Nous avons retrouvé l'équation \eqref{EqTgfaen}. La manipulation que nous venons de faire revient donc à dire que la fonction $f$, au voisinage de $a$, est bien approximée par sa tangente.

L'équation \eqref{Eqfxsimesfa} peut être aussi écrite sous la forme
\begin{equation}		\label{EqfxdxSimeqfxfpx}
	f(x+\Delta x)\simeq f(x)+f'(x)\Delta x
\end{equation}
qui est une approximation d'autant meilleure que $\Delta x$ est petit.

\begin{proposition}[\cite{ooAAFGooXRSaWs}]      \label{PROPooSGTBooFxUuXK}
    Soit \(f \) une fonction dérivable et strictement monotone de l'intervalle \( I\) sur l'intervalle \( J\)  (f est alors une bijection de $I$ vers $J$). Si  ne s'annule par sur  alors
    \begin{enumerate}
        \item
            la fonction \( f\) est une bijection de \( I\) vers \( J\),
        \item
            la fonction \( f^{-1}\) est dérivable sur \( J\),
        \item
            et nous avons la formule
            \begin{equation}        \label{EQooELIHooDxUFxH}
                (f^{-1})'=\frac{1}{ f'\circ f^{-1} }.
            \end{equation}
    \end{enumerate}
\end{proposition}
\index{réciproque!dérivabilité}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Développement limité au premier ordre}
%---------------------------------------------------------------------------------------------------------------------------

Si une fonction est dérivable en \( a\) alors elle peut être approximée «au premier ordre» par une formule simple qui sera généralisé pour des dérivées d'ordre supérieurs avec les séries de Taylor, théorème~\ref{ThoTaylor}.
\begin{proposition}[Développement limité au premier ordre]  \label{PropUTenzfQ}
    Si \( f\colon \eR\to \eR\) est une fonction dérivable, alors is existe une fonction \( \alpha\colon \eR\to \eR\) telle que
    \begin{equation}
        f(a+h)=f(a)+hf'(a)+\alpha(h)
    \end{equation}
    et
    \begin{equation}
        \lim_{h\to 0} \frac{ \alpha(h) }{ h }=0.
    \end{equation}
\end{proposition}
\index{développement!limité!premier ordre}

\begin{proof}
    La fonction \( f\) étant dérivable en \( a\) nous avons l'existence de la limite suivante :
    \begin{equation}
        f'(a)=\lim_{h\to 0} \frac{ f(a+h)-f(a) }{ h },
    \end{equation}
    ce qui revient à dire qu'en définissant la fonction \( \beta\) par
    \begin{equation}
        f'(a)=\frac{ f(a+h)-f(a) }{ h }+\beta(h)
    \end{equation}
    alors \( \beta(h)\to 0\) lorsque \( h\to 0\). En multipliant par \( h\) et en nommant \( \alpha(h)=h\beta(h)\) nous trouvons le résultat :
    \begin{equation}
        f(a+h)=f(a)+hf'(a)+\alpha(h)
    \end{equation}
    avec
    \begin{equation}
        \lim_{h\to 0} \frac{ \alpha(h) }{ h }=\lim_{h\to 0} \beta(h)=0.
    \end{equation}
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Règles de calcul}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

D'abord une dérivée facile, qui sera utile pour démontrer la formule de dérivation d'un quotient.
\begin{lemma}
    Nous avons :
    \begin{equation}
        \left( \frac{1}{ x } \right)'=-\frac{1}{ x^2 }.
    \end{equation}
\end{lemma}

\begin{proof}
    En posant \( f(x)=1/x\), nous avons le calcul
    \begin{equation}
        \frac{ f(x+\epsilon)-f(x) }{ \epsilon }=\frac{ \frac{1}{ x+\epsilon }-\frac{1}{ x } }{ \epsilon }=\frac{ x-(x+\epsilon) }{ \epsilon x(x+\epsilon) }=\frac{ -1 }{ x(x+\epsilon) }.
    \end{equation}
    Nous trouvons le résultat en passant à la limite et en tenant compte de la proposition \ref{PROPooOUPNooTrClHw} sur la limite d'un quotient.
\end{proof}


\begin{proposition}[\cite{ooRCDWooONrayj,ooVNAOooAuQSse,ooOGGJooCGQgDO}]     \label{PROPooOUZOooEcYKxn}
    Nous avons les règles suivantes.
    \begin{enumerate}
        \item       \label{ITEMooTFNPooYngHnD}
            Si \( f,g\colon \eR\to \eR\) sont dérivables en \( a\in \eR\), alors \( f+g\) est dérivable en \( a\) et
            \begin{equation}
                (f+g)'(a)=f'(a)+g'(a).
            \end{equation}
        \item       \label{ITEMooIPLRooOZXqMg}
            Si \( f\colon \eR\to \eR\) est dérivable en \( a\in \eR\) et si \( \lambda\in \eR\), alors \( (\lambda f)\) est dérivable en \( a\) et 
            \begin{equation}
                (\lambda f)'(a)=\lambda f'(a).
            \end{equation}
        \item   \label{ITEMooMQERooBCqnvS}
            Si \( f,g\colon \eR\to \eR\) sont dérivables en \( a\in \eR\), alors \( fg\) est dérivable en \( a\) et
    		\begin{equation}
    			(fg)'(a)=f'(a)g(a)+f(a)g'(a).
    		\end{equation}
    		Cette formule est appelée \defe{règle de Leibnitz}{Leibnitz}.
        \item   \label{ITEMooLYZCooVUPTyh}
            Soient deux intervalles \( I,J\) dans \( \eR\). Soient des fonctions \( f\colon I\to J\) et \( g\colon J\to \eR\). Soit encore \( a\in I\). SI \( f\) est dérivable en \( a\) et si \( g\) est dérivable en \( f(a)\), alors \( g\circ f\) est dérivable en \( a\) et
            \begin{equation}
                (g\circ f)'(a)= g'\big( f(a) \big)f'(a).
            \end{equation}
        \item      \label{ITEMooMUNQooLiKffz}
            Soient \( f,g\colon I\to \eR\) des fonction sur un intervalle ouvert \( I\). Soit \( a\in I\); supposons que \( g(a)\neq 0\). Alors la fonction \( \frac{ f }{ g }\) est dérivable en \( a\) et
            \begin{equation}
                \left( \frac{ f }{ g } \right)'(a)=\frac{ f'(a)g(a)-f(a)g'(a) }{ g(a)^2 }.
            \end{equation}
    \end{enumerate}
    En particulier, la dérivation est une opération linéaire sur l'espace des fonctions infiniement dérivables.
\end{proposition}

\begin{proof}
    Point par point.
    \begin{subproof}
        \item[Pour \ref{ITEMooTFNPooYngHnD}]
        \item[Pour \ref{ITEMooIPLRooOZXqMg}]
            Écrivons la définition de la dérivée avec $(\lambda f)$ au lieu de $f$, et calculons un petit peu :
            \begin{subequations}
                \begin{align}
                    (\lambda f)'(x) &=\lim_{\epsilon\to 0}\frac{ (\lambda f)(x+\epsilon)-(\lambda f)(x) }{ \epsilon }\\
                            &=\lim_{\epsilon\to 0}\frac{ \lambda \big( f(x+\epsilon) \big)-\lambda f(x) }{ \epsilon }\\
                            &=\lim_{\epsilon\to 0}\lambda \frac{ f(x+\epsilon) -f(x) }{ \epsilon }\\
                            &=\lambda \lim_{\epsilon\to 0}\frac{ f(x+\epsilon) -f(x) }{ \epsilon }\\
                            &=\lambda f'(x).
                \end{align}
            \end{subequations}
        \item[Pour \ref{ITEMooMQERooBCqnvS}, règle de Leibnitz]

            La définition de la dérivée dit que
            \begin{equation}        \label{Eqfgrimeepsfgx}
                (fg)'(x)=\lim_{\epsilon\to 0}\frac{f(x+\epsilon)g(x+\epsilon)-f(x)g(x)}{\epsilon}.
            \end{equation}
            La subtilité est d'ajouter au numérateur la quantité $-f(x)g(x+\epsilon)+f(x)g(x+\epsilon)$, ce qui est permis parce que cette quantité est nulle\footnote{Nous avons déjà faut le coup d'ajouter et enlever la même chose durant la démonstration du théorème~\ref{Tholimfgabab}. C'est une technique assez courante en analyse.}. Le numérateur de \eqref{Eqfgrimeepsfgx} devient donc
            \begin{equation}
                \begin{aligned}[]
            f(x+\epsilon)g(x+\epsilon)&-f(x)g(x+\epsilon)+f(x)g(x+\epsilon)-f(x)g(x) \\
                        &= g(x+\epsilon)\big( f(x+\epsilon)-f(x) \big)+f(x)\big( g(x+\epsilon)-g(x) \big),
                \end{aligned}
            \end{equation}
            où nous avons effectué deux mises en évidence. Étant donné que nous avons deux termes, nous pouvons couper la limite en deux :
            \begin{equation}
                \begin{aligned}[]
                    (fg)'(x)    &=\lim_{\epsilon\to 0}g(x+\epsilon)\frac{ f(x+\epsilon)-f(x) }{\epsilon}            &+\lim_{\epsilon\to 0}f(x)\frac{ g(x+\epsilon)-g(x) }{\epsilon}\\
                            &=\lim_{\epsilon\to 0}g(x+\epsilon)\lim_{\epsilon\to 0}\frac{ f(x+\epsilon)-f(x) }{\epsilon}    &+f(x)\lim_{\epsilon\to 0}\frac{ g(x+\epsilon)-g(x) }{\epsilon},
                \end{aligned}
            \end{equation}
            où nous avons utilisé le théorème~\ref{Tholimfgabab} pour scinder la première limite en deux, ainsi que la propriété \eqref{Eqbutmultlim} pour sortir le $f(x)$ de la limite dans le second terme. Maintenant, dans le premier terme, nous avons évidemment\footnote{Pas tout à fait évidemment : selon le théorème~\ref{ThoLimCont}, \emph{limite et continuité}, il faut que $g$ soit continue.} $\lim_{\epsilon\to 0}g(x+\epsilon)=g(x)$. Les limites qui restent sont les définitions classiques des dérivées de $f$ et $g$ au point~$x$ :
            \begin{equation}
                (fg)'(x)=g(x)f'(x)-f(x)g'(x),
            \end{equation}
            ce qu'il fallait démontrer.

        \item[Pour \ref{ITEMooLYZCooVUPTyh}]
            Nous posons \( b=f(a)\) et nous considérons la fonction suivante :
            \begin{equation}
                \begin{aligned}
                    u\colon J&\to \eR \\
                    y&\mapsto u(y)=\begin{cases}
                        \frac{ g(y)-g(b) }{ y-b }    &   \text{si } y\neq b\\
                        g'(b)    &    \text{si } y=b.
                    \end{cases}
                \end{aligned}
            \end{equation}
            Vu que \( g\) est dérivable en \( b\), la seconde ligne existe et \( u\) est continue en \( y=b=f(a)\). C'est la définition de la dérivée. 

            Mais \( f\) est continue en \( a\), donc \( u\circ f\) est également continue en \( a\), et nous avons
            \begin{equation}
                \lim_{x\to a} (u\circ f)(x)=u\big( f(a) \big)=u(b)=g'(b).
            \end{equation}
            En récrivant la définition de \( u\) en \( f(x)\), l'expression suivante est une fonction continue de \( x\) :
            \begin{equation}
                u\big( f(x) \big)=\begin{cases}
                    \frac{ g\big( f(x) \big)-g(b) }{ f(x)-b }    &   \text{si } f(x)\neq b\\
                    g'(b)    &    \text{si } y=b.
                \end{cases}
            \end{equation}
            Si \( f(x)\neq b\) nous avons :
            \begin{equation}        \label{EQooKHQZooJdbmlT}
                g\big( f(x) \big)-g(b)=u\big( f(x) \big)\big( f(x)-b \big).
            \end{equation}
            Si par contre \( f(x)=b\), en réalité, l'égalité \eqref{EQooKHQZooJdbmlT} est encore valable parce qu'elle se résume à \( 0=0\). Nous divisons par \( x-a\) et nous avons l'égalité
            \begin{equation}
                \frac{ g\big( f(x) \big)-f\big( f(a) \big) }{ x-a }=u\big( f(x) \big)\frac{ f(x)-f(a) }{ x-a }
            \end{equation}
            qui est valable sur \( I\setminus\{ a \}\).

            Il ne s'agit pas maintenant de prendre la limite \( x\to a\) des deux côtés, parce que la limite du membre de gauche est précisément ce que ce théorème s'efforce de prouver exister. Nous montrons que la limite du membre de gauche existe en montrant que celle de droite existe. 
            
            D'une part, \( u\circ f\) est continue et
            \begin{equation}
                \lim_{x\to a} u\big( f(x) \big)=u\big( f(a) \big)=u(b)=g'(b).
            \end{equation}
            D'autre par, \( f\) est dérivable en \( a\), donc
            \begin{equation}
                \lim_{x\to a} \frac{ f(x)-f(a) }{ x-a }=f'(a).
            \end{equation}
            Tout cela pour dire qu'à droite, la limite existe et vaut \( g'(b)f'(a)\). Donc nous avons l'existence de la limite que nous définissant \( (g\circ f)'(a)\), et la valeur
            \begin{equation}
                \lim_{x\to a} \frac{ g\big( f(x) \big)-f\big( f(a) \big) }{ x-a }= g'\big( f(a) \big)f'(a).
            \end{equation}
            Le résultat est prouvé.
        \item[Pour \ref{ITEMooMUNQooLiKffz}]
            Nous considérons la fonction
            \begin{equation}
                \begin{aligned}
                    i\colon \eR\setminus\{ 0 \}&\to \eR \\
                    x&\mapsto \frac{1}{ x }. 
                \end{aligned}
            \end{equation}
            La fonction \( g\) est dérivable en \( a\), la fonction \( i\) est dérivable en \( g(a)\). Donc par le théorème de dérivation des fonctions composées\footnote{Proposition \ref{PROPooOUZOooEcYKxn}\ref{ITEMooLYZCooVUPTyh}.}, la fonction \( i\circ f\) est dérivable en \( a\) et
            \begin{equation}
                (i\circ g)'(a)=i'\big( g(a) \big)g'(a)=-\frac{ g'(a) }{ g(a)^2 }.
            \end{equation}
            
            Pour le quotient, nous utilisons la formule de la dérivée du produit sur \( \frac{ f }{ g }(x)=f(x)\frac{1}{ g(x) } \) pour dire que \( f/g\) est dérivable en \( a\) et
            \begin{equation}
                    \left( \frac{ f }{ g } \right)'(a)=f'(a)\frac{1}{ g(a) }+f(a)\left( \frac{1}{ g } \right)'(a)
                    =\frac{ f'(a) }{ g(a) }-\frac{ f(a)g'(a) }{ g(a)^2 }
                    =\frac{ f'(a)g(a)-f(a)g'(a) }{ g(a)^2 },
            \end{equation}
            ce qu'il fallait démontrer.
    \end{subproof}
\end{proof}

\begin{remark}
    Nous ne pouvons pas dire que la dérivée est une opération linéaire sur l'espace des fonctions dérivables. Certes la proposition \ref{PROPooOUZOooEcYKxn} implique entre autres que l'ensemble des fonctions dérivables est un espace vectoriel. Mais la dérivée d'une fonction dérivable n'est pas spécialement dérivable.
\end{remark}

\begin{remark}
    La formule \( (1/u)'=-u'/u^2\) ne peut pas être vue comme un cas particulier de \( (u^{\alpha})'=\alpha u^{\alpha-1}\) (proposition \ref{PROPooSGLGooIgzque}) parce que cette formule est utilisée dans la démonstration de la formule générale.
\end{remark}


Pour les fonctions à valeurs dant \( \eR^n\), nous posons la définition suivante.
\begin{definition}
    Soit une fonction \( f\colon \eR\to \eR^n\) dont les composantes \( f_i\colon \eR\to \eR\) sont dérivables. Nous définissons la fonction \( f'\) par
    \begin{equation}
        f'(x)=\sum_if'_i(x)e_i,
    \end{equation}
    c'est-à-dire une dérivation composante par composante.
\end{definition}

Cette définition est celle pour une fonction \( \eR\to \eR^n\), et elles est facile. Très différente est la situation d'une fonction \( \eR^n\to \eR\) dans laquelle il faudra introduire la notion de différentielle\footnote{Ce sera pour la définition \ref{DefDifferentiellePta}.}.

Par rapport à la dérivation, les produits scalaire et vectoriel vérifient une règle de Leibnitz. 
\begin{proposition}     \label{PROPooFKKHooQZGXhE}
    Soit $I$ un intervalle de $\eR$. Si $u$ et $u$ sont dans $C^1(I,\eR^3)$, alors
    \begin{equation}		\label{EqFormLeibProdscalVect}
        \begin{aligned}[]
            \frac{ d }{ dt }\big( u(t)\cdot v(t) \big)&=\big( u'(t)\cdot v(t) \big)+\big( u(t)\cdot v'(t) \big)\\
            \frac{ d }{ dt }\big( u(t)\times v(t) \big)&=\big( u'(t)\times v(t) \big)+\big( u(t)\times v'(t) \big).
        \end{aligned}
    \end{equation}
\end{proposition}

Nous faisons la preuve pour le produit scalaire; sans doute que le produit vectoriel sera la même chose.
\begin{proof}
    Nous considérons des fonctions dérivables \( f,g\colon \eR\to \eR^3\), et nous posons \( \varphi(t)=f(t)\cdot g(t)\). En ce qui concerne la dérivée de la fonction \( f\cdot g\colon \eR\to \eR\), nous devons étudier la limite
    \begin{equation}        \label{EQooGRFKooNHceiW}
        \lim_{\epsilon\to 0}\frac{ \varphi(t+\epsilon)-\varphi(t) }{ \epsilon }=\lim_{\epsilon\to 0}\frac{ f(t+\epsilon)\cdot g(t+\epsilon)-f(t)\cdot g(t) }{ \epsilon }.
    \end{equation}
    La fonction \( f\) étant dérivable, la proposition \ref{PropUTenzfQ} nous donne une fonction \( \alpha\colon \eR\to \eR^3\) telle que
    \begin{equation}
        f(t+\epsilon)=f(t)+\epsilon f'(t)+\epsilon\alpha(\epsilon)
    \end{equation}
    et \( \lim_{\epsilon\to 0}\alpha(\epsilon)=0\). En substituant cela dans le numérateur de \eqref{EQooGRFKooNHceiW} nous calculons un peu :
    \begin{subequations}
        \begin{align}
            f(t+\epsilon)\cdot g(t+\epsilon)-f(t)\cdot g(t)&=\big( f(t)+\epsilon f'(t)+\epsilon \alpha(\epsilon) \big)\cdot\big( g(t)+\epsilon g'(t)+\epsilon\beta(\epsilon) \big)\\
            &=\epsilon f(t)\cdot g'(t)+\epsilon^2 f'(t)\cdot \beta(\epsilon)\\
            &=+\epsilon\alpha(\epsilon)\cdot g(t)+\alpha(\epsilon)\epsilon^2\cdot g'(t)+\epsilon^2\alpha(\epsilon)\cdot \beta(\epsilon).
        \end{align}
    \end{subequations}
    En divisant cela par \( \epsilon\) et en prenant la limite \( \epsilon\to 0\), et nous reste
    \begin{equation}
        f(t)\cdot g'(t)+f'(t)\cdot g(t).
    \end{equation}
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Dérivée de la réciproque}
%---------------------------------------------------------------------------------------------------------------------------

\begin{proposition}[\cite{XGIooNMtKqx}] \label{PropMRBooXnnDLq}
    Soit \( f\colon I\to J=f(I)\) une fonction bijective, continue et dérivable\footnote{Définition~\ref{DEFooOYFZooFWmcAB}.}. Soient \( x_0\in I\) et \( y_0=f(x_0)\). Si \( f'(x_0)\neq 0\) alors la fonction réciproque \( f^{-1}\) est dérivable en \( y_0\) et sa dérivée est donnée par
    \begin{equation}
        (f^{-1})'(y_0)=\frac{1}{ f'(x_0) }.
    \end{equation}
\end{proposition}

\begin{proof}
    Pour rappel, une fonction dérivable est toujours continue (proposition~\ref{PropSFyxOWF}).

    Prouvons que \( f^{-1}\) est dérivable au point \( b=f(a)\in J\). Étant donné que \( f\) est dérivable en \( a\), nous avons
    \begin{equation}\label{EqJEWooSjQrfk}
        f'(a)=\lim_{x\to a} \frac{ f(x)-f(a) }{ x-a }.
    \end{equation}
    Par ailleurs, étant donnée la continuité de \( f^{-1}\) donnée par la proposition~\ref{ThoKBRooQKXThd}\ref{ItemEJZooKuFoeFiv}, nous avons
    \begin{equation}
        \lim_{\epsilon\to 0} f^{-1}(b+\epsilon)=f^{-1}(b)=a.
    \end{equation}
    Nous pouvons donc remplacer dans \eqref{EqJEWooSjQrfk} tous les \( x\) par \( f^{-1}(b+\epsilon)\) et prendre la limite \( \epsilon\to 0\) au lieu de \( x\to a\) :
    \begin{equation}
        \begin{aligned}[]
            f'(a)&=\lim_{\epsilon\to 0}\frac{ f\big( f^{-1}(b+\epsilon) \big)-f(a) }{ f^{-1}(b+\epsilon)-a }\\
            &=\lim_{\epsilon\to 0}\frac{ b+\epsilon-f(a) }{ f^{-1}(b+\epsilon)-f^{-1}(b) }\\
            &=\lim_{\epsilon\to 0}\frac{ \epsilon }{ f^{-1}(b+\epsilon)-f^{-1}(b) }\\
            &=\frac{1}{ \lim_{\epsilon\to 0}\frac{ f^{-1}(b+\epsilon)-f^{-1}(b) }{ \epsilon } }\\
            &=\frac{1}{ (f^{-1})'(b) }.
        \end{aligned}
    \end{equation}
    Nous avons utilisé le fait que \( f(a)=b\) et \( a=f^{-1}(b)\).
\end{proof}

\begin{normaltext}
 Très souvent on préfère retenir la formule
    \begin{equation}\label{EqWWAooBRFNsv}
      (f^{-1})'(y_0) = \frac{1}{f'\left((f^{-1})(y_0)\right)}
    \end{equation}

    Elle est très simple à retrouver : il suffit d'écrire
    \begin{equation}
        f^{-1}\big( f(x) \big)=x
    \end{equation}
    puis de dériver les deux côtés par rapport à \( x\) en utilisant la règle de dérivation des fonctions composées :
    \begin{equation}
        (f^{-1})'\big( f(x) \big)f'(x)=1.
    \end{equation}
\end{normaltext}

\begin{example}[difféomorphisme entre \( \eR\) et un ouvert borné]      \label{EXooGKPNooZtmJen}
    Nous cherchons à construire une application dérivable et d'inverse dérivable entre \( \eR\) (en entier) et un ouvert borné de \( \eR\). Il serait tentant de prendre l'application arc tangente
    \begin{equation}
        \begin{aligned}
        \arctan\colon \eR&\to \left] -\frac{ \pi }{2} , \frac{ \pi }{2} \right[ \\
            x&\mapsto \arctan(x)
        \end{aligned},
    \end{equation}
    mais elle ne sera définie que dans le théorème~\ref{THOooUSVGooOAnCvC}.

    Nous posons
    \begin{equation}
        f(x)=\begin{cases}
            2+\frac{1}{ x-2 }    &   \text{si } x\leq 1\\
            \frac{1}{ x }    &    \text{si } x>1.
        \end{cases}
    \end{equation}
    Cela est continue en \( x=1\) : il suffit de calculer les deux valeurs. En ce qui concerne la dérivabilité en \( x=1\), nous devons faire
    \begin{equation}
        \lim_{\epsilon\to 0}\frac{ f(1+\epsilon)-f(1) }{ \epsilon }.
    \end{equation}
    La limite à gauche est égale à la dérivée de \( x\mapsto 2+\frac{ 1 }{ x-2 }\) en \( x=1\) et la limite à droite est égale à la dérivée de \( x\mapsto 1/x\) en \( x=1\). Dans les deux cas nous trouvons \( -1\).

    \begin{center}
        \input{auto/pictures_tex/Fig_LMHMooCscXNNdU.pstricks}
    \end{center}

    Nous voyons vite que cette fonction est strictement décroissante; et un calcul de limite nous dit qu'il s'agit d'une bijection dérivable
    \begin{equation}
        f\colon \eR\to \mathopen] 0 , 2 \mathclose[.
    \end{equation}
    La proposition~\ref{PropMRBooXnnDLq} s'applique et la bijection réciproque est également dérivable (donc continue aussi).
\end{example}

\begin{probleme}
Si vous connaissez un autre exemple, plus simple, de difféomorphisme \( f\colon \eR\to \mathopen] a , b \mathclose[\), faites-le moi savoir. Ne pas utiliser d'exponentielle (vous pensiez à bricoler quelque chose à partir de la primitive de \( x\mapsto  e^{-x^2}\) ?) ni de fonctions trigonométriques.
\end{probleme}

\begin{example}
    Nous aimerions donner le logarithme comme exemple, mais l'exponentielle ne sera définie que dans longtemps à partir des séries entières. Allez voir l'exemple~\ref{ExZLMooMzYqfK} pour le logarithme comme inverse de l'exponentielle.
\end{example}

