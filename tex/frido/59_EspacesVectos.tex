% This is part of Mes notes de mathématique
% Copyright (c) 2008-2019, 2022-2023, 2025
%   Laurent Claessens, Carlotta Donadello
% See the file fdl-1.3.txt for copying conditions.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Fonctions}		\label{Sect_fonctions}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Soient \( (E,\| . \|_E)\) et \( (F,\| . \|_F)\) deux espaces vectoriels normés, et une fonction \( f\) de \( E\) dans \( F\). Il est maintenant facile de définir les notions de limites et de continuité pour de telles fonctions en copiant les définitions données pour les fonctions de \( \eR\) dans \( \eR\) et en changeant simplement les valeurs absolues par les normes sur \( E\) et \( F\).

La proposition suivante explicite la définition \ref{DefYNVoWBx} dans le cas où la topologie est donnée par des boules.
\begin{proposition}[Caractérisation de la limite]\label{PropHOCWooSzrMjl}
	Soient des espaces vectoriels normés.  Soit \( f\colon E\to F\) une fonction de domaine \( \Domaine(f)\subset E\) et soit \( a\) un point d'accumulation de \( \Domaine(f)\).
	\begin{enumerate}
		\item
		      Si \( F\) est séparé\footnote{C'est le cas en dimension finie et en particulier pour \( \eR^n\). En dimension infinie, il faut être très prudent.} et si \( f\) admet une limite en \( a\), alors cette limite est unique.
		\item       \label{ITEMooSHKNooStKGKH}
		      La fonction \( f\) admet une limite en \( a\in E\) si et seulement si il existe un élément \( \ell\in F\) tel que pour tout \( \varepsilon>0\), il existe un \( \delta>0\) tel que pour tout \( x\in D=\Domaine(f)\),
		      \begin{equation}        \label{EqDefLimzxmasubV}
			      0<\| x-a \|_E<\delta\,\Rightarrow\,\| f(x)-\ell \|_F<\varepsilon.
		      \end{equation}
	\end{enumerate}
	Si la limite existe et est unique, nous écrivons \( \lim_{x\to a} f(x)=\ell\) et nous disons que \( \ell\) est la \defe{limite}{limite} de \( f\) lorsque \( x\) tend vers \( a\).
\end{proposition}

\begin{proof}
	L'unicité est la proposition \ref{PropFObayrf}.

	\begin{subproof}
		\spitem[\( \Rightarrow\)]
		La définition \ref{DefYNVoWBx} nous assure de l'existence d'un élément \( \ell\) tel que pour tout voisinage \( S\) de \( \ell\), il existe un ouvert \( U\) autour de \( a\) tel que \( f\big( U\cap D\setminus\{ a \} \big)\subset S\).

		Soit \( \epsilon>0\). Nous posons \( S=B(\ell,\epsilon)\). Il existe un voisinage \( U\) de \( a\) tel que \( f\big( U\cap D\setminus\{ a \} \big)\subset B(\ell,\epsilon)\). Puisque \( U\) est un voisinage de \( a\), il contient une boule centrée en \( a\) (c'est dans la définition \ref{ThoORdLYUu} de la topologie métrique). Soit donc \( \delta>0\) tel que \( B(a,\delta)\subset U\).

		Un élément de \( D\) qui est dans \( B(0,\delta)\setminus \{ a \}\) est un élément de \( D\) qui vérifie \( 0<\| x-a \|<\delta\). Nous avons donc, pour \( x\in D\) que
		\begin{equation}
			0<\| x-a \|<\delta\Rightarrow \| f(x)-\ell \|<\epsilon.
		\end{equation}
		\spitem[\( \Leftarrow\)] C'est le même raisonnement.
	\end{subproof}
\end{proof}


\begin{remark}
	Le fait que nous limitions la formule \eqref{EqDefLimzxmasubV} aux \( x\) dans le domaine de \( f\) n'est pas anodin. Considérons la fonction \( f(x)=\sqrt{x^2-4}\), de domaine \( | x |\geq 2\). Nous avons
	\begin{equation}
		\lim_{x\to 2} \sqrt{x^2-4}=0.
	\end{equation}
	Nous ne pouvons pas dire que cette limite n'existe pas en justifiant que la limite à gauche n'existe pas. Les points \( x<2\) sont hors du domaine de \( f\) et ne comptent dons pas dans l'appréciation de l'existence de la limite.

	Vous verrez plus tard que ceci provient de la \wikipedia{fr}{Topologie_induite}{topologie induite} de \( \eR\) sur l'ensemble \( \mathopen[ 2 , \infty [\).
\end{remark}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Sous-espaces caractéristiques}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

% TODO : lire le blog de Pierre Bernard; en particulier celle-ci : http://allken-bernard.org/pierre/weblog/?p=2299

Lorsqu'un opérateur n'est pas diagonalisable, les valeurs propres jouent quand même un rôle important.

\begin{definition}  \label{DefFBNIooCGbIix}
	Soient \( E\) un \( \eK\)-espace vectoriel et \( f\in\End(E)\). Pour \( \lambda\in \eK\) nous définissons
	\begin{equation}
		F_{\lambda}(f)=\{ v\in E\tq (f-\lambda\mtu)^nv=0, n\in\eN \}
	\end{equation}
	et nous appelons cet ensemble un \defe{sous-espace caractéristique}{sous-espace!caractéristique} de \( f\).
\end{definition}
L'espace \( F_{\lambda}(f)\) est l'ensemble de nilpotence de l'opérateur \( f-\lambda\mtu\) et

\begin{lemma}   \label{LemBLPooHMAoyJ}
	L'ensemble \( F_{\lambda}(f)\) est non vide si et seulement si \( \lambda\) est une valeur propre de \( f\). L'espace \( F_{\lambda}(f)\) est invariant sous \( f\).
\end{lemma}

\begin{proof}
	Si \( F_{\lambda}(f)\) est non vide, nous considérons \( v\in F_{\lambda}(f)\) et \( n\) le plus petit entier non nul tel que \( (f-\lambda)^nv=0\). Alors \( (f-\lambda)^{n-1}v\) est un vecteur propre de \( f\) pour la valeur propre \( \lambda\). Réciproquement, si \( v\) est un vecteur propre de \( f\) pour la valeur propre \( \lambda\), alors \( v\in F_{\lambda}(f)\).

	En ce qui concerne l'invariance, remarquons que \( f\) commute avec \( f-\lambda\mtu\). Si \( x\in F_{\lambda}(f)\) il existe \( n\) tel que \( (f-\lambda\mtu)^nx=0\). Nous avons aussi
	\begin{equation}
		(f-\lambda\mtu)^nf(x)=f\big( (f-\lambda\mtu)^nx \big)=0,
	\end{equation}
	par conséquent \( f(x)\in F_{\lambda}(f)\).
\end{proof}

Contrairement à ce que l'on pourrait croire, il n'est pas vrai que toute matrice à coefficient réel est diagonalisable, même pas sur \( \eC\). La raison est qu'une telle matrice peut très bien avoir des valeurs propres multiples.

\begin{example} \label{ExBRXUooIlUnSx}
	Le théorème~\ref{ThoDigLEQEXR} nous donne une façon simple de trouver des matrices non diagonalisables sur \( \eC\) : il suffit que le polynôme minimal ne soit pas scindé à racines simples. Par exemple
	\begin{equation}
		A=\begin{pmatrix}
			1 & 1 \\
			0 & 1
		\end{pmatrix},
	\end{equation}
	dont le polynôme caractéristique est \( \chi_A=(1-X)^2\). Ce polynôme n'a manifestement pas des racines simples. Nous pouvons faire le calcul explicite pour montrer que \( A\) n'est pas diagonalisable. D'abord l'unique valeur propre de \( A\) est \( 1\) et nous pouvons sans peine résoudre
	\begin{equation}
		\begin{pmatrix}
			1 & 1 \\
			0 & 1
		\end{pmatrix}\begin{pmatrix}
			x \\
			y
		\end{pmatrix}=\begin{pmatrix}
			x \\
			y
		\end{pmatrix}
	\end{equation}
	qui revient au système
	\begin{subequations}
		\begin{numcases}{}
			x+y=x\\
			y=y.
		\end{numcases}
	\end{subequations}
	La première équation donne directement \( y=0\). Le seul espace propre est de dimension \( 1\) et est engendré par \( \begin{pmatrix}
		1 \\
		0
	\end{pmatrix}\).
\end{example}

Nous donnons maintenant un exemple un peu plus avancé de matrice réelle non diagonalisable, qui montre la multiplicité algébrique et géométrique d'une racine d'un polynôme caractéristique.

\begin{remark}  \label{RemBOGooCLMwyb}
	Considérons l'endomorphisme \( f\in\End(\eC^3)\) donné par la matrice
	\begin{equation}
		\begin{pmatrix}
			a & \alpha & \beta  \\
			0 & a      & \gamma \\
			0 & 0      & b
		\end{pmatrix}
	\end{equation}
	avec \( a\neq b\), \( a\neq 0\), \( b\neq 0\), \( \alpha\neq 0\), \( \beta\) et \( \gamma\) sont des nombres complexes quelconques.
	Son polynôme caractéristique est
	\begin{equation}
		\chi_f(X)=(a-X)^2(b-X),
	\end{equation}
	et les valeurs propres sont donc \( a\) et \( b\). Nous trouvons les vecteurs propres pour la valeur \( a\) en résolvant
	\begin{equation}
		\begin{pmatrix}
			a & \alpha & \beta  \\
			0 & a      & \gamma \\
			0 & 0      & b
		\end{pmatrix}\begin{pmatrix}
			x \\
			y \\
			z
		\end{pmatrix}=\begin{pmatrix}
			ax \\
			ay \\
			az
		\end{pmatrix}.
	\end{equation}
	La troisième équation est \( bz=az\) qui oblige \( z=0\) parce que \( a\neq b\) et \( 0\neq a\). La première est \( ax+\alpha y=ax\) qui implique \( y=0\) parce que \( \alpha\neq 0\). Enfin la première équation se réduit à \( ax=ax\) qui ne donne pas de contraintes sur \( x\). En résumé : l'espace propre \( E_a(f)\) est réduit à une seule dimension générée par \( (1,0,0)\).

	De la même façon l'espace propre correspondant à la valeur propre \( b\) est donné par le système
	\begin{equation}
		\begin{pmatrix}
			a & \alpha & \beta  \\
			  & a      & \gamma \\
			  &        & b
		\end{pmatrix}\begin{pmatrix}
			w \\
			y \\
			z
		\end{pmatrix}=\begin{pmatrix}
			bx \\
			by \\
			bz
		\end{pmatrix}
	\end{equation}
	La seconde équation donne \( ay+\gamma z=by\), et donc
	\begin{equation}
		y=\frac{ \gamma }{ b-a }z.
	\end{equation}
	La première équation est \( ax+\alpha y+\beta z=bx\) qui donne
	\begin{equation}
		x=\frac{1}{ b-a }(\alpha y+\beta z).
	\end{equation}
	En y remettant la valeur déjà trouvée de \( y\), nous trouvons que l'espace propre pour la valeur propre \( b\) est engendré par le vecteur
	\begin{equation}
		\begin{pmatrix}
			\frac{1}{ b-a }\left( \beta+\frac{ \alpha\gamma }{ b-a } \right) \\
			\frac{ \gamma }{ b-a }                                           \\
			1
		\end{pmatrix}.
	\end{equation}
	Vu que nous savons que \( a\) et \( b\) sont les seules valeurs propres et que nous venons de voir que leurs espaces propres sont de dimension \( 1\), il n'y a donc pas trois vecteurs propres linéairement indépendants, et l'opérateur \( f\) n'est pas diagonalisable.

	Par contre nous pouvons voir que \( (f-a\mtu)^2e_2=0\). En effet :
	\begin{equation}
		(f-a\mtu)^2\begin{pmatrix}
			0 \\
			1 \\
			0
		\end{pmatrix}=\begin{pmatrix}
			0 & \alpha & \beta    \\
			0 & 0      & \gamma   \\
			0 & 0      & b-a    &
		\end{pmatrix}\begin{pmatrix}
			\alpha \\
			0      \\
			0
		\end{pmatrix}=\begin{pmatrix}
			0 \\
			0 \\
			0
		\end{pmatrix},
	\end{equation}
	de telle sorte que le vecteur \( (0,1,0)\) est également dans l'espace caractéristique \( F_a(f)\).

	Dans cet exemple, la multiplicité algébrique de la racine \( a\) du polynôme caractéristique vaut \( 2\) tandis que sa multiplicité géométrique vaut seulement \( 1\).
\end{remark}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Théorèmes de décomposition}
%---------------------------------------------------------------------------------------------------------------------------

%TODO : Je crois qu'on peut remplacer l'hypothèse de corps algébriquement clos par le polynôme caractéristique scindé.
\begin{theorem}[Théorème spectral, décomposition primaire]\index{théorème!spectral}     \label{ThoSpectraluRMLok}
	Soit \( E\) un espace vectoriel de dimension finie sur le corps algébriquement clos \( \eK\) et \( f\in\End(E)\). Alors
	\begin{equation}    \label{EqCTFHooBSGhYK}
		E=F_{\lambda_1}(f)\oplus\ldots\oplus F_{\lambda_k}(f)
	\end{equation}
	où la somme est sur les espaces caractéristiques engendrés par les valeurs propres distinctes de \( f\).

	Les projecteurs sur les espaces caractéristiques forment un système complet et orthogonal.
\end{theorem}
\index{décomposition!primaire}
\index{décomposition!spectrale}
\index{décomposition!sous-espaces caractéristiques}

\begin{proof}
	Soit \( P\) le polynôme caractéristique de \( f\) et une décomposition
	\begin{equation}
		P=(f-\lambda_1)^{\alpha_1}\ldots(f-\lambda_r)^{\alpha_r}
	\end{equation}
	en facteurs irréductibles. Par le théorème des noyaux (\ref{ThoDecompNoyayzzMWod}) nous avons
	\begin{equation}        \label{EqDeFVSaYv}
		E=\ker(f-\lambda_1)^{\alpha_1}\oplus\ldots\oplus\ker(f-\lambda_r)^{\alpha_r}.
	\end{equation}
	Les projecteurs sont des polynômes en \( f\) et forment un système orthogonal. Il nous reste à prouver que \( \ker(f-\lambda_i)^{\alpha_i}=F_{\lambda_i}(f)\). L'inclusion
	\begin{equation}    \label{EqzmNxPi}
		\ker(f-\lambda_i)^{\alpha_i}\subset F_{\lambda_i}(f)
	\end{equation}
	est évidente. Nous devons montrer l'inclusion inverse.
	\begin{subproof}
		\spitem[\( F_{\lambda_i}(f)\cap F_{\lambda_j}(f)={{0}}\)]

		Soit \( v\in F_{\lambda_i}(f)\cap F_{\lambda_j}(f)\). Le fait que \( v\in F_{\lambda_i}(f)\) implique qu'il existe \( n\in \eN\) tel que \( (f-\lambda_i)^nv\neq 0\) et \( (f-\lambda_i)^{n+1}v=0\) (éventuellement \( n=0\) si \( v\) est un vecteur propre). Posons \( v_1=(f-\lambda_i)^nv\).

		Étant donné que \( (f-\lambda_i)\) commute avec \( (f-\lambda_j)\), ce \( v_1\) est encore dans \( F_{\lambda_j}(f)\). En effet, si \( k\) est tel que \( (f-\lambda_j)^kv=0\), alors
		\begin{equation}
			(f-\lambda_j)^kv_1=(f-\lambda_j)^k(f-\lambda_i)^nv=(f-\lambda_i)^n(f-\lambda_j)^kv=0.
		\end{equation}

		Il existe donc \( m\in \eN\) tel que \( (f-\lambda_j)^mv_1\neq 0\) et \( (f-\lambda_j)^{m+1}v_1=0\). En posant \( w=(f-\lambda_j)^mv_1\), nous avons
		\begin{subequations}
			\begin{numcases}{}
				(f-\lambda_i)w=(f-\lambda_j)^m(f-\lambda_i)^{n+1}v=0\\
				(f-\lambda_j)w=(f-\lambda_j)^{m+1}v_1=0.
			\end{numcases}
		\end{subequations}
		Ce \( w\) serait donc un vecteur propre simultané pour les valeurs propres \( \lambda_i\) et \( \lambda_j\). Vu que les espaces propres sont linéairement indépendants, les seules possibilités sont \( i=j\) ou \( w=0\).

		\spitem[Questions de dimension]
		Étant donné que espaces \( F_{\lambda_i}\) sont en somme directe, la somme de leurs dimensions est au maximum la dimension de \( E\) :
		\begin{equation}
			\sum_i\dim F_{\lambda_i}(f)\leq \dim E.
		\end{equation}
		En tenant compte de l'inclusion \eqref{EqzmNxPi} nous avons même
		\begin{equation}
			\dim E=\sum_i\dim\ker(f-\lambda_i)^{\alpha_i}\leq\sum_i \dim F_{\lambda_i}(f)\leq \dim E.
		\end{equation}
		Vu qu'il y a \( \dim(E)\) des deux côtés des inégalités, toutes les inégalités sont des égalités et nous avons
		\begin{equation}        \label{EQooQPLMooDXAgZi}
			\sum_i\dim\ker(f-\lambda_i)^{\alpha_i}=\sum_i\dim F_{\lambda_i}(f).
		\end{equation}
		L'inclusion \eqref{EqzmNxPi} nous dit qu'il y a une inégalité terme à terme dans les sommes de \eqref{EQooQPLMooDXAgZi}. Vu qu'il y a égalité des sommes, il y a en réalité égalité de chacun des termes : \( \dim\ker(f-\lambda_i)^{\alpha_i}=\dim F_{\lambda_i}(f)\) et l'égalité des deux espaces de \eqref{EqzmNxPi} :
		\begin{equation}
			\ker(f-\lambda_i)^{\alpha_i}=F_{\lambda_i}(f).
		\end{equation}
	\end{subproof}
\end{proof}


Si l'espace vectoriel est sur un corps algébriquement clos, alors les endomorphismes semi-simples\footnote{Définition~\ref{DEFooBOHVooSOopJN}.} sont les endomorphismes diagonaux.

\begin{theorem}[Décomposition de Dunford] \label{ThoRURcpW}
	Soit \( E\) un espace vectoriel sur le corps algébriquement clos\quext{Je crois quo'n peut remplacer l'ypothèse de corps alébriquement clos par une hypothèse de polynôme caractéristique scindé. Écrivez-moi si vous avez une idée à ce propos.} \( \eK\) et \( u\in\End(E)\) un endomorphisme de \( E\).

	\begin{enumerate}
		\item

		      L'endomorphisme \( u\) se décompose de façon unique sous la forme
		      \begin{equation}
			      u=s+n
		      \end{equation}
		      où \( s\) est diagonalisable, \( n\) est nilpotent et \( [s,n]=0\)\footnote{Lorsque \( a\) et \( b\) sont des opérateurs, la notation \( [a,b]\) signifie le commutateur entre \( a\) et \( b\), c'est-à-dire \( a\circ b-b\circ a\). Dire que \( [a,b]=0\) signifie que \( ab=ba\).}.
		\item
		      Les endomorphismes \( s\) et \( n\) sont des polynômes en \( u\) et commutent avec \( u\).
		\item   \label{ItemThoRURcpWiii}
		      Si notons \( \{ \lambda_i \}\) les valeurs propres distinctes de \( u\), et \( F_{\lambda_i}(u)\) les espaces caractéristiques correspondants, alors les parties \( s\) et \( n\) sont données par
		      \begin{subequations}
			      \begin{align}
				      s & =\sum_i\lambda_ip_i         \\
				      n & =\sum_i(s-\lambda_i\mtu)p_i
			      \end{align}
		      \end{subequations}
		      \( p_i\colon E\to F_{\lambda_i}(u)\) est la projection de \( E\) sur \( F_{\lambda_i}(u)\).
	\end{enumerate}
\end{theorem}
\index{décomposition!Dunford}
\index{Dunford!décomposition}
\index{réduction!d'endomorphisme}
\index{endomorphisme!sous-espace stable}
\index{polynôme!d'endomorphisme!décomposition de Dunford}
\index{endomorphisme!diagonalisable!Dunford}
\index{endomorphisme!nilpotent!Dunford}
%TODO : comprendre comment on calcule des exponentielles de matrices avec Dunford.

\begin{proof}
	Le théorème spectral~\ref{ThoSpectraluRMLok} nous indique que
	\begin{equation}
		E=\bigoplus_iF_{\lambda_i}(f).
	\end{equation}
	Nous considérons l'endomorphisme \( s\) de \( E\) qui consiste à dilater d'un facteur \( \lambda_i\) l'espace caractéristique \( F_{\lambda_i}(f)\) :
	\begin{equation}
		s=\sum_i\lambda_ip_i
	\end{equation}
	où \( p_i\colon E\to F_{\lambda_i}(u)\) est la projection de \( E\) sur \( F_{\lambda_i}(u)\).

	Nous allons prouver que \( [s,f]=0\) et \( n=f-s\) est nilpotent. Cela impliquera que \( [s,n]=0\).

	Si \( x\in F_{\lambda}(f)\), alors nous avons \( sf(x)=\lambda f(x)\) parce que \( f(x)\in F_{\lambda}(f)\) tandis que \( fs(x)=f(\lambda x)=\lambda f(x)\). Par conséquent \( f\) commute avec \( s\).

	Pour montrer que \( f-s\) est nilpotent, nous en considérons la restriction
	\begin{equation}
		f-s\colon F_{\lambda}(f)\to F_{\lambda}(f).
	\end{equation}
	Cet opérateur est égal à \( f-\lambda\mtu\) et est par conséquent nilpotent.

	Prouvons à présent l'unicité. Soit \( u=s'+n'\) une autre décomposition qui satisfait aux conditions : \( s'\) est diagonalisable, \( n'\) est nilpotent et \( [n',s']=0\). Commençons par prouver que \( s'\) et \( n'\) commutent avec \( u\). En multipliant \( u=s'+n'\) par \( s'\) nous avons
	\begin{equation}
		s'u=s'^2+s'n'=s'^2+n's'=(s'+n')s'=us',
	\end{equation}
	par conséquent \( [u,s']=0\). Nous faisons la même chose avec \( n'\) pour trouver \( [u,n']=0\). Notons que pour obtenir ce résultat nous avons utilisé le fait que \( n'\) et \( s'\) commutent, mais pas leur propriétés de nilpotence et de diagonalisibilité.


	Si \( s'+n'=s+n\) est une autre décomposition, \( s'\) et \( n'\) commutent avec \( u\), et par conséquent avec tous les polynômes en \( u\). Ils commutent en particulier avec \( n\) et \( s\). Les endomorphismes \( s\) et \( s'\) sont alors deux endomorphismes diagonalisables qui commutent. Par la proposition~\ref{PropGqhAMei}, ils sont simultanément diagonalisables. Dans la base de diagonalisation simultanée, la matrice de l'opérateur \( s'-s=n-n'\) est donc diagonale. Mais \( n-n'\) est également nilpotent, en effet si \( A\) et \( B\) sont deux opérateurs nilpotents,
	\begin{equation}
		(A+B)^n=\sum_{k=0}^n\binom{n}{k}A^kB^{n-k}.
	\end{equation}
	Si \( n\) est assez grand, au moins un parmi \( A^k\) ou \( B^{n-k}\) est nul.

	Nous savons que \( n-n'\) est diagonal et nilpotent. Le seul opérateur diagonal à être nilpotent est l'opérateur nul\footnote{Parce qu'une puissance d'un opérateur diagonal est diagonal.}. Nous en déduisons que \( n=n'\). Nous avons alors immédiatement aussi \( s=s'\).
\end{proof}

\begin{normaltext}
	Le théorème \ref{THOooHWNWooTewPvt} montrera que \( A^nx\to 0\) pour tout \( x\) si et seulement si \( \rho(A)<1\), mais ça demande un résultat de vitesse comparée entre l'exponentielle et la puissance.
\end{normaltext}

Une application de la décomposition de Jordan est l'existence d'un logarithme pour les matrices. La proposition suivante va d'une certaine manière donner un logarithme pour les matrices inversibles complexes. Dans le cas des matrices réelles \( m\) telles que \( \| m-\mtu \|<1\), nous donnerons au lemme~\ref{LemQZIQxaB} une formule pour le logarithme sous forme d'une série; ce logarithme sera réel.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Valeurs singulières}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}      \label{DEFooZSCYooQnBzix}
	Soit \( M\) une matrice \( m\times n\) sur \( \eK\) (\( \eK\) est \( \eR\) ou \( \eC\)). Un nombre réel \( \sigma\) est une \defe{valeur singulière}{valeur singulière} de \( M\) si il existe des vecteurs unitaires \( u\in \eK^m\), \( v\in \eK^n\) tels que
	\begin{subequations}
		\begin{align}
			Mv   & =\sigma u  \\
			M^*u & =\sigma v.
		\end{align}
	\end{subequations}
\end{definition}

\begin{theorem}[Décomposition en valeurs singulières]       \label{THOooSCOLooSKlVvd}
	Soit \( M\in \eM(m\times n,\eK)\) où \( \eK=\eR,\eC\). Alors \( M\) se décompose en
	\begin{equation}
		M=ADB
	\end{equation}
	où
	il existe deux matrices unitaires \( A\in \gU(m\times m)\), \( B\in \gU(n\times n)\) et une matrice (pseudo)diagonale \( D\in \eM(m\times n)\) tels que
	\begin{enumerate}
		\item
		      \( A\in\gU(m\times m)\), \( B\in\gU(n\times n)\) sont deux matrices unitaires,
		\item
		      \( D\) est (pseudo)diagonale,
		\item
		      les éléments diagonaux de \( D\) sont les valeurs singulières de \( M\),
		\item
		      le nombre d'éléments non nuls sur la diagonale de \( D\) est le rang\footnote{Définition~\ref{DefALUAooSPcmyK}.} de \( M\).
	\end{enumerate}
\end{theorem}

\begin{corollary}
	Soit \( M\in \eM(n,\eC)\). Il existe un isomorphisme \( f\colon \eC^n\to \eC^n\) tel que \( fM\) soit autoadjoint.
\end{corollary}

\begin{proof}
	Si \( M=ADB\) est la décomposition de \( M\) en valeurs singulières, alors nous pouvons prendre \( f=\overline{ B }^tA^{-1}\) qui est une matrice inversible. Pour la vérification que ce \( f\) répond bien à la question, ne pas oublier que \( D\) est réelle, même si \( M\) ne l'est pas.
\end{proof}
