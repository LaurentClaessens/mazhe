% This is part of Mes notes de mathématique
% Copyright (c) 2011-2015,2017
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Densité des polynômes}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Théorème de Stone-Weierstrass}
%---------------------------------------------------------------------------------------------------------------------------

Voir le thème \ref{THEooPUIIooLDPUuq}.

Note : le lemme \ref{LemYdYLXb} est utilisé dans la démonstration du théorème \ref{ThoWmAzSMF}; c'est pour cela que nous l'avons isolé.

\begin{lemma}       \label{LemYdYLXb}
    Il existe une suite de polynômes sur \( \mathopen[ 0 , 1 \mathclose]\) convergeant uniformément vers la fonction racine carré.
\end{lemma}

\begin{proof}
    Nous donnons cette suite par récurrence :
    \begin{subequations}
        \begin{align}
            P_0(t)&=0\\
            P_{n+1}(t)&=P_n(t)+\frac{ 1 }{2}\big( t-P_n(t)^2 \big).
        \end{align}
    \end{subequations}
    Nous commençons par montrer que pour tout \( t\in \mathopen[ 0 , 1 \mathclose]\), \( P_n(t)\in\mathopen[ 0 , \sqrt{t} \mathclose]\). Pour \( P_0\), c'est évident. Ensuite nous avons
    \begin{subequations}
        \begin{align}
            P_{n+1}(t)-\sqrt{t}&=P_n(t)-\sqrt{t}+\frac{ 1 }{2}(t-P_n(t)^2)\\
            &=\big( P_n(t)-\sqrt{t} \big)\left( 1-\frac{ 1 }{2}\frac{ t-P_n(t)^2 }{ P_n(t)-\sqrt{t} } \right)\\
            &=\big( P_n(t)-\sqrt{t} \big)\left( 1-\frac{ \sqrt{t}+P_n(t) }{2} \right)\\
            &\leq 0
        \end{align}
    \end{subequations}
    parce que \( \sqrt{t} \leq 1\) et \( P_n(t)\leq 1\) par hypothèse de récurrence.

    Nous savons au passage que \( P_n(t)\) est une suite réelle croissante parce que \( t-P_n(t)^2\geq t-(\sqrt{t})^2=0\). La suite \( P_n(t)\) est donc croissante et majorée par \( \sqrt{t}\); elle converge donc. Les candidats limites sont déterminés par l'équation
    \begin{equation}
        \ell=\ell+\frac{ 1 }{2}(t-\ell^2),
    \end{equation}
    dont les solutions sont \( \ell=\pm\sqrt{t}\). La suite étant positive, nous avons une convergence ponctuelle de \( P_n\) vers la racine carré. Cette suite étant une suite croissante de fonctions continues sur un compact, convergeant ponctuellement vers une fonction continue, la convergence est uniforme par le théorème de Dini \ref{ThoUFPLEZh}.
\end{proof}

\begin{lemma}           \label{LemUuxcqY}
    Soit \( K\), un compact de \( \eR\) et \( f_n\) une suite de fonctions sur \( K\) convergeant uniformément vers \( f\). Soit \( g\colon X\to K\) une fonction depuis un espace topologique \( K\). Alors \( f_n\circ g\) converge uniformément vers \( f\circ g\).
\end{lemma}

\begin{proof}
    En effet, pour tout \( x\in X\) nous avons
    \begin{equation}
        \| (f_n\circ g)-(f\circ g) \|_{\infty}=\sup_{x\in X} \| f_n\big( g(x) \big)-f\big( g(x) \big) \|\leq \| f_n-f \|_{\infty}.
    \end{equation}
    Par conséquent, si \( \epsilon\>0\) est donné, il suffit de choisir \( n\) de telle sorte à avoir \( \| f_n-f \|_{\infty}<\epsilon\) et nous avons \( \| (f_n\circ g)-(f\circ g) \|_{\infty}\leq \epsilon\).
\end{proof}

\begin{definition}
    Nous disons qu'une algèbre \( A\) de fonctions sur un espace \( X\) \defe{sépare les points}{sépare!les points} de \( X\) si pour tout \( x_1\neq x_2\) il existe \( g\in A\) telle que \( g(x_1)\neq g(x_2)\).
\end{definition}

Nous pouvons maintenant énoncer et démontrer une forme nettement plus générale du théorème de Stone-Weierstrass.
\begin{theorem}[Stone-Weierstrass\cite{MGecheleSW}] \label{ThoWmAzSMF}
    Soit \( X\), un espace compact et Hausdorff et \( A\) une sous algèbre de \( C(X,\eR)\) contenant une fonction constante non nulle. Alors \( A\) est dense dans \( \Big( C(X,\eR),\| . \|_{\infty}\Big)\) si et seulement si \( A\) sépare les points de \(X\).

    Nous pouvons remplacer \( \eR\) par \( \eC\) si de plus l'algèbre \( A\) est auto-adjointe : \( g\in A\) implique \( \bar g\in A\).
\end{theorem}
\index{théorème!Stone-Weierstrass}

\begin{proof}
    Nous allons écrire la démonstration en plusieurs étapes (dont la première est le lemme \ref{LemYdYLXb}).

    \begin{description}
        \item[Première étape] Pour tout \( x\neq y\in X\) et pour tout \( \alpha,\beta\in \eR\), il existe une fonction \( f\in A\) telle que \( f(x)=\alpha\) et \( f(y)=\beta\). 

            En effet, vu que \( A\) sépare les points nous pouvons considérer une fonction \( g\in A\) telle que \( g(x)\neq g(y)\) et ensuite poser
            \begin{equation}
                f(z)=\alpha+\frac{ \alpha-\beta }{ g(y)-g(x) }\big( g(z)-g(x) \big).
            \end{equation}
            Les constantes faisant partie de \( A\), cette fonction \( f\) est encore dans \( A\).

        \item[Seconde étape] Pour tout \( n\)-uples de fonctions \( f_1,\ldots, f_n\) dans \( \bar A\), les fonctions \( \min(f_1,\ldots, f_n)\) et \( \max(f_1,\ldots, f_n)\) sont dans \( \bar A\).

            Nous le démontrons pour \( n=2\); le reste allant évidemment par récurrence. Soient \( f,g\in \bar A\). Étant donné que
            \begin{subequations}
                \begin{align}
                    \max(f,g)&=\frac{ f+g }{2}+\frac{ | f-g | }{2}\\
                    \min(f,g)&=\frac{ f+g }{2}-\frac{ | f-g | }{2},
                \end{align}
            \end{subequations}
            if suffit de montrer que si \( f\in\bar A\) alors \( | f |\in \bar A\). Si \( f\) est nulle, c'est évident; supposons que \( f\neq 0\) et posons \( M=\| f \|_{\infty}\neq 0\). Pour tout \( x\in X\) nous avons
            \begin{equation}
                \frac{ f(x)^2 }{ M^2 }\in \mathopen[ 0 , 1 \mathclose].
            \end{equation}
            Nous considérons alors la suite
            \begin{equation}
                h_n=P_n\circ\frac{ f^2 }{ M^2 }
            \end{equation}
            où \( P_n\) est une suite de polynômes convergent uniformément vers la racine carré (voir lemme \ref{LemYdYLXb}). Le lemme \ref{LemUuxcqY} nous assure que \( h_n\) converge uniformément vers \( \frac{ | f | }{ M }\) dans \( C(X,\eR)\). Étant donné que \( \bar A\) est également une algèbre, \( h_n\) est dans \( \bar A\) pour tout \( n\) et la limite s'y trouve également (pour rappel, la fermeture \( \bar A\) est celle de la topologie de la convergence uniforme).

        \item[Troisième étape] Soit \( \epsilon>0\), \( f\in C(X,\eR)\) et \( x\in X\). Il existe une fonction \( g_x\in \bar A\) telle que 
            \begin{subequations}
                \begin{numcases}{}
                    g_x(x)=f(x)\\
                    g_x(y)\leq f(y)+\epsilon
                \end{numcases}
            \end{subequations}
            pour tout \( y\in X\).

            Soit \( z\in X\setminus\{ x \}\) et une fonction \( h_z\) telle que \( h_z(x)=f(x)\) et \( h_z(z)=f(z)\). Une telle fonction existe par une des étapes précédentes. Étant donné que \( f\) et \( h_z\) sont continues, il existe un voisinage ouvert \( V_z\) de \( z\) sur lequel
            \begin{equation}
                h_z(y)\leq f(y)+\epsilon
            \end{equation}
            pour tout \( y\in V_z\). Nous pouvons sélectionner un nombre fini de points \( z_1,\ldots, z_n\) tels que les ouverts \( V_{z_1},\ldots, V_{z_n}\) recouvrent \( X\) (parce que \( X\) est compact, de tout recouvrement par des ouverts, nous extrayons un sous recouvrement fini.). Nous posons 
            \begin{equation}
                g_x=\min(h_{z_1},\ldots, h_{z_n})\in \bar A.
            \end{equation}
            Si \( y\in X\), nous sélectionnons le \( i\) tel que \( h_{z_i}(y)\leq f(y)+\epsilon\) et nous avons
            \begin{equation}
                g_x(y)\leq h_{z_i}(y)\leq f(y)+\epsilon.
            \end{equation}
            
        \item[Étape \wikipedia{fr}{Final_Doom}{finale}] Soit \( \epsilon>0\) et \( f\in C(X,\eR)\). Pour chaque \( x\in X\) nous considérons une fonction \( g_x\in \bar A\) telle que
            \begin{subequations}
                \begin{numcases}{}
                    g_x(x)=f(x)\\
                    g_x(y)\leq f(y)+\epsilon
                \end{numcases}
            \end{subequations}
            pour tout \( y\in X\). Les fonctions \( f\) et \( g_x\) sont continues, donc il existe un voisinage ouvert \( W_x\) de \( x\) sur lequel
            \begin{equation}
                g_x(y)\geq f(y)-\epsilon.
            \end{equation}
            De ces \( W_x\) nous extrayons un sous recouvrement fini de \( X\) : \( W_{x_1},\ldots, W_{x_m}\) et nous posons
            \begin{equation}
                \varphi=\max(g_{x_1},\ldots, g_{x_n})\in \bar A.
            \end{equation}
            Si \( y\in X\), il existe un \( i\) tel que 
            \begin{equation}
                \varphi(y)\geq g_{x_i}(y)\geq f(y)-\epsilon.
            \end{equation}
            La première inégalité est le fait que \( \varphi\) est le maximum des \( g_{x_k}\), et la seconde est le choix de \( i\). Donc pour tout \( y\in X\) nous avons
            \begin{equation}        \label{EqJMxHaF}
                f(y)-\epsilon\leq \varphi(y)\leq f(y)+\epsilon.
            \end{equation}
            La première inégalité est ce que l'on vient de faire. La seconde est le fait que pour tout \( i\) nous ayons \( g_{x_i}(y)\leq f(y)+\epsilon\); le fait que \( \varphi\) soit le maximum sur les \( i\) ne change pas l'inégalité.

            Le fait que les inégalités \eqref{EqJMxHaF} soient vraies pour tout \( y\in X\) signifie que \( \| \varphi-f \|_{\infty}\leq \epsilon\), et donc que \( f\in \bar{\bar A}=\bar A\).
    \end{description}

    Tout cela prouve que \( C(X,\eR)\subset \bar A\). L'inclusion inverse est le fait que \( C(X,\eR)\) est fermé pour la norme \( \| . \|_{\infty}\), étant donné qu'une limite uniforme de fonctions continues est continue.

\end{proof}

\begin{corollary}[\cite{MonCerveau}]        \label{CORooNIUJooLDrPSv}
    Soit \( B\), la boule fermée de centre \( 0\) et de rayon \( 1\) dans \( \eR^n\). La partie \( C^{\infty}(B,\eR^n)\) est dense dans \( \big( C(B,B),\| . \|_{\infty} \big)\).
\end{corollary}

\begin{proof}
    Soit \( f \in C(B,B)\) et \( \epsilon>0\). La fonction donnant la composante \( i\) est une fonction \( f_i\in C(B,\eR)\) et il existe donc, par le théorème de Stone-Weierstrass \ref{ThoWmAzSMF}, une fonction \( g_i\in  C^{\infty}(B,\eR)\) telle que \( \| g_i-f_i \|_{\infty}\leq \epsilon\).

    La fonction \( g\) dont les composantes sont les \( g_i\) ainsi construits vérifie \( \| g-f \|_{\infty}\leq n\epsilon\).
\end{proof}

Attention toutefois que rien n'assure que les fonctions construites par le corollaire \ref{CORooNIUJooLDrPSv} prennent leurs valeurs dans \( B\).

Le théorème suivant est un des énoncés les plus classiques de Stone-Weierstrass. Il découle évidement du théorème général \ref{ThoWmAzSMF} (encore qu'il faut alors bien comprendre qu'il faut traiter la fonction \( x\mapsto \sqrt{x}\) séparément). Il en existe cependant une preuve indépendante.
%TODO : trouver cette preuve indépendante.
\begin{theorem}     \label{ThoGddfas}   \index{théorème!Stone-Weierstrass}
    Soit \( f\), une fonction continue de l'intervalle compact \( \mathopen[ a , b \mathclose]\) à valeurs dans \( \eR\). Alors pour tout \( \epsilon>0\), il existe un polynôme \( P\) tel que \( \| P-f \|_{\infty}<\epsilon\).

    Autrement dit, les polynômes sont denses dans \( C\mathopen[ a , b \mathclose]\) pour la norme uniforme.
\end{theorem}

\begin{corollary}   \label{CorRSczQD}
    Si \( X\subset \eR\) est compact et de mesure finie\footnote{Dans \( \eR\) cette hypothèse est évidemment superflue par rapport à l'hypothèse de compacité; mais ça suggère des généralisations \ldots}, alors l'ensemble des polynômes est denses dans \( \big( C(X,\eR),\| . \|_2 \big)\).
\end{corollary}

\begin{proof}
    Si \( f\) est une fonction dans \( C(X,\eR)\) et si \( \epsilon\geq 0\) est donné alors nous pouvons considérer un polynôme \( P\) tel que \( \| f-P \|_{\infty}\leq \epsilon\). Dans ce cas nous avons
    \begin{equation}
        \| f-P \|_2^2=\int_X| f(x)-P(x) |^2dx\leq \int_X\epsilon^2dx=\epsilon^2\mu(X)
    \end{equation}
    où \( \mu(X)\) est la mesure de \( X\) (finie par hypothèse).
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Primitive de fonction continue}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{proposition}[\cite{MQKDooSuEGxk}]    \label{PropQACVooBnHtRJ}
    Soit un intervalle compact \( K\) de \( \eR\) et une suite \( (f_n)\) de fonctions continues sur \( K\) telles que \( f_n\stackrel{unif}{\longrightarrow}f\). Si chacune des fonctions \( f_n\) a une primitive sur \( K\) alors \( f\) également.
\end{proposition}

\begin{proof}
    Soit \( x_0\in K\) et les primitives \( F_n\) choisies\footnote{Les fonctions \( F_n\) étant dérivables sont continues.} pour avoir \( F_n'f_n\) et \( F_n(x_0)=0\). Nous allons voir que \( (F_n)\) est une suite de Cauchy dans \( \big( K,\| . \|_{\infty} \big)\). Soient \( n,m\in \eN\) et \( x\in K\). Nous avons
    \begin{subequations}
        \begin{align}
            \| F_n-F_m \|_{\infty}&\leq \| F_n(x)-F_m(x) \|\\
            &=\| (F_n-F_m)(x) \|\\
            &\leq \| F'_n-F'_m \|_{[x,x_0]}\| x-x_0 \|
        \end{align}
    \end{subequations}
    où nous avons utilisé le théorème des accroissements finis \ref{ThoNAKKght}. Vu que \( x\in K\) et que \( K\) est borné, \( \| x-x_0 \|\) est majoré par \( \diam(K)\) et
    \begin{subequations}
        \begin{align}
            \| F_n-F_m \|_K\leq \| f_n-f_m \|_K\diam(K).
        \end{align}
    \end{subequations}
    Vu que \( (f_n) \) est de Cauchy, si \( n\) et \( m\) sont assez grands, cela tend vers zéro. La suite \( (F_n)\) converge donc vers une certaine fonction \( F\).

    Le théorème \ref{ThoSerUnifDerr} nous permet de permuter la limite et la dérivée pour conclure que \( F'=f\) et donc que \( f\) a une primitive sur \( K\).
\end{proof}

\begin{proposition}[\cite{MQKDooSuEGxk}]        \label{PropKKGAooDQYGKg}
    Soit un intervalle ouvert \( I\) de \( \eR\) et une fonction \( f\colon I\to \eR\) qui admet une primitive sur tout compact de \( I\). Alors \( f\) a une primitive sur \( I\).
\end{proposition}
\index{primitive!de fonction continue}

\begin{proof}
    Nous considérons une suite exhaustive\footnote{Voir le lemme \ref{LemGDeZlOo}.} de compacts \( K_n\) pour \( I\) et \( x_0\in K_0\). Nous considérons aussi \( F_n\) la primitive de \( f\) sur \( K_n\) telle que \( F_n(x_0)=0\) (possible parce que \( x_0\in K_n\) pour tout \( n\)). Les fonctions \( F_n\) sont des restrictions les une des autres, et nous pouvons définir
    \begin{equation}
        \begin{aligned}
            F\colon I&\to \eR \\
            x&\mapsto F_n(x)\text{ si } x\in K_n. 
        \end{aligned}
    \end{equation}
    Nous avons évidemment \( F(x_0)=0\) et nous allons prouver que \( F\) est une primitive de \( f\) sur \( I\). Soit \( x\in I\) vu que \( I\) est ouvert, nous pouvons choisir \( n_0\) tel que \( x\in\Int(K_{n_0})\). Les fonctions \( F\) et \( F_{n_0}\) sont égales sur \( K_n\) et donc sur un ouvert autour de \( x\). Par conséquent \( F\) est dérivable en \( x\) et \( F'(x)=F'_{n_0}(x)=f(x)\).
\end{proof}

\begin{theorem}    \label{ThoEXXyooCLwgQg}
    Soit \( I\) un intervalle ouvert de \( \eR\). Une fonction continue sur \( I\) admet une primitive\footnote{Définition \ref{DefXVMVooWhsfuI}.} sur \( I\).
\end{theorem}

\begin{proof}
    Sur chaque compact de \( I\), la fonction \( f\) est limite uniforme de polynômes\footnote{Si tu veux te passer de Stone-Weierstrass, tu peux prouver que toute fonction continue sur un compact est limite uniforme de fonctions affines par morceaux, par exemple. Voir \cite{MQKDooSuEGxk}.} (théorème de Stone-Weierstrass \ref{ThoGddfas}). Donc \( f\) est primitivable sur tout compact de \( I\) (proposition \ref{PropQACVooBnHtRJ}) et donc sur \( I\) par la proposition \ref{PropKKGAooDQYGKg}.
\end{proof}

\begin{proposition} \label{PropHFWNpRb}
    Soit \( I \) un intervalle borné ouvert de \( \eR\). Une fonction \( h\in C^{\infty}_c(I)\) admet une primitive dans \(  C^{\infty}_c(I)\) si et seulement si \( \int_Ih=0\).
\end{proposition}

\begin{proof}
    Si une primitive \( H\) de \( h\) est à support compact, alors
    \begin{equation}
        \int_Ih=H(b)-H(a)=0-0=0.
    \end{equation}
    Pas de problèmes dans ce sens.

    Supposons maintenant que \( \int_Ih=0\). Le fait que \( h\) admette une primitive dans \(  C^{\infty}(I)\) est évident : toute fonction continue admet une primitive\footnote{Théorème \ref{ThoEXXyooCLwgQg}.}. Soit \( H\) une telle primitive et \( \tilde H=H-H(b)\). Alors \( \tilde H(b)=0\) et 
    \begin{equation}
        \tilde H(a)=H(a)-H(b)=-\int_Ih=0.
    \end{equation}
    Nous rappelons que le support d'une fonction est \emph{la fermeture} de l'ensemble des points de non-annulation.

    Supposons que le support de \( h\) soit inclus dans \( \mathopen[ m , M \mathclose]\subset\mathopen] a , b \mathclose[\). En prenant des nombres \( m'\) et \( M'\) tels que \( a<m'<m\) et \( M<M'<b\) (nous insistons sur le caractère strict de ces inégalités), la fonction \( h\) est nulle sur \( \mathopen[ a , m' \mathclose]\) et sur \( \mathopen[ M' , b \mathclose]\); la fonction \( \tilde H\) doit donc y être constante. Mais nous avons déjà vu que \( \tilde H(a)=\tilde H(b)=0\). Donc l'ensemble des points sur lesquels \( \tilde H\) n'est pas nul est inclus dans \( \mathopen] m' , M' \mathclose[\) et donc est strictement (des deux côtés) inclus dans \( I\).
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Théorème taubérien de Hardi-Littlewood}
%---------------------------------------------------------------------------------------------------------------------------

Un théorème \defe{taubérien}{taubérien}\index{théorème!taubérien} est un théorème qui compare les modes de convergence d'une série.

\begin{lemma}
    Si \( f\) et \( g\) sont des fonctions continues, alors \( s(x)=\max\{ f(x),g(x) \}\) est également une fonction continue.
\end{lemma}

\begin{proof}
    Soit \( x_0\) et prouvons que \( s\) est continue en \( x_0\). Si \( f(x_0)\neq g(x_0)\) (supposons \( f(x_0)>g(x_0)\) pour fixer les idées), alors nous avons un voisinage de \( x_0\) sur lequel \( f>g\) et alors \( s=f\) sur ce voisinage et la continuité provient de celle de \( f\).

    Si au contraire \( f(x_0)=g(x_0)=s(x_0)\) alors si \( (a_n)\) est une suite tendant vers \( x_0\), nous prenons \( N\) tel que \( \big| f(a_n)-f(x_0) \big|\leq \epsilon\) pour tout \( n>N\) et \( M\) tel que \( \big| g(a_n)-g(x_0) \big|\leq \epsilon\) pour tout \( n> M\). Alors pour tout \( n>\max\{ N,M \}\) nous avons
    \begin{equation}
        \big| s(a_n)-s(x_0) \big|\leq \epsilon,
    \end{equation}
    d'où la continuité de \( s\) en \( x_0\).
\end{proof}

La proposition suivante dit que si une fonction connaît un saut, alors on peut le lisser par une fonction continue.
\begin{proposition} \label{PropTIeYVw}
    Soit \( f\) continue sur \( \mathopen[ a , x_0 [\) et sur \( \mathopen[ x_0 , b \mathclose]\) avec \( f(x_0^-)<f(x_0)\). En particulier nous supposons que \( f(x^-)\) existe et est finie. Alors pour tout \( \epsilon>0\), il existe une fonction continue \( s\) telle que sur \( \mathopen[ a , b \mathclose]\) on ait \( s\leq f\) et
    \begin{equation}
        \int_a^bs(x)-f(x)\,dx\leq \epsilon.
    \end{equation}
\end{proposition}

\begin{proof}
    Nous notons \( A\) la taille du saut :
    \begin{equation}
        A=f(x_0)-f(x_0^-).
    \end{equation}
    Quitte à changer \( a\) et \( b\), nous pouvons supposer que
    \begin{equation}
        f(x)<f(x_0)+\frac{ A }{ 3 }
    \end{equation}
    pour \( x\in \mathopen[ a , x_0 [\) et 
    \begin{equation}
        f>f(x_0)+\frac{ 2A }{ 3 }
    \end{equation}
    pour \( x\in \mathopen[ x_0 , b \mathclose]\). C'est le théorème des valeurs intermédiaires qui nous permet de faire ce choix.

    Soit \( m(x)\) la droite qui joint le point \( \big( x_0-\epsilon, f(x_0-\epsilon) \big)\) au point \( \big( x_0,f(x_0^+) \big)\). Nous posons
    \begin{equation}
        s(x)=\begin{cases}
            f(x)    &   \text{si } x<x_0-\epsilon\\
            \max\{ m(x),f(x) \}    &   \text{si } x_0-\epsilon\leq x\leq x_0\\
            f(x)    &    \text{si }x>x_0.
        \end{cases}
    \end{equation}
    En vertu des différents choix effectués, c'est une fonction continue. En effet
    \begin{equation}
        s(x_0-\epsilon)=\max\{ f(x_0-\epsilon),f(x_0,\epsilon) \}=f(x_0-\epsilon)
    \end{equation}
    et 
    \begin{equation}
        s(x_0)=\max\{ m(x_0),f(x_0^+) \}=f(x_0^+)
    \end{equation}
    parce que \( m(x_0)=f(x_0^+)\). En ce qui concerne l'intégrale, si nous posons
    \begin{equation}
        M=\sup_{x,y\in \mathopen[ a , b \mathclose]}| f(x)-f(y) |,
    \end{equation}
    nous avons
    \begin{equation}
        \int_a^bs-f=\int_{x_0-\epsilon}^{x_0}s-f\leq \epsilon M.
    \end{equation}
\end{proof}

\begin{lemma}\label{LemauxrKN}
    Pour tout polynôme \( P\), nous avons la formule
    \begin{equation}
        \lim_{x\to 1^-} (1-x)\sum_{n=0}^{\infty}x^nP(x^n)=\int_0^1P(x)dx.
    \end{equation}
\end{lemma}

\begin{proof}
    D'abord pour \( P=1\), la formule se réduit à la série harmonique connue. Ensuite nous prouvons la formule pour le polynôme \( P=X^k\) et la linéarité fera le reste pour les autres polynômes. Nous avons
    \begin{equation}
        (1-x)\sum_nx^nx^{kn}=(1-x)\sum_n(x^{1+k})^n=\frac{ 1-x }{ 1-x^{1+k} }=\frac{1}{ 1+x+\cdots+x^k }.
    \end{equation}
    Donc
    \begin{equation}
        \lim_{x\to 1^-} (1-x)\sum_nx^nP(x^n)=\frac{1}{ 1+k }.
    \end{equation}
    Par ailleurs, c'est vite vu que
    \begin{equation}
        \int_0^1 x^kdx=\frac{1}{ k+1 }.
    \end{equation}
\end{proof}

\begin{theorem}[Hardy-Littlewood\cite{ytMOpe}]\index{théorème!Hardy-Littlewood}\index{Hardy-Littlewood (théorème)}      \label{ThoPdDxgP}
    Soit \( (a_n)\) une suite réelle telle que
    \begin{enumerate}
        \item
            \( \frac{ a_n }{ n }\) tends vers une constante,
        \item
            \( F(x)=\sum_{n=0}^{\infty}a_nx^n\) a un rayon de convergence \( \geq 1\),
        \item
            \( \lim_{x\to 1^-} F(x)=l\).
    \end{enumerate}
    Alors \( \sum_{n=0}^{\infty}a_n=l\).
\end{theorem}
\index{convergence!suite numérique}
\index{série!nombres}
\index{série!fonctions}
\index{limite!inversion}
\index{approximation!par polynômes}

\begin{proof}
    Quitte à prendre la suite \( b_0=a_0-l\) et \( b_n=a_n\), on peut supposer \( l=0\).

    Soit \( \Gamma\) l'ensemble des fonctions
    \begin{equation}
         \gamma\colon \mathopen[ 0 , 1 \mathclose]\to \eR 
    \end{equation}
    telles que 
    \begin{enumerate}
        \item
            $\sum_{n=0}^{\infty}a_n\gamma(x^n)$ converge pour \( 0\leq x<1\),
        \item
            \( \lim_{x\to 1^-} \sum_{n\geq 0}a_n\gamma(^n)=0\).
    \end{enumerate}
    Ce \( \Gamma\) est un espace vectoriel.
    \begin{subproof}
    \item[Les polynômes sont dans \( \Gamma\)]
        Soit \( \gamma(t)=t^s\). Pour \( 0\leq x<1\) nous avons
        \begin{equation}
            \sum_{n=0}^{\infty}a_n\gamma(x^n)=\sum_{n=0}^{\infty}a_nx^{ns}<\sum_{n=0}^{\infty}a_nx^n.
        \end{equation}
        Donc la condition de convergence est vérifiée. En ce qui concerne la limite,
        \begin{equation}
            \lim_{x\to 1^-} \sum_{n=0}^{\infty}a_nx^{ns}=\lim_{x\to 1^-} F(x^s)=0
        \end{equation}
        parce que par hypothèse, \( \lim_{x\to 1^-} F(x)=0\).

    \item[Définition de la fonction qui va donner la réponse]
        Nous considérons la fonction \( g=\mtu_{\mathopen[ \frac{ 1 }{2} , 1 \mathclose]}\), c'est à dire
        \begin{equation}
            g(t)=\begin{cases}
                0    &   \text{si } 0\leq t<1/2\\
                1    &    \text{si } 1/2\leq t\leq 1.
            \end{cases}
        \end{equation}
        Nous montrons que si \( g\in \gamma\), alors le théorème est terminé. Si \( 0\leq x\leq 1\), on a \( 0\leq x^n<1/2\) dès que
        \begin{equation}
            n>-\frac{ \ln(2) }{ \ln(x) }
        \end{equation}
        avec une note comme quoi \( \ln(x)<0\), donc la fraction est positive. Nous désignons par \( N_x\) la partie entière de ce \( n\) adapté à \( x\). L'idée est que la fonction  \( g(x^n)\) est la fonction indicatrice de \(0 \leq n\leq N_x\), et donc
        \begin{equation}
            \sum_{n\geq 0}a_ng(x^n)=\sum_{n=0}^{N_x}a_n.
        \end{equation}
        Mais si \( x\to 1^-\), alors \( N_x\to \infty\), donc
        \begin{equation}
            \lim_{N\to \infty} \sum_{n=0}^Na_n=\lim_{x\to 1^-} \sum_{n=0}^{N_x}a_n=\lim_{x\to 1^-} \sum_{n\in \eN}a_ng(x^n),
        \end{equation}
        et cela fait zéro si \( g\in \Gamma\).
        
    \item[Approximation de \( g\) par des polynômes]

        Nous considérons la fonction
        \begin{equation}
            h(t)=\frac{ g(t)-t }{ t(1-1) }=\begin{cases}
                \frac{1}{ t-1 }    &   \text{si } t\in \mathopen[ 0 , 1/2 [\\
                \frac{1}{ t }    &    \text{si } t\in \mathopen[ 1/2 , 1 \mathclose].
            \end{cases}
        \end{equation}
        La seconde égalité est au sens du prolongement par continuité. La fonction \( h\) est une fonction non continue qui fait un saut de \( -2\) à \( 2\) en \( x=1/2\). En vertu de la proposition \ref{PropTIeYVw} (un peu adaptée), nous pouvons considérer deux fonctions continues \( s_1\) et \( s_2\) telles que
        \begin{equation}
            s_1\leq h\leq s_2
        \end{equation}
        et
        \begin{equation}
            \int_{0}^1s_2-s_1\leq \epsilon.
        \end{equation}
        Notons que l'inégalité \( s_1\leq s_2\) doit être stricte sur au moins un petit intervalle autour de \( x=1/2\). Soient \( P_1\) et \( P_2\), deux polynômes tels que \( \| P_1-s_1 \|_{\infty}\leq \epsilon\) et \( \| P_2-s_2 \|_{\infty}\leq \epsilon\) (ici la norme supremum est prise sur \( \mathopen[ 0 , 1 \mathclose]\)). C'est le théorème de Stone-Weierstrass (\ref{ThoGddfas}) qui nous permet de le faire.

        Nous posons aussi\footnote{À ce niveau, je crois qu'il y a une faute de frappe dans \cite{ytMOpe}.}
        \begin{subequations}
            \begin{align}
                Q_1=P_1+\epsilon\\
                Q_2=P_2-\epsilon.
            \end{align}
        \end{subequations}
        Nous avons
        \begin{equation}
            \int_0^1Q_1-Q_2\leq\int_0^1 Q_1-P_1+P_1-P_2+P_2-Q_2.
        \end{equation}
        Pour majorer cela, d'abord \( Q_1-P_1=P_2-Q2=\epsilon\), ensuite,
        \begin{equation}
            P_1-P_2=P_1-s_1+s_1-s_2+s_2-P_2
        \end{equation}
        dans lequel nous avons \( P_1-s_1\leq \epsilon\), \( s_2-P_2\leq \epsilon\) et \( \int_0^1s_1-s_2\leq\epsilon\). Au final, nous posons \( q=Q_2-Q_1\) et nous avons
        \begin{equation}
            \int_0^1q\leq 5\epsilon.
        \end{equation}
        Enfin nous posons aussi
        \begin{equation}
            R_i(x)=x+x(1-x)Q_i.
        \end{equation}
        Ces polynômes vérifient \( R_i(0)=0\), \( R_i(1)=1\) et
        \begin{equation}
            R_1\leq g\leq R_2
        \end{equation}
        parce que
        \begin{equation}
            Q_1\leq P_1\leq h\leq  P_2\leq Q_2
        \end{equation}
        et
        \begin{equation}
            t+t(1-t)Q_1\leq \underbrace{t+t(1-t)h(t)}_{g(t)}\leq t+t(1-t)Q_2.
        \end{equation}
        
    \item[Preuve que \( g\) est dans \( \Gamma\)]

        D'abord si \( 0\leq x<1\), \( x^N<\frac{ 1 }{2}\) pour un certain \( N\), et alors \( g(x^N)=0\). Du coup la série
        \begin{equation}
            \sum_{n=0}^{\infty}a_ng(x^n)=\sum_{n=0}^{N}a_n
        \end{equation}
        est une somme finie qui converge donc.

        D'autre part nous prenons \( M\) tel que \( | a_n |<\frac{ M }{ n }\) pour tout \( n\). Nous majorons \( \sum_{n \in \eN}a_ng(x^n)\) en utilisant \( R_1\). Mais vu que \( R_1\) est un polynôme, nous pouvons dire que \( | \sum_{n=0}^{\infty}a_nR_1(x^n) |\leq \epsilon\) en prenant \( x\in\mathopen[ \lambda , 1 [\) et \( \lambda\) assez grand. Nous avons :
        \begin{subequations}
            \begin{align}
                \left| \sum_{n=0}^{\infty}a_ng(x^n) \right| &\leq\left| \sum_{n=0}^{\infty}a_ng(x^n)-\sum_{n=0}^{\infty}a_nR_1(x^n) \right| +\underbrace{\left| \sum_{n=0}^{\infty}a_nR_1(x^n) \right|}_{\leq \epsilon} \\
                &\leq \epsilon+\sum_{n=0}^{\infty}| a_n |(g-R_1)(x^n)\\
                &\leq \epsilon+\sum_{n=0}^{\infty}| a_n |(R_2-R_1)(x^n)\\
                &\leq \epsilon+M\sum_{n=0}^{\infty}\frac{ x^n(1-x^n) }{ n }(Q_2-Q_1)(x^n)   &R_2-R_1=x(1-x)(Q_2-Q_1)\\
                &=\epsilon+M\sum_{n=0}^{\infty}\frac{ x^n(1-x^n) }{ n }q(x^n)\\
                &\leq \epsilon+M(1-x)\sum_nx^nq(x^n)   \label{subeqtZXDvu} 
            \end{align}
        \end{subequations}
        où la ligne \eqref{subeqtZXDvu} provient d'une majoration sauvage de \( 1/n\) par \( 1\) et de \( 1-x^n\) par \( 1-x\). Par le lemme \ref{LemauxrKN}, nous avons alors
        \begin{equation}
            \lim_{x\to 1^-} | \sum_na_ng(x^n) |\leq \epsilon+M\int_0^1q\leq 6\epsilon.
        \end{equation}
    \end{subproof}
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Théorème de Müntz}
%---------------------------------------------------------------------------------------------------------------------------

\begin{theorem}[Théorème de Müntz\cite{jqZSyG,oYGash,ooRIPFooALoEWM}]  \label{ThoAEYDdHp}
    Soit \( C_0\big( \mathopen[ 0 , 1 \mathclose] \big)\), l'espace des fonctions continues sur \( \mathopen[ 0 , 1 \mathclose]\) muni de la norme \( \| . \|_{\infty}\) ou \( \| . \|_2\) et une suite \( (\alpha_n)\) strictement croissante de nombres positifs. Nous notons \( \phi_{\lambda}\) la fonction \( x\mapsto x^{\lambda}\).

    Alors 
    \begin{equation}
        \overline{  \Span\{1, \phi_{\alpha_n} \} }   
    \end{equation}
    est dense dans \( C_0\big( \mathopen[ 0 , 1 \mathclose] \big)\)  si et seulement si 
    \begin{equation}
        \sum_{n=2}^{\infty}\frac{1}{ \alpha_n }=+\infty.
    \end{equation}
\end{theorem}

Nous prouvons le théorème pour la norme \( \| . \|_2\).
\begin{proof}
    Soit \( m\in \eR^+\); nous notons \( \Delta_N(m)\) la distance entre \( \phi_m\) et \( \Span\{ \phi_{\alpha_1},\ldots, \phi_{\alpha_N} \}\). Cette distance peut être évaluée avec le déterminant de Gram\index{déterminant!Gram} (proposition \ref{PropMsZhIK})
    \begin{equation}
        \Delta_N(m)^2=\frac{ G(\phi_m,\phi_{\alpha_1},\ldots, \phi_{\alpha_N}) }{ G(\phi_{\alpha_1},\ldots, \phi_{\alpha_N}) }.
    \end{equation}
    Pour calculer cela nous avons besoin des produits scalaires\footnote{C'est ici qu'on se particularise à la norme \( \| . \|_2\).}
    \begin{equation}
        \langle \phi_a, \phi_b\rangle =\int_0^1 x^{a+b}dx=\frac{1}{ a+b+1 }.
    \end{equation}
    Pour avoir des notation plus compactes, nous notons \( \alpha_0=m\). Donc nous avons à calculer le déterminant
    \begin{equation}
        G(\phi_m,\phi_{\alpha_1},\ldots, \phi_{\alpha_N})=\det\begin{pmatrix}
            \frac{1}{ \alpha_i+\alpha_j+1 }
         \end{pmatrix}
    \end{equation}
    où \( i,j=0,\ldots, N\). Nous reconnaissons un déterminant de Cauchy (proposition \ref{ProptoDYKA})\index{déterminant!Cauchy} en posant, dans \( \frac{1}{ \alpha_i+\alpha_j+1 }\), \( a_i=\alpha_i\) et \( b_j=\alpha_j+1\). Étant donné que \( b_j-b_i=a_j-a_i\), nous avons
    \begin{equation}
        G(\phi_m,\phi_{\alpha_1},\ldots, \phi_{\alpha_N})=\frac{ \prod_{0\leq i<j\leq N}  (\alpha_j-\alpha_i)^2 }{ \prod_{i=0}^N\prod_{j=0}^N (\alpha_i+\alpha_j+1).}
    \end{equation}
    Nous séparons maintenant les termes où \( i\) ou \( j\) sont nuls. En ce qui concerne le dénominateur, il faut prendre tous les couples \( (i,j)\) avec \( i\) et \( j\) éventuellement égaux à zéro. Nous décomposant cela en trois paquets. Le premier est \( (0,0)\); le second est \( (0,i)\) (chaque couple arrive en fait deux fois parce qu'il y a aussi \( (i,0)\)); et le troisième sont les \( i,j\) tous deux différents de zéro :
    \begin{equation}
        (2m+1)\prod_{ij}(\alpha_i+\alpha_j+1)\prod_i(\alpha_i+m+1)^2.
    \end{equation}
    Notons que dans le produit central, le carré est contenu dans le fait qu'on écrit \( \prod_{ij}\) et non \( \prod_{i<j}\). Nous avons donc
    \begin{equation}
        G(\phi_m,\phi_{\alpha_1},\ldots, \phi_{\alpha_N})=\frac{ \prod_{i<j}(\alpha_i-\alpha_j)^2\prod_i(\alpha_i-m)^2 }{ (2m+1)\prod_{ij}(\alpha_i+\alpha_j+1)\prod_i(\alpha_i+m+1)^2 }.
    \end{equation}
    
    Le calcul de \( G(\phi_{\alpha_1},\ldots, \phi_{\alpha_N})\) est plus simple\footnote{Je crois qu'il y a une faute de frappe dans le dénominateur de \cite{jqZSyG}.} :
    \begin{equation}
        G(\phi_{\alpha_1},\ldots, \phi_{\alpha_N})=\frac{ \prod_{i<j}(\alpha_i-\alpha_j)^2 }{ \prod_{ij}(\alpha_i+\alpha_j+1) }.    
    \end{equation}
    En divisant l'un par l'autre il ne reste que les facteurs comprenant \( m\) et en prenant la racine carré,
    \begin{equation}    \label{EqANiuNB}
        \Delta_N(m)=\frac{1}{ \sqrt{2m+1} }\prod_{i=1}^N\left| \frac{ \alpha_i-m }{ \alpha_i+m+1 } \right| .
    \end{equation}
    
    Nous passons maintenant à la preuve proprement dite. Supposons que \( V=\Span\{ \phi_{\alpha_i},i\in \eN \}\) est dense. Si \( m\) est un des \( \alpha_i\), il peut évidemment être approché par les \( \phi_{\alpha_i}\). Mais vue la densité de \( V\), un \( \phi_m\) avec \( m\neq \alpha_i\) (pour tout \( i\)) alors \( \phi_m\) peut également être arbitrairement approché par les \( \phi_{\alpha_i}\), c'est à dire que
    \begin{equation}
        \lim_{N\to \infty} \Delta_N(m)=0.
    \end{equation}
    Nous posons 
    \begin{equation}
        u_n=\ln\left( \frac{ \alpha_n-m }{ \alpha_n+m+1 } \right)
    \end{equation}
    et nous prouvons que la série \( \sum_nu_n\) diverge. En effet nous nous souvenons de la formule \( \ln(ab)=\ln(a)+\ln(b)\), de telle sorte que la \( N\)\ieme somme partielle de \( \sum_nu_n\) est
    \begin{equation}
        \ln\left( \frac{ \alpha_1-m }{ \alpha_1+m+1 }\cdot\ldots\cdot \frac{ \alpha_N-m }{ \alpha_N+m+1 } \right)=\ln\left( \sqrt{2m+1}\Delta_N(m) \right),
    \end{equation}
    qui tends vers \( -\infty\) lorsque \( N\to \infty\).

    Si la suite \( (\alpha_n)\) est majorée et plus généralement si nous n'avons pas \( \alpha_n\to \infty\), alors évidemment la série \( \sum_n\frac{1}{ \alpha_n }\) diverge. Nous supposons donc que \( \lim_{n\to \infty} \alpha_n=\infty\). Nous avons aussi\quext{Je crois qu'il y a une faute de signe dans la dernière expression de \cite{oYGash}.}
    \begin{equation}
        u_n=\ln\left( \frac{ \alpha_n-m }{ \alpha_n+m+1 } \right)=\ln\left( 1-\frac{ 2m+1 }{ \alpha_n+m+1 } \right)\sim-\frac{ 2m+1 }{ \alpha_n }.
    \end{equation}
    Une justification est donné à l'équation \eqref{EqGICpOX}. Ce que nous avons surtout est
    \begin{equation}
        \sum_n u_n\sim -(2m+1)\sum_n\frac{1}{ \alpha_n }.
    \end{equation}
    Étant donné que la série de gauche diverge, celle de droite diverge\footnote{Nous utilisons le fait que si \( u_n=\sum v_n\) en tant que suites et si \( \sum_nu_n\) diverge, alors \( \sum_nv_n\) diverge.}.

    Nous faisons maintenant le sens opposé : nous supposons que la série \( \sum_n1/\alpha_n\) diverge et nous nous posons
    \begin{equation}
        V=\Span\{ \phi_{\alpha_n}\tq n\in \eN \}.
    \end{equation}
    Il suffit de prouver que \( \phi_m\in \bar V\) pour tout \( m\) parce qu'un corollaire du théorème de Stone-Weierstrass \ref{CorRSczQD} montre que \( \Span\{ \phi_k\tq k\in \eN \}\) est dense dans \( C\) pour la norme \( \| . \|_2\). 
    
    Si \( \alpha_n\to \infty\), nous avons :
    \begin{equation}
        u_n\sim\frac{ 2m+1 }{ \alpha_n }\to 0
    \end{equation}
    et alors \( \Delta_N(m)\to 0\). Dans ce cas nous avons immédiatement \( \phi_m\in \bar V\).

    Si par contre \( \alpha_n\) ne tend pas vers l'infini, nous repartons de l'expression \eqref{EqANiuNB}, nous posons \( 0<\alpha=\sup_i\alpha_i\) et nous calculons :
    \begin{subequations}
        \begin{align}
            \sqrt{2m+1}\Delta_N(m)&=\prod_{i=1}^N\frac{ | \alpha_i-m | }{ \alpha_i+m+1 }\\
            &\leq \prod_{i=1}^N\frac{ \alpha_i+m }{ \alpha_i+m+1 }\\
            &=\prod_{i=1}^N\left( 1-\frac{ 1 }{ \alpha_i+m+1 } \right)\\
            &\leq \prod_{i=1}^N\left( 1-\frac{1}{ \alpha+m+1 } \right)\\
            &=\left( 1-\frac{1}{ \alpha+m+1 } \right)^N.
        \end{align}
    \end{subequations}
    Cette dernière expression tend vers \( 0\) lorsque \( N\to \infty\).
\end{proof}

\begin{remark}      \label{REMooGPYYooCQJwFa}
    Certaines sources\footnote{Dont le rapport du jury 2014} citent le théorème de Müntz comme ceci (avec un implicite que \( \alpha_i\neq 0\)):
    \begin{equation}        \label{EQooPCSZooUDSzwQ}
        \overline{ \Span\{1, \phi_{\alpha_i} \} }=C\big( \mathopen[ 0 , 1 \mathclose] \big) \Leftrightarrow \sum_{i\geq 1}\frac{1}{ \alpha_i }=+\infty.
    \end{equation}
    Que penser de la présence explicite du \( 1\) (c'est à dire de \( \phi_0\)) ou non dans l'ensemble ?

    Première chose : la présence éventuelle de \( \phi_0\) est la raison pour laquelle nous faisons commencer la somme à \( i=2\) et non \( i=1\). Dans le même ordre d'idée, si $\Span\{ \phi_{\alpha_i} \}$  est dense, alors en prenant n'importe quelle queue de suite, ça reste dense.

    Prouvons donc l'énoncé \eqref{EQooPCSZooUDSzwQ}. Si \( \Span\{ 1,\phi_{\alpha_i} \}\) est dense, alors en posant \( \beta_1=0\), \( \beta_i=\alpha_{i-1}\) notre théorème prouve que \( \sum_{\beta=2}^{\infty}\frac{1}{ \beta_i }=+\infty\), cela est exactement que \( \sum_{i=1}^{\infty}\frac{1}{ \alpha_i }=+\infty\). Dans l'autre sens, si \( \sum_{i\geq 1}\frac{1}{ \alpha_i }=+\infty\), alors nous avons aussi \( \sum_{i\geq 2}\frac{1}{ \alpha_i }=+\infty\) et notre théorème dit que \( \Span \{ \phi_{\alpha_i} \}\) est dense. A fortiori, \( \Span\{ 1,\phi_{\alpha_i} \}\) est dense.
\end{remark}

\begin{example}
    Nous savons depuis le théorème \ref{ThonfVruT} que la somme des inverses des nombres premiers diverge.
\end{example}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Théorèmes de point fixe}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Points fixes attractifs et répulsifs}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}      \label{DEFooTMZUooMoBDGC}
    Soit \( I\) un intervalle fermé de \( \eR\) et \( \varphi\colon I\to I\) une application \( C^1\). Soit \( a\) un point fixe de \( \varphi\). Nous disons que \( a\) est \defe{attractif}{point fixe!attractif}\index{attractif!point fixe} s'il existe un voisinage \( V\) de \( a\) tel que pour tout \( x_0\in V\) la suite \( x_{n+1}=\varphi(x_n)\) converge vers \( a\). Le point \( a\) sera dit \defe{répulsif}{répulsif!point fixe} s'il existe un voisinage \( V\) de \( a\) tel que pour tout \( x_0\in V\) la suite \( x_{n+1}=\varphi(x_n)\) diverge.
\end{definition}

\begin{lemma}[\cite{DemaillyNum}]
    Soit \( a\) un point fixe de \( \varphi\).
    \begin{enumerate}
        \item
    Si \( | \varphi'(a) |<1\) alors \( a\) est attractif et la convergence est au moins exponentielle.
\item
    Si \( | \varphi'(a) |>1\) alors \( a\) est répulsif et la divergence est au moins exponentielle.
    \end{enumerate}
\end{lemma}

\begin{proof}
    Si \( | \varphi'(a)<1 |\) alors il existe \( k\) tel que \( | \varphi'(a) |<k<1\) et par continuité il existe un voisinage \( V\) de \( a\) dans lequel \( | \varphi'(x) |<k\) pour tout \( x\in V\). En utilisant le théorème des accroissements finis nous avons
    \begin{equation}
        | x_n-a |=\big| f(x_{n-1}-a) \big|\leq k| x_{n-1}-a |
    \end{equation}
    et par récurrence
    \begin{equation}
        | x_n-a |\leq k^n| x_0-a |.
    \end{equation}

    Le cas \( | \varphi'(a)>1 |\) se traite de façon similaire.
\end{proof}

\begin{remark}
    Dans le cas \(| \varphi'(a) |=1\), nous ne pouvons rien conclure. Si \( \varphi(x)=\sin(x)\) nous avons \( \sin(x)<x\) et le point \( a=0\) est attractif. A contrario, si \( \varphi(x)=\sinh(x)\) nous avons \( |\sinh(x)|>|x|\) et le point \( a=0\) est répulsif.
\end{remark}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Picard}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}      \label{DEFooRSLCooAsWisu}
    Une application \( f\colon (X,\| . \|_X)\to (Y,\| . \|_Y)\) entre deux espaces métriques est une \defe{contraction}{contraction} si elle est \( k\)-\defe{Lipschitz}{Lipschitz} pour un certain \( 0\leq k<1\), c'est à dire si pour tout \( x,y\in X\) nous avons
    \begin{equation}
        \| f(x)-f(y) \|_Y\leq k\| x-y \|_{X}.
    \end{equation}
\end{definition}

\begin{theorem}[Picard \cite{ClemKetl,NourdinAnal}\footnote{Il me semble qu'à la page 100 de \cite{NourdinAnal}, l'hypothèse H1 qui est prouvée ne prouve pas Hn dans le cas \( n=1\). Merci de m'écrire si vous pouvez confirmer ou infirmer. La preuve donnée ici ne contient pas cette «erreur».}.]     \label{ThoEPVkCL}
    Soit \( X\) un espace métrique complet et \( f\colon X\to X\) une application contractante, de constante de Lipschitz \( k\). Alors \( f\) admet un unique point fixe, nommé \( \xi\). Ce dernier est donné par la limite de la suite définie par récurrence 
    \begin{subequations}
        \begin{numcases}{}
            x_0\in X\\
            x_{n+1}=f(x_n).
        \end{numcases}
    \end{subequations}
    De plus nous pouvons majorer l'erreur par
    \begin{equation}    \label{EqKErdim}
        \| x_n-x \|\leq \frac{ k^n }{ 1-k }\| x_n-x_{n-1} \|\leq \frac{ k^n }{ 1-k }\| x_1-x_0 \|.
    \end{equation}

    Soit \( r>0\), \( a\in X\) tels que la fonction \( f\) laisse la boule \( K=\overline{ B(a,r) }\) invariante (c'est à dire que \( f\) se restreint à \( f\colon K\to K\)). Nous considérons les suites \( (u_n)\) et \( (v_n)\) définies par
    \begin{subequations}
        \begin{numcases}{}
            u_0=v_0\in K\\
            u_{n+1}=f(v_n), v_{n+1}\in B(u_n,\epsilon).
        \end{numcases}
    \end{subequations}
    Alors le point fixe \( \xi\) de \( f\) est dans \( K\) et la suite \( (v_n)\) satisfait l'estimation
    \begin{equation}
        \| v_n-\xi \|\leq \frac{ k^n }{ 1-k }\| u_1-u_0 \|+\frac{ \epsilon }{ 1-k }.
    \end{equation}
\end{theorem}
\index{théorème!Picard}
\index{point fixe!Picard}

La première inégalité \eqref{EqKErdim} donne une estimation de l'erreur calculable en cours de processus; la seconde donne une estimation de l'erreur calculable avant de commencer.

\begin{proof}
    
    Nous commençons par l'unicité du point fixe. Si \( a\) et \( b\) sont des points fixes, alors \( f(a)=a\) et \( f(b)=b\). Par conséquent
    \begin{equation}
        \| f(a)-f(b) \|=\| a-b \|,
    \end{equation}
    ce qui contredit le fait que \( f\) soit une contraction.

    En ce qui concerne l'existence, notons que si la suite des \( x_n\) converge dans \( X\), alors la limite est un point fixe. En effet en prenant la limite des deux côtés de l'équation \( x_{n+1}=f(x_n)\), nous obtenons \( \xi=f(\xi)\), c'est à dire que \( \xi\) est un point fixe de \( f\). Notons que nous avons utilisé ici la continuité de \( f\), laquelle est une conséquence du fait qu'elle soit Lipschitz. Nous allons donc porter nos efforts à prouver que la suite est de Cauchy (et donc convergente parce que \( X\) est complet). Nous commençons par prouver que \( \| x_{n+1}-x_n \|\leq k^n\| x_0-x_1 \|\). En effet pour tout \( n\) nous avons
    \begin{equation}
        \| x_{n+1}-x_n \|=\| f(x_n)-f(x_{n-1}) \|\leq k\| x_n-x_{n-1} \|.
    \end{equation}
    La relation cherchée s'obtient alors par récurrence. Soient \( q>p\). En utilisant une somme télescopique,
    \begin{subequations}
        \begin{align}
            \| x_q-x_p \|&\leq \sum_{l=p}^{q-1}\| x_{l+1}-x_l \|\\
            &\leq\left( \sum_{l=p}^{q-1}k^l \right)\| x_1-x_0 \|\\
            &\leq\left(\sum_{l=p}^{\infty}k^l\right)\| x_1-x_0 \|.
        \end{align}
    \end{subequations}
    Étant donné que \( k<1\), la parenthèse est la queue d'une série qui converge, et donc tend vers zéro lorsque \( p\) tend vers l'infini.

    En ce qui concerne les inégalités \eqref{EqKErdim}, nous refaisons une somme télescopique :
    \begin{subequations}
        \begin{align}
            \| x_{n+p}-x_n \|&\leq \| x_{n+p}-x_{n+p-1} \|+\cdots +\| x_{n+1}-x_n \|\\
            &\leq k^p\| x_n-x_{n-1} \|+k^{p-1}\| x_n-x_{n-1} \|+\cdots +k\| x_n-x_{n-1} \|\\
            &=k(1+\cdots +k^{p-1})\| x_n-x_{n-1}\|  \\
            &\leq \frac{ k }{ 1-k }\| x_n-x_{n-1} \|.
        \end{align}
    \end{subequations}
    En prenant la limite \( p\to \infty\) nous trouvons
    \begin{equation}        \label{EqlUMVGW}
        \| \xi-x_n \|\leq \frac{ k }{ 1-k }\| x_n-x_{n-1} \|\leq \frac{ k }{ 1-k }\| x_1-x_0 \|.
    \end{equation}

    Nous passons maintenant à la seconde partie du théorème en supposant que \( f\) se restreigne en une fonction \( f\colon K\to K\). D'abord \( K\) est encore un espace métrique complet, donc la première partie du théorème s'y applique et \( f\) y a un unique point fixe.
    
    Nous allons montrer la relation par récurrence. Tout d'abord pour \( n=1\) nous avons
    \begin{equation}
        \| v_1-\xi \|\leq\| v_1-u_1 \|+\| u_1-\xi \|\leq \epsilon+\frac{ k }{ 1-k }\| u_1-u_0 \|
    \end{equation}
    où nous avons utilisé l'estimation \eqref{EqlUMVGW}, qui reste valable en remplaçant \( x_1\) par \( u_1\)\footnote{Elle n'est cependant pas spécialement valable si on remplace \( x_n\) par \( u_n\).}. Nous pouvons maintenant faire la récurrence :
    \begin{subequations}
        \begin{align}
            \| v_{n+1}-\xi \|&\leq \| v_{n+1}-u_{n+1} \|+\| u_{n+1}-\xi \|\\
            &\leq \epsilon+k\| v_n-\xi \|\\
            &\leq \epsilon+k\left( \frac{ k^n }{ 1-k }\| u_1-u_0 \|+\frac{ \epsilon }{ 1-k } \right)\\
            &=\frac{ \epsilon }{ 1-k }+\frac{ k^{n+1} }{ 1-k }\| u_1-u_0 \|.
        \end{align}
    \end{subequations}
\end{proof}

\begin{remark}
    Ce théorème comporte deux parties d'intérêts différents. La première partie est un théorème de point fixe usuel, qui sera utilisé pour prouver l'existence de certaines équations différentielles.

    La seconde partie est intéressante d'un point de vie numérique. En effet, ce qu'elle nous enseigne est que si à chaque pas de calcul de la récurrence \( x_{n+1}=f(x_n)\) nous commettons une erreur d'ordre de grandeur \( \epsilon\), alors le procédé (la suite \( (v_n)\)) ne converge plus spécialement vers le point fixe, mais tend vers le point fixe avec une erreur majorée par \( \epsilon/(k-1)\).
\end{remark}

\begin{remark}
Au final l'erreur minimale qu'on peut atteindre est de l'ordre de \( \epsilon\). Évidemment si on commet une faute de calcul de l'ordre de \( \epsilon\) à chaque pas, on ne peut pas espérer mieux.
\end{remark}

\begin{remark}  \label{remIOHUJm}
    Si \( f\) elle-même n'est pas contractante, mais si \( f^p\) est contractante pour un certain \( p\in \eN\) alors la conclusion du théorème de Picard reste valide et \( f\) a le même unique point fixe que \( f^p\). En effet nommons \( x\) le point fixe de \( f\) : \( f^p(x)=x\). Nous avons alors
    \begin{equation}
        f^p\big( f(x) \big)=f\big( f^p(x) \big)=f(x),
    \end{equation}
    ce qui prouve que \( f(x)\) est un point fixe de \( f^p\). Par unicité nous avons alors \( f(x)=x\), c'est à dire que \( x\) est également un point fixe de \( f\).
\end{remark}

Si la fonction n'est pas Lipschitz mais presque, nous avons une variante.
\begin{proposition}
    Soit \( E\) un ensemble compact\footnote{Notez cette hypothèse plus forte} et si \( f\colon E\to E\) est une fonction telle que
    \begin{equation}        \label{EqLJRVvN}
        \| f(x)-f(y) \|< \| x-y \|
    \end{equation}
    pour tout \( x\neq y\) dans \( E\) alors \( f\) possède un unique point fixe.
\end{proposition}

\begin{proof}
    La suite \( x_{n+1}=f(x_n)\) possède une sous suite convergente. La limite de cette sous suite est un point fixe de \( f\) parce que \( f\) est continue. L'unicité est due à l'aspect strict de l'inégalité \eqref{EqLJRVvN}.
\end{proof}

\begin{theorem}[Équation de Fredholm]\index{Fredholm!équation}\index{équation!Fredholm}     \label{ThoagJPZJ}
    Soit \( K\colon \mathopen[ a , b \mathclose]\times \mathopen[ a , b \mathclose]\to \eR\) et \( \varphi\colon \mathopen[ a , b \mathclose]\to \eR\), deux fonctions continues. Alors si \( \lambda\) est suffisamment petit, l'équation
    \begin{equation}
        f(x)=\lambda\int_a^bK(x,y)f(y)dy+\varphi(x)
    \end{equation}
    admet une unique solution qui sera de plus continue sur \( \mathopen[ a , b \mathclose]\).
\end{theorem}

\begin{proof}
    Nous considérons l'ensemble \( \mF\) des fonctions continues \( \mathopen[ a , b \mathclose]\to\mathopen[ a , b \mathclose]\) muni de la norme uniforme. Le lemme \ref{LemdLKKnd} implique que \( \mF\) est complet. Nous considérons l'application \( \Phi\colon \mF\to \mF\) donnée par
    \begin{equation}
        \Phi(f)(x)=\lambda\int_a^bK(x,y)f(y)dy+\varphi(x). 
    \end{equation}
    Nous montrons que \( \Phi^p\) est une application contractante pour un certain \( p\). Pour tout \( x\in \mathopen[ a , b \mathclose]\) nous avons
    \begin{subequations}
        \begin{align}
            \| \Phi(f)-\Phi(g) \|_{\infty}&\leq \| \Phi(f)(x)-\Phi(g)(x) \|\\
            &=| \lambda |\Big\| \int_a^bK(x,y)\big( f(y)-g(y) \big)dy  \Big\|\\
            &\leq | \lambda |\| K \|_{\infty}| b-a |\| f-g \|_{\infty}
        \end{align}
    \end{subequations}
    Si \( \lambda\) est assez petit, et si \( p\) est assez grand, l'application \( \Phi^p\) est donc une contraction. Elle possède donc un unique point fixe par le théorème de Picard \ref{ThoEPVkCL}.
\end{proof}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Brouwer}
%---------------------------------------------------------------------------------------------------------------------------
\label{subSecZCCmMnQ}

\begin{proposition}
    Soit \( f\colon \mathopen[ a , b \mathclose]\to \mathopen[ a , b \mathclose]\) une fonction continue. Alors \( f\) accepte un point fixe.
\end{proposition}

\begin{proof}
    En effet si nous considérons \( g(x)=f(x)-x\) alors nous avons \( g(a)=f(a)-a\geq 0\) et \( g(b)=f(b)-b\leq 0\). Si \( g(a)\) ou \( g(b)\) est nul, la proposition est démontrée; nous supposons donc que \( g(a)>0\) et \( g(b)<0\). La proposition découle à présent du théorème des valeurs intermédiaires \ref{ThoValInter}.
\end{proof}

\begin{example}
    La fonction \( x\mapsto\cos(x)\) est continue entre \( \mathopen[ -1 , 1 \mathclose]\) et \( \mathopen[ -1 , 1 \mathclose]\). Elle admet donc un point fixe. Par conséquent il existe (au moins) une solution à l'équation \( \cos(x)=x\).
\end{example}

\begin{proposition}[Brouwer dans \( \eR^n\) version \(  C^{\infty}\) via Stokes]     \label{PropDRpYwv}
    Soit \( B\) la boule fermée de centre \( 0\) et de rayon \( 1\) de \( \eR^n\) et \( f\colon B\to B\) une fonction \(  C^{\infty}\). Alors \( f\) admet un point fixe.
\end{proposition}
\index{point fixe!Brouwer}

\begin{proof}
    Supposons que \( f\) ne possède pas de points fixes. Alors pour tout \( x\in B\) nous considérons la ligne droite partant de \( x\) dans la direction de \( f(x)\) (cette droite existe parce que \( x\) et \( f(x)\) sont supposés distincts). Cette ligne intersecte \( \partial B\) en un point que nous appelons \( g(x)\). Prouvons que cette fonction est \( C^k\) dès que \( f\) est \( C^k\) (y compris avec \( k=\infty\)).

   Le point \( g(x) \) est la solution du système
    \begin{subequations}
        \begin{numcases}{}
        g(x)-f(x)=\lambda\big( x-f(x) \big)\\
        \| g(x) \|^2=1\\
        \lambda\geq 0.
        \end{numcases}
    \end{subequations}
    En substituant nous obtenons l'équation
    \begin{equation}
        P_x(\lambda)=\| \lambda\big( x-f(x) \big)+f(x) \|^2-1=0,
    \end{equation}
    ou encore
    \begin{equation}
        \lambda^2\| x-f(x) \|^2+2\lambda\big( x-f(x) \big)\cdot f(x)+\| f(x) \|^2-1=0.
    \end{equation}
    En tenant compte du fait que \( \| f(x)<1 \|\) (pare que les images de \( f\) sont dans \( \mB\)), nous trouvons que \( P_x(0)\leq 0\) et \( P_x(1)\leq 0\). De même \( \lim_{\lambda\to\infty} P_x(\lambda)=+\infty\). Par conséquent le polynôme de second degré \( P_x\) a exactement deux racines distinctes \( \lambda_1\leq 0\) et \( \lambda_2\geq 1\). La racine que nous cherchons est la seconde. Le discriminant est strictement positif, donc pas besoin d'avoir peur de la racine dans
    \begin{equation}
        \lambda(x)=\frac{ -\big( x-f(x) \big)\cdot f(x)+\sqrt{   \Delta_x  } }{ \| x-f(x) \|^2 }
    \end{equation}
    où 
    \begin{equation}
        \Delta_x=4\Big( \big( x-f(x) \big)\cdot f(x) \Big)^2-4\| x-f(x) \|^2\big( \| f(x) \|^2-1 \big).
    \end{equation}
    Notons que la fonction \( \lambda(x)\) est \( C^k\) dès que \( f\) est \( C^k\); et en particulier elle est \( C^{\infty}\) si \( f\) l'est.

    En résumé la fonction \( g\) ainsi définie vérifie deux propriétés :
    \begin{enumerate}
        \item
            elle est \(  C^{\infty}\);
        \item
            elle est l'identité sur \( \partial B\).
    \end{enumerate}
    La suite de la preuve consiste à montrer qu'une telle rétraction sur \( B\) ne peut pas exister\footnote{Notons qu'il n'existe pas non plus de rétractions continues sur \( B\), mais pour le montrer il faut utiliser d'autres méthodes que Stokes, ou alors présenter les choses dans un autre ordre.}.

    Nous considérons une forme de volume \( \omega\) sur \( \partial B\) : l'intégrale de \( \omega\) sur \( \partial B\) est la surface de \( \partial B\) qui est non nulle. Nous avons alors
    \begin{equation}
        0<\int_{\partial B}\omega
        =\int_{\partial B}g^*\omega
        =\int_Bd(g^*\omega)
        =\int_Bg^*(d\omega)
        =0
    \end{equation}
    Justifications :
    \begin{itemize}
        \item 
            L'intégrale \( \int_{\partial B}\omega\) est la surface de \( \partial B\) et est donc non nulle.
        \item
            La fonction \( g\) est l'identité sur \( \partial B\). Nous avons donc \( \omega=g^*\omega\).
        \item
            Le lemme \ref{LemdwLGFG}.
        \item
            La forme \( \omega\) est de volume, par conséquent de degré maximum et \( d\omega=0\).
    \end{itemize}
\end{proof}

Un des points délicats est de se ramener au cas de fonctions \( C^{\infty}\). Pour la régularisation par convolution, voir \cite{AllardBrouwer}; pour celle utilisant le théorème de Weierstrass, voir \cite{KuttlerTopInAl}.
\begin{theorem}[Brouwer dans \( \eR^n\) version continue]\label{ThoRGjGdO}
    Soit \( B\) la boule fermée de centre \( 0\) et de rayon \( 1\) de \( \eR^n\) et \( f\colon B\to B\) une fonction continue\footnote{Une fonction continue sur un fermé de \( \eR^n\) est à comprendre pour la topologie induite.}. Alors \( f\) admet un point fixe.
\end{theorem}
\index{théorème!Brouwer}

\begin{proof}
    Nous commençons par définir une suite de fonctions
    \begin{equation}
        f_k(x)=\frac{ f(x) }{ 1+\frac{1}{ k } }.
    \end{equation}
    Nous avons \( \| f_k-f \|_{\infty}\leq \frac{1}{ 1+k }\) où la norme est la norme uniforme sur \( B\). Par le théorème de Weierstrass \ref{CORooNIUJooLDrPSv} il existe une suite de fonctions \(  C^{\infty}(B,\eR)\) que nous nommons \( g_k\) telles que
    \begin{equation}
        \|  g_k-f_k\|_{\infty}\leq\frac{1}{ 1+k }.
    \end{equation}
    Vérifions que cette fonction \( g_k\) soit bien une fonction qui prend ses valeurs dans \( B\) :
    \begin{subequations}
        \begin{align}
            \| g_k(x) \|&\leq \| g_k(x)-f_k(x) \|+\| f_k(x) \|\\
            &\leq \frac{1}{ 1+k }+\frac{ \| f(x) \| }{ 1+\frac{1}{ k } }\\
            &\leq \frac{1}{ 1+k}+\frac{1}{ 1+\frac{1}{ k } }\\
            &=1.
        \end{align}
    \end{subequations}
    Par la version \(  C^{\infty}\) du théorème (proposition \ref{PropDRpYwv}), \( g_k\) admet un point fixe que l'on nomme \( x_k\).

    Étant donné que \( x_k\) est dans le compact \( B\), quitte à prendre une sous suite nous supposons que la suite \( (x_k)\) converge vers un élément \( x\in B\). Nous montrons maintenant que \( x\) est un point fixe de \( f\) :
    \begin{subequations}
        \begin{align}
            \| f(x)-x \|&=\| f(x)-g_k(x)+g_k(x)-x_k+x_k-x \|\\
            &\leq \| f(x)-g_k(x) \| +\underbrace{\| g_k(x)-x_k \|}_{=0}+\| x_k-x \|\\
            &\leq \frac{1}{ 1+k }+\| x_k-x \|.
        \end{align}
    \end{subequations}
    En prenant le limite \( k\to\infty\) le membre de droite tend vers zéro et nous obtenons \( f(x)=x\).
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Théorème de Schauder}
%---------------------------------------------------------------------------------------------------------------------------

Une conséquence du théorème de Brouwer est le théorème de Schauder qui est valide en dimension infinie.

\begin{theorem}[Théorème de Schauder\cite{ooWWBQooKIciWi}]\index{théorème!Schauder}       \label{ThovHJXIU}
    Soit \( E\), un espace vectoriel normé, \( K\) un convexe compact de \( E\) et \( f\colon K\to K\) une fonction continue. Alors \( f\) admet un point fixe.
\end{theorem}
\index{théorème!Schauder}
\index{point fixe!Schauder}

\begin{proof}
    Étant donné que \( f\colon K\to K\) est continue, elle y est uniformément continue. Si nous choisissons \( \epsilon\) alors il existe \( \delta>0\) tel que 
    \begin{equation}
        \| f(x)-f(y) \|\leq \epsilon
    \end{equation}
    dès que \( \| x-y \|\leq \delta\). La compacité de \( K\) permet de choisir un recouvrement fini par des ouverts de la forme
    \begin{equation}    \label{EqKNPUVR}
        K\subset \bigcup_{1\leq i\leq p}B(x_j,\delta)
    \end{equation}
    où \( \{ x_1,\ldots, x_p \}\subset K\). Nous considérons maintenant \( L=\Span\{ f(x_j)\tq 1\leq j\leq p \}\) et
    \begin{equation}
        K^*=K\cap L.
    \end{equation}
    Le fait que \( K\) et \( L\) soient convexes implique que \( K^*\) est convexe. L'ensemble \( K^*\) est également compact parce qu'il s'agit d'une partie fermée de \( K\) qui est compact (lemme \ref{LemnAeACf}). Notons en particulier que \( K^*\) est contenu dans un espace vectoriel de dimension finie, ce qui n'est pas le cas de \( K\).

    Nous allons à présent construire une sorte de partition de l'unité subordonnée au recouvrement \eqref{EqKNPUVR} sur \( K\) (voir le lemme \ref{LemGPmRGZ}). Nous commençons par définir
    \begin{equation}
        \psi_j(x)=\begin{cases}
            0    &   \text{si } \| x-x_j \|\geq \delta\\
            1-\frac{ \| x-x_j \| }{ \delta }    &    \text{sinon}.
        \end{cases}
    \end{equation}
    pour chaque \( 1\leq j\leq p\). Notons que \( \psi_j\) est une fonction positive, nulle en-dehors de \( B(x_j,\delta)\). En particulier la fonction suivante est bien définie :
    \begin{equation}
        \varphi_j(x)=\frac{ \psi_j(x) }{ \sum_{k=1}^p\psi_k(x) }
    \end{equation}
    et nous avons \( \sum_{j=1}^p\varphi_j(x)=1\). Les fonctions \( \varphi_j\) sont continues sur \( K\) et nous définissons finalement
    \begin{equation}
        g(x)=\sum_{j=1}^p\varphi_j(x)f(x_j).
    \end{equation}
    Pour chaque \( x\in K\), l'élément \( g(x)\) est une combinaison des éléments \( f(x_j)\in K^*\). Étant donné que \( K^*\) est convexe et que la somme des coefficients \( \varphi_j(x)\) vaut un, nous avons que \( g\) prend ses valeurs dans \( K^*\) par la proposition \ref{PropPoNpPz}.

    Nous considérons seulement la restriction \( g\colon K^*\to K^*\) qui est continue sur un compact contenu dans un espace vectoriel de dimension finie. Le théorème de Brouwer nous enseigne alors que \( g\) a un point fixe (proposition \ref{ThoRGjGdO}). Nous nommons \( y\) ce point fixe. Notons que \( y\) est fonction du \( \epsilon\) choisit au début de la construction, via le \( \delta\) qui avait conditionné la partition de l'unité.

    Nous avons
    \begin{subequations}        \label{EqoXuTzE}
        \begin{align}
            f(y)-y&=f(y)-g(y)\\
            &=\sum_{j=1}^p\varphi_j(y)f(y)-\sum_{j=1}^p\varphi_j(y)f(x_j)\\
            &=\sum_{j=1}^p\varphi(j)(y)\big( f(y)-f(x_j) \big).
        \end{align}
    \end{subequations}
    Par construction, \( \varphi_j(y)\neq 0\) seulement si \( \| y-x_j \|\leq \delta\) et par conséquent seulement si \( \| f(y)-f(x_j) \|\leq \epsilon\). D'autre par nous avons \( \varphi_j(y)\geq 0\); en prenant la norme de \eqref{EqoXuTzE} nous trouvons
    \begin{equation}
        \| f(y)-y \|\leq \sum_{j=1}^p\| \varphi_j(y)\big( f(y)-f(x_j) \big) \|\leq \sum_{j=1}^p\varphi_j(y)\epsilon=\epsilon.
    \end{equation}
    Nous nous souvenons maintenant que \( y\) était fonction de \( \epsilon\). Soit \( y_m\) le \( y\) qui correspond à \( \epsilon=2^{-m}\). Nous avons alors
    \begin{equation}
        \| f(y_m)-y_m \|\leq 2^{-m}.
    \end{equation}
    L'élément \( y_m\) est dans \( K^*\) qui est compact, donc quitte à choisir une sous suite nous pouvons supposer que \( y_m\) est une suite qui converge vers \( y^*\in K\)\footnote{Notons que même dans la sous suite nous avons \( \| f(y_m)-y_m \|\leq 2^{-m}\), avec le même «\( m\)» des deux côtés de l'inégalité.}. Nous avons les majorations
    \begin{equation}
        \| f(y^*)-y^* \|\leq \| f(y^*)-f(y_m) \|+\| f(y_m)-y_m \|+\| y_m-y^* \|.
    \end{equation}
    Si \( m\) est assez grand, les trois termes du membre de droite peuvent être rendus arbitrairement petits, d'où nous concluons que
    \begin{equation}
        f(y^*)=y^*
    \end{equation}
    et donc que \( f\) possède un point fixe.
\end{proof}


%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Théorème de Markov-Kakutani et mesure de Haar}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}
    Soit \( G\) un groupe topologique. Une \defe{mesure de Haar}{mesure!de Haar} sur \( G\) est une mesure \( \mu\) telle que 
    \begin{enumerate}
        \item
            \( \mu(gA)=\mu(A)\) pour tout mesurable \( A\) et tout \( g\in G\),
        \item
            \( \mu(K)<\infty\) pour tout compact \( K\subset G\).
    \end{enumerate}
    Si de plus le groupe \( G\) lui-même est compact nous demandons que la mesure soit normalisée : \( \mu(G)=1\).
\end{definition}

Le théorème suivant nous donne l'existence d'une mesure de Haar sur un groupe compact.
\begin{theorem}[Markov-Katutani\cite{BeaakPtFix}]\index{théorème!Markov-Takutani}   \label{ThoeJCdMP}
    Soit \( E\) un espace vectoriel normé et \( L\), une partie non vide, convexe, fermée et bornée de \( E'\). Soit \( T\colon L\to L\) une application continue. Alors \( T\) a un point fixe.
\end{theorem}

\begin{proof}
    Nous considérons un point \( x_0\in L\) et la suite
    \begin{equation}
        x_n=\frac{1}{ n+1 }\sum_{i=0}^n T^ix_0.
    \end{equation}
    La somme des coefficients devant les \( T^i(x_0)\) étant \( 1\), la convexité de \( L\) montre que \( x_n\in L\). Nous considérons l'ensemble
    \begin{equation}
        C=\bigcap_{n\in \eN}\overline{ \{ x_m\tq m\geq n \} }.
    \end{equation}
    Le lemme \ref{LemooynkH} indique que \( C\) n'est pas vide, et de plus il existe une sous suite de \( (x_n)\) qui converge vers un élément \( x\in C\). Nous avons
    \begin{equation}
        \lim_{n\to \infty} x_{\sigma(n)}(v)=x(v)
    \end{equation}
    pour tout \( v\in E\). Montrons que \( x\) est un point fixe de \( T\). Nous avons
    \begin{subequations}
        \begin{align}
            \| (Tx_{\sigma(k)}-x_{\sigma(k)})v \|&=\Big\| T\frac{1}{ 1+\sigma(k) }\sum_{i=0}^{\sigma(k)}T^ix_0(v)-\frac{1}{ 1+\sigma(k) }\sum_{i=0}^{\sigma(k)}T^ix_0(v) \Big\|\\
            &=\Big\| \frac{1}{ 1+\sigma(k) }\sum_{i=0}^{\sigma(k)}T^{i+1}x_0(v)-T^ix_0(v) \Big\|\\
            &=\frac{1}{ 1+\sigma(k) }\big\| T^{\sigma(k)+1}x_0(v)-x_0(v) \big\|\\
            &\leq\frac{ 2M }{ \sigma(k)+1 }
        \end{align}
    \end{subequations}
    où \( M=\sum_{y\in L}\| y(v) \|<\infty\) parce que \( L\) est borné. En prenant \( k\to\infty\) nous trouvons
    \begin{equation}
        \lim_{k\to \infty} \big( Tx_{\sigma(k)}-x_{\sigma(k)} \big)v=0,
    \end{equation}
    ce qui signifie que \( Tx=x\) parce que \( T\) est continue.
\end{proof}

Le théorème suivant est une conséquence du théorème de Markov-Katutani.
\begin{theorem} \label{ThoBZBooOTxqcI}
    Si \( G\) est un groupe topologique compact possédant une base dénombrable de topologie alors \( G\) accepte une unique mesure de Haar normalisée. De plus elle est unimodulaire :
    \begin{equation}
        \mu(Ag)=\mu(gA)=\mu(A)
    \end{equation}
    pour tout mesurables \( A\subset G\) et tout élément \( g\in G\).
\end{theorem}
\index{mesure!de Haar}


%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Théorèmes de point fixes et équations différentielles}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Théorème de Cauchy-Lipschitz}
%---------------------------------------------------------------------------------------------------------------------------

Nous démontrons ici deux théorèmes de Cauchy-Lipschitz. De nombreuses propriétés annexes seront démontrées dans le chapitre sur les équations différentielles, section \ref{SECooNKICooDnOFTD}.

\begin{theorem}[Cauchy-Lipschitz\cite{SandrineCL,ZPNooLNyWjX}] \label{ThokUUlgU}
    Nous considérons l'équation différentielle
    \begin{subequations}        \label{XtiXON}
        \begin{numcases}{}
            y'(t)=f\big( t,y(t) \big)\\
            y(t_0)=y_0
        \end{numcases}
    \end{subequations}
    avec \( f\colon U=I\times \Omega\to \eR^n\) où \( I\) est ouvert dans \( \eR\) et \( \Omega\) ouvert dans \( \eR^n\). Nous supposons que \( f\) est continue sur \( U\) et localement Lipschitz\footnote{Définition \ref{DefJSFFooEOCogV}. Notons que nous ne supposons pas que \( f\) soit une contraction.} par rapport à \( y\). 
    
    Alors il existe un intervalle \( J\subset I\) sur lequel la solution au problème est unique. De plus toute solution du problème est une restriction de cette solution à une partie de \( J\). La solution sur \( J\) (dite «solution maximale») est de classe \( C^1\).
\end{theorem}
\index{théorème!Cauchy-Lipschitz}

% Il serait tentant de mettre ce théorème dans la partie sur les équations différentielles, mais ce n'est pas aussi simple :
% Il est utilisé pour calculer la transformée de Fourier de la Gaussienne (lemme LEMooPAAJooCsoyAJ) dans le chapitre sur la transformée de Fourier.

\begin{proof}
    Nous divisions la preuve en plusieurs étapes (même pas toutes simples).
    \begin{subproof}
    \item[Cylindre de sécurité et espace fonctionnel]

    Précisons l'espace fonctionnel \( \mF\) adéquat. Soient \( V\) et \( W\) les voisinages de \( t_0\) et \( y_0\) sur lesquels \( f\) est localement Lipschitz. Nous considérons les quantités suivantes :
    \begin{enumerate}
        \item
            \( M=\sup_{V\times W}f\) ;
        \item
            \( r>0\) tel que \( \overline{ B(y_0,r) }\subset V\)
        \item
            \( T>0\) tel que \( \overline{ B(t_0,T) }\subset W\) et \( T<r/M\).
    \end{enumerate}
    Nous considérons alors l'ensemble
    \begin{equation}
        \mF=C^0\big( \overline{ B(t_0,T) },\overline{ B(y_0,r) } \big)
    \end{equation}
    que nous munissons de la norme uniforme. Par le lemme \ref{LemdLKKnd} l'espace \( \big( \mF,\| . \|_{\infty} \big)\) est complet.

    \item[Une application \( \Phi\colon \mF\to \mF\)]


    Si \( y\) est une solution de l'équation différentielle considérée, elle vérifie
    \begin{equation}        \label{EqPGLwcL}
        y(t)=y_0+\int_{t_0}^tf\big( u,y(u) \big)du.
    \end{equation}
    Ceci nous incite à considérer l'opérateur \( \Phi\colon \mF\to \mF\) défini par
    \begin{equation}
        \Phi(y)(t)=y_0+\int_{t_0}^tf\big( u,y(u) \big)du.
    \end{equation}

    Pour que l'application \( \Phi\) soit utile nous devons montrer que pour tout \( y\in \mF\),
    \begin{itemize}
        \item l'application \( \Phi(y)\) est bien définie,
        \item pour tout \( t\in\overline{ B(y_0,r) }\) nous avons \( \Phi(y)(t)\in\overline{ B(t_0,T) }\),
        \item l'application $\Phi(y)\colon    \overline{ B(t_0,T) }\to \overline{ B(y_0,r)} $ est continue.
    \end{itemize}
    Attention : nous ne prétendons pas que \( \Phi\) elle-même soit continue. C'est parti.
    \begin{subproof}
    \item[\( \Phi(y)\) est bien définie]
            
        Il faut montrer que l'intégrale converge. Le calcul de \( \Phi(y)(t)\) ne se fait qu'avec \( t\in \overline{ B(t_0,T) }\). Vu que \( u\) prend ses valeurs dans \( \mathopen[ t_0 , t \mathclose]\) et que \( y\in\mF\), le nombre \( y(u)\) est toujours dans \( \overline{ B(y_0,r) }\). Ceci pour dire que dans l'intégrale, la fonction \( f\) n'est considérée que sur \( \mathopen[ t_0 , t \mathclose]\times \overline{ B(y_0,r) }\subset V\times W\). La fonction \( f\) est donc uniformément majorable, et l'intégrale ne pose pas de problèmes.

    \item[\( \Phi(y)(t)\in \overline{ B(t_0,T) }\)]

    Prouvons que \( \Phi(y)(t)\in\overline{ B(y_0,r) }\). Pour cela, notons que
    \begin{equation}
        | \Phi(y)(t)-y_0 |\leq \int_{t_0}^t |f\big( u,y(u) \big)|du\leq | t-t_0 |\| f \|_{\infty}.
    \end{equation}
    Étant donné que \( t\in\overline{ B(t_0,T) }\) nous avons \( | t-t_0 |\leq r/M\) et donc \( | \Phi(y)(t)-y_0 |\leq r\).

    \item[\( \Phi(y)\) est continue]

        Nous pourrions invoquer le théorème \ref{ThoKnuSNd}, mais nous allons le faire à la main. Soit \( s_0\in B(t_0,T)\) et prouvons que \( \Phi(y)\) est continue en \( s_0\). Pour cela nous prenons \( s\in B(s_0,\delta)\) et nous calculons :
        \begin{equation}
            | \Phi(y)(s)-\Phi(y)(s_0) |\leq \int_{s_0}^s|f\big( u,y(u) \big)|du\leq | s_0-s |\| f \|_{\infty}.
        \end{equation}
        C'est le fait que \( f\) soit bornée dans le cylindre de sécurité qui fait en sorte que cela tende vers zéro lorsque \( s\to s_0\).
    \end{subproof}


    
    L'équation \eqref{EqPGLwcL} signifie que \( y\) est un point fixe de \( \Phi\). L'espace \( \mF\) étant complet le théorème de point fixe de Picard (théorème \ref{ThoEPVkCL}) s'applique. Nous allons montrer qu'il existe un \( p\in\eN\) tel que \( \Phi^p\) soit contractante. Par conséquent \( \Phi^p\) aura un unique point fixe qui sera également unique point fixe de \( \Phi\) par la remarque \ref{remIOHUJm}.
    
\item[Contractante]

    Prouvons donc que \( \Phi^p\) est contractante pour un certain \( p\). Pour cela nous commençons par montrer la formule suivante par récurrence :
    \begin{equation}        \label{EqRAdKxT}
        \big\| \Phi^p(x)(t)-\Phi^p(y)(t) \big\|\leq \frac{ k^p| t-t_0 |^p }{ p! }\| x-y \|_{\infty}
    \end{equation}
    pour tout \( x,y\in\mF\), et pour tout \( t\in\overline{ B(t_0,T) }\). Pour \( p=0\) la formule \eqref{EqRAdKxT} est vérifiée parce que \( \| x-y \|_{\infty}\) est le supremum de \( \| x(t)-y(t) \|\) pour \( t\in\overline{ B(t_0,T) }\). Supposons que la formule soit vraie pour \( p\) et calculons pour \( p+1\). Pour tout \( t\in\overline{ B(t_0,T) }\) nous avons
    \begin{subequations}
        \begin{align}
            \big\| \Phi^{p+1}(x)(t)-\Phi^{p+1}(y)(t) \big\|&\leq \left| \int_{t_0}^t\big\| f\big( u,\Phi^p(x)(u) \big)-f\big( u,\Phi^p(y)(u) \big) \big\|du \right| \\
            &\leq \left| \int_{t_0}^tk\| \Phi^p(x)(u)-\Phi^p(y)(u) \|du \right|    \label{subIKYixF}\\
            &\leq \left| \int_{t_0}^tk\frac{ k^p| t-t_0 | }{ p! }\| x-y \|_{\infty} \right| \label{subxkNjiV} \\
            &=\frac{ k^{p+1}| t-t_0 |^{p+1} }{ (p+1)! }\| x-y \|_{\infty}.
        \end{align}
    \end{subequations}
    Justifications :
    \begin{itemize}
        \item \eqref{subIKYixF} parce que \( f\) est Lipschitz.
        \item \eqref{subxkNjiV} par hypothèse de récurrence.
    \end{itemize}
    La formule \eqref{EqRAdKxT} est maintenant établie. Nous pouvons maintenant montrer que \( \Phi^p\) est une contraction pour un certain \( p\). Pour tout \( t\in \overline{ B(t_0,T) }\) nous avons
    \begin{equation}
         \| \Phi^p(x)(t)-\Phi^p(y)(t) \|\leq \frac{ k^p }{ t! }| t-t_0 |^p\| x-y \|_{\infty}     \leq \frac{ k^pT^p }{ p! }\| x-y \|_{\infty}
    \end{equation}
    où nous avons utilisé le fait que \( | t-t_0 |^p<T^p\). En prenant le supremum sur \( t\) des deux côtés il vient
    \begin{equation}
        \| \Phi^p(x)-\Phi^p(y) \|_{\infty}\leq\frac{ k^pT^p }{ p! }\| x-y \|_{\infty}.
    \end{equation}
    Le membre de droite tend vers zéro lorsque \( p\to\infty\) parce que \( k<1\) et \( T^p/p!\to 0\)\footnote{C'est le terme général du développement de \(  e^{T}\) qui est une série convergente.}. Nous concluons donc que \( \Phi^p\) est une contraction pour un certain \( p\).

\item[Conclusion]

    L'unique point fixe de \( \Phi\) est alors l'unique solution continue de l'équation différentielle \eqref{XtiXON}. Par ailleurs l'équation elle-même \( y'=f(t,y)\) demande implicitement que \( y\) soit dérivable et donc continue. Nous concluons que l'unique point fixe de \( \Phi\) est l'unique solution de l'équation différentielle donnée. Cette dernière est automatiquement \( C^1\) parce que si \( y\) est continue alors \( u\mapsto f(u,y(u))\) est continue, c'est à dire que \( y'\) est continue.

\item[Unicité]

    Nous passons maintenant à la partie «prolongement maximum» du théorème. Soient \( x_1\) et \( x_2\) deux solutions maximales du problème \eqref{XtiXON} sur des intervalles \( I_1\) et \( I_2\) respectivement. Les intervalles \( I_1\) et \( I_2\) contiennent \( \overline{ B(t_0,r) }\) sur lequel \( x_1=x_2\) par unicité.
    
    
    Nous allons maintenant montrer que pour tout \( t\geq t_0\) pour lequel \( x_1\) ou \( x_2\) est défini, \( x_1(t)\) et \( x_2(t)\) sont définis et sont égaux. Le raisonnement sur \( t\leq t_0\) est similaire.
    
    Supposons que l'ensemble des \( t\geq t_0\) tels que \( x_1=x_2\) soit ouvert à droite, c'est à dire soit de la forme \( \mathopen[ t_0 ,b [\). Dans ce cas, soit \( x_1\) soit \( x_2\) (soit les deux) cesse d'exister en \( b\). En effet si nous avions les fonctions \( x_i\) sur \(\mathopen[ t_0 , b+\epsilon [\) alors l'équation \( x_1=x_2\) définirait un fermé dans \( \mathopen[ t_0 , b+\epsilon [\). Supposons pour fixer les idées que \( x_1\) cesse d'exister : le domaine de \( x_1\) (parmi les \( t\geq 0\)) est \( \mathopen[ t_0 , b [\) et sur ce domaine nous avons \( x_1=x_2\). Dans ce cas \( x_1\) pourrait être prolongé en \( x_2\) au-delà de \( b\). Si \( x_1\) et \( x_2\) s'arrêtent d'exister en même temps en \( b\), alors nous avons bien \( x_1=x_2\).

    Nous devons donc traiter le cas où \( x_1=x_2\) sur \( \mathopen[ t_0 , b \mathclose]\) alors que \( x_1\) et \( x_2\) existent sur \( \mathopen[ t_0 , b+\epsilon [\) pour un certain \( \epsilon\).

    Nous pouvons appliquer le théorème d'existence locale au problème
    \begin{subequations}
        \begin{numcases}{}
            y'=f(t,y)\\
            y(b)=x_1(b).
        \end{numcases}
    \end{subequations}
    Il existe un voisinage de \( b\) sur lequel la solution est unique. Sur ce voisinage nous devons donc avoir \( x_1=x_2\), ce qui contredit le fait que \( x_1\neq x_2\) en dehors de \( \mathopen[ t_0 , b \mathclose]\).

    Donc \( x_1\) et \( x_2\) existent et sont égaux sur au moins \( I_1\cup I_2\).
    \end{subproof}
\end{proof}

Le théorème de Cauchy-Lipschitz donne existence et unicité d'une solution maximale. Cependant cette solution peut ne pas exister partout où les hypothèses sur \( f\) sont remplies. En d'autres termes, il peut arriver que \( f\) soit Lipschitz jusqu'à \( t_1\), mais que la solution maximale ne soit définie que jusqu'en \( t_2<t_1\). Ce cas fait l'objet du théorème d'explosion en temps fini \ref{CorGDJQooNEIvpp}.

Sous quelque hypothèses nous pouvons nous assurer de l'existence d'une solution unique sur tout \( \eR\).

\begin{theorem}[Cauchy-Lipschitz global\cite{ooJZJPooAygxpk,KXjFWKA}]       \label{THOooZIVRooPSWMxg}
    Soit un intervalle \( I\) de \( \eR\), \( y_0\in \eR^n\), \( t_0\in I\) et une fonction continue \( f\colon I\times \eR^n\to \eR^n\) telle que pour tout compact \( K\) dans \( I\), il existe \( k>0\) tel que
    \begin{equation}
        \| f(t,y_1)-f(t,y_2) \|\leq k\| y_1-y_2 \|
    \end{equation}
    pour tout \( t\in K\) et \( y_1,y_2\in \eR^n\).

    Alors le problème
    \begin{subequations}        \label{EQSooBNREooUTfbMH}
        \begin{numcases}{}
            y'(t)=f\big( t,y(t) \big)\\
            y(t_0)=y_0
        \end{numcases}
    \end{subequations}
    possède une unique solution \( y\colon I\to \eR^n\) sur \( I\).
\end{theorem}

\begin{proof}
    Soit un intervalle compact \( K\) dans \( I\) et contenant \( t_0\). Nous notons \( \ell\) le diamètre de \( K\). Sur l'espace \( E=C^0(K,\eR^n)\) nous considérons la topologie uniforme : \( (E,\| . \|_{\infty})\). C'est un espace complet par le lemme \ref{LemdLKKnd} (nous utilisons le fait que \( \eR^n\) soit complet, théorème \ref{ThoTFGioqS}). Nous allons utiliser l'application suivante :
    \begin{equation}        \label{EQooJUTBooILBKoE}
        \begin{aligned}
            \Phi\colon E&\to E \\
            \Phi(y)(t)&=y_0+\int_{t_0}^tf\big( s,y(s) \big)ds
        \end{aligned}
    \end{equation}
    Démontrons quelque faits à propos de \( \Phi\).
    \begin{subproof}
        \item[La définition fonctionne bien]
            Nous devons commencer par prouver que cette application est bien définie. Si \( y\in E\) alors \( f\) et \( y\) sont continues; l'application \( s\mapsto f\big(s,y(s)\big)\) est donc également continue. L'intégrale de cette fonction sur le compact \( \mathopen[ t_0 , t \mathclose]\) ne pose alors pas de problèmes. En ce qui concerne la continuité de \( \phi(y)\) sous l'hypothèse que \( y\) soit continue,
    \begin{equation}
        \| \Phi(y)(t)-\Phi(y)(t') \|\leq \int_t^{t'}\| f(s,y(s)) \|ds\leq M| t-t' |
    \end{equation}
    où \( M\) est une majoration de \( \| s\mapsto f\big( s,y(s) \big) \|_{\infty,K}\).

        \item[Si \( y\) est solution alors \( \Phi(y)=y\)]

            Supposons que \( y\) soit une solution de l'équation différentielle \eqref{EQSooBNREooUTfbMH}. Alors, vu que \( y'(t)=f\big( t,y(t) \big)\) nous avons :
            \begin{equation}
                y(t)=y_0+\int_{t_0}^ty'(s)ds=y_0+\int_{t_0}^tf\big( s,y(s) \big)ds=\Phi(y)(t).
            \end{equation}
            
        \item[Si \( \Phi(y)=y\) alors \( y\) est solution]

            Nous avons, pour tout \( t\) :
            \begin{equation}
                y(t)=y_0+\int_{t_0}^tf\big( s,y(s) \big)ds.
            \end{equation}
            Le membre de droite est dérivable par rapport à \( t\), et la dérivée fait \(  f\big( t,y(t) \big)   \). Donc le membre de gauche est également dérivable et nous avons bien
            \begin{equation}
                y'(t)=f\big( t,y(t) \big).
            \end{equation}
            De plus \( y(t_0)=y_0+\int_{t_0}^{t_0}\ldots=y_0\).
    \end{subproof}
    
    Nous sommes encore avec \( K\) compact et \( E=C^0(K,\eR^n)\) muni de la norme uniforme. Nous allons montrer que \( \Phi\) est une contraction de \( E\) pour une norme bien choisie.

    \begin{subproof}
        \item[Une norme sur \( E\)]
            Pour \( y\in E\) nous posons
            \begin{equation}
                \| y \|_k=\max_{t\in K}\big(  e^{-k| t-t_0 |}\| y(t) \| \big).
            \end{equation}
            Ce maximum est bien définit et fini parce que la fonction de \( t\) dedans est une fonction continue sur le compact \( K\). Cela est également une norme parce que si \( \| y \|_k=0\) alors \(  e^{-k| t-t_0 |}\| y(t) \|=0\) pour tout \( t\). Étant donné que l'exponentielle ne s'annule pas, \( \| y(t) \|=0\) pour tout \( t\).
        \item[Équivalence de norme]

            Nous montrons que les normes \( \| . \|_k\) et \( \| . \|_{\infty}\) sont équivalentes\footnote{Définition \ref{DefEquivNorm}} :
            \begin{equation}        \label{EQooSQYWooBTXvDL}
                \| y \|_{\infty} e^{-k\ell}\leq \| y \|_k\leq \| y \|_{\infty}
            \end{equation}
            pour tout \( y\in E\). Pour la première inégalité, \( \ell\geq | t-t_0 |\) pour tout \( t\in K\), et \( k>0\), donc
            \begin{equation}
                \| y(t) \| e^{-k\ell}\leq  e^{-k| t-t_0 |}\| y(t) \|.
            \end{equation}
            En prenant le maximum des deux côtés, \( \| y \|_{\infty} e^{-k\ell}\leq \| y \|_k\). 

            En ce qui concerne la seconde inégalité dans \eqref{EQooSQYWooBTXvDL}, \( k| t-t_0 |\geq 0\) et donc \(  e^{-k| t-t_0 |}<1\).

    \end{subproof}
    Vu que les normes \( \| . \|_{\infty}\) et \( \| . \|_k\) sont équivalentes, l'espace \( (E,\| . \|_k)\) est tout autant complet que \( (E,\| . \|_{\infty})\). Nous démontrons à présent que \( \Phi\) est une contraction dans \( (E,\|  \|_k)\). 

    Soient \( y,z\in E\). Si \( t\geq t_0\) nous avons
    \begin{subequations}        \label{SUBEQSooEXVYooDkyTuB}
        \begin{align}
            \| \Phi(y)(t)-\Phi(z)(t) \|&\leq \int_{t_0}^t\| f\big( s,y(s) \big)-f\big( s,z(s) \big) \|ds\\
            &\leq k\int_{t_0}^t\| y(s)-z(s) \|ds.
        \end{align}
    \end{subequations}
    Il convient maintenant de remarquer que
    \begin{equation}
        \| y(t) \|= e^{-k| t-t_0 |} e^{k| t-t_0 |}\| y(t) \|\leq \| y \|_k e^{k| t-t_0 |}.
    \end{equation}
    Nous pouvons avec ça prolonger les inégalités \eqref{SUBEQSooEXVYooDkyTuB} par
    \begin{equation}
        \| \Phi(y)(t)-\Phi(z)(t) \|\leq k\| y-z \|_k\int_{t_0}^t e^{k| s-t_0 |}ds=k\| y-z \|_k\int_{t_0}^t e^{k(s-t_0)}ds
    \end{equation}
    où nous avons utilisé notre supposition \( t\geq t_0\) pour éliminer les valeurs absolues. L'intégrale peut être faite explicitement, mais nous en sommes arrivés à un niveau de fainéantise tellement inconcevable que

\lstinputlisting{tex/sage/sageSnip014.sage}

Au final, si \( t\geq t_0\),
    \begin{equation}
        \| \Phi(y)(t)-\Phi(z)(t) \|\leq \| y-z \|_k\big(  e^{k(t-t_0)}-1 \big).
    \end{equation}
    Si \( t\leq t_0\), il faut retourner les bornes de l'intégrale avant d'y faire rentrer la norme parce que \( \| \int_0^1f \|\leq \int_0^1\| f \|\), mais ça ne marche pas avec \( \| \int_1^0f \|\). Pour \( t\leq t_0\) tout le calcul donne
    \begin{equation}
        \| \Phi(y)(t)-\Phi(z)(t) \|\leq \| y-z \|_k\big(  e^{k(t_0-t)}-1 \big).
    \end{equation}
    Les deux inéquations sont valables a fortiori en mettant des valeurs absolues dans l'exponentielle, de telle sorte que pour tout \( t\in K\) nous avons
    \begin{equation}
        e^{-k| t_0-t |}\| \phi(y)(t)-\Phi(z)(t) \|\leq \| y-z \|_k\big( 1- e^{-k| t_0-t |} \big).
    \end{equation}
    En prenant le supremum sur \( t\),
    \begin{equation}
        \| \Phi(y)-\Phi(z) \|_k\leq \| y-z \|_k(1- e^{-k\ell}),
    \end{equation}
    mais \( 0<(1- e^{e-k\ell})<1\), donc \( \Phi\) est contractante pour la norme \( \| . \|_k\). Vu que \( (E,\| . \|_k)\) est complet, l'application \( \Phi\) y a un unique point fixe par le théorème de Picard \ref{ThoEPVkCL}.

    Ce point fixe est donc l'unique solution de l'équation différentielle de départ.

    \begin{subproof}
        \item[Existence et unicité sur \( I\)]
            Il nous reste à prouver que la solution que nous avons trouvée existe sur \( I\) : jusqu'à présent nous avons démontré l'existence et l'unicité sur n'importe quel compact dans \( I\).

            Soit une suite croissante de compacts \( K_n\) contenant \( t_0\) (par exemple une suite exhaustive comme celle du lemme \ref{LemGDeZlOo}). Nous avons en particulier
            \begin{equation}
                I=\bigcup_{n=0}^{\infty}K_n.
            \end{equation}
        \item[Existence sur \( I\)]
        
            Soit \( y_n\) l'unique solution sur \( K_n\). Il suffit de poser
            \begin{equation}
                y(t)=y_n(t)
            \end{equation}
            pour \( n\) tel que \( t\in K_n\). Cette définition fonctionne parce que si \( t\in K_n\cap K_m\), il y a forcément un des deux qui est inclus dans l'autre et le résultat d'unicité sur le plus grand des deux donne \( y_n(t)=y_m(t)\).

        \item[Unicité sur \( I\)]

            Soient \( y\) et \(z \) des solutions sur \( I\); vu que \( I\) n'est pas spécialement compact, le travail fait plus haut ne permet pas de conclure que \( y=z\). 

            Soit \( t\in I\). Alors \( t\in K_n\) pour un certain \( n\) et \( y\) et \( z\) sont des solutions sur \( K_n\) qui est compact. L'unicité sur \( K_n\) donne \( y(t)=z(t)\).
    \end{subproof}
\end{proof}

\begin{normaltext}
    Il y a d'autres moyens de prouver qu'une solution existe globalement sur \( \eR\). Si \( f\) est globalement bornée, le théorème d'explosion en temps fini donne quelque garanties, voir \ref{NORMooZROGooZfsdnZ}.
\end{normaltext}

Le théorème suivant donne une version du théorème de Cauchy-Lipschitz lorsque la fonction \( f\) dépend d'un paramètre. Ce théorème n'utilise rien de fondamentalement nouveau. Nous le donnons seulement pour montrer que l'on peut choisir l'espace \( \mF\) de façon un peu maligne pour élargir le résultat. Si vous voulez un théorème de Cauchy-Lipschitz avec paramètre vraiment intéressant, allez voir le théorème \ref{PROPooPYHWooIZhQST}.

\begin{theorem}[Cauchy-Lipschitz avec paramètre\cite{MonCerveau,ooXVPAooTQUIRw}]           \label{THOooDTCWooSPKeYu}
    Soit un intervalle ouvert \( I\) de \( \eR\), un connexe ouvert \( \Omega\) de \( \eR^n\) et un intervalle ouvert \( \Lambda\) de \( \eR^d\). Soit une fonction \( f\colon I\times \Omega\times \Lambda\to \eR^n\) continue et localement Lipschitz en \( \Omega\). Soient \( t_0\in I\), \( y_0\in \Omega\) et \( \lambda_0\in \Lambda\). Il existe un voisinage compact de \( (t_0,y_0,\lambda_0)\) sur lequel le problème
    \begin{subequations}
        \begin{numcases}{}
            y'_{\lambda}(t)=f\big( t,y_{\lambda}(t),\lambda \big)\\
            y_{\lambda}(t_0)=y_0
        \end{numcases}
    \end{subequations}
    possède une unique solution. De plus \( (t,\lambda)\mapsto y_{\lambda}(t)\) est continue\footnote{Ici, la surprise est que ce soit continu par rapport à \( \lambda\). Le fait qu'elle le soit par rapport à \( t\) est clair depuis le départ parce que c'est finalement rien d'autre que le Cauchy-Lipschitz vieux et connu.}.
\end{theorem}

\begin{proof}

    \begin{probleme}
        Ceci est une idée de la preuve. Je n'ai pas vérifié toutes les étapes. Soyez prudent.

    \end{probleme}

    D'abord nous avons un voisinage compact \( V\times \overline{ B(y_0,r) }\times \Lambda_0\) de \( (t_0,y_0,\lambda_0)\) sur lequel $f$ est bornée. Ensuite nous récrivons l'équation différentielle sous la forme
    \begin{subequations}
        \begin{numcases}{}
            \frac{ \partial y }{ \partial t }(t,\lambda)=f\big( t,y(t,\lambda),\lambda \big)\\
            y(t_0,\lambda)=y_0.
        \end{numcases}
    \end{subequations}
    pour une fonction \( y\colon V\times \Lambda_0\to \eR^n\).

    Nous posons \( \mF=C^0\big( V\times\Lambda_0 ,\eR^n\big)\) et nous y définissons l'application
    \begin{equation}
        \begin{aligned}
            \Phi\colon \mF&\to \mF \\
            \Phi(y)(t,\lambda)&=y_0+\int_{t_0}^tf\big( s,y(s,\lambda),\lambda \big)ds. 
        \end{aligned}
    \end{equation}
    Il y a plein de vérifications à faire\cite{ooXVPAooTQUIRw}, mais je parie que \( \Phi\) est bien définie, et que une de ses puissances est une contraction de \( (\mF,\| . \|_{\infty})\). L'unique point fixe est une solution de notre problème et est dans \( C^0\), donc \( (t,\lambda)\mapsto y(t,\lambda)=y_{\lambda}(t)\) est de classe \( C^0\), c'est à dire continue.
\end{proof}

\begin{normaltext}
    Ce théorème marque un peu la limite de ce que l'on peut faire avec la méthode des points fixes dans le cadre de Cauchy-Lipschitz : nous sommes limités à la continuité de la solution parce que les espaces \( C^p\) ne sont pas complets\footnote{Par exemple, le théorème de Stone-Weierstrass \ref{ThoGddfas} nous dit que la limite uniforme de polynômes (de classe \(  C^{\infty}\)) peut n'être que continue. Voir aussi le thème \ref{THMooOCXTooWenIJE}.}. Il n'y a donc pas d'espoir d'adapter la méthode pour prouver que si \( f\) est de classe \( C^p\) alors \( (t,\lambda)\mapsto y_{\lambda}(t)\) est de classe \( C^p\). On peut, à \( \lambda\) fixé prouver que \( t\mapsto y_{\lambda}(t)\) est de classe \( C^p\) (utiliser une récurrence), mais pas plus.

    La régularité \( C^1\) de \( y\) par rapport à la condition initiale sera l'objet du théorème \ref{THOooSTHXooXqLBoT}. Ce résultat n'est vraiment pas facile et utilise des ingrédients bien autres qu'un point fixe. Ensuite la régularité \( C^p\) par rapport à la condition initiale et par rapport à un paramètre seront presque des cadeaux (proposition \ref{PROPooINLNooDVWaMn} et \ref{PROPooPYHWooIZhQST}).
\end{normaltext}

\begin{example}[\cite{ooSBHXooOMnaTC}]          \label{EXooJXIGooQtotMc}
    Nous savons que le théorème de Picard permet de trouver le point fixe par itération de la contraction à partir d'un point quelconque. Tentons donc de résoudre
    \begin{subequations}
        \begin{numcases}{}
            y'(t)=y(t)\\
            y(0)=1
        \end{numcases}
    \end{subequations}
    dont nous savons depuis l'enfance que la solution est l'exponentielle. Partons donc de la fonction constante \( y_0=1\), et appliquons la contraction \eqref{EQooJUTBooILBKoE} :
    \begin{equation}
        u_1=1+\int_0^1u_0(s)ds=1+t.
    \end{equation}
    Ensuite
    \begin{equation}
        u_2=1+\int_0^t(1+s)ds=1+t+\frac{ t^2 }{2}.
    \end{equation}
    Et on voit que les itérations suivantes vont donner l'exponentielle.

    Nous sommes évidemment en droit de se dire que nous avons choisi un bon point de départ. Tentons le coup avec une fonction qui n'a rien à voir avec l'exponentielle : \( u_0(x)=\sin(x)\).

    Le programme suivant permet de faire de belles investigations numériques en partant d'à peu près n'importe quelle fonction :

\lstinputlisting{tex/sage/picard_exp.py}

    Ce programme fait \( 30\) itérations depuis la fonction \( \sin(x)\) pour tenter d'approximer \( \exp(x)\). Pour donner une idée, après \( 7\) itérations nous avons la fonction suivante :
    \begin{equation}
        \frac{1}{ 60 }x^5+\frac{1}{ 24 }x^4+\frac{ 1 }{2}x^2+2x-\sin(x)+1.
    \end{equation}
    Nous voyons que les coefficients sont des factorielles, mais pas toujours celles correspondantes à la puissance, et qu'il manque certains termes par rapport au développement de l'exponentielle que nous connaissons. Bref, le polynôme qui se met en face de \( \sin(x)\) s'adapte tout seul pour compenser.

    Et après \( 30\) itérations, ça donne quoi ? Voici un graphe de l'erreur entre \( u_{30}(x)\) et \( \exp(30)\) :
    
    
\begin{center}
   \input{auto/pictures_tex/Fig_XOLBooGcrjiwoU.pstricks}
\end{center}

    Pour donner une idée, \( \exp(10)\simeq 22000\). Donc il y a une faute de \( 0.01\) sur \( 22000\). Pas mal.

\end{example}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Théorème de Cauchy-Arzella}
%---------------------------------------------------------------------------------------------------------------------------

\begin{theorem}[Cauchy-Arzela\cite{ClemKetl}]   \label{ThoHNBooUipgPX}
    Nous considérons le système d'équation différentielles
    \begin{subequations}        \label{EqTXlJdH}
        \begin{numcases}{}
            y'=f(t,y)\\
            y(t_0)=y_0.
        \end{numcases}
    \end{subequations}
    avec \( f\colon U\to \eR^n\), continue où \( U\) est ouvert dans \( \eR\times \eR^n\). Alors il existe un voisinage fermé \( V\) de \( t_0\) sur lequel une solution \( C^1\) du problème \eqref{EqTXlJdH} existe.
\end{theorem}
\index{théorème!Cauchy-Arzela}

\begin{proof}[Idée de la démonstration]
    Nous considérons \( M=\| f \|_{\infty}\) et \( K\), l'ensemble des fonctions \( M\)-Lipschitz sur \( U\). Nous prouvons que \( (K,\| . \|_{\infty})\) est compact. Ensuite nous considérons l'application
    \begin{equation}
        \begin{aligned}
            \Phi\colon K&\to K \\
            \Phi(f)(t)&=x_0+\int_{t_0}^tf\big( u,f(u) \big)du. 
        \end{aligned}
    \end{equation}
    Après avoir prouvé que \( \Phi\) était continue, nous concluons qu'elle a un point fixe par le théorème de Schauder \ref{ThovHJXIU}.
\end{proof}

\begin{remark}
    Quelque remarques.
    \begin{enumerate}
        \item
    Les théorème de Cauchy-Lipschitz et Cauchy-Arzella donnent des existences pour des équations différentielles du type \( y'=f(t,y)\). Et si nous avons une équation du second ordre ? Alors il y a la méthode de la réduction de l'ordre qui permet de transformer une équation différentielle d'ordre élevé en un système d'ordre \( 1\).
\item
    Ces théorèmes posent des \emph{conditions initiales} : la valeur de \( y\) est donnée en un point, et la méthode de la réduction de l'ordre permet de donner l'existence de solutions d'un problème d'ordre \( k\) en donnant les valeurs de \( y(0)\), \( y'(0)\), \ldots \( y^{(k-1)}(0)\). C'est à dire de la fonction et de ses dérivées en un point. Rien n'est dit sur l'existence de \emph{conditions aux bords}.
    \end{enumerate}
    Ces deux points sont illustrés dans les exemples \ref{EXooSHMMooHVfsMB} et \ref{EXooJNOMooYqUwTZ}.
\end{remark}
