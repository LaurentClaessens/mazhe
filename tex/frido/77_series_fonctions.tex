% This is part of Mes notes de mathématique
% Copyright (c) 2011-2015,2017-2020,2023-2025
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.



%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Densité des polynômes}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{corollary}   \label{CorRSczQD}
	Si \( X\subset \eR\) est compact et de mesure finie\footnote{Dans \( \eR\) cette hypothèse est évidemment superflue par rapport à l'hypothèse de compacité; mais ça suggère des généralisations \ldots}, alors l'ensemble des polynômes est dense dans \( \big( C(X,\eR),\| . \|_2 \big)\).
\end{corollary}

\begin{proof}
	Si \( f\) est une fonction dans \( C(X,\eR)\) et si \( \epsilon\geq 0\) est donné alors nous pouvons considérer un polynôme \( P\) tel que \( \| f-P \|_{\infty}\leq \epsilon\). Dans ce cas nous avons
	\begin{equation}
		\| f-P \|_2^2=\int_X| f(x)-P(x) |^2dx\leq \int_X\epsilon^2dx=\epsilon^2\mu(X)
	\end{equation}
	où \( \mu(X)\) est la mesure de \( X\) (finie par hypothèse).
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Primitive et intégrale}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Nous avons déjà parlé de primitive de fonction continue en la proposition \ref{ThoEXXyooCLwgQg}.

\begin{proposition} \label{PropHFWNpRb}
	Soit \( I \) un intervalle borné ouvert de \( \eR\). Une fonction \( h\in C^{\infty}_c(I)\) admet une primitive dans \(  C^{\infty}_c(I)\) si et seulement si \( \int_Ih=0\).
\end{proposition}

\begin{proof}
	Si une primitive \( H\) de \( h\) est à support compact, alors
	\begin{equation}
		\int_Ih=H(b)-H(a)=0-0=0.
	\end{equation}
	Pas de problèmes dans ce sens.

	Supposons maintenant que \( \int_Ih=0\). Le fait que \( h\) admette une primitive dans \(  C^{\infty}(I)\) est évident : toute fonction continue admet une primitive\footnote{Théorème~\ref{ThoEXXyooCLwgQg}.}. Soit \( H\) une telle primitive et \( \tilde H=H-H(b)\). Alors \( \tilde H(b)=0\) et
	\begin{equation}
		\tilde H(a)=H(a)-H(b)=-\int_Ih=0.
	\end{equation}
	Nous rappelons que le support d'une fonction est \emph{la fermeture} de l'ensemble des points de non-annulation.

	Supposons que le support de \( h\) soit inclus dans \( \mathopen[ m , M \mathclose]\subset\mathopen] a , b \mathclose[\). En prenant des nombres \( m'\) et \( M'\) tels que \( a<m'<m\) et \( M<M'<b\) (nous insistons sur le caractère strict de ces inégalités), la fonction \( h\) est nulle sur \( \mathopen[ a , m' \mathclose]\) et sur \( \mathopen[ M' , b \mathclose]\); la fonction \( \tilde H\) doit donc y être constante. Mais nous avons déjà vu que \( \tilde H(a)=\tilde H(b)=0\). Donc l'ensemble des points sur lesquels \( \tilde H\) n'est pas nul est inclus dans \( \mathopen] m' , M' \mathclose[\) et donc est strictement (des deux côtés) inclus dans \( I\).
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Théorème taubérien de Hardy-Littlewood}
%---------------------------------------------------------------------------------------------------------------------------

Un théorème \defe{taubérien}{taubérien}\index{théorème!taubérien} est un théorème qui compare les modes de convergence d'une série.

\begin{lemma}
	Si \( f\) et \( g\) sont des fonctions continues, alors \( s(x)=\max\{ f(x),g(x) \}\) est également une fonction continue.
\end{lemma}

\begin{proof}
	Soit \( x_0\) et prouvons que \( s\) est continue en \( x_0\). Si \( f(x_0)\neq g(x_0)\) (supposons \( f(x_0)>g(x_0)\) pour fixer les idées), alors nous avons un voisinage de \( x_0\) sur lequel \( f>g\) et alors \( s=f\) sur ce voisinage et la continuité provient de celle de \( f\).

	Si au contraire \( f(x_0)=g(x_0)=s(x_0)\) alors si \( (a_n)\) est une suite tendant vers \( x_0\), nous prenons \( N\) tel que \( \big| f(a_n)-f(x_0) \big|\leq \epsilon\) pour tout \( n>N\) et \( M\) tel que \( \big| g(a_n)-g(x_0) \big|\leq \epsilon\) pour tout \( n> M\). Alors pour tout \( n>\max\{ N,M \}\) nous avons
	\begin{equation}
		\big| s(a_n)-s(x_0) \big|\leq \epsilon,
	\end{equation}
	d'où la continuité de \( s\) en \( x_0\).
\end{proof}

La proposition suivante dit que si une fonction connaît un saut, alors on peut la lisser par une fonction continue.
\begin{proposition} \label{PropTIeYVw}
	Soit \( f\) continue sur \( \mathopen[ a , x_0 [\) et sur \( \mathopen[ x_0 , b \mathclose]\) avec \( f(x_0^-)<f(x_0)\). En particulier nous supposons que \( f(x_0^-)\) existe et est finie. Alors pour tout \( \epsilon>0\), il existe une fonction continue \( s\) telle que sur \( \mathopen[ a , b \mathclose]\) on ait \( s\geq f\) et
	\begin{equation}
		\int_a^b(s-f)(x)\,dx\leq \epsilon.
	\end{equation}
\end{proposition}

\begin{proof}
	Nous notons \( A\) la taille du saut :
	\begin{equation}
		A=f(x_0)-f(x_0^-).
	\end{equation}
	Quitte à changer \( a\) et \( b\), nous pouvons supposer que
	\begin{equation}
		f(x)<f(x_0)+\frac{ A }{ 3 }
	\end{equation}
	pour \( x\in \mathopen[ a , x_0 [\) et
	\begin{equation}
		f>f(x_0)+\frac{ 2A }{ 3 }
	\end{equation}
	pour \( x\in \mathopen[ x_0 , b \mathclose]\). C'est le théorème des valeurs intermédiaires qui nous permet de faire ce choix.

	Soit \( m(x)\) la droite qui joint le point \( \big( x_0-\epsilon, f(x_0-\epsilon) \big)\) au point \( \big( x_0,f(x_0^+) \big)\). Nous posons
	\begin{equation}
		s(x)=\begin{cases}
			f(x)                & \text{si } x<x_0-\epsilon             \\
			\max\{ m(x),f(x) \} & \text{si } x_0-\epsilon\leq x\leq x_0 \\
			f(x)                & \text{si } x>x_0.
		\end{cases}
	\end{equation}
	En vertu des différents choix effectués, c'est une fonction continue. En effet
	\begin{equation}
		s(x_0-\epsilon)=\max\{ f(x_0-\epsilon),f(x_0,\epsilon) \}=f(x_0-\epsilon)
	\end{equation}
	et
	\begin{equation}
		s(x_0)=\max\{ m(x_0),f(x_0^+) \}=f(x_0^+)
	\end{equation}
	parce que \( m(x_0)=f(x_0^+)\). En ce qui concerne l'intégrale, si nous posons
	\begin{equation}
		M=\sup_{x,y\in \mathopen[ a , b \mathclose]}| f(x)-f(y) |,
	\end{equation}
	nous avons
	\begin{equation}
		\int_a^bs-f=\int_{x_0-\epsilon}^{x_0}s-f\leq \epsilon M.
	\end{equation}
\end{proof}

\begin{lemma}\label{LemauxrKN}
	Pour tout polynôme \( P\), nous avons la formule
	\begin{equation}
		\lim_{x\to 1^-} (1-x)\sum_{n=0}^{\infty}x^nP(x^n)=\int_0^1P(x)dx.
	\end{equation}
\end{lemma}

\begin{proof}
	D'abord pour \( P=1\), la formule se réduit à la série géométrique connue (proposition \ref{PROPooWOWQooWbzukS}). Ensuite nous prouvons la formule pour le polynôme \( P=X^k\) et la linéarité fera le reste pour les autres polynômes. Nous avons
	\begin{equation}
		(1-x)\sum_nx^nx^{kn}=(1-x)\sum_n(x^{1+k})^n=\frac{ 1-x }{ 1-x^{1+k} }=\frac{1}{ 1+x+\cdots+x^k }.
	\end{equation}
	Donc
	\begin{equation}
		\lim_{x\to 1^-} (1-x)\sum_nx^nP(x^n)=\frac{1}{ 1+k }.
	\end{equation}
	Par ailleurs, c'est vite vu que
	\begin{equation}
		\int_0^1 x^kdx=\frac{1}{ k+1 }.
	\end{equation}
\end{proof}

\begin{theorem}[Hardy-Littlewood\cite{ytMOpe}]\index{théorème!Hardy-Littlewood}\index{Hardy-Littlewood (théorème)}      \label{ThoPdDxgP}
	Soit \( (a_n)\) une suite réelle telle que
	\begin{enumerate}
		\item
		      \( \frac{ a_n }{ n }\) tend vers une constante,
		\item
		      \( F(x)=\sum_{n=0}^{\infty}a_nx^n\) a un rayon de convergence \( \geq 1\),
		\item
		      \( \lim_{x\to 1^-} F(x)=l\).
	\end{enumerate}
	Alors \( \sum_{n=0}^{\infty}a_n=l\).
\end{theorem}
\index{convergence!suite numérique}
\index{série!nombres}
\index{série!fonctions}
\index{limite!inversion}
\index{approximation!par polynômes}

\begin{proof}
	Quitte à prendre la suite \( b_0=a_0-l\) et \( b_n=a_n\), on peut supposer \( l=0\).

	Soit \( \Gamma\) l'ensemble des fonctions
	\begin{equation}
		\gamma\colon \mathopen[ 0 , 1 \mathclose]\to \eR
	\end{equation}
	telles que
	\begin{enumerate}
		\item
		      \( \sum_{n=0}^{\infty}a_n\gamma(x^n)\) converge pour \( 0\leq x<1\),
		\item
		      \( \lim_{x\to 1^-} \sum_{n\geq 0}a_n\gamma(x^n)=0\).
	\end{enumerate}
	Ce \( \Gamma\) est un espace vectoriel.
	\begin{subproof}
		\spitem[Les polynômes sont dans \( \Gamma\)]
		Soit \( \gamma(t)=t^s\). Pour \( 0\leq x<1\) nous avons
		\begin{equation}
			\sum_{n=0}^{\infty}a_n\gamma(x^n)=\sum_{n=0}^{\infty}a_nx^{ns}<\sum_{n=0}^{\infty}a_nx^n.
		\end{equation}
		Donc la condition de convergence est vérifiée. En ce qui concerne la limite,
		\begin{equation}
			\lim_{x\to 1^-} \sum_{n=0}^{\infty}a_nx^{ns}=\lim_{x\to 1^-} F(x^s)=0
		\end{equation}
		parce que par hypothèse, \( \lim_{x\to 1^-} F(x)=0\).

		\spitem[Définition de la fonction qui va donner la réponse]
		Nous considérons la fonction
		\begin{equation}
			g(t)=\begin{cases}
				0 & \text{si } 0\leq t<1/2      \\
				1 & \text{si } 1/2\leq t\leq 1,
			\end{cases}
		\end{equation}
		c'est-à-dire \( g=\mtu_{\mathopen[ \frac{ 1 }{2} , 1 \mathclose]}\). Nous montrons que si \( g\in \Gamma\), alors le théorème est terminé. Si \( 0\leq x\leq 1\), on a \( 0\leq x^n<1/2\) dès que
		\begin{equation}
			n>-\frac{ \ln(2) }{ \ln(x) }
		\end{equation}
		avec une note comme quoi \( \ln(x)<0\), donc la fraction est positive. Nous désignons par \( N_x\) la partie entière de ce \( n\) adapté à \( x\). L'idée est que la fonction  \( g(x^n)\) est la fonction indicatrice de \(0 \leq n\leq N_x\), et donc
		\begin{equation}
			\sum_{n\geq 0}a_ng(x^n)=\sum_{n=0}^{N_x}a_n.
		\end{equation}
		Mais si \( x\to 1^-\), alors \( N_x\to \infty\), donc
		\begin{equation}
			\lim_{N\to \infty} \sum_{n=0}^Na_n=\lim_{x\to 1^-} \sum_{n=0}^{N_x}a_n=\lim_{x\to 1^-} \sum_{n\in \eN}a_ng(x^n),
		\end{equation}
		et cela fait zéro si \( g\in \Gamma\).

		\spitem[Approximation de \( g\) par des polynômes]
		Nous considérons la fonction
		\begin{equation}
			h(t)=\frac{ g(t)-t }{ t(1-t) }=\begin{cases}
				\frac{1}{ t-1 } & \text{si } t\in \mathopen[ 0 , 1/2 [            \\
				\frac{1}{ t }   & \text{si } t\in \mathopen[ 1/2 , 1 \mathclose].
			\end{cases}
		\end{equation}
		La seconde égalité est au sens du prolongement par continuité. La fonction \( h\) est une fonction non continue qui fait un saut de \( -2\) à \( 2\) en \( x=1/2\). En vertu de la proposition~\ref{PropTIeYVw} (un peu adaptée), nous pouvons considérer deux fonctions continues \( s_1\) et \( s_2\) telles que
		\begin{equation}
			s_1\leq h\leq s_2
		\end{equation}
		et
		\begin{equation}
			\int_{0}^1s_2-s_1\leq \epsilon.
		\end{equation}
		Notons que l'inégalité \( s_1\leq s_2\) doit être stricte sur au moins un petit intervalle autour de \( x=1/2\). Soient \( P_1\) et \( P_2\), deux polynômes tels que \( \| P_1-s_1 \|_{\infty}\leq \epsilon\) et \( \| P_2-s_2 \|_{\infty}\leq \epsilon\) (ici la norme supremum est prise sur \( \mathopen[ 0 , 1 \mathclose]\)). C'est le théorème de Stone-Weierstrass (\ref{ThoGddfas}) qui nous permet de le faire.

		Nous posons aussi\footnote{À ce niveau, je crois qu'il y a une faute de frappe dans \cite{ytMOpe}.}
		\begin{subequations}
			\begin{align}
				Q_1 & =P_1+\epsilon  \\
				Q_2 & =P_2-\epsilon.
			\end{align}
		\end{subequations}
		Nous avons
		\begin{equation}
			\int_0^1Q_1-Q_2\leq\int_0^1 Q_1-P_1+P_1-P_2+P_2-Q_2.
		\end{equation}
		Pour majorer cela, d'abord \( Q_1-P_1=P_2-Q_2=\epsilon\), ensuite,
		\begin{equation}
			P_1-P_2=P_1-s_1+s_1-s_2+s_2-P_2
		\end{equation}
		dans lequel nous avons \( P_1-s_1\leq \epsilon\), \( s_2-P_2\leq \epsilon\) et \( \int_0^1s_1-s_2\leq\epsilon\). Au final, nous posons \( q=Q_2-Q_1\) et nous avons
		\begin{equation}
			\int_0^1q\leq 5\epsilon.
		\end{equation}
		Enfin nous posons aussi
		\begin{equation}
			R_i(x)=x+x(1-x)Q_i.
		\end{equation}
		Ces polynômes vérifient \( R_i(0)=0\), \( R_i(1)=1\) et
		\begin{equation}
			R_1\leq g\leq R_2
		\end{equation}
		parce que
		\begin{equation}
			Q_1\leq P_1\leq h\leq  P_2\leq Q_2
		\end{equation}
		et
		\begin{equation}
			t+t(1-t)Q_1\leq \underbrace{t+t(1-t)h(t)}_{g(t)}\leq t+t(1-t)Q_2.
		\end{equation}

		\spitem[Preuve que \( g\) est dans \( \Gamma\)]
		D'abord si \( 0\leq x<1\), \( x^N<\frac{ 1 }{2}\) pour un certain \( N\), et alors \( g(x^N)=0\). Du coup la série
		\begin{equation}
			\sum_{n=0}^{\infty}a_ng(x^n)=\sum_{n=0}^{N}a_n
		\end{equation}
		est une somme finie qui converge donc.

		D'autre part nous prenons \( M\) tel que \( | a_n |<\frac{ M }{ n }\) pour tout \( n\). Nous majorons \( \sum_{n \in \eN}a_ng(x^n)\) en utilisant \( R_1\). Mais vu que \( R_1\) est un polynôme, nous pouvons dire que \( | \sum_{n=0}^{\infty}a_nR_1(x^n) |\leq \epsilon\) en prenant \( x\in\mathopen[ \lambda , 1 [\) et \( \lambda\) assez grand. Nous avons :
		\begin{subequations}
			\begin{align}
				\left| \sum_{n=0}^{\infty}a_ng(x^n) \right| & \leq\left| \sum_{n=0}^{\infty}a_ng(x^n)-\sum_{n=0}^{\infty}a_nR_1(x^n) \right| +\underbrace{\left| \sum_{n=0}^{\infty}a_nR_1(x^n) \right|}_{\leq \epsilon} \\
				                                            & \leq \epsilon+\sum_{n=0}^{\infty}| a_n |(g-R_1)(x^n)                                                                                                       \\
				                                            & \leq \epsilon+\sum_{n=0}^{\infty}| a_n |(R_2-R_1)(x^n)                                                                                                     \\
				                                            & \leq \epsilon+M\sum_{n=0}^{\infty}\frac{ x^n(1-x^n) }{ n }(Q_2-Q_1)(x^n) \label{SUBEQooAIQWooJADvKs}                                                       \\
				                                            & =    \epsilon+M\sum_{n=0}^{\infty}\frac{ x^n(1-x^n) }{ n }q(x^n)                                                                                           \\
				                                            & \leq \epsilon+M(1-x)\sum_nx^nq(x^n).   \label{subeqtZXDvu}
			\end{align}
		\end{subequations}
		Justifications :
		\begin{itemize}
			\item La ligne \eqref{SUBEQooAIQWooJADvKs} vient du fait que \( R_2-R_1=x(1-x)(Q_2-Q_1)\).
			\item La ligne \eqref{subeqtZXDvu} provient d'une majoration sauvage de \( 1/n\) par \( 1\) et de \( 1-x^n\) par \( 1-x\).
		\end{itemize}
		Par le lemme \ref{LemauxrKN}, nous avons alors
		\begin{equation}
			\lim_{x\to 1^-} | \sum_na_ng(x^n) |\leq \epsilon+M\int_0^1q\leq 6\epsilon.
		\end{equation}
	\end{subproof}
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Théorème de Müntz}
%---------------------------------------------------------------------------------------------------------------------------

\begin{theorem}[Théorème de Müntz\cite{jqZSyG,oYGash,ooRIPFooALoEWM}]  \label{ThoAEYDdHp}
	Soit \( C_0\big( \mathopen[ 0 , 1 \mathclose] \big)\), l'espace des fonctions continues sur \( \mathopen[ 0 , 1 \mathclose]\) muni de la norme \( \| . \|_{\infty}\) ou \( \| . \|_2\) et une suite \( (\alpha_n)\) strictement croissante de nombres positifs. Nous notons \( \phi_{\lambda}\) la fonction \( x\mapsto x^{\lambda}\).

	Alors
	\begin{equation}
		\overline{  \Span\{1, \phi_{\alpha_n} \} }
	\end{equation}
	est dense dans \( C_0\big( \mathopen[ 0 , 1 \mathclose] \big)\)  si et seulement si
	\begin{equation}
		\sum_{n=2}^{\infty}\frac{1}{ \alpha_n }=+\infty.
	\end{equation}
\end{theorem}

Nous prouvons le théorème pour la norme \( \| . \|_2\).
\begin{proof}
	Soit \( m\in \eR^+\); nous notons \( \Delta_N(m)\) la distance entre \( \phi_m\) et \( \Span\{ \phi_{\alpha_1},\ldots, \phi_{\alpha_N} \}\). Cette distance peut être évaluée avec le déterminant de Gram\index{déterminant!Gram} (proposition~\ref{PropMsZhIK})
	\begin{equation}
		\Delta_N(m)^2=\frac{ G(\phi_m,\phi_{\alpha_1},\ldots, \phi_{\alpha_N}) }{ G(\phi_{\alpha_1},\ldots, \phi_{\alpha_N}) }.
	\end{equation}
	Pour calculer cela, nous avons besoin des produits scalaires\footnote{C'est ici qu'on se particularise à la norme \( \| . \|_2\).}
	\begin{equation}
		\langle \phi_a, \phi_b\rangle =\int_0^1 x^{a+b}dx=\frac{1}{ a+b+1 }.
	\end{equation}
	Pour avoir des notations plus compactes, nous notons \( \alpha_0=m\). Donc nous avons à calculer le déterminant
	\begin{equation}
		G(\phi_m,\phi_{\alpha_1},\ldots, \phi_{\alpha_N})=\det\begin{pmatrix}
			\frac{1}{ \alpha_i+\alpha_j+1 }
		\end{pmatrix}
	\end{equation}
	où \( i,j=0,\ldots, N\). Nous reconnaissons un déterminant de Cauchy (proposition~\ref{ProptoDYKA})\index{déterminant!Cauchy} en posant, dans \( \frac{1}{ \alpha_i+\alpha_j+1 }\), \( a_i=\alpha_i\) et \( b_j=\alpha_j+1\). Étant donné que \( b_j-b_i=a_j-a_i\), nous avons
	\begin{equation}
		G(\phi_m,\phi_{\alpha_1},\ldots, \phi_{\alpha_N})=\frac{ \prod_{0\leq i<j\leq N}  (\alpha_j-\alpha_i)^2 }{ \prod_{i=0}^N\prod_{j=0}^N (\alpha_i+\alpha_j+1).}
	\end{equation}
	Nous séparons maintenant les termes où \( i\) ou \( j\) sont nuls. En ce qui concerne le dénominateur, il faut prendre tous les couples \( (i,j)\) avec \( i\) et \( j\) éventuellement égaux à zéro. Nous décomposons cela en trois paquets. Le premier est \( (0,0)\); le second est \( (0,i)\) (chaque couple arrive en fait deux fois parce qu'il y a aussi \( (i,0)\)); et le troisième sont les \( i,j\) tous deux différents de zéro :
	\begin{equation}
		(2m+1)\prod_{ij}(\alpha_i+\alpha_j+1)\prod_i(\alpha_i+m+1)^2.
	\end{equation}
	Notons que dans le produit central, le carré est contenu dans le fait qu'on écrit \( \prod_{ij}\) et non \( \prod_{i<j}\). Nous avons donc
	\begin{equation}
		G(\phi_m,\phi_{\alpha_1},\ldots, \phi_{\alpha_N})=\frac{ \prod_{i<j}(\alpha_i-\alpha_j)^2\prod_i(\alpha_i-m)^2 }{ (2m+1)\prod_{ij}(\alpha_i+\alpha_j+1)\prod_i(\alpha_i+m+1)^2 }.
	\end{equation}

	Le calcul de \( G(\phi_{\alpha_1},\ldots, \phi_{\alpha_N})\) est plus simple\footnote{Je crois qu'il y a une faute de frappe dans le dénominateur de \cite{jqZSyG}.} :
	\begin{equation}
		G(\phi_{\alpha_1},\ldots, \phi_{\alpha_N})=\frac{ \prod_{i<j}(\alpha_i-\alpha_j)^2 }{ \prod_{ij}(\alpha_i+\alpha_j+1) }.
	\end{equation}
	En divisant l'un par l'autre il ne reste que les facteurs comprenant \( m\) et en prenant la racine carrée,
	\begin{equation}    \label{EqANiuNB}
		\Delta_N(m)=\frac{1}{ \sqrt{2m+1} }\prod_{i=1}^N\left| \frac{ \alpha_i-m }{ \alpha_i+m+1 } \right| .
	\end{equation}

	Nous passons maintenant à la preuve proprement dite. Supposons que \( V=\Span\{ \phi_{\alpha_i},i\in \eN \}\) est dense. Si \( m\) est un des \( \alpha_i\), il peut évidemment être approché par les \( \phi_{\alpha_i}\). Mais vue la densité de \( V\), un \( \phi_m\) avec \( m\neq \alpha_i\) (pour tout \( i\)) alors \( \phi_m\) peut également être arbitrairement approché par les \( \phi_{\alpha_i}\), c'est-à-dire que
	\begin{equation}
		\lim_{N\to \infty} \Delta_N(m)=0.
	\end{equation}
	Nous posons
	\begin{equation}
		u_n=\ln\left( \frac{ \alpha_n-m }{ \alpha_n+m+1 } \right)
	\end{equation}
	et nous prouvons que la série \( \sum_nu_n\) diverge. En effet nous nous souvenons de la formule \( \ln(ab)=\ln(a)+\ln(b)\), de telle sorte que la \( N\)\ieme\ somme partielle de \( \sum_nu_n\) est
	\begin{equation}
		\ln\left( \frac{ \alpha_1-m }{ \alpha_1+m+1 }\cdot\ldots\cdot \frac{ \alpha_N-m }{ \alpha_N+m+1 } \right)=\ln\left( \sqrt{2m+1}\Delta_N(m) \right),
	\end{equation}
	qui tend vers \( -\infty\) lorsque \( N\to \infty\).

	Si la suite \( (\alpha_n)\) est majorée et plus généralement si nous n'avons pas \( \alpha_n\to \infty\), alors évidemment la série \( \sum_n\frac{1}{ \alpha_n }\) diverge. Nous supposons donc que \( \lim_{n\to \infty} \alpha_n=\infty\). Nous avons aussi\quext{Je crois qu'il y a une faute de signe dans la dernière expression de \cite{oYGash}.}
	\begin{equation}
		u_n=\ln\left( \frac{ \alpha_n-m }{ \alpha_n+m+1 } \right)=\ln\left( 1-\frac{ 2m+1 }{ \alpha_n+m+1 } \right)\sim-\frac{ 2m+1 }{ \alpha_n }.
	\end{equation}
	Une justification est donnée à l'équation \eqref{EqGICpOX}. Ce que nous avons surtout est
	\begin{equation}
		\sum_n u_n\sim -(2m+1)\sum_n\frac{1}{ \alpha_n }.
	\end{equation}
	Étant donné que la série de gauche diverge, celle de droite diverge\footnote{Nous utilisons le fait que si \( u_n=\sum v_n\) en tant que suites et si \( \sum_nu_n\) diverge, alors \( \sum_nv_n\) diverge.}.

	Nous prouvons maintenant le sens opposé : nous supposons que la série \( \sum_n1/\alpha_n\) diverge et nous posons
	\begin{equation}
		V=\Span\{ \phi_{\alpha_n}\tq n\in \eN \}.
	\end{equation}
	Il suffit de prouver que \( \phi_m\in \bar V\) pour tout \( m\) parce qu'un corolaire du théorème de Stone-Weierstrass~\ref{CorRSczQD} montre que \( \Span\{ \phi_k\tq k\in \eN \}\) est dense dans \( C\) pour la norme \( \| . \|_2\).

	Si \( \alpha_n\to \infty\), nous avons :
	\begin{equation}
		u_n\sim\frac{ 2m+1 }{ \alpha_n }\to 0
	\end{equation}
	et alors \( \Delta_N(m)\to 0\). Dans ce cas nous avons immédiatement \( \phi_m\in \bar V\).

	Si par contre \( \alpha_n\) ne tend pas vers l'infini, nous repartons de l'expression \eqref{EqANiuNB}, nous posons \( 0<\alpha=\sup_i\alpha_i\) et nous calculons :
	\begin{subequations}
		\begin{align}
			\sqrt{2m+1}\Delta_N(m) & =\prod_{i=1}^N\frac{ | \alpha_i-m | }{ \alpha_i+m+1 }     \\
			                       & \leq \prod_{i=1}^N\frac{ \alpha_i+m }{ \alpha_i+m+1 }
			=    \prod_{i=1}^N\left( 1-\frac{ 1 }{ \alpha_i+m+1 } \right)                      \\
			                       & \leq \prod_{i=1}^N\left( 1-\frac{1}{ \alpha+m+1 } \right)
			=    \left( 1-\frac{1}{ \alpha+m+1 } \right)^N.
		\end{align}
	\end{subequations}
	Cette dernière expression tend vers \( 0\) lorsque \( N\to \infty\).
\end{proof}

\begin{remark}      \label{REMooGPYYooCQJwFa}
	Certaines sources\footnote{Dont le rapport du jury 2014} citent le théorème de Müntz comme ceci (avec un implicite que \( \alpha_i\neq 0\)):
	\begin{equation}        \label{EQooPCSZooUDSzwQ}
		\overline{ \Span\{1, \phi_{\alpha_i} \} }=C\big( \mathopen[ 0 , 1 \mathclose] \big) \Leftrightarrow \sum_{i\geq 1}\frac{1}{ \alpha_i }=+\infty.
	\end{equation}
	Que penser de la présence explicite du \( 1\) (c'est-à-dire de \( \phi_0\)) ou non dans l'ensemble ?

	Première chose : la présence éventuelle de \( \phi_0\) est la raison pour laquelle nous faisons commencer la somme à \( i=2\) et non \( i=1\). Dans le même ordre d'idée, si \( \Span\{ \phi_{\alpha_i} \}\) est dense, alors en prenant n'importe quelle queue de suite, ça reste dense.

	Prouvons donc l'énoncé \eqref{EQooPCSZooUDSzwQ}. Si \( \Span\{ 1,\phi_{\alpha_i} \}\) est dense, alors en posant \( \beta_1=0\), \( \beta_i=\alpha_{i-1}\) notre théorème prouve que \( \sum_{i=2}^{\infty}\frac{1}{ \beta_i }=+\infty\), cela est exactement que \( \sum_{i=1}^{\infty}\frac{1}{ \alpha_i }=+\infty\). Dans l'autre sens, si \( \sum_{i\geq 1}\frac{1}{ \alpha_i }=+\infty\), alors nous avons aussi \( \sum_{i\geq 2}\frac{1}{ \alpha_i }=+\infty\) et notre théorème dit que \( \Span \{ \phi_{\alpha_i} \}\) est dense. A fortiori, \( \Span\{ 1,\phi_{\alpha_i} \}\) est dense.
\end{remark}

\begin{example}
	Nous savons depuis le théorème~\ref{ThonfVruT} que la somme des inverses des nombres premiers diverge.
\end{example}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Intégrales convergeant uniformément}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Définition et propriété}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}      \label{DEFooSHWAooWtswtp}
	Soit \( (\Omega,\mu)\) un espace mesuré. Nous disons que l'intégrale
	\begin{equation}
		\int_{\Omega}f(x,\omega)d\mu(\omega)
	\end{equation}
	\defe{converge uniformément}{convergence!uniforme!intégrale} en \( x\) si pour tout \( \epsilon>0\), il existe un compact \( K_{\epsilon}\) tel que pour tout compact \( K\) tel que \( K_{\epsilon}\subset K\) nous avons
	\begin{equation}
		\left| \int_{\Omega\setminus K}f(x,\omega)d\mu(\omega) \right| \leq \epsilon.
	\end{equation}
	Le point important est que le choix de \( K_{\epsilon}\) ne dépend pas de \( x\).
\end{definition}

\begin{lemma}       \label{LemOgQdpJ}
	Soit
	\begin{equation}
		F(x)=\int_{\Omega}f(x,\omega)d\mu(\omega),
	\end{equation}
	une intégrale uniformément convergente. Pour chaque \( k\in \eN\) nous considérons un compact \( K_k\) tel que
	\begin{equation}
		\left| \int_{\Omega\setminus K_k}f(x,\omega)d\mu(\omega) \right| \leq\frac{1}{ k }.
	\end{equation}
	Alors la suite de fonctions \( F_k\) définie par
	\begin{equation}
		F_k(x)=\int_{K_k}f(x,\omega)d\mu(\omega)
	\end{equation}
	converge uniformément vers \( F\).
\end{lemma}

\begin{proof}
	Nous avons
	\begin{subequations}
		\begin{align}
			\big| F_k(x)-F(x) \big| & =\left| \int_{K_k}f(x,\omega)d\mu(\omega)-\int_{\Omega}f(x,\omega)d\mu(\omega) \right| \\
			                        & =| \int_{\Omega\setminus K_k}f(x,\omega)d\mu(\omega) |                                 \\
			                        & \leq \frac{1}{ k }.
		\end{align}
	\end{subequations}
\end{proof}

%------------------------------------------------------------------------------------------------------------------------
\subsection{Critères de convergence uniforme}
%---------------------------------------------------------------------------------------------------------------------------

Afin de tester l'uniforme convergence d'une intégrale, nous avons le \defe{critère de Weierstrass}{critère!Weierstrass}:
\begin{theorem}     \label{ThoCritWeiIntUnifCv}
	Soit \( f(x,t)\colon [\alpha,\beta]\times[a,\infty[ \to \eR\), une fonction dont la restriction à toute demi-droite \( x=c\) est mesurable. Si \( | f(x,t) |< \varphi(t)\) et \( \int_a^{\infty}\varphi(t)dt\) existe, alors l'intégrale
	\begin{equation}
		\int_0^{\infty}f(x,t)dt
	\end{equation}
	est uniformément convergente.
\end{theorem}

Le théorème suivant est le \defe{critère d'Abel}{critère!Abel pour intégrales} :
\begin{theorem}     \label{ThoAbelIntUnif}
	Supposons que \( f(x,t)=\varphi(x,t)\psi(x,t)\) où \( \varphi\) et \( \psi\) sont bornées et intégrables en \( t\) au sens de Riemann sur tout compact \( [a,b]\), \( b\geq a\). Supposons que :
	\begin{enumerate}
		\item \( \left| \int_a^{T}\varphi(x,t)dt \right| \leq M\) où \( M\) est indépendant de \( T\) et de \( x\),
		\item \( \psi(x,t)\geq 0\),
		\item pour tout \( x\in[\alpha,\beta]\), \( \psi(x,t)\) est une fonction décroissante de \( t\),
		\item les fonctions \( x\mapsto \psi(x,t)\) convergent uniformément vers \( 0\) lorsque \( t\to\infty\).
	\end{enumerate}
	Alors l'intégrale
	\begin{equation}
		\int_a^{\infty}f(x,t)dt
	\end{equation}
	est uniformément convergente.
\end{theorem}

\begin{remark}
	Étant donné que la fonction sinus est bornée, il est tentant de l'utiliser comme \( \varphi\) dans le critère d'Abel (théorème~\ref{ThoAbelIntUnif}). Hélas,
	\begin{equation}
		\int_0^T\sin(xt)dt=-\frac{ 1 }{ x }\big( \cos(xT)-\cos(x) \big),
	\end{equation}
	qui n'est pas bornée en \( x\). Poser \( \varphi(x,t)=\sin(xt)\) \emph{ne fonctionne pas} pour assurer la convergence uniforme sur un intervalle qui contient des \( x\) arbitrairement proches de \( 0\). Le critère d'Abel avec \( \varphi(x,t)=\sin(xt)\) ne permet que de conclure à l'uniforme convergence \emph{sur tout compact} ne contenant pas \( 0\). C'est toutefois souvent suffisant pour étudier la continuité ou la dérivabilité en se servant coup du compact, voir \ref{NORMooZWECooHvRgBw}.
	%1403337912512
\end{remark}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Fonctions définies par une intégrale}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\label{SecCHwnBDj}
\index{suite!de fonctions intégrables}
\index{fonction!définie par une intégrale}
\index{permuter limite et intégrale}

Soit \( (\Omega,\mu)\) un espace mesuré. Nous nous demandons dans quel cas l'intégrale
\begin{equation}
	F(x)=\int_{\Omega}f(x,\omega)d\omega
\end{equation}
définit une fonction \( F\) continue, dérivable ou autre.

Dans la suite nous allons considérer des fonctions \( f\) à valeurs réelles. Quitte à passer aux composantes, nous pouvons considérer des fonctions à valeurs vectorielles. Par contre le fait que \( x\) soit dans \( \eR\) ou dans \( \eR^n\) n'est pas spécialement une chose facile à traiter.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Continuité sous l'intégrale}
%---------------------------------------------------------------------------------------------------------------------------
\index{continuité!fonction définie par une intégrale}

Nous allons présenter deux théorèmes donnant la continuité de \( F\).
\begin{enumerate}
	\item
	      Si \( f\) est majorée par une fonction ne dépendant pas de \( x\), nous avons le théorème~\ref{ThoKnuSNd},
	\item
	      si l'intégrale est uniformément convergente, nous avons le théorème~\ref{ThotexmgE}.
\end{enumerate}

\begin{theorem} \label{ThoKnuSNd}
	Soit \( (\Omega,\mu)\) est un espace mesuré, soit \( x_0\in \eR^m\) et \( f\colon U\times \Omega\to \eR\) où \( U\) est ouvert dans \( \eR^m\). Nous supposons que
	\begin{enumerate}
		\item
		      Pour chaque \( x\in \eR^m\), la fonction \( \omega\mapsto f(x,\omega)\) est dans \( L^1(\Omega,\mu)\).
		\item
		      Pour chaque \( \omega\in \Omega\), la fonction \( x\mapsto f(x,\omega)\) est continue en \( x_0\).
		      %TODO : peut-être qu'on peut dire seulement pour presque tout omega dans Omega, voir la proposition~\ref{prop:fdefint}.
		\item       \label{ItemNAuYNG}
		      Il existe une fonction \( G\in L^1(\Omega)\) telle que
		      \begin{equation}
			      | f(x,\omega) |\leq G(\omega)
		      \end{equation}
		      pour tout \( x\in U\).
	\end{enumerate}
	Alors la fonction
	\begin{equation}
		\begin{aligned}
			F\colon U & \to \eR                                      \\
			x         & \mapsto \int_{\Omega}f(x,\omega)d\mu(\omega)
		\end{aligned}
	\end{equation}
	est continue en \( x_0\).
\end{theorem}
\index{permuter!limite et intégrale!espace mesuré}


\begin{proof}
	Soit \( (x_n)\) une suite convergente vers \( x_0\). Nous considérons la suite de fonctions \( f_n\colon \Omega\to \eR\) définies par
	\begin{equation}
		f_n(\omega)=f(x_n,\omega).
	\end{equation}
	sur qui nous pouvons utiliser le théorème de la convergence dominée (théorème~\ref{ThoConvDomLebVdhsTf}) pour obtenir
	\begin{subequations}
		\begin{align}
			\lim_{n\to \infty} F(x_n) & =\lim_{n\to \infty} \int_{\Omega}f(x_n,\omega)d\mu(\omega) \\
			                          & =\int_{\Omega}\lim_{n\to \infty} f(x_n,\omega)d\mu(\omega) \\
			                          & =\int_{\Omega}f(x_0,\omega)d\mu(\omega)                    \\
			                          & =F(x_0).
		\end{align}
	\end{subequations}
	Nous avons utilisé la continuité de \( f(.,\omega)\).
\end{proof}

Si nous avons un peu de compatibilité entre la topologie et la mesure, alors nous pouvons utiliser l'uniforme convergence d'une intégrale pour obtenir la continuité d'une fonction définie par une intégrale.

\begin{theorem} \label{ThotexmgE}
	Soit \( (\Omega,\mu)\) un espace topologique mesuré tel que tout compact est de mesure finie. Soit une fonction \( f\colon \eR\times \Omega\to \eR\) telle que
	\begin{enumerate}
		\item
		      Pour chaque \( x\in \eR\), la fonction \( f(x,.)\) est \( L^1(\Omega,\mu)\).
		\item
		      Pour chaque \( \omega\in \Omega\), la fonction \( f(.,\omega)\) est continue en \( x_0\).
		\item
		      L'intégrale
		      \begin{equation}
			      F(x)=\int_{\Omega}f(x,\omega)d\mu(\omega)
		      \end{equation}
		      est uniformément convergente\footnote{Définition~\ref{DEFooSHWAooWtswtp}.}.
	\end{enumerate}
	Alors la fonction \( F\) est continue en \( x_0\).
\end{theorem}
\index{permuter!limite et intégrale!espace mesuré}

\begin{proof}
	Nous reprenons les notations du lemme~\ref{LemOgQdpJ}. Les fonctions
	\begin{equation}
		F_k(x)=\int_{K_k}f(x,\omega)d\mu(\omega)
	\end{equation}
	existent parce que les fonctions \( f(x,.)\) sont dans \( L^1(\Omega)\). Montrons que les fonctions \( F_k\) sont continues. Soit une suite \( x_k\to x_0\) nous avons
	\begin{equation}
		\lim_{n\to \infty} F_k(x_n)=\lim_{n\to \infty} \int_{K_k}f(x_n,\omega)d\mu(\omega).
	\end{equation}
	Nous pouvons inverser la limite et l'intégrale en utilisant le théorème de la convergence dominée. Pour cela, la fonction \( f(x_n,\omega)\) étant continue sur le compact \( K_k\), elle y est majorée par une constante. Le fait que les compacts soient de mesure finie (hypothèse) implique que les constantes soient intégrables sur \( K_k\). Le théorème de la convergence dominée implique alors que
	\begin{equation}
		\lim_{n\to \infty} F_k(x_n)=\int_{K_k}\lim_{n\to \infty} f(x_n,\omega)d\mu(\omega)=\int_{K_k}f(x_0,\omega)d\mu(\omega)=F_k(x_0).
	\end{equation}
	Nous avons utilisé le fait que \( f(.,\omega)\) était continue en \( x_0\).

	Le lemme~\ref{LemOgQdpJ} nous indique alors que la convergence \( F_k\to F\) est uniforme. Les fonctions \( F_k\) étant continues, la fonction \( F\) est continue.
\end{proof}

Pour finir, citons ce résultat concernant les fonctions réelles.
\begin{theorem}     \label{ThoInDerrtCvUnifFContinue}
	Nous considérons \( F(x)=\int_a^{\infty}f(x,t)dt\). Si \( f\) est continue sur \( [\alpha,\beta]\times[a,\alpha[\) et l'intégrale converge uniformément, alors \( F(x)\) est continue.
\end{theorem}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Le coup du compact}
%---------------------------------------------------------------------------------------------------------------------------

\begin{normaltext}      \label{NORMooZWECooHvRgBw}

	Nous avons vu des fonctions définies par toute une série de processus de limite (suites, séries, intégrales). Une des questions centrales est de savoir si la fonction limite est continue, dérivable, intégrable, etc. étant donné que les fonctions sont continues.

	Pour cela, nous inventons le concept de \emph{convergence uniforme}. Si la limite (série, intégrale) est uniforme, alors la fonction limite sera continue. Il arrive qu'une limite ne soit pas uniforme sur un intervalle ouvert \( ]0,1]\), et que nous voulions quand même prouver la continuité sur cet intervalle. C'est à cela que sert la notion de convergence uniforme \emph{sur tout compact}. En effet, la notion de continuité est une notion locale : savoir ce qu'il se passe dans un petit voisinage autour de \( x\) est suffisant pour savoir la continuité en \( x\) (idem pour sa dérivée).

	%TODOooDKHWooXpyxsH mettre ça dans un lemme et mettre une référence en 1403337912512.
	Si nous avons uniforme convergence sur tout compact de \( ]0,1]\), mais pas uniforme convergence sur cet intervalle, la limite sera quand même continue sur \( \mathopen] 0 , 1 \mathclose]\). En effet, si \( x\in]0,1]\), il existe un ouvert autour de \( x\) contenu dans un compact contenu dans \( ]0,1]\). L'uniforme convergence sur ce compact suffit à prouver la continuité en \( x\).

	Déduire la continuité sur un ouvert à partir de l'uniforme convergence sur tout compact de l'ouvert est appelé faire le \defe{coup du compact}{compact!le coup du}.
\end{normaltext}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Dérivabilité sous l'intégrale}
%---------------------------------------------------------------------------------------------------------------------------
\index{dérivabilité!fonction définie par une intégrale}

Nous traitons à présent de la dérivabilité de la fonction \( F\) définie comme intégrale de \( f\). Dans le théorème \ref{ThoMWpRKYp} nous traitons de fonctions sur \( \eR\) à valeurs dans \( \eC\). Pour les fonctions définies sur \( \eC\), voir le théorème \ref{ThopCLOVN}.

\begin{theorem}[Dérivation sous le signe intégral, formule de Leibniz, thème \ref{THEMEooJGEHooNzQkMT}\cite{MesIntProbb,BIBooSNRXooSXmdxt}]    \label{ThoMWpRKYp}
	Soit \( (\Omega,\mu)\) un espace mesuré, un intervalle ouvert \( I\subset \eR\), et une fonction \( f\colon \eR\times \Omega\to \eC\). Nous supposons qu'il existe \( A\) mesurable de mesure nulle dans \( \Omega\) tels que
	\begin{enumerate}
		\item       \label{ITEMooAFVMooAeCEco}
		      Pour tout \( x\in I\), la fonction \( \omega\mapsto f(x,\omega)\) soit dans \( L^1(\Omega)\).
		\item        \label{ITEMooXIZXooGPYFyT}
		      L'application \( x\mapsto f(x,\omega)\) est dérivable\footnote{La dérivabilité pour une fonction à valeurs dans \( \eC\) n'a rien de mystérieux : c'est la dérivée composante par composante. Rien à voir avec la dérivée complexe.} pour tout \( x\in I\) et pour tout \( \omega\in \Omega\setminus A\).
		\item       \label{ITEMooDTTIooWkldfB}
		      Il existe une fonction \( G\colon \Omega\to \eR^+\) intégrable sur \( \Omega\) telle que
		      \begin{equation}        \label{EQooUHQYooHtwfML}
			      \left| \frac{ \partial f }{ \partial x }(x,\omega) \right| \leq G(\omega)
		      \end{equation}
		      pour tout \( x\in I\) et pour tout \( \omega\in\Omega\setminus A\).
	\end{enumerate}
	Alors la fonction
	\begin{equation}
		\begin{aligned}
			F\colon \eR & \to \eC                                      \\
			x           & \mapsto \int_{\Omega}f(x,\omega)d\mu(\omega)
		\end{aligned}
	\end{equation}
	est dérivable sur \( I\) et pour tout \( a\in I\) nous avons
	\begin{equation}
		F'(a)=\int_{\Omega}\frac{ \partial f }{ \partial x }(a,\omega)d\mu(\omega),
	\end{equation}
\end{theorem}
\index{permuter!dérivée et intégrale!dans \( \eR\)}

\begin{proof}
	Soit une suite \( (x_n)\) dans \( I\) telle que \( x_n\neq a\) et \( x_n\to a\). Si la limite
	\begin{equation}
		\lim_{n\to \infty} \frac{ F(a)-F(x_n) }{ a-x_n }
	\end{equation}
	existe et ne dépend pas de la suite choisie, alors la fonction \( F\) est dérivable en \( a\) et sa dérivée vaut cette limite. Autrement dit, nous nous mettons en devoir d'étudier la limite
	\begin{equation}    \label{EqLIiralx}
		\lim_{n\to \infty} \int_{\Omega}\frac{ f(a,\omega)-f(x_n,\omega) }{ a-x_n }d\omega.
	\end{equation}
	montrer qu'elle existe, ne dépend pas de la suite choisie et vaut \( \int_{\Omega}\partial_xf(a,\omega)d\omega\). On y va.

	\begin{subproof}
		\spitem[La bonne suite de fonctions]
		D'abord nous posons
		\begin{equation}    \label{EqAFOUbQB}
			g_n(\omega)=\frac{ f(x_n,\omega)-f(a,\omega) }{ x_n-a }.
		\end{equation}
		Nous montrons à présent que cette suite vérifie les hypothèses du théorème de la convergence dominée \ref{ThoConvDomLebVdhsTf}.
		\begin{itemize}
			\item
			      Chacune des fonctions \( g_n\) est dans \( L^1(\Omega)\) parce que, \( a\) étant fixé, l'élément \( x_n\) est dans \( I\setminus\{ a \}\); le dénominateur n'a donc aucun rôle. L'hypothèse \ref{ITEMooAFVMooAeCEco} montre que \( \omega\mapsto f(x_n,\omega)\) et \( \omega\mapsto f(a,\omega)\) sont dans \( L^1\). La somme est donc dans \( L^1\) (proposition \ref{PROPooFIYEooCpdmwZ}).
			\item
			      Par l'hypothèse \ref{ITEMooXIZXooGPYFyT}, pour chaque \( \omega\) nous avons une fonction dérivable. Nous pouvons donc passer à la limite :
			      \begin{equation}
				      \lim_{n\to \infty} g_n(\omega)=\frac{ \partial f }{ \partial x }(a,\omega).
			      \end{equation}
			\item
			      En ce qui concerne la majoration de \( g_n\), nous utilisons le théorème des accroissements finis \ref{ThoAccFinis}\ref{ITEMooXRQKooDBFpdQ}. Pour chaque \( \omega\), ce théorème peut être utilisé sur la fonction \( x\mapsto f(x,\omega)\) qui est dérivable. Nous avons :
			      \begin{equation}
				      \big| \frac{  f(x_n,\omega)-f(a,\omega)   }{ x_n-a  } \big|\leq \sup_{x\in \mathopen[ a , x_n \mathclose]}| \frac{ \partial f }{ \partial x }(x,\omega) |\leq G(\omega).
			      \end{equation}
			      Nous avons utilisé l'hypothèse \ref{ITEMooDTTIooWkldfB}.
		\end{itemize}
		Les hypothèses de la convergence dominée sont satisfaites.

		\spitem[Convergence dominée]
		Le théorème de la convergence dominée de Lebesgue (théorème~\ref{ThoConvDomLebVdhsTf}) nous permet alors de calculer la limite \eqref{EqLIiralx} :
		\begin{equation}
			\lim_{n\to \infty} \int_{\Omega}g_n(\omega)d\omega=\int_{\Omega}\lim_{n\to \infty} g_n(\omega)d\omega=\int_{\Omega}\frac{ \partial f }{ \partial x }(a,\omega)d\omega.
		\end{equation}
		Notons que l'existence de la dernière intégrale fait partie du théorème de la convergence dominée.

		Nous avons donc prouvé que la limite de gauche existait et ne dépendait pas de la suite choisie. Donc \( F\) est dérivable en \( a\) et la dérivée vaut cette limite :
		\begin{equation}
			F'(a)=\int_{\Omega}\frac{ \partial f }{ \partial x }(a,\omega)d\mu(\omega).
		\end{equation}
	\end{subproof}
\end{proof}

En ce qui concerne les fonctions dans \( \eR^n\), il y a les  propositions~\ref{PropDerrSSIntegraleDSD} et~\ref{PropAOZkDsh} qui parlent de différentiabilité sous l'intégrale.

\begin{probleme}
	Attention : l'énoncé et la démonstration de la proposition \ref{PROPooJKXJooLxgEGd} sont de moi. Écrivez-moi pour
	\begin{itemize}
		\item me dire si ça vous semble correct (ou pas),
		\item me donner un lien vers une source qui énonce et démontre ce résultat.
	\end{itemize}
\end{probleme}


\begin{proposition}[\cite{MonCerveau}]     \label{PROPooJKXJooLxgEGd}
	Soient un espace mesuré \( (\Omega,\mu)\) ainsi qu'une fonction \( f\colon \eR^n\times \Omega\to \eC\). Si \( \omega\in \Omega\) est fixé, nous notons
	\begin{equation}
		\begin{aligned}
			f_{\omega}\colon \eR^n & \to \eC             \\
			x                      & \mapsto f(x,\omega)
		\end{aligned}
	\end{equation}
	et si \( x\in \eR^n\) est fixé, nous notons
	\begin{equation}
		\begin{aligned}
			f_x\colon \Omega & \to \eC              \\
			\omega           & \mapsto f(x,\omega).
		\end{aligned}
	\end{equation}
	Soient \( \delta>0\), \( A\) de mesure nulle dans \( \Omega\) et une liste d'indices\footnote{Voir \ref{NORMooRRZCooMOKAzY}.} \( \alpha\) tels que
	\begin{enumerate}
		\item
		      pour tout \( x\in \eR^n\), la fonction \( f_x\) est dans \( L^1(\Omega)\),
		\item
		      la dérivée partielle multiple \( \partial^{\alpha}f_{\omega}(x)\) existe pour tout \( x\in B(a,\delta)\) et pour tout \( \omega\in A^c\).
		\item pour toute queue \( \beta\) de la liste d'indice \( \alpha\), il existe une fonction \( G_{\beta}\in L^1(\Omega)\) telle que
		      \begin{equation}
			      | (\partial^{\beta}f_{\omega})(x) |\leq G_{\beta}(\omega)
		      \end{equation}
		      pour tout \( x\in B(a,\delta)\) et \( \omega\in A^{c}\).
	\end{enumerate}
	Enfin nous posons
	\begin{equation}
		F(x)=\int_{\Omega}f(x,\omega)d\mu(\omega).
	\end{equation}
	Alors pour toute queue de suite \( \beta\) de \( \alpha\), nous avons
	\begin{enumerate}
		\item
		      \( (\partial^{\beta}F)\) existe en \( a\),
		\item
		      nous avons la formule
		      \begin{equation}        \label{EQooTDDWooAcLRwX}
			      (\partial^{\beta}F)(x)=\int_{\Omega}(\partial^{\beta}f_{\omega})(a)d\mu(\omega).
		      \end{equation}
	\end{enumerate}
\end{proposition}

\begin{proof}
	Nous allons opérer une récurrence sur \( \alpha\). Plus précisément, si \( | \alpha |=p\), nous allons ajouter une dérivation à la fois, et dans l'ordre inverse de \( \alpha\). Donc nous commençons par \( \partial_{\alpha_p}\), puis par \( (\partial_{p-1}, \partial_p)\), etc.

	Nous commençons par prouver la formule \eqref{EQooTDDWooAcLRwX} dans le cas de \( \beta=(\alpha_p)\). Et pour alléger les notations nous notons \( \alpha_p=i\). Nous posons
	\begin{equation}
		\begin{aligned}
			\varphi\colon \eR\times \Omega & \to \eC                   \\
			(t,\omega)                     & \mapsto f(a+te_i,\omega).
		\end{aligned}
	\end{equation}
	Posons \( H(t)=F(a+te_i)\), c'est-à-dire
	\begin{equation}
		H(t)=\int_{\Omega}f(a+te_i,\omega)d\mu(\omega)=\int_{\Omega}\varphi(t,\omega)d\mu(\omega).
	\end{equation}
	En utilisant le théorème \ref{ThoMWpRKYp} sur la fonction \( \varphi\) nous trouvons
	\begin{equation}
		H'(0)=\int_{\Omega}\varphi'(0,\omega)d\mu(\omega)=\int_{\Omega}\frac{ \partial f }{ \partial x_i }(a,\omega)d\mu(\omega),
	\end{equation}
	ce qui est la formule demandée dans le cas \( \alpha=(i)\).

	Pour la récurrence, nous supposons que la formule est démontrée pour \( \beta=(\alpha_{p-k},\ldots, \alpha_p)\), et nous montrons qu'elle fonctionne encore pour \( \sigma=(i, \beta)\).

	Il s'agit simplement de remarquer que la fonction
	\begin{equation}
		g(x,\omega)=(\partial^{\beta}f_{\omega})(x)
	\end{equation}
	vérifie encore les conditions du théorème \ref{ThoMWpRKYp}\quext{Je n'ai pas fait cette vérification. Écrivez-moi si vous l'avez faite.}.
\end{proof}

%-------------------------------------------------------
\subsection{Dérivation et intégrale}
%----------------------------------------------------


\begin{probleme}		\label{PROBooGVWHooOTNJFe}
	Si je regarde bien, le théorème \ref{ThoDerSousIntegrale} n'est utilisé nulle part. Je vais donc le supprimer un jour. Si vous l'aimez, vous devriez m'en envoyer une démonstration.
\end{probleme}


\begin{theorem}     \label{ThoDerSousIntegrale}
	Soient \( A\) un intervalle ouvert de \( \eR\) et \( \Omega\) un espace mesuré. Soient une fonction \( f\colon A\times \Omega\to \eR\) et
	\begin{equation}
		F(x)=\int_{\Omega}f(x,\omega)d\omega.
	\end{equation}
	Nous supposons les points suivants.
	\begin{enumerate}
		\item
		      La fonction \( f\) est mesurable.
		\item
		      Pour chaque \( x\in A\), la fonction  \( \omega\mapsto f(x,\omega)\) est intégrable sur \( \Omega\).
		\item
		      Pour presque tout \( \omega\in\Omega\), la fonction \( f(x,\omega)\) est une fonction absolument continue\footnote{Définition \ref{DEFooLZWPooSSRaMv} et proposition \ref{PROPooUMXIooUhbZvl}.} de \( x\).
		\item
		      La fonction \( \frac{ \partial f }{ \partial x }\) est localement intégrable, c'est-à-dire que pour tout \( \mathopen[ a , b \mathclose]\subset A\),
		      \begin{equation}
			      \int_a^b\int_{\Omega}\left| \frac{ \partial f }{ \partial x }(x,\omega) \right| d\omega\,dx<\infty.
		      \end{equation}
	\end{enumerate}
	Alors la fonction \( F\) est absolument continue et pour presque tout \( x\in A\), la dérivée est donné par
	\begin{equation}
		\frac{ d }{ dx }\int_{\Omega}f(x,\omega)d\omega=\int_{\Omega}\frac{ \partial f }{ \partial x }(x,\omega)d\omega.
	\end{equation}
	% Note que je crois que ce théorème n'est utilisé nulle part. On peut juste le supprimer, et le problème PROBooGVWHooOTNJFe en même temps
\end{theorem}

\ssdem

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Différentiabilité sous l'intégrale}
%---------------------------------------------------------------------------------------------------------------------------

Le théorème suivant est restrictif sur l'ensemble d'intégration (qui doit être compact), mais accepte des fonctions de plusieurs variables, ce qui est un premier pas vers la différentiabilité.
\begin{proposition}[Dérivation sous l'intégrale]        \label{PropDerrSSIntegraleDSD}
	Supposons \( A\subset\eR^m\) ouvert et \( B\subset\eR^n\) compact. Nous considérons une fonction \( f\colon A\times B\to \eR\). Si pour un \( i\in\{ i,\ldots,n \}\), la dérivée partielle \( \frac{ \partial f }{ \partial x_i }\) existe dans \( A\times B\) et est continue, alors la fonction
	\begin{equation}
		F(x)=\int_Bf(x,t)dt
	\end{equation}
	admet une dérivée partielle dans la direction \( x_i\) sur \( A\). Cette dérivée partielle y est continue et
	\begin{equation}
		\frac{ \partial F }{ \partial x_i }(a)=\int_B\frac{ \partial f }{ \partial x_i }(a,t)dt,
	\end{equation}
	pour tout \( a\) dans l'ouvert \( A\).
\end{proposition}
\index{fonction!définie par une intégrale}
\index{permuter!dérivée et intégrale!\( \eR^n\)}

\begin{proof}
	Nous procédons en plusieurs étapes.
	\begin{subproof}
		\spitem[\( F\) est dérivable]
		Nous voulons prouver que \( \frac{ \partial F }{ \partial x_i }(a,t)\) existe. Pour cela nous posons
		\begin{equation}
			g_l(t)=\frac{ f(a_1,\ldots, a_i+\epsilon_l,\ldots, a_n,t)-f(a_1,\ldots, a_i,\ldots, a_n,t) }{ \epsilon_l }
		\end{equation}
		où \( \epsilon_l\) est une suite de nombres tendant vers zéro. La fonction \( f\) est dérivable dans la direction \( x_i\) si et seulement si \( \lim_{l\to \infty}g_l(t) \) existe et ne dépend pas du choix de la suite. À ce moment, la valeur de la dérivée partielle sera cette limite. Dans notre cas, nous savons que \( f\) admet une dérivée partielle dans la direction \( x_i\) et donc nous avons
		\begin{equation}
			\frac{ \partial f }{ \partial x_i }(a,t)=\lim_{l\to \infty} g_l(t).
		\end{equation}

		De la même façon pour \( F\) nous avons
		\begin{equation}
			\frac{ \partial F }{ \partial x_i }=\lim_{l\to \infty} \int_{B}g_l(t)dt.
		\end{equation}
		Sous-entendu : si la limite de droite ne dépend pas de la suite choisie, alors \( \frac{ \partial F }{ \partial x_i }\) existe et vaut cette limite.

		Considérant la continuité de \( f\), le seul point à vérifier pour le théorème de la convergence dominée de Lebesgue est l'existence d'une fonction intégrable de \( t\) majorant \( g_l\). Pour cela le théorème de accroissements finis (théorème~\ref{ThoAccFinis}) appliqué à la fonction \( \epsilon\mapsto f(a_n,\ldots, a_i+\epsilon,\ldots, a_n)\) nous dit que
		\begin{equation}
			f(a_1,\ldots, a_i+\epsilon_l,\ldots, a_n,t)-f(a_1,\ldots, a_i,\ldots, a_n,t)=\epsilon_l\frac{ \partial f }{ \partial x_i }(a_1,\ldots, \theta,\ldots, a_n,t)
		\end{equation}
		pour un certain \( \theta\in B(a_i,\epsilon_l)\). Notons que ce \( \theta\) dépend de \( t\) mais pas de \( l\). Vu que \( \partial_if\) est continue par rapport à ses deux variables, si \( K\) est un voisinage compact autour de \( a\), il existe \( M>0\) tel que
		\begin{equation}    \label{EqMXqviPC}
			\left| \frac{ \partial f }{ \partial x_i }(x,t) \right| < M
		\end{equation}
		pour tout \( x\in K\) et tout \( t\in B\). La valeur de \( \frac{ \partial f }{ \partial x_i }(a_1,\ldots, \theta,\ldots, a_n,t)\) est donc bien majorée par rapport à \( \theta\) et par rapport à \( t\) en même temps par une constante qui n'a pas de mal à être intégrée sur le compact \( B\).

		Le théorème de la convergence dominée (théorème~\ref{ThoConvDomLebVdhsTf}) s'applique donc bien et nous avons
		\begin{equation}
			\lim_{l\to \infty} \int_Bg_l(t)dt=\int_B\lim_{l\to \infty} g_l(t)=\int_B\frac{ \partial f }{ \partial x_i }(a,t)dt.
		\end{equation}
		Le membre de droite ne dépendant pas de la suite \( \epsilon_l\) choisie, le membre de gauche est bien la dérivée de \( F\) par rapport à \( x_i\) et nous avons
		\begin{equation}
			\frac{ \partial F }{ \partial x_i }(a)=\int_B\frac{ \partial f }{ \partial x_i }(a,t)dt.
		\end{equation}
		Cela prouve la première partie de la proposition.

		\spitem[La dérivée est continue]
		Soit \( K\) un voisinage compact autour de \( a\) et \( U'\) un ouvert tel que \( a\in U'\subset K\). Nous avons encore la majoration \eqref{EqMXqviPC} sur \( U'\) et donc le théorème de continuité sous l'intégrale~\ref{ThoKnuSNd} nous indique que la fonction
		\begin{equation}
			\begin{aligned}
				U' & \to \eR                                                    \\
				x  & \mapsto \int_{B}\frac{ \partial f }{ \partial x_i }(x,t)dt
			\end{aligned}
		\end{equation}
		est continue en \( a\).

	\end{subproof}
\end{proof}

Une conséquence de la proposition~\ref{PropDerrSSIntegraleDSD} est que si elle fonctionne pour tous les \( i\), alors \( F\) est différentiable et même de classe \( C^1\), et la différentielle de \( F\) s'obtient comme intégrale de la différentielle de \( f\).

\begin{proposition}\label{PropAOZkDsh}
	Supposons \( A\subset\eR^m\) ouvert et \( B\subset\eR^n\) compact. Si pour tout \( i\in\{ i,\ldots,n \}\), la dérivée partielle \( \frac{ \partial f }{ \partial x_i }\) existe dans \( A\times B\) et est continue, alors \( F\) est de classe \( C^1\) et
	\begin{equation}
		(dF)_a=\int_B(df_t)_adt
	\end{equation}
	où \( f_t(x)=f(x,t)\).
\end{proposition}
\index{permuter!différentielle et intégrale!\( \eR^n\)}

\begin{proof}
	En vertu de la proposition~\ref{PropDerrSSIntegraleDSD}, toutes les dérivées partielles de \( F\) sont continues. Cela implique que \( F\) est de classe \( C^1\) par le théorème \ref{THOooBEAOooBdvOdr} et que la différentielle s'écrive en termes des dérivées partielles avec la formule usuelle. Nous avons alors
	\begin{subequations}
		\begin{align}
			(dF)_a(u) & =\sum_k\frac{ \partial F }{ \partial x_k }(a)u_k           \\
			          & =\int_B\sum_k\frac{ \partial f }{ \partial x_k }(a,t)dt    \\
			          & =\int_B\sum_k\frac{ \partial f_t }{ \partial x_k }(a)u_kdt \\
			          & =\int_B (df_t)_a(u)dt.
		\end{align}
	\end{subequations}
	Ce qui est la formule annoncée.
\end{proof}

Un autre théorème tourne autour du pot, et me semble inutile.
\begin{theorem} \label{ThoOLAQyRL}
	Soit \( (\Omega,\mu)\) un espace mesuré, une fonction \( f\colon \eR^n\times \Omega\to \eR\) et \( a\in \eR^n\). Nous considérons la fonction
	\begin{equation}
		F(x)=\int_{\Omega}f(x,\omega)d\mu(\omega).
	\end{equation}
	Pour chaque \( k=1,\ldots, n\) nous supposons avoir
	\begin{equation}
		\frac{ \partial F }{ \partial x_k }(a)=F_{|_k}'(a)=\int_{\Omega}\frac{ \partial f_{|_k} }{ \partial t }(a_k,\omega)d\mu(\omega)
	\end{equation}
	où \( F_{|_k}(t)=F(a_1,\ldots, t,\ldots, a_n)\) et \( f_{|_k}\) est définie de façon similaire.

	Nous supposons de plus que les fonctions \( \partial_{x_k}F\) sont continues.

	Alors \( F\) est de classe \( C^1\) et sa différentielle est donnée par
	\begin{equation}
		dF_a=\int_{\Omega}(df_{\omega})_ad\omega
	\end{equation}
	où \( f_{\omega}\) est définie par \( f_{\omega}(x)=f(x,\omega)\).
\end{theorem}

\begin{proof}
	Étant donné que les dérivées partielles de \( F\) en \( a\) existent et sont continues, le théorème \ref{THOooBEAOooBdvOdr} dit que \( F\) est différentiable et que
	\begin{equation}
		dF_a(u)=\sum_{k=1}^n\frac{ \partial F }{ \partial x_k }(a)u_k.
	\end{equation}
	La linéarité de l'intégrale et les hypothèses nous donnent alors
	\begin{subequations}
		\begin{align}
			dF_a(u) & =\sum_{k=1}^n\frac{ \partial F }{ \partial x_k }(a)u_k                                 \\
			        & =\int_{\Omega}\sum_k\frac{ \partial f_{|_k} }{ \partial t }(a_k;\omega)u_kd\mu(\omega) \\
			        & =\int_{\Omega}\sum_k\frac{ \partial f }{ \partial x_k }(a;\omega)u_kd\mu(\omega)       \\
			        & =\int_{\Omega}(df_{\omega})_a(u)d\mu(\omega),
		\end{align}
	\end{subequations}
	et donc \( dF_a=\int_{\Omega}(df_{\omega})_ad\mu(\omega)\).
\end{proof}
Notons qu'en passant aux composantes, ce théorème fonctionne tout aussi bien pour des fonctions à valeurs dans un espace vectoriel normé de dimension finie plutôt que dans \( \eR\).


%+++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Théorème d'Hadamard}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++


\begin{lemma}[Hadamard\cite{MVIooKLsjpa}]   \label{LemWNBooGPlIwT}
	Soit une fonction \( f\colon \eR^n\to \eR\) de classe \( C^p\) avec \( p\geq 1\). Pour tout \( a\in \eR^n\) il existe des fonctions \( g_1\),\ldots, \( g_n\) de classe \( C^{p-1}\) telles que
	\begin{equation}
		f(x)=f(a)+\sum_{i=1}^n(x_i-a_i)g_i(x).
	\end{equation}
\end{lemma}
\index{lemme!Hadamard}

\begin{proof}
	Puisque \( f\) est de classe \( C^1\), le théorème fondamental de l'analyse~\ref{ThoRWXooTqHGbC} s'applique et
	\begin{equation}    \label{EqZLTooVKmGln}
		f(x)-f(a)=\int_0^1\frac{ d }{ dt }\Big[ f\big( a+t(x-a) \big) \Big]dt=\int_0^1\sum_{i=1}^n\frac{ \partial f }{ \partial x_i }\big( a+t(x-a) \big)(x_i-a_i).
	\end{equation}
	Plus de détails : la fonction \( t\mapsto \frac{ d }{ dt }\Big[ f\big( a+t(x-a) \big) \Big]\) possède comme primitive la fonction \( F(t)=f\big( a+t(x-a) \big)\).

	Nous posons
	\begin{equation}
		g_i(x)=\int_0^1\frac{ \partial f }{ \partial x_i }\big( a+t(x-a) \big)dt
	\end{equation}
	L'intégrale existe parce qu'il s'agit d'une fonction continue sur un compact et donc majorée par une constante. Pour voir que \( g_i\) est de classe \( C^{p-1}\) nous pouvons calculer \( \frac{ \partial g_i }{ \partial x_k }\) en permutant dérivée et intégrale par la proposition~\ref{PropDerrSSIntegraleDSD} :
	\begin{equation}
		\frac{ \partial g_i }{ \partial x_k }(x)=\int_0^1\frac{ \partial  }{ \partial x_k }\left( \frac{ \partial f }{ \partial x_i }\big( a+t(x-a) \big) \right)dt=\int_0^1 t\frac{ \partial^2f }{ \partial x_k\partial x_i }\big( a+t(x-a) \big).
	\end{equation}
	Nous pouvons ainsi permuter \( p-1\) dérivées tout en gardant une fonction continue dans l'intégrale. Le théorème~\ref{ThoKnuSNd} nous donne alors une fonction continue. Ainsi toutes les fonctions
	\begin{equation}
		\frac{ \partial^{p-1}g_i }{ \partial x_{i_1}\ldots\partial x_{i_{p-1}} }
	\end{equation}
	sont continues et \( g_i\) est de classe \( C^{p-1}\) par le théorème \ref{THOooPZTAooTASBhZ}.

	En repartant de \eqref{EqZLTooVKmGln} nous avons alors bien ce qui était annoncé :
	\begin{equation}
		f(x)=f(a)+\sum_{i=1}^ng_i(x)(x_i-a_i).
	\end{equation}
\end{proof}

\begin{corollary}       \label{CorQBXHooZVKeNG}
	Soit \( \phi\in\swD(\eR)\) tel que \( \phi^{(k)}(x_0)=0\) pour tout \( k\leq n\). Alors il existe une fonction \( \psi\in\swD(\eR)\) telle que
	\begin{equation}
		\phi(x)=(x-x_0)^{n+1}\psi(x)
	\end{equation}
	pour tout \( x\in \eR\).
\end{corollary}

\begin{proof}
	En utilisant le lemme de Hadamard~\ref{LemWNBooGPlIwT} avec \( a=x_0\), \( n=1\) et \( f(x_0)=0\), nous avons une fonction \( g_1\) à support compact telle que
	\begin{equation}        \label{EqTOJGooWZBBRJ}
		\phi(x)=\phi(x_0)+(x-x_0)g_1(x).
	\end{equation}
	Alors \( \phi'(x)=g_1(x)+(x-x_0)g'_1(x)\), ce qui donne immédiatement \( g_1(x_0)=0\) et donc une fonction \( g_2\) telle que \( g_1(x)=(x-x_0)g_2(x)\). En injectant dans \eqref{EqTOJGooWZBBRJ} nous avons
	\begin{equation}
		\phi(x)=(x-x_0)^2g_2(x).
	\end{equation}
	Il suffit de continuer ainsi tant que les dérivées de \( \phi\) s'annulent.
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Deux théorèmes de point fixe}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Nous allons voir Picard. Les autres théorème de point fixe que sont Brouwer, Schauder et Markov-Kakutani sont plus bas\footnote{Dans la section \ref{SECooDWMPooWZgzRZ}.} parce qu'ils utilisent de l'intégration. Voir le thème \ref{THEMEooWAYJooUSnmMh} pour les retrouver.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Points fixes attractifs et répulsifs}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}[\cite{MonCerveau}]      \label{DEFooTMZUooMoBDGC}
	Soit \( I\) un intervalle fermé de \( \eR\) et \( \varphi\colon I\to I\) une application \( C^1\). Soit \( a\) un point fixe de \( \varphi\). Nous disons que \( a\) est \defe{attractif}{point fixe!attractif}\index{attractif!point fixe} si il existe un voisinage \( V\) de \( a\) tel que pour tout \( x_0\in V\) la suite \( x_{n+1}=\varphi(x_n)\) converge vers \( a\).

	Le point \( a\) est dit \defe{répulsif}{répulsif!point fixe} si il existe un voisinage\quext{Cette partie de la définition est de moi. Je suis loin d'être sûr que c'est une bonne définition. Si vous avez une idée, écrivez-moi. Sinon, tenez-vous en à prendre le lemme \ref{LEMooTIRAooQIHLyt} comme définition.} \( V\) de \( a\) tel que pour toute suite de la forme \( x_{n+1}=\varphi(x_n) \), si \( u_n\in V\), alors \( | x_{n+1}-a |\geq | u_n-a |\).
\end{definition}

\begin{normaltext}
	Beaucoup de sources prennent le lemme \ref{LEMooTIRAooQIHLyt} comme définition de point fixe attractif et répulsif. Celle en termes de suites ne demande au moins pas la dérivabilité de \( f\). Elle est donc un tout petit peu plus générale.
\end{normaltext}

\begin{lemma}[\cite{DemaillyNum,BIBooJDCBooGNRxMN}]		\label{LEMooTIRAooQIHLyt}
	Soient un intervalle \( I\) de \( \eR\), et une application \(\varphi \colon I\to I  \) de classe \( C^1\). Soit \( a\) un point fixe de \( \varphi\).
	\begin{enumerate}
		\item
		      Si \( | \varphi'(a) |<1\) alors \( a\) est attractif et la convergence est au moins exponentielle.
		\item
		      Si \( | \varphi'(a) |>1\) alors \( a\) est répulsif et la divergence est au moins exponentielle.
	\end{enumerate}
\end{lemma}

\begin{proof}
	Si \( | \varphi'(a)|<1 \) alors il existe \( k\) tel que \( | \varphi'(a) |<k<1\) et par continuité il existe un voisinage \( V\) de \( a\) dans lequel \( | \varphi'(x) |<k\) pour tout \( x\in V\). En utilisant le théorème des accroissements finis\footnote{Proposition \ref{PropUTenzfQ}.} nous avons
	\begin{equation}
		| x_n-a |=\big|  \varphi(x_n)-a  \big|\leq k| x_{n-1}-a |
	\end{equation}
	et par récurrence
	\begin{equation}
		| x_n-a |\leq k^n| x_0-a |.
	\end{equation}

	Pour la seconde partie, nous supposons que \( | f'(a) |>1\). Il existe un voisinage \( V\) sur lequel \( f'>1\). La formule des accroissements finis donne une application \(  \alpha\colon \eR\to \eR  \) telle que
	\begin{equation}
		f(a+h)=f(a)+hf'(a)+\alpha(h)
	\end{equation}
	et \( \alpha(h)/h\to 0\). Nous restreignons \( V\) pour que tout \( x\in V\) nous ayons \( | \alpha(x-a)/| x-a | +| f'(a) | <1\). Bref. Supposons que \( x_n\in V\) avec \( x_n\neq a\). Nous avons alors
	\begin{subequations}
		\begin{align}
			x_{n+1} & =f(x_n)                           \\
			        & =f\big( a+(x_n-a) \big)           \\
			        & =f(a)+(x_n-a)f'(a)+\alpha(x_n-a).
		\end{align}
	\end{subequations}
	Nous avons donc
	\begin{equation}
		\frac{| x_{n+1}-f(a) |}{| x_n-a |}\leq | f'(a) |+\frac{| \alpha(x_n-a) |}{| x_n-a |}.
	\end{equation}
	Avec toutes les hypothèses que nous avons prises, nous avons
	\begin{equation}
		\frac{| x_{n+1}-f(a) |}{| x_n-a |}\leq 1,
	\end{equation}
	et donc \( | x_{n+1}-f(a) |<| x_n-a |\).
\end{proof}

\begin{remark}
	Dans le cas \(| \varphi'(a) |=1\), nous ne pouvons rien conclure. Si \( \varphi(x)=\sin(x)\) nous avons \( \sin(x)<x\) et le point \( a=0\) est attractif. À contrario, si \( \varphi(x)=\sinh(x)\) nous avons \( |\sinh(x)|>|x|\) et le point \( a=0\) est répulsif.
\end{remark}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Picard}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}      \label{DEFooRSLCooAsWisu}
	Une application \( f\colon (X,d_X)\to (Y,d_Y)\) entre deux espaces métriques est une \defe{contraction}{contraction} si elle est \( k\)-\defe{lipschitzienne}{lipschitzienne} pour un certain \( 0\leq k<1\), c'est-à-dire si pour tout \( x,y\in X\) nous avons
	\begin{equation}
		d_Y\big(  f(x),f(y) \big) \leq k d_X(x,y).
	\end{equation}
\end{definition}

\begin{theorem}[Picard \cite{ClemKetl,NourdinAnal}\footnote{Il me semble qu'à la page 100 de \cite{NourdinAnal}, l'hypothèse H1 qui est prouvée ne prouve pas Hn dans le cas \( n=1\). Merci de m'écrire si vous pouvez confirmer ou infirmer. La preuve donnée ici ne contient pas cette «erreur».}.]     \label{ThoEPVkCL}
	Soit \( X\) un espace métrique complet et \( f\colon X\to X\) une application contractante, de constante de Lipschitz \( k\). Alors \( f\) admet un unique point fixe, nommé \( \xi\). Ce dernier est donné par la limite de la suite définie par récurrence
	\begin{subequations}
		\begin{numcases}{}
			x_0\in X\\
			x_{n+1}=f(x_n).
		\end{numcases}
	\end{subequations}
	De plus nous pouvons majorer l'erreur par
	\begin{equation}    \label{EqKErdim}
		\| x_n-x \|\leq \frac{ k^n }{ 1-k }\| x_n-x_{n-1} \|\leq \frac{ k^n }{ 1-k }\| x_1-x_0 \|.
	\end{equation}

	Soit \( r>0\), \( a\in X\) tels que la fonction \( f\) laisse la boule \( K=\overline{ B(a,r) }\) invariante (c'est-à-dire que \( f\) se restreint à \( f\colon K\to K\)). Nous considérons les suites \( (u_n)\) et \( (v_n)\) définies par
	\begin{subequations}
		\begin{numcases}{}
			u_0=v_0\in K\\
			u_{n+1}=f(v_n), v_{n+1}\in B(u_n,\epsilon).
		\end{numcases}
	\end{subequations}
	Alors le point fixe \( \xi\) de \( f\) est dans \( K\) et la suite \( (v_n)\) satisfait l'estimation
	\begin{equation}
		\| v_n-\xi \|\leq \frac{ k^n }{ 1-k }\| u_1-u_0 \|+\frac{ \epsilon }{ 1-k }.
	\end{equation}
\end{theorem}
\index{théorème!Picard}
\index{point fixe!Picard}

La première inégalité \eqref{EqKErdim} donne une estimation de l'erreur calculable en cours de processus; la seconde donne une estimation de l'erreur calculable avant de commencer.

\begin{proof}
	Nous commençons par l'unicité du point fixe. Si \( a\) et \( b\) sont des points fixes, alors \( f(a)=a\) et \( f(b)=b\). Par conséquent
	\begin{equation}
		\| f(a)-f(b) \|=\| a-b \|,
	\end{equation}
	ce qui contredit le fait que \( f\) soit une contraction.

	En ce qui concerne l'existence, notons que si la suite des \( x_n\) converge dans \( X\), alors la limite est un point fixe. En effet en prenant la limite des deux côtés de l'équation \( x_{n+1}=f(x_n)\), nous obtenons \( \xi=f(\xi)\), c'est-à-dire que \( \xi\) est un point fixe de \( f\). Notons que nous avons utilisé ici la continuité de \( f\), laquelle est une conséquence du fait qu'elle soit lipschitzienne. Nous allons donc porter nos efforts à prouver que la suite est de Cauchy (et donc convergente parce que \( X\) est complet). Nous commençons par prouver que \( \| x_{n+1}-x_n \|\leq k^n\| x_0-x_1 \|\). En effet pour tout \( n\) nous avons
	\begin{equation}
		\| x_{n+1}-x_n \|=\| f(x_n)-f(x_{n-1}) \|\leq k\| x_n-x_{n-1} \|.
	\end{equation}
	La relation cherchée s'obtient alors par récurrence. Soient \( q>p\). En utilisant une somme télescopique,
	\begin{subequations}
		\begin{align}
			\| x_q-x_p \| & \leq \sum_{l=p}^{q-1}\| x_{l+1}-x_l \|                 \\
			              & \leq \left( \sum_{l=p}^{q-1}k^l \right)\| x_1-x_0 \|   \\
			              & \leq \left(\sum_{l=p}^{\infty}k^l\right)\| x_1-x_0 \|.
		\end{align}
	\end{subequations}
	Étant donné que \( k<1\), la parenthèse est la queue d'une série qui converge, et donc tend vers zéro lorsque \( p\) tend vers l'infini.

	En ce qui concerne les inégalités \eqref{EqKErdim}, nous refaisons une somme télescopique :
	\begin{subequations}
		\begin{align}
			\| x_{n+p}-x_n \| & \leq \| x_{n+p}-x_{n+p-1} \|+\cdots +\| x_{n+1}-x_n \|                        \\
			                  & \leq k^p\| x_n-x_{n-1} \|+k^{p-1}\| x_n-x_{n-1} \|+\cdots +k\| x_n-x_{n-1} \|
			= k(1+\cdots +k^{p-1})\| x_n-x_{n-1}\|                                                            \\
			                  & \leq \frac{ k }{ 1-k }\| x_n-x_{n-1} \|.
		\end{align}
	\end{subequations}
	En prenant la limite \( p\to \infty\) nous trouvons
	\begin{equation}        \label{EqlUMVGW}
		\| \xi-x_n \|\leq \frac{ k }{ 1-k }\| x_n-x_{n-1} \|\leq \frac{ k }{ 1-k }\| x_1-x_0 \|.
	\end{equation}

	Nous passons maintenant à la seconde partie du théorème en supposant que \( f\) se restreigne en une fonction \( f\colon K\to K\). D'abord \( K\) est encore un espace métrique complet, donc la première partie du théorème s'y applique et \( f\) y a un unique point fixe.

	Nous allons montrer la relation par récurrence. Tout d'abord pour \( n=1\) nous avons
	\begin{equation}
		\| v_1-\xi \|\leq\| v_1-u_1 \|+\| u_1-\xi \|\leq \epsilon+\frac{ k }{ 1-k }\| u_1-u_0 \|
	\end{equation}
	où nous avons utilisé l'estimation \eqref{EqlUMVGW}, qui reste valable en remplaçant \( x_1\) par \( u_1\)\footnote{Elle n'est cependant pas spécialement valable si on remplace \( x_n\) par \( u_n\).}. Nous pouvons maintenant faire la récurrence :
	\begin{subequations}
		\begin{align}
			\| v_{n+1}-\xi \| & \leq  \| v_{n+1}-u_{n+1} \|+\| u_{n+1}-\xi \|                                            \\
			                  & \leq  \epsilon+k\| v_n-\xi \|                                                            \\
			                  & \leq  \epsilon+k\left( \frac{ k^n }{ 1-k }\| u_1-u_0 \|+\frac{ \epsilon }{ 1-k } \right)
			=   \frac{ \epsilon }{ 1-k }+\frac{ k^{n+1} }{ 1-k }\| u_1-u_0 \|.
		\end{align}
	\end{subequations}
\end{proof}

\begin{remark}
	Ce théorème comporte deux parties d'intérêts différents. La première partie est un théorème de point fixe usuel, qui sera utilisé pour prouver l'existence de certaines équations différentielles.

	La seconde partie est intéressante d'un point de vue numérique. En effet, ce qu'elle nous enseigne est que si à chaque pas de calcul de la récurrence \( x_{n+1}=f(x_n)\) nous commettons une erreur d'ordre de grandeur \( \epsilon\), alors le procédé (la suite \( (v_n)\)) ne converge plus spécialement vers le point fixe, mais tend vers le point fixe avec une erreur majorée par \( \epsilon/(1-k)\).
\end{remark}

\begin{remark}
	Au final l'erreur minimale qu'on peut atteindre est de l'ordre de \( \epsilon\). Évidemment si on commet une faute de calcul de l'ordre de \( \epsilon\) à chaque pas, on ne peut pas espérer mieux.
\end{remark}

\begin{remark}  \label{remIOHUJm}
	Si \( f\) elle-même n'est pas contractante, mais si \( f^p\) est contractante pour un certain \( p\in \eN\) alors la conclusion du théorème de Picard reste valide et \( f\) a le même unique point fixe que \( f^p\). En effet nommons \( x\) le point fixe de \( f\) : \( f^p(x)=x\). Nous avons alors
	\begin{equation}
		f^p\big( f(x) \big)=f\big( f^p(x) \big)=f(x),
	\end{equation}
	ce qui prouve que \( f(x)\) est un point fixe de \( f^p\). Par unicité nous avons alors \( f(x)=x\), c'est-à-dire que \( x\) est également un point fixe de \( f\).
\end{remark}

\begin{theorem}[Équation de Fredholm]\index{Fredholm!équation}\index{équation!Fredholm}     \label{ThoagJPZJ}
	Soit \( K\colon \mathopen[ a , b \mathclose]\times \mathopen[ a , b \mathclose]\to \eR\) et \( \varphi\colon \mathopen[ a , b \mathclose]\to \eR\), deux fonctions continues. Alors si \( \lambda\) est suffisamment petit, l'équation
	\begin{equation}
		f(x)=\lambda\int_a^bK(x,y)f(y)dy+\varphi(x)
	\end{equation}
	admet une unique solution qui sera de plus continue sur \( \mathopen[ a , b \mathclose]\).
\end{theorem}

\begin{proof}
	Nous considérons l'ensemble \( \mF\) des fonctions continues \( \mathopen[ a , b \mathclose]\to\mathopen[ a , b \mathclose]\) muni de la norme uniforme. Le lemme~\ref{LemdLKKnd} implique que \( \mF\) est complet. Nous considérons l'application \( \Phi\colon \mF\to \mF\) donnée par
	\begin{equation}
		\Phi(f)(x)=\lambda\int_a^bK(x,y)f(y)dy+\varphi(x).
	\end{equation}
	Nous montrons que \( \Phi^p\) est une application contractante pour un certain \( p\). Pour tout \( x\in \mathopen[ a , b \mathclose]\) nous avons
	\begin{subequations}
		\begin{align}
			\| \Phi(f)-\Phi(g) \|_{\infty} & \leq \| \Phi(f)(x)-\Phi(g)(x) \|                                    \\
			                               & =   | \lambda |\Big\| \int_a^bK(x,y)\big( f(y)-g(y) \big)dy  \Big\| \\
			                               & \leq  | \lambda |\| K \|_{\infty}| b-a |\| f-g \|_{\infty}
		\end{align}
	\end{subequations}
	Nous choississons \( \lambda\) assez petit pour avoir \( | \lambda |\| K \|_{\infty}| b-a |<1\). Dans ce cas, l'application \( \Phi\) est une contraction. Elle possède donc un unique point fixe par le théorème de Picard~\ref{ThoEPVkCL}.
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Théorèmes de point fixes et équations différentielles}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Théorème de Cauchy-Lipschitz}
%---------------------------------------------------------------------------------------------------------------------------

Nous démontrons ici deux théorèmes de Cauchy-Lipschitz. De nombreuses propriétés annexes seront démontrées dans le chapitre sur les équations différentielles, section~\ref{SECooNKICooDnOFTD}.

Le théorème de Cauchy-Arzella \ref{ThoHNBooUipgPX} sera pour plus tard parce qu'il utilise Schauder \ref{ThovHJXIU}.

\begin{theorem}[Cauchy-Lipschitz\cite{SandrineCL,ZPNooLNyWjX}] \label{ThokUUlgU}
	Nous considérons l'équation différentielle
	\begin{subequations}        \label{XtiXON}
		\begin{numcases}{}
			y'(t)=f\big( t,y(t) \big)\\
			y(t_0)=y_0
		\end{numcases}
	\end{subequations}
	avec \( f\colon U=I\times \Omega\to \eR^n\) où \( I\) est ouvert dans \( \eR\) et \( \Omega\) ouvert dans \( \eR^n\). Nous supposons que \( f\) est continue sur \( U\) et localement lipschitzienne\footnote{Définition~\ref{DefJSFFooEOCogV}. Notons que nous ne supposons pas que \( f\) soit une contraction.} par rapport à \( y\).

	Alors il existe un intervalle \( J\subset I\) sur lequel la solution au problème est unique. De plus toute solution du problème est une restriction de cette solution à une partie de \( J\). La solution sur \( J\) (dite «solution maximale») est de classe \( C^1\).
\end{theorem}
\index{théorème!Cauchy-Lipschitz}

% Il serait tentant de mettre ce théorème dans la partie sur les équations différentielles, mais ce n'est pas aussi simple :
% Il est utilisé pour calculer la transformée de Fourier de la Gaussienne (lemme LEMooPAAJooCsoyAJ) dans le chapitre sur la transformée de Fourier.

\begin{proof}
	Nous divisions la preuve en plusieurs étapes (même pas toutes simples).
	\begin{subproof}
		\spitem[Cylindre de sécurité]

		Précisons l'espace fonctionnel \( \mF\) adéquat. Soient \( V\) et \( W\) les voisinages de \( t_0\) et \( y_0\) sur lesquels \( f\) est localement lipschitzienne. Nous considérons les quantités suivantes :
		\begin{enumerate}
			\item
			      \( M=\sup_{V\times W}f\) ;
			\item
			      \( r>0\) tel que \( \overline{ B(y_0,r) }\subset V\)
			\item
			      \( T>0\) tel que \( \overline{ B(t_0,T) }\subset W\) et \( T<r/M\).
		\end{enumerate}
		Nous considérons alors l'ensemble
		\begin{equation}
			\mF=C^0\big( \overline{ B(t_0,T) },\overline{ B(y_0,r) } \big)
		\end{equation}
		que nous munissons de la norme uniforme. Par le lemme~\ref{LemdLKKnd} l'espace \( \big( \mF,\| . \|_{\infty} \big)\) est complet.

		\spitem[Une application \( \Phi\colon \mF\to \mF\)]


		Si \( y\) est une solution de l'équation différentielle considérée, elle vérifie\footnote{C'est le théorème fondamental du calcul intégral \ref{ThoRWXooTqHGbC}.}
		\begin{equation}        \label{EqPGLwcL}
			y(t)=y_0+\int_{t_0}^tf\big( u,y(u) \big)du.
		\end{equation}
		Ceci nous incite à considérer l'opérateur \( \Phi\colon \mF\to \mF\) défini par
		\begin{equation}
			\Phi(y)(t)=y_0+\int_{t_0}^tf\big( u,y(u) \big)du.
		\end{equation}

		Pour que l'application \( \Phi\) soit utile nous devons montrer que pour tout \( y\in \mF\),
		\begin{itemize}
			\item l'application \( \Phi(y)\) est bien définie,
			\item pour tout \( t\in\overline{ B(t_0,T) }\) nous avons \( \Phi(y)(t)\in\overline{ B(y_0,r) }\),
			\item l'application \( \Phi(y)\colon  \overline{ B(t_0,T) } \to \overline{ B(y_0,r)}\) est continue.
		\end{itemize}
		Attention : nous ne prétendons pas que \( \Phi\) elle-même soit continue. C'est parti.
		\begin{subproof}
			\spitem[\( \Phi(y)\) est bien définie]
			%------------------------------------

			Il faut montrer que l'intégrale converge. Le calcul de \( \Phi(y)(t)\) ne se fait qu'avec \( t\in \overline{ B(t_0,T) }\). Vu que \( u\) prend ses valeurs dans \( \mathopen[ t_0 , t \mathclose]\) et que \( y\in\mF\), le nombre \( y(u)\) est toujours dans \( \overline{ B(y_0,r) }\). Ceci pour dire que dans l'intégrale, la fonction \( f\) n'est considérée que sur \( \mathopen[ t_0 , t \mathclose]\times \overline{ B(y_0,r) }\subset V\times W\). La fonction \( f\) est donc uniformément majorable, et l'intégrale ne pose pas de problèmes.

			\spitem[\( \Phi(y)(t)\in \overline{ B(y_0,r) }\)]
			%------------------------------------

			Prouvons que \( \Phi(y)(t)\in\overline{ B(y_0,r) }\). Pour cela, notons que
			\begin{equation}
				| \Phi(y)(t)-y_0 |\leq \int_{t_0}^t |f\big( u,y(u) \big)|du\leq | t-t_0 |\| f \|_{\infty}.
			\end{equation}
			Étant donné que \( t\in\overline{ B(t_0,T) }\) nous avons \( | t-t_0 |\leq r/M\) et donc \( | \Phi(y)(t)-y_0 |\leq r\).

			\spitem[\( \Phi(y)\) est continue]
			%------------------------------------

			Nous pourrions invoquer le théorème~\ref{ThoKnuSNd}, mais nous allons le faire à la main. Soit \( s_0\in B(t_0,T)\) et prouvons que \( \Phi(y)\) est continue en \( s_0\). Pour cela nous prenons \( s\in B(s_0,\delta)\) et nous calculons :
			\begin{equation}
				| \Phi(y)(s)-\Phi(y)(s_0) |\leq \int_{s_0}^s|f\big( u,y(u) \big)|du\leq | s_0-s |\| f \|_{\infty}.
			\end{equation}
			C'est le fait que \( f\) soit bornée dans le cylindre de sécurité qui fait en sorte que cela tende vers zéro lorsque \( s\to s_0\).
		\end{subproof}

		L'équation \eqref{EqPGLwcL} signifie que \( y\) est un point fixe de \( \Phi\). L'espace \( \mF\) étant complet, le théorème de point fixe de Picard (théorème~\ref{ThoEPVkCL}) s'applique. Nous allons montrer qu'il existe un \( p\in\eN\) tel que \( \Phi^p\) soit contractante. Par conséquent \( \Phi^p\) aura un unique point fixe qui sera également unique point fixe de \( \Phi\) par la remarque~\ref{remIOHUJm}.

		\spitem[Contractante]

		Prouvons donc que \( \Phi^p\) est contractante pour un certain \( p\). Pour cela nous commençons par montrer la formule suivante par récurrence :
		\begin{equation}        \label{EqRAdKxT}
			\big\| \Phi^p(x)(t)-\Phi^p(y)(t) \big\|\leq \frac{ k^p| t-t_0 |^p }{ p! }\| x-y \|_{\infty}
		\end{equation}
		pour tout \( x,y\in\mF\), et pour tout \( t\in\overline{ B(t_0,T) }\). Pour \( p=0\) la formule \eqref{EqRAdKxT} est vérifiée parce que \( \| x-y \|_{\infty}\) est le supremum de \( \| x(t)-y(t) \|\) pour \( t\in\overline{ B(t_0,T) }\). Supposons que la formule soit vraie pour \( p\) et calculons pour \( p+1\). Pour tout \( t\in\overline{ B(t_0,T) }\) nous avons
		\begin{subequations}
			\begin{align}
				\big\| \Phi^{p+1}(x)(t)-\Phi^{p+1}(y)(t) \big\| & \leq \left| \int_{t_0}^t\big\| f\big( u,\Phi^p(x)(u) \big)-f\big( u,\Phi^p(y)(u) \big) \big\|du \right|                     \\
				                                                & \leq \left| \int_{t_0}^tk\| \Phi^p(x)(u)-\Phi^p(y)(u) \|du \right|                  \label{subIKYixF}                       \\
				                                                & \leq \left| \int_{t_0}^tk\frac{ k^p| t-t_0 | }{ p! }\| x-y \|_{\infty} \right|                          & \label{subxkNjiV} \\
				                                                & = \frac{ k^{p+1}| t-t_0 |^{p+1} }{ (p+1)! }\| x-y \|_{\infty}.
			\end{align}
		\end{subequations}
		Justifications :
		\begin{itemize}
			\item \eqref{subIKYixF} parce que \( f\) est lipschitzienne.
			\item \eqref{subxkNjiV} par hypothèse de récurrence.
		\end{itemize}
		La formule \eqref{EqRAdKxT} est maintenant établie. Nous pouvons maintenant montrer que \( \Phi^p\) est une contraction pour un certain \( p\). Pour tout \( t\in \overline{ B(t_0,T) }\) nous avons
		\begin{equation}
			\| \Phi^p(x)(t)-\Phi^p(y)(t) \|\leq \frac{ k^p }{ p! }| t-t_0 |^p\| x-y \|_{\infty}     \leq \frac{ k^pT^p }{ p! }\| x-y \|_{\infty}
		\end{equation}
		où nous avons utilisé le fait que \( | t-t_0 |^p<T^p\). En prenant le supremum sur \( t\) des deux côtés il vient
		\begin{equation}
			\| \Phi^p(x)-\Phi^p(y) \|_{\infty}\leq\frac{ k^pT^p }{ p! }\| x-y \|_{\infty}.
		\end{equation}
		Le membre de droite tend vers zéro lorsque \( p\to\infty\) parce que \( k^pT^p/p!\to 0\)\footnote{Parce que les factorielles vont plus vite que les puissances.}. Nous concluons donc que \( \Phi^p\) est une contraction pour un certain \( p\).

		\spitem[Conclusion]

		L'unique point fixe de \( \Phi\) est alors l'unique solution continue de l'équation différentielle \eqref{XtiXON}. Par ailleurs l'équation elle-même \( y'=f(t,y)\) demande implicitement que \( y\) soit dérivable et donc continue. Nous concluons que l'unique point fixe de \( \Phi\) est l'unique solution de l'équation différentielle donnée. Cette dernière est automatiquement \( C^1\) parce que si \( y\) est continue alors \( u\mapsto f(u,y(u))\) est continue, c'est-à-dire que \( y'\) est continue.

		\spitem[Unicité]

		Nous passons maintenant à la partie «prolongement maximum» du théorème. Soient \( x_1\) et \( x_2\) deux solutions maximales du problème \eqref{XtiXON} sur des intervalles \( I_1\) et \( I_2\) respectivement. Les intervalles \( I_1\) et \( I_2\) contiennent \( \overline{ B(t_0,T) }\) sur lequel \( x_1=x_2\) par unicité.

		Nous allons maintenant montrer que pour tout \( t\geq t_0\) pour lequel \( x_1\) ou \( x_2\) est défini, \( x_1(t)\) et \( x_2(t)\) sont définis et sont égaux. Le raisonnement sur \( t\leq t_0\) est similaire.

		Supposons que l'ensemble des \( t\geq t_0\) tels que \( x_1=x_2\) soit ouvert à droite, c'est-à-dire soit de la forme \( \mathopen[ t_0 ,b [\). Dans ce cas, soit \( x_1\), soit \( x_2\) (soit les deux) cesse d'exister en \( b\). En effet si nous avions les fonctions \( x_i\) sur \(\mathopen[ t_0 , b+\epsilon [\) alors l'équation \( x_1=x_2\) définirait un fermé dans \( \mathopen[ t_0 , b+\epsilon [\). Supposons pour fixer les idées que \( x_1\) cesse d'exister : le domaine de \( x_1\) (parmi les \( t\geq 0\)) est \( \mathopen[ t_0 , b [\) et sur ce domaine nous avons \( x_1=x_2\). Dans ce cas \( x_1\) pourrait être prolongé en \( x_2\) au-delà de \( b\). Si \( x_1\) et \( x_2\) s'arrêtent d'exister en même temps en \( b\), alors nous avons bien \( x_1=x_2\).

		Nous devons donc traiter le cas où \( x_1=x_2\) sur \( \mathopen[ t_0 , b \mathclose]\) alors que \( x_1\) et \( x_2\) existent sur \( \mathopen[ t_0 , b+\epsilon [\) pour un certain \( \epsilon\).

		Nous pouvons appliquer le théorème d'existence locale au problème
		\begin{subequations}
			\begin{numcases}{}
				y'=f(t,y)\\
				y(b)=x_1(b).
			\end{numcases}
		\end{subequations}
		Il existe un voisinage de \( b\) sur lequel la solution est unique. Sur ce voisinage nous devons donc avoir \( x_1=x_2\), ce qui contredit le fait que \( x_1\neq x_2\) en dehors de \( \mathopen[ t_0 , b \mathclose]\).

		Donc \( x_1\) et \( x_2\) existent et sont égaux sur, au moins \( I_1\cup I_2\).
	\end{subproof}
\end{proof}

Le théorème de Cauchy-Lipschitz donne existence et unicité d'une solution maximale. Cependant cette solution peut ne pas exister partout où les hypothèses sur \( f\) sont remplies. En d'autres termes, il peut arriver que \( f\) soit Lipschitz jusqu'à \( t_1\), mais que la solution maximale ne soit définie que jusqu'en \( t_2<t_1\). Ce cas fait l'objet du théorème d'explosion en temps fini~\ref{CorGDJQooNEIvpp}.

Sous quelques hypothèses, nous pouvons nous assurer de l'existence d'une solution unique sur tout \( \eR\).

\ifbool{isGiulietta}{Ce théorème de Cauchy-Lipschitz global est utilisé pour faire le lien entre les représentations des algèbres de Lie et celles du groupe, voir la proposition \ref{PROPooXCGMooKlJlwp}.}{}

\begin{theorem}[Cauchy-Lipschitz global\cite{ooJZJPooAygxpk,KXjFWKA}]       \label{THOooZIVRooPSWMxg}
	Soit un intervalle \( I\) de \( \eR\), \( y_0\in \eR^n\), \( t_0\in I\) et une fonction continue \( f\colon I\times \eR^n\to \eR^n\) telle que pour tout compact \( K\) dans \( I\), il existe \( k>0\) tel que
	\begin{equation}
		\| f(t,y_1)-f(t,y_2) \|\leq k\| y_1-y_2 \|
	\end{equation}
	pour tout \( t\in K\) et \( y_1,y_2\in \eR^n\).

	Alors le problème
	\begin{subequations}        \label{EQSooBNREooUTfbMH}
		\begin{numcases}{}
			y'(t)=f\big( t,y(t) \big)\\
			y(t_0)=y_0
		\end{numcases}
	\end{subequations}
	possède une unique solution \( y\colon I\to \eR^n\) sur \( I\).
\end{theorem}

\begin{proof}
	Soit un intervalle compact \( K\) dans \( I\) et contenant \( t_0\). Nous notons \( \ell\) le diamètre de \( K\). Sur l'espace \( E=C^0(K,\eR^n)\) nous considérons la topologie uniforme : \( (E,\| . \|_{\infty})\). C'est un espace complet par le lemme~\ref{LemdLKKnd} (nous utilisons le fait que \( \eR^n\) soit complet, proposition~\ref{PROPooTFVOooFoSHPg}). Nous allons utiliser l'application suivante :
	\begin{equation}        \label{EQooJUTBooILBKoE}
		\begin{aligned}
			\Phi\colon E & \to E                                  \\
			\Phi(y)(t)   & =y_0+\int_{t_0}^tf\big( s,y(s) \big)ds
		\end{aligned}
	\end{equation}
	Démontrons quelques faits à propos de \( \Phi\).
	\begin{subproof}
		\spitem[\( \Phi\) est bien définie]
		Nous devons commencer par prouver que cette application est bien définie. Si \( y\in E\) alors \( f\) et \( y\) sont continues; l'application \( s\mapsto f\big(s,y(s)\big)\) est donc également continue. L'intégrale de cette fonction sur le compact \( \mathopen[ t_0 , t \mathclose]\) ne pose alors pas de problèmes. En ce qui concerne la continuité de \( \Phi(y)\) sous l'hypothèse que \( y\) soit continue,
		\begin{equation}
			\| \Phi(y)(t)-\Phi(y)(t') \|\leq \int_t^{t'}\| f(s,y(s)) \|ds\leq M| t-t' |
		\end{equation}
		où \( M\) est une majoration de \( \| s\mapsto f\big( s,y(s) \big) \|_{\infty,K}\).

		\spitem[Si \( y\) est solution alors \( \Phi(y)=y\)]

		Supposons que \( y\) soit une solution de l'équation différentielle \eqref{EQSooBNREooUTfbMH}. Alors, vu que \( y'(t)=f\big( t,y(t) \big)\) nous avons :
		\begin{equation}
			y(t)=y_0+\int_{t_0}^ty'(s)ds=y_0+\int_{t_0}^tf\big( s,y(s) \big)ds=\Phi(y)(t).
		\end{equation}

		\spitem[Si \( \Phi(y)=y\) alors \( y\) est solution]

		Nous avons, pour tout \( t\) :
		\begin{equation}
			y(t)=y_0+\int_{t_0}^tf\big( s,y(s) \big)ds.
		\end{equation}
		Le membre de droite est dérivable par rapport à \( t\), et la dérivée est \( f\big( t,y(t) \big) \). Donc le membre de gauche est également dérivable et nous avons bien
		\begin{equation}
			y'(t)=f\big( t,y(t) \big).
		\end{equation}
		De plus \( y(t_0)=y_0+\int_{t_0}^{t_0}\ldots=y_0\).
	\end{subproof}

	Nous sommes encore avec \( K\) compact et \( E=C^0(K,\eR^n)\) muni de la norme uniforme. Nous allons montrer que \( \Phi\) est une contraction de \( E\) pour une norme bien choisie.

	\begin{subproof}
		\spitem[Une norme sur \( E\)]
		Pour \( y\in E\) nous posons
		\begin{equation}
			\| y \|_k=\max_{t\in K}\big(  e^{-k| t-t_0 |}\| y(t) \| \big).
		\end{equation}
		Ce maximum est bien défini et fini, parce que dedans, la fonction de \( t\) est une fonction continue sur le compact \( K\). C'est également une norme parce que si \( \| y \|_k=0\) alors \(  e^{-k| t-t_0 |}\| y(t) \|=0\) pour tout \( t\). Étant donné que l'exponentielle ne s'annule pas, \( \| y(t) \|=0\) pour tout \( t\).
		\spitem[Équivalence de norme]
		Nous montrons que les normes \( \| . \|_k\) et \( \| . \|_{\infty}\) sont équivalentes\footnote{Définition~\ref{DefEquivNorm}} :
		\begin{equation}        \label{EQooSQYWooBTXvDL}
			\| y \|_{\infty} e^{-k\ell}\leq \| y \|_k\leq \| y \|_{\infty}
		\end{equation}
		pour tout \( y\in E\). Pour la première inégalité, \( \ell\geq | t-t_0 |\) pour tout \( t\in K\), et \( k>0\), donc
		\begin{equation}
			\| y(t) \| e^{-k\ell}\leq  e^{-k| t-t_0 |}\| y(t) \|.
		\end{equation}
		En prenant le maximum des deux côtés, \( \| y \|_{\infty} e^{-k\ell}\leq \| y \|_k\).

		En ce qui concerne la seconde inégalité dans \eqref{EQooSQYWooBTXvDL}, \( k| t-t_0 |\geq 0\) et donc \(  e^{-k| t-t_0 |}<1\).

	\end{subproof}
	Puisque les normes \( \| . \|_{\infty}\) et \( \| . \|_k\) sont équivalentes, l'espace \( (E,\| . \|_k)\) est tout autant complet que \( (E,\| . \|_{\infty})\). Nous démontrons à présent que \( \Phi\) est une contraction dans \( (E,\|  \|_k)\).

	Soient \( y,z\in E\). Si \( t\geq t_0\) nous avons
	\begin{subequations}        \label{SUBEQSooEXVYooDkyTuB}
		\begin{align}
			\| \Phi(y)(t)-\Phi(z)(t) \| & \leq  \int_{t_0}^t\| f\big( s,y(s) \big)-f\big( s,z(s) \big) \|ds \\
			                            & \leq k\int_{t_0}^t\| y(s)-z(s) \|ds.
		\end{align}
	\end{subequations}
	Il convient maintenant de remarquer que
	\begin{equation}
		\| y(t) \|= e^{-k| t-t_0 |} e^{k| t-t_0 |}\| y(t) \|\leq \| y \|_k e^{k| t-t_0 |}.
	\end{equation}
	Nous pouvons avec ça prolonger les inégalités \eqref{SUBEQSooEXVYooDkyTuB} par
	\begin{equation}
		\| \Phi(y)(t)-\Phi(z)(t) \|\leq k\| y-z \|_k\int_{t_0}^t e^{k| s-t_0 |}ds=k\| y-z \|_k\int_{t_0}^t e^{k(s-t_0)}ds
	\end{equation}
	où nous avons utilisé notre supposition \( t\geq t_0\) pour éliminer les valeurs absolues. L'intégrale peut être calculée explicitement, mais nous en sommes arrivés à un niveau de fainéantise tellement inconcevable que

	\lstinputlisting{tex/sage/sageSnip014.sage}

	Au final, si \( t\geq t_0\),
	\begin{equation}
		\| \Phi(y)(t)-\Phi(z)(t) \|\leq \| y-z \|_k\big(  e^{k(t-t_0)}-1 \big).
	\end{equation}
	Si \( t\leq t_0\), il faut retourner les bornes de l'intégrale avant d'y faire rentrer la norme parce que \( \| \int_0^1f \|\leq \int_0^1\| f \|\), mais ça ne marche pas avec \( \| \int_1^0f \|\). Pour \( t\leq t_0\) tout le calcul donne
	\begin{equation}
		\| \Phi(y)(t)-\Phi(z)(t) \|\leq \| y-z \|_k\big(  e^{k(t_0-t)}-1 \big).
	\end{equation}
	Les deux inéquations sont valables a fortiori en mettant des valeurs absolues dans l'exponentielle, de telle sorte que pour tout \( t\in K\) nous avons
	\begin{equation}
		e^{-k| t_0-t |}\| \phi(y)(t)-\Phi(z)(t) \|\leq \| y-z \|_k\big( 1- e^{-k| t_0-t |} \big).
	\end{equation}
	En prenant le supremum sur \( t\),
	\begin{equation}
		\| \Phi(y)-\Phi(z) \|_k\leq \| y-z \|_k(1- e^{-k\ell}),
	\end{equation}
	mais \( 0<(1- e^{e-k\ell})<1\), donc \( \Phi\) est contractante pour la norme \( \| . \|_k\). Comme \( (E,\| . \|_k)\) est complet, l'application \( \Phi\) y a un unique point fixe par le théorème de Picard~\ref{ThoEPVkCL}.

	Ce point fixe est donc l'unique solution de l'équation différentielle de départ.

	\begin{subproof}
		\spitem[Existence et unicité sur \( I\)]
		Il nous reste à prouver que la solution que nous avons trouvée existe sur \( I\) : jusqu'à présent nous avons démontré l'existence et l'unicité sur n'importe quel compact dans \( I\).

		Soit une suite croissante de compacts \( K_n\) contenant \( t_0\) (par exemple une suite exhaustive comme celle du lemme~\ref{LemGDeZlOo}). Nous avons en particulier
		\begin{equation}
			I=\bigcup_{n=0}^{\infty}K_n.
		\end{equation}
		\spitem[Existence sur \( I\)]
		Soit \( y_n\) l'unique solution sur \( K_n\). Il suffit de poser
		\begin{equation}
			y(t)=y_n(t)
		\end{equation}
		pour \( n\) tel que \( t\in K_n\). Cette définition fonctionne parce que si \( t\in K_n\cap K_m\), il y a forcément un des deux qui est inclus dans l'autre et le résultat d'unicité sur le plus grand des deux donne \( y_n(t)=y_m(t)\).

		\spitem[Unicité sur \( I\)]

		Soient \( y\) et \(z \) des solutions sur \( I\); puisque \( I\) n'est pas spécialement compact, le travail fait plus haut ne permet pas de conclure que \( y=z\).

		Soit \( t\in I\). Alors \( t\in K_n\) pour un certain \( n\) et \( y\) et \( z\) sont des solutions sur \( K_n\) qui est compact. L'unicité sur \( K_n\) donne \( y(t)=z(t)\).
	\end{subproof}
\end{proof}

\begin{normaltext}
	Il y a d'autres moyens de prouver qu'une solution existe globalement sur \( \eR\). Si \( f\) est globalement bornée, le théorème d'explosion en temps fini donne quelques garanties, voir~\ref{NORMooZROGooZfsdnZ}.
\end{normaltext}

Le théorème suivant donne une version du théorème de Cauchy-Lipschitz lorsque la fonction \( f\) dépend d'un paramètre. Ce théorème n'utilise rien de fondamentalement nouveau. Nous le donnons seulement pour montrer que l'on peut choisir l'espace \( \mF\) de façon un peu maligne pour élargir le résultat. Si vous voulez un théorème de Cauchy-Lipschitz avec paramètre vraiment intéressant, allez voir le théorème~\ref{PROPooPYHWooIZhQST}.

\begin{theorem}[Cauchy-Lipschitz avec paramètre\cite{MonCerveau,ooXVPAooTQUIRw}]          \label{THOooDTCWooSPKeYu}
	Soit un intervalle ouvert \( I\) de \( \eR\), un connexe ouvert \( \Omega\) de \( \eR^n\) et un intervalle ouvert \( \Lambda\) de \( \eR^d\). Soit une fonction \( f\colon I\times \Omega\times \Lambda\to \eR^n\) continue et localement lipschitzienne en \( \Omega\). Soient \( t_0\in I\), \( y_0\in \Omega\) et \( \lambda_0\in \Lambda\). Il existe un voisinage compact de \( (t_0,y_0,\lambda_0)\) sur lequel le problème
	\begin{subequations}
		\begin{numcases}{}
			y'_{\lambda}(t)=f\big( t,y_{\lambda}(t),\lambda \big)\\
			y_{\lambda}(t_0)=y_0
		\end{numcases}
	\end{subequations}
	possède une unique solution. De plus \( (t,\lambda)\mapsto y_{\lambda}(t)\) est continue\footnote{Ici, la surprise est que ce soit continu par rapport à \( \lambda\). Le fait qu'elle le soit par rapport à \( t\) est clair depuis le départ, parce que ce n'est finalement rien d'autre que le Cauchy-Lipschitz vieux et connu.}.
\end{theorem}

\begin{proof}[Idée rapide de la preuve]

	\begin{probleme}
		Ceci est une idée de la preuve. Je n'ai pas vérifié toutes les étapes. Soyez prudent.
	\end{probleme}

	D'abord nous avons un voisinage compact \( V\times \overline{ B(y_0,r) }\times \Lambda_0\) de \( (t_0,y_0,\lambda_0)\) sur lequel \( f\) est bornée. Ensuite nous récrivons l'équation différentielle sous la forme
	\begin{subequations}
		\begin{numcases}{}
			\frac{ \partial y }{ \partial t }(t,\lambda)=f\big( t,y(t,\lambda),\lambda \big)\\
			y(t_0,\lambda)=y_0.
		\end{numcases}
	\end{subequations}
	pour une fonction \( y\colon V\times \Lambda_0\to \eR^n\).

	Nous posons \( \mF=C^0\big( V\times\Lambda_0 ,\eR^n\big)\) et nous y définissons l'application
	\begin{equation}
		\begin{aligned}
			\Phi\colon \mF     & \to \mF                                                 \\
			\Phi(y)(t,\lambda) & =y_0+\int_{t_0}^tf\big( s,y(s,\lambda),\lambda \big)ds.
		\end{aligned}
	\end{equation}
	Il y a plein de vérifications à faire\cite{ooXVPAooTQUIRw}, mais je parie que \( \Phi\) est bien définie, et qu'une de ses puissances est une contraction de \( (\mF,\| . \|_{\infty})\). L'unique point fixe est une solution de notre problème et est dans \( C^0\), donc \( (t,\lambda)\mapsto y(t,\lambda)=y_{\lambda}(t)\) est de classe \( C^0\), c'est-à-dire continue.
\end{proof}

\begin{normaltext}
	Ce théorème marque un peu la limite de ce que l'on peut faire avec la méthode des points fixes dans le cadre de Cauchy-Lipschitz : nous sommes limités à la continuité de la solution parce que les espaces \( C^p\) ne sont pas complets\footnote{Par exemple, le théorème de Stone-Weierstrass~\ref{ThoGddfas} nous dit que la limite uniforme de polynômes (de classe \(  C^{\infty}\)) peut n'être que continue. Voir aussi le thème~\ref{THMooOCXTooWenIJE}.}. Il n'y a donc pas d'espoir d'adapter la méthode pour prouver que si \( f\) est de classe \( C^p\) alors \( (t,\lambda)\mapsto y_{\lambda}(t)\) est de classe \( C^p\). On peut, à \( \lambda\) fixé, prouver que \( t\mapsto y_{\lambda}(t)\) est de classe \( C^p\) (utiliser une récurrence), mais pas plus.

	La régularité \( C^1\) de \( y\) par rapport à la condition initiale sera l'objet du théorème~\ref{THOooSTHXooXqLBoT}. Ce résultat n'est vraiment pas facile et utilise des ingrédients bien autres qu'un point fixe. Ensuite la régularité \( C^p\) par rapport à la condition initiale et par rapport à un paramètre seront presque des cadeaux (proposition~\ref{PROPooINLNooDVWaMn} et~\ref{PROPooPYHWooIZhQST}).
\end{normaltext}

\begin{example}[\cite{ooSBHXooOMnaTC}]          \label{EXooJXIGooQtotMc}
	Nous savons que le théorème de Picard permet de trouver le point fixe par itération de la contraction à partir d'un point quelconque. Tentons donc de résoudre
	\begin{subequations}
		\begin{numcases}{}
			y'(t)=y(t)\\
			y(0)=1
		\end{numcases}
	\end{subequations}
	dont nous savons depuis l'enfance que la solution est l'exponentielle\footnote{Voir par exemple le théorème \ref{ThoKRYAooAcnTut}.}. Partons donc de la fonction constante \( y_0=1\), et appliquons la contraction \eqref{EQooJUTBooILBKoE} :
	\begin{equation}
		u_1=1+\int_0^1u_0(s)ds=1+t.
	\end{equation}
	Ensuite
	\begin{equation}
		u_2=1+\int_0^t(1+s)ds=1+t+\frac{ t^2 }{2}.
	\end{equation}
	Et on voit que les itérations suivantes vont donner l'exponentielle.

	Nous sommes évidemment en droit de se dire que nous avons choisi un bon point de départ. Tentons le coup avec une fonction qui n'a rien à voir avec l'exponentielle : \( u_0(x)=\sin(x)\).

	Le programme suivant permet de faire de belles investigations numériques en partant d'à peu près n'importe quelle fonction :

	\lstinputlisting{tex/sage/picard_exp.py}

	Ce programme fait \( 30\) itérations depuis la fonction \( \sin(x)\) pour tenter d'approximer \( \exp(x)\). Pour donner une idée, après \( 7\) itérations nous avons la fonction suivante :
	\begin{equation}
		\frac{1}{ 60 }x^5+\frac{1}{ 24 }x^4+\frac{ 1 }{2}x^2+2x-\sin(x)+1.
	\end{equation}
	Nous voyons que les coefficients sont des factorielles, mais pas toujours celles correspondantes à la puissance, et qu'il manque certains termes par rapport au développement de l'exponentielle que nous connaissons. Bref, le polynôme qui se met en face de \( \sin(x)\) s'adapte tout seul pour compenser.

	Et après \( 30\) itérations, ça donne quoi ? Voici un graphe de l'erreur entre \( u_{30}(x)\) et \( \exp(30)\) :

	\begin{center}
		\input{auto/pictures_tex/Fig_XOLBooGcrjiwoU.pstricks}
	\end{center}

	Pour donner une idée, \( \exp(10)\simeq 22000\). Donc il y a une faute de \( 0.01\) sur \( 22000\). Pas mal.

\end{example}
