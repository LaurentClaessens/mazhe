% This is part of Mes notes de mathématique
% Copyright (c) 2011-2025
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Algèbre engendrée par une matrice}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Nous allons en dire le strict minimum indispensable pour notre propos. Pour plus de détails, voir \cite{BIBooYLFXooSFCrlS}, et pour nettement plus de détails, \cite{Landsman}.

\begin{definition}      \label{DEFooXPFVooZzPXEK}
	Si \( A\in \eM(n, \eK)\), alors l'\defe{algèbre engendrée}{algèbre engendrée} par \( A\) est l'intersection de toutes les sous-algèbres de \( \eM(n,\eK)\) contenant \( A\).
\end{definition}

\begin{lemma}[\cite{BIBooYLFXooSFCrlS, MonCerveau}]     \label{LEMooZGFYooOHvxLy}
	Si le polynôme minimal\footnote{Toute matrice a un polynôme minimal par le lemme \ref{LEMooQJQGooRcAxmJ}.} de \( A\) est de degré \( p\), alors la partie \( \{ \mtu, A, A^2,\ldots, A^{p-1} \}\) est une base de \( \Alg(A)\).
\end{lemma}

\begin{proof}
	La partie proposée est libre parce qu'une combinaison linéaire de ses éléments est un polynôme de degré \( p-1\) en \( A\). Une annulation d'un tel polynôme serait contraire au fait que le polynôme minimal est de degré \( p\).

	Cette partie est génératrice parce que, étant elle-même une sous-algèbre de \( \eM(n)\) contenant \( A\), elle contient \( \Alg(A)\).
\end{proof}

\begin{corollary}[\cite{MonCerveau}]       \label{CORooQTUQooDtjljc}
	L'algèbre \( \Alg(A)\) est commutative.
\end{corollary}

\begin{proof}
	Écrire deux combinaisons linéaires d'éléments de la base donnée par le lemme \ref{LEMooZGFYooOHvxLy}, et notez que les produits ne font intervenir que des produits de \( A\).
\end{proof}


Une bonne question est de savoir si \(  e^{tA}\) est dans \( \Alg(A)\). Pour le savoir il va falloir d'abord définir l'exponentielle; rendez-vous donc au lemme \ref{LEMooCEVGooFVXndZ}.


%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Exponentielle sur une algèbre normée}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Définition}
%---------------------------------------------------------------------------------------------------------------------------

Dans ce qui suit, nous considérons une algèbre commutative.
\begin{propositionDef}[Exponentielle\cite{MonCerveau}]       \label{DEFooSFDUooMNsgZY}
	Soit \( (A,\| . \|)\) une algèbre\footnote{Définition~\ref{DefAEbnJqI}.} commutative de dimension finie sur \( \eC\) munie d'une norme d'algèbre. Pour \( x\in A\) nous définissons
	\begin{equation}        \label{EQooCUVTooGNOrFj}
		\exp(x)=\sum_{k=0}^{\infty}\frac{ x^k }{ k! }.
	\end{equation}
	Cette définition a les propriétés suivantes :
	\begin{enumerate}
		\item
		      C'est bien défini pour tout \( x\in A\). C'est-à-dire que pour chaque \( x\), la série \eqref{EQooCUVTooGNOrFj} converge.
		\item
		      Cela donne une application continue \( \exp\colon A\to A\).
		\item       \label{ITEMooGGVAooVfhGuu}
		      La fonction \( \exp\) est différentiable et
		      \begin{equation}        \label{EQooKWBUooLUdBAw}
			      (d\exp)_x(y)=\exp(x)y,
		      \end{equation}
		      le dernier produit étant la structure d'algèbre sur \( A\).
	\end{enumerate}
\end{propositionDef}

\begin{proof}
	Pour la différentiabilité de \( \exp\), nous voulons utiliser le théorème~\ref{ThoLDpRmXQ}. Pour cela nous posons
	\begin{equation}
		u_k(x)=\frac{ x^k }{ k! }
	\end{equation}

	\begin{subproof}
		\spitem[Convergence simple]
		Nous prouvons la convergence simple, c'est-à-dire pour chaque \( x\) séparément, de la série \eqref{EQooCUVTooGNOrFj} dans deux buts. D'abord de nous assurer que la définition posée de \( \exp\) a un sens, et ensuite pour commencer à vérifier les hypothèses du théorème~\ref{ThoLDpRmXQ}.

		Nous montrons que les sommes partielles forment une suite de Cauchy. Nous fixons \( x\in A\) et nous posons
		\begin{equation}
			s_n=\sum_{k=0}^{n}\frac{ x^k }{ k! }.
		\end{equation}
		Soient \( p>q\), deux entiers. Nous avons :
		\begin{equation}        \label{EQooYNZNooDaiPhU}
			\| s_p-s_q \|=\| \sum_{k=q+1}^p\frac{ x^k }{ k! } \|\leq \sum_{k=q+1}^p\frac{ \| x^k \| }{ k! }\leq \sum_{k=q+1}^p\frac{ \| x \|^k }{ k! }
		\end{equation}
		où nous avons utilisé le fait que la norme sur \( A\) soit une norme d'algèbre.

		C'est le moment d'utiliser la série exponentielle donnée dans le lemme \ref{ExIJMHooOEUKfj} que nous appliquons avec \( t=\| x \|\). La série donnée par les coefficients \( a_k=\| x \|^k/k!\) converge et ses sommes partielles forment en particulier une suite de Cauchy. Donc ce que nous avons à droite dans \eqref{EQooYNZNooDaiPhU} peut être rendu arbitrairement petit lorsque \( p\) et \( q\) sont grands.

		\spitem[\( u_k\) est continue]
		Il s'agit de remarquer que \( (x+h)^k=x^k+hC(x,h)\) où \( C\) est une fonction bornée de \( h\) (lorsque \( h\) est dans un voisinage de \( 0\in A\)). Donc
		\begin{equation}
			\| (x+h)^k-x^k \|\leq \| h \|\| C(x,h) \|\to 0.
		\end{equation}
		\spitem[Candidat différentielle de \( u_k\)]
		Nous trouvons à présent un candidat à être différentielle de \( u_k\). Pour cela nous faisons le calcul suivant, sans trop nous soucier de la rigueur :
		\begin{equation}
			(du_k)_x(y)=\Dsdd{ u_k(x+ty) }{t}{0}=k\frac{1}{ k! }x^{k-1}y=u_{k-1}(x)y.
		\end{equation}
		\spitem[\( u_k\) est différentiable]
		Nous fixons \( x\in A\) et nous posons \( T(y)=u_{k-1}(x)y\). Ensuite nous vérifions que cela vérifie la définition de la différentielle : nous devons calculer
		\begin{equation}        \label{EQooNPKGooVmEYAV}
			\lim_{h\to 0} \frac{ u_k(x+h)-u_k(x)-T(h) }{ \| h \| }=\lim_{h\to 0} \frac{ (x+h)^k-x^k-kx^{k-1}h }{ k! \| h \| }=\clubsuit.
		\end{equation}
		Vous vous souvenez de la formule pour \( (x+h)^k\) ? Essayez de vous en souvenir. Le premier terme est \( x^k\), et le second est \( kx^{k-1}h\). Pour le reste c'est un polynôme dont tous les termes contiennent au moins \( h^2\). Nous avons donc
		\begin{equation}
			\clubsuit=\lim_{h\to 0} \frac{ h^2P(x,h) }{ k!\| h \| }=0.
		\end{equation}
		Nous en concluons que \( u_k\) est différentiable et que
		\begin{equation}
			(du_k)_x(y)=u_{k-1}(x)y.
		\end{equation}
		\spitem[\( u_k\) est de classe \( C^1\)]
		Nous devons démontrer que la différentielle est continue; cela est la continuité de l'application
		\begin{equation}
			\begin{aligned}
				du_k\colon A & \to \aL(A,A)      \\
				x            & \mapsto (du_k)_x.
			\end{aligned}
		\end{equation}
		La topologie sur \( A\) est celle de la norme, et celle sur \( \aL(A,A)\) est celle de la norme opérateur associée à la norme sur \( A\). Nous avons\footnote{N'oubliez pas de faire à part le cas \( k=0\) parce que ce qui suit n'est correct que pour \( k\geq 1\).} :
		\begin{subequations}
			\begin{align}
				\lim_{h\to 0} \| (du_k)_{x+h}-(du_k)_x \| & =\lim_{h\to 0} \sup_{\| y \|=1}\| u_{k-1}(x+h)y-u_{k-1}(x)y \|         \\
				                                          & \leq\lim_{h\to 0} \sup_{\| y \|=1}\| u_{k+1}(x+h)-u_{k-1}(x) \|\| y \| \\
				                                          & =\lim_{h\to 0} \| u_{k+1}(x+h)-u_{k-1}(x) \|.
			\end{align}
		\end{subequations}
		Le fait que cette limite vaille zéro est maintenant la continuité de \( u_{k-1}\).

		\spitem[Convergence normale sur tout compact]

		Soit un compact \( K\) de \( A\). Par le théorème de Borel-Lebesgue~\ref{ThoXTEooxFmdI}, \( K\) est fermé et borné. C'est pour ceci que nous avons supposé que \( A\) était de dimension finie sur \( \eR\). Soit donc \( R>0\) tel que \( \| y \|<R\) pour tout \( y\in K\). Nous avons
		\begin{equation}
			\| du_k \|_K=\sup_{x\in K}\| (du_k)_x \|=\sup_{x\in K}\frac{ \| x^{k-1} \| }{ (k-1)! }\leq \sup_{x\in K}\frac{ \| x \|^{k-1} }{ (k-1)! }\leq \frac{ R^{k-1} }{ (k-1)! }.
		\end{equation}
		Mais la série \( \sum_{k=0}^{\infty}\frac{ R^k }{k!}\) converge. Nous avons donc la convergence normale demandée.

		\spitem[Conclusion]

		Le théorème~\ref{ThoLDpRmXQ} conclut que l'exponentielle est de classe \( C^1\) et que sa différentielle est donnée par la formule
		\begin{equation}
			(d\exp)_x(y)=\sum_{k=0}^{\infty}(du_k)_x(y)=\sum_{k=1}^{\infty}(du_k)_x(y)=\sum_{k=0}^{\infty}u_k(x)y=\exp(x)y.
		\end{equation}
		Notez le jeu d'indices : \( du_k=0\) lorsque \( k=0\) (ce qui permet de faire commencer la somme à \( 1\)) et ensuite \( du_k\) fait intervenir \( u_{k-1}\) (ce qui fait revenir le départ de la somme à \( k=0\)).

	\end{subproof}
\end{proof}

\begin{normaltext}
	Lorsque nous disons que la différentielle de l'exponentielle est l'exponentielle elle-même, nous référons au point~\ref{DEFooSFDUooMNsgZY}\ref{ITEMooGGVAooVfhGuu} : la différentielle de \( \exp\) en \( x\) est l'opérateur de multiplication par \( \exp(x)\).

	Nous pouvons comprendre maintenant que \( \exp\) est même de classe \(  C^{\infty}\) parce qu'à chaque différentiation nous tombons sur la même fonction, laquelle est de classe au moins \( C^1\).

	Cependant, pour formaliser ça, il faut un peut travailler. Le cauchemar des différentielles successives d'une application \( A\to A\) est que les espaces en jeu sont des emboîtements terribles de \( \aL(A,\aL(A,\aL(A,A)))\).

	Ce qui nous sauve est que l'espace \( \aL(A,V)\) est un \( A\)-module, quel que soit \( V\). En particulier lorsque \( V\) est lui-même déjà un emboîtement. Faisons un lemme pour voir comment ça fonctionne.
\end{normaltext}


\begin{lemma}[\cite{MonCerveau}]        \label{LEMooCEVGooFVXndZ}
	Si \( A\in \eM(n,\eK)\) avec \( \eK=\eR\) ou \( \eC\), nous considérons l'algèbre \( \Alg(A)\) engendrée par \( A\)\footnote{Définition \ref{DEFooXPFVooZzPXEK}.}. Alors
	\begin{equation}
		e^{\Alg(A)}\subset \Alg(A).
	\end{equation}
\end{lemma}

\begin{proof}
	Le lemme \ref{LEMooZGFYooOHvxLy} nous dit que \( \Alg(A)\) est une algèbre de dimension finie. Elle est commutative par le corolaire \ref{CORooQTUQooDtjljc}. Donc la proposition \ref{DEFooSFDUooMNsgZY} s'applique.
\end{proof}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Différentielles}
%---------------------------------------------------------------------------------------------------------------------------

\begin{lemma}[\cite{MonCerveau}]        \label{LEMooHKQVooQTrHHW}
	Soient deux espaces vectoriels normés \( E\) et \( V\) tels que \( V\) soit un \( E\)-module\footnote{Définition~\ref{DEFooHXITooBFvzrR}.}. Nous supposons les normes soient telles que \( \| xv \|_{V}\leq \| x \|_E\| v \|_V\).

	Soit une fonction différentiable \( f\colon E\to V\) telle que la différentielle \( df\colon E\to \aL(E,V)\) soit de la forme
	\begin{equation}
		df_x(y)=yg(x)
	\end{equation}
	pour une certaine fonction différentiable \( g\colon E\to V\).

	Alors \( f\) est \( C^1\), et deux fois différentiable telle que
	\begin{equation}
		\begin{aligned}
			d^2f\colon E & \to \aL\big( E,\aL(E,V) \big) \\
			(d^2f)_x(y)z & =z(dg_x)(y)
		\end{aligned}
	\end{equation}
	pour tout \( x,y,z\in E\).
\end{lemma}

\begin{proof}
	En plusieurs étapes.
	\begin{subproof}
		\spitem[\( f\) est \( C^1\)]
		Nous savons, par hypothèse, que \( f\) est différentiable. Il faut montrer que sa différentielle est continue, en remarquant déjà que \( g\) est continue parce que différentiable.

		Soit \( x_k\stackrel{E}{\longrightarrow}x\), et calculons \( \| df_{x_k}-df_x \|\) :
		\begin{equation}
			\begin{aligned}[]
				\| df_{x_k}-df_x \| & =\sup_{\| y \|=1}\| df_{x_k}(y)-df_x(y) \|    \\
				                    & =\sup_{\| y \|=1}\| \big(g(x_k)-g(x)\big)y \| \\
				                    & \leq\sup_{\| y \|=1}\| g(x_k)-g(x) \|\| y \|  \\
				                    & =\| g(x_k)-g(x) \|.
			\end{aligned}
		\end{equation}
		Donc nous avons bien \(df_{x_k}\stackrel{\aL(E,V)}{\longrightarrow}df_x\), ce qui signifie la continuité de \( df\). Donc \( f\) est de classe \( C^1\).

		\spitem[\( f\) est deux fois différentiable]

		Pour montrer que \( df\) est différentiable, nous mettons directement dans la définition \eqref{DefDifferentiellePta} le candidat
		\begin{equation}
			\begin{aligned}
				T_x(h)\colon R & \to V      \\
				T_x(h)z        & =zdg_x(y).
			\end{aligned}
		\end{equation}
		Nous devons vérifier la limite suivante :
		\begin{equation}        \label{EQooTBCKooRxBCum}
			\lim_{h\stackrel{E}{\longrightarrow} 0} \frac{ df_{x+h}-df_x-T_x(h) }{ \| h \| }=0.
		\end{equation}
		Étudions la norme du numérateur :
		\begin{subequations}
			\begin{align}
				\| df_{x+h}-df_x-T_x(h) \| & =\sup_{\| y \|=1}\| df_{x+h}(y)-df_x(y)-T_x(h)y \|      \\
				                           & =\sup_{\| y \|=1}\| yg(x+h)-yg(x)-ydg_x(h) \|           \\
				                           & \leq \sup_{\| y \|=1}\| y \| \| g(x+h)-g(x)-dg_x(h) \|.
			\end{align}
		\end{subequations}
		La limite \eqref{EQooTBCKooRxBCum} se déduit donc de la différentiabilité de \( g\).
	\end{subproof}
	Note : la partie démontrant que \( f\) est \( C^1\) n'est pas strictement obligatoire parce qu'en vérifiant que \( f\) est deux fois différentiable, nous vérifions de facto que \( df\) est en particulier continue.
\end{proof}

\begin{lemma}[\cite{MonCerveau}]   \label{LEMooTUWQooMCCDcm}
	Soient des algèbres normées \( A\) et \( V\) telles que \( V\) soit un \( A\)-module vérifiant \( \| xv \|\leq \| x \|\| v \|\) pour tout \( x\in A\) et \( v\in V\). Alors \( \aL(A,V)\) est un \( A\)-module vérifiant \( \| x\alpha \|\leq \| x \|\|\alpha  \|\) pour tout \( x\in A\) et \( \alpha\in \aL(A,V)\).
\end{lemma}

\begin{proof}
	C'est un simple calcul utilisant la norme opérateur :
	\begin{equation}
		\| x\alpha \|=\sup_{\| y \|=1}\| (x\alpha)y \|
		=\sup_{\| y \|=1}\| x\alpha(y) \|
		\leq \sup_{\| y \|=1}\| x \|\| \alpha(y) \|
		=\| x \|\sup_{\| y \|=1}\| \alpha(y) \|
		=\| x \|\| \alpha \|.
	\end{equation}
\end{proof}

\begin{proposition}[\cite{MonCerveau}]      \label{PROPooTBDAooQouzSk}
	La fonction \( \exp\colon A\to A\) est de classe \(  C^{\infty}\) et vérifie, pour tout \( k\geq 1\) la récurrence
	\begin{equation}
		(d^k\exp)_x(y)=y(d^{k-1}\exp)_x.
	\end{equation}
\end{proposition}

\begin{proof}
	La formule proposée fonctionne avec \( k=1\) :
	\begin{equation}
		(d\exp)_x(y)=y\exp(x).
	\end{equation}
	C'est la relation~\ref{EQooKWBUooLUdBAw}.

	Nous considérons \( k>1\), nous supposons que \( \exp\) est de classe \( C^{k-1}\) et \( k\) fois différentiable. Nous allons prouver que \( \exp\) est alors de classe \( C^k\) et \( k+1\) fois différentiable, et que la différentielle de \( d^k\exp\) est donné par la formule
	\begin{equation}
		(d^{k+1}\exp)_x(y)=y(d^{k}\exp)_x.
	\end{equation}

	Pour nous mettre au clair avec les espaces en présence, nous supposons que
	\begin{subequations}
		\begin{align}
			d^{k-1}\exp & \colon A\to \aL(A,V)                  \\
			d^{k}\exp   & \colon A\to \aL\big( A,\aL(A,V) \big)
		\end{align}
	\end{subequations}
	pour un certain espace vectoriel normé \( V\), lequel est un de ces terrifiants emboîtement de type \( \aL\Big( A,\aL\big( A,\aL(A,A) \big) \Big)\). Il est bien un espace vectoriel normé, et également un \( A\)-module parce qu'on peut toujours définir la multiplication d'un élément \( v\in V\) par un élément \(x\in A\) comme étant la multiplication par \( x\) du résultat final de l'évaluation emboîtée, laquelle se termine par un élément de \( A\). Donc tout se met bien.

	Quoi qu'il en soit, nous posons
	\begin{equation}
		T_x(y)=y(d^{k}\exp)_x
	\end{equation}
	et nous vérifions ce que cela donne dans la définition de la différentielle. Si nous avons
	\begin{equation}
		\lim_{h\to 0} \frac{ (d^k\exp)_{x+h}-(d^k\exp)_x-T_x(h) }{ \| h \| }=0
	\end{equation}
	alors nous aurons prouvé tout ce qu'il nous faut.

	Le numérateur est une application \( A\to \aL(A,V)\); nous en écrivons la norme comme il se doit :
	\begin{subequations}
		\begin{align}
			\|   (d^k\exp)_{x+h}-(d^k\exp)_x-T_x(h) \| & =\sup_{\| y \|=1}\| (d^{k}\exp)_{x+h}(y)-(d^k\exp)_x(y)-h(d^{k}\exp)_xy \|     \\
			                                           & =\sup_{\| y \|=1}\| y(d^{k-1}\exp)_{x+h}-y(d^{k-1}\exp)_x-h(d^k\exp)_xy \|     \\
			                                           & =\sup_{\| y \|=1}\| y(d^{k-1}\exp)_{x+h}-y(d^{k-1}\exp)_x-hy(d^{k-1}\exp)_x \| \\
			                                           & \leq \| (d^{k-1}\exp)_{x+h}-(d^{k-1}\exp)_x-h(d^{k-1}\exp)_x \|                \\
			                                           & =\| (d^{k-1}\exp)_{x+h}-(d^{k-1}\exp)_x-(d^{k}\exp)_x(h) \|.
		\end{align}
	\end{subequations}
	Dans ce calcul nous avons utilisé le lemme~\ref{LEMooTUWQooMCCDcm} et \( T_x(h)y=h(d^{k}\exp)_xy\).
	Maintenant, la limite
	\begin{equation}
		\lim_{h\to 0} \frac{  \| (d^{k-1}\exp)_{x+h}-(d^{k-1}\exp)_x-(d^{k}\exp)_x(h) \|.}{ \| h \| }
	\end{equation}
	n'est rien d'autre que la limite arrivant dans la définition du fait que \( d^k\exp\) est la différentielle de \( d^{k-1}\exp\). Cette limite est donc zéro comme nous voulions le prouver.
\end{proof}


Le théorème suivant est très important parce qu'il permet de définir l'exponentielle d'une matrice. Et les exponentielles de matrices sont utiles, entre très nombreuses autres choses pour résoudre certaines équations différentielles.
\begin{theoremDef}[\cite{MonCerveau}]      \label{THOooFGTQooZPiVLO}
	Soit une algèbre normée \( A\) (pas spécialement commutative). La formule
	\begin{equation}
		\exp(x)=\sum_{k=0}^{\infty}\frac{ x^k }{ k! }
	\end{equation}
	définit une fonction différentiable dont la différentielle est donnée par\quext{La fonction exponentielle est, j'en suis quasiment certain, de classe \(  C^{\infty}\). Si vous connaissez un moyen pas trop douloureux de prouver cela, faites-le moi savoir.}
	\begin{equation}        \label{EQooFGPPooZKHeXU}
		(d\exp)_x(y)=\sum_{i,j\in \eN}\frac{ x^iyx^j }{ (i+j+1)! }
	\end{equation}
\end{theoremDef}

\begin{normaltext}
	Nous ne démontrons pas cela ici.

	Il s'agit d'une adaptation de la proposition~\ref{DEFooSFDUooMNsgZY}. Là où il faut faire attention, c'est dans l'équation \eqref{EQooNPKGooVmEYAV} : il n'y a pas \( k\) termes \( x^{k-1}h\) dans \( (x+h)^k\), mais \( k\) termes de la forme \( x^ihx\). C'est pour cela que la différentielle n'est pas donnée par \( T(y)=u_{k-1}(x)y\), mais bien par la somme \eqref{EQooFGPPooZKHeXU}.

	M'est avis en réalité que toute la démonstration du théorème~\ref{PropXFfOiOb} passe facilement au cas présent.
\end{normaltext}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Exponentielle de matrice}
%---------------------------------------------------------------------------------------------------------------------------
\label{SECooBYQBooZifJsg}

\begin{proposition}[\cite{BIBooROFBooCcFjms}]
	Soient des matrices \( A,P\in \eM(n,\eC)\) telle que \( P\) soit inversible. Alors\footnote{La définition de l'exponentielle de matrice est \ref{DEFooSFDUooMNsgZY} où la convergence de la somme est celle de la norme opérateur \ref{DefNFYUooBZCPTr}.}
	\begin{equation}
		e^{P^{-1}AP}=P^{-1} e^{A}P.
	\end{equation}
\end{proposition}

\begin{proof}
	Pour chaque \( m\in \eN\) nous avons \( (P^{-1}AP)^m=P^{-1} A^mP\). Ensuite,
	\begin{equation}
		e^{P^{-1}AP}=\sum_k\frac{(P^{-1}AP)^k}{ k! }=\sum_k\frac{ P^{-1}A^kP }{ k! }=P^{-1}\sum_k\frac{ A^k }{ k! }P.
	\end{equation}
	Nous avons utilisé la proposition \ref{PROPooMZZQooEhQsgQ} pour sortir \( P^{-1}\) à gauche et \( P\) à droite de la somme.
\end{proof}

\begin{proposition}[\cite{BIBooROFBooCcFjms}]       \label{PROPooFLHPooRhLiZE}
	L'exponentielle de matrice vérifie
	\begin{enumerate}
		\item       \label{ITEMooCVALooEfLQCyI}
		      \( e^0=\id\)
		\item       \label{ITEMooNGPWooIyPEQt}
		      \( A^m e^{A}= e^{A}A^m\)
		\item       \label{ITEMooEOSMooQWjcjA}
		      \( \exp(A)^t=\exp(A^t)\)
		\item       \label{ITEMooROPJooMarenu}
		      Si \( AB=BA\) alors \( A e^{B}= e^{B}A\) et \(  e^{A} e^{B}= e^{B} e^{A}\).
	\end{enumerate}
\end{proposition}

\begin{proof}
	Point par point.
	\begin{subproof}
		\spitem[Pour \ref{ITEMooCVALooEfLQCyI}]
		Juste substituer \( A=0\) dans la définition. Tous les termes tombent sauf le premier. Il faut utiliser le fait que \( A^0=\id\).
		\spitem[Pour \ref{ITEMooNGPWooIyPEQt}]
		Il faut utiliser la proposition \ref{PROPooMZZQooEhQsgQ} pour écrire
		\begin{equation}        \label{EQooLUUVooCtUtIC}
			A^m\sum_k\frac{ A^k }{ k! }=\sum_k\frac{ A^mA^k }{ k! }=\sum_{k}\frac{ A^kA^m }{ k! }=\sum_k\frac{ A^k }{ k! }A^m.
		\end{equation}
		\spitem[Pour \ref{ITEMooEOSMooQWjcjA}]
		Pour chaque \( k\) nous avons l'égalité \( (A^k)^t=(A^t)^k\). En utilisant encore le coup de la queue de suite qui converge vers zéro,
		\begin{equation}
			\| \sum_{k=0}^N\frac{ (A^t)^k }{ k! }-( e^{A})^t \|=\| \sum_{k=N+1}^{\infty}\frac{ (A^t)^k }{ k! } \|\to 0.
		\end{equation}
		\spitem[Pour \ref{ITEMooROPJooMarenu}]
		Pour prouver \( A e^{B}= e^{B}A\), c'est le même genre de manipulations que \eqref{EQooLUUVooCtUtIC}.

		Maintenant, vu que \( A\) et \( e^B\) commutent, l'égalité à peine prouvée montre que \(  e^{A}\) et \(  e^{B}\) commutent.
	\end{subproof}
\end{proof}

\begin{proposition}[\cite{BIBooROFBooCcFjms}]       \label{PROPooKDKDooCUpGzE}
	Soient \( A\in \eM(n,\eC)\) ainsi que \( s,t\in \eC\). Alors
	\begin{equation}
		e^{sA} e^{tA} = e^{(s+t)A}.
	\end{equation}
\end{proposition}

\begin{proof}
	Nous calculons le produit \( e^{sA} e^{tA}\) par le produit de Cauchy de la proposition \ref{PROPooFMEXooCNjdhS} :
	\begin{equation}
		\clubsuit = \left( \sum_k\frac{ t^k }{ k! }A^k \right)\left( \sum_l\frac{ s^l }{ l! }A^l \right)=\sum_{n=0}^{\infty}\sum_{m=0}^n\frac{ t^m }{ m! }\frac{ s^{n-m} }{ (n-m)! }A^n.
	\end{equation}
	À ce point, nous multiplions et divisons par \( n!\) et nous réarrangons la somme de la façon suivante :
	\begin{equation}
		\clubsuit = \sum_{n=0}^{\infty}\frac{ A^n }{ n! }\sum_{m=0}^n\frac{ n! }{ m!(n-m)! }t^ms^{n-m}.
	\end{equation}
	Nous reconnaissons la somme sur \( m\) comme étant un binôme de Newton\footnote{Proposition \ref{PropBinomFExOiL}.} pour \( (t+s)^n\). Nous avons donc finalement
	\begin{equation}
		\clubsuit = \sum_{n=0}^{\infty}\frac{ \big( (t+s)A \big)^n }{ n! }= e^{(t+s)A}.
	\end{equation}
\end{proof}

La proposition suivante dit que les exponentielles de matrices sont inversibles. Elle ne dit pas que toutes les matrices inversibles sont des exponentielles. Ce sera la proposition \ref{PropKKdmnkD}.
\begin{proposition}[\cite{BIBooROFBooCcFjms}]       \label{PROPooRERRooMutKcg}
	Si \( A\in \eM(n,\eC)\), alors \(  e^{A}\) est inversible et
	\begin{equation}
		( e^{A})^{-1}= e^{-A}.
	\end{equation}
\end{proposition}

\begin{proof}
	Il suffit de prendre \( s=1\) et \( t=-1\) dans la proposition \ref{PROPooKDKDooCUpGzE} et nous avons
	\begin{equation}
		e^{A} e^{-A}= e^{0}=\mtu.
	\end{equation}
	Cela prouve que \(  e^{A}\) est inversible et que son inverse est \(  e^{-A}\).
\end{proof}

\begin{proposition}[\cite{BIBooROFBooCcFjms, MonCerveau}]       \label{PROPooSDNNooQtHkhA}
	Soit \( A\in \eM(n,\eC)\). Nous considérons l'application
	\begin{equation}
		\begin{aligned}
			\varphi\colon \eR & \to \eM(n,\eC)   \\
			t                 & \mapsto  e^{tA}.
		\end{aligned}
	\end{equation}
	Nous avons la formule de dérivation
	\begin{equation}
		\varphi'(t)=A e^{tA}.
	\end{equation}
\end{proposition}

\begin{proof}
	L'application \( \varphi\) est une fonction composée de
	\begin{equation}
		\begin{aligned}
			f\colon \eR & \to \eM(n,\eR) \\
			t           & \mapsto tA
		\end{aligned}
	\end{equation}
	et
	\begin{equation}
		\begin{aligned}
			\exp\colon \eM(n,\eR) & \to \eM(n,\eR) \\
			A                     & \mapsto e^A.
		\end{aligned}
	\end{equation}
	Et nous avons \( \varphi=\exp\circ f\). Il y a un choix difficile à faire. Soit nous travaillons dans \( \eM(n,\eR)\) et nous allons devoir invoquer le théorème \ref{THOooFGTQooZPiVLO}, soit nous travaillons dans l'algèbre \( \Alg(A)\)  engendrée par \( A\) (définition \ref{DEFooXPFVooZzPXEK})
	qui est une algèbre commutative\footnote{Corolaire \ref{CORooQTUQooDtjljc}.} qui nous permet de n'utiliser que \ref{EQooKWBUooLUdBAw}, qui est quand même plus basique.

	Coup de théâtre, nous prenons la seconde solution et nous réécrivons les fonctions \( f\) et \( \exp\) de la façon suivante :
	\begin{equation}
		\begin{aligned}
			\varphi\colon \eR & \to \Alg(A)     \\
			t                 & \mapsto  e^{tA}
		\end{aligned}
	\end{equation}
	se décompose en
	\begin{equation}
		\begin{aligned}
			f\colon \eR & \to \Alg(A) \\
			t           & \mapsto tA
		\end{aligned}
	\end{equation}
	et
	\begin{equation}
		\begin{aligned}
			\exp\colon \Alg(A) & \to \Alg(A)      \\
			A                  & \mapsto \exp(A).
		\end{aligned}
	\end{equation}
	Le fait que ces applications soient bien définies est le lemme \ref{LEMooCEVGooFVXndZ} qui assure que les espaces d'arrivée sont bien dans \( \Alg(A)\). Et c'est parti pour le calcul :
	\begin{subequations}
		\begin{align}
			\varphi'(u) & =d\varphi_u(1)      \label{SUBEQooFDPQooBzTDXF}                    \\
			            & =d\exp_{f(u)}\big( df_u(1) \big)       \label{SUBEQooVOFWooDoTQGy} \\
			            & =\exp\big( f(u) \big)df_u(1)       \label{SUBEQooCILLooHsFDOE}     \\
			            & = e^{uA}A      \label{SUBEQooBMAQooNtbzBI}
		\end{align}
	\end{subequations}

	Justifications:
	\begin{itemize}
		\item Pour \ref{SUBEQooFDPQooBzTDXF}. Pour la dérivée, nous utilisons le corolaire \ref{CORooTBUMooHPncPH}.
		\item Pour \ref{SUBEQooVOFWooDoTQGy}. La règle de la différentielle en chaine du théorème \ref{THOooIHPIooIUyPaf}.
		\item Pour \ref{SUBEQooCILLooHsFDOE}. La formule \eqref{EQooKWBUooLUdBAw}.
		\item Pour \ref{SUBEQooBMAQooNtbzBI}. Parce que \( f(u)=uA\) et que \( df_u(1)=A\).
	\end{itemize}
\end{proof}

Le théorème suivant montre que le produit d'exponentielle de matrices suit la règle usuelle tant que les matrices commutent. Cela est cependant plutôt l'exception que la règle. À priori nous avons \(  e^{A} e^{B}\neq  e^{A+B}\).
\begin{theorem}[\cite{BIBooROFBooCcFjms}]       \label{THOooXCPEooYGyLOp}
	Soient \( A,B\in \eM(n,\eC)\) telles que \( AB=BA\). Alors
	\begin{equation}
		e^{A+B}= e^{A} e^{B}.
	\end{equation}
\end{theorem}

\begin{proof}
	Vu que \( A\) et \( B\) commutent nous avons \( A e^{tB}= e^{tB}A\) (proposition \ref{PROPooFLHPooRhLiZE}\ref{ITEMooROPJooMarenu}). Ensuite nous posons
	\begin{equation}
		g(t)= e^{t(A+B)} e^{-tB} e^{-tA}.
	\end{equation}
	Nous calculons la dérivée de \( g\) en utilisant la règle de Leibniz et la proposition \ref{PROPooSDNNooQtHkhA} :
	\begin{equation}
		\begin{aligned}[]
			g'(t) & =(A+B) e^{t(A+B)} e^{-tB} e^{-tA}        \\
			      & \quad + e^{t(A+B)}(-B) e^{-tB} e^{-tA}   \\
			      & \quad +  e^{t(A+B)} e^{-tB}(-A) e^{-tA}.
		\end{aligned}
	\end{equation}
	Vu que \( A\), \( B\) et \( A+B \) commutent, nous pouvons réarranger les facteurs en
	\begin{equation}
		\begin{aligned}[]
			g'(t) & =(A+B) e^{t(A+B)} e^{-tB} e^{-tA}     \\
			      & \quad -B e^{t(A+B)} e^{-tB} e^{-tA}   \\
			      & \quad -A  e^{t(A+B)} e^{-tB} e^{-tA}.
		\end{aligned}
	\end{equation}
	Enfin, cela fait
	\begin{equation}
		g'(t)=(A+B-B-A) e^{t(A+B)} e^{-tB} e^{-tA}=0.
	\end{equation}
	Donc \( g\) est constante et nous avons
	\begin{equation}
		e^{t(A+B)} e^{-tB} e^{-tA}=g(0)=\mtu.
	\end{equation}
	En multipliant à droite par \(  e^{tA} e^{tB}\) nous trouvons
	\begin{equation}
		e^{t(A+B)}= e^{tA} e^{tB}
	\end{equation}
	comme annoncé.
\end{proof}

\begin{normaltext}		\label{NORMooMYHYooEKbUlP}
	Pour tout anneau normé \( A\) où cela a un sens, nous définissons
	\begin{equation}
		\begin{aligned}
			\phi\colon A & \to A                                                   \\
			a            & \mapsto \sum_{k=0}^{\infty}\frac{ (-1)^k }{ (k+1)! }a^k
		\end{aligned}
	\end{equation}
\end{normaltext}

\begin{proposition}[\cite{MonCerveau}]	\label{PROPooCVIAooTovqVg}
	À propos de la fonction \( \phi\)\footnote{De \ref{NORMooMYHYooEKbUlP}.}.
	\begin{enumerate}
		\item		\label{ITEMooKNRIooJxHXDq}
		      Si \( r\in \eR^+\), alors la série
		      \begin{equation}
			      \sum_{k=0}^{\infty}\frac{ (-1)^k }{ (k+1)! }r^k
		      \end{equation}
		      converge.
		\item		\label{ITEMooUYJVooMYnesX}
		      Dans le cas de \( A=\eC\), nous avons
		      \begin{equation}
			      \phi(z)=\sum_{k=0}^{\infty}\frac{ (-1)^k }{ (k+1)! }z^k=\frac{ 1-e^{-z} }{ z }.
		      \end{equation}
	\end{enumerate}
\end{proposition}

\begin{proof}
	Pour \ref{ITEMooKNRIooJxHXDq}, c'est le critère des séries alternées \ref{THOooOHANooHYfkII} qui marche parce que \( r^k/k!\to 0\).

	Pour \ref{ITEMooUYJVooMYnesX} \ldots Si vous avez une idée, écrivez-moi.
	%TODOooSSZLooQFUnLr. Prouver ça.
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Exponentielle et logarithme dans les réels}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Pour avoir une vue synthétique du plan, voir le thème \ref{THEMEooKXSGooCsQNoY}.

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{L'équation différentielle}
%---------------------------------------------------------------------------------------------------------------------------

Pour la suite nous notons \( y\) une solution de l'équation \( y'=y\), \( y(0)=1\), et nous allons en donner des propriétés indépendamment de l'existence, donnée par le théorème~\ref{ThoKRYAooAcnTut}.

\begin{proposition} \label{PropTLECooEiLbPP}
	Quelques propriétés de \( y\) (si elle existe) :
	\begin{enumerate}
		\item
		      Pour tout \( x\in \eR\) nous avons \( y(x)y(-x)=1\).
		\item
		      \( y(x)>0\) pour tout \( x\).
		\item
		      \( y\) est strictement croissante.
	\end{enumerate}
\end{proposition}

\begin{proof}
	Nous posons \( \varphi(x)=y(x)y(-x)\) et nous dérivons :
	\begin{equation}
		\varphi'(x)=y'(x)y(-x)-y(x)y'(-x)=0.
	\end{equation}
	Donc \( \varphi\) est constante\footnote{Proposition~\ref{PropGFkZMwD}.}. Vu que \( \varphi(0)=1\) nous avons automatiquement \( y(x)y(-x)=1\) pour tout \( x\).

	Les deux autres allégations sont simples : si \( y(x_0)<0\) alors il existe \( t\in\mathopen] 0 , x_0 \mathclose[\) tel que \( y(t)=0\), ce qui est impossible parce que \( y(t)y(-t)=1\). La stricte croissance de \( y\) s'ensuit.
\end{proof}

\begin{proposition}     \label{PROPooGGUIooExVHPM}
	Quelques formules pour tout \( a,b\in \eR\) et \( n\in \eZ\) :
	\begin{enumerate}
		\item       \label{ITEMooMPSUooWQpVQJ}
		      \( y(a+b)=y(a)y(b)\)
		\item
		      \( y(na)=y(a)^n\)
		\item
		      \( y\left( \frac{ a }{ n } \right)=\sqrt[n]{y(a)}\).
	\end{enumerate}
\end{proposition}

\begin{proof}
	Nous posons \( h(x)=y(a+b-x)y(x)\) et nous avons encore \( h'(x)=0\) dont nous déduisons que \( h\) est constante. De plus
	\begin{equation}
		h(0)=y(a+b)y(0)=y(a+b)
	\end{equation}
	et
	\begin{equation}
		h(b)=y(a)y(b).
	\end{equation}
	Vu que \( h\) est constante, ces deux expressions sont égales : \( y(a+b)=y(a)y(b)\).

	Forts de cette relation, une récurrence donne \( y(na)=y(a)^n\) pour tout \( n\in \eN\). De plus
	\begin{equation}
		y(a)=y\left( \frac{ a }{ n }\times n \right)=y\left( \frac{ a }{ n } \right)^n,
	\end{equation}
	ce qui donne \( y(a)=y(a/n)^n\) ou encore \( y(a/n)=\sqrt[n]{y(a)}\).

	Enfin pour les négatifs, si \( n\in \eN\),
	\begin{equation}
		y(-na)=\frac{1}{ y(na) }=\frac{1}{ y(a)^n }=y(a)^{-n}.
	\end{equation}
	Et de la même façon,
	\begin{equation}
		y\left( -\frac{ a }{ n } \right)=\frac{1}{ y\left( \frac{ a }{ n } \right) }=\sqrt[n]{\frac{1}{ y(a) }}=\sqrt[-n]{y(a)}.
	\end{equation}
\end{proof}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Existence}
%---------------------------------------------------------------------------------------------------------------------------

Jusqu'ici nous avons donné des propriétés d'une éventuelle fonction \( y\) qui vérifierait l'équation différentielle. Il est temps de montrer qu'une telle fonction existe.

\begin{theorem} \label{ThoKRYAooAcnTut}
	La série entière
	\begin{equation}    \label{EqEIGZooKWSvPS}
		\exp(x)=\sum_{k=0}^{\infty}\frac{ x^k }{ k! }
	\end{equation}
	définit une fonction dérivable solution de
	\begin{subequations}
		\begin{numcases}{}
			y'=y        \label{EQooSEIHooNmQKiC}\\
			y(0)=1.
		\end{numcases}
	\end{subequations}
\end{theorem}
\index{exponentielle!existence}

\begin{proof}
	La formule de Hadamard (théorème~\ref{ThoSerPuissRap}) donne le rayon de convergence de la série \eqref{EqEIGZooKWSvPS} par
	\begin{equation}
		\frac{1}{ R }=\lim_{k\to \infty} \frac{ \frac{1}{ (k+1)! } }{ \frac{1}{ k! } }=\lim_{k\to \infty} \frac{1}{ k+1 }=0.
	\end{equation}
	Donc nous avons un rayon de convergence infini. La fonction \( y\) est définie sur \( \eR\) et la proposition~\ref{ProptzOIuG} nous dit que \( y\) est dérivable. Nous pouvons aussi dériver terme à terme :
	\begin{equation}
		y'(x)=\sum_{k=0}^{\infty}\frac{ kx^{k-1} }{ k! }=\sum_{k=1}^{\infty}\frac{ kx^{k-1} }{ k! }=\sum_{k=1}^{\infty}\frac{ x^{k-1} }{ (k-1)! }=\sum_{k=0}^{\infty}\frac{ x^k }{ k! }=y(x).
	\end{equation}
	Notez le petit jeu d'indice de départ de \( k\). Dans un premier temps, nous remarquons que \( k=0\) donne un terme nul et nous le supprimons, et dans un second temps nous effectuons la simplification des factorielles (qui ne fonctionne pas avec \( k=0\)).
\end{proof}

\begin{normaltext}
	Nous savons que la fonction \( y\) existe parce qu'une solution de l'équation différentielle \( y'=y\), \( y(0)=1\) est donnée par la fameuse série (théorème \ref{ThoKRYAooAcnTut}). À part cela, ce qui a été fait avec cette équation différentielle ne permet pas de prouver l'existence de \( y\). Donc, du point de vue de «définir l'exponentielle par son équation différentielle», c'est pas encore gagné. Notons au passage que le nombre \( e\) n'est pas encore bien défini via l'équation différentielle.
\end{normaltext}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Le nombre de Neper \texorpdfstring{\(  e\)}{e}}
%---------------------------------------------------------------------------------------------------------------------------

Nous savons par le théorème \ref{ThoKRYAooAcnTut} que \( x\mapsto \exp(x)\) est une solution de l'équation différentielle exponentielle (avec la bonne condition initiale). Or une telle solution est unique par la proposition \ref{PropDJQSooYIwwhy}.

\begin{definition}[Le nombre de Neper]
	Nous notons \( e\) le nombre \( \exp(1)\).
\end{definition}

\begin{proposition}     \label{PropCELWooLBSYmS}
	Pour tout \( x\in \eR\), nous avons
	\begin{equation}        \label{EQooBFIHooKopcmf}
		\exp(x)=e^x.
	\end{equation}
\end{proposition}

\begin{proof}
	Soit \( y\) vérifiant la fameuse équation différentielle. Nous savons que \( y=\exp\) parce que c'est l'unique solution (proposition \ref{PropDJQSooYIwwhy}). Nous avons :
	\begin{equation}
		y(x)=y(1)^x.
	\end{equation}
	Si \( q\in \eQ\) alors \( q=a/b\) et
	\begin{equation}
		y(q)=y\left( \frac{ a }{ b } \right)=y\left( a\times \frac{1}{ b } \right)=y\left( \frac{1}{ b } \right)^a=\big( \sqrt[b]{y(1)} \big)^a=y(1)^{a/b}=y(1)^{q}.
	\end{equation}
	Le résultat est prouvé pour les rationnels.

	En ce qui concerne un élément général \( x\in \eR\), la fonction \( x\mapsto y(x)\) est continue sur \( \eR\), et la fonction \( x\mapsto e^x\) également (proposition \ref{DEFooOJMKooJgcCtq}). Ces deux fonctions étant égales sur \( \eQ\), elles sont égales sur \( \eR\) par la proposition  \ref{PropCJGIooZNpnGF}).
\end{proof}

\begin{proposition}	\label{PROPooIKJBooLOipUM}
	Pour tout \( \lambda\in \eR\), l'équation différentielle
	\begin{subequations}
		\begin{numcases}{}
			y'=\lambda y\\
			y(0)=1
		\end{numcases}
	\end{subequations}
	a une unique solution donnée par
	\begin{equation}
		y(t)=\exp(\lambda t)=e^{\lambda t}
	\end{equation}
	%TODOooJZQRooCLLJiq. Démontrer ça.
\end{proposition}


Une conséquence des propositions \ref{PropCELWooLBSYmS} et \ref{PROPooGCBZooTcyGtO} est que

\begin{subequations}    \label{EqLOIUooHxnEDn}
	\begin{align}
		\lim_{x\to -\infty}  e^{x} & =0        \\
		\lim_{x\to +\infty}  e^{x} & =+\infty,
	\end{align}
\end{subequations}
et en particulier,
\begin{equation}
	\begin{aligned}
		\exp\colon \eR & \to \mathopen] 0 , \infty \mathclose[ \\
		x              & \mapsto  e^{x}
	\end{aligned}
\end{equation}
est une bijection.

\begin{lemma}		\label{LEMooXFAXooLVbebl}
	Nous avons l'encadrement \( 2.5<e<2.8\).
\end{lemma}

\begin{proof}
	Vu que tous les termes de la série exponentielle sont strictement positifs, nous avons
	\begin{equation}
		e=\sum_{k=0}^{\infty}\frac{1}{ k!}>\frac{1}{ 1}+\frac{1}{ 1}+\frac{1}{ 2}=2.5.
	\end{equation}

	Pour la majoration, nous notons que \( k!>2^k\) à partir de \( k=4\). Donc nous gardons les termes \( k=0,1,2,3\) sous la forme \( 1/k!\) et nous remplaçons les autres par \( 1/2^n\) :
	\begin{equation}
		e<\frac{1}{ 1}+\frac{1}{ 1}+\frac{1}{ 2}+\frac{1}{ 6}+\sum_{k=4}^{\infty}\frac{1}{ 2^n}.
	\end{equation}
	Nous pouvons calculer explicitement la somme en utilisant la série géométrique de la proposition \ref{PROPooWOWQooWbzukS}\ref{ITEMooVZHKooNGpDkx} :
	\begin{equation}
		\sum_{k=4}^{\infty}\frac{1}{ 2^n}=1-\big( \frac{1}{ 2}+\frac{1}{ 4}+\frac{1}{ 8} \big)=\frac{1}{ 8}.
	\end{equation}
	En remettant tout ensemble,
	\begin{equation}
		e<2+\frac{ 2 }{ 3 }+\frac{1}{ 8}=\frac{ 67 }{ 24 }<2.8.
	\end{equation}
\end{proof}

\begin{proposition}[\cite{BIBooONOBooGXayID}]     \label{PROPooFRKUooZyhHIC}
	Le nombre \( e\) est irrationnel.
\end{proposition}

\begin{proof}
	En vertu de la proposition \ref{PropCELWooLBSYmS}, nous avons \( e^x=\exp(x)\) pour tout réel \( x\). En particulier pour \( x=1\),
	\begin{equation}
		e=\sum_{k=0}^{\infty}\frac{1}{ k! }.
	\end{equation}
	Supposons que \( e=p/q\) pour certains \( p,q\in \eN\) avec \( q\neq 0\) (notez que ça signifie \( q\geq 1\)).

	Nous avons
	\begin{equation}
		q!e=\sum_{k=0}^q\frac{ q! }{ k! }+\sum_{k=q+1}^{\infty}\frac{ q! }{ k! }.
	\end{equation}
	Dans le membre de gauche,
	\begin{equation}
		q!e=q!\frac{ p }{ q }=(q-1)!p\in \eN.
	\end{equation}
	Dans la première somme du membre de droite, vu que \( q\geq k\), nous avons
	\begin{equation}
		\sum_{k=0}^q\frac{ q! }{ k! }\in \eN.
	\end{equation}
	Nous devons donc avoir \( \sum_{k=q+1}^{\infty}\frac{ q! }{ k! }\in \eN\). Nous allons maintenant prouver que ce n'est pas le cas. Nous avons :
	\begin{subequations}
		\begin{align}
			\sum_{k=1}^{\infty}\frac{ q! }{ (q+k)! } & =\sum_{k=1}^{\infty}\frac{1}{ \prod_{l=q+1}^{q+k}l }                                  \\
			                                         & =\frac{1}{ q+1 }+\sum_{k=2}^{\infty}\frac{1}{ \prod_{l=q+1}^{q+k}l }                  \\
			                                         & =\frac{1}{ q+1 }\left[ 1+\sum_{k=2}^{\infty}\frac{1}{ \prod_{l=q+2}^{q+k}l } \right]  \\
			                                         & <\frac{1}{ q+1 }\left[ 1+\sum_{k=2}^{\infty}\frac{1}{ (q+1)^{(q+k)-(q+2)+1} } \right] \\
			                                         & =\frac{1}{ q+1 }\left[ 1+\sum_{k=2}^{\infty}\frac{1}{ (q+1)^{k-1} } \right]           \\
			                                         & =\frac{1}{ q+1 }\left[ 1+\sum_{k=1}^{\infty}\frac{1}{ (q+1)^k } \right]               \\
			                                         & =\frac{1}{ q+1 }\sum_{k=0}^{\infty}\frac{1}{ (q+1)^k }.
		\end{align}
	\end{subequations}
	C'est le moment d'utiliser la série géométrique de la proposition \ref{PROPooWOWQooWbzukS}\ref{ITEMooBJHBooBMEmiG}. Vu que \( q\geq 1\) nous avons \( 1/(q+1)<1\) et la somme fonctionne :
	\begin{equation}
		\sum_{k=1}^{\infty}\frac{ q! }{ (q+k)! }<\frac{1}{ q+1 }\left( \frac{1}{ 1-\frac{1}{ q+1 } } \right)=\frac{1}{ q }.
	\end{equation}
	Nous avons donc
	\begin{equation}
		0< \sum_{k=1}^{\infty}\frac{ q! }{ (q+k)! }<\frac{1}{ q }<1.
	\end{equation}
	Donc ce terme n'est pas un nombre entier, ce que nous avions énoncé.
\end{proof}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Application réciproque : logarithme}
%---------------------------------------------------------------------------------------------------------------------------

\begin{propositionDef}    \label{DEFooELGOooGiZQjt}
	L'application \(\exp\colon \eR\to \mathopen] 0 , \infty \mathclose[\) est une bijection. L'application réciproque
	\begin{equation}
		\ln\colon \mathopen] 0 , \infty \mathclose[\to \eR
	\end{equation}
	est le \defe{logarithme}{logarithme!sur les réels positifs}.
\end{propositionDef}

\begin{proof}
	Le fonction exponentielle est dérivable, toujours strictement positive, donc strictement croissante. Les limites en \( \pm \infty\) sont \( 0\) et \( +\infty\). Le théorème des valeurs intermédiaires~\ref{ThoValInter} nous dit que c'est une bijection. En effet, l'injectivité est la stricte croissance. En ce qui concerne la surjection, soit \( y\in \mathopen] 0 , \infty \mathclose[\). Vu que la limite en \( -\infty\) est zéro, il existe \( A\in \eR\) tel que \( \exp(x)<y\) pour tout \( x<A\), et de la même façon, il existe \( B\in \eR\) tel que \( \exp(x)>y\) pour tout \( x>B\). Si \( a<A\) et \( b>B\) alors \( \exp(a)<y\) et \( \exp(b)>y\), donc \( y\) est dans l'image de \( \mathopen[ a , b \mathclose]\) par l'exponentielle.
\end{proof}

\begin{lemma}[\cite{MonCerveau}]        \label{LEMooCYGTooEjXEUu}
	Le logarithme est une fonction continue.
\end{lemma}

\begin{proof}
	C'est une conséquence du théorème de la bijection \ref{ThoKBRooQKXThd}\ref{ItemEJZooKuFoeFiv}, et de la continuité de l'exponentielle sur \( \eR\), qui est une partie du théorème \ref{ThoKRYAooAcnTut}.
\end{proof}

\begin{proposition}[Dérivée du logarithme]      \label{PROPooPDJLooXphpEM}
	Pour tout \( s\in \eR^+\) nous avons
	\begin{equation}
		\ln'(s)=\frac{1}{ s }.
	\end{equation}
\end{proposition}

\begin{proof}
	L'application \( \exp\colon \eR\to \mathopen] 0 , \infty \mathclose[\) est une bijection continue dérivable\footnote{Dérivable (et donc continue) par le théorème \ref{ThoKRYAooAcnTut}. Bijection par la proposition \ref{DEFooELGOooGiZQjt}.}. La proposition \ref{PropMRBooXnnDLq} s'applique donc et pour tout \( x\in \eR\) nous avons
		\begin{equation}
			\ln'\big( \exp(x) \big)=\frac{1}{ \exp'(x) }.
		\end{equation}
		Le théorème \ref{ThoKRYAooAcnTut} nous indique que \( \exp'(x)=\exp(x)\). Donc pour tout \( x\) nous avons \( \ln'\big( \exp(x) \big)=\frac{1}{  \exp(x) }\). Vu que \( x\) est arbitraire et que \( \exp\) est surjective sur \( \eR^+\), pour tout \( s\in \mathopen] 0 , \infty \mathclose[\) nous avons
	\begin{equation}
		\ln'(s)=\frac{1}{ s }.
	\end{equation}
\end{proof}

\begin{proposition}[\cite{MonCerveau}]      \label{PROPooLAOWooEYvXmI}
	Pour tout \( x,y\in \eR\) et pour \( a>0\) nous avons
	\begin{equation}
		\ln(\frac{1}{ x })=-\ln(x),
	\end{equation}
	et
	\begin{equation}        \label{EQooJVMUooVpUKyo}
		\ln(xy)=\ln(x)+\ln(y),
	\end{equation}
	et
	\begin{equation}        \label{EQooEJQSooWCczXy}
		\ln(a^x)=x\ln(a)
	\end{equation}
	et
	\begin{equation}
		a^x= e^{x\ln(a)}.
	\end{equation}
\end{proposition}

\begin{proof}
	Nous avons, par la proposition \ref{PROPooVADRooLCLOzP},
	\begin{equation}
		e^{-\ln(x)}=\frac{1}{  e^{\ln(x)} }=\frac{1}{ x }.
	\end{equation}
	En prenant le logarithme des deux côtés nous trouvons
	\begin{equation}
		-\ln(x)=\ln\left( \frac{1}{ x } \right).
	\end{equation}

	Nous pouvons continuer avec la suivante.

	Par définition, \( \ln(xy)\) est donné par \( \exp\big( \ln(xy) \big)=xy\). Mais nous avons aussi, par la proposition \ref{PROPooVADRooLCLOzP} :
	\begin{equation}
		e^{\ln(x)+\ln(y)}=e^{\ln(x)}e^{\ln(y)}=xy.
	\end{equation}
	Nous avons donc démontré \eqref{EQooJVMUooVpUKyo}.

	La relation \eqref{EQooEJQSooWCczXy} de démontre d'abord pour \( x\in \eN\), puis pour \( x\in \eQ\) et enfin pour \( x\in\eR\). Si \( n\in \eN\) alors la relation \eqref{EQooJVMUooVpUKyo} donne immédiatement
	\begin{equation}
		\ln(a^n)=n\ln(a).
	\end{equation}
	pour tout \( a\in \eR\).

	Si \( m,n\in \eN\), le nombre \( a^{n/m}\) est par définition le \( x>0\) tel que
	\begin{equation}
		x^m=a^n.
	\end{equation}
	En prenant le logarithme des deux côtés : \( \ln(x^m)=\ln(a^n)\) et en utilisant la relation déjà démontrée pour \( \eN\) nous trouvons \( m\ln(x)=n\ln(a)\) et donc
	\begin{equation}
		\ln(a^{m/n})=\ln(x)=\frac{ m }{ n }\ln(a).
	\end{equation}
	La relation est donc démontré pour \( \ln(a^q)\) avec \( q\in \eQ^+\).

	Nous passons à \( q=-m/n\in \eQ^-\), c'est-à-dire toujours \( m,n\in \eN\). Nous avons, en utilisant la proposition \ref{PROPooLAOWooEYvXmI},
	\begin{equation}
		\ln(a^{-q})=\ln(\frac{1}{ a^q })=-\ln(a^q)=-q\ln(a).
	\end{equation}

	Enfin si \( x\in \eR\) nous considérons une suite de rationnels \( x_k\to x\). Pour chaque \( k\) nous avons
	\begin{equation}
		\ln(a^{x_k})=x_k\ln(a).
	\end{equation}
	Nous prenons la limite deux deux côtés. À droite nous avons tout de suite \( x\ln(a)\), et à gauche, par continuité de la fonction \( \ln\) (lemme \ref{LEMooCYGTooEjXEUu}) et de la fonction puissance (définition \ref{DEFooOJMKooJgcCtq}) nous trouvons \( \ln(a^x)\).
\end{proof}

\begin{lemma}   \label{LemPEYJooEZlueU}
	Si \( a,b\in\mathopen] 0 , \infty \mathclose[\) alors
	\begin{equation}
		\ln(ab)=\ln(a)+\ln(b)
	\end{equation}
	et
	\begin{equation}    \label{EqOOZGooOWkGlA}
		\ln\left( \frac{1}{ b } \right)=-\ln(b).
	\end{equation}
\end{lemma}

\begin{proof}
	Nous posons \( f(x)=\ln(ax)\) qui est une fonction dérivable\footnote{Dérivée du logarithme, proposition \ref{PROPooPDJLooXphpEM}.}. Alors \( f'(x)=\frac{ a }{ ax }=\frac{1}{ x }\). Cette fonction \( f\) est donc une primitive de \( \frac{1}{ x }\) et il existe une constante \( K\) telle que
	\begin{equation}
		f(x)=\ln(x)+K.
	\end{equation}
	Vu que \( \ln(1)=0\) nous avons \( K=f(1)= \ln(a)\). Donc
	\begin{equation}
		\ln(ax)=\ln(x)+\ln(a).
	\end{equation}

	En ce qui concerne la seconde formule à démontrer, nous avons
	\begin{equation}
		\ln(1)=\ln\left( \frac{1}{ b }b \right)=\ln\left( \frac{1}{ b } \right)+\ln(b).
	\end{equation}
	Étant donné que \( \ln(1)=0\) nous en déduisons la formule \eqref{EqOOZGooOWkGlA}.
\end{proof}

\begin{normaltext}
	La formule \eqref{EQooEJQSooWCczXy} en particulier est pratique pour réexprimer des fonctions puissances compliquées en écrivant
	\begin{equation}        \label{EQooYEWCooKyravP}
		a^x= e^{\ln(a^x)}= e^{x\ln(a)}.
	\end{equation}
	Cela aide à calculer la dérivée de \( x\mapsto a^x\).

	Notons que certains prennent \eqref{EQooYEWCooKyravP} comme définition de la fonction puissance.
\end{normaltext}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Approximations numériques de \texorpdfstring{\(  e\)}{e}}
%---------------------------------------------------------------------------------------------------------------------------

Nous donnons maintenant quelques approximations numériques de \( e\), particulièrement inefficaces.

\begin{lemma}
	Nous avons
	\begin{equation}
		2<e<3.
	\end{equation}
\end{lemma}

\begin{proof}
	Nous savons que \( y(0)=1\) et \( y'(0)=1\). La fonction \( y\) est strictement croissante (et donc sa dérivée aussi). Nous avons donc \( y'(x)>1\) pour tout \( x\in\mathopen] 0 , 1 \mathclose]\), et donc
	\begin{equation}
		y(1)>1+1\times 1=2.
	\end{equation}
	Sachant que \( 2>y'(x)\) pour tout \( x\in \mathopen] 0 , 1 \mathclose[\) nous pouvons refaire le coup de l'approximation affine, cette fois en majorant :
	\begin{equation}
		y(1)<1+2\times 1=3.
	\end{equation}
\end{proof}

De la même façon nous savons que
\begin{equation}
	y(\frac{1}{ n })>1+\frac{1}{ n }
\end{equation}
parce que \( y'\) est minoré par \( 1\) sur \( \mathopen] 0 , \frac{1}{ n } \mathclose[\). Avec cela nous avons aussi la majoration
	\begin{equation}
		y(\frac{1}{ n })<1+\frac{1}{ n }\times \left( 1+\frac{1}{ n } \right)=1+\frac{1}{ n }+\frac{1}{ n^2 }.
	\end{equation}
	Et enfin nous pouvons donner l'encadrement, valable pour tout \( n\) :
	\begin{equation}
		\left( 1+\frac{1}{ n } \right)^n<y(1)<\left( 1+\frac{1}{ n }+\frac{1}{ n^2 } \right)^n.
	\end{equation}
	Pour \( n=10\) nous trouvons
	\begin{equation}
		2.50<e<2.83.
	\end{equation}

	Bien que ce soit à mon avis humainement pas possible à faire à la main nous avons, pour \( n=100\) :
	\begin{equation}
		2.70<e<2.7317
	\end{equation}
	Cela reste un encadrement très modeste.

	Une méthode plus efficace consiste à calculer directement le développement de définition
	\begin{equation}
		e=\exp(1)=\sum_{k=0}^{\infty}\frac{1}{ n! }.
	\end{equation}
	\lstinputlisting{tex/sage/sageSnip013.sage}

	\begin{probleme}
		Comment trouver, avec cette méthode, un \emph{encadrement pour \( e\) ?}
	\end{probleme}

	Ce petit programme, avec \( 5\) termes donne \( e\simeq 65/24\simeq 2.708\). Avouez que c'est déjà bien mieux.

	%--------------------------------------------------------------------------------------------------------------------------- 
	\subsection{Résumé des propriétés de l'exponentielle}
	%---------------------------------------------------------------------------------------------------------------------------

	\begin{theorem}  \label{ThoRWOZooYJOGgR}
		Les choses que nous savons sur l'exponentielle :
		\begin{enumerate}
			\item       \label{ITEMooEIKKooLNoaRD}
			      Il y a unicité de la solution à l'équation différentielle
			      \begin{subequations}    \label{subeqBKJNooJQtbBD}
				      \begin{numcases}{}
					      y'=y\\
					      y(0)=1.
				      \end{numcases}
			      \end{subequations}
			\item
			      L'équation différentielle \eqref{subeqBKJNooJQtbBD} possède une solution donnée par la série entière\nomenclature[Y]{\( \exp\)}{exponentielle}
			      \begin{equation}    \label{EqUARSooKXnQxu}
				      \exp(x)=\sum_{k=0}^{\infty}\frac{ x^k }{ k! }
			      \end{equation}
			\item
			      Cette solution est une bijection \( y\colon \eR\to \mathopen] 0 , \infty \mathclose[\).
			\item   \label{ItemYTLTooSnfhOu}
			      La fonction \( y\) ainsi définie est de classe \(  C^{\infty}\).
			\item
			      Elle est également donnée par la formule
			      \begin{equation}
				      \exp(x)=e^x
			      \end{equation}
			      où \( e\) est défini par \( e=\exp(1)\).
			\item
			      Elle vérifie
			      \begin{equation}        \label{EQooVFXUooBfwjJY}
				      e^{a+b}= e^{a} e^{b}
			      \end{equation}
		\end{enumerate}
	\end{theorem}
	Nous nommons \defe{exponentielle}{exponentielle} cette fonction.

	\begin{proof}
		Point par point.
		\begin{enumerate}
			\item
			      C'est la proposition~\ref{PropDJQSooYIwwhy}.
			\item
			      C'est le théorème~\ref{ThoKRYAooAcnTut}.
			\item
			      Le rayon de convergence de la série \eqref{EqUARSooKXnQxu} est infini (théorème~\ref{ThoKRYAooAcnTut}); elle est donc définie sur \( \eR\). Le fait que ce soit une bijection est dû au fait qu'elle est strictement croissante (proposition~\ref{PropTLECooEiLbPP}) ainsi qu'aux limites \eqref{EqLOIUooHxnEDn}.
			\item
			      Vu que \( y=y'\), \( y\) est dérivable. Mais comme \( y'\) est alors égale à une fonction dérivable, \( y'\) est dérivable. En dérivant l'égalité \( y'=y\) nous obtenons \( y''=y'\) et le jeu continue.
			\item
			      C'est la proposition~\ref{PropCELWooLBSYmS}.
			\item
			      C'est la proposition~\ref{PROPooGGUIooExVHPM}\ref{ITEMooMPSUooWQpVQJ}.
		\end{enumerate}
	\end{proof}

	\begin{example}[Un endomorphisme sans polynôme annulateur\cite{RombaldiO}]     \label{ExooLRHCooMYLQTU}
		l'exponentielle permet de donner un exemple d'un endomorphisme n'ayant pas de polynôme annulateur\footnote{En dimension finie, le lemme \ref{LEMooQJQGooRcAxmJ} dit qu'il y en a toujours un.} : l'endomorphisme de dérivation
		\begin{equation}
			\begin{aligned}
				D\colon C^{\infty}(\eR,\eR) & \to  C^{\infty}(\eR,\eR) \\
				f                           & \mapsto f'
			\end{aligned}
		\end{equation}
		n'a pas de polynôme annulateur. En effet supposons que \( P=\sum_{k=0}^{p}a_kX^k\) en soit un, et considérons les fonctions \( f_{\lambda}\colon t\mapsto  e^{\lambda t}\). Nous avons
		\begin{equation}
			0=P(D)f_{\lambda}
			=\sum_ka_kD^k(f_{\lambda})
			=\sum_ka_k\lambda^kf_{\lambda}
			=P(\lambda)f_{\lambda}.
		\end{equation}
		Par conséquent \( \lambda\) est une racine de \( P\) pour tout \( \lambda\in \eR\). Cela implique que \( P=0\).

		D'ailleurs si on y pense bien, cet exemple n'est qu'un habillage de l'exemple~\ref{ExooDTUJooIMqSKn}.
	\end{example}

	\begin{proposition}\label{ExZLMooMzYqfK}
		Quelques propriétés du logarithme.
		\begin{enumerate}
			\item
			      Le logarithme est une application dérivable et strictement croissante.
			\item
			      Le logarithme est la primitive de \( x\mapsto\frac{1}{ x }\) qui s'annule en \( x=1\).
		\end{enumerate}
	\end{proposition}

	\begin{proof}
		Elle est donc bijective, d'inverse continue et dérivable par le théorème~\ref{ThoKBRooQKXThd} et la proposition~\ref{PropMRBooXnnDLq}.

		La dérivée de la fonction logarithme peut être calculée en utilisant la formule \eqref{EqWWAooBRFNsv}, mais aussi de façon plus piettone en écrivant l'expression suivante, valable pour tout \( x\in \eR\) :
		\begin{equation}
			\ln\big( \exp(x) \big)=x,
		\end{equation}
		que nous pouvons dériver en utilisant le théorème de dérivation des fonctions composées :
		\begin{equation}
			\ln'\big( \exp(x) \big)\exp'(x)=1.
		\end{equation}
		Mais \( \exp'(x)=\exp(x)\), donc
		\begin{equation}
			\ln'(y)=\frac{1}{ y }
		\end{equation}
		pour tout \( y\) dans l'image de \( \exp\), c'est-à-dire pour tout \( y\) dans l'ensemble de définition de \( \ln\).

		Par ailleurs, \( \exp(0)=1\) donc
		\begin{equation}
			\ln(1)=\ln\big( \exp(0) \big)=0.
		\end{equation}

		En ce qui concerne l'unicité d'une primitive s'annulant en \( x=1\), c'est le corolaire~\ref{CorZeroCst}.
	\end{proof}

	%--------------------------------------------------------------------------------------------------------------------------- 
	\subsection{Dérivée de la fonction puissance}
	%---------------------------------------------------------------------------------------------------------------------------

	\begin{example}     \label{EXooGMRIooUucRez}
		Soit la fonction \( f(x,y)=x^y\), définie en \ref{DEFooOJMKooJgcCtq}. Nous allons en calculer les dérivées partielles au point \( (1,2)\). Notons que \( f\) n'est pas définie pour \( x<0\), mais que cela n'a pas d'importance parce que nous pouvons nous restreindre à un voisinage du point \( (1,2)\). La première dérivée partielle est facile :
		\[
			\partial_x f(1,2)=(yx^{y-1})_{(x,y)=(1,2)}=2.
		\]
		Pour la seconde, il faut utiliser les propriétés de l'exponentielle et du logarithme. D'abord le logarithme est par définition l'application réciproque de l'exponentielle (définition \ref{DEFooELGOooGiZQjt}), donc
		\begin{equation}
			x^y=\exp\big( \ln(x^y) \big).
		\end{equation}
		Ensuite nous calculons en utilisant la proposition \ref{PROPooLAOWooEYvXmI} :
		\begin{equation}
			\partial_y f(1,2)=\partial_y\left(e^{y\ln x}\right)_{(x,y)=(1,2)}=\left(\ln x e^{y\ln x}\right)_{(x,y)=(1,2)}=\ln(1) e^{2\ln(1)}.
		\end{equation}
	\end{example}


	Cet exemple est facilement généralisable aux fonctions de la forme \( x\mapsto u(x)^{v(x)}\). Voici une proposition qui dit comment faire.
	\begin{proposition}[\cite{MonCerveau}]     \label{PROPooKUULooKSEULJ}
		Soit une fonction dérivable \( u\colon \eR\to \eR\) et \( a>0\). Nous avons
		\begin{equation}
			\left( a^u\right)'=u'\ln(a)a^u.
		\end{equation}

		Si de plus \( u(x)>0\) pour tout \( x\), nous avons
		\begin{equation}
			\left( u^a \right)'=au'u^{a-1}.
		\end{equation}
	\end{proposition}

	\begin{proof}
		Nous considérons la fonction \( f(x)= a^{u(x)}\). Vu que \( f(x)>0\) pour tout \( x\), nous pouvons en prendre le logarithme et écrire l'égalité, valable pour tout \( x\) :
		\begin{equation}
			f(x)= e^{\ln(a^{u(x)})}=\exp\big( u(x)\ln(a) \big).
		\end{equation}
		Sachant la dérivée de l'exponentielle, cela n'est rien d'autre que la dérivée d'une fonction composée :
		\begin{equation}
			f'(x)=\ln(a) u'(x) e^{u(x)\ln(a)}.
		\end{equation}

		Pour l'autre, nous posons
		\begin{equation}
			g(x)=u(x)^a,
		\end{equation}
		qui peut encore s'écrire sous la forme
		\begin{equation}
			g(x)= e^{a\ln\big( u(x) \big)}.
		\end{equation}
		Ici encore, c'est la dérivée de fonctions composées qui donne le résultat.
	\end{proof}

	%--------------------------------------------------------------------------------------------------------------------------- 
	\subsection{Dérivée du logarithme}
	%---------------------------------------------------------------------------------------------------------------------------

	\begin{lemma}       \label{LEMooTGCBooJdkLpg}
		Si \( u\colon \eR\to \mathopen] 0 , \infty \mathclose[\) est dérivable alors \( \ln(u)'=\dfrac{ u' }{ u }\).
	\end{lemma}

	\begin{proof}
		Cela est une conséquence du théorème de dérivation des fonctions composées : si \( g(x)=\ln(u(x))\) alors
		\begin{equation}
			g'(x)=\ln'\big( u(x) \big)u'(x)=\frac{1}{ u(x) }u'(x).
		\end{equation}
	\end{proof}

	%--------------------------------------------------------------------------------------------------------------------------- 
	\subsection{Taylor pour l'exponentielle}
	%---------------------------------------------------------------------------------------------------------------------------

	\begin{proposition}[Développement de l'exponentielle]       \label{PROPooQBRGooAhGrvP}
		Pour tout entier \( n\), il existe une fonction \( \alpha\colon \eR\to \eR\) telle que \( \lim_{t\to 0} \alpha(t)=0\) et
		\begin{equation}
			e^x=\sum_{k=0}^n\frac{ x^k }{ k! }+x^n\alpha(x).
		\end{equation}
	\end{proposition}

	\begin{proof}
		Il s'agit de la proposition \ref{PROPooQLHNooRsBYbe} appliquée à la série entière \eqref{DEFooSFDUooMNsgZY}.
	\end{proof}

	%--------------------------------------------------------------------------------------------------------------------------- 
	\subsection{Analycité}
	%---------------------------------------------------------------------------------------------------------------------------

	Vu que \( \exp(x)\) est défini par une série entière (définition \ref{DEFooSFDUooMNsgZY}) et vu la proposition \ref{PROPooTRWVooETTtbP}, il n'est pas étonnant que \( \exp\) soit analytique. Traitons ce cas.

	\begin{example}[Analycité de l'exponentielle]
		Soient \( a\in \eR\) et \( R>0\). Nous démontrons que \( \exp\) est analytique sur \( B(a,R)\). Si \( f(x)= e^{x}\), alors \( f^{(n)}(x)= e^{x}\) pour tout \( n\) (équation \eqref{EQooSEIHooNmQKiC}). Nous avons donc
		\begin{equation}
			| f^{(n)}(x) |< e^{a+R}
		\end{equation}
		pour tout \( x\in B(a,R)\). Nous partons de l'expression \eqref{THOooEUVEooXZJTRL} du reste :
		\begin{equation}
			| R_n(x) |\leq \frac{ M_n }{ (n+1)! }| x-a |^{n+1}\leq \frac{  e^{a+R} }{ (n+1)! }R^{n+1}.
		\end{equation}
		Mais nous avons la limite
		\begin{equation}
			\lim_{n\to \infty} \frac{ R^{n+1} }{ (n+1)! }=0
		\end{equation}
		pour tout \( R\).

		Donc avec les polynômes de Taylor \( P_n\) calculés en \( a\), nous avons \( P_n\to \exp\) simplement sur \( \eR\).

		Nous pouvons donc développer la fonction exponentielle autour de n'importe quel point, et avoir convergence des polynômes vers l'exponentielle sur tout \( \eR\). Vous accepterez cependant que si \( a\) et \( x\) sont éloignés, la convergence \( P_n(x)\to \exp(x)\) peut être extrêmement lente.
	\end{example}

	%--------------------------------------------------------------------------------------------------------------------------- 
	\subsection{Autres propriétés et petits calculs}
	%---------------------------------------------------------------------------------------------------------------------------

	\begin{lemma}
		Si les suites \( (u_n)\) et \( (v_n)\) sont équivalentes\footnote{Définition \ref{DEFooEWRTooKgShmT}.} et si \( (v_n)\) admet une limite \( l\) différente de \( 1\), alors les suites \( (\ln u_n)\) et \( (\ln v_n)\) sont équivalentes.
	\end{lemma}

	\begin{proof}
		En effet si \( u_n=v_n\alpha(n)\) alors en utilisant la formule du lemme \ref{LemPEYJooEZlueU},
		\begin{equation}
			\ln(u_n)=\ln(v_n)+\ln\big( \alpha(n) \big)=\ln(v_n)\left( 1+\frac{ \ln\big( \alpha(n) \big) }{ \ln(v_n) } \right),
		\end{equation}
		et comme \( \alpha(n)\to 1\), la parenthèse tend vers \( 1\).
	\end{proof}

	%--------------------------------------------------------------------------------------------------------------------------- 
	\subsection{Taylor pour le logarithme}
	%---------------------------------------------------------------------------------------------------------------------------

	Vu que \( \ln(0)\) n'existe pas, il n'est pas question de développer \( \ln\) autour de \( x=0\). À la place, nous allons le développer autour de \( x=1\) et plus précisément nous allons étudier Taylor pour la fonction \( f(x)=\ln(1+x)\). Les résultats seront résumés dans la proposition \ref{PROPooKPBIooJdNsqX}.

	\begin{proposition}[\cite{MonCerveau}]     \label{PROPooWCUEooJudkCV}
		Soit la fonction
		\begin{equation}
			\begin{aligned}
				f\colon \mathopen] -1 , \infty \mathclose[ & \to \eR           \\
				x                                          & \mapsto \ln(1+x).
			\end{aligned}
		\end{equation}
		Pour tout \( n\), il existe une fonction \( \alpha\colon \eR\to \eR\) telle que \( \lim_{t\to 0} \alpha(t)=0\) et
		\begin{equation}
			f(x)=\sum_{k=1}^n\frac{ (-1)^{k+1} }{ k }x^k+\alpha(x)x^n
		\end{equation}
		pour tout \( x\) dans le domaine de \( f\).

		Notez la somme qui part de \( k=1\) et non \( k=0\).
	\end{proposition}

	\begin{proof}
		Nous utilisons la formule de Taylor-Young (proposition \ref{PropVDGooCexFwy}). La première dérivée de \( f\) se calcule en utilisant le lemme \ref{LEMooTGCBooJdkLpg} :
		\begin{equation}
			f'(x)=\frac{1}{ 1+x }.
		\end{equation}
		Pour les dérivées suivantes, c'est juste du calcul et nous pouvons prouver par récurrence que
		\begin{equation}        \label{EQooKEAOooGmTLJF}
			f^{(k)}(x)=\frac{ (k-1)!(-1)^{k+1} }{ (1+x)^k }.
		\end{equation}
		En ce qui concerne l'évaluation en zéro :
		\begin{equation}
			f^{(k)}(0)=\begin{cases}
				0                & \text{si } k=0 \\
				(k-1)!(-1)^{k+1} & \text{sinon.}
			\end{cases}
		\end{equation}
		Du fait que \( f^{(0)}(0)=\ln(1)=0\), la somme commence à \( k=1\) et non \( k=0\). Nous avons
		\begin{equation}
			f(x)=\sum_{k=1}^{n}\frac{ f^{(k)}(0) }{ k! }x^k+\alpha(x)x^n=\sum_{k=1}^n\frac{ (-1)^{k+1} }{ k }x^k+\alpha(x)x^n.
		\end{equation}
	\end{proof}

	Nous étudions les polynômes de la série de Taylor pour
	\begin{equation}
		\begin{aligned}
			f\colon \mathopen] -1 , \infty \mathclose[ & \to \eR           \\
			x                                          & \mapsto \ln(1+x).
		\end{aligned}
	\end{equation}

	Les dérivées successives de \( f\) ont déjà été calculées en \eqref{EQooKEAOooGmTLJF}. Nous développons autour de \( x=0\). Donc \( f(0)=\ln(1)=0\) et pour les autres,
	\begin{equation}
		f^{(k)}(0)=(-1)^{k+1}(k-1)!.
	\end{equation}
	Pour les polynômes de Taylor, nous avons
	\begin{equation}
		P_n(x)=\sum_{k=1}^n\frac{ (-1)^{k+1} }{ k }x^k
	\end{equation}
	où vous noterez la somme qui part de \( k=1\) et non de \( k=0\). Nous avons aussi la série de Taylor de \( f\) donnée par
	\begin{equation}        \label{EQooTAREooKfpTPo}
		T(x)=\sum_{k=1}^{\infty}\frac{ (-1)^{k+1} }{ k }x^k.
	\end{equation}
	La somme est une limite ponctuelle, là où elle existe.

	Jusqu'à présent, la seule certitude à props de \( T\) est que \( T(0)=f(0)=0\). Pour le reste :
	\begin{itemize}
		\item Rien ne dit que \( T(x)\) existe pour d'autres \( x\) que \( x=1\).
		\item Et même si \( T(x)\) existait pour d'autres \( x\) (c'est-à-dire si le rayon de convergence de \eqref{EQooTAREooKfpTPo} était strictement plus grand que zéro), rien n'assurerait que la valeur serait celle de \( f\).
		\item Et même si \( T(x)\) convergeait vers \( f\) sur son disque de convergence, ce ne serait pas encore assez pour dire que \( f\) est analytique, parce que l'analycité demande que les séries de Taylor autour de \emph{chaque} point converge vers \( f\). Or ici nous ne parlons encore que de \( T\) qui est la série autour de \( x=0\).
	\end{itemize}

	\begin{lemma}       \label{LEMooWMGGooRpAxBa}
		La série de Taylor de \( x\mapsto \ln(1+x)\) autour de \( x=0\) converge sur \( \mathopen] -1 , 1 \mathclose]\). Elle ne converge pas pour \( x=-1\).
	\end{lemma}

	\begin{proof}

		En ce qui concerne le rayon de convergence de \( T\), nous utilisons la formule de Hadamard\footnote{Théorème \ref{ThoSerPuissRap}.} avec
		\begin{equation}
			a_k=\frac{ (-1)^{k+1} }{ k }.
		\end{equation}
		Ce que nous trouvons est
		\begin{equation}
			\frac{1}{ R }=\lim_{k\to \infty} | \frac{ a_{k+1} }{ a_k } |=\lim_{k\to \infty} \frac{ k }{ k+1 }=1.
		\end{equation}
		Le rayon de convergence de \( T\) est donc \( 1\). Nous avons donc que \( P_n\to T\) sur \( \mathopen] -1 , 1 \mathclose[\), et peut-être que \( P_n\to T\) en \( x=\pm 1\).

		Pour \( x=-1\). L'intuition nous dit que ce serait \( \ln(0)\) qui n'est pas défini. C'est le cas parce que
		\begin{equation}
			P_n(-1)=\sum_{k=1}^n\frac{ (-1)^{k+1}(-1)^k }{ k }=-\sum_{k=1}^n\frac{1}{ k }.
		\end{equation}
		La limite \( n\to \infty\) diverge. Donc \( T\) n'est pas définie en \( x=-1\).

		Pour \( x=1\) par contre,
		\begin{equation}
			P_n(1)=\sum_{k=1}^n\frac{ (-1)^{k+1} }{ k }.
		\end{equation}
		Le critère des séries alternées\footnote{Théorème \ref{THOooOHANooHYfkII}.} nous donne la convergence de cette série.
	\end{proof}

	Nous savons maintenant que la série de Taylor \( T\) converge sur \( \mathopen] -1 , 1 \mathclose]\), et que \( T(0)=f(0)=\ln(1)=0\). Le premier gros morceau intéressant vient maintenant : nous allons prouver que \( T(x)\) converge vers ce que nous croyons, c'est-à-dire \( \ln(1+x)\) en personne.

\begin{proposition}     \label{PROPooKPBIooJdNsqX}
	Pour tout \( x\in\mathopen] -1 , 1 \mathclose]\) nous avons
	\begin{equation}        \label{EqweEZnV}
		\ln(1+x)=\sum_{k=1}^{\infty}\frac{ (-1)^{k+1} }{ k }x^k
	\end{equation}
	De plus nous avons
	\begin{equation}    \label{EqKUQmOZ}
		\sum_{k=1}^{\infty}\frac{ (-1)^{k+1} }{ k }=\ln(2).
	\end{equation}
\end{proposition}

\begin{proof}
	Il s'agit d'utiliser l'expression du reste fourni par le théorème \ref{THOooSIGRooJTLvlV}. Pour tout \( x\in \mathopen] -1 , \infty \mathclose[\), il existe un \( c\in\mathopen] 0 , x \mathclose[\) (le \( c\) dépend de \( x\)) tel que
		\begin{equation}
			P_n(x)-f(x)=\frac{ f^{(n+1)}(c) }{ (n+1)! }x^{n+1}.
		\end{equation}
		Cela est parce que \( f\) est de classe \(  C^{\infty}\). Calculons un peu :
		\begin{subequations}
			\begin{align}
				P_n(x)-f(x) & =\frac{ f^{(n+1)}(c) }{ (n+1)! }x^{n+1}                        \\
				            & =\frac{ (-1)^nn! }{ (1+c)^{n+1} }\frac{1}{ (n+1)! }x^{n+1}     \\
				            & =\frac{ (-1)^n }{ n+1 }\left( \frac{ x }{ 1+c } \right)^{n+1}.
			\end{align}
		\end{subequations}
		Lorsque \( x>1\), il n'y a aucune garantie sur la convergence de cela pour \( n\to \infty\). Pour rappel, \( c\in\mathopen] 0 , x \mathclose[\). Si par contre \( x\in\mathopen] -1 , 1 \mathclose[\), alors nous savons que
		\begin{equation}
			\left| \frac{ x }{ 1+c } \right| <1,
		\end{equation}
		et donc convergence \( P_n(x)-f(x)\to 0\).

		Jusqu'ici nous avons prouvé que pour la série de Taylor converge vers \( \ln(1+x)\) pour \( x\in \mathopen] -1 , 1 \mathclose[\). Nous avons également vu que la série converge pour \( x=1\). Donc la fonction
		\begin{equation}
			g(x)=\sum_{k=1}^{\infty}\frac{ (-1)^{k+1} }{ k }x^k
		\end{equation}
		est continue sur \( \mathopen] -1 , 1 \mathclose]\) et égale à \( \ln(x+1)\) sur \( \mathopen] -1 , 1 \mathclose[\). Vu que \( f\colon x\mapsto \ln(x+1)\) est continue sur \( \mathopen] -1 , \infty \mathclose[\), nous avons également \( g(1)=f(1)=\ln(2)\).

	Ceci nous mène au dernier point de notre proposition : \( g(1)=\ln(2)\) s'écrit précisément
	\begin{equation}
		\sum_{k=1}^{\infty}\frac{ (-1)^{k+1} }{ k }=\ln(2).
	\end{equation}
\end{proof}

\begin{normaltext}
	La formule \eqref{EqKUQmOZ} peut sembler très chouette pour trouver des approximations de \( \ln(2)\). Le problème est qu'elle ne donne aucune idée de l'erreur commise en tronquant la série.

	Vous pouvez, certes, écrire ceci :
	\begin{equation}
		1-\frac{ 1 }{2}+\frac{1}{ 3 }-\frac{1}{ 4 }+\frac{1}{ 5 }=\frac{ 47 }{ 60 }\simeq 0.78.
	\end{equation}
	Hélas, ce calcul n'a aucune valeur pour affirmer que \( \ln(2)\) doit être proche de \( 0.78\). Ni même pour affirmer que \( \ln(2)<1\).

	Avoir des valeurs numériques de \( \ln(2)\) (c'est-à-dire que «chiffres corrects devant ou derrière la virgule») demande d'avoir un encadrement. Cela doit donc se faire avec des formules de séries avec reste; les formules exactes qui demandent de sommer jusqu'à l'inifini sont inutiles pour avoir des approximations numériques.

	Dans le cas de \( \ln(2)\), une approximation numérique sera donnée à l'aide de Taylor avec reste intégrale dans la proposition \ref{PROPooHOMYooFclkCU}.
\end{normaltext}

\begin{lemma}
	Soit la fonction\footnote{Pour la définition du logarithme, c'est la définition~\ref{DEFooELGOooGiZQjt}.}
	\begin{equation}
		f(x)=\frac{ \ln(1+x) }{ x }
	\end{equation}
	\begin{enumerate}
		\item
		      Elle admet un prolongement de classe \(  C^{\infty}\) sur \( \mathopen] -1 , \infty \mathclose[\).
		\item
		      \( f(0)=1\).
	\end{enumerate}
	La seconde condition étant évidemment avec un abus de notation entre \( f\) et son prolongement, parce que \( f\) n'est pas définie en zéro.
\end{lemma}

\begin{proof}
	La difficulté étant de voir que \( f\) a un prolongement en zéro et qu'elle y est de classe \(  C^{\infty}\).

	La proposition \ref{PROPooKPBIooJdNsqX} nous donne l'égalité
	\begin{equation}
		\ln(1+x)=\sum_{k=1}^{\infty}\frac{ (-1)^{k+1} }{ k }x^k
	\end{equation}
	pour tout \( x\in \mathopen] -1 , 1 \mathclose]\); en particulier pour \( x=0\). Nous faisons le petit calcul suivant :
	\begin{subequations}        \label{SUBEQooRLQOooEzNFDp}
		\begin{align}
			\frac{1}{ x }\ln(1+x) & = \frac{1}{ x }\sum_{n=1}^{\infty}\frac{ (-1)^{n+1} }{ n }x^n \\
			                      & =\sum_{n=1}^{\infty}\frac{ (-1)^{n+1} }{ n }x^{n-1}           \\
			                      & =\sum_{n=0}^{\infty}\frac{ (-1)^n }{ n+1 }x^n.
		\end{align}
	\end{subequations}
	Ce calcul n'est pas valable pour \( x=0\), mais ça ne nous empèche pas de poser
	\begin{equation}
		T(x)=\sum_{n=0}^{\infty}\frac{ (-1)^n }{ n+1 }x^n,
	\end{equation}
	qui, lui, est bien définie en zéro. Le rayon de convergence de la série \( T\) est égal à \( 1\), de telle sorte que
	\begin{equation}
		T\colon \mathopen] -1 , 1 \mathclose[\to \eR \\
	\end{equation}
	de classe \(  C^{\infty}\), et est égale à \( f\) sur \( \mathopen] -1 , 1 \mathclose[\setminus\{ 0 \}\).

	La série \( T\) est donc le prolongement demandé. En ce qui concerne \( f(0)\), c'est un abus pour écrire \( T(0)\) qui vaut immédiatement \( 1\).
\end{proof}

Notons qu'un calcul de limite
\begin{equation}
	\lim_{x\to 0} \frac{ \ln(1+x) }{ x }
\end{equation}
donnait la valeur \( f(0)=1\). Donc prolonger avec \( f(0)=1\) était la seule possibilité pour avoir une fonction continue. De là à dire que le prolongement ainsi créé est de classe \(  C^{\infty}\), c'est une autre histoire, qui est résolue par les séries entières.

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Développements et calcul de limites}
%---------------------------------------------------------------------------------------------------------------------------

Lors d'un calcul de limite, développer une partie d'une expression peut être utile.

\begin{example}
	À calculer :
	\begin{equation}
		\lim_{x\to 0} \frac{ \ln(1+x) }{ x }.
	\end{equation}
	Cela est une indétermination de type \( \frac{ 0 }{ 0 }\). Le développement limité du numérateur\footnote{Proposition \ref{PROPooWCUEooJudkCV}.} nous donne une fonction \( \alpha(x)\) telle que \( \lim_{x\to 0} \alpha(x)=0\) et
	\begin{equation}
		\frac{ \ln(1+x) }{ x }=\frac{ x-\frac{ x^2 }{2}+x^2\alpha(x) }{ x }=1-\frac{ x }{ 2 }+x\alpha(x).
	\end{equation}
	Sur le membre de droite la limite est facile à calculer :
	\begin{equation}
		\lim_{x\to 0} \frac{ \ln(1+x) }{ x }=\lim_{x\to 0} \Big( 1-\frac{ x }{ 2 }+x\alpha(x) \Big) =1.
	\end{equation}
\end{example}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Une petite intégrale}
%---------------------------------------------------------------------------------------------------------------------------

\begin{example}     \label{EXooNIOZooWxciAC}
	Soit \( V\) la région trapézoïdale de sommets \( (0,-1)\), \( (1,0)\), \( (2,0)\), \( (0,-2)\), comme à la figure~\ref{LabelFigZTTooXtHkcissLabelSubFigZTTooXtHkci0}. Calculons ensemble l'intégrale double
	\[
		\int_{V}e^{\frac{x+y}{x-y}}\,dV,
	\]
	avec le changement de variable\footnote{Théorème \ref{THOooUMIWooZUtUSg}.} \( \psi(x,y)=(x+y,x-y)\). C'est-à-dire que nous considérons les nouvelles variables
	\begin{subequations}
		\begin{numcases}{}
			u=x+y\\
			v=x-y.
		\end{numcases}
	\end{subequations}
	Il faut remarquer d'abord que le changement de variable proposé est dans le mauvais sens. On écrit alors \( \phi(u,v)=\psi^{-1}(u,v)=\big((u+v)/2, (u-v)/2\big)\), c'est-à-dire
	\begin{subequations}
		\begin{numcases}{}
			x=\frac{ u+v }{ 2 }\\
			y=\frac{ u-v }{2}.
		\end{numcases}
	\end{subequations}
	La région qui correspond à \( V\) est \( U\), le trapèze de sommets  \( (-1,1)\), \( (1,1)\), \( (2,2)\) et \( (-2,2)\), qu'on voit sur la figure~\ref{LabelFigZTTooXtHkcissLabelSubFigZTTooXtHkci1} et qu'on décrit par
	\[
		U=\{ (u,v)\in\eR^2\,\vert\, 1\leq v\leq 2, \, -v\leq u\leq v\}.
	\]

	% Celui-ci a été supprimée le 17 juillet 2014
	%\ref{LabelFigexamplechangementvariables}
	%\newcommand{\CaptionFigexamplechangementvariables}{Avant et après le changement de variables}
	%\input{auto/pictures_tex/Fig_examplechangementvariables.pstricks}

	%The result is on figure~\ref{LabelFigZTTooXtHkci}. % From file ZTTooXtHkci
	%See also the subfigure~\ref{LabelFigZTTooXtHkcissLabelSubFigZTTooXtHkci0}
	%See also the subfigure~\ref{LabelFigZTTooXtHkcissLabelSubFigZTTooXtHkci1}
	\newcommand{\CaptionFigZTTooXtHkci}{Avant et après le changement de variables}
	\input{auto/pictures_tex/Fig_ZTTooXtHkci.pstricks}

	Le déterminant de la  matrice  jacobienne de \( \psi^{-1}\) est  \( J_{\psi^{-1}}\),
	\begin{equation}
		J_{\psi^{-1}}(u,v)= \left\vert\begin{array}{cc}
			\frac{1}{2} & \frac{1}{2}  \\
			\frac{1}{2} & -\frac{1}{2}
		\end{array}\right\vert= -\frac{1}{2}.
	\end{equation}
	On a alors, en utilisant le fait que \( F(x)=a e^{x/a}\) est une primitive de \( f(x)= e^{x/a}\) (proposition \ref{ThoKRYAooAcnTut}) ainsi que le théorème fondamental de l'analyse (théorème \ref{ThoRWXooTqHGbC}),
	\[
		\int_{V}e^{\frac{x+y}{x-y}}\,dV=\int_{U}e^{\frac{u}{v}}\,\frac{1}{2}\,dV=\int_1^2\int_{-v}^{v}e^{\frac{u}{v}}\,\frac{1}{2}\, du\,dv= \frac{3}{4}(e-e^{-1}).
	\]
\end{example}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Vitesses des puissances, de l'exponentielle et du logarithme}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Un peu de théorie}
%---------------------------------------------------------------------------------------------------------------------------

Voici une série de résultats qui lient les vitesses des polynômes, du logarithme et de l'exponentielle.

\begin{lemma}       \label{LEMooNYFVooXjFShk}
	Si \( P\) est un polynôme et si \( a>0\), alors
	\begin{equation}
		\lim_{x\to \infty}  e^{-ax}P(x)=0
	\end{equation}
\end{lemma}

\begin{proof}
	Nous prouvons par récurrence que pour tout \( n\), nous avons \(  e^{-ax}x^n\to 0\). D'abord nous écrivons\footnote{En utilisant \ref{PROPooVADRooLCLOzP}\ref{ITEMooSCJBooNVJZah}.}
	\begin{equation}
		f(x)= e^{-ax}x=\frac{ x }{  e^{ax} },
	\end{equation}
	et ensuite la règle de l'Hospital \ref{PROPooTJVCooMeUhIy} nous donne
	\begin{equation}
		\lim_{x\to \infty} \frac{ x }{  e^{ax} }=\lim_{x\to \infty} \frac{1}{ a e^{ax} }=0.
	\end{equation}

	En ce qui concerne la récurrence, c'est encore la règle de l'Hospital :
	\begin{equation}
		\lim_{x\to \infty} \frac{ x^n }{  e^{ax} }=\frac{ n }{ a }\lim_{x\to \infty} \frac{ x^{n-1} }{  e^{ax} }=0.
	\end{equation}
\end{proof}

\begin{proposition}     \label{PROPooKVIFooGdKpfP}
	Nous avons :
	\begin{enumerate}
		\item   \label{ITEMooCDSQooSIctbz}
		      Pour tout \( \alpha>0\), il existe \( N\) tel que \( \ln(n)\leq n^{\alpha}\) pour tout \( n\geq N\).
		\item       \label{ITEMooZMAWooTbDNAd}
		      Pour tout \( p>0\) et tout \( \alpha>0\), il existe \( N\) tel que
		      \begin{equation}
			      \ln(n)^p<n^{\alpha}
		      \end{equation}
		      pour tout \( n\geq N\).
		\item       \label{ITEMooBLNOooZQNTfd}
		      Pour tout \( n\geq 1\) nous avons la limite
		      \begin{equation}
			      \lim_{x\to 0^+} x^n\ln(x)=0.
		      \end{equation}
		\item       \label{ITEMooMLNMooAyJTox}
		      Nous avons
		      \begin{equation}
			      \lim_{x\to 0^+} \frac{ \ln(1-x) }{ x }=-1.
		      \end{equation}
		\item       \label{ITEMooIQEKooBionsK}
		      L'exponentielle croit plus vite que tout polynôme, et plus vite que logarithme :
		      \begin{equation}        \label{EqExpDecrtPlusVite}
			      \lim_{x\to\infty} e^{-x}(\ln x)^{n}x^{\alpha}=0
		      \end{equation}
		      pour tout \( n\) et pour tout \( \alpha\).
		\item       \label{ITEMooDUQWooNvAvmR}
		      Pour tout \( n>0\), nous avons la limite
		      \begin{equation}
			      \lim_{x\to 0^+} x^n e^{1/x}=\infty.
		      \end{equation}
	\end{enumerate}
\end{proposition}

Le point \ref{ITEMooCDSQooSIctbz} et sa généralisation \ref{ITEMooZMAWooTbDNAd} nous font dire que le logarithme croît moins vite que n'importe quel polynôme.

\begin{proof}
	En plusieurs parties.
	\begin{subproof}
		\spitem[Pour \ref{ITEMooCDSQooSIctbz}]
		En effet, nous avons, par la règle de l'Hospital (proposition~\ref{PROPooBZHTooHmyGsy}),
		\begin{equation}
			\lim_{x\to\infty} \frac{ x^{\alpha} }{ \ln(x) }=\lim_{x\to\infty} \frac{ \alpha x^{\alpha-1} }{ 1/x }=\lim_{x\to\infty} \alpha x^{\alpha}=\infty
		\end{equation}
		quand \( \alpha>0\). La dérivée du logarithme est dans la proposition \ref{ExZLMooMzYqfK}.
		\spitem[Pour \ref{ITEMooZMAWooTbDNAd}]
		Il faut prendre le \( N\) qui convient à l'item \ref{ITEMooCDSQooSIctbz} pour \( n^{\alpha/p}\). Ainsi nous avons \( \ln(n)<n^{\alpha/p}\) et donc \( \ln(n)^p\leq n^{\alpha}\).
		\spitem[Pour \ref{ITEMooBLNOooZQNTfd}]
		Lorsque \( x\neq 0\) nous avons
		\begin{equation}
			x^n\ln(x)=\frac{ \ln(x) }{ 1/x^n },
		\end{equation}
		qui est un cas \( \frac{ \infty }{ \infty }\). Nous nous en remettons à la règle de l'Hospital \ref{PROPooTJVCooMeUhIy}. D'abord nous nous assurons de la limite des dérivées :
		\begin{equation}
			\lim_{x\to 0^+} \frac{ 1/x }{ -nx^{-n-1} }=\lim_{x\to 0^+} -\frac{1}{ n }\frac{ x^{n+1} }{ x }=0.
		\end{equation}
		La règle de l'Hospital conclut à l'existence de la limite demandée et à son égalité à \( 0\).
		\spitem[Pour \ref{ITEMooMLNMooAyJTox}]
		En effet, par la règle de l'Hospital \ref{PROPooBZHTooHmyGsy},
		\begin{equation}    \label{EqGICpOX}
			\lim_{x\to 0} -\frac{ \ln(1-x) }{ x }=\lim_{x\to 0} -\frac{ \frac{ -1 }{ 1-x } }{ 1 }=\lim_{x\to 0} \frac{1}{ 1-x }=1
		\end{equation}
		\spitem[Pour \ref{ITEMooIQEKooBionsK}]
		Notons \( f_1(x)= e^{-x/2}(\ln x)^n\) et \( f_2(x)= e^{-x/2}x^{\alpha}\). Le lemme \ref{LEMooNYFVooXjFShk} donne tout de suite \( \lim_{x\to \infty} f_2(x)=0\).

		En ce qui concerne \( f_1\), l'item \ref{ITEMooZMAWooTbDNAd} nous indique que nous avons
		\begin{equation}
			f_1(x)= e^{-x/2}(\ln x)^n\leq  e^{-x/2}x
		\end{equation}
		dès que \( x\) est assez grand. Le lemme \ref{LEMooNYFVooXjFShk} nous dit alors que \( \lim_{x\to \infty} f_2(x)=0\).

		Enfin, nous avons
		\begin{equation}
			e^{-x}(\ln x)^nx^{\alpha}=f_1(x)f_2(x)
		\end{equation}
		et donc la limite demandée.
		\spitem[Pour \ref{ITEMooDUQWooNvAvmR}]
		Nous passons au logarithme :
		\begin{equation}
			\ln(x^n e^{1/x})=\ln(x^n)+\ln( e^{1/x})=n\ln(x)+\frac{1}{ x }=\frac{ n x\ln(x)+1 }{ x }.
		\end{equation}
		Grâce à la limite déjà prouvée en \ref{ITEMooBLNOooZQNTfd}, le numérateur tend vers \( 1\) lorsque \( x\to 0^+\). Donc le tout tend vers \( +\infty\). Au final,
		\begin{equation}
			\lim_{x\to 0^+} x^n e^{1/x}=\lim_{x\to 0^+}  e^{\ln(x^n e^{1/x})}=\infty.
		\end{equation}
	\end{subproof}
\end{proof}

\begin{example}     \label{EXooQNCJooFpnvnf}
	Le lemme \ref{LemLJOSooEiNtTs} a déjà prouvé la limite
	\begin{equation}
		\lim_{n\to \infty} n^{\alpha}a^n
	\end{equation}
	pour tout \( \alpha>0\) et \( a<1\).

	L'utilisation de propriétés de l'exponentielle nous permet de donner une nouvelle preuve, plus courte\footnote{C'est toujours facile de prétendre qu'une preuve est plus courte qu'une autre lorsqu'on utilise en une ligne des très gros théorèmes qui ont mis dix pages à être démontrés.}.

	Le théorème \ref{ThoRWOZooYJOGgR} et la proposition \ref{PROPooLAOWooEYvXmI} nous permettent de passer à l'exponentielle. Pour chaque \( n\) nous avons :
	\begin{equation}        \label{EqLKLQooLIlWgm}
		n^{\alpha}a^n= e^{\alpha\ln(n)+n\ln(a)}.
	\end{equation}
	Ce qui est dans l'exponentielle est
	\begin{equation}
		\alpha\ln(n)+n\ln(a)=n\big(\alpha \frac{ \ln(n) }{ n }+\ln(a) \big).
	\end{equation}
	Dans la parenthèse, \( \ln(a)<0\) et \( \frac{ \ln(n) }{ n }\to 0\). Donc ce qui est dans l'exponentielle \eqref{EqLKLQooLIlWgm} tend vers \( -\infty\) et au final l'expression demandée tend vers zéro.
\end{example}

\begin{remark}
	Vous ne pouvez pas à priori considérer l'exemple \ref{EXooQNCJooFpnvnf} comme une preuve alternative au lemme \ref{LemLJOSooEiNtTs}, parce que vous n'êtes pas sûr que dans toute la théorie permettant de définir l'exponentielle (en particulier la convergence de \( \sum_kx^k/k!\)), le lemme n'est pas utilisé\quext{Faites la vérification et dites moi si c'est bon.}.
\end{remark}

\begin{proposition}[\cite{MonCerveau}]	\label{PROPooXIROooAprBJh}
	Soient \( r>0\) et une suite \( (a_n)_{n\in \eN}\) telle que \( a_nr^n\to 0\). Alors pour tout polynôme \( P\) nous avons
	\begin{equation}
		P(n)a_nr^n\to 0.
	\end{equation}
	De même si \( a_nr^n\to \infty\), alors pour tout polynôme nous avons\footnote{En ne considérant que la queue de suite assez lointaine pour avoir dépassé toutes les racines de \( P\). D'ailleurs c'est le moment de se rappeler que \( P\) a seulement un nombre fini de racines par la proposition \ref{ThoLXTooNaUAKR}.}
	\begin{equation}
		\frac{ a_n }{ P(n) }r^n\to \infty.
	\end{equation}
	%TODOooIVKWooZkQhUP
\end{proposition}



\begin{lemma}
	La \defe{fonction de Riemann}{Riemann!fonction}
	\begin{equation}
		\zeta(x)=\sum_{n=1}^{\infty}\frac{1}{ n^x }
	\end{equation}
	est de classe \( C^{\infty}\) sur \( \mathopen] 1 , \infty \mathclose[\).
\end{lemma}

\begin{proof}
	Afin de faire le coup du compact, nous étudions la convergence uniforme de la série sur tout compact de \( ]1,\infty[\). Soit \( \epsilon>0\), et regardons ce qu'il se passe sur un compact dont le minimum\footnote{Pour rappel, un compact dans \( \eR\) a \emph{toujours} un minimum.} est \( 1+\epsilon\). Dans ce cas, \( n^x\geq n^{1+\epsilon}\), et donc \( f_n(x)=\frac{ 1 }{ n^x }\leq \frac{1}{ n^{1+\epsilon} }\). Étant donné que la série numérique \( \sum_{n=1}^{\infty}\frac{1}{ n^{1+\epsilon} }\) converge, la fonction de Riemann converge uniformément par le critère de Weierstrass (théorème \ref{ThoCritWeierstrass}). Nous avons donc convergence uniforme de la série sur tout compact de \( ]1,\infty[\), ce qui fait que \( \zeta\) est une fonction continue pour \( x>1\) par le théorème \ref{ThoSerUnifCont}.

	Nous allons à présent utiliser le théorème \ref{THOooXZQCooSRteSr} pour prouver que la fonction de Riemann est \( C^1\). Il faut donc prouver que la série des dérivées \( (n^{-x})'=-\ln(n)n^{-x}\) converge uniformément sur tout compact de \( ]1,\infty[\).

	Nous prenons encore une fois un compact \( K\) dont le minimum est \( 1+\epsilon\). D'abord, nous majorons le logarithme par un \( x^{\alpha}\) : lorsque \( n\) est assez grand, nous avons
	\begin{equation}
		\ln(n)n^{-x}\leq n^{\alpha}n^{-x};
	\end{equation}
	la proposition \ref{PROPooKVIFooGdKpfP}\ref{ITEMooCDSQooSIctbz} nous dit que pour tout \( \alpha>0\), il existe un \( n\) à partir duquel cette inégalité est valide. Étant donné que \( 1+\epsilon\) est le minimum du compact, nous pouvons encore majorer en remplaçant \( x\) par \( 1+\epsilon\) :
	\begin{equation}
		\ln(n)n^{-x}\leq \frac{1}{ n^{1+\epsilon-\alpha} }.
	\end{equation}
	Afin de pouvoir utiliser le critère de Weierstrass, nous devons nous assurer que la série \( \sum_{n=1}^{\infty} \frac{ 1 }{ n^{1+\epsilon-\alpha} } \) converge. Cela n'est vrai que si \( 1+\epsilon-\alpha > 1\), mais le choix de \( \alpha\) étant encore arbitraire, nous choisissons \( 0<\alpha<\epsilon\).

	Ainsi, la série des dérivées converge uniformément sur tout compact et nous en déduisons que cette série est bien la dérivée de la fonction de Riemann qui est \( C^1\).

	Afin de traiter les dérivées d'ordre supérieur, il faut calculer
	\begin{equation}
		(n^{-x})^{p}=(-1)^p\big( \ln(n) \big)^p n^{-x},
	\end{equation}
	et remarquer que \( \lim_{x\to\infty} x^{\alpha}/(\ln(x))^p=\infty\). Par conséquent y a encore moyen de remplacer le logarithme par un \( x^{\alpha}\). Le reste de la preuve est la même.
\end{proof}

Ici se termine la preuve de ce lemme. Nous restons cependant sur notre faim en ce qui concerne la convergence uniforme de la série sur l'ouvert \( ]1,\infty[\). En effet, nous avons prouvé la convergence uniforme sur tout compact (et cela nous a suffit pour prouver le lemme), mais nous n'avons pas prouvé que la série n'était pas uniformément convergente sur \( ]1,\infty[\) pour autant.

	Nous allons montrer qu'il n'y a pas uniforme convergence en prouvant que si \( x\) est assez proche de \( 1\), alors la suite des sommes partielles de \( \zeta(x)\) est aussi proche que l'on veut de la suite des sommes partielles de \( \sum_{n=1}^{\infty}\frac{1}{ n }\) qui, elle, diverge.

	\begin{lemma}
		Nous avons
		\begin{equation}
			\lim_{x\to 1^+}\zeta(x)=\infty
		\end{equation}
		où la limite est une limite à droite : la limite à gauche n'existe pas.
	\end{lemma}

	\begin{proof}
		Soit \( M>0\). Prouvons que \( \exists\epsilon\) tel que \( \zeta(1+\epsilon)\geq M\). D'abord, choisissons un \( k\) tel que
		\begin{equation}
			\sum_{n=1}^k\frac{1}{ n }>M,
		\end{equation}
		et choisissons un \( \epsilon\) tel que
		\begin{equation}
			\max_{n\in\{ 1,\ldots,k \}}\left|  \frac{1}{ n }-\frac{1}{ n^{1+\epsilon} }\right|<\alpha.
		\end{equation}
		Un tel choix de \( \epsilon\) est possible pour tout \( \alpha\). Maintenant, nous choisissons \( \alpha\) de façon à avoir \( k\alpha<\sigma\). Avec ça, nous avons
		\begin{equation}
			\sum_{n=1}^k\frac{1}{ n }-\sum_{n=1}^k\frac{1}{ n^{1+\epsilon} }=\sum_{n=1}^k\left( \frac{1}{ n }-\frac{1}{ n^{1+\epsilon} } \right)<k\alpha<\sigma.
		\end{equation}
		En prenant \( \sigma\) tel que \( M-\sum_{n=1}^k(1/n)<\sigma\), nous trouvons ainsi un \( \epsilon\) tel que \( \sum_{n=1}^k\frac{1}{ n^{1+\epsilon} }>M\). Cela prouve le lemme.
	\end{proof}

	Armé de ce lemme, il est maintenant aisé de prouver que la série définissant la fonction de Riemann n'est pas uniformément convergente sur \( ]1,\infty[\). Prenons la \( k\)ième somme partielle \( s_k(x)=\sum_{n=1}^k(1/n^x)\). Pour chaque \( k\), cela est une fonction bornée de \( x\) (y compris en \( x=1\)), donc \( \sup_{x\in]1,\infty[}s_k(x)=M_k\). Armé de cette majoration, nous faisons
\begin{equation}
	\| s_k-\zeta \|_{\infty}=\sup_{x\in]1,\infty[}\big( \zeta(x)-s_k(x) \big)>\sup\big( \zeta(x)-M_k \big)=\infty,
\end{equation}
il n'y a donc pas moyen que la limite de \( \| \zeta-s_k \|_{\infty}\) quand \( k\to\infty\) soit nulle. Il n'y a donc pas uniforme convergence de \( \zeta\) sur l'intervalle \( ]1,\infty[\).

\begin{proposition} \label{PropBQGBooHxNrrf}
	Pour tout polynôme \( P\) et pour tout \( a>0\) la fonction \( f(x)=P(x) e^{-ax}\) est intégrable\footnote{Définition~\ref{DefTCXooAstMYl}.} sur \( \mathopen[ 0 , \infty [\).
\end{proposition}

\begin{proof}
	Nous avons \( f(x)=P(x) e^{-ax/2} e^{-ax/2}\), et par la vitesse comparée des exponentielles et polynômes\footnote{Voir \ref{PROPooKVIFooGdKpfP} et \ref{LEMooNYFVooXjFShk}.}, pour un certain \( M>0\) nous pouvons affirmer que \( P(x) e^{-ax/2}<1\) sur \( \mathopen[ M , \infty [\). Dès lors
	\begin{equation}
		| f(x) |< e^{-ax/2},
	\end{equation}
	qui est intégrable.
\end{proof}

\begin{example}     \label{EXooAGEOooQdQkrS}
	La fonction logarithme (définition~\ref{DEFooELGOooGiZQjt}) n'est pas définie pour \( x\leq 0\). Par conséquent la fonction \( f(x)=x\ln(|x|)\) n'est pas définie en \( x=0\). Elle est bien définie pour \( x<0\) et vérifie
	\begin{equation}
		\lim_{x\to 0} x\ln(|x|)=0.
	\end{equation}
	Nous pouvons donc définir la fonction
	\begin{equation}
		\begin{aligned}
			\tilde f\colon \eR & \to \eR                                  \\
			x                  & \mapsto \begin{cases}
				                             x\ln(| x |) & \text{si } x\neq 0 \\
				                             0           & \text{si } x=0.
			                             \end{cases}
		\end{aligned}
	\end{equation}
	Contrairement à la fonction initiale \( f\), cette fonction \( \tilde f\) est définie et continue en \( 0\).

	Notez que sur le graphe de la fonction \( \tilde f\), la courbe est bien régulière en \( x=0\).
	\begin{center}
		\input{auto/pictures_tex/Fig_XJMooCQTlNL.pstricks}
	\end{center}
\end{example}


\begin{definition}			\label{DEFooFJZXooIVrzvk}
	Soient deux suites \( (a_n)\) et \( (b_n)\) dans \( \eR\). Nous disons que
	\begin{enumerate}
		\item
		      \( a_n\to \infty\) \defe{plus vite}{vitesse de convergence de suites} que \( (b_n)\) si \( \lim{n\to\infty }a_n/b_n=\infty\).
		\item
		      \( a_n\to \infty\) \defe{aussi vite}{} que \( (b_n)\) si \( \lim{n\to\infty }a_n/b_n\) existe et est finie.
		\item
		      \( a_n\to 0\) \defe{plus vite}{} que \( (b_n)\) si \( \lim{n\to\infty }a_n/b_n=0\).
		\item
		      \( a_n\to 0\) \defe{moins vite}{} que \( (b_n)\) si \( \lim{n\to\infty }a_n/b_n=\infty\).
	\end{enumerate}
\end{definition}

\begin{example}
	Deux petits exemples.
	\begin{enumerate}
		\item
		      Les suites \( a_n=n^2\) et \( b_n=n\) tendent toutes deux vers \( \infty\), mais \( (a_n)\) va plus vite parce que \( a_n/b_n=n\to \infty\).
		\item
		      Les suites \( a_n=1/n\) et \( b_n=1/n^2\) tendent toutes deux vers \( 0\), mais \( (a_n)\) va moins vite parce que \( a_n/b_n=n\to\infty\).
	\end{enumerate}
\end{example}


\begin{normaltext}
	Je vous laisse cogiter sur l'énoncé suivant : si \( A\) est un ensemble de suites tendant toutes vers \( \infty\), alors il existe une suite qui converge vers \( \infty\) plus vite que tous les éléments de \( A\).

	Lorsque \( A\) est dénombrable, à mon avis, il suffit de prendre \( x_n=\big(  \max_{i=1,\ldots,n}\{ a^{(i)}_n,2 \} \big)^2 \).

	Lorsque \( A\) n'est pas dénombrable, je ne suis pas sûr. Écrivez-moi si vous avez une idée.
\end{normaltext}

\begin{lemma}
	Si \( a_n\to \infty\), il existe une suite tendant vers \( \infty\) plus vite.
\end{lemma}

\begin{proof}
	Il suffit de prendre \( b_n=a_n^2\).
\end{proof}

\begin{lemma}
	La suite \( a_n=n!\) tend vers \( \infty\) vite que l'exponentielle \( b_n=e^n\).
\end{lemma}

\begin{proof}
	Nous devons étudier le comportement de \( n!/e^n\) lorsque \( n\) est grand. Étant donné que \( e<3\) (lemme \ref{LEMooXFAXooLVbebl}), nous avons
	\begin{equation}
		\frac{ n! }{ e^n }\geq \frac{ 1\times 2\times 3\times 4^{n-3} }{ 3^n }=\frac{ 5 }{ 3^3 }\left( \frac{ 4 }{ 3 } \right)^{n-3}.
	\end{equation}
	Et comme \( 4/3>1\) nous avons bien \( n!/e^n\to\infty\).
\end{proof}


%---------------------------------------------------------------------------------------------------------------------------
\subsection{Nombres premiers}
%---------------------------------------------------------------------------------------------------------------------------

Le théorème suivant dit que la somme des inverses des nombre premiers diverge. Cela est à comparer avec la proposition \ref{PROPooFPVZooGnsqrs} qui dit que la somme des inverses des carrés converge.
\begin{theorem} \label{ThonfVruT}
	Soit \( P\), l'ensemble des nombres premiers. Alors la somme \( \sum_{p\in P}\frac{1}{ p }\) diverge et plus précisément,
	\begin{equation}
		\sum_{\substack{p\leq x\\p\in P}}\frac{1}{ p }\geq \ln(\ln(x))-\ln(2).
	\end{equation}
\end{theorem}
\index{nombre!premier}
\index{convergence!rapidité}
\index{série!numérique}

\begin{proof}
	Nous posons
	\begin{equation}
		S_x=\{  q\leq x\text{ avec } q\text{ sans facteurs carrés} \}
	\end{equation}
	et
	\begin{equation}
		P_x=\{ p\in P\tq p\leq x \}.
	\end{equation}
	Si
	\begin{equation}
		K_x=\{  (q,m)\text{ tels que } q\text{ n'a pas de facteurs carrés et } qm^2\leq x \},
	\end{equation}
	alors nous avons
	\begin{equation}
		K_x=\bigcup_{q\in S_x}\bigcup_{m\leq \sqrt{x/q}}(q,m).
	\end{equation}
	Par définition et par le lemme~\ref{LemheKdsa} nous avons aussi
	\begin{equation}
		\{ n\leq x \}=\{ qm^2\tq (q,m)\in K_x \}.
	\end{equation}
	Tout cela pour décomposer la somme
	\begin{equation}        \label{EqpoJpuC}
		\sum_{n\leq x}\frac{1}{ n }=\sum_{q\in S_x}\sum_{m\leq\sqrt{x/q}}\frac{1}{ qm^2 }\leq \sum_{q\in S_x}\frac{1}{ q }\underbrace{\sum_{m\geq 1}\frac{1}{ m^2 }}_{=C}.
	\end{equation}
	Nous avons aussi
	\begin{subequations}
		\begin{align}
			\prod_{p\in P_x}\left( 1+\frac{1}{ p } \right) & =1+\sum_{p\in P_x}\frac{1}{ p }+\sum_{\substack{p,q\in P_x     \\p<q}}\frac{1}{ pq }+\sum_{\substack{p,q,r\in P_x\\p<q<r}}\frac{1}{ pqr }+\ldots\\
			                                               & \geq 1+\sum_{p\in P_x}\frac{1}{ p }+\sum_{\substack{p,q\in P_x \\pq\leq x}}\frac{1}{ pq }+\sum_{\substack{p,q,r\in P_x\\pqr\leq x}}\frac{1}{ pqr }+\ldots
		\end{align}
	\end{subequations}
	Les sommes sont finies. Les sommes s'étendent sur toutes les façons de prendre des produits de nombres premiers distincts de telle sorte de conserver un produit plus petit que \( x\); c'est-à-dire que les sommes se résument en une somme sur les éléments de \( S_x\) :
	\begin{equation}        \label{EqooilOz}
		\exp\left( \sum_{p\in P_x}\frac{1}{ p } \right)\geq\prod_{p\in P_x}\left( 1+\frac{1}{ p } \right)\geq \sum_{q\in S_x}\frac{1}{ q }.
	\end{equation}
	La première inégalité est simplement le fait que \( 1+u\leq e^u\) si \( u\geq 0\) (directe de la définition~\ref{ThoRWOZooYJOGgR}). Les inégalités suivantes proviennent du fait que le logarithme est une primitive de la fonction inverse (proposition~\ref{ExZLMooMzYqfK}) :
	\begin{equation}
		\ln(x)\leq \sum_{n\geq x}\int_{n}^{n+1}\frac{dt}{ t }\leq \sum_{n\geq x}\frac{1}{ n }.
	\end{equation}
	Nous prolongeons ces inégalités avec les inégalités \eqref{EqpoJpuC} et \eqref{EqooilOz} :
	\begin{equation}
		\ln(x)\leq \sum_{n\geq x}\frac{1}{ n }\leq C\sum_{q\in S_x}\frac{1}{ q }\leq C \exp\left( \sum_{p\in P_x}\frac{1}{ p } \right).
	\end{equation}
	En passant au logarithme,
	\begin{equation}
		\ln\big( \ln(x) \big)\leq\ln(C)+\sum_{p\in P_x}\frac{1}{ p }.
	\end{equation}
	Ceci montre la divergence de la série de droite. Nous cherchons maintenant une borne pour \( C\). Pour cela nous écrivons
	\begin{subequations}
		\begin{align}
			\sum_{n=1}^N\frac{1}{ n^2 } & \leq 1+\sum_{n=2}^N\frac{1}{ n(n-1) }                       \\
			                            & =1+\sum_{n=2}^N\left( \frac{1}{ n-1 }-\frac{1}{ n } \right) \\
			                            & =1+1-\frac{1}{ N }                                          \\
			                            & \leq 2.
		\end{align}
	\end{subequations}
	Donc \( C\leq 2\).
\end{proof}
Ce théorème prend une nouvelle force en considérant le théorème de Müntz~\ref{ThoAEYDdHp} qui dit qu'alors l'ensemble \( \Span\{ x^p\tq  p\text{ est premier} \}\) est dense dans les fonctions continues sur \( \mathopen[ 0 , 1 \mathclose]\) muni de la norme uniforme ou \( \| . \|_2\).

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Quelques limites}
%---------------------------------------------------------------------------------------------------------------------------

Nous voyons à présent quelques calculs de limite et de développements mettant en scène des logarithmes et exponentielles.

\begin{example}\label{compose1}
	Pour trouver le développement de la fonction \( f(x)= e^{-2x}\), il suffit d'écrire celui de \( e^t\) et de remplacer ensuite \( t\) par \( -2x\). Le développement à l'ordre \( 3\) de la fonction exponentielle est :
	\begin{equation}
		e^t=1+t+\frac{ t^2 }{2}+\frac{ t^3 }{ 6 }+t^3\alpha(t).
	\end{equation}
	Le développement de \( f(x)= e^{-2x}\) sera donc
	\begin{equation}
		f(x)=1-2x+\frac{ 4x^2 }{ 2 }-\frac{ 8x^3 }{ 6 }-8x^3\alpha(-2x).
	\end{equation}
	Donc le polynôme de degré \( 3\) partie régulière de \( g\) est :
	\begin{equation}
		1-2x+2x^2-\frac{ 4 }{ 3 }x^3,
	\end{equation}
	et la fonction reste correspondante est :
	\begin{equation}
		\alpha_g(x)=-8\alpha(-2x).
	\end{equation}
\end{example}

\begin{example}
	Nous savons les développements
	\begin{equation}
		f(x)=\ln(1+x)\sim x-\frac{ x^2 }{ 2 }+\frac{ x^3 }{ 3 }
	\end{equation}
	et
	\begin{equation}
		\sin(x)\sim x-\frac{ x^3 }{ 6 }.
	\end{equation}
	Nous obtenons le développement d'ordre \( 3\) de la fonction \( x\mapsto \ln\big( 1+\sin(x) \big)\) en écrivant
	\begin{equation}    \label{EqGXMooWKQkIL}
		\ln\big( 1+\sin(x) \big)\sim \big( x-\frac{ x^3 }{ 6 } \big)-\frac{ 1 }{2}\left( x-\frac{ x^3 }{ 6 } \right)^2+\frac{1}{ 3 }\left( x-\frac{ x^3 }{ 6 } \right)^3.
	\end{equation}
	Il s'agit maintenant de trouver les termes qui sont de degré inférieur ou égal à \( 3\).

	D'abord
	\begin{equation}
		\left( x-\frac{ x^3 }{ 6 } \right)^2=x^2-\frac{ x^4 }{ 3 }+\frac{ x^6 }{ 36 }\sim x^2
	\end{equation}
	Nous avons alors aussi
	\begin{equation}
		\left( x-\frac{ x^3 }{ 6 } \right)^6\sim x^2\left( x-\frac{ x^3 }{ 6 } \right)\sim x^3.
	\end{equation}
	En replaçant tout ça dans \eqref{EqGXMooWKQkIL} nous trouvons
	\begin{equation}
		\ln\big( 1+\sin(x) \big)\sim x-\frac{ x^2 }{2}+\frac{ x^3 }{ 6 }.
	\end{equation}
\end{example}

\begin{example}	\label{ExBCDookjljhjk}
	Calculer
	\begin{equation}\label{EqABCoolkjh}
		\lim_{x\to \infty}  e^{1/x}\sqrt{1+4x^2}-2x.
	\end{equation}
	Nous allons effectuer un développement asymptotique de la partie «difficile» de l'expression posant d'abord \( x=1/h\). Si \( f(x)=e^{1/x}\sqrt{1-4x^2}\) alors
	\begin{equation}
		g(h)=\frac{1}{|h|}e^h\sqrt{h^2+4}=\frac{1}{h}\big(  1+h+h\alpha(h) \big)\big( 2+h\beta(h) \big).
	\end{equation}
	La première parenthèse est le développement de \( e^h\) et la seconde celui de \( \sqrt{h^2+4}\). Nous nous apprêtons à faire la limite \( x\to\infty\) qui correspond à \( h\to 0^+\), nous pouvons donc supposer que \( h>0\) et omettre la valeur absolue. En effectuant le produit et en regroupant tous les termes contenant \( h^2\), \( \alpha(h)\) ou \( \beta(h)\) dans un seul terme \( h\gamma(h)\),
	\begin{equation}
		f(h)=\frac{1}{h}\big(  2+2h+h\gamma(h) \big)=\frac{2}{h}+2+\gamma(h)=2x+2+\gamma(1/x)
	\end{equation}
	où \( \gamma\) est une fonction vérifiant \( \lim_{t\to 0}\gamma(t)=0\).

	Nous sommes maintenant en mesure de calculer la limite \eqref{EqABCoolkjh} :
	\begin{equation}
		\lim_{x\to\infty}e^{1/x}\sqrt{1+x^2}-2x= \lim_{x\to \infty}\big(  2x+2+\gamma(1/x)-2x \big)=2.
	\end{equation}
\end{example}

\begin{definition}[\cite{}]	\label{DEFooYDZMooXPnGZf}
	Soit  \( \alpha \in \eC\), la \defe{série de Riemann}{série!Riemann} est
	\begin{equation}
		\sum_{k=1	}^{\infty}\frac{1}{ k^{\alpha}}.
	\end{equation}
\end{definition}


\begin{normaltext}
	Quelques trucs à propos de la série de Riemann.
	\begin{enumerate}
		\item
		      La série de Riemann est très liée aux intégrales impropres de la proposition \ref{PropBKNooPDIPUc}.
		\item
		      Nous avons un théorème de (non)-convergence lorsque \( \alpha\in \eR\) : proposition \ref{PROPooRACTooLOGyjF}.
		\item
		      Et un théorème qui traite le cas \( \alpha\in \eC\) : \ref{PROPooFPVZooGnsqrs}.
	\end{enumerate}
\end{normaltext}

\begin{proposition}[Série de Riemann\cite{BIBooWFIVooVbNnvJ}]	\label{PROPooRACTooLOGyjF}
	Soit \( \alpha\in \eR\).
	\begin{enumerate}
		\item
		      Si \( \alpha\leq 1\), alors
		      \begin{equation}
			      \sum_{k=1}^{\infty}\frac{1}{ k^{\alpha}}=\infty,
		      \end{equation}
		      et
		      \begin{equation}		\label{EQooUAXMooNLzxLh}
			      S_n\sim \frac{ n^{1-\alpha} }{ 1-\alpha }
		      \end{equation}
		\item
		      Si \( \alpha=1\), alors
		      \begin{equation}
			      \sum_{k=1}^{\infty}\frac{1}{ k^{\alpha}}=\infty,
		      \end{equation}
		      et
		      \begin{equation}
			      S_n\sim\ln(n).
		      \end{equation}
		\item
		      Si \( \alpha>0\), alors la série des \( 1/k^{\alpha}\) converge et nous avons l'encadrement
		      \begin{equation}
			      \frac{1}{ \alpha-1}\leq \sum_{k=1}^{\infty}\frac{1}{ k^{\alpha}}\leq 1+\frac{ 1 }{ \alpha-1 }.
		      \end{equation}
	\end{enumerate}
\end{proposition}

\begin{proof}
	Nous posons \( f(t)=1/t^{\alpha}\) et \( S_n=\sum_{k=1}^nf(k)\). Et maintenant nous faisons plusieurs sous-cas.
	\begin{subproof}
		\spitem[\( \alpha\leq 0\)]
		%-----------------------------------------------------------
		Nous posons \( f(t)=t^{-\alpha}\) et \( g(t)=t^{1-\alpha}/(1-\alpha)\), de telle sorte que \( f(t)=g'(t)\). Vu que \( f\) est croissante, nous avons \( f(k)\leq f(t)\leq f(k+1)\) pour tout \( t\in \mathopen[ k,k+1\mathclose]\). Cela donne l'encadrement suivant pour \( g'\) :
		\begin{equation}
			f(k)\leq g'(t)\leq f(k+1).
		\end{equation}
		Nous appliquons donc l'inégalité des accroissements finis \ref{THOooRALIooVGDcFi} à la fonction \( g\) entre \( k\) et \( k+1\) de la façon suivante :
		\begin{equation}
			f(k)\leq g(k+1)-g(k)\leq f(k+1).
		\end{equation}
		Nous sommons cela pour \( k\) entre \( 1\) et \( n\) en utilisant la somme téléscopique de la proposition \ref{PROPooQLOUooTDWfFF} :
		\begin{equation}
			\sum_{k=1}^nf(k)\leq g(n+1)-g(1)\leq \sum_{k=1}^nf(k+1).
		\end{equation}
		Nous gardons la première inégalité \( S_n\leq g(n+1)-g(1)\). Pour la seconde, nous remarquons qu'elle est valable pour tout \( n\geq 1\); nous l'écrivons pour \( n-1\) :
		\begin{equation}
			g(n)-g(1)\leq\sum_{k=1}^{n-1}f(k+1)=\sum_{k=2}^nf(k)=S_n-f(1).
		\end{equation}
		D'où l'inégalité \( S_n\geq g(n+1)-g(1) +f(1)\). Écrivons les deux :
		\begin{equation}		\label{EQooSHNRooQsznHB}
			g(n)-g(1)+f(1)\leq S_n\leq g(n+1)-g(1).
		\end{equation}
		Vu que \( g(n)\to \infty\), la première inégalité prouve que \( \sum_{k=1}^{\infty}1/k^{\alpha}=\infty\).

		En ce qui concerne l'équivalence de suites, nous divisons tous les membres de \ref{EQooSHNRooQsznHB} par \( g(n)\) :
		\begin{equation}
			\frac{ g(n)-g(1)+f(1) }{ g(n) }\leq \frac{ S_n }{ g(n) }\leq \frac{ g(n+1)-g(1) }{ g(n) }.
		\end{equation}
		Vu que \( g(n)\to \infty\) nous avons
		\begin{equation}
			\frac{ g(n)-g(1)+f(1) }{ g(n) }\to 1.
		\end{equation}
		En remplaçant les différentes fonctions par leurs valeurs, nous avons aussi
		\begin{equation}
			\frac{ g(n+1)-g(1) }{ g(n) }=\underbrace{\frac{ (n+1)^{1-\alpha} }{ n^{1-\alpha} }}_{=(\frac{ n+1 }{ n })^{1-\alpha}\to 1}-\underbrace{\frac{1}{ n^{1-\alpha}(1-\alpha)}}_{\to 0}\to 1.
		\end{equation}
		Nous avons donc bien \( S_n/g(n)\to 1\), comme demandé en \eqref{EQooUAXMooNLzxLh}.

		\spitem[\( 0<\alpha<1\)]
		%-----------------------------------------------------------
		Nous posons encore \( f(t)=t^{-\alpha}\) et \( g(t)=t^{1-\alpha}/(1-\alpha)\), et nous avons encore \( g'(t)=f(t)\). Cette fois, \( f\) est décroissante, et nous avons donc cet encadrement pour \( g'(t)\) :
		\begin{equation}
			f(k+1)\leq g'(t)\leq f(k).
		\end{equation}
		L'inégalité des accroissements finis donne
		\begin{equation}
			f(k+1)\leq g(k+1)-g(k)\leq f(k).
		\end{equation}
		Nous refaisons la somme téléscopique :
		\begin{equation}
			\sum_{k=1}^nf(k+1)\leq g(n+1)-g(1)\leq S_n.
		\end{equation}
		Nous gardons la seconde inégalité et écrivons la première avec \( n-1\), et nous trouvons l'encadrement
		\begin{equation}
			g(n+1)-g(1)\leq S_n\leq g(n)-g(1)+f(1).
		\end{equation}
		La première inégalité dit que \( S_n\to \infty\). En ce qui concerne l'équivalence de suites, nous divisons encore par \( g(n)\) et tout va bien.

		\spitem[\( \alpha=1\)]
		%-----------------------------------------------------------
		Cette fois, nous faisons un tout petit peu attention aux domaines. Vu qu'à la fin nous ne sommes intéressés à \( f\) que pour les valeurs \( k\ge 1\), nous prenons
		\begin{equation}
			\begin{aligned}
				f\colon \mathopen] 0,\infty\mathclose[ & \to \eR              \\
				t                                      & \mapsto \frac{1}{ t}
			\end{aligned}
		\end{equation}
		et
		\begin{equation}
			\begin{aligned}
				g\colon \mathopen] 0,\infty\mathclose[ & \to \eR         \\
				t                                      & \mapsto \ln(t).
			\end{aligned}
		\end{equation}
		Nous avons encore \( g'=f\) par la proposition \ref{PROPooPDJLooXphpEM}. Ensuite nous faisons comme les autres cas. Nous avons d'abord l'encadrement \( f(k+1)\leq g'(t)\leq f(k)\) pour tout \( t\in \mathopen[ k,k+1\mathclose]\), puis nous utilisons l'inégalité des accroissements finis : \( f(k+1)\leq g(k+1)-g(k)\leq f(k)\). En sommant,
		\begin{equation}
			\sum_{k+1}^nf(k+1)\leq g(n+1)-g(1)\leq S_n.
		\end{equation}
		Nous écrivons la première inégalité avec \( n_1\) pour trouver \( S_n\leq g(n)-g(1)+f(1)\). Et au final,
		\begin{equation}
			g(n+1)-g(1)\leq S_n\leq g(n)-g(1)+f(1).
		\end{equation}
		La première inégalité donne \( S_n\to \infty\). Pour l'équivalence de suites, nous disons par \( g(n)\) et nous faisons un peu de limites, en tenant compte que\footnote{En utilisant la règle de l'Hospital \ref{PROPooTJVCooMeUhIy}.}
		\begin{equation}
			\lim_{x\to \infty}\frac{ \ln(x+1) }{ \ln(x) }=\lim_{x\to 0}\frac{ 1/(x+1) }{ 1/x }=\lim_{x\to \infty}\frac{ x }{ x+1 }=1.
		\end{equation}

		\spitem[Si \( \alpha>1\)]
		%-----------------------------------------------------------
		Encore \( f(t)=t^{-\alpha}\) et \( g(t)=t^{1-\alpha}/(1-\alpha)\). Nous avons l'encadrement \( f(k+1)\leq f(t)\leq f(k)\). Nous sommes dans le même cas qu'avec \( 0<\alpha<1\) et nous arrivons aux mêmes conclusions :
		\begin{equation}
			g(n+1)-g(1)\leq S_n\leq S(n)-g(1)+f(1).
		\end{equation}
		Cette fois nous avons \( g(n)\to 0\), et donc
		\begin{equation}
			-g(1)\leq \sum_{k=1}^{\infty}\leq f(1)-g(1).
		\end{equation}
		Vu que \( S_n\) est une suite croissante et bornée, elle converge. Nous ne donnons par une valeur précise à la limite, mais l'encadrement
		\begin{equation}
			\frac{1}{ \alpha-1}\leq \sum_{k=1}^{\infty}\frac{1}{ k^{\alpha}}\leq 1+\frac{1}{ \alpha-1}.
		\end{equation}
	\end{subproof}
\end{proof}


\begin{proposition}[Série de Riemann\cite{BIBooPSDCooKLYhqi}] \label{PROPooFPVZooGnsqrs}
	Soit \( \alpha\in \eC\). Nous considérons a série de Riemann\footnote{Voir la proposition \ref{DEFooYDZMooXPnGZf}.}
	\begin{equation}        \label{EqSerRiem}
		\sum_{k=1}^\infty \frac{ 1 }{ k^{\alpha}}.
	\end{equation}
	En termes de convergence :
	\begin{enumerate}
		\item
		      Si \( \real(\alpha)>1\), alors \( S\) converge absolument.
		\item
		      Si \( \real(\alpha)<1\) alors \( S\) diverge.
	\end{enumerate}
	%TODOooAASVooOqMJeR. Prouver ça. Probablement pas difficile à partir de PROPooRACTooLOGyjF.
\end{proposition}

\begin{proposition}[\cite{MonCerveau}]	\label{PROPooKXGWooRmSxou}
	Pour tout \( z\in \eC\) nous avons
	\begin{equation}
		\sum_{m=0}^{\infty}\frac{ (-1)^m }{ (m+1)! }z^m=\frac{ 1-e^z }{ z }.
	\end{equation}
	%TODOooWBZCooTijRIi.Prouver ça.
\end{proposition}



%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Trigonométrie hyperbolique}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{definition}
	Les fonctions \defe{cosinus hyperbolique}{cosinus!hyperbolique} et \defe{sinus hyperbolique}{sinus!hyperbolique} sont les fonctions définies sur \( \eR\) par les formules suivantes :
	\begin{subequations}
		\begin{align}
			\cosh(x) & =\frac{  e^{x}+ e^{-x} }{2}  \\
			\sinh(x) & =\frac{  e^{x}- e^{-x} }{2}.
		\end{align}
	\end{subequations}
	Si vous ne vous rappelez plus la définition de \( e^x\), c'est \ref{DEFooSFDUooMNsgZY}.
\end{definition}

\begin{proposition}     \label{PROPooUNHHooIksdoJ}
	Quelques propriétés algébriques des fonctions trigonométriques hyperboliques.
	\begin{enumerate}
		\item
		      \( \cosh(-x)=\cosh(x)\)
		\item
		      \( \sinh(-x)=-\sinh(x)\)
		\item
		      \( \cosh^2(x)-\sinh^2(x)=1\)
		\item       \label{ITEMooSJBDooAiRgjj}
		      \( \cosh^2(x)+\sinh^2(x)=\cosh(2x)\)
		\item
		      \( \cosh(x)\cosh(y)+\sinh(x)\sinh(y)=\cosh(x+y)\)
		\item       \label{ITEMooOJRFooUCUaDl}
		      \( \cosh(x)\cosh(y)-\sinh(x)\sinh(y)=\cosh(x-y)\)
		\item
		      \( \cosh(x)\sinh(y)+\sinh(x)\cosh(y)=\sinh(x+y)\)
		\item
		      \( \cosh(x)\sinh(y)-\sinh(x)\cosh(y)=-\sinh(x-y)\).
	\end{enumerate}
\end{proposition}

\begin{proof}
	Si s'agit simplement de remplacer les définitions et d'utiliser les formules concernant les puissances, dont la formule \eqref{EQooEWIHooDRAQGR}.
\end{proof}

\begin{proposition}     \label{PROPooAOOHooXvLfrZ}
	Quelques propriétés analytiques des fonctions trigonométriques hyperboliques.
	\begin{enumerate}
		\item
		      \( \cosh'(x)=\sinh(x)\)
		\item
		      \( \sinh'(x)=\cosh(x)\).
		\item       \label{ITEMooZNZLooNMQFWr}
		      \( \cosh(x)\geq 1\).
	\end{enumerate}
\end{proposition}

\begin{proof}
	Pour les dérivées, il s'agit d'utiliser la dérivation de l'exponentielle, laquelle est facile par le théorème \ref{ThoRWOZooYJOGgR}\ref{ITEMooEIKKooLNoaRD}.

	Pour \ref{ITEMooZNZLooNMQFWr}, nous commençons par les \( x\geq 0\). D'abord \( \cosh(0)=1\). Ensuite \( \cosh'(x)=\sinh(x)=\frac{  e^{x}- e^{-x} }{ 2 }\). Vu que \( x> 0\) nous avons \(  e^{x}> e^{-x}>0\). Donc la dérivée de \( \cosh\) est strictement positive sur \( \mathopen] 0 , \infty \mathclose[\). La fonction y est donc partout plus grande que \( \cosh(0)=1\).

	Pour les \( x<0\), nous avons la fait que \( \cosh\) est paire.
\end{proof}

\begin{proposition}     \label{PROPooQLNYooIIOdvm}
	La fonction \( \sinh\colon \eR\to \eR\) est bijective.
\end{proposition}

\begin{proof}
	En deux parties.
	\begin{subproof}
		\spitem[Injective]
		Si \( \sinh(a)=\sinh(b)\), alors le théorème de Rolle \ref{ThoRolle} affirme qu'il existe \( c\in \mathopen] a , b \mathclose[\) tel que \( \sinh'(c)=0\). Mais la proposition \ref{PROPooAOOHooXvLfrZ} nous dit que \( \sinh'(x)=\cosh(c)\geq 1\). Donc impossible.

		\spitem[Surjective]
		Nous avons
		\begin{equation}
			\lim_{x\to -\infty} \sinh(x)=-\infty
		\end{equation}
		et
		\begin{equation}
			\lim_{x\to\infty } \sinh(x)=\infty.
		\end{equation}
		Soit \( y\in \eR\). Il existe \( m<0\) tel que \( \sinh(m)<y\) et \( M>0\) tel que \( \sinh(M)>y\). Le théorème des valeurs intermédiaires \ref{ThoValInter} nous enseigne qu'il existe \( x\in \mathopen[ m , M \mathclose]\) tel que \( \sinh(x)=y\).
	\end{subproof}
\end{proof}

\begin{proposition}[\cite{MonCerveau}]      \label{PROPooWEHGooOBqSHY}
	Soient \( a,b\in \eR\) tels que \( a^2-b^2=1\). Il existe un unique \( (x,\sigma)\in \eR\times \{ \pm1 \}\) tel que
	\begin{subequations}        \label{SUBEQSooBIYDooIBuduV}
		\begin{numcases}{}
			a=\sigma\cosh(x)\\
			b=\sinh(x).
		\end{numcases}
	\end{subequations}
\end{proposition}

\begin{proof}
	Vu que le sinus hyperbolique est une bijection\footnote{Proposition \ref{PROPooQLNYooIIOdvm}.}, il existe un unique \( x\in \eR\) tel que \( \sinh(x)=b\). Maintenant un petit calcul :
	\begin{equation}
		a^2=1+\sinh(x)^2=1+\frac{  e^{2x}+ e^{-2x}-2 }{ 4 }=\frac{  e^{2x}+ e^{-2x}+2 }{ 4 }=\cosh(x)^2.
	\end{equation}
	Vu que \( \cosh(x)^2=a^2\), il existe un unique \( \sigma\in\{ \pm1 \}\) tel que \( \sigma\cosh(x)=a\).
\end{proof}

Les représentations graphiques sont ceci :
\begin{center}
	\input{auto/pictures_tex/Fig_UNVooMsXxHa.pstricks}
\end{center}

La \defe{tangente hyperbolique}{tangente hyperbolique} est donnée par le quotient
\begin{equation}
	\tanh(x)=\frac{ \sinh(x) }{ \cosh(x) }.
\end{equation}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Séries entières de matrices}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Différentiabilité}
%---------------------------------------------------------------------------------------------------------------------------

\begin{proposition} \label{PropAMBXKgV}
	Soit \( (a_n)\) une suite dans \( \eC\) de rayon de convergence \( R\) et la fonction
	\begin{equation}
		\begin{aligned}
			f\colon \eM(n,\eC) & \to \eM(n,\eC)                    \\
			A                  & \mapsto \sum_{k=0}^{\infty}a_kA^k
		\end{aligned}
	\end{equation}
	Alors
	\begin{enumerate}
		\item
		      La différentielle de \( f\) sur \( B(0,R)\) est
		      \begin{equation}    \label{EqRDVodDa}
			      df_A(U)=\sum_{k=0}^{\infty}a_k\sum_{l=0}^{k-1}A^lUA^{k-1-l},
		      \end{equation}
		      c'est-à-dire que l'on peut différentier terme à terme. (Ici c'est \( A\) qui est dans \( B(0,R)\))
		\item
		      La convergence de la somme~\ref{EqRDVodDa} est absolue.
		\item
		      La convergence de la somme~\ref{EqRDVodDa} est normale sur tout compact.
		\item
		      La fonction \( f\) est de classe \( C^1\) sur \( B(0,R)\), c'est-à-dire que la fonction \( A\mapsto df_A\) est continue.
	\end{enumerate}
\end{proposition}
Notons que \( df_A\) n'est pas tout à fait une série entière. Cependant, en ce qui concerne les normes, c'est tout comme si ça l'était.

\begin{proof}
	Nous posons \( u_k(A)=a_kA^k\), qui est une fonction de classe \(  C^{\infty}\) et dont la différentielle est donnée par
	\begin{equation}
		(du_k)_A(U)=\Dsdd{ u_k(A+tU) }{t}{0}=a_k\Dsdd{ (A+tU)^k }{t}{0};
	\end{equation}
	en distribuant le produit nous trouvons tout un tas de termes dont seuls ceux contenant exactement une fois \( tU\) ne vont pas s'annuler. Étant donné que \( U\) et \( A\) ne commutent pas nous avons l'expression un peu moche
	\begin{equation}
		(du_k)_A(U)=\sum_{l=0}^{k-1}a_kA^lUA^{k-1-l}.
	\end{equation}
	En ce qui concerne la norme, nous regardons celle de \( (du_k)_A\) pour un \( A\) fixé; c'est-à-dire que nous en regardons la norme opérateur :
	\begin{equation}
		\| (du_k)_A \|=\sup_{\| U \|=1}\| \sum_{l=0}^{k-1}a_kA^lUA^{k-1-l} \|\leq \sum_{l=0}^{k-1}| a_k |\| A \|^{l}\| A \|^{k-1-l}\leq k| a_k |\| A \|^{k-1}.
	\end{equation}
	Pour donner la convergence nous considérons un nombre \( r\) tel que \( \| A \|<r<R\), de telle sorte que la suite \( (a_nr^n)\) soit bornée par un nombre \( M\) et que nous puissions écrire
	\begin{equation}    \label{EqTGEwhnL}
		\| (du_k)_A \|\leq k| a_k |\| A \|^{k-1}=\frac{ k| a_k |\| A \|^k }{ \| A \| }=\frac{ k| a_k | }{ \| A \| }r^k\left( \frac{ \| A \| }{ r } \right)^k\leq \frac{ M }{ \| A \| }k\left( \frac{ \| A \| }{ r } \right)^k,
	\end{equation}
	dont la série converge. Nous avons donc convergence absolue de la série
	\begin{equation}
		\sum_{k=0}^{\infty}(du_k)_A.
	\end{equation}
	Passons à la convergence normale sur tout compact. Nous nous fixons \( r<R\) et nous nous intéressons à la norme de \( du_k\) sur \( \overline{ B(0,r) }\), c'est-à-dire
	\begin{equation}
		\| du_k \|_{\infty}=\sup_{x\in\overline{ B(0,r) }}\| (du_k)_A \|.
	\end{equation}
	Vu que \( \overline{ B(0,r) }\) est compact, ce supremum est un maximum et nous pouvons noter \( A_k\) la matrice qui le réalise. Nous réalisons alors les mêmes manipulations que pour \eqref{EqTGEwhnL} :
	\begin{equation}
		\| du_k \|_{\infty}=\| (du_k)_{A_k} \|\leq k| a_k |\| A_k \|^{k-1}\leq  k| a_k |r^{k-1}=\frac{1}{ r }k| a_k |r^k.
	\end{equation}
	Nous prenons maintenant \( r<r_0<R\) et \( M\), un majorant de \( (a_nr_0^n)\), de telle sorte qu'en multipliant et divisant par \( r_0^k\),
	\begin{equation}
		\| du_k \|_{\infty}\leq \frac{ k| a_k |r_0^k }{ r }\frac{ r^k }{ r_0^k }\leq \frac{ kM }{ r }\left( \frac{ r }{ r_0 } \right)^k,
	\end{equation}
	dont la série converge. Nous avons donc convergence normale sur tout compact. Par voie de \sout{fait} conséquences nous avons continuité de la série
	\begin{equation}
		\sum_{k=0}^{\infty}(du_k)_A
	\end{equation}
	et convergence vers \( df_A\) par le théorème~\ref{ThoLDpRmXQ}.
\end{proof}

\begin{proposition} \label{PropQIIURAh}
	Si le rayon de convergence de la série \( u(A)=\sum_{k=0}^{\infty}a_kA^k\) est \( R\), alors
	\begin{enumerate}
		\item
		      elle converge normalement sur tout compact de \( B(0,R)\);
		\item
		      la fonction \( u\) y est de classe \(  C^{\infty}\).
	\end{enumerate}
\end{proposition}

\begin{proof}
	Nous posons
	\begin{equation}
		\begin{aligned}
			u_k\colon \eM(n,\eR) & \to \eM(n,\eR) \\
			A                    & \mapsto a_kA^k
		\end{aligned}
	\end{equation}
	qui est évidemment une fonction de classe \(  C^{\infty}\). Nous étudions la \( j\)\ieme\ différentielle en \( m\), pour \( k>j\) (dans une série, nous ne nous intéressons pas aux premiers termes). La \( j\)\ieme\ différentielle appliquée à \( v_1\) appliquée à \( v_2\), etc s'exprime de la façon suivante :
	\begin{equation}
		(d^ju_k)_m(v_1,\ldots, v_j)=\frac{ d  }{ d t_1 }\ldots\frac{ d  }{ d t_j }\Big( u_k(m+t_1v_1+\cdots +t_jv_j)    \Big)_{t_i=0}.
	\end{equation}
	Dans le produit \( (m+t_1v_1+\cdots +t_jv_j)^k\), seuls les termes contenant exactement une fois chacun des \( t_i\) ne s'annulera pas après avoir fait la dérivée et évalué en \( t_i=0\). Combien de termes cela fait ? Parmi les \( k\) facteurs, il faut en placer \( j\) qui ne sont pas \( m\) (cela fait \( \binom{ k }{ j }\) possibilités), et puis il faut ordonner ces \( j\) termes, cela fait encore \( j!\) possibilités. Au final,
	\begin{equation}
		\| (d^ju_k)_m \|\leq | a_k | \binom{ k }{ j }j!\| m \|^{k-j}=| a_k |P(k)\| m \|^{k-j}
	\end{equation}
	où \( P(k)=\frac{ k! }{ (k-j)! }\) est un polynôme de degré \( j\).

	Afin d'étudier la convergence normale sur tout compact de la série des \( d^ju_k\), nous considérons \( r<r_0<R\) et nous allons prouver la convergence normale sur \( \overline{ B(0,r) }\). Vu que c'est un compact, il existe une matrice \( m_k\in\overline{ B(0,r) }\) telle que
	\begin{subequations}
		\begin{align}
			\| d^ju_k \|_{\infty} & =\| (d^ju_k)_{m_k} \|                                               \\
			                      & \leq | a_k |P(k)\| m_k \|^{k-j}                                     \\
			                      & \leq | a_k |P(k)r^{k-j}                                             \\
			                      & =\frac{ | a_k |P(k) }{ r^j }r^k                                     \\
			                      & =\frac{ | a_k |r_0^kP(k) }{ r^j }\left( \frac{ r }{ r_0 } \right)^k \\
			                      & \leq \frac{ M }{ r^j }P(k)\left( \frac{ r }{ r_0 } \right)^k
		\end{align}
	\end{subequations}
	où \( M\) est un majorant de \( a_nr_0^n\). Vu que \( r/r_0<1\), la somme sur \( k\) converge et nous avons convergence normale sur tout compact de
	\begin{equation}
		d^j\sum_{k=0}^{\infty}a_kA^k=\sum_{k=0}^{\infty}d^j(a_kA^k)
	\end{equation}
	avec un peu d'abus de notation.
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Exponentielle de matrices}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{proposition} \label{PropKKdmnkD}
	Une matrice complexe est inversible si et seulement si elle est une exponentielle.

	Autrement dit :
	\begin{equation}
		\GL(n,\eC)= e^{\eM(n,\eC)}.
	\end{equation}
\end{proposition}
\index{exponentielle!de matrice}
\index{décomposition!Jordan!et exponentielle de matrice}

\begin{proof}
	Nous avons déjà prouvé dans la proposition \ref{PROPooRERRooMutKcg} que toutes les exponentielles étaient inversibles. Ici nous nous concentrons sur la réciproque.

	Soit \( A\in \GL(n,\eC)\); nous allons donner une matrice \( B\in \eM(n,\eC)\) telle que \( A=\exp(B)\). D'abord remarquons qu'il suffit de prouver le résultat pour une matrice par classe de similitude. En effet si \( A=\exp(B)\) et si \( M\) est inversible alors
	\begin{subequations}    \label{EqqACuGK}
		\begin{align}
			\exp(MBM^{-1}) & =\sum_k\frac{1}{ k! }(MBM^{-1})^k \\
			               & =\sum_k\frac{1}{ k! }MB^kM^{-1}   \\
			               & =M\exp(B)M^{-1}.
		\end{align}
	\end{subequations}
	Donc \( MAM^{-1}=\exp(MBM^{-1})\). Nous pouvons donc nous contenter de trouver un logarithme pour les blocs de Jordan. Nous supposons donc que \( A=(\mtu+N)\) avec \( N^m=0\).
	En nous inspirant de \eqref{EqweEZnV}, nous posons\footnote{Le logarithme d'un nombre n'est pas encore définit à ce moment, mais cela ne nous empêche pas de poser une définition ici pour une application des réels vers les matrices.}
	\begin{equation}
		D(t)=tN-\frac{ t^2 }{ 2 }N^2+\cdots +(-1)^m\frac{ t^{m-1} }{ m-1 }N^{m-1}
	\end{equation}
	et nous allons prouver que \(  e^{D(1)}=\mtu+N\). Notons que \( N\) étant nilpotente, cette somme ainsi que toutes celles qui viennent sont finies. Il n'y a donc pas de problèmes de convergences dans cette preuve (si ce n'est les passages des équations \eqref{EqqACuGK}).

	Nous posons \( S(t)= e^{D(t)}\) (la somme est finie), et nous avons
	\begin{equation}
		S'(t)=D'(t) e^{D(t)}
	\end{equation}
	Afin d'obtenir une expression qui donne \( S'\) en termes de \( S\), nous multiplions par \( (\mtu+tN)\) en remarquant que \( (\mtu+tN)D'(t)=N\) nous avons
	\begin{equation}
		(\mtu+tN)S'(t)=NS(t).
	\end{equation}
	En dérivant à nouveau,
	\begin{equation}    \label{EqKjccqP}
		(\mtu+tN)S''(t)=0.
	\end{equation}
	La matrice \( (\mtu+tN)\) est inversible parce que son noyau est réduit à \( \{ 0 \}\). En effet si \( (\mtu+tN)x=0\), alors \( Nx=-\frac{1}{ t }x\), ce qui est impossible parce que \( N\) est nilpotente. Ce que dit l'équation \eqref{EqKjccqP} est alors que \( S''(t)=0\). Si nous développons \( S(t)\) en puissances de \( t\) nous nous arrêtons au terme d'ordre \( 1\) et nous avons
	\begin{equation}
		S(t)=S(0)+tS'(0)=\mtu+tD'(0)=1+tN.
	\end{equation}
	En \( t=1\) nous trouvons \( S(1)=\mtu+N\). La matrice \( D(1)\) donnée est donc bien un logarithme de \( \mtu+N\).
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Diagonalisabilité d'exponentielle}
%---------------------------------------------------------------------------------------------------------------------------

\begin{proposition}[\cite{fJhCTE}]      \label{PropCOMNooIErskN}
	Si \( A\in \eM(n,\eR)\) a un polynôme caractéristique scindé, alors \( A\) est diagonalisable si et seulement si \( e^A\) est diagonalisable.
\end{proposition}
\index{décomposition!Dunford!application}
\index{exponentielle!de matrice}
\index{diagonalisable!exponentielle}

\begin{proof}
	Si \( A\) est diagonalisable, alors il existe une matrice inversible \( M\) telle que \( D=M^{-1}AM\) soit diagonale (c'est la définition~\ref{DefCNJqsmo}). Dans ce cas nous avons aussi \( (M^{-1}AM)^k=M^{-1}A^kM\) et donc \( M^{-1}e^AM=e^{M^{-1}AM}=e^D\) qui est diagonale.

	La partie difficile est donc le contraire.

	\begin{subproof}
		\spitem[Qui est diagonalisable et comment ?]
		Nous supposons que \( e^A\) est diagonalisable et nous écrivons la décomposition de Dunford (théorème~\ref{ThoRURcpW}) :
		\begin{equation}
			A=S+N
		\end{equation}
		où \( S\) est diagonalisable, \( N\) est nilpotente, \( [S,N]=0\). Nous avons besoin de prouver que \( N=0\).

		Les matrices \( A\) est \( S\) commutent; en passant au développement nous en déduisons que \( A\) et \( e^S\) commutent, puis encore en passant au développement que \( e^A\) et \( e^S\) commutent. Vu que \( S\) est diagonalisable, \( e^S\) l'est et par hypothèse \( e^A\) est également diagonalisable. Donc \( e^A\) et \( e^{-S}\) sont simultanément diagonalisables par la proposition~\ref{PropGqhAMei}.

		Étant donné que \( A\) et \( S\) commutent, nous avons \( e^N=e^{A-S}=e^Ae^{-S}\), et nous en déduisons que \( e^N\) est diagonalisable vu que les deux facteurs \( e^A\) et \( e^{-S}\) sont simultanément diagonalisables.

		\spitem[Unipotence]

		Si \( r\) est le degré de nilpotence de \( N\), nous avons
		\begin{equation}    \label{EqQHjvLZQ}
			e^N-\mtu=N+\frac{ N^2 }{2}+\cdots +\frac{ N^{r-1} }{ (r-1)! }.
		\end{equation}
		Donc
		\begin{equation}
			(e^N-\mtu)^k=\left( N+\frac{ N^2 }{2}+\cdots +\frac{ N^{r-1} }{ (r-1)! } \right)^k
		\end{equation}
		où le membre de droite est un polynôme en \( N\) dont le terme de plus bas degré est de degré \( k\). Donc \( (e^N-\mtu)\) est nilpotente et \( e^N\) est unipotente.

		Si \( M\) est la matrice qui diagonalise \( e^N\), alors la matrice diagonale \( M^{-1}e^NM\) est tout autant unipotente que \( e^N\) elle-même. En effet,
		\begin{subequations}
			\begin{align}
				(M^{-1}e^NM-\mtu)^r & =\sum_{k=0}^r\binom{ r }{ k }(-1)^{r-k}M^{-1}(e^N)^kM                \\
				                    & =M^{-1}\left( \sum_{k=0}^r\binom{ r }{ k }(-1)^{r-k}(e^N)^k \right)M \\
				                    & =M^{-1}(e^N-\mtu)^rM                                                 \\
				                    & =0.
			\end{align}
		\end{subequations}

		La matrice \( M^{-1}e^NM\) est donc une matrice diagonale et unipotente; donc \( M^{-1}e^NM=\mtu\), ce qui donne immédiatement que \( e^N=\mtu\).

		\spitem[Polynômes annulateurs]

		En reprenant le développement \eqref{EqQHjvLZQ} sachant que \( e^N=\mtu\), nous savons que
		\begin{equation}
			N+\frac{ N^2 }{2}+\cdots +\frac{ N^{r-1} }{ (r-1)! }=0.
		\end{equation}
		Dit en termes pompeux (mais non moins porteurs de sens), le polynôme
		\begin{equation}
			Q(X)=X+\frac{ X^2 }{2}+\cdots +\frac{ X^{r-1} }{ (r-1)! }
		\end{equation}
		est un polynôme annulateur de \( N\).

		La proposition~\ref{PropAnnncEcCxj} stipule que le polynôme minimal d'un endomorphisme divise tous les polynômes annulateurs. Dans notre cas, \( X^r\) est un polynôme annulateur et donc le polynôme minimal de \( N\) est de la forme \( X^k\). Donc il est \( X^r\) lui-même.

		Nous avons donc \( X^r\divides Q\). Mais \( Q\) est un polynôme contenant le monôme \( X\) donc \( X^r\) ne peut diviser \( Q\) que si \( r=1\). Nous en concluons que \( X\) est un polynôme annulateur de \( N\). C'est-à-dire que \( N=0\).

		\spitem[Conclusion]

		Vu que Dunford\footnote{Théorème~\ref{ThoRURcpW}.} dit que \( A=S+N\) et que nous venons de prouver que \( N=0\), nous concluons que \( A=S\) avec \( S\) diagonalisable.

	\end{subproof}
\end{proof}
