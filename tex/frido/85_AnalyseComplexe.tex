% This is part of Mes notes de mathématique
% Copyright (c) 2012-2013,2016-2019, 2021
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Singularités, pôles et méromorphe}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{definition}      \label{DEFooKWDUooVPvtpy}
    Si \( f\) est holomorphe\footnote{Définition \ref{DefMMpjJZ}.} sur un ouvert \( \Omega\), alors une \defe{singularité}{singularité} de \( f\) est un point isolé du bord de \( \Omega\).

    \begin{enumerate}
        \item
            La singularité est \defe{effaçable}{singularité effaçable} si la fonction \( f\) s'y prolonge en une fonction holomorphe.
        \item
            La singularité \( a\) est \defe{isolée}{singularité isolée} si \( f\) est holomorphe sur \( B(a,r)\setminus\{ a \}\).
    \end{enumerate}
\end{definition}


\begin{definition}[pôle d'une fonction\cite{MonCerveau,frwiki155205828}]    \label{DEFooUIJTooUJPiDG}
    Soient un ouvert \( \Omega\) de \( \eC\) ainsi que \( a\in \Omega\). La fonction \( f\colon \Omega\setminus\{ a \}\to \eC\) a un \defe{pôle d'ordre \( n\)}{pôle} en \( a\) si il existe \( r>0\) et une fonction holomorphe $g\colon B(a,r)\to \eC$ telle que
    \begin{enumerate}
        \item
            \( g(a)\neq 0\)
        \item
            pour tout \( z\in B(a,r)\setminus\{ a \}\) nous avons
            \begin{equation}
                f(z)=\frac{ g(z) }{ (z-a)^n }.
            \end{equation}
    \end{enumerate}
\end{definition}

\begin{lemma}
    Soit \( n\in \eN\). Nous notons \( \gU_n\) l'ensemble des racines \( n\)\ieme\ de l'unité\footnote{Voir la définition \ref{DEFooDUWPooZaAByH} et le lemme \ref{LEMooSXFBooYJmRTK}.} dans \( \eC\). La fonction
    \begin{equation}
        \begin{aligned}
            f\colon \eC\setminus\gU_n&\to \eC \\
            z&\mapsto \frac{1}{ z^n-1 } 
        \end{aligned}
    \end{equation}
    est holomorphe et possède un pôle d'ordre \( 1\) en chaque point de \( \gU_n\).
\end{lemma}

\begin{proof}
    Le fait que \( f\) soit holomorphe est simplement le fait que sur le domaine, le dénominateur est un bête polynôme qui ne s'annule pas. 

    Nous énumérons \( \gU_n = \{ \xi_i \}_{i=1,\ldots, n}\). Prouvons que \( \xi_k\) est un pôle d'ordre \( 1\) de \( f\). La première égalité du lemme \ref{LemKYGBooAwpOHD} donne \( z^n-1=\prod_i(z-\xi_i)\). D'abord nous considérons \( r>0\) tel que \( B(\xi_k,r)\cap \gU_n=\{ \xi_k \}\).

    Nous posons
    \begin{equation}
        \begin{aligned}
            g_k\colon B(\xi_k,r)\setminus\{ \xi_k \}&\to \eC \\
            z&\mapsto \frac{1}{ \prod_{i\neq k}(z-\xi_i) }. 
        \end{aligned}
    \end{equation}
    Cela est bien une fonction holomorphe et nous avons 
    \begin{equation}
        f(z)=\frac{ g_k(z) }{ (z-\xi_k) }.
    \end{equation}
\end{proof}

\begin{example}
    La fonction
    \begin{equation}
        z\mapsto \frac{ \sin(z) }{ z }
    \end{equation}
    n'est pas définie en \( z=0\), mais elle s'y prolonge en une fonction continue en posant \( f(0)=1\).
\end{example}
%TODO : dans \eC je ne sais pas si c'est facile à montrer. De toutes façons, il faudrait déjà définir le sinus.

\begin{proposition}
    Une singularité de \( f\) est un pôle si et seulement si
    \begin{equation}
        \lim_{z\to Z}f(z)=\infty.
    \end{equation}
\end{proposition}

Le théorème suivant complète la proposition~\ref{PropDRnYkKP}.
\begin{theorem}[Prolongement de Riemann\cite{BIBooZMRPooRygeHT}]    \label{ThoTLQOEwW}
    Soient un ouvert \( \Omega\subset \eC\), un point \( a\in \Omega \) et une fonction holomorphe \( f\colon \Omega\setminus\{ a \}\to \eC\). Nous supposons que \( a\) est une singularité\footnote{Singularité et singularité effaçable : définition \ref{DEFooKWDUooVPvtpy}.} de \( f\). Les points suivants sont équivalents.
    \begin{enumerate}
        \item       \label{ITEMooMLXJooMfuifN}
            la singularité \( a\) est effaçable;
        \item       \label{ITEMooBWPEooEltHAa}
            \( f\) possède un prolongement continu en \( a\);
        \item       \label{ITEMooEAUOooIWcxHS}
            il existe un voisinage épointé de \( a\) sur lequel \( f\) est bornée;
        \item       \label{ITEMooETRWooDTTpxs}
            \( \lim_{z\to a}(z-a)f(z)=0\).
    \end{enumerate}
\end{theorem}
\index{théorème!prolongement de Riemann}

\begin{proof}
    En plusieurs implications.
    \begin{subproof}
        \item[\ref{ITEMooMLXJooMfuifN} implique \ref{ITEMooBWPEooEltHAa}]
            La fonction \( f\) admet même un prolongement holomorphe.
        \item[\ref{ITEMooBWPEooEltHAa} implique \ref{ITEMooEAUOooIWcxHS}]
            Soit un prolongement continu \( \tilde f\colon B(a,r)\to \eC\) de \( f\). La restriction \( \tilde f\colon \overline{ B(a,r/2) }\to \eC\) est continue sur un compact et donc bornée\footnote{Théorème \ref{ThoWeirstrassRn}.} tout en étant égale à \( f\) sur \( B(a,r/2)\setminus\{ a \}\).
        \item[\ref{ITEMooEAUOooIWcxHS} implique \ref{ITEMooETRWooDTTpxs} dans le cas \( a=0\)]
            Nous supposons que \( f\colon B(a,r)\setminus\{ a \}\to \eC\) est bornée. Disons \( | f(z) |<A\). Alors pour tout \( z\in B(a,r)\setminus\{ a \}\) nous avons
            \begin{equation}
                | (z-a)f(a) |\leq A| z-a |
            \end{equation}
            Or $\lim_{z\to a}A(z-a)$ existe et vaut zéro. Donc \( \lim_{z\to a}| (z-a)f(z) |\) existe et vaut également zéro.
        \item[\ref{ITEMooETRWooDTTpxs} implique \ref{ITEMooMLXJooMfuifN}]
            Nous commençons par supposer que \( a=0\), et nous posons \( D=B(0,r)\setminus\{ 0 \}\). La fonction \( f\colon D\to \eC\) est holomorphe et vérifie \( \lim_{z\to 0}zf(z)=0\).

            Nous considérons la fonction suivante :
            \begin{equation}
                \begin{aligned}
                    g\colon B(0,r)&\to \eC \\
                    z&\mapsto \begin{cases}
                        0    &   \text{si } z=0\\
                        z^2f(z)    &    \text{sinon. }
                    \end{cases}
                \end{aligned}
            \end{equation}
            La fonction \( g\) est holomorphe sur \( D\) parce que \( f\) l'est. Voyons que \( g\) est dérivable en zéro. Pour tout \( z\) sur un voisinage,
            \begin{equation}
                \frac{ g(z)-g(0) }{ z }=\frac{ z^2f(z) }{ z }=zf(z).
            \end{equation}
            Or par hypothèse \( \lim_{z\to 0}zf(z)=0\) donc \( g'(0)=0\), et \( g\) est holomorphe en \( 0\) (c'est la définition \ref{DefMMpjJZ} d'une fonction holomorphe). Bref, \( g\) est holomorphe sur \( B(0,r)\).

            Nous pouvons donc développer \( g\) en série entière\footnote{Théorème \ref{ThomcPOdd}.} dans un voisinage \( B(0,r)\) :
            \begin{equation}
                g(z)=\sum_{n=0}^{\infty}a_nz^n.
            \end{equation}
            En utilisant le \ref{CORooJISDooFgwOPh}, \( a_0=g(0)=0\) et \( a_1=g'(0)=0\). Donc en réalité
            \begin{equation}
                g(z)=\sum_{n=2}^{\infty}a_nz^n.
            \end{equation}

            Considérons la série entière
            \begin{equation}
                \sum_{n=0}^{\infty}b_nz^n
            \end{equation}
            avec \( b_n=a_{n+2}\). Le lemme \ref{LEMooVCTNooCQHkzs} dit que son rayon de convergence est le même que celui de \( g\). Donc la fonction
            \begin{equation}
                \begin{aligned}
                    h\colon B(0,r)&\to \eC \\
                    z&\mapsto \sum_{n=2}^{\infty}a_nz^{n-2} 
                \end{aligned}
            \end{equation}
            est holomorphe.
            
            Par ailleurs, sur la partie \( D\) (qui ne contient pas \( z=0\)) nous pouvons écrire
            \begin{equation}
                f(z)=\frac{ g(z) }{ z^2 }
            \end{equation}
            et donc
            \begin{equation}
                f(z)=\sum_{n=2}^{\infty}a_nz^{n-2}.
            \end{equation}
            Autrement dit \( f=h\) sur \( D\), et \( h\) en est un prolongement holomorphe.
        \item[\ref{ITEMooEAUOooIWcxHS} implique \ref{ITEMooETRWooDTTpxs} dans le cas \( a\neq 0\)]
            Nous posons \( g(z)=f(z+a)\). Nous avons
            \begin{equation}
                \lim_{z\to 0}zg(z)=\lim_{z\to 0}zf(z+a)=\lim_{z\to a}(z-a)f(z)=0.
            \end{equation}
            Le changement de variable dans la limite est le lemme \ref{LEMooAHIGooJhpPvo}. Donc le premier cas s'applique à \( g\) et nous avons un prolongement holomorphe \( \tilde g\colon B(0,r)\to \eC\) de \( g\). La fonction donnée par \( \tilde f(z)=g(z-a)\) prolonge \( f\).
    \end{subproof}
\end{proof}

\begin{definition}[Fonction méromorphe\cite{ooBBIEooFYzkzz}]
    Soient \( \mU\) un ouvert de \( \eC\) et \( \{ p_i \}\) une suite de points dans \( \mU\) sans points d'accumulation (éventuellement il y a un nombre fini de \( p_i\)). Si la fonction \( f\) est holomorphe sur \( \mU\setminus\{ p_i \}\) et si chaque \( p_i\) est un point régulier ou un pôle de \( f\), alors nous disons que \( f\) est \defe{méromorphe}{méromorphe} sur \( \mU\).
\end{definition}

\begin{proposition} \label{PropPUZTQKl}
    Soient \( \Omega\) un ouvert de \( \eC\) et \( f_n\colon \Omega\to \eC\) une suite de fonctions telles que pour tout compact \( K\) de \( \Omega\) il existe \( N_K\geq 0\) tel que
    \begin{enumerate}
        \item
            \( f_n\) n'a pas de pôle dans \( K\) dès que \( n\geq N_K\);
        \item
            la série \( \sum_{n\geq N_K}f_n\) converge uniformément sur \( K\).
    \end{enumerate}
    Alors
    \begin{enumerate}
        \item
            La fonction
            \begin{equation}
                f(z)=\sum_{n=0}^{\infty}f_n(z)
            \end{equation}
            est méromorphe sur \( \Omega\) et ses pôles sont l'union de ceux des \( f_n\).
        \item
            Nous pouvons permuter la somme et la dérivée :
            \begin{equation}
                f'(z)=\sum_{n=0}^{\infty}f'_n(z).
            \end{equation}
    \end{enumerate}
\end{proposition}

\begin{theorem}[Série de Laurent]       \label{THOooMKJOooVghZyG}
    Soient \( C\) une couronne de rayons \( r_1<r_2\) centrée en zéro et une fonction \( f\) holomorphe dans cette couronne. Alors nous avons la \defe{série de Laurent}{série!de Laurent}
    \begin{equation}
        f(z)=\sum_{n\in \eZ}a_nz^n.
    \end{equation}
    \begin{enumerate}
        \item
            Cette série converge uniformément sur tout compact de \( C\).
        \item
            Les coefficients sont donnés par
            \begin{equation}
                a_n=\frac{1}{ 2\pi i }\int_{\gamma}\frac{ f(z) }{ z^{n+1} }dz
            \end{equation}
            où \( \gamma\) est un cercle centré en zéro.
        \item
            Ce développement en série est unique.
        \item
            La valeur des \( a_n\) ne dépend pas du choix du rayon du cercle \( \gamma\).
    \end{enumerate}
\end{theorem}

\begin{probleme}
    L'énoncé de la proposition \ref{PROPooBMZGooLoaGLK} n'est peut-être pas précis.
\end{probleme}

\begin{proposition}     \label{PROPooBMZGooLoaGLK}
    Si \( f\) est holomorphe sur \( B(a,r)\), alors sa série de Laurent est de la forme
    \begin{equation}
        f(z)=\sum_{n=0}^{\infty}a_n(z-a)^n.
    \end{equation}
\end{proposition}


%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Dénombrement des solutions d'une équation diophantienne}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Le théorème \ref{THOooQDYWooCOiUMb} peut être vu soit comme un dénombrement de solutions d'une certaine équation diophantienne, soit comme partition d'un entier en parts fixées. Avant de nous lancer dans sa démonstration, nous prouvons un certain nombre de lemmes qui vont traiter des aspects combinatoires de la preuve.

Soit \( n,N\in \eN\). Soit \( a\in \eN^N\). Nous considérons les ensembles suivants :
\begin{subequations}
    \begin{align}
    V_n(N)&=\{ x\in \eN^N\tq \sum_{i=1}^Nx_i=n \}, \\
    W_n(a,N)&=\{ y\in \eN^N\tq y\cdot a=n \},\\
    V_n(N)_a&=\{ x\in V_n(N)\tq a_i\divides x_i\,\forall i=1,\ldots, N \}.
    \end{align}
\end{subequations}
L'ensemble \( V_n(N)\) avait déjà été rencontré en \eqref{EQooJCBSooMSbaCd}.

\begin{lemma}       \label{LEMooLKCAooCeDnSj}
    L'application
    \begin{equation}
        \begin{aligned}
            \psi\colon W_n(a,N)&\to V_n(N)_a \\
            (y_1,\ldots, y_N)&\mapsto (y_1a_1,\ldots, y_Na_N) 
        \end{aligned}
    \end{equation}
    \begin{enumerate}
        \item       
            est bien définie, c'est à dire qu'elle prend effectivement ses valeurs dans \( V_n(N)_a\),
        \item
            est une bijection.
    \end{enumerate}
\end{lemma}

\begin{proof}
    En plusieurs parties.
    \begin{subproof}
        \item[Bien définie]
            Soit \( y\in W_n(a,N)\). Nous avons \( \psi(y)_i=a_iy_i\). Le nombre \( a_i\) divise donc bien \( \psi(y)_i\) et \( \sum_{i=1}^N\psi(y)_i=n\).
        \item[Injective]
            Si \( \psi(y)=\psi(y')\), alors pour tout \( i\) nous avons \( y_ia_i=y'_ia_i\), et donc \( y_i=y'_i\). La fonction \( \psi\) est donc bien injective.
        \item[Surjective]
            Soit \( x\in V_n(N)_a\). Vu que \( a_i\divides x_i\), il existe \( y_i\in \eN\) tel que \( x_i=a_iy_i\). On vérifie que \( y\in W_n(a,N)\) et que \( \psi(y)=x\).
    \end{subproof}
\end{proof}


\begin{lemma}       \label{LEMooOPXHooHzoHrm}
    Pour \( i=1,\ldots, N\), nous posons
    \begin{equation}
        \begin{aligned}
            b_i\colon \eN^N&\to \{ 0,1 \} \\
            x&\mapsto \begin{cases}
                1    &   \text{si } a_i\divides x_i\\
                0    &    \text{sinon. }
            \end{cases}
        \end{aligned}
    \end{equation}
    Nous avons
    \begin{equation}
        \sum_{x\in V_n(N)}\prod_{i=1}^Nb_i(x)=\Card\big( W_n(a,N) \big).
    \end{equation}
\end{lemma}

\begin{proof}
    Nous décomposons la somme en \( V_n(N)_a\) et son complémentaire dans \( V_n(N)\) :
    \begin{subequations}
        \begin{align}
        \sum_{x\in V_n(N)}\prod_{i=1}^Nb_i(x)&=\sum_{x\in V_n(N)_a}\prod_{i=1}^Nb_i(x)+\sum_{x\in V_n(N)\setminus V_n(N)_a}\prod_{i=1}^Nb_i(x)\\
        &=\sum_{x\in V_n(N)_a}1+\sum_{x\in V_n(N)\setminus V_n(N)_a}0       \label{SUBEQooLMBGooIfxjgy}\\
        &=\Card\big( V_n(N)_a \big) \\
        &=\Card\big( W_n(N,a) \big)     \label{SUBEQooBBOIooBHDgYF}
        \end{align}
    \end{subequations}
    Justifications :
    \begin{itemize}
        \item Pour \eqref{SUBEQooLMBGooIfxjgy}.
    Si \( x\in V_n(N)_a\), alors \( a_i\divides x_i\) pour tout \( i\), et donc \( b_i(x)=1\) pour tout \( i\). Si au contraire \( x\in V_n(N)\setminus V_n(N)_a\), il existe un \( i\) tel que \( a_i\) ne divise pas \( x_i\) et donc tel que \( b_i(x)=0\).
\item Pour \eqref{SUBEQooBBOIooBHDgYF}. Les deux ensembles sont en bijection par le lemme \ref{LEMooLKCAooCeDnSj}.
    \end{itemize}
\end{proof}

\begin{lemma}       \label{LEMooRJOKooPJGVTr}
    Soit \( s\geq 1\). La série entière
    \begin{equation}
        \sum_{n=0}^{\infty}z^{ns}
    \end{equation}
    a un rayon de convergence égal à \( 1\). Pour \(z\in B(0,1)\) nous avons
    \begin{equation}        \label{EQooIRAZooKQoZnp}
        \sum_{n=0}^{\infty}z^{ns}=\frac{1}{ 1-z^s }.
    \end{equation}
\end{lemma}

\begin{proof}
    Pour un \( z\in \eC\) fixé, nous avons \( z^{ns}=(z^s)^n\)\footnote{Vu qu'ici \( n\) et \( s\) sont entiers, c'est pas profond ça. Il ne faut pas invoquer la proposition générale \ref{PROPooDWZKooNwXsdV}.}. Nous appelons donc la proposition \ref{PROPooWOWQooWbzukS} avec \( q=z^s\).

    Si \( | z |<1\), alors \( | z^s |<1\) et la proposition \ref{PROPooWOWQooWbzukS} nous dit que la série converge. Si au contraire \( | z |>1\), alors \( | z^s |>1\) et la série diverge.

    Le corollaire \ref{CORooCUDSooTfMvAB} conclu que le rayon de convergence est bien \( 1\).

    La valeur \eqref{EQooIRAZooKQoZnp} est également une partie de la proposition \ref{PROPooWOWQooWbzukS}.
\end{proof}


\begin{lemma}       \label{LEMooVMLEooCzPuKy}
    Si \( a,b\in \eC\), si \( N\in \eN\) et si \( p\in \eN\) avec \( p<N\), nous posons
    \begin{equation}
        a_n=a\frac{ (n+N-1)! }{ n! }
    \end{equation}
    et 
    \begin{equation}
        b_n=b\frac{ (n+p-1)! }{ n! }.
    \end{equation}
    Nous avons \( a_n\sim a_n+b_n\).
\end{lemma}

\begin{proof}
    Nous posons \( \alpha(n)=(a_n+b_n)/a_n\) et nous prouvons que \( \lim_{n\to \infty} \alpha(n)=1\). Pour ce faire,
    \begin{subequations}
        \begin{align}
        \frac{ b_n }{ a_n }&=\frac{ b }{ a }\frac{ (n+p-1)! }{ n! }\frac{ n! }{ (n+N-1)! }\\
        &=\frac{ b }{ a }\frac{ (n+p-1)! }{ (n+N-1)! }\\
        &=\frac{ b }{ a }\frac{ (n+p-1)! }{ (n+p-1)!\prod_{k=n+p}^{n+N-1}k }\\
        &=\frac{ b }{ a }\prod_{k=n+p}^{n+N-1}\frac{1}{ k }\\
        &\leq \frac{ b }{ a }\frac{1}{ n+p },
        \end{align}
    \end{subequations}
    et nous avons
    \begin{equation}
        \lim_{n\to \infty} \frac{ b_n }{ a_n }=0, 
    \end{equation}
    de telle sorte que \( \lim_{n\to \infty} \alpha(n)=1\).
\end{proof}

\begin{lemma}       \label{LEMooTGHHooZHZsgE}
    Si \( N\in \eN\), nous avons équivalence des suites
    \begin{equation}
        \frac{ (n+N-1)! }{ n! }\sim n^{N-1}.
    \end{equation}
\end{lemma}

\begin{proof}
    Sachez que dans \( \prod_{i=a}^b\), il y a \( b-a+1\) facteurs, et non \( b-a\) comme on pourrait naïvement le croire. Cela dit, nous avons le calcul
    \begin{subequations}
        \begin{align}
            \frac{ (n+N-1)! }{ n!n^{N-1} }&=\left( \prod_{k=n+1}^{n+N-1}k \right)\frac{1}{ n^{N-1} }\\
            &=\prod_{k=n+1}^{n+N-1}\frac{ k }{ n }\\
            &=\prod_{k=1}^{N-1}\frac{ n+k }{ n }.
        \end{align}
    \end{subequations}
    Donc la limite
    \begin{equation}
        \lim_{n\to \infty} \frac{ (n+N-1)! }{ n!n^{N-1} }=1.
    \end{equation}
\end{proof}

\begin{theorem}[\cite{MonCerveau,fJhCTE,NHXUsTa,BIBooLIDJooYWosFk,KXjFWKA}] \label{THOooQDYWooCOiUMb}
    Soient \( N\in \eN\) et \( a\in \eN^N\) tel que \( \pgcd(a_1,\ldots, a_{N})=1\). Nous posons
    \begin{equation}
        W_n(a,N)=\{ y\in \eN^N\tq y\cdot a=n \}.
    \end{equation}
    Nous avons alors\footnote{Équivalence de suites, définition \ref{DEFooEWRTooKgShmT}.}
    \begin{equation}
        \Card\big( W_n(a,N) \big)\sim\frac{1}{ \prod_{k=1}^Na_k }\frac{ n^{N-1} }{ (N-1)! }.
    \end{equation}
\end{theorem}

\begin{proof}
    Pour chaque \( i=1,\ldots, N\), nous considérons la série entière
    \begin{equation}
        s_i(z)=\sum_{k=0}^{\infty}z^{ka_i}.
    \end{equation}
    dont le rayon de convergence vaut \( 1\) par le lemme \ref{LEMooRJOKooPJGVTr}. Nous nous apprêtons à faire le produit de Cauchy multiple de la proposition \ref{PROPooJPVVooLqSdSn}; nous posons donc
    \begin{equation}
        b_{ik}=\begin{cases}
            1    &   \text{si } a_i|k\\
            0    &    \text{sinon },
        \end{cases}
    \end{equation}
    et nous écrivons toutes les séries \( s_i\) sous la forme
    \begin{equation}
        s_i(z)=\sum_{k=0}^{\infty}b_{ik}z^k.
    \end{equation}
    La proposition \ref{PROPooJPVVooLqSdSn} nous assure que si \( | z |<1\), le produit \( \prod_{i=1}^Ns_i(z)\) peut être écrit sous la forme de la série entière
    \begin{subequations}        \label{SUBEQooYESHooChEKGm}
        \begin{align}
            \prod_{i=1}^Ns_i(z)&=\sum_{s=0}^{\infty}\left( \sum_{x\in V_s(N)}\prod_{i=1}^Nb_{ix_i} \right)z^s\\
            &=\sum_{s=0}^{\infty}\left( \sum_{x\in V_s(N)}\prod_{i=1}^Nb_i(x) \right)z^s        \label{SUBEQooEEHKooPSrpiT} \\
            &=\sum_{s=0}^{\infty}\Card\big( W_s(a,N) \big)z^s       \label{SUBEQooULBCooSTuHvy}
        \end{align}
    \end{subequations}
    Justifications :
    \begin{itemize}
        \item Pour \eqref{SUBEQooEEHKooPSrpiT}. Notation \( b_i\) du lemme \ref{LEMooOPXHooHzoHrm}.
        \item Pour \eqref{SUBEQooULBCooSTuHvy}. Utilisation du lemme \ref{LEMooOPXHooHzoHrm}
    \end{itemize}
    
    D'autre part, le lemme \ref{LEMooRJOKooPJGVTr} nous permet d'écrire
    \begin{equation}
        f(z)=\prod_{i=1}^Ns_i(z)=\prod_{i=1}^N\frac{1}{ 1-z^{a_i} }.
    \end{equation}
    Notre but sera d'écrire ce produit sous forme de série entière est d'identifier les coefficients avec ceux que l'on trouve dans \eqref{SUBEQooULBCooSTuHvy}.

    \begin{subproof}
    \item[\( m_{\omega}=N\) si et seulement si \( \omega^{a_i}=1\)]
    Nous montrons à présent que \( \omega\) est un pôle d'ordre \( N\) de \( f\) si et seulement si \( \omega^{a_1}=\ldots=\omega^{a_N}=1\).
    \begin{subproof}
    \item[Un polynôme]
        Nous considérons le polynôme
        \begin{equation}
            P(X)=\prod_{i=1}^N(1-X^{a_i})=\prod_{i=1}^N\prod_{\omega\in \gU_{a_i}}(X-\omega)
        \end{equation}
        où, pour la seconde égalité, nous avons utilisé le lemme \ref{LemKYGBooAwpOHD}. En posans \( \gU=\bigcup_{i=1}^N\gU_{a_i}\) nous écrivons encore
        \begin{equation}
            P(X)=\prod_{\omega\in \gU}(X-\omega)^{m_{\omega}}
        \end{equation}
        où \( m_{\omega}=\Card\{ i\tq \omega\in \gU_{a_i} \}\). Cela pour dire que, pour \( | z |<1\),
        \begin{equation}
            f(z)=\frac{1}{ P(z) }=\frac{1}{ \prod_{\omega\in \gU} (X-\omega)^{m_{\omega}}}.
        \end{equation}
    \item[Sens \( \Rightarrow\)]
        Si \( \omega\) est un pôle d'ordre \( N\), alors \( N=m_{\omega}=\{ i\tq \omega\in \gU_{a_i} \}\). Donc \( \omega\in \gU_{a_i}\) pour tout \( i\), c'est à dire que \( \omega^{a_i}=1\) pour tout \( i\).
    \item[Sens \( \Leftarrow\)]
        Dans l'autre sens, si \( \omega^{a_i}=1\) pour tout \( i\), alors \( m_{\omega}=N\) et \( \omega\) est un pôle d'ordre \( N\).
    \end{subproof}

    Nous pouvons continuer.
    \item[\( m_{\omega}=N\) si et seulement si \( \omega=1\)]
        Nous savons que \( \omega=1\) est un pôle d'ordre \( N\) parce que \( 1\in \gU_{a_i}\) pour tout \( i\). Dans l'autre sens, si \( \omega\) est d'ordre \( N\), alors nous venons de voir que \( \omega^{a_i}=1\) pour tout \( i\).

        Vu que les \( a_i\) sont premiers entre eux, le théorème de Bézout \ref{PROPooWSMTooMdfqse} nous donne des entiers \( u_i\) tels que \( \sum_{i=1}^Nu_ia_i=1\). Nous avons alors
        \begin{equation}
            \omega=\omega^{u\cdot a}=\prod_{i=1}^N(\omega^{a_i})^{u_i}=1.
        \end{equation}
        Donc les pôles de \( f\) différents de \( 1\) sont d'ordre strictement inférieur à \( N\).
    \item[Décomposition en éléments simples]
        Décomposons un peu l'expression de \( f(z)\) :
        \begin{subequations}
            \begin{align}
                f(z)&=\prod_{i=1}\frac{1}{ 1-z^{a_i} }\\
                &=\prod_{i=1}^N\frac{1}{ -\prod_{\omega\in \gU_{a_i}}(z-\omega) }     \label{SUBEQooDFKPooBsxXxt}     \\
                &=(-1)^N\prod_{i=1}^{N}\prod_{\omega\in \gU_{a_i}}\frac{1}{ z-\omega }\\
                &=(-1)^N\prod_{i=1}^N\sum_{\omega\in \gU_{a_i}}\frac{ \lambda{\omega,i} }{ z-\omega }   \label{SUBEQooBVBNooZGsWSE}
            \end{align}
        \end{subequations}
        Justifications :
        \begin{itemize}
            \item Pour \eqref{SUBEQooDFKPooBsxXxt}. Lemme \ref{LemKYGBooAwpOHD}; vous noterez le signe de différence.
            \item Pour \eqref{SUBEQooBVBNooZGsWSE}. Lemme \ref{LEMooABJMooJTUpgV} pour la décomposition en éléments simples.
        \end{itemize}
    \item[Isoler le terme \( \omega=1\)]
        Nous notons \( \gU=\bigcup_{i=1}^N\gU_{a_i}\). Chaque \( \gU_{a_i}\) contient \( \omega=1\). L'expression \eqref{SUBEQooBVBNooZGsWSE} contient donc un terme en \( \frac{1}{ (z-1)^N }\). Tous les autres \( \omega\) de \( \gU\) ne sont présents que dans au maximum \( N-1\) des \( \gU_{a_i}\). Nous avons donc
        \begin{equation}        \label{EQooUUEPooQrVASA}
            f(z)=\frac{ A }{ (z-1)^N }+\sum_{p=1}^{N-1}\sum_{\omega\in \gU}\frac{ B_{p,\omega} }{ (z-\omega)^p }
        \end{equation}
        avec \( B_{p,\omega}\in \eC\).
    \item[Une belle lampée de factorielles]
        Le lemme \ref{LemPQFDooGUPBvF}\ref{ITEMooHFVHooPCgzZV} permet d'écrire \( f\) avec des séries entières :
        \begin{equation}        \label{EQooNHYXooACBOcJ}
            \begin{aligned}[]
            f(z)&=  \frac{A}{ (N-1)! }\sum_{s=0}^{\infty}\frac{ (s+N-1)! }{ s! }z^s\\
            &\quad+\sum_{p=1}^{N-1}\sum_{\omega\in \gU}\frac{(-1)^pB_{p,\omega}}{ (p-1)! }\sum_{s=0}^{\infty}\frac{ (s+p-1)! }{ s! }\frac{ z^s }{ \omega^{s+p+1} }
            \end{aligned}
        \end{equation}
        qui est valable pour \( z\in B(0,1)\).
        
    \item[Ce qu'on en fait]
        Pour rappel, l'équation \eqref{SUBEQooYESHooChEKGm} nous dit que
        \begin{equation}
            f(z)=\sum_{s=0}^{\infty}\Card\big( W_s(a,N) \big)z^s.
        \end{equation}
        Nous allons donc identifier le coefficient de \( z^n\) dans \eqref{EQooNHYXooACBOcJ} avec \( \Card\big( W_n(a,N) \big)\) :
        \begin{equation}
            \begin{aligned}[]
            \Card\big( W_n(a,N) \big)&=\frac{ A }{ (N-1)! }\frac{ (n+N-1)! }{ n! }\\
            &\quad+\sum_{p=1}^{N-1}\sum_{\omega\in \gU}\frac{ (-1)^{p}B_{p,\omega} }{ (p-1)! }\frac{ (n+p-1)! }{ n! }\frac{1}{ \omega^{n+p+1} }.
            \end{aligned}
        \end{equation}
        Voici une belle suite (par rapport à \( n\)) donc nous devons étudier le comportement asymptotique.
    \item[Des équivalences]
        Le lemme \ref{LEMooVMLEooCzPuKy} nous permet de supprimer tous les termes autres que celui qui contient \( A\) :
        \begin{equation}
            \Card\big( W_n(a,N) \big)\sim\frac{ A }{ (N-1)! }\frac{ (n+N-1)! }{ n! }.
        \end{equation}
        Notez que, à gauche, nous avons une suite dans \( \eN\) et à droite, une suite dans \( \eC\) (il n'y a pas de raisons à priori que \( A\) soit entier ou réel). Cela n'a pas d'importance; ça n'empêche pas les suites d'être équivalentes.

        Le lemme \ref{LEMooTGHHooZHZsgE} donne maintenant
        \begin{equation}        \label{EQooTPXCooGHSzoP}
            \Card\big( W_n(a,N) \big)\sim \frac{ A }{ (N-1)! }n^{N-1}.
        \end{equation}
        Cela est déjà très bien parce que ça donne la vitesse de croissance en fonction de \( N\) et \( n\). Mais puisque nous sommes perfectionistes, nous allons encore déterminer la valeur de \( A\).
    \item[La valeur de \( A\)]
        Pour déterminer la valeur de \( A\), l'astuce est de considérer la fonction \( z\mapsto f(z)(1-z)^N\) :
        \begin{subequations}
            \begin{align}
                f(z)(1-z)^N&=(1-z)^N\prod_{i=1}^N\frac{1}{ 1-z^{a_i} }\\
                &=\prod_{i=1}^N\frac{ 1-z }{ 1-z^{a_i} }\\
                &=\prod_{i=1}^N\frac{1}{ 1+\ldots +z^{a_i-1} }.      \label{SUBEQooUZTCooYgHaES}
            \end{align}
        \end{subequations}
        Justifications :
        \begin{itemize}
            \item Pour \eqref{SUBEQooUZTCooYgHaES}. C'est le lemme \ref{LemISPooHIKJBU}\ref{ItemLTBooAcyMtNii}.
        \end{itemize}
        La dernière expression montre qu'il n'y a pas de mal à prendre la limite \( z\to 1\); elle vaut
        \begin{equation}
            \lim_{z\to 1} f(z)(1-z)^N=\prod_{i=1}^N\frac{1}{ a_i }.
        \end{equation}
        Mais en partant d'autre par de \eqref{EQooUUEPooQrVASA}, nous avons
        \begin{equation}
            f(z)(1-z)^N=A+\sum_{p=1}^{N-1}\sum_{\omega\in \gU}\frac{ B_{p,\omega}(1-z)^N }{ (z-\omega)^p }.
        \end{equation}
        Vu que \( N>p\), la limite \( z\to 0\) existe et vaut zéro dans tous les éléments de la somme, y compris les éléments avec \( \omega=1\). Donc
        \begin{equation}
            \lim_{z\to 1}f(z)(1-z)^N=A.
        \end{equation}
        Nous savons donc que
        \begin{equation}        \label{EQooJMALooUrXJZc}
            A=\prod_{i=1}^N\frac{1}{ a_i }.
        \end{equation}
    \end{subproof}
    En remettant la valeur \eqref{EQooJMALooUrXJZc} dans l'équivalence \eqref{EQooTPXCooGHSzoP}, nous trouvons le résultat demandé.
\end{proof}

\begin{example}
    Pour \( p=1\), l'équation est \( \alpha x=n\), qui possède au maximum une solution, quel que soit \( n\). Et de plus pour avoir une solution il faut et suffit que \( \alpha\) divise \( n\), c'est-à-dire que \( n\) soit un multiple de \( \alpha\). Il n'y a que un nombre sur \( \alpha\) à être multiple de \( \alpha\). D'où le comportement en \( \frac{1}{ \alpha }\).

    Pour \( p=2\), c'est l'équation \eqref{EqTOVSooJbxlIq} déjà étudiée. Il y a une famille à un paramètre de solutions dont seulement un certain nombre sont positives. À priori, le nombre de solutions positives croît linéairement en \( n\).
\end{example}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Fonctions d'Euler}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{theorem}[Prolongement méromorphe de la fonction \( \Gamma\) d'Euler\cite{KXjFWKA}]   \label{ThoZJYooWKfbVz}
    Nous considérons la formule
    \begin{equation}
        \Gamma(z)=\int_0^{\infty} e^{-t}t^{z-1}dt.
    \end{equation}
    Alors
    \begin{enumerate}
        \item
            Cette formule définit une fonction holomorphe sur
            \begin{equation}
                \mP=\{ z\in \eC\tq \Re(z)>0 \}.
            \end{equation}
        \item
            La fonction \( \Gamma\colon \mP\to \eC\) admet un unique prolongement méromorphe sur \( \eC\), lequel a des pôles sur les entiers négatifs.
    \end{enumerate}
\end{theorem}
\index{fonction!\( \Gamma\) d'Euler}
\index{prolongement!méromorphe de la fonction \( \Gamma\)}
\index{fonction!définie par une intégrale!\( \Gamma\) d'Euler}
\index{fonction!méromorphe!\( \Gamma\) d'Euler}

\begin{proof}
    \begin{subproof}
        \item[Holomorphie sous l'intégrale]

            Pour étudier l'holomorphie de la fonction \( \Gamma\) sur \( \mP\) nous utilisons le théorème~\ref{ThopCLOVN}.

            Nous considérons la fonction
            \begin{equation}
                \begin{aligned}
                    g\colon \mP\times \eR^+&\to \eC \\
                    (z,t)&\mapsto  e^{-t}z^{z-1}
                \end{aligned}
            \end{equation}
            et nous commençons par montrer que c'est holomorphe en \( z\) pour chaque \( t>0\) fixé. Nous le vérifions par le critère de \( \partial_{\bar zf=0}\)\footnote{Théorème~\ref{PropkwIQwg}.} et en nous souvenant que \( t^i= e^{\ln(t^i)}= e^{i\ln(t)}\). Nous obtenons rapidement que
            \begin{equation}
                \frac{ \partial g }{ \partial \bar z }=0.
            \end{equation}

            Le fait que la fonction \( t\mapsto g(z,t)\) soit mesurable pour tout \( z\) est d'accord.

            Et enfin soit \( K\) compact dans \( \mP\). Il faut trouver une fonction \( g_K(t)\) intégrable sur \( \mathopen[ 0 , \infty [\) telle que pour tout \( z\in K\) et \( t\in\mathopen[ 0 , \infty [\) nous ayons \( | f(z,t)\leq g(t) |\). Pour cela nous majorons séparément les parties \( t\in\mathopen] 0 , 1 \mathclose[\) et \( t\geq 1\).

            Soit donc \( K\) compact dans \( \mP\); nous posons \( M=\max_{z\in K}\Re(z)\) et \( \epsilon=\min_{z\in K}\Re(z)\).

            Si \( t\in \mathopen] 0 , 1 \mathclose[\) alors nous avons
            \begin{equation}
                e^{-t}t^{z-1}= e^{-t} e^{(z-1)\ln(t)},
            \end{equation}
            de telle façon à que que
            \begin{subequations}
                \begin{align}
                    |  e^{-t}t^{z-1} |&\leq|  e^{(x-1+iy)\ln(t)} |\\
                    &=|   e^{(\Re(z)-1)\ln(t)} |\\
                    &=| t^{\Re(z)-1} |\\
                    &\leq | t^{\epsilon-1} |\\
                    &=\frac{1}{ t^{1-\epsilon} }.
                \end{align}
            \end{subequations}
            Cette dernière fonction est intégrable sur \( \mathopen] 0 , 1 \mathclose[\).

            Nous considérons maintenant \( t\geq 1\). Dans ce cas nous avons
            \begin{equation}
                |  e^{-t}z^{z-1} |= e^{-t}t^{\Re(z)-1}\leq  e^{-t}t^{M-1}.
            \end{equation}
            Cette dernière fonction est un produit d'une exponentielle décroissante avec un polynôme. C'est donc intégrable entre \( 1\) et l'infini.

            La fonction \( g_K\) que nous considérons est donc
            \begin{equation}
                g_K(t)=\begin{cases}
                    \frac{1}{ t^{1-\epsilon} }    &   \text{si } t<1\\
                    \text{borné}    &    \text{si } 1\leq t\leq b\\
                    e^{-t}t^{M-1}    &    \text{si } t>b.
                \end{cases}
            \end{equation}
            Cela est une fonction intégrable sur \( \mathopen] 0    \infty ,  \mathclose[\) et qui majore \( f\) uniformément en \( z\) sur le compact \( K\) de \( \mP\). Le théorème~\ref{ThopCLOVN} nous permet donc de conclure que
            \begin{equation}
                \Gamma(z)=\int_0^{\infty}f(z,t)dt
            \end{equation}
            est holomorphe en \( z\) sur \( \mP\) et que
            \begin{equation}
                \Gamma'(z)=\int_0^{\infty}\frac{ \partial f }{ \partial z }(z,t)dt.
            \end{equation}

        \item[En deux morceaux] Nous passons maintenant à la seconde partie du théorème. Pour \( z\in \mP\) nous coupons l'intégrale en deux :
            \begin{equation}
                \Gamma(z)=\int_0^1 e^{-t}t^{z-1}dt+\int_1^{\infty} e^{-t}t^{z-1}dt
            \end{equation}

        \item[Première partie] Nous commençons par parler de la première partie : \( \int_0^1 e^{-t}t^{z-1}dt\) dans laquelle nous voulons utiliser le développement en série de l'exponentielle \(  e^{-t}\). Nous devons donc traiter
            \begin{equation}
                \int_0^1\sum_{n=0}^{\infty}\frac{ (-1)^n }{ n! }t^{n+z-1}dt.
            \end{equation}
            Nous allons permuter la somme avec l'intégrale à l'aide du théorème de Fubini~\ref{ThoFubinioYLtPI} en posant la fonction
            \begin{equation}
                g(n,t)=\frac{ (-1)^n }{ n! }t^{n+z-1}
            \end{equation}
            et en considérant le produit entre la mesure de Lebesgue sur \( \eC\) et la mesure de comptage sur \( \eN\), c'est-à-dire que nous étudions
            \begin{equation}
                \int_0^1\int_{\eN}g(n,t)dndt.
            \end{equation}
            Pour permuter il suffit de prouver que \( | g |\) est intégrable pour la mesure produit, c'est-à-dire que
            \begin{equation}
                \int_0^1\int_{\eN}\left| \frac{ (-1)^n }{ n! }t^{n+z-1} \right| <\infty.
            \end{equation}
            Nous avons \( | t^z=t^{\Re(z)} |\), donc
            \begin{equation}
                \sum_{n=0}^{\infty}\left| \frac{ t^{n+z-1} }{ n! } \right| =t^{\Re(z)-1}\sum_{n=0}^{\infty}\frac{ t^n }{ n! }=t^{\Re(z)-1} e^{t}.
            \end{equation}
            Étant donné que nous avons fixé \( z\in\mP\), nous avons \( \Re(z)-1>-1\) et donc \( t^{\Re(z)-1}\) est intégrable entre \( 0\) et \( 1\).
            %TODO : il faudrait prouver et citer ici le coup du 1/x^alpha qui est intégrable ou non.
            La partie \(  e^{t}\) se majore sur \( \mathopen[ 0 , 1 \mathclose]\) par une constante quelconque. Nous avons donc payé le droit d'inverser la somme et l'intégrale :
            \begin{equation}
                \int_0^1 e^{-t}t^{z-1}dt=\sum_{n=0}^{\infty}\int_0^1\frac{ (-1)^n }{ n! }t^{n+z-1}dt=\sum_{n=0}^{\infty}\frac{ (-1)^n }{ n! }[t^{n+z}]_0^1=\sum_{n=0}^{\infty}\frac{ (-1)^n }{ n!(n+z) }.
            \end{equation}
            Nous avons donc l'intéressante formule suivante, valable pour tout \( z\in\mP\) :
            \begin{equation}
                \Gamma(z)=\sum_{n=0}^{\infty}\frac{ (-1)^n }{ n!(n-z) }+\int_1^{\infty} e^{-t}t^{z-1}dt.
            \end{equation}

        \item[Prolongation de la première partie] Nous voudrions montrer maintenant que la fonction
            \begin{equation}
                \sum_{n=0}^{\infty}\frac{ (-1)^n }{ n!(n-z) }
            \end{equation}
            est méromorphe sur \( \eC\) avec des pôles en les entiers négatifs. Pour cela nous considérons la suite de fonctions
            \begin{equation}
                f_n(z)=\frac{ (-1)^n }{ n!(z+n) }
            \end{equation}
            et nous allons utiliser la proposition~\ref{PropPUZTQKl}. Si \( n\geq 0\), la fonction \( f_n\) est méromorphe sur \( \eC\) avec un pôle simple en \( z=-n\). Soit \( K\) compact de \( \eC\) et \( N_K\) tel que \( K\subset\overline{ B(0,N_K) }\). Pour \( n\geq N_K+1\), la fonction \( f_n\) n'a pas de pôle dans \( K\) et de plus pour tout \( z\in K\) nous avons
            \begin{equation}
                | z+n |=| z-(-z) |\geq\big| n-| z | \big|\geq n-| z |\geq n-N_K,
            \end{equation}
            et par conséquent
            \begin{equation}
                | f_n(z) |\leq \frac{1}{ n!(n-N) },
            \end{equation}
            ou pour le dire de façon plus snob :
            \begin{equation}
                \| f_n \|_{\infty,K}\leq \frac{1}{ n!(n-N) },
            \end{equation}
            dont la série converge. Cela signifie que la série \( \sum_{n\geq N}f_n\) converge normalement\footnote{Définition~\ref{DefVBrJUxo}.} sur \( K\), donc la fonction
            \begin{equation}
                f(z)=\sum_{n=0}^{\infty}f_n(z)
            \end{equation}
            est une fonction méromorphe dont les pôles sont ceux des \( f_n\), c'est-à-dire les entiers négatifs (proposition~\ref{PropPUZTQKl}).

        \item[La seconde partie]

            Nous allons à présent prouver que la fonction
            \begin{equation}
                g(z)=\int_1^{\infty} e^{-t}t^{z-1}dt
            \end{equation}
            est holomorphe sur \( \eC\). Pour cela nous considérons la fonction de deux variables \( f(z,t)= e^{-t}t^{z-1}\) et nous utilisons le théorème d'holomorphie sous l'intégrale~\ref{ThopCLOVN}. D'abord pour \( z_0\) fixé dans \( \eC\) nous avons
            \begin{equation}
                \int_1^{\infty}|  e^{-t}t^{z_0-1} |\leq \int_1^{\infty} e^{-t}t^{\Re(z_0)-1}dt,
            \end{equation}
            donc l'intégrale converge parce que c'est polynôme contre exponentielle. Par ailleurs pour chaque \( t_0\) fixé sur \( \mathopen[ 0 , \infty [\), la fonction \( z\mapsto  e^{-t_0}t_0^{z-1}\) est holomorphe sur \( \eC\) comme en témoigne le calcul suivant :
                \begin{equation}
                    \frac{ 1 }{2}\left( \frac{ \partial  }{ \partial x }+i\frac{ \partial  }{ \partial y } \right)t_0^{x+iy-1}=0.
                \end{equation}
                Et enfin si \( K\) est compact dans \( \eC\) nous avons
                \begin{equation}
                    | f(z,t) |=|  e^{-t}t^{z-1} |= e^{-t}| t^{\Re(z)-1} |\leq  e^{-t}t^{M-1}
                \end{equation}
                où \( M=\max_{z\in K}\Re(z)\). Nous en déduisons que la fonction
                \begin{equation}
                    z\mapsto\int_1^{\infty} e^{-t}t^{z-1}dt
                \end{equation}
                est une fonction holomorphe sur \( \eC\).

            \item[Conclusion]

                Au final nous avons prouvé que la fonction \( \Gamma\) d'Euler admet le prolongement méromorphe sur \( \eC\) donné par
                \begin{equation}
                    \Gamma(z)=\sum_{n=0}^{\infty}\frac{ (-1)^n }{ n!(z+n) }+\int_1^{\infty} e^{-t}t^{z-1}dt.
                \end{equation}
    \end{subproof}
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Euler et factorielle}
%---------------------------------------------------------------------------------------------------------------------------

\begin{proposition}
    Nous avons la formule \( \Gamma(n)=(n-1)!\) pour tout \( n\in \eN\).
\end{proposition}

\begin{proof}
    Nous partons de la formule
    \begin{equation}
        \Gamma(n)=\int_0^{\infty} e^{-t}t^{n-1}dt
    \end{equation}
    que nous intégrons par partie en posant
    \begin{equation}
        \begin{aligned}[]
            u&=t^{n-1}&u'&=(n-1)t^{n-1}\\
            v&= e^{-t}&v'&=- e^{-t}.
        \end{aligned}
    \end{equation}
    Les termes au bord s'annulent (ici il y a un passage à la limite qui n'est pas écrit) et nous trouvons
    \begin{equation}
        \Gamma(n)=\int_0^{\infty}(n-1) e^{-t}t^{n-2}dt=(n-1)\Gamma(n-1).
    \end{equation}

    Pour conclure il suffit de remarquer que
    \begin{equation}
        \Gamma(1)=\int_0^{\infty}=-[ e^{-t}]_0^{\infty}=1.
    \end{equation}
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Exponentielle et logarithme complexe}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Propriétés de l'exponentielle}
%---------------------------------------------------------------------------------------------------------------------------

\begin{proposition}
    Soit \( z\in\eC\) fixé. La fonction
    \begin{equation}
        \begin{aligned}
            E\colon \eR&\to \eC \\
            t&\mapsto  e^{tz}
        \end{aligned}
    \end{equation}
    est  \(  C^{\infty}\), sa dérivée est
    \begin{equation}
        E'(t)=z e^{tz}.
    \end{equation}
    La fonction \( E\) est développable en série entière (voir définition~\ref{DefwmRzKh}) sur \( \eR\) en \( t=0\) et
    \begin{equation}
        e^{tz}=\sum_{n=0}^{\infty}\frac{ z^n }{ n! }t^n.
    \end{equation}
\end{proposition}

\begin{proof}
    Nous fixons \( z\in \eC\). Par définition~\ref{DefJilXoM}, la série suivante est \(  e^{tz}\) :
    \begin{equation}
        f(t)=\sum_{n=0}^{\infty}\frac{ z^n }{ n! }t^n.
    \end{equation}
    Cette série a un rayon de convergence infini et la fonction \( f\) est donc \(  C^{\infty}\) sur \( \eR\). Nous pouvons la dériver terme à terme :
    \begin{equation}
            f'(t)=\sum_{n=1}^{\infty}\frac{ z^n }{ n! }nt^{n-1}
            =z\sum_{n=1}^{\infty}\frac{ z^{n-1} }{ (n-1)! }t^{n-1}
            =z e^{tz}.
    \end{equation}
\end{proof}

\begin{theorem}     \label{THOooNGOIooEECfAv}
    La fonction exponentielle vérifie les propriétés suivantes.
    \begin{enumerate}
        \item
            \( \exp\) est holomorphe\footnote{Définition \ref{DefMMpjJZ}.}.
        \item
            \( (e^z)'=e^z\).
        \item
            L'exponentielle est développable en série entière,
            \begin{equation}
                e^z=\sum_{n=0}^{\infty}\frac{ z^n }{ n! }
            \end{equation}
            et la série converge normalement sur tout compact de \( \eC\).
    \end{enumerate}
\end{theorem}

\begin{proof}
    En tant que application \( E\colon \eR^2\to \eC\), la fonction
    \begin{equation}
        E(x,y)=e^x(\cos y+i\sin y)
    \end{equation}
    est \( C^{\infty}\). De plus nous avons
    \begin{subequations}
        \begin{align}
            \frac{ \partial E }{ \partial x }(x,y)= e^{x+iy}=E(x,y)\\
            \frac{ \partial E }{ \partial y }(x,y)=iE(x,y),
        \end{align}
    \end{subequations}
    et par conséquent la fonction \( E\) vérifie les équations de Cauchy-Riemann.

    Si \( r\) est fixé, par le critère d'Abel appliqué à la suite \(r/n!\) nous savons que la série \( \sum z^n/n!\) converge normalement sur le compact \( B(0,r)\).
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Intégrale de Fresnel}
%---------------------------------------------------------------------------------------------------------------------------

Nous allons calculer l'\defe{intégrale de Fresnel}{intégrale!Fresnel}\index{Fresnel!intégrale}
\begin{equation}
    \int_0^{\infty} e^{-ix^2}dx=\frac{ \sqrt{\pi} }{ 2 } e^{-i\pi/4}
\end{equation}
en suivant la démarche présentée par Wikipédia\cite{ooOXWGooGhLJvX}. Nous commençons par prouver que l'intégrale est convergente en nous contentant de justifier la convergence de
\begin{equation}
    \int_0^{\infty}\sin(x^2)dx.
\end{equation}
Pour chaque \( a>0\) fixé, l'intégrale \( \int_0^a\sin(x^2)dx\) ne pose pas de problèmes. Le lemme \ref{LemTHBSEs} nous permet de passer à la limite; nous devons donc seulement calculer
\begin{equation}
    \lim_{b\to \infty}\int_a^b\sin(x^2)dx
\end{equation}
où \( a\) est une constante strictement positive. Nous effectuons une intégration par partie en posant
\begin{subequations}
    \begin{align}
        u&=\frac{1}{ x }&   u'&=-\frac{1}{ x^2 }\\
        v'&=x\sin(x)    & v&=\frac{ 1-\cos(x) }{2}.
    \end{align}
\end{subequations}
Notons que la primitive \( v\) a été choisie pour avoir \( v(0)=0\). Nous avons
\begin{equation}    \label{EqOdeKye}
    \int_a^b\sin(x^2)dx=\left[ \frac{ 1-\cos(x^2) }{ 2x } \right]_a^b-\int_a^b\frac{ \cos(x^2)-1 }{ 2x^2 }dx
\end{equation}
Pour le premier terme nous avons
\begin{equation}
    \lim_{b\to \infty}\left[ \frac{ 1-\cos(x^2) }{ 2x } \right]_a^b=\lim_{b\to \infty}\frac{ 1-\cos(b^2) }{ 2b }-\frac{ 1-\cos(a^2) }{ 2a }=-\frac{ 1-\cos(a^2) }{ 2a }.
\end{equation}
C'est borné. Pour le second terme de \eqref{EqOdeKye}, la fonction
\begin{equation}
    \frac{ \cos(x^2)-1 }{ 2x^2 }
\end{equation}
est majorée par la fonction \( 1/x^2\) qui est intégrable entre \( a\) et \( \infty\).


Nous allons calculer l'intégrale demandée en passant par la fonction
\begin{equation}
    f(x)= e^{-z^2}
\end{equation}
définie sur le plan complexe. Nous l'intégrons sur le chemin \( \gamma=\gamma_1+\gamma_2-\gamma_3\) indiqué à la figure~\ref{LabelFigCheminFresnel}.
\newcommand{\CaptionFigCheminFresnel}{Chemin d'intégration pour l'intégrale de Fresnel}
\input{auto/pictures_tex/Fig_CheminFresnel.pstricks}
Ces chemins sont donnés par
\begin{equation}
    \begin{aligned}
        \gamma_1\colon \mathopen[ 0 , R \mathclose]&\to \eC \\
        t&\mapsto t,
    \end{aligned}
\end{equation}
\begin{equation}
    \begin{aligned}
        \gamma_2\colon \mathopen[ 0 , \frac{ \pi }{ 4 } \mathclose]&\to \eC \\
        t&\mapsto R e^{it},
    \end{aligned}
\end{equation}
\begin{equation}
    \begin{aligned}
        \gamma_3\colon \mathopen[ 0 , R \mathclose]&\to \eC \\
        t&\mapsto t e^{i\pi/4}.
    \end{aligned}
\end{equation}
Tout d'abord la fonction \( f\) est bien holomorphe par le critère du théorème~\ref{PropkwIQwg}. Le calcul de \( \frac{ \partial f }{ \partial \bar z }\) se fait simplement en posant \( f(x,y)= e^{-(x+iy)^2}\). Le calcul est usuel :
\begin{verbatim}
----------------------------------------------------------------------
| Sage Version 4.8, Release Date: 2012-01-20                         |
| Type notebook() for the GUI, and license() for information.        |
----------------------------------------------------------------------
sage: f(x,y)=exp(-(x+I*y)**2)
sage: A=f.diff(x)+I*f.diff(y)
sage: A.simplify_full()
(x, y) |--> 0
\end{verbatim}
Nous avons donc
\begin{equation}    \label{EqfaoRgU}
    0=\int_{\gamma}f=\underbrace{\int_0^R e^{-t^2}dt}_{I_1(R)}+\underbrace{\int_0^{\pi/4} e^{-R^2 e^{2it}}Ri e^{it}dt}_{I_2(R)}+\underbrace{\int_0^R e^{-t^2 e^{i\pi/2}} e^{i\pi/4}dt}_{I_3(R)}.
\end{equation}
L'intégrale est nulle pour tout \( R\) en vertu de la proposition~\ref{PrpopwQSbJg}. L'intégrale \( I_1\) est une gaussienne et nous avons
\begin{equation}
    \lim_{R\to\infty}I_1(R)=\frac{ \sqrt{\pi} }{ 2 }
\end{equation}
par l'exemple~\ref{EXooLUFAooGcxFUW}. Nous montrons maintenant que \( \lim_{R\to\infty}| I_2(R) |=0\)\footnote{Il y a moyen de démontrer cela via le lemme de Jordan\cite{FresnelDavidS}. Nous donnons ici une démonstration moins technologique.}. D'abord nous majorons en prenant la norme puis nous effectuons le changement de variables \( u=2t\) :
\begin{subequations}
    \begin{align}
        | I_2(R) |&\leq \int_{0}^{\pi/4}R e^{-R^2\cos(2t)}dt\\
        &=\frac{ R }{ 2 }\int_0^{\pi/2} e^{-R^2\cos(u)}du.
    \end{align}
\end{subequations}
Nous savons que le graphe du cosinus est concave : il reste au dessus de la droite que joint \( (0,1)\) à \( (\frac{ \pi }{2},0)\). Du coup \( \cos(u)\geq 1-\frac{ 2 }{ \pi }u\) et par conséquent
\begin{equation}
        e^{-R^2\cos(u)}\leq  e^{-R^2(1-\frac{ 2 }{ \pi }u)}= e^{R^2(\frac{ 2 }{ \pi }u-1)}.
\end{equation}
Nous effectuons l'intégrale
\begin{subequations}
    \begin{align}
        | I_2(R) |&\leq \frac{ R }{2}\int_0^{\pi/2} e^{-R^2} e^{\frac{ 2R^2 }{ \pi }u}du\\
        &=\frac{ R }{2} e^{-R^2}\left[ \frac{ \pi }{ 2R^2 } e^{2R^2 u/\pi} \right]_0^{\pi/2}\\
        &=\frac{ \pi }{ 4R }-\frac{ \pi e^{-R^2} }{ 4R },
    \end{align}
\end{subequations}
et nous avons bien \( \lim_{R\to\infty}| I_2(R) |=0\). Nous passons à la troisième intégrale. En tenant compte que \(  e^{i\pi/2}=i\), nous avons
\begin{subequations}
    \begin{align}
        I_3(R)&=-\int_0^R e^{-\gamma_3(t)^2} e^{i\pi/4}dt\\
        &=-\frac{ 1+i }{ \sqrt{2} }\int_0^R e^{-t^2} e^{2i\pi/4}\\
        &=-\frac{ 1+i }{ \sqrt{2} }\int_0^R e^{-it^2}.
    \end{align}
\end{subequations}
En passant à la limite \( R\to 0 \), de l'équation \eqref{EqfaoRgU} il ne reste que
\begin{equation}
    0=\frac{ \sqrt{2} }{2}-\frac{ 1+i }{ \sqrt{2} }\int_0^{\infty} e^{-it^2}dt,
\end{equation}
ce qui signifie que
\begin{equation}
    \int_0^{\infty} e^{-it^2}dt=\frac{ \sqrt{2\pi} }{ 2(1+i) }=\frac{ \sqrt{\pi} }{2} e^{-i\pi/4}.
\end{equation}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Logarithme complexe}
%---------------------------------------------------------------------------------------------------------------------------


%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{La fonction argument}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Nous savons la définition~\ref{DefJilXoM} de l'exponentielle complexe.

\begin{definition}
    Un \defe{logarithme}{logarithme!dans \( \eC\)} de \( \alpha\in \eC\) est une solution de l'équation \(  e^{z}=\alpha\).
\end{definition}
Notons bien que cela définit \emph{un} logarithme, et non \emph{le} logarithme.

\begin{lemma}       \label{LEMooUMESooJVzeDb}
    Si \( z_1\) et \( z_2\) sont des logarithmes de \( \alpha\) alors il existe \( k\in \eZ\) tel que \( z_1=z_2+2ik\pi\).
\end{lemma}

\begin{proof}
    Nous commençons par déterminer les logarithmes de \( \alpha=1\). Nous avons besoin de \(  e^{a+bi}=1\) (\( a,b\in \eR\)). Nous avons
    \begin{equation}
        e^{a} e^{bi}=1,
    \end{equation}
    et en prenant la norme nous trouvons \( | e^a |=1\), ce qui donne \( a=0\). Ensuite \(  e^{bi}=1\), qui signifie \( b=2k\pi\). Les logarithmes de \( 1\) sont donc les nombres de la forme \( 2ik\pi\).

    Soient maintenant \( z_1\) et \( z_2\) des logarithmes de \( \alpha\). Alors \(  e^{z_1}= e^{z_2}\), donc\footnote{C'est facile de dire «donc». Il faut surtout citer la proposition~\ref{PropdDjisy}\ref{ITEMooRLHCooJTuYKV}.} \(  e^{z_1-z_2}=1\), ce qui signifie que \( z_1-z_2\) est un logarithme de \( 1\). Donc il existe un \( k\in \eZ\) tel que \( z_1-z_2=2ik\pi\).
\end{proof}

\begin{remark}
    Jusqu'ici nous n'avons pas donné de conditions donnant l'existence d'un logarithme. Nous avons seulement supposé des existences et donné des propriétés sur ces hypothétiques objets.
\end{remark}

\begin{definition}[\cite{ooDQKTooXNjklV}]
Si \( z\in \eC^*\) nous définissons la \defe{valeur principale}{valeur principale} de son argument le nombre \( \theta\in \mathopen] -\pi , \pi \mathclose]\) tel que
\begin{equation}
    z=| z | e^{i\theta}
\end{equation}
Nous le notons \( \arg(z)\)\nomenclature[Y]{\( \arg(z)\)}{La valeur principale de l'argument de \( z\in \eC\)}.
\end{definition}

\begin{normaltext}      \label{NORMooOGHNooYriCBH}
    Il ne faut pas se ruer sur \( \arg(x+iy)=\arctan(y/x)\). Pour rappel, la fonction \( \arctan\) a été définie dans le théorème~\ref{THOooUSVGooOAnCvC}, et elle prend ses valeurs dans \( \mathopen] -\pi/2 , \pi/2 \mathclose[\). La formule \( v(x,y)=\arctan(y/x)\) n'est donc valable que pour \( x>0\). Les valeurs sont :
        \begin{equation}        \label{EQooPJVFooSEKTny}
            \arg(x+iy)=\begin{cases}
                 \arctan(y/x)   &   \text{si } x>0\\
                 \pi+\arctan(y/x)    &    \text{si } x<0\text{ et }y\geq 0 \\
                 -\pi+\arctan(y/x)    &    \text{si } x<0 \text{ et }y<0\\
                 \frac{ \pi }{ 2 }    &    \text{si } x=0 \text{ et }y>0\\
                 \frac{- \pi }{ 2 }    &    \text{si } x=0 \text{ et }y<0.
            \end{cases}
        \end{equation}

    Pour \( x>0\) nous avons \( \arg(x+iy)=\arctan(y/x)  \) parce que justement la fonction \( \arctan\) prend ses valeurs en particulier entre \( -\pi\) et \( \pi\). Pour \( x<0\) et \( y>0 \) nous avons \( \arg(x+iy)=\pi+\arctan(y/x)\) (dans ce cas, \( \arctan(y/x)<0\)) et si \( x<0\), \( y<0\) nous avons \( \arg(x+iy)=-\pi+\arctan(y/x)\).
\end{normaltext}

\begin{normaltext}[Les dérivées partielles de la fonction argument]     \label{NORMooMRBEooVtTcIA}
    Vu que nous en aurons besoin plusieurs fois, nous calculons maintenant les dérivées partielles de la fonction
    \begin{equation}
        \begin{aligned}
            \varphi\colon \eR^2&\to \eR \\
            (x,y)&\mapsto \arg(x+iy).
        \end{aligned}
    \end{equation}
    Nous commençons par la dérivée \( \partial_x\varphi(x,y)\). Et il y a de nombreux cas à séparer.
    \begin{subproof}

         \item[\( x>0\)]

             Nous avons
             \begin{equation}
                 \frac{ \partial \varphi }{ \partial x }(x,y)=\lim_{\epsilon\to 0}\frac{ \arctan(y/(x+\epsilon))-\arctan(y/x) }{ \epsilon },
             \end{equation}
             qui n'est autre que la dérivée de la fonction \( x\mapsto\arctan(y/x)\). Nous pouvons la calculer facilement avec le théorème~\ref{THOooUSVGooOAnCvC}\ref{ITEMooMNHLooOVhIIb} :
             \begin{equation}
                 \frac{ \partial \varphi }{ \partial x }(x,y)=-\frac{ y }{ x^2+y^2 }.
             \end{equation}

         \item[\( x<0\)]

             Nous avons
             \begin{equation}
                 \frac{ \partial \varphi }{ \partial x }(x,y)=\lim_{\epsilon\to 0}\frac{ \pm\pi+\arctan(y/(x+\epsilon))-\big( \pm\pi+\arctan(y/x) \big) }{ \epsilon }
             \end{equation}
             où les signes \( \pm\) dépendent du signe de \( y\). De toutes façons, les termes en \( \pi\) se simplifient et le calcul est le même que celui du cas \( x>0\). Encore une fois nous avons
             \begin{equation}
                 \frac{ \partial \varphi }{ \partial x }(x,y)=-\frac{ y }{ x^2+y^2 }.
             \end{equation}

         \item[\( x=0\)]

             Nous devons calculer
             \begin{equation}
                 \frac{ \partial \varphi }{ \partial x }(0,y)=\lim_{\epsilon\to 0}\frac{ \arg(\epsilon+ iy)-\arg(iy) }{ \epsilon }.
             \end{equation}
             Il y a quatre cas d'après les signes de \( \epsilon\) (séparer limite à gauche et à droite) et \( y\).

             Si \( \epsilon>0\) et \( y>0\) alors nous avons à faire le calcul
             \begin{equation}
                 \lim_{\epsilon\to 0^+}\frac{ \arctan(y/\epsilon)-\pi/2 }{ \epsilon }
             \end{equation}
             qui se traite par la règle de l'Hospital. Cela donne \( -1/y\).

             Les trois autres cas ne se distinguent que par des constantes au numérateur, lesquelles disparaissent en appliquant la règle de l'Hospital\footnote{Nonobstant le fait que ces constantes se mettent bien pour avoir un vrai cas d'indétermination \( 0/0\), sinon la règle de l'Hospital ne s'applique pas.}. Au final,
             \begin{equation}
                 \frac{ \partial \varphi }{ \partial x }(0,y)=-\frac{1}{ y }.
             \end{equation}
    \end{subproof}

    Nous avons calculé jusqu'ici :
    \begin{equation}        \label{EQooAOJPooOrvUBR}
        \frac{ \partial \varphi }{ \partial x }(x,y)=\frac{ -y }{ x^2+y^2 }
    \end{equation}
    pour tout \( (x,y)\in \eR^2\setminus\{ (0,0) \}\). En particulier vous avez noté que cette dérivée partielle est continue sur \( \eR^2\setminus\{ (0,0) \}\).

    Nous calculons à présent la dérivée partielle par rapport à \( y\) :
    \begin{equation}
        \frac{ \partial \varphi }{ \partial y }(x,y)=\lim_{\epsilon\to 0}\frac{ \arg(x+iy+i\epsilon)-\arg(x+iy) }{ \epsilon }.
    \end{equation}

    \begin{subproof}

        \item[\( x>0\)]

            Nous avons à calculer
            \begin{equation}
                \lim_{\epsilon\to 0}\frac{ \arctan\frac{ y+\epsilon }{ x }-\arctan\frac{ y }{ x } }{ \epsilon },
            \end{equation}
            qui n'est autre que la dérivée de la fonction \( t\mapsto\arctan\frac{ t }{ x }\) en \( t=y\). Résultat :
            \begin{equation}
                \frac{ \partial \varphi }{ \partial y }(x,y)=\frac{ x }{ x^2+y^2 }.
            \end{equation}

        \item[\( x<0  \) et \( y\neq 0\)]

            Le calcul à faire est :
            \begin{equation}
                \lim_{\epsilon\to 0}\frac{ \pm\pi+\arctan\frac{ y+\epsilon }{ x }-\left( \pm\pi+\arctan\frac{ y }{ x } \right) }{ \epsilon }
            \end{equation}
            Une chose importante à remarquer est que dans le calcul de la limite nous pouvons supposer que \( y\) et \( y+\epsilon\) aient le même signe, quelle que soit la valeur et le signe de \( \epsilon\) (assez petit). C'est pour cela que les deux termes \( \pm\pi\) arrivent avec le même signe des deux côtés de la différence, et se simplifient. Nous tombons sur une limite déjà faite et
            \begin{equation}
                \frac{ \partial \varphi }{ \partial y }(x,y)=\frac{ x }{ x^2+y^2 }
            \end{equation}

        \item[\( x<0\) et \( y=0\)]

            Vu que \( x<0\) nous avons \( \arg(x)=\pi\) et nous devons calculer
            \begin{equation}
                \lim_{\epsilon\to 0}\frac{ \arg(x+i\epsilon)-\pi }{ \epsilon }.
            \end{equation}
            La limite \( \epsilon\to 0^+\) est classique et donne \( 1/x\).

            Mais la limite \( \epsilon\to 0^-\) n'existe pas :
            \begin{equation}
                \lim_{\epsilon\to 0^-}\frac{ -\pi+\arctan(\epsilon/x)-\pi }{ \epsilon }
            \end{equation}
            n'existe pas.

            Donc
            \begin{equation}
                \frac{ \partial \varphi }{ \partial y }(x,0)
            \end{equation}
            n'existe pas pour \( x<0\).

        \item[\( x=0\) et \( y\neq 0\)]

            Le calcul est immédiat
            \begin{equation}
                \lim_{\epsilon\to 0}\frac{ \arg(iy+i\epsilon)-\arg(iy) }{ \epsilon }=0,
            \end{equation}
            donc
            \begin{equation}
                \frac{ \partial \varphi }{ \partial y }(0,y)=0.
            \end{equation}


    \end{subproof}
    En ce qui concerne la continuité, nous avons que \( \partial_y\varphi\) est continue partout sauf sur la demi-droite \(  \{ (x,0)\tq x\leq 0 \}   \) où elle n'existe pas.

\end{normaltext}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Une définition possible du logarithme}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

\begin{definition}      \label{DEFooWDYNooYIXVMC}
    Nous définissons la fonction \defe{logarithme}{logarithme!complexe} par
    \begin{equation}
        \begin{aligned}
            \ln\colon \eC^*&\to \eC \\
            z&\mapsto \ln\big( | z | \big)+i\arg(z)
        \end{aligned}
    \end{equation}
    où le \( \ln\) à droite est le logarithme usuel sur \( \eR^+\).
\end{definition}

\begin{remark}
Cette fonction généralise le logarithme déjà vu sur \( \mathopen] 0 , \infty \mathclose[\subset \eR\). En effet pour des valeurs de \( z\) dans cette partie nous avons \( \arg(z)=0\) et \( | z |=z\).
\end{remark}

\begin{lemma}
    Le nombre \( \ln(z)\) est un logarithme de \( z\).
\end{lemma}

\begin{proof}
    Nous avons
    \begin{equation}
        e^{\ln(z)}= e^{\ln| z |} e^{i\arg(z)}=| z | e^{i\arg(z)}=z.
    \end{equation}
    Nous avons utilisé le fait que \(  e^{\ln(x)}=x\) pour \( x\in\eR^+\) et \( | z | e^{i\arg(z)}=z\) par définition de la fonction \( \arg\).
\end{proof}

Notons que si on avait pris d'autres conventions pour définir \( \arg\), nous aurions eu d'autres définitions possibles de \( \ln\).

\begin{example}
    Nous avons
    \begin{equation}
        \ln(-1)=\ln(1)+i\arg(-1).
    \end{equation}
    Mais \( \ln(1)=0\) et \( \arg(-1)=\pi\) (et non \( -\pi\)), donc
    \begin{equation}
        \ln(-1)=i\pi.
    \end{equation}

    C'est cette définition du logarithme qui est prise par Sage, et c'est cela qui lui permet de donner la primitive de \( 1/x\) comme \( \ln(x)\) et non \( \ln(| x |)\), parce que Sage connaît les logarithmes de nombres réels négatifs :
\lstinputlisting{tex/sage/sageSnip010.sage}
\end{example}

Nous avons jusqu'ici défini une fonction sur \( \eC^*\) qui fait correspondre à chaque nombre complexe un de ses logarithmes. Il reste quelques questions à régler :
\begin{itemize}
    \item Est-ce que cette fonction est continue ? Holomorphe ? (réponses : non et non)
    \item Si non, est-ce qu'il y avait moyen de trouver une définition plus efficace ? (réponse : non)
\end{itemize}

\begin{lemma}       \label{LEMooMUOIooCnoWwq}
La fonction \( \ln\) n'est pas continue sur \( \mathopen] -\infty , 0 \mathclose]\).
\end{lemma}

\begin{proof}
    Attention à bien comprendre l'énoncé. La fonction
    \begin{equation}
        \begin{aligned}
        f\colon \mathopen] -\infty , 0 \mathclose[&\to \eC \\
            x&\mapsto \ln(x)
        \end{aligned}
    \end{equation}
    est continue. D'ailleurs c'est \( \ln(x)=\ln(| x |)+i\pi\). Ce dont il est question dans l'énoncé, c'est de la fonction \( \ln\) vue comme fonction sur \( \eC^*\).

    Soit \( x>0\) dans \( \eR\); nous avons
    \begin{equation}
        \ln(-x)=\ln(x)+i\pi.
    \end{equation}
    Cependant \( \lim_{\substack{\lambda\to 0^-\\\lambda\in \eR}}\ln(-x+\lambda i) \) va valoir \( \ln(| x |-i\pi)\). En effet lorsque \( \lambda<0\) est petit, l'argument de \( -x+\lambda i\) se rapproche de \( -\pi\) (et non de \( \pi\)).

\begin{center}
   \input{auto/pictures_tex/Fig_CWKJooppMsZXjw.pstricks}
\end{center}

Donc
\begin{equation}
    \lim_{\substack{\lambda\to 0^-\\\lambda\in \eR}}\ln(-x+\lambda i)=\lim \ln(| x+\lambda i |)+i\arg(-x+\lambda i)=\ln(| x |)-i\pi.
\end{equation}
Nous n'avons donc pas continuité de la fonction logarithme comme fonction sur \( \eC^*\).
\end{proof}

\begin{theorem}     \label{THOooWUXOooYKvLbJ}
    La restriction
    \begin{equation}
        \ln\colon \eC\setminus\mathopen] -\infty , 0 \mathclose]\to \eC
    \end{equation}
    est holomorphe.
\end{theorem}

\begin{proof}
    Nous allons utiliser la proposition~\ref{PropKJUDooJfqgYS} et considérer la fonction
    \begin{equation}
        \begin{aligned}
            F\colon S&\to \eR^2 \\
            (x,y)&\mapsto \big( \ln(| x+iy |),\arg(x+iy) \big)
        \end{aligned}
    \end{equation}
    où \( S=\eR^2\setminus\{ (x,0)\tq x\leq 0 \}\). Nous devons vérifier que \( F\) est différentiable et que sa différentielle en un point de \( S\) est une similitude.

    Nous posons
    \begin{equation}
        u(x,y)=\ln\big( \sqrt{ x^2+y^2 } \big)
    \end{equation}
    et
    \begin{equation}
        v(x,y)=\arg(x+iy).
    \end{equation}
    Les dérivées partielles de \( u\) ne sont pas très compliquées :
    \lstinputlisting{tex/sage/sageSnip011.sage}
    c'est-à-dire
    \begin{subequations}
        \begin{align}
            \frac{ \partial u }{ \partial x }=\frac{ x }{ x^2+y^2 }\\
            \frac{ \partial u }{ \partial y }=\frac{ y }{ x^2+y^2 }.
        \end{align}
    \end{subequations}

    Pour celles de \( v \) par contre, il faut se poser des questions, par exemples résister à la tentation d'écrire \( v(x,y)=\arctan(y/x)\) et lire~\ref{NORMooOGHNooYriCBH}.

    Nous avons déjà calculé les dérivées partielles de \( v\) dans~\ref{NORMooMRBEooVtTcIA}, et nous avons vu qu'elles étaient continues sur \( \eR^2\) privé de la demi-droite.

    Vu que les dérivées partielles sont continues, le théorème \ref{THOooBEAOooBdvOdr} nous dit que \( F\) est différentiable. La matrice de la différentielle est alors la matrice des dérivées partielles
    \begin{equation}
        \begin{pmatrix}
            \frac{ x }{ x^2+y^2 }    &   \frac{ y }{ x^2+y^2 }    \\
            \frac{ -y }{ x^2+y^2 }    &   \frac{ x }{ x^2+y^2 }
        \end{pmatrix},
    \end{equation}
    qui a la forme requise \eqref{EQooWZGKooLDEHGr} pour que la proposition~\ref{PropKJUDooJfqgYS} nous assure que \( \ln\) soit \( \eC\)-dérivable, c'est-à-dire holomorphe.
\end{proof}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Pas plus de continuité}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Bon. La fonction logarithme que nous avons définie est holomorphe sur \( \eC^*\) privé d'une demi-droite \( U\). Et elle n'est pas continue sur \( U\); elle y est cependant continue «par le haut». Pouvons-nous faire mieux ? Nous allons maintenant prouver quelques résultats d'impossibilité de faire mieux que holomorphe partout sauf une partie pas si petite que ça.

\begin{proposition}
    Il n'existe pas de fonctions continues \( f\colon \eC^*\to \eC\) telle que \(  e^{f(z)}=z\) pour tout \( z\in \eC^*\).
\end{proposition}

\begin{proof}
    Pour tout \( z\), le nombre \( f(z)\) est un logarithme de \( z\). Or \( \ln(z)\) en est également un. Donc par le lemme~\ref{LEMooUMESooJVzeDb}
    \begin{equation}
        f(z)=\ln(z)+2i k(z)\pi
    \end{equation}
    pour une certaine fonction \( k\colon \eC^*\to \eZ\). Sur le domaine d'holomorphie de \( \ln\), les fonctions \( \ln\) et \( f\) étant continues, la fonction \( k\) l'est aussi. Mais une fonction continue à valeurs dans \( \eZ\) est constante (son domaine est connexe).

    Il existe donc \( k\in \eZ\) tel que
    \begin{equation}
         f(z)=\ln(z)+2ik\pi
    \end{equation}
    au moins pour tout \( z\in \eC^*\setminus U\). Une telle fonction ne peut pas être continue sur \( U\) parce que \( \ln\) ne l'est pas.
\end{proof}

Ok. Pas continue sur tout \( \eC\). Mais continue sur un peu plus que \( \eC\) privé de toute une demi-droite ? La proposition suivante répond que bof.

\begin{proposition}
    Soit \( \Omega\) un ouvert de \( \eC\) contenant \( S(0,r)\) (le cercle centré en \( 0\) et de rayon \( r>0\)). Il n'existe pas de fonction continue \( f\colon \Omega\to \eC\) telle que \(  e^{f(z)}=z\) pour tout \( z\in \Omega\).
\end{proposition}

\begin{proof}
    Encore une fois, pour tout \( z\in \Omega\) nous avons
    \begin{equation}
        f(z)=\ln(z)+2i\pi k(z)
    \end{equation}
    pour une certaine fonction \( k\colon \Omega\to \eZ\). Sur \( \Omega\setminus U\), la fonction \( \ln\) est continue et \( k\) doit également l'être. Donc \( k\) est constante sur les composantes connexes de \( \Omega\setminus U\).

    Vu que \( S(0,r)\) est compact, on peut le recouvrir par un nombre fini de boules centrées en des points de \( S(0,r)\). En prenant le minimum des rayons de ces boules, nous voyons que \( \Omega\) contient une couronne
    \begin{equation}
        \{ z\in \eC\tq r-\delta\leq | z |\leq r+\delta \}.
    \end{equation}
    Soit le point \( x_0=-r\). C'est un point de \( \Omega\) contenu dans \( U\). Nous allons prouver que \( B(x_0,\delta)\setminus U\) est dans une seule composante connexe de \( \Omega\).

    Soit un point \( z_1\in B(x_0,\delta)\) situé au-dessus de \( U\), et \( z_2\) un point de \( B(x_0,\delta)\) situé en dessous de \( U\). Le cercle \( S(0,r)\) coupe \( B(x_0,\delta)\) en deux points : un au-dessus et un en-dessous de \( U\). On peut lier \( z_1\) au point de «sortie» supérieur de \( S(0,r)\) en restant dans \( B(x_0,\delta)\); ce point est ensuite relié en suivant le cercle au point d'entrée inférieur du cercle dans \( B(x_0,\delta)\). Ce dernier point est lié à \( z_2\) par un chemin restant dans la boule.

    Tout cela pour dire que \( z_1\) et \( z_2\) sont dans la même composante connexe de \( \Omega\) et que \( k(z_1)=k(z_2)\). Il existe donc \( k\in \eZ\) tel que
    \begin{equation}
        f(z)=\ln(z)+2ik\pi
    \end{equation}
    sur \( B(x_0,\delta)\setminus U\). Une telle fonction \( f\) ne peut pas être continue.
\end{proof}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Pas d'unicité : autres déterminations de l'argument}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

\begin{normaltext}      \label{NORMooFCDOooFDzAjp}
    Nous avons pris la fonction d'argument \( \arg\colon \eC\to \mathopen] -\pi , \pi \mathclose]\). Il y en a évidemment beaucoup d'autres de possibles. Par exemple pour \( \alpha\in \eR\) nous pouvons considérer
    \begin{equation}        \label{EQooNKKDooOuJxXe}
        \arg_{\alpha^+}\colon \eC\to \mathopen] \alpha , \alpha+2\pi \mathclose]
    \end{equation}
    ou
    \begin{equation}
        \arg_{\alpha^-}\colon \eC\to \mathopen[ \alpha , \alpha+2\pi \mathclose[.
    \end{equation}
    En posant
    \begin{equation}
        \ln_{\alpha^{\pm}}(z)=\ln(| z |)+i\arg_{\alpha^{\pm}}(z)
    \end{equation}
nous avons une fonction réciproque de l'exponentielle définie sur \( \eC^*\) et holomorphe sur \( \eC^*\) privé d'une demi-droite \( D_{\alpha}\) (dépendante de la valeur de \( \alpha\)).
\end{normaltext}

La différence entre \( \ln_{\alpha^+}\) et \( \ln_{\alpha^-}\) est seulement la valeur sur la demi-droite de non-holomorphie. L'une sera semi-continue d'un côté et l'autre, de l'autre côté.

\begin{remark}
    La fonction \( \arg_{0^-}\) a déjà été utilisée en \ref{SUBSECooWFNMooOuZBRN} pour écrire un inverse de la fonction
    \begin{equation}
        \begin{aligned}
            \varphi\colon \mathopen[ 0 , 2\pi \mathclose[  &\to S^1 \\
                t&\mapsto  e^{it}. 
        \end{aligned}
    \end{equation}
\end{remark}

\begin{definition}[\cite{ooXDXQooWXsXlk}]
    Soit un ouvert \( \Omega\subset \eC^*\). Nous disons que la fonction \( f\colon \Omega\to \eC\) est une \defe{détermination}{détermination!logarithme} sur \( \Omega\) si elle est continue et vérifie
    \begin{equation}
        e^{f(z)}=z
    \end{equation}
    pour tout \( z\in \eC\).
\end{definition}

Les différents résultats vus jusqu'ici montrent qu'il n'existe pas de détermination du logarithme sur \( \eC^*\).

\begin{definition}
    La \defe{détermination principale}{détermination!logarithme!principale} du logarithme est la restriction de notre logarithme~\ref{DEFooWDYNooYIXVMC}
    \begin{equation}
        \begin{aligned}
            \ln\colon \eC^*&\to \eC \\
            z&\mapsto \ln(| z |)+i\arg(z)
        \end{aligned}
    \end{equation}
    à l'ouvert \( \eC^*\setminus U\) où \( U\) est la partie \( \Re(z)\leq 0\) de \( \eC\).
\end{definition}

\begin{remark}      \label{REMooFBLLooDnkmjR}
    Beaucoup de sources\cite{ooGUROooApafph} ne définissent pas \( \ln_{\alpha^{\pm}}\) sur la droite \( D_{\alpha}\). C'est-à-dire qu'ils notent \( \ln_{\alpha}\) notre fonction \( \ln_{\alpha^+}\) restreinte à \( \eC^*\setminus D_{\alpha}\). Dans ce cas, les fonctions \( \ln_{\alpha^+}\) et \( \ln_{\alpha^-}\) sont identiques\footnote{Cela n'est pas tout à fait évident; vous devriez y penser.}.

    Cette remarque est importante parce que certains vont vous dire «le logarithme n'est pas définit sur la demi-droite»; de leur point de vue, la fonction que nous avons définie est une prolongation (non continue) à \( U\) du logarithme, qui est continu.

    \begin{enumerate}
        \item
            Certaines personnes pourraient vous dire que notre logarithme «n'est pas bien définit parce que si on fait le tour dans un sens ou dans l'autre nous n'obtenons pas la même valeur pour \( \ln(z)\) lorsque \( z\) est sur \( U\)». Et cela avec des arguments aussi forts que «\( 2\pi\) et \( 0\), c'est le même point».

            Nous préférons être bien clairs\quext{Est-ce qu'il faut vraiment un pluriel ici ?} sur ce point : notre fonction \( \ln\) est parfaitement définie sur \( \eC^*\) et \( 2\pi\) n'est pas la même chose que zéro. En particulier \( \arg( e^{2i\pi})=0\) et \(  \arg(e^{-i\pi})=\pi\) et non \( -\pi\).
        \item
            Il n'en reste pas moins que Sage donne \( \ln(-1)=I\pi\) et que nous avons choisi de faire de même, parce que le Frido n'est pas un cours d'agrégation, mais un texte qui donne quelques éléments de mathématique dans le but d'utiliser Sage efficacement.
        \item
            Tout ceci pour dire que si vous utilisez ce livre pour l'agrégation, vous devriez sérieusement considérer l'option de ne pas donner du logarithme la définition donnée ici, mais bien sa restriction.
    \end{enumerate}

    En fait notre logarithme est maximum pour la propriété «être une réciproque de l'exponentielle» alors que beaucoup de monde préfère avoir une fonction maximale pour la propriété «être réciproque de l'exponentielle tout en étant continue».

\end{remark}

De toutes les fonctions ayant le droit de vouloir être appelée «logarithme», celle que nous avons choisie (un peu arbitrairement) pour s'appeler «logarithme» et accaparer de la notation «\( \ln\)» est \( \ln_{\pi^+}\). Elle est d'une certaine manière celle qui arrive le plus naturellement.

En effet si nous pensons au logarithme népérien \( \ln\colon \eR^+\to \eR\) que nous voulons prolonger sur \( \eR\), nous devons poser
\begin{equation}
    \ln(-x)=\ln(-1)+\ln(x)
\end{equation}
pour \( x>0\). Que peut valoir \( \ln(-1)\) ? Il doit vérifier \(  e^{\ln(-1)}=-1\). La première valeur qui nous tombe sous la main est \( \ln(-1)=\pi\). Bien entendu, d'autres possibilités étaient possibles, comme \( \ln(-1)=2017\pi\) par exemple.

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Pas d'unicité : développement en série}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Pour \( z_0\in \eC^*\) nous pouvons écrire un développement en série de la réciproque de l'exponentielle autour de \( z_0\). La fonction ainsi définie est holomorphe sur la boule \( B(z_0,| z_0 |)\) et diverge en dehors de cette boule.

Voilà encore une fonction «logarithme» pour chaque point de \( \eC^*\). Nous nommons \( \ln_{z_0}\) la fonction
\begin{equation}
    \ln_{z_0}\colon B(z_0,| z_0 |)\to \eC
\end{equation}
donnée par la série.

En général nous n'avons pas \( \ln_{z_1}=\ln_{z_2}\) sur l'intersection des disques de convergence. Si c'était le cas, de proche en proche nous pourrions construire une fonction continue réciproque du logarithme sur \( \eC^*\), ce qui est impossible.

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Pas d'unicité : laquelle choisir ?}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Bon. Pour chaque demi-droite \( D\) nous avons une détermination du logarithme sur \( \eC^*\setminus D\). Et pour tout \( z_0\in \eC^*\) nous en avons une sur \( B(z_0,| z_0 |)\).

En pratique, quel logarithme choisir ? Cela dépend du problème.

Si vous avez besoin ou envie de travailler avec des série entières, le mieux est de choisir une détermination donnée par un développement autour d'un point bien choisi par rapport à votre problème.

Si vous avez surtout besoin d'holomorphie, et que vous en avez besoin sur un grand domaine, vous devriez choisir une détermination sur un des ensembles \( \eC^*\setminus D_{\alpha}\) en choisissant \( \alpha\) de telle sorte que la demi-droite maudite ne passe pas par la zone sur laquelle vous travaillez.

Dans tous les cas, vous devez préciser très explicitement la détermination choisie. Dans ce texte, sauf mention du contraire, nous utiliserons la détermination principale, et même son extension (non continue) à \( \eC^*\). Lorsque nous aurions besoin d'holomorphie, nous préciserons que nous considérons la restriction.

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Logarithme comme primitive}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Tout le monde sait que le logarithme \( \ln\colon \eR^+\to \eR\) est une primitive de la fonction \( x\mapsto 1/x\). Qu'en est-il dans le cas complexe ? Tout d'abord précisons que nous ne comptons pas encore parler d'intégrale sur \( \eC\), mais seulement d'intégrales sur \( \eR\) d'une fonction à valeur complexes.

\begin{proposition}     \label{PROPooNIJVooKueuYJ}
    Si \( z\in \eC\) alors
    \begin{equation}        \label{EQooAHYXooTPGXDS}
        \int\frac{1}{ x+z }dx=\ln(x+z)
    \end{equation}
\end{proposition}

\begin{proof}
    Il est important de comprendre que la formule \eqref{EQooAHYXooTPGXDS} est un abus de notation pour dire que si nous considérons la fonction
    \begin{equation}
        \begin{aligned}
            \varphi\colon \eR&\to \eC \\
            x&\mapsto \ln(x+z)
        \end{aligned}
    \end{equation}
    alors nous avons \( \varphi'(x)=\frac{1}{ x+z }\). Ici la dérivation est une dérivation sur \( \eR\) et l'intégrale est une intégrale sur \( \eR\), c'est-à-dire «composante par composantes». La fonction \(  \varphi\) se décompose en partie réelle et imaginaire qui sont à dériver séparément :
    \begin{equation}
        \varphi(x)=\ln(| x+z |)+i\arg(x+z).
    \end{equation}

    \begin{subproof}

        \item[Si \( z\) est imaginaire pur]

            Nous posons \( z=\lambda i\) avec \( \lambda\in \eR^*\). D'abord nous avons
            \begin{equation}
                \frac{1}{ x+\lambda i }=\frac{ x }{ x^2+\lambda^2 }-i\frac{ \lambda }{ x^2+\lambda^2 }.
            \end{equation}
            La partie réelle de \( \varphi(x)\) est
            \begin{equation}
                \varphi_1(x)=\ln\big( \sqrt{ x^2+\lambda^2 } \big),
            \end{equation}
            dont la dérivée est
            \begin{equation}
                \varphi_1'(x)=\frac{ x }{ x^2+\lambda^2 },
            \end{equation}
            qui correspond bien à la partie réelle de \( \frac{1}{ x+\lambda i }\).

            En ce qui concerne la partie imaginaire, \( \varphi_2(x)=\arg(x+\lambda i)\), et sa dérivée n'est rien d'autre que la dérivée partielle par rapport à \( x\) de la fonction argument, déjà calculée en \eqref{EQooAOJPooOrvUBR} :
            \begin{equation}
                \varphi_2'(x)=\frac{ -\lambda }{ x^2+\lambda }.
            \end{equation}
            Cela est bien la partie imaginaire de \( \frac{1}{ x+\lambda i }\).

    Notons que nous n'avons pas de problèmes sur la demi-droite des réels négatifs parce que nous ne considérons au final que la dérivée partielle par rapport à \( x\) de la fonction argument, laquelle existe et est continue, même sur cette partie.

        \item[Pour \( z\) quelconque]

            Soit \( z=s+\lambda i\) avec \( s,\lambda\in \eR\). En posant \( \varphi_0(x)=\ln(x+\lambda i)\) nous avons \( \varphi(x)=\varphi_0(x+s)\) et donc
            \begin{equation}
                \varphi'(x)=\varphi_0'(x+s)=\frac{ 1 }{ x+s+\lambda i }=\frac{1}{ x+z }.
            \end{equation}
            Tout va bien.

    \end{subproof}
\end{proof}

\begin{example}     \label{EXooAKEDooZgjocX}
    Un petit calcul d'intégrale, que nous avions déjà faite dans l'exemple~\ref{EXooIPEQooGKDjea} (avec la méthode de Rothstein-Trager). En passant par une décomposition en fractions simples :
    \begin{subequations}
        \begin{align}
            \int\frac{1}{ x^3+x }&=\int\left( \frac{1}{ x }-\frac{ 1/2 }{ x-i }-\frac{ 1/2 }{ x+i } \right)\\
            &=\ln(x)-\frac{ 1 }{2}\ln(x-i)-\frac{ 1 }{2}\ln(x+i)\\
            &=\ln(x)-\frac{ 1 }{2}\ln(x^2+1).       \label{SUBEQooRNQLooScfSlG}
        \end{align}
    \end{subequations}
    Attention aux justifications. Il n'est pas vrai en général dans le cas de nombres complexes \( a\) et \( b\) que \( \ln(ab)=\ln(a)+\ln(b)\). En effet, pour la partie réelle, ça passe parce que \( | ab |=| a | |b |\). Mais en ce qui concerne la partie imaginaire,
    \begin{equation}
        \arg(ab)\neq \arg(a)+\arg(b)
    \end{equation}
lorsque la somme dépasse les bornes de \( \mathopen] -\pi , \pi \mathclose]\). Le passage à \eqref{SUBEQooRNQLooScfSlG} fonctionne parce que dans le cas particulier des nombres \( x+i\) et \( x-i\), les arguments se somment à zéro : \( \arg(x+i)+\arg(x-i)=0\).
\end{example}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Théorème de Weierstrass}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{theorem}[Théorème de Weierstrass\cite{uTyBDj}]       \label{ThoArYtQO}
    Soit \( (f_n)\) une suite de fonctions holomorphes sur un ouvert \( \Omega\) de \( \eC\) que nous supposons converger uniformément sur tout compact vers \( f\). Alors \( f\) est holomorphe sur \( \Omega\) et pour tout \( k\) nous avons
    \begin{equation}
        f^{(k)}_n\to f^{(k)}
    \end{equation}
    uniformément sur tout compact.

    Dit en peu de mots, la limite uniforme d'une suite de fonctions holomorphes est holomorphe, et on peut permuter la limite avec la dérivation.
\end{theorem}
\index{compacité}
\index{suite!de fonctions intégrables}
\index{fonction!définie par une intégrale}
\index{fonction!holomorphe}
\index{limite!inversion}
\index{limite!de fonctions holomorphes}

\begin{proof}
    Chacune des fonctions \( f_n\) étant holomorphes, si \( a\in \Omega\) et \( r\) est tel que \( B(a,r)\subset \Omega\), nous avons par la formule de Cauchy~\ref{ThoUHztQe} :
    \begin{equation}
        f_n(z)=\frac{1}{ 2\pi i }\int_{\partial B(a,r)}\frac{ f_n(\xi) }{ \xi-z }d\xi
    \end{equation}
    pour tout \( z\) dans un boule \( B(a,\rho)\) incluse dans \( B(a,r)\). Étant donné que le cercle \( \partial B\) est compact, elle y est majorée par une constante \( M\). Montrons que de plus nous pouvons choisir \( M\) de telle façon à avoir \( | f_n(\xi) |\leq M\) pour tout \( n\) et tout \( \xi\) en même temps. D'abord nous utilisons la continuité de la limite \( f\) sur le compact \( \partial B \) pour poser \( A=\max_{z\in\partial B}| f(z) |\). Ensuite nous considérons un \( \epsilon>0\) et \( N\) tel que \( |\ f_n-f \|_{\partial B}\leq \epsilon\) pour tout \( n\geq N\). Nous savons maintenant que
    \begin{equation}
        \{ | f_n(\xi) |\tq n \geq N,\xi\in\partial B \}
    \end{equation}
    est majoré par \( A+\epsilon\). Nous posons enfin
    \begin{equation}
        B=\max_{n\leq N}\max_{\xi\in\partial B}| f_n(z) |,
    \end{equation}
    et alors le nombre \( M=\max\{ A+\epsilon,B \}\) majore \( | f_n(\xi) |\) pour tout \( n\) et tout \( \xi\in\partial B\).

    De plus pour tout \( \xi\in\partial B\) et pour tout \( z\) dans la petite boule, nous avons \( | \xi-z |>r-\rho\), donc  la fonction dans l'intégrale est majorée par une constante ne dépendant ni de \( n\) ni de \( \xi\). Nous pouvons donc permuter l'intégrale et la limite sur \( n\) :
    \begin{equation}
        f(z)=\frac{1}{ 2i\pi }\int_{\partial B}\frac{ f(\xi) }{ \xi-z }.
    \end{equation}
    Cela implique que la fonction \( f\) est holomorphe par le corolaire~\ref{CorwfHtJu}.

    Nous voudrions maintenant parler des dérivées des \( f_n\) et de \( f\). Pour cela nous voulons permuter l'intégrale et les dérivées, ce qui est fait au corolaire~\ref{CorNxTjEj} :
    \begin{equation}
        f_n^{(k)}=\frac{1}{ 2\pi i }\int_{\partial B(z_0,r)}\frac{ f(\omega) }{ (\omega-z)^{k+1} }d\omega.
    \end{equation}
    Nous voulons la convergence sur tout compact contenu dans l'ouvert \( \Omega\). Pour ce faire, nous allons considérer un compact \( K\subset \Omega\) et prouver la convergence uniforme dans toute boule de la forme \( B(z_0,r)\) avec \( z_0\in K\) et \( B(z_0,r)\subset \Omega\). Pour chaque tel couple \( (z_0,r)\), nous aurons un \( N_{(z_0,r)}\in \eN\) tel que si \( n\geq N_{(z_0,r)}\),
    \begin{equation}
        \| f_n^{(k)}-f^{(k)} \|_{B(z_0,r)}\leq \epsilon.
    \end{equation}
    Vu que ces boules \( B(z_0,r)\) forment un recouvrement de \( K\) par des ouverts, nous pouvons en retirer un sous-recouvrement fini et prendre, comme \( N\), le maximum des \( N_{(z_0,r)}\) correspondants. Pour ce \( N\) nous aurons
    \begin{equation}
        \| f_n^{(k)}-f^{(k)} \|_K\leq \epsilon.
    \end{equation}
    Au travail !

    Pour \( z\in B(z_0,r)\) nous considérons \( r'>r\) tel que \( B(z_0,r')\subset \Omega\) et nous avons
    \begin{subequations}
        \begin{align}
            | f^{(k)}_n(z)-f^{(k)}(z) |&=\left| \frac{1}{ 2\pi i }\int_{\partial B(z_0,r')}\frac{ f_n(\xi)-f(\xi) }{ (\xi-z)^{k+1} }d\xi \right| \\
            &\leq\frac{1}{ 2\pi }\int_{\partial B(z_0,r')}\frac{ | f_n(\xi)-f(\xi) | }{ | r-r' |^{k+1} }d\xi.
        \end{align}
    \end{subequations}
    Nous avons pris ce \( r'\) de telle manière que \( | \xi-z |\) soit borné par le bas par \( | r-r' |\); sinon la majoration que nous venons de faire ne marche pas. Étant donné que \( f_n\to f\) uniformément, nous pouvons considérer \( n\) assez grand pour que le numérateur soit plus petit que \( \epsilon\) indépendamment de \( \xi\) et de \( z\). Donc pour un \( n\) assez grand,
    \begin{equation}
        | f^{(k)}_n(z)-f^{(k)}(z) |\leq \frac{ \epsilon }{ 2\pi }\frac{ 2\pi r' }{ | r-r' |^{k+1} }
    \end{equation}
    pour tout \( z\in B(z_0,r)\). Donc nous avons convergence uniforme \( f_n^{(k)}\to f^{(k)}\) sur cette boule. Par l'argument de compacité donné plus haut, nous avons la convergence uniforme sur tout compact.
\end{proof}
