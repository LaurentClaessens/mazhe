% This is part of Mes notes de mathématique
% Copyright (c) 2012-2013,2016-2019
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Singularités, pôles et méromorphe}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{definition}
    Si \( f\) est holomorphe sur un ouvert \( \Omega\), alors une \defe{singularité}{singularité} de \( f\) est un point isolé du bord de \( \Omega\).
    \begin{enumerate}
        \item
            La singularité est \defe{effaçable}{singularité!effaçable} si la fonction \( f\) s'y prolonge en une fonction holomorphe.
        \item
            La singularité \( Z\) est un \defe{pôle}{singularité!pôle} d'ordre \( k\) de \( f\) si elle n'est pas effaçable et si la fonction \( z\mapsto (z-Z)^kf(z)\) se prolonge en une fonction holomorphe en \( Z\).
    \end{enumerate}
\end{definition}

\begin{example}
    La fonction
    \begin{equation}
        z\mapsto \frac{ \sin(z) }{ z }
    \end{equation}
    n'est pas définie en \( z=0\), mais elle s'y prolonge en une fonction continue en posant \( f(0)=1\).
\end{example}
%TODO : dans \eC je ne sais pas si c'est facile à montrer. De toutes façons, il faudrait déjà définir le sinus.

\begin{proposition}
    Une singularité de \( f\) est un pôle si et seulement si
    \begin{equation}
        \lim_{z\to Z}f(z)=\infty.
    \end{equation}
\end{proposition}

Le théorème suivant compète la proposition~\ref{PropDRnYkKP}.
\begin{theorem}[Prolongement de Riemann]    \label{ThoTLQOEwW}
    Soient \( f\colon \Omega\to \eC\) et \( Z\) une singularité de \( f\). Nous avons équivalence de
    \begin{enumerate}
        \item
            la singularité \( Z\) est effaçable;
        \item
            \( f\) possède un prolongement continue en \( Z\);
        \item
            il existe un voisinage épointé de \( Z\) sur lequel \( f\) est bornée;
        \item
            \( \lim_{z\to Z}(z-Z)f(z)=0\).
    \end{enumerate}
\end{theorem}
\index{théorème!prolongement de Riemann}

\begin{definition}[Fonction méromorphe\cite{ooBBIEooFYzkzz}]
    Soient \( \mU\) un ouvert de \( \eC\) et \( \{ p_i \}\) une suite de points dans \( \mU\) sans points d'accumulation (éventuellement il y a un nombre fini de \( p_i\)). Si la fonction \( f\) est holomorphe sur \( \mU\setminus\{ p_i \}\) et si chaque \( p_i\) est un point régulier ou un pôle de \( f\), alors nous disons que \( f\) est \defe{méromorphe}{méromorphe} sur \( \mU\).
\end{definition}

\begin{proposition} \label{PropPUZTQKl}
    Soient \( \Omega\) un ouvert de \( \eC\) et \( f_n\colon \Omega\to \eC\) une suite de fonctions telles que pour tout compact \( K\) de \( \Omega\) il existe \( N_K\geq 0\) tel que
    \begin{enumerate}
        \item
            \( f_n\) n'a pas de pôle dans \( K\) dès que \( n\geq N_K\);
        \item
            la série \( \sum_{n\geq N_K}f_n\) converge uniformément sur \( K\).
    \end{enumerate}
    Alors
    \begin{enumerate}
        \item
            La fonction
            \begin{equation}
                f(z)=\sum_{n=0}^{\infty}f_n(z)
            \end{equation}
            est méromorphe sur \( \Omega\) et ses pôles sont l'union de ceux des \( f_n\).
        \item
            Nous pouvons permuter la somme et la dérivée :
            \begin{equation}
                f'(z)=\sum_{n=0}^{\infty}f'_n(z).
            \end{equation}
    \end{enumerate}
\end{proposition}

\begin{theorem}[Série de Laurent]       \label{THOooMKJOooVghZyG}
    Soient \( C\) une couronne de rayons \( r_1<r_2\) centrée en zéro et une fonction \( f\) holomorphe dans cette couronne. Alors nous avons la \defe{série de Laurent}{série!de Laurent}
    \begin{equation}
        f(z)=\sum_{n\in \eZ}a_nz^n.
    \end{equation}
    \begin{enumerate}
        \item
            Cette série converge uniformément sur tout compact de \( C\).
        \item
            Les coefficients sont donnés par
            \begin{equation}
                a_n=\frac{1}{ 2\pi i }\int_{\gamma}\frac{ f(z) }{ z^{n+1} }dz
            \end{equation}
            où \( \gamma\) est un cercle centré en zéro.
        \item
            Ce développement en série est unique.
        \item
            La valeur des \( a_n\) ne dépend pas du choix du rayon du cercle \( \gamma\).
    \end{enumerate}
\end{theorem}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Fonctions d'Euler}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{theorem}[Prolongement méromorphe de la fonction \( \Gamma\) d'Euler\cite{KXjFWKA}]   \label{ThoZJYooWKfbVz}
    Nous considérons la formule
    \begin{equation}
        \Gamma(z)=\int_0^{\infty} e^{-t}t^{z-1}dt.
    \end{equation}
    Alors
    \begin{enumerate}
        \item
            Cette formule définit une fonction holomorphe sur
            \begin{equation}
                \mP=\{ z\in \eC\tq \Re(z)>0 \}.
            \end{equation}
        \item
            La fonction \( \Gamma\colon \mP\to \eC\) admet un unique prolongement méromorphe sur \( \eC\), lequel a des pôles sur les entiers négatifs.
    \end{enumerate}
\end{theorem}
\index{fonction!\( \Gamma\) d'Euler}
\index{prolongement!méromorphe de la fonction \( \Gamma\)}
\index{fonction!définie par une intégrale!\( \Gamma\) d'Euler}
\index{fonction!méromorphe!\( \Gamma\) d'Euler}

\begin{proof}
    \begin{subproof}
        \item[Holomorphie sous l'intégrale]

            Pour étudier l'holomorphie de la fonction \( \Gamma\) sur \( \mP\) nous utilisons le théorème~\ref{ThopCLOVN}.

            Nous considérons la fonction
            \begin{equation}
                \begin{aligned}
                    g\colon \mP\times \eR^+&\to \eC \\
                    (z,t)&\mapsto  e^{-t}z^{z-1}
                \end{aligned}
            \end{equation}
            et nous commençons par montrer que c'est holomorphe en \( z\) pour chaque \( t>0\) fixé. Nous le vérifions par le critère de \( \partial_{\bar zf=0}\)\footnote{Théorème~\ref{PropkwIQwg}.} et en nous souvenant que \( t^i= e^{\ln(t^i)}= e^{i\ln(t)}\). Nous obtenons rapidement que
            \begin{equation}
                \frac{ \partial g }{ \partial \bar z }=0.
            \end{equation}

            Le fait que la fonction \( t\mapsto g(z,t)\) soit mesurable pour tout \( z\) est d'accord.

            Et enfin soit \( K\) compact dans \( \mP\). Il faut trouver une fonction \( g_K(t)\) intégrable sur \( \mathopen[ 0 , \infty [\) telle que pour tout \( z\in K\) et \( t\in\mathopen[ 0 , \infty [\) nous ayons \( | f(z,t)\leq g(t) |\). Pour cela nous majorons séparément les parties \( t\in\mathopen] 0 , 1 \mathclose[\) et \( t\geq 1\).

            Soit donc \( K\) compact dans \( \mP\); nous posons \( M=\max_{z\in K}\Re(z)\) et \( \epsilon=\min_{z\in K}\Re(z)\).

            Si \( t\in \mathopen] 0 , 1 \mathclose[\) alors nous avons
            \begin{equation}
                e^{-t}t^{z-1}= e^{-t} e^{(z-1)\ln(t)},
            \end{equation}
            de telle façon à que que
            \begin{subequations}
                \begin{align}
                    |  e^{-t}t^{z-1} |&\leq|  e^{(x-1+iy)\ln(t)} |\\
                    &=|   e^{(\Re(z)-1)\ln(t)} |\\
                    &=| t^{\Re(z)-1} |\\
                    &\leq | t^{\epsilon-1} |\\
                    &=\frac{1}{ t^{1-\epsilon} }.
                \end{align}
            \end{subequations}
            Cette dernière fonction est intégrable sur \( \mathopen] 0 , 1 \mathclose[\).

            Nous considérons maintenant \( t\geq 1\). Dans ce cas nous avons
            \begin{equation}
                |  e^{-t}z^{z-1} |= e^{-t}t^{\Re(z)-1}\leq  e^{-t}t^{M-1}.
            \end{equation}
            Cette dernière fonction est un produit d'une exponentielle décroissante avec un polynôme. C'est donc intégrable entre \( 1\) et l'infini.

            La fonction \( g_K\) que nous considérons est donc
            \begin{equation}
                g_K(t)=\begin{cases}
                    \frac{1}{ t^{1-\epsilon} }    &   \text{si } t<1\\
                    \text{borné}    &    \text{si } 1\leq t\leq b\\
                    e^{-t}t^{M-1}    &    \text{si } t>b.
                \end{cases}
            \end{equation}
            Cela est une fonction intégrable sur \( \mathopen] 0    \infty ,  \mathclose[\) et qui majore \( f\) uniformément en \( z\) sur le compact \( K\) de \( \mP\). Le théorème~\ref{ThopCLOVN} nous permet donc de conclure que
            \begin{equation}
                \Gamma(z)=\int_0^{\infty}f(z,t)dt
            \end{equation}
            est holomorphe en \( z\) sur \( \mP\) et que
            \begin{equation}
                \Gamma'(z)=\int_0^{\infty}\frac{ \partial f }{ \partial z }(z,t)dt.
            \end{equation}

        \item[En deux morceaux] Nous passons maintenant à la seconde partie du théorème. Pour \( z\in \mP\) nous coupons l'intégrale en deux :
            \begin{equation}
                \Gamma(z)=\int_0^1 e^{-t}t^{z-1}dt+\int_1^{\infty} e^{-t}t^{z-1}dt
            \end{equation}

        \item[Première partie] Nous commençons par parler de la première partie : \( \int_0^1 e^{-t}t^{z-1}dt\) dans laquelle nous voulons utiliser le développement en série de l'exponentielle \(  e^{-t}\). Nous devons donc traiter
            \begin{equation}
                \int_0^1\sum_{n=0}^{\infty}\frac{ (-1)^n }{ n! }t^{n+z-1}dt.
            \end{equation}
            Nous allons permuter la somme avec l'intégrale à l'aide du théorème de Fubini~\ref{ThoFubinioYLtPI} en posant la fonction
            \begin{equation}
                g(n,t)=\frac{ (-1)^n }{ n! }t^{n+z-1}
            \end{equation}
            et en considérant le produit entre la mesure de Lebesgue sur \( \eC\) et la mesure de comptage sur \( \eN\), c'est-à-dire que nous étudions
            \begin{equation}
                \int_0^1\int_{\eN}g(n,t)dndt.
            \end{equation}
            Pour permuter il suffit de prouver que \( | g |\) est intégrable pour la mesure produit, c'est-à-dire que
            \begin{equation}
                \int_0^1\int_{\eN}\left| \frac{ (-1)^n }{ n! }t^{n+z-1} \right| <\infty.
            \end{equation}
            Nous avons \( | t^z=t^{\Re(z)} |\), donc
            \begin{equation}
                \sum_{n=0}^{\infty}\left| \frac{ t^{n+z-1} }{ n! } \right| =t^{\Re(z)-1}\sum_{n=0}^{\infty}\frac{ t^n }{ n! }=t^{\Re(z)-1} e^{t}.
            \end{equation}
            Étant donné que nous avons fixé \( z\in\mP\), nous avons \( \Re(z)-1>-1\) et donc \( t^{\Re(z)-1}\) est intégrable entre \( 0\) et \( 1\).
            %TODO : il faudrait prouver et citer ici le coup du 1/x^alpha qui est intégrable ou non.
            La partie \(  e^{t}\) se majore sur \( \mathopen[ 0 , 1 \mathclose]\) par une constante quelconque. Nous avons donc payé le droit d'inverser la somme et l'intégrale :
            \begin{equation}
                \int_0^1 e^{-t}t^{z-1}dt=\sum_{n=0}^{\infty}\int_0^1\frac{ (-1)^n }{ n! }t^{n+z-1}dt=\sum_{n=0}^{\infty}\frac{ (-1)^n }{ n! }[t^{n+z}]_0^1=\sum_{n=0}^{\infty}\frac{ (-1)^n }{ n!(n+z) }.
            \end{equation}
            Nous avons donc l'intéressante formule suivante, valable pour tout \( z\in\mP\) :
            \begin{equation}
                \Gamma(z)=\sum_{n=0}^{\infty}\frac{ (-1)^n }{ n!(n-z) }+\int_1^{\infty} e^{-t}t^{z-1}dt.
            \end{equation}

        \item[Prolongation de la première partie] Nous voudrions montrer maintenant que la fonction
            \begin{equation}
                \sum_{n=0}^{\infty}\frac{ (-1)^n }{ n!(n-z) }
            \end{equation}
            est méromorphe sur \( \eC\) avec des pôles en les entiers négatifs. Pour cela nous considérons la suite de fonctions
            \begin{equation}
                f_n(z)=\frac{ (-1)^n }{ n!(z+n) }
            \end{equation}
            et nous allons utiliser la proposition~\ref{PropPUZTQKl}. Si \( n\geq 0\), la fonction \( f_n\) est méromorphe sur \( \eC\) avec un pôle simple en \( z=-n\). Soit \( K\) compact de \( \eC\) et \( N_K\) tel que \( K\subset\overline{ B(0,N_K) }\). Pour \( n\geq N_K+1\), la fonction \( f_n\) n'a pas de pôle dans \( K\) et de plus pour tout \( z\in K\) nous avons
            \begin{equation}
                | z+n |=| z-(-z) |\geq\big| n-| z | \big|\geq n-| z |\geq n-N_K,
            \end{equation}
            et par conséquent
            \begin{equation}
                | f_n(z) |\leq \frac{1}{ n!(n-N) },
            \end{equation}
            ou pour le dire de façon plus snob :
            \begin{equation}
                \| f_n \|_{\infty,K}\leq \frac{1}{ n!(n-N) },
            \end{equation}
            dont la série converge. Cela signifie que la série \( \sum_{n\geq N}f_n\) converge normalement\footnote{Définition~\ref{DefVBrJUxo}.} sur \( K\), donc la fonction
            \begin{equation}
                f(z)=\sum_{n=0}^{\infty}f_n(z)
            \end{equation}
            est une fonction méromorphe dont les pôles sont ceux des \( f_n\), c'est-à-dire les entiers négatifs (proposition~\ref{PropPUZTQKl}).

        \item[La seconde partie]

            Nous allons à présent prouver que la fonction
            \begin{equation}
                g(z)=\int_1^{\infty} e^{-t}t^{z-1}dt
            \end{equation}
            est holomorphe sur \( \eC\). Pour cela nous considérons la fonction de deux variables \( f(z,t)= e^{-t}t^{z-1}\) et nous utilisons le théorème d'holomorphie sous l'intégrale~\ref{ThopCLOVN}. D'abord pour \( z_0\) fixé dans \( \eC\) nous avons
            \begin{equation}
                \int_1^{\infty}|  e^{-t}t^{z_0-1} |\leq \int_1^{\infty} e^{-t}t^{\Re(z_0)-1}dt,
            \end{equation}
            donc l'intégrale converge parce que c'est polynôme contre exponentielle. Par ailleurs pour chaque \( t_0\) fixé sur \( \mathopen[ 0 , \infty [\), la fonction \( z\mapsto  e^{-t_0}t_0^{z-1}\) est holomorphe sur \( \eC\) comme en témoigne le calcul suivant :
                \begin{equation}
                    \frac{ 1 }{2}\left( \frac{ \partial  }{ \partial x }+i\frac{ \partial  }{ \partial y } \right)t_0^{x+iy-1}=0.
                \end{equation}
                Et enfin si \( K\) est compact dans \( \eC\) nous avons
                \begin{equation}
                    | f(z,t) |=|  e^{-t}t^{z-1} |= e^{-t}| t^{\Re(z)-1} |\leq  e^{-t}t^{M-1}
                \end{equation}
                où \( M=\max_{z\in K}\Re(z)\). Nous en déduisons que la fonction
                \begin{equation}
                    z\mapsto\int_1^{\infty} e^{-t}t^{z-1}dt
                \end{equation}
                est une fonction holomorphe sur \( \eC\).

            \item[Conclusion]

                Au final nous avons prouvé que la fonction \( \Gamma\) d'Euler admet le prolongement méromorphe sur \( \eC\) donné par
                \begin{equation}
                    \Gamma(z)=\sum_{n=0}^{\infty}\frac{ (-1)^n }{ n!(z+n) }+\int_1^{\infty} e^{-t}t^{z-1}dt.
                \end{equation}
    \end{subproof}
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Euler et factorielle}
%---------------------------------------------------------------------------------------------------------------------------

\begin{proposition}
    Nous avons la formule \( \Gamma(n)=(n-1)!\) pour tout \( n\in \eN\).
\end{proposition}

\begin{proof}
    Nous partons de la formule
    \begin{equation}
        \Gamma(n)=\int_0^{\infty} e^{-t}t^{n-1}dt
    \end{equation}
    que nous intégrons par partie en posant
    \begin{equation}
        \begin{aligned}[]
            u&=t^{n-1}&u'&=(n-1)t^{n-1}\\
            v&= e^{-t}&v'&=- e^{-t}.
        \end{aligned}
    \end{equation}
    Les termes au bord s'annulent (ici il y a un passage à la limite qui n'est pas écrit) et nous trouvons
    \begin{equation}
        \Gamma(n)=\int_0^{\infty}(n-1) e^{-t}t^{n-2}dt=(n-1)\Gamma(n-1).
    \end{equation}

    Pour conclure il suffit de remarquer que
    \begin{equation}
        \Gamma(1)=\int_0^{\infty}=-[ e^{-t}]_0^{\infty}=1.
    \end{equation}
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Partition d'un entier en parts fixées}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\index{partition!d'un entier en parts fixées}

\begin{proposition}[\cite{KXjFWKA}]     \label{PropWUFpuBR}
    Soient \( a_1,\ldots, a_k\in \eN^*\) des entiers premiers entre eux dans leur ensemble. Pour \( n\geq 1\) nous posons
    \begin{equation}
        u_n=\Card\left\{  (x_1,\ldots, x_k)\in \eN^*\tq \sum_{i=1}^ka_ix_i=n \right\},
    \end{equation}
    et \( u_0=1\).

    Alors nous avons l'équivalence de suite (pour \( n\to \infty\)) :
    \begin{equation}
        u_n\sim\frac{1}{ a_1\ldots a_k }\frac{ n^{k-1} }{ (k-1)! }.
    \end{equation}
\end{proposition}
\index{série!entière!utilisation}
\index{série!génératrice d'une suite!utilisation}
\index{anneau!de séries formelles!utilisation}
\index{corps!des fractions rationnelles!utilisation}

\begin{proof}
    Pour chacun des \( i\in\{ 1,\ldots, k \}\) nous considérons la série entière
    \begin{equation}
        \sum_{x=0}^{\infty}z^{xa_i}=\sum_k(z^{a_i})^x.
    \end{equation}
    Étant donné que \( | z^{a_i} |<1\) si et seulement si \( | z<1 |\), cette série a un rayon de convergence égal à \( 1\). Nous allons calculer le produit de Cauchy de ces \( k\) séries, en nous souvenant que le théorème~\ref{ThokPTXYC} nous assure que la série résultante aura un rayon de convergence au moins égal à \( 1\) et vaudra le produit des différentes séries.

    Le coefficient de \( z^n\) dans cette série vaut
    \begin{equation}
        \sum_{\substack{x\in \eN^k\\\sum x_ia_i=n}}1=u_n
    \end{equation}
    parce que dans chacune des séries, le coefficient de tous les \( z^{xa_i}\) est \( 1\). Nous définissons la fonction
    \begin{equation}    \label{EqKTRNFSl}
        f(z)=\sum_{n=0}^{\infty}u_nz^n=\prod_{i=1}^k\left( \sum_{x=0}^{\infty}z^{xa_i} \right)=\prod_{i=1}^k\frac{1}{ 1-z^{a_i} }.
    \end{equation}
    La fonction \( f\) existe sur \( | z |<1\) parce que nous venons de voir qu'elle peut  s'exprimer comme un produit de Cauchy; et la dernière égalité est simplement la somme de la série harmonique. D'autre part la fonction \( f\) est la série génératrice de la suite \( (u_n)\).

    Nous sommes en présence d'une fonction ayant des pôles aux racines \( a_1\),\ldots, \( a_k\)\ieme\ de l'unité. Étant donné que \( 1\) est une racine de l'unité de tous les ordres, le pôle en \( z=1\) est de multiplicité \( k\). Les autres pôles sont de multiplicité strictement inférieure; en effet soit \( \omega\in \eC\) tel que \( \omega^{a_i}=1\) pour tout \( i\). Alors Bezout\footnote{Théorème~\ref{ThoBuNjam}.} nous donne des entiers \( v_i\in \eZ\) tels que \( \sum_iv_ia_i=1\). Alors nous avons
%TODO : il faudrait citer ici un théorème de Bezout pour les ensembles de nombres premiers dans leur ensemble; le théorème cité ici n'est pas suffisant.
    \begin{equation}
        \omega=\omega^{\sum_{v_ia_i}}=\prod_{i=1}^k(\omega^{a_i})^{v_i}=1.
    \end{equation}
    Donc nous voyons que \( 1\) est le seul à être racine de tous les ordres en même temps. Nous notons
    \begin{equation}
        P=\{ \omega_1,\ldots, \omega_p \}
    \end{equation}
    l'ensemble des pôles avec \( \omega_1=1\). Par ailleurs la fonction \( f\) est une fraction rationnelle dont nous connaissons les racines du dénominateur (ce sont les \( \omega_i\)) et à peu près leurs ordres. Nous utilisons le truc de la décomposition en fractions simples
%TODO : après avoir fait la décomposition en fractions simples, il faut mettre une référence ici.
    en séparant le terme de puissance \( k\) qui n'existe que pour la racine \( \omega_1=1\) :
    \begin{equation}    \label{EqDLTJaYr}
        f(z)=\frac{ \alpha }{ (1-z)^k }+\sum_{i=1}^p\sum_{j=1}^{k-1}\frac{ c_{ij} }{ (\omega_i-z)^j }.
    \end{equation}
    Ce développement est valable pour tout \( | z |<1\). Nous considérons maintenant \( \omega\in P\) et \( j\in \eN\) et nous étudions la fonction
    \begin{equation}
        g(z)=\frac{1}{ \omega-z }.
    \end{equation}
    Un rapide calcul (par exemple par récurrence) montre que
    \begin{equation}    \label{EqEJLDIFJ}
        g^{(k)}(z)=\frac{ k! }{ (\omega-z)^{k+1} },
    \end{equation}
    et étant donné que \( | \omega |=1\) nous pouvons écrire la série
    \begin{equation}
        \frac{1}{ \omega-z }=\sum_{k=0}^{\infty}\frac{ z^k }{ \omega^{k+1} },
    \end{equation}
    valable pour \( | z |<1\). Ce qui nous intéresse, c'est d'exprimer une série pour \( 1/(\omega-z)^j\); et voyant \eqref{EqEJLDIFJ}, nous voyons qu'il suffit de calculer les dérivées de la série de \( g\). Nous dériver terme à terme à l'intérieur du rayon de convergence. Avec quelques abus d'écriture, et en utilisant la bête formule \eqref{EqSOFdwhw} nous avons\quext{À ce niveau j'ai pas exactement le même coefficient binomial que dans \cite{KXjFWKA}, mais je n'exclus absolument pas que ce soit moi qui me trompe. Écrivez-moi si vous pouvez infirmer ou confirmer l'erreur. Quoi qu'il en soit, cela ne change pas le résultat asymptotique que nous cherchons.}
    \begin{subequations}
        \begin{align}
            \frac{1}{ (\omega-z)^j }&=\frac{ g^{(j-1)}(z) }{ (j-1)! }\\
            &=\frac{1}{ (j-1)! }\left( \frac{1}{ \omega-z } \right)^{(j-1)}\\
            &=\frac{1}{ (j-1)! }\sum_{k=0}^{\infty}\frac{1}{ \omega^{k+1} }(z^k)^{(j-1)}\\
            &=\sum_{k=j-^{\infty}}\frac{1}{ (j-1)! }\frac{1}{ \omega^{k+1} }\frac{ k! }{ (k-j+1)! }z^{k-j+1}\\
            &=\sum_{n=0}^{\infty}\frac{1}{ \omega^{n+j} }\frac{ (n+j-1)! }{ n!(j-1)! }z^n\\
            &=\sum_{n=0}^{\infty}\frac{1}{ \omega^{n+j} }{n+j-1\choose n}z^n.
        \end{align}
    \end{subequations}
    Nous pouvons utiliser cela pour récrire la formule \eqref{EqDLTJaYr} de façon considérablement plus compliquée :
    \begin{equation}
            f(z)=\alpha\sum_{n=0}^{\infty}{n+j-1\choose n}z^n
            +\sum_{i=1}^p\sum_{j=1}^{k-1}\sum_{n=0}^{\infty}c_{ij}{n+j-1\choose n}\frac{ z^n }{ \omega_i^{n+j} }.
    \end{equation}
    Mais nous savons que ce \( f\) est la série génératrice de la suite \( (u_n)\) et que nous pouvons donc utiliser la formule \eqref{EqNGhVCpP} pour exprimer les nombres \( u_l\) : \( u_l\) est simplement le coefficient de \( z^l\) divisé par \( l!\). C'est-à-dire
    \begin{equation}
        u_l=\alpha{l+k-1\choose l}+\sum_{i=1}^p\sum_{j=1}^{k-1}c_{ij}{l+j-1\choose l}\frac{1}{ \omega_i^{l+j} }.
    \end{equation}
    Notre boulot est d'examiner le comportement de cela lorsque \( l\to\infty\), c'est-à-dire regarder quels sont les puissances de \( l\) en présence. Notons que

    En ce qui concerne le premier terme, la puissance dominante dans le coefficient binomial est \( l^{k-1}\). Dans les autres termes\footnote{Attention : les termes \( i=1\) ont \( \omega_1=1\) et il n'est donc pas possible de conclure simplement en disant que \( \omega_i^{l-j}\to 0\) pour \( l\to \infty\); bien que cela soit vrai pour tous les \( i\neq 1\).}, c'est \( l^{j-1}\) qui est de degré moins grand. Donc le comportement de \( u_l\) en terme de \( l\) est
    \begin{equation}
        u_l\sim \alpha\frac{ l^{k-1} }{ (k-1)! }.
    \end{equation}
    Il nous reste à voir ce que vaut \( \alpha\). Pour cela nous repartons de l'expression~\ref{EqKTRNFSl} que nous écrivons sous la forme
    \begin{equation}
        (1-z)^kf(z)=\prod_{i=1}^{k}\frac{ 1-z }{ 1-z^{a_i} }.
    \end{equation}
    Nous reconnaissons l'inverse d'une somme harmonique partielle :
    \begin{equation}    \label{EqTIAxvHE}
        (1-z)^kf(z)=\prod_{i=1}^k\frac{1}{ 1+z+z^2+\cdots +z^{a_i-1} }.
    \end{equation}
    Par ailleurs, nous ne savons pas si \( f(1)\) existe parce que son rayon de convergence n'est que de \( 1\); et nous savons même qu'elle n'existe pas (parce que ce serait la somme des \( u_n\)). Mais nous savons aussi que le pôle de plus grande multiplicité de \( f\) est en \( z=1\) et est de multiplicité \( k\). Donc \( (1-z)^kf(z)\) devrait converger pour \( z\to 1\). Pour tout \( | z<1 |\) nous avons
    \begin{equation}
        (1-z)^kf(z)=\alpha+\sum_{i=1}^p\sum_{j=1}^{k-1}c_{ij}\frac{ (1-z)^k }{ (\omega_i-z)^j }.
    \end{equation}
    Lorsque \( z\to 1\), tous les termes des sommes tendent vers zéro, y compris ceux avec \( i=1\) parce que \( j<k\). Il reste donc
    \begin{equation}
        \lim_{z\to 0} (1-z)^kf(z)=\alpha.
    \end{equation}
    En calculant la même limite avec \eqref{EqTIAxvHE} nous trouvons
    \begin{equation}
        \lim_{z\to 1}(1-z)^kf(z)=\lim_{z\to 1}\prod_{i=1}^k\frac{1}{ 1+z+z^2+\cdots +z^{a_i-1} }=\frac{1}{ a_1\ldots a_k }.
    \end{equation}
    Donc
    \begin{equation}
        \alpha=\frac{1}{ a_1\ldots a_k },
    \end{equation}
    et le résultat est prouvé.

\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Exponentielle et logarithme complexe}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Propriétés de l'exponentielle}
%---------------------------------------------------------------------------------------------------------------------------

\begin{proposition}
    Soit \( z\in\eC\) fixé. La fonction
    \begin{equation}
        \begin{aligned}
            E\colon \eR&\to \eC \\
            t&\mapsto  e^{tz}
        \end{aligned}
    \end{equation}
    est  \(  C^{\infty}\), sa dérivée est
    \begin{equation}
        E'(t)=z e^{tz}.
    \end{equation}
    La fonction \( E\) est développable en série entière (voir définition~\ref{DefwmRzKh}) sur \( \eR\) en \( t=0\) et
    \begin{equation}
        e^{tz}=\sum_{n=0}^{\infty}\frac{ z^n }{ n! }t^n.
    \end{equation}
\end{proposition}

\begin{proof}
    Nous fixons \( z\in \eC\). Par définition~\ref{DefJilXoM}, la série suivante est \(  e^{tz}\) :
    \begin{equation}
        f(t)=\sum_{n=0}^{\infty}\frac{ z^n }{ n! }t^n.
    \end{equation}
    Cette série a un rayon de convergence infini et la fonction \( f\) est donc \(  C^{\infty}\) sur \( \eR\). Nous pouvons la dériver terme à terme :
    \begin{equation}
            f'(t)=\sum_{n=1}^{\infty}\frac{ z^n }{ n! }nt^{n-1}
            =z\sum_{n=1}^{\infty}\frac{ z^{n-1} }{ (n-1)! }t^{n-1}
            =z e^{tz}.
    \end{equation}
\end{proof}

\begin{theorem}     \label{THOooNGOIooEECfAv}
    La fonction exponentielle vérifie les propriétés suivantes.
    \begin{enumerate}
        \item
            \( \exp\) est holomorphe\footnote{Définition \ref{DefMMpjJZ}.}.
        \item
            \( (e^z)'=e^z\).
        \item
            L'exponentielle est développable en série entière,
            \begin{equation}
                e^z=\sum_{n=0}^{\infty}\frac{ z^n }{ n! }
            \end{equation}
            et la série converge normalement sur tout compact de \( \eC\).
    \end{enumerate}
\end{theorem}

\begin{proof}
    En tant que application \( E\colon \eR^2\to \eC\), la fonction
    \begin{equation}
        E(x,y)=e^x(\cos y+i\sin y)
    \end{equation}
    est \( C^{\infty}\). De plus nous avons
    \begin{subequations}
        \begin{align}
            \frac{ \partial E }{ \partial x }(x,y)= e^{x+iy}=E(x,y)\\
            \frac{ \partial E }{ \partial y }(x,y)=iE(x,y),
        \end{align}
    \end{subequations}
    et par conséquent la fonction \( E\) vérifie les équations de Cauchy-Riemann.

    Si \( r\) est fixé, par le critère d'Abel appliqué à la suite \(r/n!\) nous savons que la série \( \sum z^n/n!\) converge normalement sur le compact \( B(0,r)\).
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Intégrale de Fresnel}
%---------------------------------------------------------------------------------------------------------------------------

Nous allons calculer l'\defe{intégrale de Fresnel}{intégrale!Fresnel}\index{Fresnel!intégrale}
\begin{equation}
    \int_0^{\infty} e^{-ix^2}dx=\frac{ \sqrt{\pi} }{ 2 } e^{-i\pi/4}
\end{equation}
en suivant la démarche présentée par Wikipédia\cite{ooOXWGooGhLJvX}. Nous commençons par prouver que l'intégrale est convergente en nous contentant de justifier la convergence de
\begin{equation}
    \int_0^{\infty}\sin(x^2)dx.
\end{equation}
Pour chaque \( a>0\) fixé, l'intégrale \( \int_0^a\sin(x^2)dx\) ne pose pas de problèmes. Le lemme \ref{LemTHBSEs} nous permet de passer à la limite; nous devons donc seulement calculer
\begin{equation}
    \lim_{b\to \infty}\int_a^b\sin(x^2)dx
\end{equation}
où \( a\) est une constante strictement positive. Nous effectuons une intégration par partie en posant
\begin{subequations}
    \begin{align}
        u&=\frac{1}{ x }&   u'&=-\frac{1}{ x^2 }\\
        v'&=x\sin(x)    & v&=\frac{ 1-\cos(x) }{2}.
    \end{align}
\end{subequations}
Notons que la primitive \( v\) a été choisie pour avoir \( v(0)=0\). Nous avons
\begin{equation}    \label{EqOdeKye}
    \int_a^b\sin(x^2)dx=\left[ \frac{ 1-\cos(x^2) }{ 2x } \right]_a^b-\int_a^b\frac{ \cos(x^2)-1 }{ 2x^2 }dx
\end{equation}
Pour le premier terme nous avons
\begin{equation}
    \lim_{b\to \infty}\left[ \frac{ 1-\cos(x^2) }{ 2x } \right]_a^b=\lim_{b\to \infty}\frac{ 1-\cos(b^2) }{ 2b }-\frac{ 1-\cos(a^2) }{ 2a }=-\frac{ 1-\cos(a^2) }{ 2a }.
\end{equation}
C'est borné. Pour le second terme de \eqref{EqOdeKye}, la fonction
\begin{equation}
    \frac{ \cos(x^2)-1 }{ 2x^2 }
\end{equation}
est majorée par la fonction \( 1/x^2\) qui est intégrable entre \( a\) et \( \infty\).


Nous allons calculer l'intégrale demandée en passant par la fonction
\begin{equation}
    f(x)= e^{-z^2}
\end{equation}
définie sur le plan complexe. Nous l'intégrons sur le chemin \( \gamma=\gamma_1+\gamma_2-\gamma_3\) indiqué à la figure~\ref{LabelFigCheminFresnel}.
\newcommand{\CaptionFigCheminFresnel}{Chemin d'intégration pour l'intégrale de Fresnel}
\input{auto/pictures_tex/Fig_CheminFresnel.pstricks}
Ces chemins sont donnés par
\begin{equation}
    \begin{aligned}
        \gamma_1\colon \mathopen[ 0 , R \mathclose]&\to \eC \\
        t&\mapsto t,
    \end{aligned}
\end{equation}
\begin{equation}
    \begin{aligned}
        \gamma_2\colon \mathopen[ 0 , \frac{ \pi }{ 4 } \mathclose]&\to \eC \\
        t&\mapsto R e^{it},
    \end{aligned}
\end{equation}
\begin{equation}
    \begin{aligned}
        \gamma_3\colon \mathopen[ 0 , R \mathclose]&\to \eC \\
        t&\mapsto t e^{i\pi/4}.
    \end{aligned}
\end{equation}
Tout d'abord la fonction \( f\) est bien holomorphe par le critère du théorème~\ref{PropkwIQwg}. Le calcul de \( \frac{ \partial f }{ \partial \bar z }\) se fait simplement en posant \( f(x,y)= e^{-(x+iy)^2}\). Le calcul est usuel :
\begin{verbatim}
----------------------------------------------------------------------
| Sage Version 4.8, Release Date: 2012-01-20                         |
| Type notebook() for the GUI, and license() for information.        |
----------------------------------------------------------------------
sage: f(x,y)=exp(-(x+I*y)**2)
sage: A=f.diff(x)+I*f.diff(y)
sage: A.simplify_full()
(x, y) |--> 0
\end{verbatim}
Nous avons donc
\begin{equation}    \label{EqfaoRgU}
    0=\int_{\gamma}f=\underbrace{\int_0^R e^{-t^2}dt}_{I_1(R)}+\underbrace{\int_0^{\pi/4} e^{-R^2 e^{2it}}Ri e^{it}dt}_{I_2(R)}+\underbrace{\int_0^R e^{-t^2 e^{i\pi/2}} e^{i\pi/4}dt}_{I_3(R)}.
\end{equation}
L'intégrale est nulle pour tout \( R\) en vertu de la proposition~\ref{PrpopwQSbJg}. L'intégrale \( I_1\) est une gaussienne et nous avons
\begin{equation}
    \lim_{R\to\infty}I_1(R)=\frac{ \sqrt{\pi} }{ 2 }
\end{equation}
par l'exemple~\ref{EXooLUFAooGcxFUW}. Nous montrons maintenant que \( \lim_{R\to\infty}| I_2(R) |=0\)\footnote{Il y a moyen de démontrer cela via le lemme de Jordan\cite{FresnelDavidS}. Nous donnons ici une démonstration moins technologique.}. D'abord nous majorons en prenant la norme puis nous effectuons le changement de variables \( u=2t\) :
\begin{subequations}
    \begin{align}
        | I_2(R) |&\leq \int_{0}^{\pi/4}R e^{-R^2\cos(2t)}dt\\
        &=\frac{ R }{ 2 }\int_0^{\pi/2} e^{-R^2\cos(u)}du.
    \end{align}
\end{subequations}
Nous savons que le graphe du cosinus est concave : il reste au dessus de la droite que joint \( (0,1)\) à \( (\frac{ \pi }{2},0)\). Du coup \( \cos(u)\geq 1-\frac{ 2 }{ \pi }u\) et par conséquent
\begin{equation}
        e^{-R^2\cos(u)}\leq  e^{-R^2(1-\frac{ 2 }{ \pi }u)}= e^{R^2(\frac{ 2 }{ \pi }u-1)}.
\end{equation}
Nous effectuons l'intégrale
\begin{subequations}
    \begin{align}
        | I_2(R) |&\leq \frac{ R }{2}\int_0^{\pi/2} e^{-R^2} e^{\frac{ 2R^2 }{ \pi }u}du\\
        &=\frac{ R }{2} e^{-R^2}\left[ \frac{ \pi }{ 2R^2 } e^{2R^2 u/\pi} \right]_0^{\pi/2}\\
        &=\frac{ \pi }{ 4R }-\frac{ \pi e^{-R^2} }{ 4R },
    \end{align}
\end{subequations}
et nous avons bien \( \lim_{R\to\infty}| I_2(R) |=0\). Nous passons à la troisième intégrale. En tenant compte que \(  e^{i\pi/2}=i\), nous avons
\begin{subequations}
    \begin{align}
        I_3(R)&=-\int_0^R e^{-\gamma_3(t)^2} e^{i\pi/4}dt\\
        &=-\frac{ 1+i }{ \sqrt{2} }\int_0^R e^{-t^2} e^{2i\pi/4}\\
        &=-\frac{ 1+i }{ \sqrt{2} }\int_0^R e^{-it^2}.
    \end{align}
\end{subequations}
En passant à la limite \( R\to 0 \), de l'équation \eqref{EqfaoRgU} il ne reste que
\begin{equation}
    0=\frac{ \sqrt{2} }{2}-\frac{ 1+i }{ \sqrt{2} }\int_0^{\infty} e^{-it^2}dt,
\end{equation}
ce qui signifie que
\begin{equation}
    \int_0^{\infty} e^{-it^2}dt=\frac{ \sqrt{2\pi} }{ 2(1+i) }=\frac{ \sqrt{\pi} }{2} e^{-i\pi/4}.
\end{equation}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Logarithme complexe}
%---------------------------------------------------------------------------------------------------------------------------


%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{La fonction argument}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Nous savons la définition~\ref{DefJilXoM} de l'exponentielle complexe.

\begin{definition}
    Un \defe{logarithme}{logarithme!dans \( \eC\)} de \( \alpha\in \eC\) est une solution de l'équation \(  e^{z}=\alpha\).
\end{definition}
Notons bien que cela définit \emph{un} logarithme, et non \emph{le} logarithme.

\begin{lemma}       \label{LEMooUMESooJVzeDb}
    Si \( z_1\) et \( z_2\) sont des logarithmes de \( \alpha\) alors il existe \( k\in \eZ\) tel que \( z_1=z_2+2ik\pi\).
\end{lemma}

\begin{proof}
    Nous commençons par déterminer les logarithmes de \( \alpha=1\). Nous avons besoin de \(  e^{a+bi}=1\) (\( a,b\in \eR\)). Nous avons
    \begin{equation}
        e^{a} e^{bi}=1,
    \end{equation}
    et en prenant la norme nous trouvons \( | e^a |=1\), ce qui donne \( a=0\). Ensuite \(  e^{bi}=1\), qui signifie \( b=2k\pi\). Les logarithmes de \( 1\) sont donc les nombres de la forme \( 2ik\pi\).

    Soient maintenant \( z_1\) et \( z_2\) des logarithmes de \( \alpha\). Alors \(  e^{z_1}= e^{z_2}\), donc\footnote{C'est facile de dire «donc». Il faut surtout citer la proposition~\ref{PropdDjisy}\ref{ITEMooRLHCooJTuYKV}.} \(  e^{z_1-z_2}=1\), ce qui signifie que \( z_1-z_2\) est un logarithme de \( 1\). Donc il existe un \( k\in \eZ\) tel que \( z_1-z_2=2ik\pi\).
\end{proof}

\begin{remark}
    Jusqu'ici nous n'avons pas donné de conditions donnant l'existence d'un logarithme. Nous avons seulement supposé des existences et donné des propriétés sur ces hypothétiques objets.
\end{remark}

\begin{definition}[\cite{ooDQKTooXNjklV}]
Si \( z\in \eC^*\) nous définissons la \defe{valeur principale}{valeur principale} de son argument le nombre \( \theta\in \mathopen] -\pi , \pi \mathclose]\) tel que
\begin{equation}
    z=| z | e^{i\theta}
\end{equation}
Nous le notons \( \arg(z)\)\nomenclature[Y]{\( \arg(z)\)}{La valeur principale de l'argument de \( z\in \eC\)}.
\end{definition}

\begin{normaltext}      \label{NORMooOGHNooYriCBH}
    Il ne faut pas se ruer sur \( \arg(x+iy)=\arctan(y/x)\). Pour rappel, la fonction \( \arctan\) a été définie dans le théorème~\ref{THOooUSVGooOAnCvC}, et elle prend ses valeurs dans \( \mathopen] -\pi/2 , \pi/2 \mathclose[\). La formule \( v(x,y)=\arctan(y/x)\) n'est donc valable que pour \( x>0\). Les valeurs sont :
        \begin{equation}        \label{EQooPJVFooSEKTny}
            \arg(x+iy)=\begin{cases}
                 \arctan(y/x)   &   \text{si } x>0\\
                 \pi+\arctan(y/x)    &    \text{si } x<0\text{ et }y\geq 0 \\
                 -\pi+\arctan(y/x)    &    \text{si } x<0 \text{ et }y<0\\
                 \frac{ \pi }{ 2 }    &    \text{si } x=0 \text{ et }y>0\\
                 \frac{- \pi }{ 2 }    &    \text{si } x=0 \text{ et }y<0.
            \end{cases}
        \end{equation}

    Pour \( x>0\) nous avons \( \arg(x+iy)=\arctan(y/x)  \) parce que justement la fonction \( \arctan\) prend ses valeurs en particulier entre \( -\pi\) et \( \pi\). Pour \( x<0\) et \( y>0 \) nous avons \( \arg(x+iy)=\pi+\arctan(y/x)\) (dans ce cas, \( \arctan(y/x)<0\)) et si \( x<0\), \( y<0\) nous avons \( \arg(x+iy)=-\pi+\arctan(y/x)\).
\end{normaltext}

\begin{normaltext}[Les dérivées partielles de la fonction argument]     \label{NORMooMRBEooVtTcIA}
    Vu que nous en aurons besoin plusieurs fois, nous calculons maintenant les dérivées partielles de la fonction
    \begin{equation}
        \begin{aligned}
            \varphi\colon \eR^2&\to \eR \\
            (x,y)&\mapsto \arg(x+iy).
        \end{aligned}
    \end{equation}
    Nous commençons par la dérivée \( \partial_x\varphi(x,y)\). Et il y a de nombreux cas à séparer.
    \begin{subproof}

         \item[\( x>0\)]

             Nous avons
             \begin{equation}
                 \frac{ \partial \varphi }{ \partial x }(x,y)=\lim_{\epsilon\to 0}\frac{ \arctan(y/(x+\epsilon))-\arctan(y/x) }{ \epsilon },
             \end{equation}
             qui n'est autre que la dérivée de la fonction \( x\mapsto\arctan(y/x)\). Nous pouvons la calculer facilement avec le théorème~\ref{THOooUSVGooOAnCvC}\ref{ITEMooMNHLooOVhIIb} :
             \begin{equation}
                 \frac{ \partial \varphi }{ \partial x }(x,y)=-\frac{ y }{ x^2+y^2 }.
             \end{equation}

         \item[\( x<0\)]

             Nous avons
             \begin{equation}
                 \frac{ \partial \varphi }{ \partial x }(x,y)=\lim_{\epsilon\to 0}\frac{ \pm\pi+\arctan(y/(x+\epsilon))-\big( \pm\pi+\arctan(y/x) \big) }{ \epsilon }
             \end{equation}
             où les signes \( \pm\) dépendent du signe de \( y\). De toutes façons, les termes en \( \pi\) se simplifient et le calcul est le même que celui du cas \( x>0\). Encore une fois nous avons
             \begin{equation}
                 \frac{ \partial \varphi }{ \partial x }(x,y)=-\frac{ y }{ x^2+y^2 }.
             \end{equation}

         \item[\( x=0\)]

             Nous devons calculer
             \begin{equation}
                 \frac{ \partial \varphi }{ \partial x }(0,y)=\lim_{\epsilon\to 0}\frac{ \arg(\epsilon+ iy)-\arg(iy) }{ \epsilon }.
             \end{equation}
             Il y a quatre cas d'après les signes de \( \epsilon\) (séparer limite à gauche et à droite) et \( y\).

             Si \( \epsilon>0\) et \( y>0\) alors nous avons à faire le calcul
             \begin{equation}
                 \lim_{\epsilon\to 0^+}\frac{ \arctan(y/\epsilon)-\pi/2 }{ \epsilon }
             \end{equation}
             qui se traite par la règle de l'Hospital. Cela donne \( -1/y\).

             Les trois autres cas ne se distinguent que par des constantes au numérateur, lesquelles disparaissent en appliquant la règle de l'Hospital\footnote{Nonobstant le fait que ces constantes se mettent bien pour avoir un vrai cas d'indétermination \( 0/0\), sinon la règle de l'Hospital ne s'applique pas.}. Au final,
             \begin{equation}
                 \frac{ \partial \varphi }{ \partial x }(0,y)=-\frac{1}{ y }.
             \end{equation}
    \end{subproof}

    Nous avons calculé jusqu'ici :
    \begin{equation}        \label{EQooAOJPooOrvUBR}
        \frac{ \partial \varphi }{ \partial x }(x,y)=\frac{ -y }{ x^2+y^2 }
    \end{equation}
    pour tout \( (x,y)\in \eR^2\setminus\{ (0,0) \}\). En particulier vous avez noté que cette dérivée partielle est continue sur \( \eR^2\setminus\{ (0,0) \}\).

    Nous calculons à présent la dérivée partielle par rapport à \( y\) :
    \begin{equation}
        \frac{ \partial \varphi }{ \partial y }(x,y)=\lim_{\epsilon\to 0}\frac{ \arg(x+iy+i\epsilon)-\arg(x+iy) }{ \epsilon }.
    \end{equation}

    \begin{subproof}

        \item[\( x>0\)]

            Nous avons à calculer
            \begin{equation}
                \lim_{\epsilon\to 0}\frac{ \arctan\frac{ y+\epsilon }{ x }-\arctan\frac{ y }{ x } }{ \epsilon },
            \end{equation}
            qui n'est autre que la dérivée de la fonction \( t\mapsto\arctan\frac{ t }{ x }\) en \( t=y\). Résultat :
            \begin{equation}
                \frac{ \partial \varphi }{ \partial y }(x,y)=\frac{ x }{ x^2+y^2 }.
            \end{equation}

        \item[\( x<0  \) et \( y\neq 0\)]

            Le calcul à faire est :
            \begin{equation}
                \lim_{\epsilon\to 0}\frac{ \pm\pi+\arctan\frac{ y+\epsilon }{ x }-\left( \pm\pi+\arctan\frac{ y }{ x } \right) }{ \epsilon }
            \end{equation}
            Une chose importante à remarquer est que dans le calcul de la limite nous pouvons supposer que \( y\) et \( y+\epsilon\) aient le même signe, quelle que soit la valeur et le signe de \( \epsilon\) (assez petit). C'est pour cela que les deux termes \( \pm\pi\) arrivent avec le même signe des deux côtés de la différence, et se simplifient. Nous tombons sur une limite déjà faite et
            \begin{equation}
                \frac{ \partial \varphi }{ \partial y }(x,y)=\frac{ x }{ x^2+y^2 }
            \end{equation}

        \item[\( x<0\) et \( y=0\)]

            Vu que \( x<0\) nous avons \( \arg(x)=\pi\) et nous devons calculer
            \begin{equation}
                \lim_{\epsilon\to 0}\frac{ \arg(x+i\epsilon)-\pi }{ \epsilon }.
            \end{equation}
            La limite \( \epsilon\to 0^+\) est classique et donne \( 1/x\).

            Mais la limite \( \epsilon\to 0^-\) n'existe pas :
            \begin{equation}
                \lim_{\epsilon\to 0^-}\frac{ -\pi+\arctan(\epsilon/x)-\pi }{ \epsilon }
            \end{equation}
            n'existe pas.

            Donc
            \begin{equation}
                \frac{ \partial \varphi }{ \partial y }(x,0)
            \end{equation}
            n'existe pas pour \( x<0\).

        \item[\( x=0\) et \( y\neq 0\)]

            Le calcul est immédiat
            \begin{equation}
                \lim_{\epsilon\to 0}\frac{ \arg(iy+i\epsilon)-\arg(iy) }{ \epsilon }=0,
            \end{equation}
            donc
            \begin{equation}
                \frac{ \partial \varphi }{ \partial y }(0,y)=0.
            \end{equation}


    \end{subproof}
    En ce qui concerne la continuité, nous avons que \( \partial_y\varphi\) est continue partout sauf sur la demi-droite \(  \{ (x,0)\tq x\leq 0 \}   \) où elle n'existe pas.

\end{normaltext}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Une définition possible du logarithme}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

\begin{definition}      \label{DEFooWDYNooYIXVMC}
    Nous définissons la fonction \defe{logarithme}{logarithme!complexe} par
    \begin{equation}
        \begin{aligned}
            \ln\colon \eC^*&\to \eC \\
            z&\mapsto \ln\big( | z | \big)+i\arg(z)
        \end{aligned}
    \end{equation}
    où le \( \ln\) à droite est le logarithme usuel sur \( \eR^+\).
\end{definition}

\begin{remark}
Cette fonction généralise le logarithme déjà vu sur \( \mathopen] 0 , \infty \mathclose[\subset \eR\). En effet pour des valeurs de \( z\) dans cette partie nous avons \( \arg(z)=0\) et \( | z |=z\).
\end{remark}

\begin{lemma}
    Le nombre \( \ln(z)\) est un logarithme de \( z\).
\end{lemma}

\begin{proof}
    Nous avons
    \begin{equation}
        e^{\ln(z)}= e^{\ln| z |} e^{i\arg(z)}=| z | e^{i\arg(z)}=z.
    \end{equation}
    Nous avons utilisé le fait que \(  e^{\ln(x)}=x\) pour \( x\in\eR^+\) et \( | z | e^{i\arg(z)}=z\) par définition de la fonction \( \arg\).
\end{proof}

Notons que si on avait pris d'autres conventions pour définir \( \arg\), nous aurions eu d'autres définitions possibles de \( \ln\).

\begin{example}
    Nous avons
    \begin{equation}
        \ln(-1)=\ln(1)+i\arg(-1).
    \end{equation}
    Mais \( \ln(1)=0\) et \( \arg(-1)=\pi\) (et non \( -\pi\)), donc
    \begin{equation}
        \ln(-1)=i\pi.
    \end{equation}

    C'est cette définition du logarithme qui est prise par Sage, et c'est cela qui lui permet de donner la primitive de \( 1/x\) comme \( \ln(x)\) et non \( \ln(| x |)\), parce que Sage connaît les logarithmes de nombres réels négatifs :
\lstinputlisting{tex/sage/sageSnip010.sage}
\end{example}

Nous avons jusqu'ici défini une fonction sur \( \eC^*\) qui fait correspondre à chaque nombre complexe un de ses logarithmes. Il reste quelques questions à régler :
\begin{itemize}
    \item Est-ce que cette fonction est continue ? Holomorphe ? (réponses : non et non)
    \item Si non, est-ce qu'il y avait moyen de trouver une définition plus efficace ? (réponse : non)
\end{itemize}

\begin{lemma}       \label{LEMooMUOIooCnoWwq}
La fonction \( \ln\) n'est pas continue sur \( \mathopen] -\infty , 0 \mathclose]\).
\end{lemma}

\begin{proof}
    Attention à bien comprendre l'énoncé. La fonction
    \begin{equation}
        \begin{aligned}
        f\colon \mathopen] -\infty , 0 \mathclose[&\to \eC \\
            x&\mapsto \ln(x)
        \end{aligned}
    \end{equation}
    est continue. D'ailleurs c'est \( \ln(x)=\ln(| x |)+i\pi\). Ce dont il est question dans l'énoncé, c'est de la fonction \( \ln\) vue comme fonction sur \( \eC^*\).

    Soit \( x>0\) dans \( \eR\); nous avons
    \begin{equation}
        \ln(-x)=\ln(x)+i\pi.
    \end{equation}
    Cependant \( \lim_{\substack{\lambda\to 0^-\\\lambda\in \eR}}\ln(-x+\lambda i) \) va valoir \( \ln(| x |-i\pi)\). En effet lorsque \( \lambda<0\) est petit, l'argument de \( -x+\lambda i\) se rapproche de \( -\pi\) (et non de \( \pi\)).

\begin{center}
   \input{auto/pictures_tex/Fig_CWKJooppMsZXjw.pstricks}
\end{center}

Donc
\begin{equation}
    \lim_{\substack{\lambda\to 0^-\\\lambda\in \eR}}\ln(-x+\lambda i)=\lim \ln(| x+\lambda i |)+i\arg(-x+\lambda i)=\ln(| x |)-i\pi.
\end{equation}
Nous n'avons donc pas continuité de la fonction logarithme comme fonction sur \( \eC^*\).
\end{proof}

\begin{theorem}     \label{THOooWUXOooYKvLbJ}
    La restriction
    \begin{equation}
        \ln\colon \eC\setminus\mathopen] -\infty , 0 \mathclose]\to \eC
    \end{equation}
    est holomorphe.
\end{theorem}

\begin{proof}
    Nous allons utiliser la proposition~\ref{PropKJUDooJfqgYS} et considérer la fonction
    \begin{equation}
        \begin{aligned}
            F\colon S&\to \eR^2 \\
            (x,y)&\mapsto \big( \ln(| x+iy |),\arg(x+iy) \big)
        \end{aligned}
    \end{equation}
    où \( S=\eR^2\setminus\{ (x,0)\tq x\leq 0 \}\). Nous devons vérifier que \( F\) est différentiable et que sa différentielle en un point de \( S\) est une similitude.

    Nous posons
    \begin{equation}
        u(x,y)=\ln\big( \sqrt{ x^2+y^2 } \big)
    \end{equation}
    et
    \begin{equation}
        v(x,y)=\arg(x+iy).
    \end{equation}
    Les dérivées partielles de \( u\) ne sont pas très compliquées :
    \lstinputlisting{tex/sage/sageSnip011.sage}
    c'est-à-dire
    \begin{subequations}
        \begin{align}
            \frac{ \partial u }{ \partial x }=\frac{ x }{ x^2+y^2 }\\
            \frac{ \partial u }{ \partial y }=\frac{ y }{ x^2+y^2 }.
        \end{align}
    \end{subequations}

    Pour celles de \( v \) par contre, il faut se poser des questions, par exemples résister à la tentation d'écrire \( v(x,y)=\arctan(y/x)\) et lire~\ref{NORMooOGHNooYriCBH}.

    Nous avons déjà calculé les dérivées partielles de \( v\) dans~\ref{NORMooMRBEooVtTcIA}, et nous avons vu qu'elles étaient continues sur \( \eR^2\) privé de la demi-droite.

    Vu que les dérivées partielles sont continues, la proposition~\ref{Diff_totale} nous dit que \( F\) est différentiable. La matrice de la différentielle est alors la matrice des dérivées partielles
    \begin{equation}
        \begin{pmatrix}
            \frac{ x }{ x^2+y^2 }    &   \frac{ y }{ x^2+y^2 }    \\
            \frac{ -y }{ x^2+y^2 }    &   \frac{ x }{ x^2+y^2 }
        \end{pmatrix},
    \end{equation}
    qui a la forme requise \eqref{EQooWZGKooLDEHGr} pour que la proposition~\ref{PropKJUDooJfqgYS} nous assure que \( \ln\) soit \( \eC\)-dérivable, c'est-à-dire holomorphe.
\end{proof}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Pas plus de continuité}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Bon. La fonction logarithme que nous avons définie est holomorphe sur \( \eC^*\) privé d'une demi-droite \( U\). Et elle n'est pas continue sur \( U\); elle y est cependant continue «par le haut». Pouvons-nous faire mieux ? Nous allons maintenant prouver quelques résultats d'impossibilité de faire mieux que holomorphe partout sauf une partie pas si petite que ça.

\begin{proposition}
    Il n'existe pas de fonctions continues \( f\colon \eC^*\to \eC\) telle que \(  e^{f(z)}=z\) pour tout \( z\in \eC^*\).
\end{proposition}

\begin{proof}
    Pour tout \( z\), le nombre \( f(z)\) est un logarithme de \( z\). Or \( \ln(z)\) en est également un. Donc par le lemme~\ref{LEMooUMESooJVzeDb}
    \begin{equation}
        f(z)=\ln(z)+2i k(z)\pi
    \end{equation}
    pour une certaine fonction \( k\colon \eC^*\to \eZ\). Sur le domaine d'holomorphie de \( \ln\), les fonctions \( \ln\) et \( f\) étant continues, la fonction \( k\) l'est aussi. Mais une fonction continue à valeurs dans \( \eZ\) est constante (son domaine est connexe).

    Il existe donc \( k\in \eZ\) tel que
    \begin{equation}
         f(z)=\ln(z)+2ik\pi
    \end{equation}
    au moins pour tout \( z\in \eC^*\setminus U\). Une telle fonction ne peut pas être continue sur \( U\) parce que \( \ln\) ne l'est pas.
\end{proof}

Ok. Pas continue sur tout \( \eC\). Mais continue sur un peu plus que \( \eC\) privé de toute une demi-droite ? La proposition suivante répond que bof.

\begin{proposition}
    Soit \( \Omega\) un ouvert de \( \eC\) contenant \( S(0,r)\) (le cercle centré en \( 0\) et de rayon \( r>0\)). Il n'existe pas de fonction continue \( f\colon \Omega\to \eC\) telle que \(  e^{f(z)}=z\) pour tout \( z\in \Omega\).
\end{proposition}

\begin{proof}
    Encore une fois, pour tout \( z\in \Omega\) nous avons
    \begin{equation}
        f(z)=\ln(z)+2i\pi k(z)
    \end{equation}
    pour une certaine fonction \( k\colon \Omega\to \eZ\). Sur \( \Omega\setminus U\), la fonction \( \ln\) est continue et \( k\) doit également l'être. Donc \( k\) est constante sur les composantes connexes de \( \Omega\setminus U\).

    Vu que \( S(0,r)\) est compact, on peut le recouvrir par un nombre fini de boules centrées en des points de \( S(0,r)\). En prenant le minimum des rayons de ces boules, nous voyons que \( \Omega\) contient une couronne
    \begin{equation}
        \{ z\in \eC\tq r-\delta\leq | z |\leq r+\delta \}.
    \end{equation}
    Soit le point \( x_0=-r\). C'est un point de \( \Omega\) contenu dans \( U\). Nous allons prouver que \( B(x_0,\delta)\setminus U\) est dans une seule composante connexe de \( \Omega\).

    Soit un point \( z_1\in B(x_0,\delta)\) situé au-dessus de \( U\), et \( z_2\) un point de \( B(x_0,\delta)\) situé en dessous de \( U\). Le cercle \( S(0,r)\) coupe \( B(x_0,\delta)\) en deux points : un au-dessus et un en-dessous de \( U\). On peut lier \( z_1\) au point de «sortie» supérieur de \( S(0,r)\) en restant dans \( B(x_0,\delta)\); ce point est ensuite relié en suivant le cercle au point d'entrée inférieur du cercle dans \( B(x_0,\delta)\). Ce dernier point est lié à \( z_2\) par un chemin restant dans la boule.

    Tout cela pour dire que \( z_1\) et \( z_2\) sont dans la même composante connexe de \( \Omega\) et que \( k(z_1)=k(z_2)\). Il existe donc \( k\in \eZ\) tel que
    \begin{equation}
        f(z)=\ln(z)+2ik\pi
    \end{equation}
    sur \( B(x_0,\delta)\setminus U\). Une telle fonction \( f\) ne peut pas être continue.
\end{proof}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Pas d'unicité : autres déterminations de l'argument}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

\begin{normaltext}      \label{NORMooFCDOooFDzAjp}
    Nous avons pris la fonction d'argument \( \arg\colon \eC\to \mathopen] -\pi , \pi \mathclose]\). Il y en a évidemment beaucoup d'autres de possibles. Par exemple pour \( \alpha\in \eR\) nous pouvons considérer
    \begin{equation}        \label{EQooNKKDooOuJxXe}
        \arg_{\alpha^+}\colon \eC\to \mathopen] \alpha , \alpha+2\pi \mathclose]
    \end{equation}
    ou
    \begin{equation}
        \arg_{\alpha^-}\colon \eC\to \mathopen[ \alpha , \alpha+2\pi \mathclose[.
    \end{equation}
    En posant
    \begin{equation}
        \ln_{\alpha^{\pm}}(z)=\ln(| z |)+i\arg_{\alpha^{\pm}}(z)
    \end{equation}
nous avons une fonction réciproque de l'exponentielle définie sur \( \eC^*\) et holomorphe sur \( \eC^*\) privé d'une demi-droite \( D_{\alpha}\) (dépendante de la valeur de \( \alpha\)).
\end{normaltext}

La différence entre \( \ln_{\alpha^+}\) et \( \ln_{\alpha^-}\) est seulement la valeur sur la demi-droite de non-holomorphie. L'une sera semi-continue d'un côté et l'autre, de l'autre côté.

\begin{remark}
    La fonction \( \arg_{0^-}\) a déjà été utilisée en \ref{SUBSECooWFNMooOuZBRN} pour écrire un inverse de la fonction
    \begin{equation}
        \begin{aligned}
            \varphi\colon \mathopen[ 0 , 2\pi \mathclose[  &\to S^1 \\
                t&\mapsto  e^{it}. 
        \end{aligned}
    \end{equation}
\end{remark}

\begin{definition}[\cite{ooXDXQooWXsXlk}]
    Soit un ouvert \( \Omega\subset \eC^*\). Nous disons que la fonction \( f\colon \Omega\to \eC\) est une \defe{détermination}{détermination!logarithme} sur \( \Omega\) si elle est continue et vérifie
    \begin{equation}
        e^{f(z)}=z
    \end{equation}
    pour tout \( z\in \eC\).
\end{definition}

Les différents résultats vus jusqu'ici montrent qu'il n'existe pas de détermination du logarithme sur \( \eC^*\).

\begin{definition}
    La \defe{détermination principale}{détermination!logarithme!principale} du logarithme est la restriction de notre logarithme~\ref{DEFooWDYNooYIXVMC}
    \begin{equation}
        \begin{aligned}
            \ln\colon \eC^*&\to \eC \\
            z&\mapsto \ln(| z |)+i\arg(z)
        \end{aligned}
    \end{equation}
    à l'ouvert \( \eC^*\setminus U\) où \( U\) est la partie \( \Re(z)\leq 0\) de \( \eC\).
\end{definition}

\begin{remark}      \label{REMooFBLLooDnkmjR}
    Beaucoup de sources\cite{ooGUROooApafph} ne définissent pas \( \ln_{\alpha^{\pm}}\) sur la droite \( D_{\alpha}\). C'est-à-dire qu'ils notent \( \ln_{\alpha}\) notre fonction \( \ln_{\alpha^+}\) restreinte à \( \eC^*\setminus D_{\alpha}\). Dans ce cas, les fonctions \( \ln_{\alpha^+}\) et \( \ln_{\alpha^-}\) sont identiques\footnote{Cela n'est pas tout à fait évident; vous devriez y penser.}.

    Cette remarque est importante parce que certains vont vous dire «le logarithme n'est pas définit sur la demi-droite»; de leur point de vue, la fonction que nous avons définie est une prolongation (non continue) à \( U\) du logarithme, qui est continu.

    \begin{enumerate}
        \item
            Certaines personnes pourraient vous dire que notre logarithme «n'est pas bien définit parce que si on fait le tour dans un sens ou dans l'autre nous n'obtenons pas la même valeur pour \( \ln(z)\) lorsque \( z\) est sur \( U\)». Et cela avec des arguments aussi forts que «\( 2\pi\) et \( 0\), c'est le même point».

            Nous préférons être bien clairs\quext{Est-ce qu'il faut vraiment un pluriel ici ?} sur ce point : notre fonction \( \ln\) est parfaitement définie sur \( \eC^*\) et \( 2\pi\) n'est pas la même chose que zéro. En particulier \( \arg( e^{2i\pi})=0\) et \(  \arg(e^{-i\pi})=\pi\) et non \( -\pi\).
        \item
            Il n'en reste pas moins que Sage donne \( \ln(-1)=I\pi\) et que nous avons choisi de faire de même, parce que le Frido n'est pas un cours d'agrégation, mais un texte qui donne quelques éléments de mathématique dans le but d'utiliser Sage efficacement.
        \item
            Tout ceci pour dire que si vous utilisez ce livre pour l'agrégation, vous devriez sérieusement considérer l'option de ne pas donner du logarithme la définition donnée ici, mais bien sa restriction.
    \end{enumerate}

    En fait notre logarithme est maximum pour la propriété «être une réciproque de l'exponentielle» alors que beaucoup de monde préfère avoir une fonction maximale pour la propriété «être réciproque de l'exponentielle tout en étant continue».

\end{remark}

De toutes les fonctions ayant le droit de vouloir être appelée «logarithme», celle que nous avons choisie (un peu arbitrairement) pour s'appeler «logarithme» et accaparer de la notation «\( \ln\)» est \( \ln_{\pi^+}\). Elle est d'une certaine manière celle qui arrive le plus naturellement.

En effet si nous pensons au logarithme népérien \( \ln\colon \eR^+\to \eR\) que nous voulons prolonger sur \( \eR\), nous devons poser
\begin{equation}
    \ln(-x)=\ln(-1)+\ln(x)
\end{equation}
pour \( x>0\). Que peut valoir \( \ln(-1)\) ? Il doit vérifier \(  e^{\ln(-1)}=-1\). La première valeur qui nous tombe sous la main est \( \ln(-1)=\pi\). Bien entendu, d'autres possibilités étaient possibles, comme \( \ln(-1)=2017\pi\) par exemple.

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Pas d'unicité : développement en série}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Pour \( z_0\in \eC^*\) nous pouvons écrire un développement en série de la réciproque de l'exponentielle autour de \( z_0\). La fonction ainsi définie est holomorphe sur la boule \( B(z_0,| z_0 |)\) et diverge en dehors de cette boule.

Voilà encore une fonction «logarithme» pour chaque point de \( \eC^*\). Nous nommons \( \ln_{z_0}\) la fonction
\begin{equation}
    \ln_{z_0}\colon B(z_0,| z_0 |)\to \eC
\end{equation}
donnée par la série.

En général nous n'avons pas \( \ln_{z_1}=\ln_{z_2}\) sur l'intersection des disques de convergence. Si c'était le cas, de proche en proche nous pourrions construire une fonction continue réciproque du logarithme sur \( \eC^*\), ce qui est impossible.

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Pas d'unicité : laquelle choisir ?}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Bon. Pour chaque demi-droite \( D\) nous avons une détermination du logarithme sur \( \eC^*\setminus D\). Et pour tout \( z_0\in \eC^*\) nous en avons une sur \( B(z_0,| z_0 |)\).

En pratique, quel logarithme choisir ? Cela dépend du problème.

Si vous avez besoin ou envie de travailler avec des série entières, le mieux est de choisir une détermination donnée par un développement autour d'un point bien choisi par rapport à votre problème.

Si vous avez surtout besoin d'holomorphie, et que vous en avez besoin sur un grand domaine, vous devriez choisir une détermination sur un des ensembles \( \eC^*\setminus D_{\alpha}\) en choisissant \( \alpha\) de telle sorte que la demi-droite maudite ne passe pas par la zone sur laquelle vous travaillez.

Dans tous les cas, vous devez préciser très explicitement la détermination choisie. Dans ce texte, sauf mention du contraire, nous utiliserons la détermination principale, et même son extension (non continue) à \( \eC^*\). Lorsque nous aurions besoin d'holomorphie, nous préciserons que nous considérons la restriction.

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Logarithme comme primitive}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Tout le monde sait que le logarithme \( \ln\colon \eR^+\to \eR\) est une primitive de la fonction \( x\mapsto 1/x\). Qu'en est-il dans le cas complexe ? Tout d'abord précisons que nous ne comptons pas encore parler d'intégrale sur \( \eC\), mais seulement d'intégrales sur \( \eR\) d'une fonction à valeur complexes.

\begin{proposition}     \label{PROPooNIJVooKueuYJ}
    Si \( z\in \eC\) alors
    \begin{equation}        \label{EQooAHYXooTPGXDS}
        \int\frac{1}{ x+z }dx=\ln(x+z)
    \end{equation}
\end{proposition}

\begin{proof}
    Il est important de comprendre que la formule \eqref{EQooAHYXooTPGXDS} est un abus de notation pour dire que si nous considérons la fonction
    \begin{equation}
        \begin{aligned}
            \varphi\colon \eR&\to \eC \\
            x&\mapsto \ln(x+z)
        \end{aligned}
    \end{equation}
    alors nous avons \( \varphi'(x)=\frac{1}{ x+z }\). Ici la dérivation est une dérivation sur \( \eR\) et l'intégrale est une intégrale sur \( \eR\), c'est-à-dire «composante par composantes». La fonction \(  \varphi\) se décompose en partie réelle et imaginaire qui sont à dériver séparément :
    \begin{equation}
        \varphi(x)=\ln(| x+z |)+i\arg(x+z).
    \end{equation}

    \begin{subproof}

        \item[Si \( z\) est imaginaire pur]

            Nous posons \( z=\lambda i\) avec \( \lambda\in \eR^*\). D'abord nous avons
            \begin{equation}
                \frac{1}{ x+\lambda i }=\frac{ x }{ x^2+\lambda^2 }-i\frac{ \lambda }{ x^2+\lambda^2 }.
            \end{equation}
            La partie réelle de \( \varphi(x)\) est
            \begin{equation}
                \varphi_1(x)=\ln\big( \sqrt{ x^2+\lambda^2 } \big),
            \end{equation}
            dont la dérivée est
            \begin{equation}
                \varphi_1'(x)=\frac{ x }{ x^2+\lambda^2 },
            \end{equation}
            qui correspond bien à la partie réelle de \( \frac{1}{ x+\lambda i }\).

            En ce qui concerne la partie imaginaire, \( \varphi_2(x)=\arg(x+\lambda i)\), et sa dérivée n'est rien d'autre que la dérivée partielle par rapport à \( x\) de la fonction argument, déjà calculée en \eqref{EQooAOJPooOrvUBR} :
            \begin{equation}
                \varphi_2'(x)=\frac{ -\lambda }{ x^2+\lambda }.
            \end{equation}
            Cela est bien la partie imaginaire de \( \frac{1}{ x+\lambda i }\).

    Notons que nous n'avons pas de problèmes sur la demi-droite des réels négatifs parce que nous ne considérons au final que la dérivée partielle par rapport à \( x\) de la fonction argument, laquelle existe et est continue, même sur cette partie.

        \item[Pour \( z\) quelconque]

            Soit \( z=s+\lambda i\) avec \( s,\lambda\in \eR\). En posant \( \varphi_0(x)=\ln(x+\lambda i)\) nous avons \( \varphi(x)=\varphi_0(x+s)\) et donc
            \begin{equation}
                \varphi'(x)=\varphi_0'(x+s)=\frac{ 1 }{ x+s+\lambda i }=\frac{1}{ x+z }.
            \end{equation}
            Tout va bien.

    \end{subproof}
\end{proof}

\begin{example}     \label{EXooAKEDooZgjocX}
    Un petit calcul d'intégrale, que nous avions déjà faite dans l'exemple~\ref{EXooIPEQooGKDjea} (avec la méthode de Rothstein-Trager). En passant par une décomposition en fractions simples :
    \begin{subequations}
        \begin{align}
            \int\frac{1}{ x^3+x }&=\int\left( \frac{1}{ x }-\frac{ 1/2 }{ x-i }-\frac{ 1/2 }{ x+i } \right)\\
            &=\ln(x)-\frac{ 1 }{2}\ln(x-i)-\frac{ 1 }{2}\ln(x+i)\\
            &=\ln(x)-\frac{ 1 }{2}\ln(x^2+1).       \label{SUBEQooRNQLooScfSlG}
        \end{align}
    \end{subequations}
    Attention aux justifications. Il n'est pas vrai en général dans le cas de nombres complexes \( a\) et \( b\) que \( \ln(ab)=\ln(a)+\ln(b)\). En effet, pour la partie réelle, ça passe parce que \( | ab |=| a | |b |\). Mais en ce qui concerne la partie imaginaire,
    \begin{equation}
        \arg(ab)\neq \arg(a)+\arg(b)
    \end{equation}
lorsque la somme dépasse les bornes de \( \mathopen] -\pi , \pi \mathclose]\). Le passage à \eqref{SUBEQooRNQLooScfSlG} fonctionne parce que dans le cas particulier des nombres \( x+i\) et \( x-i\), les arguments se somment à zéro : \( \arg(x+i)+\arg(x-i)=0\).
\end{example}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Théorème de Weierstrass}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{theorem}[Théorème de Weierstrass\cite{uTyBDj}]       \label{ThoArYtQO}
    Soit \( (f_n)\) une suite de fonctions holomorphes sur un ouvert \( \Omega\) de \( \eC\) que nous supposons converger uniformément sur tout compact vers \( f\). Alors \( f\) est holomorphe sur \( \Omega\) et pour tout \( k\) nous avons
    \begin{equation}
        f^{(k)}_n\to f^{(k)}
    \end{equation}
    uniformément sur tout compact.

    Dit en peu de mots, la limite uniforme d'une suite de fonctions holomorphes est holomorphe, et on peut permuter la limite avec la dérivation.
\end{theorem}
\index{compacité}
\index{suite!de fonctions intégrables}
\index{fonction!définie par une intégrale}
\index{fonction!holomorphe}
\index{limite!inversion}
\index{limite!de fonctions holomorphes}

\begin{proof}
    Chacune des fonctions \( f_n\) étant holomorphes, si \( a\in \Omega\) et \( r\) est tel que \( B(a,r)\subset \Omega\), nous avons par la formule de Cauchy~\ref{ThoUHztQe} :
    \begin{equation}
        f_n(z)=\frac{1}{ 2\pi i }\int_{\partial B(a,r)}\frac{ f_n(\xi) }{ \xi-z }d\xi
    \end{equation}
    pour tout \( z\) dans un boule \( B(a,\rho)\) incluse dans \( B(a,r)\). Étant donné que le cercle \( \partial B\) est compact, elle y est majorée par une constante \( M\). Montrons que de plus nous pouvons choisir \( M\) de telle façon à avoir \( | f_n(\xi) |\leq M\) pour tout \( n\) et tout \( \xi\) en même temps. D'abord nous utilisons la continuité de la limite \( f\) sur le compact \( \partial B \) pour poser \( A=\max_{z\in\partial B}| f(z) |\). Ensuite nous considérons un \( \epsilon>0\) et \( N\) tel que \( |\ f_n-f \|_{\partial B}\leq \epsilon\) pour tout \( n\geq N\). Nous savons maintenant que
    \begin{equation}
        \{ | f_n(\xi) |\tq n \geq N,\xi\in\partial B \}
    \end{equation}
    est majoré par \( A+\epsilon\). Nous posons enfin
    \begin{equation}
        B=\max_{n\leq N}\max_{\xi\in\partial B}| f_n(z) |,
    \end{equation}
    et alors le nombre \( M=\max\{ A+\epsilon,B \}\) majore \( | f_n(\xi) |\) pour tout \( n\) et tout \( \xi\in\partial B\).

    De plus pour tout \( \xi\in\partial B\) et pour tout \( z\) dans la petite boule, nous avons \( | \xi-z |>r-\rho\), donc  la fonction dans l'intégrale est majorée par une constante ne dépendant ni de \( n\) ni de \( \xi\). Nous pouvons donc permuter l'intégrale et la limite sur \( n\) :
    \begin{equation}
        f(z)=\frac{1}{ 2i\pi }\int_{\partial B}\frac{ f(\xi) }{ \xi-z }.
    \end{equation}
    Cela implique que la fonction \( f\) est holomorphe par le corollaire~\ref{CorwfHtJu}.

    Nous voudrions maintenant parler des dérivées des \( f_n\) et de \( f\). Pour cela nous voulons permuter l'intégrale et les dérivées, ce qui est fait au corollaire~\ref{CorNxTjEj} :
    \begin{equation}
        f_n^{(k)}=\frac{1}{ 2\pi i }\int_{\partial B(z_0,r)}\frac{ f(\omega) }{ (\omega-z)^{k+1} }d\omega.
    \end{equation}
    Nous voulons la convergence sur tout compact contenu dans l'ouvert \( \Omega\). Pour ce faire, nous allons considérer un compact \( K\subset \Omega\) et prouver la convergence uniforme dans toute boule de la forme \( B(z_0,r)\) avec \( z_0\in K\) et \( B(z_0,r)\subset \Omega\). Pour chaque tel couple \( (z_0,r)\), nous aurons un \( N_{(z_0,r)}\in \eN\) tel que si \( n\geq N_{(z_0,r)}\),
    \begin{equation}
        \| f_n^{(k)}-f^{(k)} \|_{B(z_0,r)}\leq \epsilon.
    \end{equation}
    Vu que ces boules \( B(z_0,r)\) forment un recouvrement de \( K\) par des ouverts, nous pouvons en retirer un sous-recouvrement fini et prendre, comme \( N\), le maximum des \( N_{(z_0,r)}\) correspondants. Pour ce \( N\) nous aurons
    \begin{equation}
        \| f_n^{(k)}-f^{(k)} \|_K\leq \epsilon.
    \end{equation}
    Au travail !

    Pour \( z\in B(z_0,r)\) nous considérons \( r'>r\) tel que \( B(z_0,r')\subset \Omega\) et nous avons
    \begin{subequations}
        \begin{align}
            | f^{(k)}_n(z)-f^{(k)}(z) |&=\left| \frac{1}{ 2\pi i }\int_{\partial B(z_0,r')}\frac{ f_n(\xi)-f(\xi) }{ (\xi-z)^{k+1} }d\xi \right| \\
            &\leq\frac{1}{ 2\pi }\int_{\partial B(z_0,r')}\frac{ | f_n(\xi)-f(\xi) | }{ | r-r' |^{k+1} }d\xi.
        \end{align}
    \end{subequations}
    Nous avons pris ce \( r'\) de telle manière que \( | \xi-z |\) soit borné par le bas par \( | r-r' |\); sinon la majoration que nous venons de faire ne marche pas. Étant donné que \( f_n\to f\) uniformément, nous pouvons considérer \( n\) assez grand pour que le numérateur soit plus petit que \( \epsilon\) indépendamment de \( \xi\) et de \( z\). Donc pour un \( n\) assez grand,
    \begin{equation}
        | f^{(k)}_n(z)-f^{(k)}(z) |\leq \frac{ \epsilon }{ 2\pi }\frac{ 2\pi r' }{ | r-r' |^{k+1} }
    \end{equation}
    pour tout \( z\in B(z_0,r)\). Donc nous avons convergence uniforme \( f_n^{(k)}\to f^{(k)}\) sur cette boule. Par l'argument de compacité donné plus haut, nous avons la convergence uniforme sur tout compact.
\end{proof}
