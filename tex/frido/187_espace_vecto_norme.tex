% This is part of Le Frido
% Copyright (c) 2008-2022
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.


%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Produit tensoriel d'espaces vectoriels}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Si vous êtes pressés, vous pouvez aller lire la définition \ref{DEFooKTVDooSPzAhH} de produit tensoriel d'espaces vectoriels. Mais si vous étiez vraiment pressés, vous ne seriez pas en train de lire des choses sur le produit tensoriel (il vous suffit de croire que \( x\otimes y\) n'est finalement que la concatenation de \( x\) et \( y\)).

\begin{propositionDef}      \label{PROPooYONEooWvwPZT}
    Soient un espace vectoriel \( V\) et un sous-espace \( N\). Le \defe{quotient}{quotient d'un espace vectoriel} de \( V\) par \( N\), noté \( V/N\) est l'ensemble des classes d'équivalence\footnote{Définition \ref{DEFooRHPSooHKBZXl}.} pour la relation \( x\sim y\) si et seulement si \( x-y\in N\).

	Les définitions
	\begin{enumerate}
		\item
		      \( [v]+[w]=[v+w]\)
		\item
		      \( \lambda[v]=[\lambda v]\)
	\end{enumerate}
	ont un sens et définissent une structure d'espace vectoriel sur \( V/N\).

    En ce qui concerne la topologie, ce sera la définition \ref{DEFooHWSYooZZLXQU}.
\end{propositionDef}

\begin{proof}
	Un élément général de la classe \( [v]\) est de la forme \( v+n\) avec \( n\in N\). Le calcul suivant montre que la somme fonctionne :
	\begin{equation}
		[v+n_1]+[w+n_2]=[v+w+n_1+n_2]=[v+w]
	\end{equation}
	parce que \( n_1+n_2\in N\). De même,
	\begin{equation}
		\lambda[v+n]=[\lambda v+\lambda n]=[\lambda v]
	\end{equation}
	toujours parce que \( \lambda n\in N\).

	Notons que nous avons utilisé de façon on ne peut plus cruciale le fait que \( N\) soit un sous-espace vectoriel.
\end{proof}

\begin{proposition}
	Si \( \{ e_i \}\) est une base de \( V\) et si \( N\) est un sous-espace de \( V\), alors \( \{ [e_i] \}\) est une partie génératrice de \( V/N\).
\end{proposition}

\begin{proof}
	Si \( x=\sum_kx_ke_k\), alors \( [x]=\sum_kx_k[e_k]\), donc oui.
\end{proof}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Les produits tensoriels}
%---------------------------------------------------------------------------------------------------------------------------

Nous allons procéder en deux temps. D'abord nous allons définir ce qu'est \emph{un} produit tensoriel entre deux espaces vectoriels \( V\) et \( W\), et nous allons montrer que tous les produits tensoriels possibles sont isomorphes. Ensuite nous allons montrer qu'un produit tensoriel existe en en construisant un. Voir la proposition \ref{PROPooIWZDooRRZNCf}.

\begin{definition}[\cite{ooWHNKooYVCiYc}]       \label{DEFooXKKQooAvWRNp}
	Soient deux espaces vectoriels \( V\) et \( W\). Un \defe{produit tensoriel}{produit tensoriel} de \( V\) et \( W\) est un couple \( (T,h)\) où \( T\) est un espace vectoriel et \( h\colon V\oplus W\to T\) est une application
	\begin{enumerate}
		\item
		      bilinéaire\footnote{Définition \ref{DEFooEEQGooNiPjHz}.}
		\item
		      surjective
		\item       \label{ITEMooJCNYooGvjjtL}
		      telle que pour tout espace vectoriel \( U\) et toute applications bilinéaire \( f\colon V\oplus W\to U\), il existe une application linéaire \( g\colon T\to U\) telle que \( f=g\circ h\).
	\end{enumerate}
	La propriété \ref{ITEMooJCNYooGvjjtL} est appelée \defe{propriété universelle}{propriété universelle} du produit tensoriel.
\end{definition}

\begin{definition}  \label{DEFooPLHTooRiHjlE}
	Un \defe{morphisme}{morphisme de produits tensoriels} entre \( (T,h)\) et \( (T',h')\) est une application linéaire \( \psi\colon T\to T'\) telle que \( h'=\psi\circ h\).

	Nous parlons d'\defe{isomorphisme}{isomorphisme} si \( \psi\) a un inverse qui est également un morphisme.
\end{definition}

\begin{proposition}[\cite{ooWHNKooYVCiYc}]      \label{PROPooROPHooQXqNzZ}
	Si \( V\) et \( W\) sont des espaces vectoriels, tous les produits tensoriels entre \( V\) et \( W\) sont isomorphes entre eux au sens de la définition \ref{DEFooPLHTooRiHjlE}.

	Plus précisément, si \( (T,h)\) et \( (T',h')\) sont deux produits tensoriels de \( V\) et \( W\), alors
	\begin{enumerate}
		\item
		      il existe une unique unique application linéaire \( g\colon T\to T'\) telle que \( h'=g\circ h\),
		\item
		      cette application \( g\) est inversible.
	\end{enumerate}
	En particulier, l'application \( g\) est un isomorphisme d'espaces vectoriels.
\end{proposition}

\begin{proof}
	Soient deux produits tensoriels \( (T,h)\) et \( (T',h')\).

	\begin{subproof}
		\spitem[Existence]

		L'application \( h'\colon V\oplus W\to T'\) est bilinéaire, et \( (T,h)\) est un produit tensoriel. Donc il existe \( g\colon T\to T'\) tel que \( h'=g\circ h\). De même, il existe une application \( g'\colon T'\to T\) telle que \( h=g'\circ h\).

		\spitem[Unicité]

		En ce qui concerne l'unicité, vu que \( h\colon V\oplus W\to T\) est surjective, la relation \( h'=g\circ h\) prescrit les valeurs de \( g\) sur tous les éléments de \( T\).

		\spitem[Inversible]

		Ces deux applications \( g\) et \( g'\) vérifient \( h'=gg'h\) et \( h=g'gh\), et de plus \( h\colon V\oplus W\to T\) est surjective. Soient \( t\in T\) et \( x\in V\oplus W\) tel que \( t=h(x)\). Nous avons \( h(x)=g'gh(x)\). C'est-à-dire \( t=(g'\circ g)(t)\). De même dans l'autre sens, il existe \( x'\in V\oplus W\) tel que \( t=h'(x')\). En appliquant l'égalité \( h'=gg'h'\) à \( x'\), nous trouvons \( t=(g\circ g')(t)\).

		Tout cela pour dire que \( g'=g^{-1}\). Cette application \( g\) est donc un isomorphisme de produits tensoriels entre \( (T,h)\) et \( (T',h')\).
	\end{subproof}
	Au final, l'application \( g\colon T\to T'\) étant linéaire et inversible, elle est un isomorphisme d'espaces vectoriels.
\end{proof}

Tout cela est fort bien : nous avons unicité à isomorphisme près du produit tensoriel d'espaces vectoriels. Mais nous n'avons pas encore de certitudes à propos de l'existence d'un couple \( (T,h)\) vérifiant les propriétés demandées pour être un produit tensoriel.

Nous allons maintenant construire un produit tensoriel.

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Le produit tensoriel}
%---------------------------------------------------------------------------------------------------------------------------

C'est le moment pour vous de relire la définition \ref{DEFooCPNIooNxsYMY} d'espace vectoriel librement engendré, et surtout le lemme \ref{LEMooLOPAooUNQVku} qui en donne une base.

\begin{definition}[\cite{ooWHNKooYVCiYc}]       \label{DEFooKTVDooSPzAhH}
	Soient deux espaces vectoriels \( V\) et \( W\) sur le corps commutatif\footnote{À part mention du contraire, tous les corps du Frido sont commutatifs.} \( \eK\). Dans \( F_{\eK}(V\times W)\) nous considérons les sous-espaces suivants:
	\begin{subequations}
		\begin{align}
			A_1 & =\{ \delta_{(v_1,w)}+\delta_{(v_2,w)}-\delta_{(v_1+v_2,w)}\tq v_1,v_2\in V,w\in W  \}                             \\
			A_2 & =\{ \delta_{(v,w_1)}+\delta_{(v,w_2)}-\delta_{(v,w_1+w_2)}\tq v\in V,w_1,w_2\in W  \} \label{SUBEQooSHBJooJLPVbK} \\
			A_3 & =\{ \lambda\delta_{v,w}-\delta_{(\lambda v, w)}\tq v\in V,w\in W,\lambda\in \eK \}                                \\
			A_4 & =\{ \lambda\delta_{v,w}-\delta_{(v,\lambda w)}\tq v\in V,w\in W,\lambda\in \eK \}.
		\end{align}
	\end{subequations}
	Nous considérons alors \( N=\Span(A_1,A_2,A_3,A_4)\) et le quotient
	\begin{equation}
		V\otimes_{\eK}W=F_{\eK}(V\times W)/N.
	\end{equation}
	Ce dernier espace vectoriel est le \defe{produit tensoriel}{produit tensoriel} de \( V\) par \( W\).
\end{definition}

\begin{remark}      \label{REMooSLEGooWEiutz}
	Quelque remarques.
	\begin{enumerate}
		\item
		      Les éléments de \( V\otimes W\) ne s'écrivent pas tous sous la forme \( v\otimes w\). Certains ont vraiment besoin d'être écrits avec des sommes. En cela, la situation de \( V\otimes W\) est réellement différente de celle de \( V\times W\). Dans ce dernier, tous les éléments sont des couples.
		\item
		      La classe de l'élément \( \delta_{(v,w)}\in F(V\times W)\) sera d'habitude noté \( v\otimes w\).
		\item
		      Pour insister sur la notion de classe, nous allons aussi noter \( [x]\) la classe de \( x\in F(V\times W)\).
		\item       \label{ITEMooPVWHooMkgQoT}
		      L'arithmétique dans \( V\otimes W\) est relativement simple. En ajoutant et soustrayant le même élément de \( A_3\) nous avons par exemple
		      \begin{equation}
			      (\lambda v)\otimes w=(\lambda v)\otimes w+\lambda (v\otimes w)-(\lambda v)\otimes w.
		      \end{equation}
		      Nous obtenons de cette façon
		      \begin{equation}
			      \lambda(v\otimes w)=(\lambda v)\otimes w=v\otimes (\lambda w),
		      \end{equation}
		      que nous noterons \( \lambda v\otimes w\) sans plus de précision.
	\end{enumerate}
\end{remark}

\begin{proposition}[\cite{ooWHNKooYVCiYc}]     \label{PROPooIWZDooRRZNCf}
	L'espace vectoriel \( V\times W\) muni de
	\begin{equation}
		\begin{aligned}
			h\colon V\oplus W & \to V\otimes W     \\
			(v,w)             & \mapsto v\otimes w
		\end{aligned}
	\end{equation}
	est un produit tensoriel entre \( V\) et \( W\).
\end{proposition}

\begin{proof}
	Nous devons prouver les conditions de la définition \ref{DEFooXKKQooAvWRNp}.

	\begin{subproof}
		\spitem[\( h\) est bilinéaire]

		Ce sont des calculs tels que faits dans la remarque \ref{REMooSLEGooWEiutz}\ref{ITEMooPVWHooMkgQoT} qui font le travail.

		\spitem[\(h \) est surjective]

		Un élément de \( V\otimes W\) est la classe d'un élément de \( F(V\times W)\), c'est-à-dire de la forme
		\begin{equation}
			\big[ \sum_{i\alpha}\delta_{(v_i,w_{\alpha})} \big]=\sum_{i\alpha}a_{i\alpha}v_i\otimes w_{\alpha}.
		\end{equation}
		Cet élément est dans l'image de \( h\) comme le montre le calcul suivant\footnote{Faites bien la distinction entre \( \delta_{v,w}\), \( (v,w)\) et \( v\otimes w\). Sachez dans quel ensemble se trouvent chacun de ces trois objets.} :
		\begin{equation}
			h\big( \sum_{i\alpha}(v_i,w_{\alpha}) \big)=\sum_{i\alpha}a_{i\alpha}h(v_i,w_{\alpha})=\sum_{i\alpha}v_i\otimes w_{\alpha}.
		\end{equation}

		\spitem[Propriété universelle]

		Soient un espace vectoriel \( U\) et une application linéaire \( f\colon V\oplus W\to U \). Nous devons trouver une application linéaire \( g\colon V\otimes W\to U\) telle que \( f=g\circ h\). Pour cela nous commençons par considérer l'application
		\begin{equation}
			\begin{aligned}
				g\colon F(V\times W) & \to U          \\
				\delta_{(v,w)}       & \mapsto f(v,w)
			\end{aligned}
		\end{equation}
		définie sur tout \( F(V\times W)\) par linéarité sans encombres parce que les \( \delta_{v,w}\) forment une base par le lemme \ref{LEMooLOPAooUNQVku}.

		Nous démontrons que \( g(N)=0\) pour avoir le droit de passer \( g\) aux classes et le considérer comme application partant de \( V\otimes W\) au lieu de \( F(V\times W)\). Prenons par exemple
		\begin{subequations}
			\begin{align}
				g\big( \delta_{(v_1,w)}+\delta_{(v_2,w)}-\delta_{(v_1+v_2,w)} \big) & =g( \delta_{(v_1,w)} )+g(\delta_{(v_2,w)})-g(\delta_{v_1+v_2,w}) \\
				                                                                    & =f(v_1,w)+f(v_2,w)-f(v_1+v_2,w)                                  \\
				                                                                    & =0
			\end{align}
		\end{subequations}
		par la bilinéarité de \( f\). Cela montre que \( g(A_1)=0\). Nous montrons de même que \( g(A_2)=g(A_3)=g(A_4)=0\), et enfin toujours par linéarité que \( g(N)=0\). Pour rappel, les éléments de \( N\) sont les combinaisons linéaires finies d'éléments de \( A_1\), \( A_2\), \( A_3\) et \( A_4\).

		Par passage aux classes, nous avons une application (que nous notons également \( g\))
		\begin{equation}
			g\colon F(V\times W)/N\to U
		\end{equation}
		vérifiant \( g(v\otimes w)=f(v,w)\). Mais comme \( h(v,w)=v\otimes w\), nous avons \( g\circ h\colon V\oplus W\to U\) vérifiant \( g\circ h=f\).
	\end{subproof}
	L'espace vectoriel \( V\otimes W\) est donc un produit tensoriel.
\end{proof}

\begin{normaltext}
	Vu que \( V\otimes W\) est un produit tensoriel de \( V\) et \( W\), et vu qu'il y a unicité par la proposition \ref{PROPooROPHooQXqNzZ}, nous avons bien le droit de dire que \( V\otimes W\) est \emph{le} produit tensoriel. Cela justifie le titre.
\end{normaltext}

\begin{normaltext}
	Les prochains lemmes et propositions vont nous dire que l'application
	\begin{equation}
		\begin{aligned}
			\varphi\colon V^*\otimes W & \to \aL(V,W)                            \\
			\alpha\otimes w            & \mapsto \big( v\mapsto \alpha(v)w \big)
		\end{aligned}
	\end{equation}
	est un isomorphisme d'espaces vectoriels lorsque \( V\) est de dimension finie. Vu que nous aimons les énoncés très explicites, ça va être découpé en plusieurs morceaux, l'énoncé va devenir un peu long; mais c'est pour la bonne cause.
\end{normaltext}

\begin{lemma}       \label{LEMooOJEBooQruWEp}
	Soient deux espaces vectoriels \( V\) et \( W\) dont \( W\) est de dimension finie. Alors l'application définie par
	\begin{equation}
		\begin{aligned}
			\varphi\colon F(V^*\times W) & \to \aL(V,W)                            \\
			\delta_{(\alpha,w)}          & \mapsto \big( v\mapsto \alpha(v)w \big)
		\end{aligned}
	\end{equation}
	sur la base «canonique» de \( F(V^*\times W)\) passe aux classes.
\end{lemma}

\begin{proof}
	Avec les notations de la définition \ref{DEFooKTVDooSPzAhH} nous devons prouver que \( \varphi(N)=0\). Nous montrons que \( \varphi(A_4)=0\), et nous vous laissons faire les autres. Pour \( \lambda\in \eK\), \( \alpha\in V^*\) et \( w\in W\) en utilisant la linéarité de \( \varphi\) nous avons :
	\begin{subequations}
		\begin{align}
			\varphi\big( \lambda\delta_{(\alpha,w)}-\delta_{(\alpha,\lambda w)} \big)v & =\lambda\varphi(\delta_{(\alpha,w)})(v)-\varphi(\delta_{(\alpha,\lambda w)})(v) \\
			                                                                           & =\lambda\alpha(v)w-\alpha(v)(\lambda w)                                         \\
			                                                                           & =0
		\end{align}
	\end{subequations}
	parce que \( \alpha(v)(\lambda w)=\lambda \alpha(v)w\) du fait que \( \eK\) est commutatif. La commutativité de \( \eK\) est ce qui permet de permuter le produit \( \lambda \alpha(v)\).

	Nous laissons à la lectrice le soin de prouver que \( \varphi(A_1)=\varphi(A_2)=\varphi(A_3)=0\).
\end{proof}

\begin{lemma}       \label{LEMooUQZHooWjIGsy}
	Si \( W\) est de dimension finie, alors \( \aL(V,W)\) muni de
	\begin{equation}
		\begin{aligned}
			h'\colon V^*\oplus W & \to \aL(V,W)                            \\
			(\alpha,w)           & \mapsto \big( v\mapsto \alpha(v)w \big)
		\end{aligned}
	\end{equation}
	est un produit tensoriel\footnote{Définition \ref{DEFooXKKQooAvWRNp}.} de \( V^*\) par \( W\).
\end{lemma}

\begin{proof}
	Nous devons prouver que
	\begin{itemize}
		\item \( h\) est bilinéaire,
		\item \( h\) est surjective
		\item pour tout espace vectoriel \( U\), et pour toute application bilinéaire \( f\colon V^*\oplus W\to U\), il existe une application linéaire \( g\colon \aL(V,W)\to U\) tel que \( f=g\circ h\).
	\end{itemize}

	\begin{subproof}
		\spitem[Bilinéaire]
		Le fait que \( h\) soit bilinéaire est une simple vérification.
		\spitem[Surjective]
		L'espace \( W\) étant de dimension finie, nous pouvons en considérer une base \( \{ z_i \}_{i\in I}\). Soit \( \alpha\in \aL(V,W)\). Si \( v\in V\), l'élément \( \alpha(v)\) peut être décomposé dans la base \( \{ z_i \}\), ce qui définit des applications linéaires \( \alpha_i\colon V\to \eK\) par
		\begin{equation}
			\alpha(v)=\sum_{i\in I}\alpha_i(v)z_i.
		\end{equation}
		Notons que \( \alpha_i\in V^*\). En comparant avec la définition de \( h'\), nous voyons que
		\begin{equation}
			\alpha(v)=\sum_i h(\alpha_i,z_i)(v),
		\end{equation}
		c'est-à-dire \( \alpha=\sum_ih(\alpha_i,w_i)=h\big( \sum_i(\alpha_i,z_i) \big)\). Nous avons donc bien \( \alpha\in h(V^*\oplus W)\).
		\spitem[Propriété universelle]

		Soient un espace vectoriel \( U\) et une application bilinéaire \( f\colon V^*\oplus W\to U\). Pour \( \alpha\in\aL(V,W)\) nous définissons \( g(\alpha)\) comme suit. D'abord nous écrivons \( \alpha\) sous la forme
		\begin{equation}
			\alpha(v)=\sum_i\alpha_i(v)z_i,
		\end{equation}
		et nous posons
		\begin{equation}
			g(\alpha)=\sum_if(\alpha_i,z_i).
		\end{equation}
		Avec cette définition, en posant \( w=\sum_iw_iz_i\), nous avons
		\begin{subequations}
			\begin{align}
				(g\circ h')(\alpha,w) & =g\big( v\mapsto \alpha(v)w \big)            \\
				                      & =g\big( v\mapsto \sum_i\alpha(v)w_iz_i \big) \\
				                      & =\sum_if(w_i\alpha,z_i)                      \\
				                      & =\sum_if(\alpha,w_iz_i)                      \\
				                      & =f(\alpha,\sum_iw_iz_i)                      \\
				                      & =f(\alpha,w).
			\end{align}
		\end{subequations}
		Cela prouve que \( g\circ h=f\).
	\end{subproof}
\end{proof}

\begin{proposition}[\cite{ooNHIGooYlXxMf}]      \label{PROPooKJTCooVTXWAQ}
	Soient deux espaces vectoriels \( V\) et \( W\) dont \( V\) est de dimension finie. Alors l'application
	\begin{equation}
		\begin{aligned}
			\varphi\colon V^*\otimes W & \to \aL(V,W)                            \\
			\alpha\otimes w            & \mapsto \big( v\mapsto \alpha(v)w \big)
		\end{aligned}
	\end{equation}
	est bien définie\footnote{Au sens où il existe une fonction \( \varphi\) définie sur tout \( V^*\otimes W\) qui se réduit à cela pour les éléments de la forme \( \alpha\otimes w\).} et est un isomorphisme d'espaces vectoriels.
\end{proposition}

\begin{proof}
	Le lemme \ref{LEMooUQZHooWjIGsy} donne une structure de produit tensoriel de \( V^*\) par \( W\) sur \( \aL(V,W)\). Rappelons les structures :
	\begin{equation}
		\begin{aligned}
			h\colon V^*\oplus W & \to V^*\otimes W        \\
			(\alpha,w)          & \mapsto \alpha\otimes w
		\end{aligned}
	\end{equation}
	et
	\begin{equation}
		\begin{aligned}
			h'\colon V^*\oplus W & \to \aL(V,W)                             \\
			(\alpha,w)           & \mapsto \big[ v\mapsto \alpha(v)w \big].
		\end{aligned}
	\end{equation}

	La proposition \ref{PROPooROPHooQXqNzZ} a déjà fait tout le boulot. La seule chose à faire est de vérifier qu'il existe une application \( \varphi\colon V^*\otimes W\to \aL(V,W)\) vérifiant simultanément les deux conditions suivantes :
	\begin{enumerate}
		\item       \label{ITEMooVNNSooNIXRoG}
		      \( \varphi(\alpha\otimes w)=\big[ v\mapsto \alpha(v)w \big]\)
		\item
		      \( h'=\varphi\varphi\circ h\).
	\end{enumerate}
	La seconde condition assure que \( \varphi\) sera un isomorphisme d'espaces vectoriels.

	L'existence de \( \varphi\) vérifiant la condition \ref{ITEMooVNNSooNIXRoG} est un effet du lemme \ref{LEMooOJEBooQruWEp} qui donne une fonction sur \( F(V^*\times W)\) dont le \( \varphi\) qui nous concerne est un quotient. Il reste à voir que cette application vérifie \( h'=\varphi\circ h\).

	En nous rappellant que \( \alpha\otimes w=[\delta_{(\alpha,w)}]\) et en écrivant \( \varphi\) à la fois l'application et son passage au quotient,
	\begin{equation}
		(\varphi\circ h)(\alpha,w)=\varphi(\alpha\otimes w)=\varphi\big( [\delta_{(\alpha,w)}] \big)=\varphi(\delta_{(\alpha,w)}).
	\end{equation}
	En appliquant à \( v\in V\) nous avons:
	\begin{equation}
		(\varphi\circ h)(\alpha,w)v=\varphi(\delta_{(\alpha,w)})v=\alpha(v)w=h'(\alpha,w)v.
	\end{equation}
	Et voilà. Nous avons \( \varphi\circ h=h'\).
\end{proof}

Une conséquence de la proposition \ref{PROPooKJTCooVTXWAQ} est que
\begin{equation}
	\dim(V\otimes W)=\dim(V)\dim(W)
\end{equation}
via le lemme \ref{LEMooJXFIooKDzRWR}\ref{ITEMooPMLWooNbTyJI}.

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Bases}
%---------------------------------------------------------------------------------------------------------------------------

Voici un lemme entièrement dédié au principe «dans le Frido, on ne fait pas d'abus de notations, sauf pour la logique formelle et la théorie des ensembles, que nous admettons».
\begin{lemma}[\cite{MonCerveau}]        \label{LEMooXFIMooDkTSrq}
	Si \( \tau\colon V_1\to V_2\) est un isomorphisme d'espaces vectoriels, alors
	\begin{equation}        \label{EQooEYUGooYYRZxD}
		\begin{aligned}
			\varphi\colon V_1\otimes W & \to V_2\otimes W         \\
			v\otimes w                 & \mapsto \tau(v)\otimes W
		\end{aligned}
	\end{equation}
	est un isomorphisme d'espaces vectoriels.
\end{lemma}

\begin{proof}
	Comme d'habitude, l'expression \eqref{EQooEYUGooYYRZxD} ne définit pas réellement \( \varphi\) parce que nous ne savons pas du tout si \( \{v\otimes w\tq v\in V,w\in W\}\) est plus ou moins une base de \( V\otimes W\)\footnote{Ne lisez pas la proposition \ref{PROPooTHDPooWgjUwk} qui dévoile toute l'intrigue.}. Ce que dit réellement ce lemme est qu'il existe une application \( V_1\otimes W\to V_2\otimes W\) qui est isomorphisme et qui se réduit à l'expression donnée dans le cas d'éléments de \( V_1\otimes W\) de la forme \( v\otimes w\).

	L'application
	\begin{equation}
		\begin{aligned}
			\varphi_0\colon F(V_1\times W) & \to F(V_2\times W)                     \\
			\delta{(v,w)}                  & \mapsto \delta_{\big( \tau(v),w \big)}
		\end{aligned}
	\end{equation}
	est un isomorphisme.

	Cette application passe aux classes, mais pas au sens où \( x\in [y]\) impliquerait \( \varphi_0(x)=\varphi_0(y)\); au sens où si \( x\in [y]\), alors \( \varphi_0(x)\in[\varphi_0(y)]\). Par exemple
	\begin{equation}
		\varphi_0\big( \lambda\delta_{(v,w)}-\delta_{(v,\lambda w)} \big)=\lambda\delta_{\big( \tau(v),w \big)}-\delta_{\big( \tau(v),w \big)}\in [0].
	\end{equation}
	Nous vous laissons le soin de vérifier les égalités correspondantes pour les autres parties de \( N\).

	Le passage au classes de \( \varphi_0\) signifie que l'on considère l'application
	\begin{equation}
		\begin{aligned}
			\varphi\colon V_1\otimes W & \to V_2\otimes W       \\
			[x]                        & \mapsto [\varphi_0(x)]
		\end{aligned}
	\end{equation}
	où vous aurez noté que la prise de classe à gauche n'est pas la même que celle à droite.

	Il faut prouver que ce \( \varphi\) est un isomorphisme. En ce qui concerne la linéarité,
	\begin{subequations}
		\begin{align}
			\varphi\big( [x]+[y] \big) & =\varphi\big( [x+y] \big)      \\
			                           & =[\varphi_0(x+y)]              \\
			                           & =[\varphi_0(x)+\varphi_0(y)]   \\
			                           & =[\varphi_0(x)]+[\varphi_0(y)] \\
			                           & =\varphi([x])+\varphi([y]).
		\end{align}
	\end{subequations}
	Je vous laisse le reste de la linéarité. Et en ce qui concerne le fait que ce soit une bijection, allez-y.
\end{proof}

\begin{proposition}[\cite{ooNHIGooYlXxMf}]      \label{PROPooTHDPooWgjUwk}
	Soient des espaces vectoriels de dimension finie \( V\) et \( W\). Soient une base \( \{e_i\}\) de \( V\) et une base \( \{f_{\alpha}\}\) de \( W\).

	Alors :
	\begin{enumerate}
		\item       \label{ITEMooQCILooUncdGl}
		      La partie \( \{e_i\otimes f_{\alpha}\}\) est une base de \( V\otimes W\).
		\item
		      Au niveau des dimensions, \( \dim(V\otimes W)=\dim(V)\dim(W)\).
	\end{enumerate}
\end{proposition}

\begin{proof}
	Vu que \( V\) est de dimension finie, nous avons un isomorphisme d'espaces vectoriels \( V^*=V\), et même un isomorphisme d'espaces vectoriels
	\begin{equation}
		\begin{aligned}
			\tau\colon V  & \to (V^*)^* \\
			\tau(v)\alpha & =\alpha(v).
		\end{aligned}
	\end{equation}
	Recopions l'isomorphisme de la proposition \ref{PROPooKJTCooVTXWAQ} en utilisant \( V^*\) au lieu de \( V\) :
	\begin{equation}
		\begin{aligned}
			\psi_0\colon (V^*)^*\otimes W & \to \aL(V^*,W)                                                  \\
			\tau(v)\otimes w              & \mapsto \big( \alpha\mapsto \tau(v)(\alpha)w =\alpha(v)w \big).
		\end{aligned}
	\end{equation}
	En écrivant cela, nous avons tenu compte du fait que tout élément de \( (V^*)^*\) peut être écrit de façon univoque sous la forme \( \tau(v)\) pour un certain \( v\in V\).

	Vu que \( \tau\) est un isomorphisme, l'application suivante est encore un isomorphisme\footnote{Lemme \ref{LEMooXFIMooDkTSrq}.} :
	\begin{equation}        \label{EQooAEFRooPfmAnj}
		\begin{aligned}
			\psi\colon V\otimes W & \to \aL(V^*,W)                                \\
			v\otimes w            & \mapsto \big( \alpha\mapsto \alpha(v)w \big).
		\end{aligned}
	\end{equation}
	Nous avançons. Vu que nous avons un isomorphisme, nous pouvons faire passer des bases. Le lemme \ref{LEMooJXFIooKDzRWR} nous donne une base de \( \aL(V^*,W)\) en les éléments \( \beta_{i\alpha}\colon V^*\to W\) définies par
	\begin{equation}
		\beta_{ij}(\alpha)=\alpha(e_i)f_{\alpha}.
	\end{equation}
	Donc \( \{ \psi^{-1}(\beta_{i\alpha}) \}\) est une base de \( V\otimes W\).

	Pour \( a=\sum_ia_ie_i^*\) (base duale, définition \ref{DEFooTMSEooZFtsqa}) nous avons :
	\begin{equation}
		\psi(e_i\otimes f_{\alpha})a=a(e_i)f_{\alpha}=\beta_{i\alpha}(a).
	\end{equation}
	Cela prouve que \( \psi^{-1}(\beta_{i\alpha})=e_i\otimes f_{\alpha}\), et donc que ces \( e_i\otimes f_{\alpha}\) est une base de \( V\otimes W\).

	La formule concernant les dimensions est simplement la définition \ref{DEFooWRLKooArTpgh} de la dimension : le nombre d'éléments dans une base.
\end{proof}

\begin{example}
	Dans le produit tensoriel \( \eR\otimes \eR\), nous avons \( x\otimes 1=1\otimes x=x(1\otimes x)\) pour tout \( x\in \eR\). Et si \( x\geq 0\) nous avons aussi \( x\otimes 1=\sqrt{ x }\otimes \sqrt{ x }\).
\end{example}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Norme}
%---------------------------------------------------------------------------------------------------------------------------

Nous considérons des espaces vectoriels \( V\) et \( W\) de dimension finie. L'application \eqref{EQooAEFRooPfmAnj} donne un isomorphisme d'espaces vectoriels
\begin{equation}
	\begin{aligned}
		\psi\colon V\otimes W & \to \aL(V^*,W)                                \\
		v\otimes w            & \mapsto \big( \alpha\mapsto \alpha(v)w \big).
	\end{aligned}
\end{equation}
Et ça, c'est très bien, parce que nous connaissons une norme sur \( \aL(V^*,W)\) :  la norme opérateur \ref{DefNFYUooBZCPTr}.

\begin{definition}[\cite{MonCerveau}]      \label{DEFooEXXNooMgIpSV}
	Soient deux espaces vectoriels normés de dimension finie \( V\) et \( W\). Sur \( V\otimes W\) nous définissons, pour \( t\in V\otimes W\)
	\begin{equation}
		\| t \|=\| \psi(t) \|_{\aL(V^*,W)}.
	\end{equation}
\end{definition}

\begin{lemma}[\cite{MonCerveau}]        \label{LEMooQPXHooJWfpmk}
	La norme sur \( V\otimes W\) vérifie
	\begin{equation}
		\| v\otimes w \|=\| v \|\| w \|
	\end{equation}
	pour tout \( v\in V\) et \( w\in W\).
\end{lemma}

\begin{proof}
	C'est un simple(?) calcul :
	\begin{equation}
		\| v\otimes w \|=\| \psi(v\otimes w) \|=\| \alpha\mapsto \alpha(v)w \|=\sup_{\| \alpha \|=1}\| \alpha(v)w \|=\sup_{\| \alpha \|=1}| \alpha(v) |\| w \|.
	\end{equation}
	Étant donné que \( V\) est de dimension finie, \( \sup_{\| \alpha \|=1}| \alpha(v) |=\| v \|\)\quext{Cela est une des raisons pour lesquelles nous sommes en dimension finie : je ne sais pas si cette égalité est vraie en dimension inifinie.}. Nous avons donc
	\begin{equation}
		\| v\otimes w \|=\| v \|\| w \|.
	\end{equation}
\end{proof}

Le lemme suivant montre que \( \eR\otimes \eR\) n'est pas du tout \( \eR\times \eR=\eR^2\). Au contraire, \( \eR\otimes \eR\) est isomorphe à \( \eR\).
\begin{lemma}[\cite{MonCerveau}]        \label{LEMooVONEooQpPgcn}
	L'application
	\begin{equation}
		\begin{aligned}
			\varphi\colon \eR\otimes \eR & \to \eR   \\
			1\otimes 1                   & \mapsto 1
		\end{aligned}
	\end{equation}
	prolongée par linéarité est un isomorphisme isométrique.
\end{lemma}

\begin{proof}
	D'abord une base de \( \eR\) est \( \{ 1 \}\); donc une base de \( \eR\otimes \eR\) est \( \{ 1\otimes 1 \}\) par la proposition \ref{PROPooTHDPooWgjUwk}. Donc l'application proposée se prolonge par linéarité à tout \( \eR\otimes \eR\).

	Le fait que \( \varphi\) soit une bijection provient du fait que \( \varphi\) transforme une base en une base; si vous n'y croyez pas, la vérification de l'injectivité et de la surjectivité est facile.

	Pour que \( \varphi\) soit isométrique, nous faisons le calcul
	\begin{equation}
		\| \varphi(x\otimes y) \|=\| xy(1\otimes 1) \|=| xy |\| 1\otimes 1 \|=| xy |=\| x\otimes y \|.
	\end{equation}
	Nous avons utilisé la propriété \ref{DefNorme}\ref{ItemDefNormeii} d'une norme ainsi que le lemme \ref{LEMooQPXHooJWfpmk} pour la norme sur \( \eR\otimes \eR\).
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Applications bilinéaires, matrices et produit tensoriel}
%---------------------------------------------------------------------------------------------------------------------------
\label{SECooUKRYooZjagcX}

Soit \( E\), un espace vectoriel de dimension finie. Si \( \alpha\) et \( \beta\) sont deux formes linéaires sur un espace vectoriel \( E\), nous définissons \( \alpha\otimes \beta\) comme étant la \( 2\)-forme donnée par
\begin{equation}        \label{EQooUNRYooKBrXyK}
	(\alpha\otimes \beta)(u,v)=\alpha(u)\beta(v).
\end{equation}
Si \( a\) et \( b\) sont des vecteurs de \( E\), ils sont vus comme des formes sur \( E\) via le produit scalaire et nous avons
\begin{equation}
	(a\otimes b)(u,v)=(a\cdot u)(b\cdot v).
\end{equation}
Cette dernière équation nous incite à pousser un peu plus loin la définition de \( a\otimes b\) et de simplement voir cela comme la matrice de composantes
\begin{equation}
	(a\otimes b)_{ij}=a_ib_j.
\end{equation}
Cette façon d'écrire a l'avantage de ne pas demander de se souvenir qui est une vecteur ligne, qui est un vecteur colonne et où il faut mettre la transposée. Évidemment \( (a\otimes b)\) est soit \( ab^t\) soit \( a^tb\) suivant que \( a\) et \( b\) soient ligne ou colonne.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Application d'opérateurs}
%---------------------------------------------------------------------------------------------------------------------------

\begin{lemma}   \label{LemMyKPzY}
	Soient \( x,y\in E\) et \( A,B\) deux opérateurs linéaires sur \( E\) vus comme matrices. Alors
	\begin{equation}        \label{EqXdxvSu}
		(Ax\otimes By)=A(x\otimes y)B^t.
	\end{equation}
\end{lemma}

\begin{proof}
	Calculons la composante \( ij\) de la matrice \( (Ax\otimes By)\). Nous avons
	\begin{subequations}
		\begin{align}
			(Ax\otimes By)_{ij} & =(Ax)_i(By)_j                       \\
			                    & =\sum_{kl}A_{ik}x_kB_{jl}y_l        \\
			                    & =A_{ik}(x\otimes y)_{kl}B_{jl}      \\
			                    & =\big( A(x\otimes y)B^t \big)_{ij}.
		\end{align}
	\end{subequations}
\end{proof}


Le fait que les applications linéaires soient continues\footnote{Proposition \ref{PROPooQZYVooYJVlBd}.} est valable dans une assez large gamme d'espaces vectoriels\cite{BIBooUWMLooWEPxcC}. Nous voyons ici dans le cas des espaces vectoriels normés de dimension finies.
\begin{proposition}     \label{PROPooADPDooOtukQP}
	Soient des espaces vectoriels normés \( E\) et \( F\). Si \( f\colon E\to F\) est une application linéaire et si \( E\) est de dimension finie, alors \( f\) est continue.
\end{proposition}

\begin{proof}
	La proposition \ref{DefNFYUooBZCPTr}\ref{ITEMooGIPIooUvVBIv} nous dit que \( \| f \|<\infty\), c'est-à-dire que \( f\) est borné. Donc la proposition \ref{PROPooQZYVooYJVlBd} conclut.
\end{proof}


\begin{lemma}   \label{LemWWXVSae}
	Soit \( F\) un espace de Banach et deux suites \( A_k\to A\) et \( B_k\to B\) dans \( \aL(F,F)\). Alors \( A_k\circ B_k\to A\circ B\) dans \( \aL(F,F)\), c'est-à-dire
	\begin{equation}
		\lim_{n\to \infty} (A_kB_k)=\left( \lim_{n\to \infty} A_k \right)\left( \lim_{n\to \infty} B_k \right).
	\end{equation}
\end{lemma}

\begin{proof}
	Il suffit d'écrire
	\begin{equation}
		\| A_kB_k-AB \|\leq \| A_kB_k-A_kB \|+\| A_kB-AB \|.
	\end{equation}
	Le premier terme tend vers zéro pour \( k\to\infty\) parce que
	\begin{subequations}
		\begin{align}
			\| A_kB_k-A_kB \| & =\| A_k(B_k-B) \|                           \\
			                  & \leq \| A_k \|\| B_k-B \|\to \| A \|\cdot 0 \\
			                  & =0
		\end{align}
	\end{subequations}
	où nous avons utilisé la propriété fondamentale de la norme opérateur : la proposition~\ref{PROPooQZYVooYJVlBd}. Le second terme tend également vers zéro pour la même raison.
\end{proof}



%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Sommes de familles infinies}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\label{SECooHHDXooUgLhHR}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Convergence commutative}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}
	Soit \( x_k\) une suite dans un espace vectoriel normé \( E\). Nous disons que la suite \defe{converge commutativement}{convergence!commutative} vers \( x\in E\) si \( \lim_{n\to \infty}\| x_n-x \| =0\) et si pour toute bijection \( \tau\colon \eN\to \eN\) nous avons aussi
	\begin{equation}
		\lim_{n\to \infty} \| x_{\tau(k)}-x \|=0.
	\end{equation}
	La notion de convergence commutative est surtout intéressante pour les séries. La somme
	\begin{equation}
		\sum_{k=0}^{\infty}x_k
	\end{equation}
	converge commutativement vers \( x\) si \( \lim_{N\to \infty} \| x-\sum_{k=0}^Nx_k \|=0\) et si pour toute bijection \( \tau\colon \eN\to \eN\) nous avons
	\begin{equation}
		\lim_{N\to \infty} \| x-\sum_{k=0}^Nx_{\tau(k)} \|=0.
	\end{equation}
\end{definition}

Nous démontrons maintenant qu'une série converge réelle commutativement si et seulement si elle converge absolument.

\begin{proposition} \label{PopriXWvIY}
	Soit \( (a_i)_{i\in \eN}\) une suite absolument convergente\footnote{Définition \ref{DefVFUIXwU}.} dans \( \eC\). Alors elle converge commutativement.
\end{proposition}

\begin{proof}
	Soit \( \epsilon>0\). Nous posons \( \sum_{i=0}^\infty a_i=a\) et nous considérons \( N\) tel que
	\begin{equation}
		| \sum_{i=0}^Na_i-a |<\epsilon.
	\end{equation}
	Étant donné que la série des \( | a_i |\) converge, il existe \( N_1\) tel que pour tout \( p,q>N_1\) nous ayons \( \sum_{i=p}^q| a_i |<\epsilon\). Nous considérons maintenant une bijection \( \tau\colon \eN\to \eN \). Prouvons que la série \( \sum_{i=0}^{\infty}| a_{\tau(i)} |\) converge. Nous choisissons \( M\) de telle sorte que pour tout \( n>M\), \( \tau(n)>N_1\). Si \( s_k\) est la somme partielle de la suite \( ( a_{\tau(i)} )_{i\in \eN}\) et si \( M<p<q \) nous avons
	\begin{equation}
		| s_q-s_p |= | \sum_{i=p}^q a_{\tau(i)} | \leq \sum_{i=p}^q| a_{\tau(i)} |<\epsilon.
	\end{equation}
	Cela montre que \( (s_k)\) est une suite de Cauchy. Elle est alors convergente et nous en déduisons que la série
	\begin{equation}
		\sum_{i=0}^{\infty}a_{\tau(i)}
	\end{equation}
	converge. Nous devons montrer à présent qu'elle converge vers la même limite que la somme «usuelle» \( \lim_{N\to \infty} \sum_{i=0}^Na_i\).

	Soit \( n>\max\{ M,N \}\). Alors
	\begin{equation}
		\sum_{k=0}^na_{\tau(k)}-\sum_{k=0}^na_k=\sum_{k=0}^Ma_{\tau(k)}-\sum_{k=0}^Na_k+\underbrace{\sum_{M+1}^na_{\tau(k)}}_{<\epsilon}-\underbrace{\sum_{k=N+1}^na_k}_{<\epsilon}.
	\end{equation}
	Par construction les deux derniers termes sont plus petits que \( \epsilon\) parce que \( M\) et \( N\) sont les constantes de Cauchy pour les séries \( \sum a_{\tau(i)}\) et \( \sum a_i\). Afin de traiter les deux premiers termes, quitte à redéfinir \( M\), nous supposons que \( \{ 1,\ldots, N \}\subset \tau\{ 1,\ldots, M \}\); par conséquent tous les \( a_i\) avec \( i<N\) sont atteints par les \( a_{\tau(i)}\) avec \( i<M\). Dans ce cas, les termes qui restent dans la différence
	\begin{equation}
		\sum_{k=0}a_{\tau(k)}-\sum_{k=0}^Na_k
	\end{equation}
	sont des \( a_k\) avec \( k>N\). Cette différence est donc en valeur absolue plus petite que \( \epsilon\), et nous avons en fin de compte que
	\begin{equation}
		\left| \sum_{k=0}^na_{\tau(k)}-\sum_{k=0}^na_k \right| <\epsilon.
	\end{equation}
\end{proof}

\begin{proposition}[\cite{BIBooAMLZooLamOJO}]     \label{PropyFJXpr}
	Soit \( \sum_{k=0}^{\infty}a_k\) une série réelle qui converge mais qui ne converge pas absolument. Alors pour tout \( b\in \eR\), il existe une bijection \( \tau\colon \eN\to \eN\) telle que \( \sum_{i=0}^{\infty}a_{\tau(i)}=b\).
\end{proposition}

Les propositions~\ref{PopriXWvIY} et~\ref{PropyFJXpr} disent entre autres qu'une série dans \( \eC\) est commutativement sommable si et seulement si elle est absolument sommable.

Soit \( (a_i)_{i\in I}\) une famille de nombres complexes indexée par un ensemble \( I\) quelconque. Nous allons nous intéresser à la somme \( \sum_{i\in I}a_i\).

Soit \( \{ a_i \}_{i\in I}\) des nombres positifs. Nous définissons la somme
\begin{equation}
	\sum_{i\in I}a_i=\sup_{ J\text{ fini}}\sum_{j\in J}a_j.
\end{equation}
Notons que cela est une définition qui ne fonctionne bien que pour les sommes de nombres positifs. Si \( a_i=(-1)^i\), alors selon la définition nous aurions \( \sum_i(-1)^i=\infty\). Nous ne voulons évidemment pas un tel résultat.


\begin{definition}  \label{DefIkoheE}
	Si \( \{ v_i \}_{i\in I}\) est une famille de vecteurs dans un espace vectoriel normé indexée par un ensemble quelconque \( I\). Nous disons que cette famille est \defe{sommable}{famille!sommable} de somme \( v\) si pour tout \( \epsilon>0\), il existe un \( J_0\) fini dans \( I\) tel que pour tout ensemble fini \( K\) tel que \( J_0\subset K\) nous avons
	\begin{equation}
		\| \sum_{j\in K}v_j-v \|<\epsilon.
	\end{equation}
\end{definition}
Notons que cette définition implique la convergence commutative.

Dans le cas de familles de nombres réels positifs, nous avons une caractérisation plus comode.
\begin{proposition}  \label{DefHYgkkA}
	% TODOooCNAJooDWEXlI prouver ceci, changer le label et les endroits où c'est référentié.
	Soit \( (a_i)_{i\in I}\) une famille de nombres réels positifs indexés par un ensemble quelconque \( I\). Nous définissons
	\begin{equation}
		\sum_{i\in I}a_i=\sup_{ J\text{ fini dans } I}\sum_{j\in J}a_j.
	\end{equation}
\end{proposition}

\begin{lemma}       \label{LEMooGXPGooZTJPoN}
	Soient un espace vectoriel normé \( V\) ainsi qu'une suite \( (a_k)_{k\in \eN}\) telles que \( \sum_{k\in \eN}\) existe. Alors
	\begin{equation}
		\sum_{k\in \eN}a_k=\lim_{N\to \infty} \sum_{k=0}^N a_k.
	\end{equation}
	La somme à gauche est celle de la définition \ref{DefIkoheE} et celle de droite est donnée par la définition \ref{DEFooNEVNooJlmJOC}.
\end{lemma}

\begin{example}
	La suite \( a_i=(-1)^i\) n'est pas sommable parce que quel que soit \( J_0\) fini dans \( \eN\), nous pouvons trouver \( J\) fini contenant \( J_0\) tel que \( \sum_{j\in J}(-1)^j>10\). Pour cela il suffit d'ajouter à \( J_0\) suffisamment de termes pairs. De la même façon en ajoutant des termes impairs, on peut obtenir \( \sum_{j\in J'}(-1)^i<-10\).
\end{example}

\begin{example}
	De temps en temps, la somme peut sortir d'un espace. Si nous considérons l'espace des polynômes \( \mathopen[ 0 , 1 \mathclose]\to \eR\) muni de la norme uniforme, la somme de l'ensemble
	\begin{equation}
		\{ 1,-1,\pm\frac{ x^n }{ n! } \}_{n\in \eN}
	\end{equation}
	est zéro.

	Par contre la somme de l'ensemble \( \{ 1,\frac{ x^n }{ n! } \}_{n\in \eN}\) est l'exponentielle qui n'est pas un polynôme.
\end{example}

\begin{proposition}[\cite{MonCerveau}]      \label{PROPooJLQAooAEbIvZ}
	Soient un espace vectoriel normé \( V\), deux ensembles disjoints \( A\) et \( B\) ainsi que \( v\colon A\cup B\to V\). Si \( \sum_{k\in A}v_k\) et \( \sum_{k\in B}v_k\) sont sommables\footnote{Définition \ref{DefIkoheE}.}, alors
	\begin{equation}
		\sum_{k\in A\cup B}v_k=\sum_{k\in A}v_k+\sum_{k\in B}v_k.
	\end{equation}
\end{proposition}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Somme non dénombrables}
%---------------------------------------------------------------------------------------------------------------------------

Nous allons voir que les sommes non dénombrables ne sont pas intéressantes : si le nombre de valeurs non nulles parmi les \( (x_i)_{i\in I}\) est non dénombrable, alors la somme est infinie. La bonne généralisation de somme infinie dans le cas non dénombrable est l'intégrale qui viendra seulement avec la définition \ref{DefTVOooleEst} et la mesure de Lebesgue \ref{DefooYZSQooSOcyYN}.

\begin{lemma}       \label{LEMooYJCVooHajEbg}
	Si \( A\) est non dénombrable dans \( \eR\), alors il existe \( \delta>0\) tel que \( A\cap \{ | x |\geq \delta \}\) est non dénombrable.
\end{lemma}

\begin{proof}
	Nous y allons par l'absurde, et nous supposons que \( A\) ne contient pas zéro (sinon il faut ajouter zéro aux \( A_n\) ci-dessous, et ça alourdit les notations). Nous supposons donc que les parties
	\begin{equation}
		A_n=A\cap\{ | x |\geq \frac{1}{ n } \}
	\end{equation}
	sont dénombrables. Mais
	\begin{equation}
		A\subset \bigcup_{n=1}^{\infty}A_n.
	\end{equation}
	Une union dénombrable d'ensembles dénombrables est dénombrable\footnote{Proposition \ref{PROPooENTPooSPpmhY}.}. Vu qu'un ensemble non dénombrable ne peut être inclus dans un ensemble dénombrable\footnote{Proposition \ref{PropQEPoozLqOQ}.}, nous avons une contradiction.
\end{proof}

\begin{lemma}       \label{LEMooQIMGooOUpZjk}
	Soit un ensemble \( I\) et une «suite» \( (x_i)_{i\in I}\) avec \( x_i\geq 0\) pour tout \( i\). Si l'ensemble
	\begin{equation}
		F=\{ i\in I\tq x_i>0 \}
	\end{equation}
	est non dénombrable, alors
	\begin{equation}
		\sum_{i\in I}x_i=\infty.
	\end{equation}
\end{lemma}

\begin{proof}
	Nous considérons l'ensemble des valeurs non nulles atteintes par \( x\) :
	\begin{equation}
		V=\{ x_i\tq i\in F \}.
	\end{equation}
	Il y a deux possibilités : soit \( V\) est dénombrable (ou fini), soit il est non dénombrable.

	\begin{subproof}
		\spitem[\( V\) est fini ou dénombrable]
		Dans ce cas, l'application \( x\colon F\to \mathopen[ 0 , \infty \mathclose[\) est une application d'un ensemble indénombrable vers un ensemble dénombrable. Le lemme \ref{LEMooGTOTooFbpvzU} nous indique qu'il existe \( y\in \eR\) tel que \( x^{-1}(y)\) est indénombrable et en particulier infini. La somme \( \sum_{i\in x^{-1}(y)}x_i\) est une somme indénombrable de termes tous égaux et strictement positifs. Elle est infinie.

		\spitem[\( V\) est indénombrable]
		La partie \( V\) de \( \eR\) est non dénombrable; elle est donc sujette au lemme \ref{LEMooYJCVooHajEbg} : il existe \( \delta>0\) tel que \( W=V\cap\{ x\geq \delta \}\) est indénombrable. Vu que \( x_i\geq \delta\) pour tout \( i\) dans \( x^{-1}(W)\) nous avons
		\begin{equation}
			\sum_{i\in x^{-1}(W)}x_i=\infty.
		\end{equation}
	\end{subproof}
\end{proof}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Sommes dénombrables}
%---------------------------------------------------------------------------------------------------------------------------

Nous avons vu que les sommes non dénombrables ne sont pas intéressantes. La notion \ref{DefHYgkkA} de sommes est par contre réellement plus utile que la notion de somme sur \( \eN\) parce que \( \eN\) a un ordre. En effet une somme sur \( \eN\) peut être définie par les sommes partielles avec un ordre sans réelle discussions, alors que l'ordre de sommation sur \( \eZ\) est déjà plus discutable. Bref, nous allons voir maintenant quelques propriétés de la somme \ref{DefHYgkkA} dans le cas dénombrable.

\begin{example}     \label{EXooULLXooTDFYqf}
	Au sens de la définition~\ref{DefIkoheE} la famille
	\begin{equation}
		\frac{ (-1)^n }{ n }
	\end{equation}
	n'est pas sommable. En effet la somme des termes pairs est \( \infty\) alors que la somme des termes impairs est \( -\infty\). Quel que soit \( J_0\in \eN\), nous pouvons concocter, en ajoutant des termes pairs, un \( J\) avec \( J_0\subset J\) tel que \( \sum_{j\in J}(-1)^j/j\) soit arbitrairement grand. En ajoutant des termes négatifs, nous pouvons également rendre \( \sum_{j\in J}(-1)^j/j\) arbitrairement petit.
\end{example}

\begin{proposition} \label{PropVQCooYiWTs}
	Si \( (a_{ij})\) est une famille de nombres positifs indexés par \( \eN\times \eN\) alors
	\begin{equation}
		\sum_{(i,j)\in \eN^2}a_{ij}=\sum_{i=1}^{\infty}\Big( \sum_{j=1}^{\infty}a_{ij} \Big)
	\end{equation}
	où la somme de gauche est celle de la définition~\ref{DefHYgkkA}.
\end{proposition}
%TODO : cette proposition peut être vue comme une application de Fubini pour la mesure de comptage. Le faire et référentier ici.

\begin{proof}
	Nous considérons \( J_{m,n}=\{ 0,\ldots, m \}\times \{ 0,\ldots, n \}\) et nous avons pour tout \( m\) et \( n\) :
	\begin{equation}
		\sum_{(i,j)\in \eN^2}a_{ij}\geq \sum_{(i,j)\in J_{m,n}}a_{ij}=\sum_{i=1}^m\Big( \sum_{j=1}^na_{ij} \Big).
	\end{equation}
	Si nous fixons \( m\) et que nous prenons la limite \( n\to \infty\) (qui commute avec la somme finie sur \( i\)) nous trouvons
	\begin{equation}
		\sum_{(i,j)\in \eN^2}a_{ij}\geq =\sum_{i=1}^m\Big( \sum_{j=1}^{\infty}a_{ij} \Big).
	\end{equation}
	Cela étant valable pour tout \( m\), c'est encore valable à la limite \( m\to \infty\) et donc
	\begin{equation}
		\sum_{(i,j)\in \eN^2}a_{ij}\geq \sum_{i=1}^{\infty}\Big( \sum_{j=1}^{\infty}a_{ij} \Big).
	\end{equation}

	Pour l'inégalité inverse, il faut remarquer que si \( J\) est fini dans \( \eN^2\), il est forcément contenu dans \( J_{m,n}\) pour \( m\) et \( n\) assez grand. Alors
	\begin{equation}
		\sum_{(i,j)\in J}a_{ij}\leq \sum_{(i,j)\in J_{m,n}}a_{ij}=\sum_{i=1}^m\sum_{j=1}^na_{ij}\leq \sum_{i=1}^{\infty}\Big( \sum_{j=1}^{\infty}a_{ij} \Big).
	\end{equation}
	Cette inégalité étant valable pour tout ensemble fini \( J\subset \eN^2\), elle reste valable pour le supremum.
\end{proof}

La définition générale de la somme~\ref{DefIkoheE} est compatible avec la définition usuelle dans les cas où cette dernière s'applique.
\begin{proposition}[commutative sommabilité]\label{PropoWHdjw}
	Soit \( I\) un ensemble dénombrable et une bijection \( \tau\colon \eN\to I\). Soit \( (a_i)_{i\in I}\) une famille dans un espace vectoriel normé.  Si \( \sum_{i\in I}a_i\) existe, alors il est donné par
	\begin{equation}
		\sum_{i\in I}a_i=\lim_{N\to \infty} \sum_{k=0}^Na_{\tau(k)}.
	\end{equation}
\end{proposition}

\begin{proof}
	Nous posons \( a=\sum_{i\in I}a_i\). Soit \( \epsilon>0\) et \( J_0\) comme dans la définition. Nous choisissons
	\begin{equation}
		N>\max_{j\in J_0}\{ \tau^{-1}(j) \}.
	\end{equation}
	En tant que sommes sur des ensembles finis, nous avons l'égalité
	\begin{equation}
		\sum_{k=0}^Na_{\tau(k)}=\sum_{j\in J_0}a_j
	\end{equation}
	où \( J\) est un sous-ensemble de \( I\) contenant \( J_0\). Soit \( J\) fini dans \( I\) tel que \( J_0\subset J\). Nous avons alors
	\begin{equation}
		\| \sum_{k=0}^Na_{\tau(k)}-a \|=\| \sum_{j\in J}a_j-a \|<\epsilon.
	\end{equation}
	Nous avons prouvé que pour tout \( \epsilon\), il existe \( N\) tel que \( n>N\) implique \( \| \sum_{k=0}^na_{\tau(k)}-a\| <\epsilon\).
\end{proof}

La réciproque n'est pas vraie. Même en supposant que \( \lim_{N\to \infty} \sum_{n=0}^Na_n\) existe, il n'est pas forcé que \( \sum_{n\in\eN}a_n\) existe. Cela est une conséquence de l'exemple \ref{EXooULLXooTDFYqf}.

La proposition suivante nous enseigne que les sommes infinies peuvent être manipulée de façon usuelle.
\begin{proposition} \label{PropMpBStL}
	Soit \( I\) un ensemble dénombrable. Soient \( (a_i)_{i\in I}\) et \( (b_i)_{i\in I}\), deux familles de réels positifs telles que \( a_i<b_i\) et telles que \( (b_i)\) est sommable. Alors \( (a_i)\) est sommable.

	Si \( (a_i)_{i\in I}\) est une famille de complexes telle que \( (| a_i |)\) est sommable, alors \( (a_i)\) est sommable.
\end{proposition}

\begin{proposition}[\cite{MonCerveau}]     \label{PROPooWLEDooJogXpQ}
	Soit un espace vectoriel normé \( E\) et une famille sommable\footnote{Définition~\ref{DefIkoheE}.} \( \{ v_i \}_{i\in I}\) d'éléments de \( E\). Soit \( f\colon E\to \eC\) une application sur laquelle nous supposons
	\begin{enumerate}
		\item
		      \( f\) est linéaire et continue;
		\item
		      la partie \( \{ f(v_i)_{i\in I} \} \) est sommable.
	\end{enumerate}
	Alors nous pouvons permuter la somme et \( f\) :
	\begin{equation}        \label{EQooONHXooKqIEbY}
		f\big( \sum_{i\in I}v_i \big)=\sum_{i\in I}f(v_i).
	\end{equation}
\end{proposition}

\begin{proof}
	Soit \( \epsilon>0\); vu que les familles \( \{ v_i \}_{i\in I}\) et \( \{ f(v_i) \}_{i\in I}\) sont sommables, nous pouvons considérer les parties finies \( J_1\) et \( J_2\) de \( I\) telles que
	\begin{equation}
		\big\| \sum_{j\in J_1}v_j-\sum_{i\in I}v_i \big\|\leq \epsilon
	\end{equation}
	et
	\begin{equation}
		\big\| \sum_{j\in J_2}f(v_j)-\sum_{i\in I}f(v_i) \big\|\leq \epsilon
	\end{equation}
	Ensuite nous posons \( J=J_1\cup J_2\). Avec cela nous calculons un peu avec les majorations usuelles :
	\begin{equation}
		\| f(\sum_{i\in I}v_i) -\sum_{i\in I}f(v_i) \|\leq \| f(\sum_{i\in I}v_i)- f(\sum_{j\in J}v_j) \|+  \| f(\sum_{j\in J}v_j)-\sum_i\in If(v_i) \|.
	\end{equation}
	Le second terme est majoré par \( \epsilon\), tandis que le premier, en utilisant la linéarité de \( f\) possède la majoration
	\begin{equation}
		\| f(\sum_{i\in I}v_i)- f(\sum_{j\in J}v_j) \|=\| f(\sum_{i\in I}v_i-\sum_{j\in J}v_j) \|\leq \| f \| \| \sum_{i\in I}v_i- \sum_{j\in J}v_j\|\leq \epsilon\| f \|.
	\end{equation}
	Donc pour tout \( \epsilon>0\) nous avons
	\begin{equation}
		\| f(\sum_{i\in I}v_i) -\sum_{i\in I}f(v_i) \|\leq \epsilon(1+\| f \|).
	\end{equation}
	D'où l'égalité \eqref{EQooONHXooKqIEbY}.
\end{proof}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Convergence en norme et par composante}
%---------------------------------------------------------------------------------------------------------------------------

En dimension infinie, la convergence en norme et la convergence composante par composante ne s'impliquent ni dans un sens ni dans l'autre.

L'exemple suivant devrait être formalisé dans l'espace \( \ell^2\) des suites de carré sommable, mais vous voyez l'idée.
\begin{example}
	Nous considérons l'ensemble des suites réelle munie de la norme \( \| x \|=\sqrt{ \sum_{k=0}^{\infty}| x_k |^2 } \). Dedans nous considérons les vecteurs de base \( e_i\) donnés par
	\begin{equation}
		(e_i)_n=\delta_{in}.
	\end{equation}
	Ensuite nous considérons la base
	\begin{equation}
		f_i=e_1+\frac{1}{ 2^i }e_i.
	\end{equation}
	La suite \( x_n=f_n-f_1\), dans cette base a toujours \( -1\) comme première composante\footnote{N'essayez pas de faire un dessin : ça ne fonctionne qu'en dimension infinie.}. Et pourtant elle converge en norme vers \( 0\).
\end{example}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Calcul différentiel dans un espace vectoriel normé}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\label{SecLStKEmc}

Quelques motivations pour la notion de différentielle sont données dans \ref{SEBSECooLPRQooJRQCFL}.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Définition de la différentielle}
%---------------------------------------------------------------------------------------------------------------------------

\begin{propositionDef}[\cite{MonCerveau}]      \label{DefDifferentiellePta}
	Soient deux espaces vectoriels normés\footnote{Définition \ref{DefNorme}.} \( E\) et \( F\) ainsi qu'une fonction \( f\colon \mU\to F\) où \( \mU\) est un ouvert de \( E\). Si il existe une une application linéaire \( T\in\aL(E,F)\) satisfaisant
	\begin{equation}	\label{EqCritereDefDiff}
		\lim_{\substack{h\to 0\\h\in E}}\frac{f(a+h)-f(a)-T(h)}{\|h\|_E}=0,
	\end{equation}
	alors il en existe une seule.

	Dans ce cas nous disons que \( f\) est \defe{différentiable au point \( a\)}{application!différentiable} et l'application \( T\) ainsi définie est appelée \defe{différentielle}{différentielle} de \( f\) au point \( a\), et nous la notons \( df_a\).
\end{propositionDef}

\begin{proof}
	Soient deux applications linéaires \( T_1\), \( T_2\) satisfaisant la condition \eqref{EqCritereDefDiff}. Nous avons
	\begin{equation}
		\frac{ \| T_1(h)-T_2(h) \|_F }{ \| h \|_E }\leq \frac{ \| T_1(h)-f(a+h)+f(a) \| }{ \| h \| }+\frac{ \| f(a+h)-f(a)-T_2(h) \| }{ \| h \| }\to 0.
	\end{equation}
	Nous avons donc
	\begin{equation}
		\lim_{h\to 0} \frac{ \| (T_1-T_2)(h) \|_F }{ \| h \|_E }=0.
	\end{equation}
	Soit \( \epsilon>0\). Ce que signifie la limite est qu'il existe un \( r>0\) tel que pour tout \( u\in B_E(0,r)\), nous ayons
	\begin{equation}
		\frac{ \| (T_1-T_2)(u) \|_F }{ \| u \|_E }<\epsilon.
	\end{equation}
	Soit \( v\in E\). Nous considérons \( \lambda\in\eR\) tel que \( \lambda v\in B(0,r)\), par exemple \( \lambda<r/\| v \|\). Nous avons
	\begin{equation}
		\epsilon>\frac{ \| (T_1-T_2)(\lambda v) \|_F }{ \| \lambda v \|_E }=\frac{ \| (T_1-T_2)(v) \| }{ \| v \| }.
	\end{equation}
	Cela donne
	\begin{equation}
		\| (T_1-T_2)(v) \|<\| v \|\epsilon.
	\end{equation}
	Nous avons donc \( \| (T_1-T_2)(v) \|=0\), soit \( T_1(v)=T_2(v)\).
\end{proof}

L'application différentielle
\begin{equation}
	\begin{aligned}
		df\colon E & \to \aL(E,F) \\
		a          & \mapsto df_a
	\end{aligned}
\end{equation}
est également très importante.

\begin{definition}[\cite{ZCKMFRg, MonCerveau}]  \label{DefPNjMGqy}
	Soient deux espaces vectoriels normés \( V\) et \( W\) ainsi qu'une application \( f\colon V\to W\). Nous disons que \( f\) est
	\begin{itemize}
		\item de classe  \( C^0\) si elle est continue,
		\item de classe \( C^1\) si l'application différentielle \( df\colon V\to \aL(V,W)\),
		\item de classe \( C^k\) si sa différentielle est de classe \( C^{k-1}\).
		\item de classe \( C^{\infty}\) si elle est de classe \( C^k\) pour tout \( k\).
	\end{itemize}
\end{definition}
\index{application!différentiable}
\index{application!de classe \( C^k\)}

Le lien entre classe \( C^k\) et dérivées partielles d'ordre \( k\) sera le théorème \ref{THOooPZTAooTASBhZ}.

\begin{remark}
	Lorsque nous demandons que la différentielle de \( f\) soit continue, nous entendons bien la continuité de \( df\colon V\to \aL(V,W)\), c'est-à-dire la continuité de \( df_x\) par rapport à \( x\).
\end{remark}

\begin{definition}[difféomorphisme]      \label{DefAQIQooYqZdya}
	Soient \( U\) et \( V\), deux ouverts d'un espace vectoriel normé. Une application \( f\) de \( U\) dans \( V\) est un \defe{difféomorphisme}{difféomorphisme} si elle est bijective, différentiable\footnote{Différentiables, définition \ref{DefDifferentiellePta}.} et dont l'inverse \( f^{-1}:V\to U \) est aussi différentiable.

	Un \( C^k\)-difféomorphisme est un difféomorphisme qui est \( C^k\) et dont l'inverse est \( C^k\).
\end{definition}

\begin{normaltext}
	Truc marrant : un \( C^1\)-difféomorphisme n'est pas seulement un difféomorphisme qui est \( C^1\). L'inverse doit également être \( C^1\). Comment nommer un difféomorphisme qui est par ailleurs un application de classe \( C^1\) ? Je ne sais pas.
\end{normaltext}

\begin{remark}  % TOTOooVTLSooSNLVBD justifier ça.
	Il n'existe pas de bijection bicontinues d'un ouvert de \( \eR^m\) vers un ouvert de \( \eR^n\) si \( m\neq n\). Il n'y a donc pas de notion de difféomorphismes entre ouverts de dimensions différentes.
\end{remark}

\begin{remark}      \label{RemATQVooDnZBbs}
	L'application norme étant continue, le critère du théorème~\ref{ThoWeirstrassRn} est en réalité assez général. Par exemple à partir d'une application différentiable\footnote{Définition~\ref{DefDifferentiellePta}.} \( f\colon X\to Y\)  nous pouvons considérer la fonction réelle
	\begin{equation}
		a\mapsto \|  df_a   \|
	\end{equation}
	où la norme est la norme opérateur\footnote{Définition~\ref{DefNFYUooBZCPTr}.}. Si \( f\) est de classe \( C^1\) alors cette application est continue et donc bornée sur un compact \( K\) de \( X\).
\end{remark}


%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Différentielle d'applications linéaires}
%---------------------------------------------------------------------------------------------------------------------------

\begin{lemma}[Différentielle d'une application linéaire]       \label{LEMooZSNMooCfjzOB}
    Soient deux espaces vectoriels normés \( E\) et \( F\). Soit une application linéaire \( f\colon E\to F\).  La différentielle de \( f\) est l'application constante
    \begin{equation}
        \begin{aligned}
            df\colon E&\to  \aL(E,F) \\
            a&\mapsto f. 
        \end{aligned}
    \end{equation}
    Toutes les autres différentielles d'ordre supérieures sont nulles. En particulier une application linéaire est de classe \(  C^{\infty}\).
\end{lemma}

\begin{proof}
    Pour rappel, toujours bon à avoir en tête : \( df\colon E\to \aL(E,F)\). Soit \( a\in E\); nous avons
	\begin{equation}
		\lim_{h\to 0} \frac{ \| f(a+h)-f(a)- f(h) \|_F }{ \| h \|_E }=0
	\end{equation}
    parce que le numérateur est nul pour tout \( h\). Donc \( h\mapsto f(h)\) est la différentielle de \( f\) au point \( a\) parce que elle vérifie la condition \eqref{DefDifferentiellePta}.

    Nous avons prouvé que la différentielle de \( f\) est l'application constante
    \begin{equation}
        \begin{aligned}
            df\colon E&\to \aL(E,F) \\
            a&\mapsto f 
        \end{aligned}
    \end{equation}

    En ce qui concerne la différentielle seconde, nous prouvons que \( d(df)_a=0\) pour tout \( a\in E\). En effet,
    \begin{equation}
        \lim_{h\to 0} \frac{ \| df_{a+h}-df_a \|_{\aL(E,F)} }{ \| h \|_E }=0
    \end{equation}
    parce que le numérateur vaut \( f-f=0\).

    Maintenant il n'est pas compliqué de faire une récurrence : si \( f\) est de classe \( C^k\) et si \( d^k(f)=0\), alors \( d^k(f)\) est de classe \( C^1\) et \( d^kf=0\).
\end{proof}

\begin{lemma}       \label{LEMooAJDLooIPcmIV}
    Soient \( a<b\) dans \( \eR\). L'application
    \begin{equation}        \label{EQooIINJooAlSqKF}
        \begin{aligned}
            f\colon \mathopen[ a , b \mathclose]&\to \mathopen[ 0 , 1 \mathclose] \\
            x&\mapsto \frac{ x-a }{ b-a } 
        \end{aligned}
    \end{equation}
    est une \(  C^{\infty}\)-difféomorphisme\footnote{Définition \ref{DefPNjMGqy}.}.
\end{lemma}

\begin{proof}
    En plusieurs parties.
    \begin{subproof}
        \spitem[Valeurs dans \( \mathopen\lbrack 0 , 1 \mathclose\rbrack\)]     \label{ITEMooLRECooOSEqJL}
        Nous devons prouver que pour tout \( x\in\mathopen[ a , b \mathclose]\), nous avons \( f(x)\in \mathopen[ 0 , 1 \mathclose]\). D'une part si \( x\in\mathopen[ a , b \mathclose]\), alors \( x-a\geq 0\) et donc \( (x-a)/(b-a)\geq 0\).

        Dans l'autre sens, si \( (x-a)/(b-a)>1\), alors \( x-a>b-a\) et donc \( x>b\). Donc \( f(x)>1\) n'arrive jamais pour \( x\in \mathopen[ a , b \mathclose]\).
        \spitem[Injectif]
        % -------------------------------------------------------------------------------------------- 
        Si \( f(x)=f(t)\), alors en simplifiant par \( b-a\neq 0\), nous trouvons \( x-a=t-a\) et donc \( x=t\) (ne citez le lemme \ref{LEMooFQMVooDNaTDT} que si vous êtes capables de le prouver, sinon faites comme si c'était évident et il ne vous arrivera rien).
        \spitem[Surjectif]
        % -------------------------------------------------------------------------------------------- 
         Il est vite vérifié que 
         \begin{equation}       \label{EQooPSAWooNEJFih}
             f^{-1}(t)=t(b-a)+a,
         \end{equation}
         et en procédant de même qu'au point \ref{ITEMooLRECooOSEqJL}, nous voyons que pour tout \( t\in \mathopen[ 0 , 1 \mathclose]\), \( f^{-1}(t)\in\mathopen[ a , b \mathclose]\).
         \spitem[De classe \(  C^{\infty}\)]
         % -------------------------------------------------------------------------------------------- 
         C'est le lemme \ref{LEMooZSNMooCfjzOB} fait le travail parce que \eqref{EQooIINJooAlSqKF} est linéaire.
         \spitem[Inverse de classe \(  C^{\infty}\)]
         % -------------------------------------------------------------------------------------------- 
         Encore le lemme \ref{LEMooZSNMooCfjzOB} parce que \eqref{EQooPSAWooNEJFih} est linéaire.
    \end{subproof}
\end{proof}
