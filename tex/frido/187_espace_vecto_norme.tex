% This is part of Le Frido
% Copyright (c) 2008-2023
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.


%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Produit tensoriel d'espaces vectoriels}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Si vous êtes pressés, vous pouvez aller lire la définition \ref{DEFooKTVDooSPzAhH} de produit tensoriel d'espaces vectoriels. Mais si vous étiez vraiment pressés, vous ne seriez pas en train de lire des choses sur le produit tensoriel (il vous suffit de croire que \( x\otimes y\) n'est finalement que la concatenation de \( x\) et \( y\)).

\begin{propositionDef}      \label{PROPooYONEooWvwPZT}
	Soient un espace vectoriel \( V\) et un sous-espace \( N\). Le \defe{quotient}{quotient d'un espace vectoriel} de \( V\) par \( N\), noté \( V/N\) est l'ensemble des classes d'équivalence\footnote{Définition \ref{DEFooRHPSooHKBZXl}.} pour la relation \( x\sim y\) si et seulement si \( x-y\in N\).

	Les définitions
	\begin{enumerate}
		\item
		      \( [v]+[w]=[v+w]\)
		\item
		      \( \lambda[v]=[\lambda v]\)
	\end{enumerate}
	ont un sens et définissent une structure d'espace vectoriel sur \( V/N\).

	En ce qui concerne la topologie, ce sera la définition \ref{DEFooHWSYooZZLXQU}.
\end{propositionDef}

\begin{proof}
	Un élément général de la classe \( [v]\) est de la forme \( v+n\) avec \( n\in N\). Le calcul suivant montre que la somme fonctionne :
	\begin{equation}
		[v+n_1]+[w+n_2]=[v+w+n_1+n_2]=[v+w]
	\end{equation}
	parce que \( n_1+n_2\in N\). De même,
	\begin{equation}
		\lambda[v+n]=[\lambda v+\lambda n]=[\lambda v]
	\end{equation}
	toujours parce que \( \lambda n\in N\).

	Notons que nous avons utilisé de façon on ne peut plus cruciale le fait que \( N\) soit un sous-espace vectoriel.
\end{proof}

\begin{proposition}
	Si \( \{ e_i \}\) est une base de \( V\) et si \( N\) est un sous-espace de \( V\), alors \( \{ [e_i] \}\) est une partie génératrice de \( V/N\).
\end{proposition}

\begin{proof}
	Si \( x=\sum_kx_ke_k\), alors \( [x]=\sum_kx_k[e_k]\), donc oui.
\end{proof}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Les produits tensoriels}
%---------------------------------------------------------------------------------------------------------------------------

Nous allons procéder en deux temps. D'abord nous allons définir ce qu'est \emph{un} produit tensoriel entre deux espaces vectoriels \( V\) et \( W\), et nous allons montrer que tous les produits tensoriels possibles sont isomorphes. Ensuite nous allons montrer qu'un produit tensoriel existe en en construisant un. Voir la proposition \ref{PROPooIWZDooRRZNCf}.

\begin{definition}[\cite{ooWHNKooYVCiYc}]       \label{DEFooXKKQooAvWRNp}
	Soient deux espaces vectoriels \( V\) et \( W\). Un \defe{produit tensoriel}{produit tensoriel} de \( V\) et \( W\) est un couple \( (T,h)\) où \( T\) est un espace vectoriel et \( h\colon V\oplus W\to T\) est une application
	\begin{enumerate}
		\item
		      bilinéaire\footnote{Définition \ref{DEFooEEQGooNiPjHz}.}
		\item
		      surjective
		\item       \label{ITEMooJCNYooGvjjtL}
		      telle que pour tout espace vectoriel \( U\) et toute application bilinéaire \( f\colon V\oplus W\to U\), il existe une application linéaire \( g\colon T\to U\) telle que \( f=g\circ h\).
	\end{enumerate}
	La propriété \ref{ITEMooJCNYooGvjjtL} est appelée \defe{propriété universelle}{propriété universelle} du produit tensoriel.
\end{definition}

\begin{definition}  \label{DEFooPLHTooRiHjlE}
	Un \defe{morphisme}{morphisme de produits tensoriels} entre \( (T,h)\) et \( (T',h')\) est une application linéaire \( \psi\colon T\to T'\) telle que \( h'=\psi\circ h\).

	Nous parlons d'\defe{isomorphisme}{isomorphisme} si \( \psi\) a un inverse qui est également un morphisme.
\end{definition}

\begin{proposition}[\cite{ooWHNKooYVCiYc}]      \label{PROPooROPHooQXqNzZ}
	Si \( V\) et \( W\) sont des espaces vectoriels, tous les produits tensoriels entre \( V\) et \( W\) sont isomorphes entre eux au sens de la définition \ref{DEFooPLHTooRiHjlE}.

	Plus précisément, si \( (T,h)\) et \( (T',h')\) sont deux produits tensoriels de \( V\) et \( W\), alors
	\begin{enumerate}
		\item
		      il existe une unique application linéaire \( g\colon T\to T'\) telle que \( h'=g\circ h\),
		\item
		      cette application \( g\) est inversible.
	\end{enumerate}
	En particulier, l'application \( g\) est un isomorphisme d'espaces vectoriels.
\end{proposition}

\begin{proof}
	Soient deux produits tensoriels \( (T,h)\) et \( (T',h')\).

	\begin{subproof}
		\spitem[Existence]

		L'application \( h'\colon V\oplus W\to T'\) est bilinéaire, et \( (T,h)\) est un produit tensoriel. Donc il existe \( g\colon T\to T'\) tel que \( h'=g\circ h\). De même, il existe une application \( g'\colon T'\to T\) telle que \( h=g'\circ h\).

		\spitem[Unicité]

		En ce qui concerne l'unicité, vu que \( h\colon V\oplus W\to T\) est surjective, la relation \( h'=g\circ h\) prescrit les valeurs de \( g\) sur tous les éléments de \( T\).

		\spitem[Inversible]

		Ces deux applications \( g\) et \( g'\) vérifient \( h'=gg'h\) et \( h=g'gh\), et de plus \( h\colon V\oplus W\to T\) est surjective. Soient \( t\in T\) et \( x\in V\oplus W\) tel que \( t=h(x)\). Nous avons \( h(x)=g'gh(x)\). C'est-à-dire \( t=(g'\circ g)(t)\). De même dans l'autre sens, il existe \( x'\in V\oplus W\) tel que \( t=h'(x')\). En appliquant l'égalité \( h'=gg'h'\) à \( x'\), nous trouvons \( t=(g\circ g')(t)\).

		Tout cela pour dire que \( g'=g^{-1}\). Cette application \( g\) est donc un isomorphisme de produits tensoriels entre \( (T,h)\) et \( (T',h')\).
	\end{subproof}
	Au final, l'application \( g\colon T\to T'\) étant linéaire et inversible, elle est un isomorphisme d'espaces vectoriels.
\end{proof}

Tout cela est fort bien : nous avons unicité à isomorphisme près du produit tensoriel d'espaces vectoriels. Mais nous n'avons pas encore de certitudes à propos de l'existence d'un couple \( (T,h)\) vérifiant les propriétés demandées pour être un produit tensoriel.

Nous allons maintenant construire un produit tensoriel.

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Le produit tensoriel}
%---------------------------------------------------------------------------------------------------------------------------

C'est le moment pour vous de relire la définition \ref{DEFooCPNIooNxsYMY} d'espace vectoriel librement engendré, et surtout le lemme \ref{LEMooLOPAooUNQVku} qui en donne une base.

\begin{definition}[\cite{ooWHNKooYVCiYc}]       \label{DEFooKTVDooSPzAhH}
	Soient deux espaces vectoriels \( V\) et \( W\) sur le corps commutatif\footnote{À part mention du contraire, tous les corps du Frido sont commutatifs.} \( \eK\). Dans \( F_{\eK}(V\times W)\) nous considérons les sous-espaces suivants:
	\begin{subequations}
		\begin{align}
			A_1 & =\{ \delta_{(v_1,w)}+\delta_{(v_2,w)}-\delta_{(v_1+v_2,w)}\tq v_1,v_2\in V,w\in W  \}                             \\
			A_2 & =\{ \delta_{(v,w_1)}+\delta_{(v,w_2)}-\delta_{(v,w_1+w_2)}\tq v\in V,w_1,w_2\in W  \} \label{SUBEQooSHBJooJLPVbK} \\
			A_3 & =\{ \lambda\delta_{v,w}-\delta_{(\lambda v, w)}\tq v\in V,w\in W,\lambda\in \eK \}                                \\
			A_4 & =\{ \lambda\delta_{v,w}-\delta_{(v,\lambda w)}\tq v\in V,w\in W,\lambda\in \eK \}.
		\end{align}
	\end{subequations}
	Nous considérons alors \( N=\Span(A_1,A_2,A_3,A_4)\) et le quotient
	\begin{equation}
		V\otimes_{\eK}W=F_{\eK}(V\times W)/N.
	\end{equation}
	Ce dernier espace vectoriel est le \defe{produit tensoriel}{produit tensoriel} de \( V\) par \( W\).
\end{definition}

\begin{remark}      \label{REMooSLEGooWEiutz}
	Quelque remarques.
	\begin{enumerate}
		\item
		      Les éléments de \( V\otimes W\) ne s'écrivent pas tous sous la forme \( v\otimes w\). Certains ont vraiment besoin d'être écrits avec des sommes. En cela, la situation de \( V\otimes W\) est réellement différente de celle de \( V\times W\). Dans ce dernier, tous les éléments sont des couples.
		\item
		      La classe de l'élément \( \delta_{(v,w)}\in F(V\times W)\) sera d'habitude noté \( v\otimes w\).
		\item
		      Pour insister sur la notion de classe, nous allons aussi noter \( [x]\) la classe de \( x\in F(V\times W)\).
		\item       \label{ITEMooPVWHooMkgQoT}
		      L'arithmétique dans \( V\otimes W\) est relativement simple. En ajoutant et soustrayant le même élément de \( A_3\) nous avons par exemple
		      \begin{equation}
			      (\lambda v)\otimes w=(\lambda v)\otimes w+\lambda (v\otimes w)-(\lambda v)\otimes w.
		      \end{equation}
		      Nous obtenons de cette façon
		      \begin{equation}
			      \lambda(v\otimes w)=(\lambda v)\otimes w=v\otimes (\lambda w),
		      \end{equation}
		      que nous noterons \( \lambda v\otimes w\) sans plus de précision.
	\end{enumerate}
\end{remark}

\begin{proposition}[\cite{ooWHNKooYVCiYc}]     \label{PROPooIWZDooRRZNCf}
	L'espace vectoriel \( V\times W\) muni de
	\begin{equation}
		\begin{aligned}
			h\colon V\oplus W & \to V\otimes W     \\
			(v,w)             & \mapsto v\otimes w
		\end{aligned}
	\end{equation}
	est un produit tensoriel entre \( V\) et \( W\).
\end{proposition}

\begin{proof}
	Nous devons prouver les conditions de la définition \ref{DEFooXKKQooAvWRNp}.

	\begin{subproof}
		\spitem[\( h\) est bilinéaire]

		Ce sont des calculs tels que faits dans la remarque \ref{REMooSLEGooWEiutz}\ref{ITEMooPVWHooMkgQoT} qui font le travail.

		\spitem[\(h \) est surjective]

		Un élément de \( V\otimes W\) est la classe d'un élément de \( F(V\times W)\), c'est-à-dire de la forme
		\begin{equation}
			\big[ \sum_{i\alpha}\delta_{(v_i,w_{\alpha})} \big]=\sum_{i\alpha}v_i\otimes w_{\alpha}.
		\end{equation}
		Cet élément est dans l'image de \( h\) comme le montre le calcul suivant\footnote{Faites bien la distinction entre \( \delta_{v,w}\), \( (v,w)\) et \( v\otimes w\). Sachez dans quel ensemble se trouvent chacun de ces trois objets.} :
		\begin{equation}
			h\big( \sum_{i\alpha}(v_i,w_{\alpha}) \big)=\sum_{i\alpha}h(v_i,w_{\alpha})=\sum_{i\alpha}v_i\otimes w_{\alpha}.
		\end{equation}

		\spitem[Propriété universelle]

		Soient un espace vectoriel \( U\) et une application linéaire \( f\colon V\oplus W\to U \). Nous devons trouver une application linéaire \( g\colon V\otimes W\to U\) telle que \( f=g\circ h\). Pour cela nous commençons par considérer l'application
		\begin{equation}
			\begin{aligned}
				g\colon F(V\times W) & \to U          \\
				\delta_{(v,w)}       & \mapsto f(v,w)
			\end{aligned}
		\end{equation}
		définie sur tout \( F(V\times W)\) par linéarité sans encombres parce que les \( \delta_{v,w}\) forment une base par le lemme \ref{LEMooLOPAooUNQVku}.

		Nous démontrons que \( g(N)=0\) pour avoir le droit de passer \( g\) aux classes et le considérer comme application partant de \( V\otimes W\) au lieu de \( F(V\times W)\). Prenons par exemple
		\begin{subequations}
			\begin{align}
				g\big( \delta_{(v_1,w)}+\delta_{(v_2,w)}-\delta_{(v_1+v_2,w)} \big) & =g( \delta_{(v_1,w)} )+g(\delta_{(v_2,w)})-g(\delta_{v_1+v_2,w}) \\
				                                                                    & =f(v_1,w)+f(v_2,w)-f(v_1+v_2,w)                                  \\
				                                                                    & =0
			\end{align}
		\end{subequations}
		par la bilinéarité de \( f\). Cela montre que \( g(A_1)=0\). Nous montrons de même que \( g(A_2)=g(A_3)=g(A_4)=0\), et enfin toujours par linéarité que \( g(N)=0\). Pour rappel, les éléments de \( N\) sont les combinaisons linéaires finies d'éléments de \( A_1\), \( A_2\), \( A_3\) et \( A_4\).

		Par passage aux classes, nous avons une application (que nous notons également \( g\))
		\begin{equation}
			g\colon F(V\times W)/N\to U
		\end{equation}
		vérifiant \( g(v\otimes w)=f(v,w)\). Mais comme \( h(v,w)=v\otimes w\), nous avons \( g\circ h\colon V\oplus W\to U\) vérifiant \( g\circ h=f\).
	\end{subproof}
	L'espace vectoriel \( V\otimes W\) est donc un produit tensoriel.
\end{proof}

\begin{normaltext}
	Vu que \( V\otimes W\) est un produit tensoriel de \( V\) et \( W\), et vu qu'il y a unicité par la proposition \ref{PROPooROPHooQXqNzZ}, nous avons bien le droit de dire que \( V\otimes W\) est \emph{le} produit tensoriel. Cela justifie le titre.
\end{normaltext}

\begin{normaltext}
	Les prochains lemmes et propositions vont nous dire que l'application
	\begin{equation}
		\begin{aligned}
			\varphi\colon V^*\otimes W & \to \aL(V,W)                            \\
			\alpha\otimes w            & \mapsto \big( v\mapsto \alpha(v)w \big)
		\end{aligned}
	\end{equation}
	est un isomorphisme d'espaces vectoriels lorsque \( V\) est de dimension finie. Vu que nous aimons les énoncés très explicites, ça va être découpé en plusieurs morceaux, l'énoncé va devenir un peu long; mais c'est pour la bonne cause.
\end{normaltext}

\begin{lemma}       \label{LEMooOJEBooQruWEp}
	Soient deux espaces vectoriels \( V\) et \( W\) dont \( W\) est de dimension finie. Alors l'application définie par
	\begin{equation}
		\begin{aligned}
			\varphi\colon F(V^*\times W) & \to \aL(V,W)                            \\
			\delta_{(\alpha,w)}          & \mapsto \big( v\mapsto \alpha(v)w \big)
		\end{aligned}
	\end{equation}
	sur la base «canonique» de \( F(V^*\times W)\) passe aux classes.
\end{lemma}

\begin{proof}
	Avec les notations de la définition \ref{DEFooKTVDooSPzAhH} nous devons prouver que \( \varphi(N)=0\). Nous montrons que \( \varphi(A_4)=0\), et nous vous laissons faire les autres. Pour \( \lambda\in \eK\), \( \alpha\in V^*\) et \( w\in W\) en utilisant la linéarité de \( \varphi\) nous avons :
	\begin{subequations}
		\begin{align}
			\varphi\big( \lambda\delta_{(\alpha,w)}-\delta_{(\alpha,\lambda w)} \big)v & =\lambda\varphi(\delta_{(\alpha,w)})(v)-\varphi(\delta_{(\alpha,\lambda w)})(v) \\
			                                                                           & =\lambda\alpha(v)w-\alpha(v)(\lambda w)                                         \\
			                                                                           & =0
		\end{align}
	\end{subequations}
	parce que \( \alpha(v)(\lambda w)=\lambda \alpha(v)w\) du fait que \( \eK\) est commutatif. La commutativité de \( \eK\) est ce qui permet de permuter le produit \( \lambda \alpha(v)\).

	Nous laissons à la lectrice le soin de prouver que \( \varphi(A_1)=\varphi(A_2)=\varphi(A_3)=0\).
\end{proof}

\begin{lemma}       \label{LEMooUQZHooWjIGsy}
	Si \( W\) est de dimension finie, alors \( \aL(V,W)\) muni de
	\begin{equation}
		\begin{aligned}
			h\colon V^*\oplus W & \to \aL(V,W)                            \\
			(\alpha,w)          & \mapsto \big( v\mapsto \alpha(v)w \big)
		\end{aligned}
	\end{equation}
	est un produit tensoriel\footnote{Définition \ref{DEFooXKKQooAvWRNp}.} de \( V^*\) par \( W\).
\end{lemma}

\begin{proof}
	Nous devons prouver que
	\begin{itemize}
		\item \( h\) est bilinéaire,
		\item \( h\) est surjective
		\item pour tout espace vectoriel \( U\), et pour toute application bilinéaire \( f\colon V^*\oplus W\to U\), il existe une application linéaire \( g\colon \aL(V,W)\to U\) tel que \( f=g\circ h\).
	\end{itemize}

	\begin{subproof}
		\spitem[Bilinéaire]
		Le fait que \( h\) soit bilinéaire est une simple vérification.
		\spitem[Surjective]
		L'espace \( W\) étant de dimension finie, nous pouvons en considérer une base \( \{ z_i \}_{i\in I}\). Soit \( \alpha\in \aL(V,W)\). Si \( v\in V\), l'élément \( \alpha(v)\) peut être décomposé dans la base \( \{ z_i \}\), ce qui définit des applications linéaires \( \alpha_i\colon V\to \eK\) par
		\begin{equation}
			\alpha(v)=\sum_{i\in I}\alpha_i(v)z_i.
		\end{equation}
		Notons que \( \alpha_i\in V^*\). En comparant avec la définition de \( h\), nous voyons que
		\begin{equation}
			\alpha(v)=\sum_i h(\alpha_i,z_i)(v),
		\end{equation}
		c'est-à-dire \( \alpha=\sum_ih(\alpha_i,w_i)=h\big( \sum_i(\alpha_i,z_i) \big)\). Nous avons donc bien \( \alpha\in h(V^*\oplus W)\).
		\spitem[Propriété universelle]

		Soient un espace vectoriel \( U\) et une application bilinéaire \( f\colon V^*\oplus W\to U\). Pour \( \alpha\in\aL(V,W)\) nous définissons \( g(\alpha)\) comme suit. D'abord nous écrivons \( \alpha\) sous la forme
		\begin{equation}
			\alpha(v)=\sum_i\alpha_i(v)z_i,
		\end{equation}
		et nous posons
		\begin{equation}
			g(\alpha)=\sum_if(\alpha_i,z_i).
		\end{equation}
		Avec cette définition, en posant \( w=\sum_iw_iz_i\), nous avons
		\begin{subequations}
			\begin{align}
				(g\circ h)(\alpha,w) & =g\big( v\mapsto \alpha(v)w \big)            \\
				                     & =g\big( v\mapsto \sum_i\alpha(v)w_iz_i \big) \\
				                     & =\sum_if(w_i\alpha,z_i)                      \\
				                     & =\sum_if(\alpha,w_iz_i)                      \\
				                     & =f(\alpha,\sum_iw_iz_i)                      \\
				                     & =f(\alpha,w).
			\end{align}
		\end{subequations}
		Cela prouve que \( g\circ h=f\).
	\end{subproof}
\end{proof}

\begin{proposition}[\cite{ooNHIGooYlXxMf}]      \label{PROPooKJTCooVTXWAQ}
	Soient deux espaces vectoriels \( V\) et \( W\) dont \( V\) est de dimension finie. Alors l'application
	\begin{equation}
		\begin{aligned}
			\varphi\colon V^*\otimes W & \to \aL(V,W)                            \\
			\alpha\otimes w            & \mapsto \big( v\mapsto \alpha(v)w \big)
		\end{aligned}
	\end{equation}
	est bien définie\footnote{Au sens où il existe une fonction \( \varphi\) définie sur tout \( V^*\otimes W\) qui se réduit à cela pour les éléments de la forme \( \alpha\otimes w\).} et est un isomorphisme d'espaces vectoriels.
\end{proposition}

\begin{proof}
	Le lemme \ref{LEMooUQZHooWjIGsy} donne une structure de produit tensoriel de \( V^*\) par \( W\) sur \( \aL(V,W)\). Rappelons les structures :
	\begin{equation}
		\begin{aligned}
			h\colon V^*\oplus W & \to V^*\otimes W        \\
			(\alpha,w)          & \mapsto \alpha\otimes w
		\end{aligned}
	\end{equation}
	et
	\begin{equation}
		\begin{aligned}
			h'\colon V^*\oplus W & \to \aL(V,W)                             \\
			(\alpha,w)           & \mapsto \big[ v\mapsto \alpha(v)w \big].
		\end{aligned}
	\end{equation}

	La proposition \ref{PROPooROPHooQXqNzZ} a déjà fait tout le boulot. La seule chose à faire est de vérifier qu'il existe une application \( \varphi\colon V^*\otimes W\to \aL(V,W)\) vérifiant simultanément les deux conditions suivantes :
	\begin{enumerate}
		\item       \label{ITEMooVNNSooNIXRoG}
		      \( \varphi(\alpha\otimes w)=\big[ v\mapsto \alpha(v)w \big]\)
		\item
		      \( h'=\varphi\circ h\).
	\end{enumerate}
	La seconde condition assure que \( \varphi\) sera un isomorphisme d'espaces vectoriels.

	L'existence de \( \varphi\) vérifiant la condition \ref{ITEMooVNNSooNIXRoG} est un effet du lemme \ref{LEMooOJEBooQruWEp} qui donne une fonction sur \( F(V^*\times W)\) dont le \( \varphi\) qui nous concerne est un quotient. Il reste à voir que cette application vérifie \( h'=\varphi\circ h\).

	En nous rappelant que \( \alpha\otimes w=[\delta_{(\alpha,w)}]\) et en écrivant \( \varphi\) à la fois l'application et son passage au quotient,
	\begin{equation}
		(\varphi\circ h)(\alpha,w)=\varphi(\alpha\otimes w)=\varphi\big( [\delta_{(\alpha,w)}] \big)=\varphi(\delta_{(\alpha,w)}).
	\end{equation}
	En appliquant à \( v\in V\) nous avons:
	\begin{equation}
		(\varphi\circ h)(\alpha,w)v=\varphi(\delta_{(\alpha,w)})v=\alpha(v)w=h'(\alpha,w)v.
	\end{equation}
	Et voilà. Nous avons \( \varphi\circ h=h'\).
\end{proof}

Une conséquence de la proposition \ref{PROPooKJTCooVTXWAQ} est que
\begin{equation}
	\dim(V\otimes W)=\dim(V)\dim(W)
\end{equation}
via le lemme \ref{LEMooJXFIooKDzRWR}\ref{ITEMooPMLWooNbTyJI}.

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Bases}
%---------------------------------------------------------------------------------------------------------------------------

\begin{lemma}[\cite{MonCerveau}]        \label{LEMooXFIMooDkTSrq}
	Si \( \tau\colon V_1\to V_2\) est un isomorphisme d'espaces vectoriels, alors il existe un isomorphisme d'espaces vectoriels \( \varphi\colon V_1\otimes W\to V_2\otimes W\) tel que \( \varphi(v\otimes w)=\tau(v)\otimes w \)\footnote{La proposition \ref{PROPooTHDPooWgjUwk} dira que cette condition fixe complètement \( \varphi\), mais c'est une autre histoire qui vous sera contée une autre fois.}.
\end{lemma}

\begin{proof}
	L'application
	\begin{equation}
		\begin{aligned}
			\varphi_0\colon F(V_1\times W) & \to F(V_2\times W)                     \\
			\delta_{(v,w)}                 & \mapsto \delta_{\big( \tau(v),w \big)}
		\end{aligned}
	\end{equation}
	est un isomorphisme.

	Cette application passe aux classes, mais pas au sens où \( x\in [y]\) impliquerait \( \varphi_0(x)=\varphi_0(y)\); au sens où si \( x\in [y]\), alors \( \varphi_0(x)\in[\varphi_0(y)]\). Par exemple
	\begin{equation}
		\varphi_0\big( \lambda\delta_{(v,w)}-\delta_{(v,\lambda w)} \big)=\lambda\delta_{\big( \tau(v),w \big)}-\delta_{\big( \tau(v),\lambda w \big)}\in [0].
	\end{equation}
	Nous vous laissons le soin de vérifier les égalités correspondantes pour les autres parties de \( N\).

	Le passage au classes de \( \varphi_0\) signifie que l'on considère l'application
	\begin{equation}
		\begin{aligned}
			\varphi\colon V_1\otimes W & \to V_2\otimes W       \\
			[x]                        & \mapsto [\varphi_0(x)]
		\end{aligned}
	\end{equation}
	où vous aurez noté que la prise de classe à gauche n'est pas la même que celle à droite.

	Il faut prouver que ce \( \varphi\) est un isomorphisme. En ce qui concerne la linéarité,
	\begin{subequations}
		\begin{align}
			\varphi\big( [x]+[y] \big) & =\varphi\big( [x+y] \big)      \\
			                           & =[\varphi_0(x+y)]              \\
			                           & =[\varphi_0(x)+\varphi_0(y)]   \\
			                           & =[\varphi_0(x)]+[\varphi_0(y)] \\
			                           & =\varphi([x])+\varphi([y]).
		\end{align}
	\end{subequations}
	Je vous laisse le reste de la linéarité. Et en ce qui concerne le fait que ce soit une bijection, allez-y.
\end{proof}

\begin{proposition}[\cite{ooNHIGooYlXxMf}]      \label{PROPooTHDPooWgjUwk}
	Soient des espaces vectoriels de dimension finie \( V\) et \( W\). Soient une base \( \{e_i\}\) de \( V\) et une base \( \{f_{\alpha}\}\) de \( W\).

	Alors :
	\begin{enumerate}
		\item       \label{ITEMooQCILooUncdGl}
		      La partie \( \{e_i\otimes f_{\alpha}\}\) est une base de \( V\otimes W\).
		\item
		      Au niveau des dimensions, \( \dim(V\otimes W)=\dim(V)\dim(W)\).
	\end{enumerate}
\end{proposition}

\begin{proof}
	Vu que \( V\) est de dimension finie, nous avons un isomorphisme d'espaces vectoriels \( V^*=V\), et même un isomorphisme d'espaces vectoriels
	\begin{equation}
		\begin{aligned}
			\tau\colon V & \to (V^*)^* \\
			\tau(v)\mu   & =\mu(v).
		\end{aligned}
	\end{equation}
	Recopions l'isomorphisme de la proposition \ref{PROPooKJTCooVTXWAQ} en utilisant \( V^*\) au lieu de \( V\) :
	\begin{equation}
		\begin{aligned}
			\psi_0\colon (V^*)^*\otimes W & \to \aL(V^*,W)                                         \\
			\tau(v)\otimes w              & \mapsto \big( \mu\mapsto \tau(v)(\mu)w =\mu(v)w \big).
		\end{aligned}
	\end{equation}
	En écrivant cela, nous avons tenu compte du fait que tout élément de \( (V^*)^*\) peut être écrit de façon univoque sous la forme \( \tau(v)\) pour un certain \( v\in V\).

	Vu que \( \tau\) est un isomorphisme, l'application suivante est encore un isomorphisme\footnote{Lemme \ref{LEMooXFIMooDkTSrq}.} :
	\begin{equation}        \label{EQooAEFRooPfmAnj}
		\begin{aligned}
			\psi\colon V\otimes W & \to \aL(V^*,W)                          \\
			v\otimes w            & \mapsto \big( \mu\mapsto \mu(v)w \big).
		\end{aligned}
	\end{equation}
	Nous avançons. Vu que nous avons un isomorphisme, nous pouvons faire passer des bases. Le lemme \ref{LEMooJXFIooKDzRWR} nous donne une base de \( \aL(V^*,W)\) en les éléments \( \beta_{i\alpha}\colon V^*\to W\) définies par
	\begin{equation}
		\beta_{ij}(\mu)=\mu(e_i)f_{\alpha}.
	\end{equation}
	Donc \( \{ \psi^{-1}(\beta_{i\alpha}) \}\) est une base de \( V\otimes W\).

	Pour \( a=\sum_ia_ie_i^*\) (base duale, définition \ref{DEFooTMSEooZFtsqa}) nous avons :
	\begin{equation}
		\psi(e_i\otimes f_{\alpha})a=a(e_i)f_{\alpha}=\beta_{i\alpha}(a).
	\end{equation}
	Cela prouve que \( \psi^{-1}(\beta_{i\alpha})=e_i\otimes f_{\alpha}\), et donc que ces \( e_i\otimes f_{\alpha}\) est une base de \( V\otimes W\).

	La formule concernant les dimensions est simplement la définition \ref{DEFooWRLKooArTpgh} de la dimension : le nombre d'éléments dans une base.
\end{proof}

\begin{lemma}       \label{LEMooYJIQooRCkHMq}
	Dans le produit tensoriel \( \eR\otimes \eR\), nous avons
	\begin{enumerate}
		\item
		      \( x\otimes 1=1\otimes x=x(1\otimes 1)\) pour tout \( x\in \eR\).
		\item
		      Si \( x\geq 0\) nous avons aussi \( x\otimes 1=\sqrt{ x }\otimes \sqrt{ x }\).
	\end{enumerate}
\end{lemma}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Norme}
%---------------------------------------------------------------------------------------------------------------------------

Nous considérons des espaces vectoriels \( V\) et \( W\) de dimension finie. L'application \eqref{EQooAEFRooPfmAnj} donne un isomorphisme d'espaces vectoriels
\begin{equation}
	\begin{aligned}
		\psi\colon V\otimes W & \to \aL(V^*,W)                                \\
		v\otimes w            & \mapsto \big( \alpha\mapsto \alpha(v)w \big).
	\end{aligned}
\end{equation}
Et ça, c'est très bien, parce que nous connaissons une norme sur \( \aL(V^*,W)\) :  la norme opérateur \ref{DefNFYUooBZCPTr}.

\begin{definition}[\cite{MonCerveau}]      \label{DEFooEXXNooMgIpSV}
	Soient deux espaces vectoriels normés de dimension finie \( V\) et \( W\). Sur \( V\otimes W\) nous définissons, pour \( t\in V\otimes W\)
	\begin{equation}
		\| t \|=\| \psi(t) \|_{\aL(V^*,W)}.
	\end{equation}
\end{definition}

\begin{lemma}[\cite{MonCerveau}]        \label{LEMooQPXHooJWfpmk}
	La norme sur \( V\otimes W\) vérifie
	\begin{equation}
		\| v\otimes w \|=\| v \|\| w \|
	\end{equation}
	pour tout \( v\in V\) et \( w\in W\).
\end{lemma}

\begin{proof}
	C'est un simple(?) calcul :
	\begin{equation}
		\| v\otimes w \|=\| \psi(v\otimes w) \|=\| \alpha\mapsto \alpha(v)w \|=\sup_{\| \alpha \|=1}\| \alpha(v)w \|=\sup_{\| \alpha \|=1}| \alpha(v) |\| w \|.
	\end{equation}
	Étant donné que \( V\) est de dimension finie, \( \sup_{\| \alpha \|=1}| \alpha(v) |=\| v \|\)\quext{Cela est une des raisons pour lesquelles nous sommes en dimension finie : je ne sais pas si cette égalité est vraie en dimension inifinie.}. Nous avons donc
	\begin{equation}
		\| v\otimes w \|=\| v \|\| w \|.
	\end{equation}
\end{proof}

Le lemme suivant montre que \( \eR\otimes \eR\) n'est pas du tout \( \eR\times \eR=\eR^2\). Au contraire, \( \eR\otimes \eR\) est isomorphe à \( \eR\).
\begin{lemma}[\cite{MonCerveau}]        \label{LEMooVONEooQpPgcn}
	L'application
	\begin{equation}
		\begin{aligned}
			\varphi\colon \eR\otimes \eR & \to \eR   \\
			1\otimes 1                   & \mapsto 1
		\end{aligned}
	\end{equation}
	prolongée par linéarité est un isomorphisme isométrique.
\end{lemma}

\begin{proof}
	D'abord une base de \( \eR\) est \( \{ 1 \}\); donc une base de \( \eR\otimes \eR\) est \( \{ 1\otimes 1 \}\) par la proposition \ref{PROPooTHDPooWgjUwk}. Donc l'application proposée se prolonge par linéarité à tout \( \eR\otimes \eR\).

	Le fait que \( \varphi\) soit une bijection provient du fait que \( \varphi\) transforme une base en une base; si vous n'y croyez pas, la vérification de l'injectivité et de la surjectivité est facile.

	Pour que \( \varphi\) soit isométrique, nous faisons le calcul
	\begin{equation}
		\| \varphi(x\otimes y) \|=\| xy(1\otimes 1) \|=| xy |\| 1\otimes 1 \|=| xy |=\| x\otimes y \|.
	\end{equation}
	Nous avons utilisé la propriété \ref{DefNorme}\ref{ItemDefNormeii} d'une norme ainsi que le lemme \ref{LEMooQPXHooJWfpmk} pour la norme sur \( \eR\otimes \eR\).
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Applications bilinéaires, matrices et produit tensoriel}
%---------------------------------------------------------------------------------------------------------------------------
\label{SECooUKRYooZjagcX}

Soit \( E\), un espace vectoriel de dimension finie. Si \( \alpha\) et \( \beta\) sont deux formes linéaires sur un espace vectoriel \( E\), nous définissons \( \alpha\otimes \beta\) comme étant la \( 2\)-forme donnée par
\begin{equation}        \label{EQooUNRYooKBrXyK}
	(\alpha\otimes \beta)(u,v)=\alpha(u)\beta(v).
\end{equation}
Si \( a\) et \( b\) sont des vecteurs de \( E\), ils sont vus comme des formes sur \( E\) via le produit scalaire et nous avons
\begin{equation}
	(a\otimes b)(u,v)=(a\cdot u)(b\cdot v).
\end{equation}
Cette dernière équation nous incite à pousser un peu plus loin la définition de \( a\otimes b\) et de simplement voir cela comme la matrice de composantes
\begin{equation}
	(a\otimes b)_{ij}=a_ib_j.
\end{equation}
Cette façon d'écrire a l'avantage de ne pas demander de se souvenir qui est une vecteur ligne, qui est un vecteur colonne et où il faut mettre la transposée. Évidemment \( (a\otimes b)\) est soit \( ab^t\) soit \( a^tb\) suivant que \( a\) et \( b\) soient ligne ou colonne.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Application d'opérateurs}
%---------------------------------------------------------------------------------------------------------------------------

\begin{lemma}   \label{LemMyKPzY}
	Soient \( x,y\in E\) et \( A,B\) deux opérateurs linéaires sur \( E\) vus comme matrices. Alors
	\begin{equation}        \label{EqXdxvSu}
		(Ax\otimes By)=A(x\otimes y)B^t.
	\end{equation}
\end{lemma}

\begin{proof}
	Calculons la composante \( ij\) de la matrice \( (Ax\otimes By)\). Nous avons
	\begin{subequations}
		\begin{align}
			(Ax\otimes By)_{ij} & =(Ax)_i(By)_j                       \\
			                    & =\sum_{kl}A_{ik}x_kB_{jl}y_l        \\
			                    & =A_{ik}(x\otimes y)_{kl}B_{jl}      \\
			                    & =\big( A(x\otimes y)B^t \big)_{ij}.
		\end{align}
	\end{subequations}
\end{proof}


Le fait que les applications linéaires soient continues\footnote{Proposition \ref{PROPooQZYVooYJVlBd}.} est valable dans une assez large gamme d'espaces vectoriels\cite{BIBooUWMLooWEPxcC}. Nous voyons ici dans le cas des espaces vectoriels normés de dimension finies.
\begin{proposition}     \label{PROPooADPDooOtukQP}
	Soient des espaces vectoriels normés \( E\) et \( F\). Si \( f\colon E\to F\) est une application linéaire et si \( E\) est de dimension finie, alors \( f\) est continue.
\end{proposition}

\begin{proof}
	La proposition \ref{DefNFYUooBZCPTr}\ref{ITEMooGIPIooUvVBIv} nous dit que \( \| f \|<\infty\), c'est-à-dire que \( f\) est borné. Donc la proposition \ref{PROPooQZYVooYJVlBd} conclut.
\end{proof}


\begin{lemma}   \label{LemWWXVSae}
	Soit \( F\) un espace de Banach et deux suites \( A_k\to A\) et \( B_k\to B\) dans \( \aL(F,F)\). Alors \( A_k\circ B_k\to A\circ B\) dans \( \aL(F,F)\), c'est-à-dire
	\begin{equation}
		\lim_{k\to \infty} (A_kB_k)=\left( \lim_{k\to \infty} A_k \right)\left( \lim_{k\to \infty} B_k \right).
	\end{equation}
\end{lemma}

\begin{proof}
	Il suffit d'écrire
	\begin{equation}
		\| A_kB_k-AB \|\leq \| A_kB_k-A_kB \|+\| A_kB-AB \|.
	\end{equation}
	Le premier terme tend vers zéro pour \( k\to\infty\) parce que
	\begin{subequations}
		\begin{align}
			\| A_kB_k-A_kB \| & =\| A_k(B_k-B) \|                           \\
			                  & \leq \| A_k \|\| B_k-B \|\to \| A \|\cdot 0 \\
			                  & =0
		\end{align}
	\end{subequations}
	où nous avons utilisé la propriété fondamentale de la norme opérateur : la proposition~\ref{PROPooQZYVooYJVlBd}. Le second terme tend également vers zéro pour la même raison.
\end{proof}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Convergence en norme et par composante}
%---------------------------------------------------------------------------------------------------------------------------

En dimension infinie, la convergence en norme et la convergence composante par composante ne s'impliquent ni dans un sens ni dans l'autre.

L'exemple suivant devrait être formalisé dans l'espace \( \ell^2\) des suites de carré sommable, mais vous voyez l'idée.
\begin{example}
	Nous considérons l'ensemble des suites réelle munie de la norme \( \| x \|=\sqrt{ \sum_{k=0}^{\infty}| x_k |^2 } \). Dedans nous considérons les vecteurs de base \( e_i\) donnés par
	\begin{equation}
		(e_i)_n=\delta_{in}.
	\end{equation}
	Ensuite nous considérons la base
	\begin{equation}
		f_i=e_1+\frac{1}{ 2^i }e_i.
	\end{equation}
	La suite \( x_n=f_n-f_1\), dans cette base a toujours \( -1\) comme première composante\footnote{N'essayez pas de faire un dessin : ça ne fonctionne qu'en dimension infinie.}. Et pourtant elle converge en norme vers \( 0\).
\end{example}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Calcul différentiel dans un espace vectoriel normé}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\label{SecLStKEmc}

Quelques motivations pour la notion de différentielle sont données dans \ref{SEBSECooLPRQooJRQCFL}.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Définition de la différentielle}
%---------------------------------------------------------------------------------------------------------------------------

\begin{propositionDef}[\cite{MonCerveau}]      \label{DefDifferentiellePta}
	Soient deux espaces vectoriels normés\footnote{Définition \ref{DefNorme}.} \( E\) et \( F\) ainsi qu'une fonction \( f\colon \mU\to F\) où \( \mU\) est un ouvert de \( E\). Si il existe une une application linéaire \( T\in\aL(E,F)\) satisfaisant
	\begin{equation}	\label{EqCritereDefDiff}
		\lim_{\substack{h\to 0\\h\in E}}\frac{f(a+h)-f(a)-T(h)}{\|h\|_E}=0,
	\end{equation}
	alors il en existe une seule.

	Dans ce cas nous disons que \( f\) est \defe{différentiable au point \( a\)}{application!différentiable} et l'application \( T\) ainsi définie est appelée \defe{différentielle}{différentielle} de \( f\) au point \( a\), et nous la notons \( df_a\).
\end{propositionDef}

\begin{proof}
	Soient deux applications linéaires \( T_1\), \( T_2\) satisfaisant la condition \eqref{EqCritereDefDiff}. Nous avons
	\begin{equation}
		\frac{ \| T_1(h)-T_2(h) \|_F }{ \| h \|_E }\leq \frac{ \| T_1(h)-f(a+h)+f(a) \| }{ \| h \| }+\frac{ \| f(a+h)-f(a)-T_2(h) \| }{ \| h \| }\to 0.
	\end{equation}
	Nous avons donc
	\begin{equation}
		\lim_{h\to 0} \frac{ \| (T_1-T_2)(h) \|_F }{ \| h \|_E }=0.
	\end{equation}
	Soit \( \epsilon>0\). Ce que signifie la limite est qu'il existe un \( r>0\) tel que pour tout \( u\in B_E(0,r)\), nous ayons
	\begin{equation}
		\frac{ \| (T_1-T_2)(u) \|_F }{ \| u \|_E }<\epsilon.
	\end{equation}
	Soit \( v\in E\). Nous considérons \( \lambda\in\eR\) tel que \( \lambda v\in B(0,r)\), par exemple \( \lambda<r/\| v \|\). Nous avons
	\begin{equation}
		\epsilon>\frac{ \| (T_1-T_2)(\lambda v) \|_F }{ \| \lambda v \|_E }=\frac{ \| (T_1-T_2)(v) \| }{ \| v \| }.
	\end{equation}
	Cela donne
	\begin{equation}
		\| (T_1-T_2)(v) \|<\| v \|\epsilon.
	\end{equation}
	Nous avons donc \( \| (T_1-T_2)(v) \|=0\), soit \( T_1(v)=T_2(v)\).
\end{proof}

L'application différentielle
\begin{equation}
	\begin{aligned}
		df\colon E & \to \aL(E,F) \\
		a          & \mapsto df_a
	\end{aligned}
\end{equation}
est également très importante.


%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Quelque mots à propos des différentielles d'ordre supérieures}
%---------------------------------------------------------------------------------------------------------------------------

Soient deux espaces vectoriels normés \( V\) et \( W\) ainsi qu'une application \( f\colon V\to W\). La différentielle est une application \( df\colon V\to \aL(V,W)\). Pour être clair, la différentielle seconde consiste à différentier \( df_x\) par rapport à \( x\). C'est-à-dire que la différentielle seconde est une application \( d(df)\colon V\to \aL\big( V,\aL(V,W) \big)\).

Et c'est là que commencent les problèmes. Les différentielles successives font intervenir des emboîtements de plus en plus profonds d'espaces comme \( d^3f\colon V\to \aL\Big( V,\aL\big( V,\aL(V,W) \big) \Big)\).

Nous introduisons quelque notations pour traiter ces espaces.

\begin{definition}[\cite{ZCKMFRg, MonCerveau}]  \label{DefPNjMGqy}
	Soient deux espaces vectoriels normés \( V\) et \( W\) ainsi qu'une application \( f\colon V\to W\). Nous disons que \( f\) est
	\begin{itemize}
		\item de classe  \( C^0\) si elle est continue,
		\item de classe \( C^1\) si l'application différentielle \( df\colon V\to \aL(V,W)\) est continue,
		\item de classe \( C^k\) si sa différentielle est de classe \( C^{k-1}\).
		\item de classe \( C^{\infty}\) si elle est de classe \( C^k\) pour tout \( k\).
	\end{itemize}

	Lorsque nous demandons que la différentielle de \( f\) soit continue, nous entendons bien la continuité de \( df\colon V\to \aL(V,W)\), c'est-à-dire la continuité de \( df_x\) par rapport à \( x\). Sur\( \aL(V,E)\), nous considérons la topologie de la norme opérateur \ref{DefNFYUooBZCPTr}.

\end{definition}
\index{application!différentiable}
\index{application!de classe \( C^k\)}
Le lien entre classe \( C^k\) et dérivées partielles d'ordre \( k\) sera le théorème \ref{THOooPZTAooTASBhZ}.

\begin{definition}      \label{DEFooJYOPooBzditG}
	Soient des espaces vectoriels normés \( V\) et \( W\). Nous définissons les espaces emboîtés par récurrence :
	\begin{subequations}
		\begin{numcases}{}
			E_0=E\\
			E_{k+1}=\aL(V,E_k).
		\end{numcases}
	\end{subequations}
\end{definition}

\begin{definition}
	Si \( \{ e_i \}\) est une base d'un espace vectoriel \( V\), nous allons noter
	\begin{equation}
		\begin{aligned}
			\omega_i\colon V & \to \eR      \\
			x                & \mapsto x_i.
		\end{aligned}
	\end{equation}
	Ce \( \omega_i\) est ce qu'on appelle souvent \( e_i^*\). Plus généralement, si \( I\) est le multiindice \( (i_1,\ldots, i_l)\) nous notons \( \omega_I\in \aL^l(V,\eR)\) par
	\begin{equation}
		\begin{aligned}
			\omega_I\colon V^l        & \to \eR                                     \\
			(x^{(1)},\ldots, x^{(l)}) & \mapsto  x^{(1)}_{i_1}\ldots x^{(l)}_{i_l}.
		\end{aligned}
	\end{equation}
	Ce seront nos formes multilinéaires de base.
\end{definition}

Afin de garder des notations très explicites, nous ne pouvons pas écrire des formules comme
\[
	df_a=\sum_i\frac{ \partial f }{ \partial x_i }(a)\omega_i
\]
parce que si \( f\) prend ses valeurs dans \( \aL(V,\eR)\), lorsqu'on écrit \( df_a(v)\), il n'y a aucune raison à priori de vouloir que \( v\) soit pris par \( \omega_i\) au lieu de \( \partial_if(a)\).

Nous introduisons donc un produit fait exprès pour dire que «c'est celui de droite qui prend».
\begin{definition}[\cite{MonCerveau}]       \label{DEFooLULCooYjBEaZ}
	Si \( W\) est un espace vectoriel, nous définissons le produit \( \times_n\) par
	\begin{equation}
		\begin{aligned}
			\times_1\colon W\times \aL(V,\eR) & \to \aL(V,W) \\
			(w\times_1\alpha)(v)              & =\alpha(v)w
		\end{aligned}
	\end{equation}
	et par\footnote{Définition \ref{DEFooJYOPooBzditG} pour les espaces \( E_n\) et \( \eR_n\).}
	\begin{equation}
		\begin{aligned}
			\times_n\colon W\times \eR_n & \to W_n                  \\
			(w\times_n\alpha)(v)         & =w\times_{n-1} \alpha(v)
		\end{aligned}
	\end{equation}
\end{definition}
Cette notation sera utilisée dans la proposition \ref{PROPooUDJLooHwzjQF} pour écrire correctement \( df_a\). Pour l'instant nous n'en avons pas besoin.



\begin{definition}[difféomorphisme]      \label{DefAQIQooYqZdya}
	Soient \( U\) et \( V\), deux ouverts d'un espace vectoriel normé. Une application \( f\) de \( U\) dans \( V\) est un \defe{difféomorphisme}{difféomorphisme} si elle est bijective, différentiable\footnote{Différentiables, définition \ref{DefDifferentiellePta}.} et dont l'inverse \( f^{-1}:V\to U \) est aussi différentiable.

	Un \( C^k\)-difféomorphisme est un difféomorphisme qui est \( C^k\) et dont l'inverse est \( C^k\).
\end{definition}

\begin{normaltext}
	Truc marrant : un \( C^1\)-difféomorphisme n'est pas seulement un difféomorphisme qui est \( C^1\). L'inverse doit également être \( C^1\). Comment nommer un difféomorphisme qui est par ailleurs un application de classe \( C^1\) ? Je ne sais pas.
\end{normaltext}

\begin{remark}  % TOTOooVTLSooSNLVBD justifier ça.
	Il n'existe pas de bijection bicontinues d'un ouvert de \( \eR^m\) vers un ouvert de \( \eR^n\) si \( m\neq n\). Il n'y a donc pas de notion de difféomorphismes entre ouverts de dimensions différentes.
\end{remark}

\begin{remark}      \label{RemATQVooDnZBbs}
	L'application norme étant continue, le critère du théorème~\ref{ThoWeirstrassRn} est en réalité assez général. Par exemple à partir d'une application différentiable\footnote{Définition~\ref{DefDifferentiellePta}.} \( f\colon X\to Y\)  nous pouvons considérer la fonction réelle
	\begin{equation}
		a\mapsto \|  df_a   \|
	\end{equation}
	où la norme est la norme opérateur\footnote{Définition~\ref{DefNFYUooBZCPTr}.}. Si \( f\) est de classe \( C^1\) alors cette application est continue et donc bornée sur un compact \( K\) de \( X\).
\end{remark}


%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Différentielle d'applications linéaires}
%---------------------------------------------------------------------------------------------------------------------------

\begin{lemma}[Différentielle d'une application linéaire]       \label{LEMooZSNMooCfjzOB}
	Soient deux espaces vectoriels normés \( E\) et \( F\). Soit une application linéaire \( f\colon E\to F\).
	\begin{enumerate}
		\item
		      Si \( f\colon E\to F\) est linéaire, alors sa différentielle est
		      \begin{equation}
			      \begin{aligned}
				      df\colon E & \to  \aL(E,F) \\
				      a          & \mapsto f.
			      \end{aligned}
		      \end{equation}
		\item
		      Si \( f\colon E\to F\) est linéaire, toutes les différentielles d'ordre supérieures sont nulles.
		\item
		      Toute application linéaire est de classe \(  C^{\infty}\).
		\item
		      Toute application affine est de classe \(  C^{\infty}\).
	\end{enumerate}
\end{lemma}
%TODOooMGPJooZCgTRv Je crois que seul le premier point est prouvé. En particulier je suis sûr que le dernier n'est pas prouvé.
% La partie sur les applications affines C^oo est utilisée dans LEMooAJDLooIPcmIV.

\begin{proof}
	Pour rappel, toujours bon à avoir en tête : \( df\colon E\to \aL(E,F)\). Soit \( a\in E\); nous avons
	\begin{equation}
		\lim_{h\to 0} \frac{ \| f(a+h)-f(a)- f(h) \|_F }{ \| h \|_E }=0
	\end{equation}
	parce que le numérateur est nul pour tout \( h\). Donc \( h\mapsto f(h)\) est la différentielle de \( f\) au point \( a\) parce que elle vérifie la condition \eqref{DefDifferentiellePta}.

	Nous avons prouvé que la différentielle de \( f\) est l'application constante
	\begin{equation}
		\begin{aligned}
			df\colon E & \to \aL(E,F) \\
			a          & \mapsto f
		\end{aligned}
	\end{equation}

	En ce qui concerne la différentielle seconde, nous prouvons que \( d(df)_a=0\) pour tout \( a\in E\). En effet,
	\begin{equation}
		\lim_{h\to 0} \frac{ \| df_{a+h}-df_a \|_{\aL(E,F)} }{ \| h \|_E }=0
	\end{equation}
	parce que le numérateur vaut \( f-f=0\).

	Maintenant il n'est pas compliqué de faire une récurrence : si \( f\) est de classe \( C^k\) et si \( d^k(f)=0\), alors \( d^k(f)\) est de classe \( C^1\) et \( d^kf=0\).
\end{proof}

\begin{lemma}       \label{LEMooAJDLooIPcmIV}
	Soient \( a<b\) dans \( \eR\). L'application
	\begin{equation}        \label{EQooIINJooAlSqKF}
		\begin{aligned}
			f\colon \mathopen[ a , b \mathclose] & \to \mathopen[ 0 , 1 \mathclose] \\
			x                                    & \mapsto \frac{ x-a }{ b-a }
		\end{aligned}
	\end{equation}
	est un \(  C^{\infty}\)-difféomorphisme\footnote{Définition \ref{DefPNjMGqy}.}.
\end{lemma}

\begin{proof}
	En plusieurs parties.
	\begin{subproof}
		\spitem[Valeurs dans \( \mathopen\lbrack 0 , 1 \mathclose\rbrack\)]     \label{ITEMooLRECooOSEqJL}
		Nous devons prouver que pour tout \( x\in\mathopen[ a , b \mathclose]\), nous avons \( f(x)\in \mathopen[ 0 , 1 \mathclose]\). D'une part si \( x\in\mathopen[ a , b \mathclose]\), alors \( x-a\geq 0\) et donc \( (x-a)/(b-a)\geq 0\).

		Dans l'autre sens, si \( (x-a)/(b-a)>1\), alors \( x-a>b-a\) et donc \( x>b\). Donc \( f(x)>1\) n'arrive jamais pour \( x\in \mathopen[ a , b \mathclose]\).
		\spitem[Injectif]
		% -------------------------------------------------------------------------------------------- 
		Si \( f(x)=f(t)\), alors en simplifiant par \( b-a\neq 0\), nous trouvons \( x-a=t-a\) et donc \( x=t\) (ne citez le lemme \ref{LEMooFQMVooDNaTDT} que si vous êtes capables de le prouver, sinon faites comme si c'était évident et il ne vous arrivera rien).
		\spitem[Surjectif]
		% -------------------------------------------------------------------------------------------- 
		Il est vite vérifié que
		\begin{equation}       \label{EQooPSAWooNEJFih}
			f^{-1}(t)=t(b-a)+a,
		\end{equation}
		et en procédant de même qu'au point \ref{ITEMooLRECooOSEqJL}, nous voyons que pour tout \( t\in \mathopen[ 0 , 1 \mathclose]\), \( f^{-1}(t)\in\mathopen[ a , b \mathclose]\).
		\spitem[De classe \(  C^{\infty}\)]
		% -------------------------------------------------------------------------------------------- 
		C'est le lemme \ref{LEMooZSNMooCfjzOB} qui fait le travail parce que \eqref{EQooIINJooAlSqKF} est affine.
		\spitem[Inverse de classe \(  C^{\infty}\)]
		% -------------------------------------------------------------------------------------------- 
		Encore le lemme \ref{LEMooZSNMooCfjzOB} parce que \eqref{EQooPSAWooNEJFih} est affine.
	\end{subproof}
\end{proof}
