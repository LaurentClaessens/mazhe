% This is part of (everything) I know in mathematics
% Copyright (c) 2011-2019
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.


%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Calcul de limites}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Beaucoup de techniques de calcul de limites fonctionnent bien avec les fonctions trigonométriques, entre autres grâce à l'utilisation des coordonnées polaires de la proposition~\ref{PROPooFLUAooDsyMXO}. De plus, le théorème de la fonction implicite Nous en voyons quelques exemples à présent.

\begin{example}[Limite et prolongement par continuité] \label{ExQWHooGddTLE}
    La fonction
    \begin{equation}
        f(x)=\frac{ \cos(x)-1 }{ x }
    \end{equation}
    n'est pas définie en \( x=0\).

    Nous avons vu dans l'équation \eqref{SUBEQooTTNNooXzApSM} que \( \cos(0)=1\), donc la limite
    \begin{equation}
        \lim_{x\to 0} \frac{ \cos(x)-1 }{ x }
    \end{equation}
    est la limite définissant la dérivée de cosinus en \( 0\) (ici, le \( x\) joue le rôle de \( \epsilon\)). Le lemme~\ref{LEMooBBCAooHLWmno} nous donne la dérivée du cosinus comme étant le sinus. Nous avons donc :
    \begin{equation}
        \lim_{x\to 0} \frac{ \cos(x)-1 }{ x }=\sin(0)=0,
    \end{equation}
    et nous définissons le prolongement par continuité :
    \begin{equation}
        \tilde f(x)=\begin{cases}
            \frac{ \cos(x)-1 }{ x }    &   \text{si } x\neq 0\\
            0    &    \text{sinon}.
        \end{cases}
    \end{equation}

    Encore une fois, le graphe de la fonction \(\tilde f\) ne présente aucune particularité autour de \( x=0\).
    \begin{center}
        \input{auto/pictures_tex/Fig_RPNooQXxpZZ.pstricks}
    \end{center}
\end{example}

\begin{example}[Un calcul heuristique de limite]        \label{EXooINLRooPzRWEA}
    Soit à calculer la limite suivante :
    \begin{equation}
        \lim_{x\to 0} \frac{  e^{-2\cos(x)+2}\sin(x) }{ \sqrt{ e^{2\cos(x)+2}}-1 }.
    \end{equation}
    La stratégie que nous allons suivre pour calculer cette limite est de développer certaines parties de l'expression en série de Taylor, afin de simplifier l'expression. La première chose à faire est de remplacer $ e^{y(x)}$ par $1+y(x)$ lorsque $y(x)\to 0$. La limite devient
    \begin{equation}
        \lim_{x\to 0} \frac{ \big( -2\cos(x)+3 \big)\sin(x) }{ \sqrt{-2\cos(x)+2} }.
    \end{equation}
    Nous allons maintenant remplacer $\cos(x)$ par $1$ au numérateur et par $1-x^2/2$ au dénominateur. Pourquoi ? Parce que le cosinus du dénominateur est dans une racine, donc nous nous attendons à ce que le terme de degré deux du cosinus donne un degré un en dehors de la racine, alors que du degré un est exactement ce que nous avons au numérateur : le développement du sinus commence par $x$.

    Nous calculons donc
    \begin{equation}
        \begin{aligned}[]
            \lim_{x\to 0} \frac{ \sin(x) }{ \sqrt{-2\left( 1-\frac{ x^2 }{ 2 } \right)+2} }=\lim_{x\to 0} \frac{ \sin(x) }{ x }=1.
        \end{aligned}
    \end{equation}
    Tout ceci n'est évidemment pas très rigoureux, mais en principe vous avez tous les éléments en main pour justifier les étapes.
\end{example}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Méthode des coordonnées polaires}
%---------------------------------------------------------------------------------------------------------------------------
\label{SUBSECooWCGMooPrXSpt}

La proposition suivante exprime la définition de la limite en d'autres termes, et va être pratique dans le calcul de certaines limites.
\begin{proposition}		\label{PropMethodePolaire}
	Soit $f\colon D\subset\eR^m\to \eR^n$, $a$ un point d'accumulation de $D$ et $\ell\in \eR^n$. Nous définissons
	\begin{equation}
		E_r=\{ f(x)\tq x\in B(a,r)\cap D \},
	\end{equation}
	et
	\begin{equation}
		s_r=\sup\{ \| v-\ell \|\tq v\in E_r \}.
	\end{equation}
	Alors nous avons $\lim_{x\to a} f(x)=\ell$ si et seulement si $\lim_{r\to 0} s_r=0$.
\end{proposition}

Dans cette proposition, $E_r$ représente l'ensemble des valeurs atteintes par $f$ dans un rayon $r$ autour de $a$. Le nombre $s_r$ sélectionne, parmi toutes ces valeurs, celle qui est la plus éloignée de $\ell$ et donne la distance. En d'autres termes, $s_r$ est la distance maximale entre $f(x)$ et $\ell$ lorsque $x$ est à une distance au maximum $r$ de $a$.

Lorsque nous avons affaire à une fonction $f\colon \eR^2\to \eR$, cette proposition nous permet de calculer facilement les limites en passant aux coordonnées polaires.

\begin{example}		\label{ExempleMethodeTrigigi}
	Reprenons la fonction de l'exemple~\ref{ExFNExempleMethodeTrigigi}:
	\begin{equation}
		f(x,y)=\frac{ xy }{ x^2+y^2 }.
	\end{equation}
	Son domaine est $\eR^2\setminus\{ (0,0) \}$. Nous voulons calculer $\lim_{(x,y)\to(0,0)}f(x,y)$. Écrivons la définition de $E_r$~:
	\begin{equation}
		E_r=\{ f(x,y)\tq (x,y)\in B\big( (0,0),r \big) \}.
	\end{equation}
	Les points de la boule sont, en coordonnées polaires, les points de la forme $(\rho,\theta)$ avec $\rho<r$. La chose intéressante est que $f(\rho,\theta)$ est relativement simple (plus simple que la fonction départ). En effet en remplaçant tous les $x$ par $\rho\cos(\theta)$ et tous les $y$ par $\rho\sin(\theta)$, et en utilisant le fait que $\cos^2(\theta)+\sin^2(\theta)=1$, nous trouvons
	\begin{equation}		\label{Eq2807fpolairerhodeuxcossin}
		f(\rho,\theta)=\frac{ \rho^2\cos(\theta)\sin(\theta) }{ \rho^2 }=\cos(\theta)\sin(\theta).
	\end{equation}
	Cela signifie que
	\begin{equation}
		E_r=\{ \cos(\theta)\sin(\theta)\tq\theta\in\mathopen[ 0 , 2\pi [ \}.
	\end{equation}
	Prenons $\ell$ quelconque. Le nombre $s_r$ est le supremum des
	\begin{equation}
		\| \ell-\cos(\theta)\sin(\theta) \|
	\end{equation}
	lorsque $\theta$ parcours $\mathopen[ 0 , 2\pi \mathclose]$. Nous ne sommes pas obligés calculer la valeur exacte de $s_r$. Ce qui compte ici est que $s_r$ ne vaut certainement pas zéro, et ne dépend pas de $r$. Donc il est impossible d'avoir $\lim_{r\to 0} s_r=0$, et la fonction donnée n'a pas de limite en $(0,0)$.
\end{example}

Nous pouvons retenir cette règle pour calculer les limites lorsque $(x,y)\to(0,0)$ de fonctions $f\colon \eR^2\to \eR$ :
\begin{enumerate}
	\item
		passer en coordonnées polaires, c'est-à-dire remplacer $x$ par $\rho\cos(\theta)$ et $y$ par $\rho\sin(\theta)$;
	\item
		nous obtenons une fonction $g$ de $\rho$ et $\theta$. Si la limite $\lim_{r\to 0} g(r,\theta)$ n'existe pas ou dépend de $\theta$, alors la fonction n'a pas de limite. Si on peut majorer $g$ par une fonction ne dépendant pas de $\theta$, et que cette fonction a une limite lorsque $r\to 0$, alors cette limite est la limite de la fonction.
\end{enumerate}

La vraie difficulté de la technique des coordonnées polaires est de trouver le supremum de $E_r$, ou tout au moins de montrer qu'il est borné par une fonction qui a une limite qui ne dépend pas de $\theta$. Une des situations classiques dans laquelle c'est facile est lorsque la fonction se présente comme une fonction de $r$ multiplié par une fonction de $\theta$.

\begin{example}		\label{Exemplexyxsqysq}
	Soit à calculer la limite
	\begin{equation}
		\lim_{(x,y)\to(0,0)}xy\left( \frac{ x^2-y^2 }{ x^2+y^2 }\right).
	\end{equation}
	Le passage aux coordonnées polaires donne
	\begin{equation}
		f(r,\theta)=r^2\sin\theta\cos\theta(\cos^2\theta-\sin^2\theta).
	\end{equation}
	Déterminer le supremum de cela est relativement difficile. Mais nous savons que de toutes façons, la quantité $\sin\theta\cos\theta(\cos^2\theta-\sin^2\theta)$ est bornée par $1$. Donc
	\begin{equation}
		\| f(r,\theta) \|\leq r^2.
	\end{equation}
	Maintenant la règle de l'étau montre que $\lim_{(x,y)\to(0,0)}f(x,y)$ est zéro.

	La situation vraiment gênante serait celle avec une fonction de $\theta$ qui risque de s'annuler dans un dénominateur.
\end{example}

L'exemple~\ref{EXooSDHDooJzDioW} donnera un cas où la méthode fonctionne plus difficilement. Entre autres parce qu'il utilisera en même temps la méthode des chemins et celle des coordonnées polaires.

\begin{example}\label{ExmeASDLAf}
	Considérons fonction
	\begin{equation}
		f(x,y)=\frac{ x^2+y^2 }{ x-y }.
	\end{equation}
	Une mauvaise idée pour prouver que la limite n'existe pas pour $(x,y)\to(0,0)$ est de considérer le chemin $(t,t)$. En effet, la fonction n'existe pas sur ce chemin. Or la méthode des chemins parle uniquement de chemins contenus dans le domaine de la fonction.

	Nous prouvons que la limite n'existe pas en trouvant des chemins le long desquels les limites sont différentes. Si nous essayons le chemin \( (t,kt)\) avec \( k\) constant, nous trouvons
    \begin{equation}
        f(t,kt)=\frac{ t(1+k^2) }{ 1-k }.
    \end{equation}
    La limite \( t\to 0\) est hélas toujours \( 0\). Nous ne pouvons donc pas conclure.

    Nous allons maintenant utiliser la même technique que celle utilisée en coordonnées polaires. Vous noterez que dans ce cas, travailler en cartésiennes donne lieu à des calculs plus longs.  L'astuce consiste à prendre \( k\) non constant et à chercher par exemple \( k(t)\) de façon à avoir
    \begin{equation}
        \frac{ 1+k(t)^2 }{ 1-k(t) }=\frac{1}{ t }.
    \end{equation}
    Avec une telle fonction \( k\), la fonction \( t\mapsto f(t,tk(t))\) serait la constante \( 1\). L'équation à résoudre pour \( k\) est
    \begin{equation}
        tk^2+k+(t-1)=0,
    \end{equation}
    et les solutions sont
    \begin{equation}
        k(t)=\frac{ -1\pm\sqrt{1-4t(t-1)} }{ 2t }.
    \end{equation}
    Nous proposons donc les chemins
    \begin{equation}
        \begin{pmatrix}
            x    \\
            y
        \end{pmatrix}=\begin{pmatrix}
            t    \\
            \frac{ -1\pm\sqrt{1-4t(t-1)}    }{2}
        \end{pmatrix}
    \end{equation}
    Nous devons vérifier deux points. D'abord que ce chemin est bien défini, et ensuite que \( tk(t)\) tend bien vers zéro lorsque \( t\to 0\) (sinon \( (t,k(t)t)\)) n'est pas un chemin passant par \( (0,0)\). Lorsque \( t\) est petit, ce qui se trouve sous la racine est proche de \( 1\) et ne pose pas de problèmes. Ensuite,
    \begin{equation}
        \lim_{t\to 0} tk(t)=\frac{ -1\pm 1 }{ 2 }.
    \end{equation}
    En choisissant le signe \( +\), nous trouvons un chemin qui nous convient.

    Ce que nous avons prouvé est que
    \begin{equation}
        f\left( t,   \frac{ -1+\sqrt{1-4t(t-1)}    }{2}\right)=1
    \end{equation}
    pour tout \( t\). Le long de ce chemin, la limite de \( f\) est donc \( 1\). Cette limite est différente des limites obtenues le long de chemins avec \( k\) constant. La limite \( \lim_{(x,y)\to (0,0)} f(x,y)\) n'existe donc pas.
\end{example}

\begin{example}\label{seno}
	Considérons la fonction (figure~\ref{LabelFigsenotopologo})

	\begin{equation}
		f(x,y)=\begin{cases}
			\sqrt{x^2+y^2}\sin\frac{1}{ x^2+y^2 }	&	\text{si }(x,y)\neq(0,0)\\
			0	&	 \text{si }(x,y)=(0,0),
		\end{cases}
	\end{equation}
    et cherchons la limite $(x,y)\to(0,0)$. Le passage en coordonnées polaires\footnote{Proposition~\ref{PROPooFLUAooDsyMXO}.} donne
	\begin{equation}		\label{EqFoncRho2907}
		f(\rho,\theta)=\rho\sin\frac{1}{ \rho }.
	\end{equation}
	Pour calculer la limite de cela lorsque $\rho\to 0$, nous remarquons que
	\begin{equation}
		0\leq|\rho\sin\frac{1}{ \rho }|\leq\rho
	\end{equation}
	parce que $\sin(\frac{1}{ \rho })\leq 1$ quel que soit $\rho$. Or évidemment $\lim_{\rho\to 0} \rho=0$, donc la limite de la fonction \eqref{EqFoncRho2907} est zéro et ne dépend pas de $\theta$. Nous en concluons que $\lim_{(x,y)\to(0,0)}f(x,y)=0$.
\end{example}
\newcommand{\CaptionFigsenotopologo}{La fonction de l'exemple~\ref{seno}.}
\input{auto/pictures_tex/Fig_senotopologo.pstricks}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Méthode du développement asymptotique}
%---------------------------------------------------------------------------------------------------------------------------
\label{SUBSECooRAKKooAnpvkE}

Nous savons  que nous pouvons développer certaines fonctions en série grâce au développement de Taylor (théorème~\ref{ThoTaylor}). Lorsque nous avons une limite à calculer, nous pouvons remplacer certaines parties de la fonction à traiter par la formule \eqref{subeqfTepseqb}. Cela est très utile pour comparer des fonctions trigonométrique à des polynômes.

\begin{lemma}       \label{LEMooZYNEooYkwsWD}
    Nous avons la limite
    \begin{equation}
        \lim_{x\to 0} \frac{ \sin(x) }{ x }=1.
    \end{equation}
\end{lemma}

\begin{proof}
    Une manière de prouver cela est d'écrire
    \begin{equation}
		\sin(x)=x+h(x)
	\end{equation}
	avec $h\in o(x)$, c'est-à-dire $\lim_{x\to 0} h(x)/x=0$. Alors nous avons
	\begin{equation}
		\lim_{x\to 0} \frac{ \sin(x) }{ x }=\lim_{x\to 0} \frac{ x+h(x) }{ x }=\lim_{x\to 0} \frac{ x }{ x }+\lim_{x\to 0} \frac{ h(x) }{ x }=1.
	\end{equation}
\end{proof}

L'utilisation de la proposition~\ref{PropLimCompose} permet d'utiliser cette technique dans le cadre de limites à plusieurs variables. Reprenons le lemme \ref{LEMooZYNEooYkwsWD} un tout petit peu modifié :

\begin{lemma}       \label{LEMooSFALooVRBdNb}
    Pour tout \( x>0\) nous avons \( \sin(x)<x\).
\end{lemma}

\begin{proof}
    Nous posons \( f(x)=x-\sin(x)\). Cette fonction vérifie \( f(0)=0\) et
    \begin{equation}
        f'(x)=1-\cos(x).
    \end{equation}
    Vu que \( | \cos(x) |\leq 1\), nous avons toujours \( f'(x)\geq 0\) et même \( f'(x)>0\) pour \( x\in \mathopen] 0 , \delta \mathclose]\). Donc \( f\) est au moins strictement croissante sur \( \mathopen] 0 , \delta \mathclose]\) et ensuite strictement croissante presque partout.
\end{proof}

\begin{example}
	Soit à calculer $\lim_{(x,y)\to(0,0)}f(x,y)$ où
	\begin{equation}
		f(x,y)=\frac{ \sin(xy) }{ xy }.
	\end{equation}
	La première chose à faire est de voir $f$ comme la composée de fonctions $f=f_1\circ f_2$ avec
	\begin{equation}
		\begin{aligned}
			f_1\colon \eR&\to \eR \\
			t&\mapsto \frac{ \sin(t) }{ t }
		\end{aligned}
	\end{equation}
	et
	\begin{equation}
		\begin{aligned}
			f_2\colon \eR^2&\to \eR \\
			(x,y)&\mapsto xy.
		\end{aligned}
	\end{equation}
	Étant donné que $\lim_{(x,y)\to(0,0)}f_2(x,y)=0$, nous avons $\lim_{(x,y)\to(0,0)}f(x,y)=\lim_{t\to 0} f_1(t)=1$.
\end{example}

\begin{example}     \label{EXooETZYooYsKPDJ}
Les dérivées partielles de la fonction $f(x,y)=xy^3+\sin y$ au point $(0,\pi)$ sont
\[
\partial_xf(0,\pi)=\frac{ \partial f }{ \partial x }(0,\pi)=\lim_{\begin{subarray}{l}
    t\to 0\\ t\neq 0
  \end{subarray}} \frac{(t\pi^3+\sin \pi)-(\sin \pi)}{t}= \pi^3,
\]
\[
\partial_yf(0,\pi)=\frac{ \partial f }{ \partial y }(0,\pi)=\lim_{\begin{subarray}{l}
    t\to 0\\ t\neq 0
  \end{subarray}} \frac{0(\pi+t)^3+\sin (t+\pi)-0\cdot \pi^3}{t}= \cos \pi=-1,
\]
\end{example}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Quelques intégrales avec de la trigonométrie}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\label{SECooOOPPooZLbaEH}

Le théorème~\ref{THOooUMIWooZUtUSg} manque un peu d'exemples. Nous allons en voir quelques-uns maintenant.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Changement de variables}
%---------------------------------------------------------------------------------------------------------------------------

Le domaine $E=\{ (x,y)\in\eR^2\tq x^2+y^2<1 \}$ s'écrit plus facilement $E=\{ (r,\theta)\tq r<1 \}$ en coordonnées polaires. Le passage aux coordonnées polaires permet de transformer une intégration sur un domaine rond à une intégration sur le domaine rectangulaire $\mathopen]0,2\pi\mathclose[\times\mathopen]0,1\mathclose[$. La question est évidemment de savoir si nous pouvons écrire
\begin{equation}
    \int_Ef=\int_{0}^{2\pi}\int_0^1f(r\cos\theta,r\sin\theta)drd\theta.
\end{equation}
Hélas, non; la vie n'est pas aussi simple.

\begin{definition}      \label{DEFooYRXQooMqfQaO}
    Un \defe{difféomorphisme}{difféomorphisme} est une application $g\colon A\to B$ telle que $g$ et $g^{-1}\colon B\to A$ soient de classe $C^1$.
\end{definition}

Comme dans les intégrales simples, il y a souvent moyen de trouver un changement de variables qui simplifie les expressions.  Le domaine $E=\{ (x,y)\in\eR^2\tq x^2+y^2<1 \}$ par exemple s'écrit plus facilement $E=\{ (r,\theta)\tq r<1 \}$ en coordonnées polaires. Le passage aux coordonnées polaires permet de transformer une intégration sur un domaine rond à une intégration sur le domaine rectangulaire $\mathopen]0,2\pi\mathclose[\times\mathopen]0,1\mathclose[$. La question est évidemment de savoir si nous pouvons écrire
\begin{equation}
	\int_Ef=\int_{0}^{2\pi}\int_0^1f(r\cos\theta,r\sin\theta)drd\theta.
\end{equation}
Hélas ce n'est pas le cas. Il faut tenir compte du fait que le changement de base dilate ou contracte certaines surfaces.

Soit $\varphi\colon D_1\subset\eR^2\to D_2\subset \eR^2$ une fonction bijective de classe $C^1$ dont l'inverse est également de classe $C^1$. On désigne par $x$ et $y$ ses composantes, c'est-à-dire que
\begin{equation}
    \varphi(u,v)=\begin{pmatrix}
        x(u,v)    \\
        y(u,v)
    \end{pmatrix}
\end{equation}
avec $(u,v)\in D_1$.

\begin{theorem}     \label{ThoChamDeVarIntDDf}
    Soit une fonction continue $f\colon D_2\to \eR$. Alors
    \begin{equation}
        \int_{\varphi(D_1)}f(x,y)dxdy=\int_{D_1}f\big( x(u,v),y(u,v) \big)| J_{\varphi}(u,v) |dudv
    \end{equation}
    où $J_{\varphi}$ est le Jacobien de $\varphi$ c'est-à-dire
    \begin{equation}
        J_{\varphi}(u,v)=\det\begin{pmatrix}
            \frac{ \partial x }{ \partial u }    &   \frac{ \partial x }{ \partial v }    \\
            \frac{ \partial y }{ \partial u }    &   \frac{ \partial u }{ \partial v }
        \end{pmatrix}.
    \end{equation}
\end{theorem}
Ne pas oublier de prendre la valeur absolue lorsqu'on utilise le Jacobien dans un changement de variables.

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Coordonnées polaires}
%---------------------------------------------------------------------------------------------------------------------------

\begin{example}
    Calculons la surface du disque $D$ de rayon $R$. Nous devons calculer
    \begin{equation}
        \int_Ddxdy.
    \end{equation}
    Pour passer au polaires, nous savons que le disque est décrit par
    \begin{equation}
        D=\{ (r,\theta)\tq 0\leq r\leq R,0\leq\theta\leq 2\pi \}.
    \end{equation}
    Nous avons donc
    \begin{equation}
        \int_Ddxdy=\int_{D}r\,drd\theta=\int_0^{2\pi}\int_0^Rr\,drd\theta=2\pi\int_0^Rr\,dr=\pi R^2.
    \end{equation}
\end{example}

\begin{example}     \label{ExpmfDtAtV}
    Montrons comment intégrer la fonction $f(x,y)=\sqrt{1-x^2-y^2}$ sur le domaine délimité par la droite $y=x$ et le cercle $x^2+y^2=y$, représenté sur la figure~\ref{LabelFigHFAYooOrfMAA}. Pour trouver le centre et le rayon du cercle $x^2+y^2=y$, nous commençons par écrire $x^2+y^2-y=0$, et ensuite nous reformons le carré : $y^2-y=(y-\frac{ 1 }{2})^2-\frac{1}{ 4 }$.

\newcommand{\CaptionFigHFAYooOrfMAA}{Passage en polaire pour intégrer sur un morceau de cercle.}
\input{auto/pictures_tex/Fig_HFAYooOrfMAA.pstricks}

    Le passage en polaire transforme les équations du bord du domaine en
    \begin{equation}
        \begin{aligned}[]
            \cos(\theta)&=\sin(\theta)\\
            r^2&=r\sin(\theta).
        \end{aligned}
    \end{equation}
    L'angle $\theta$ parcours donc $\mathopen] 0 , \pi/4 \mathclose[$, et le rayon, pour chacun de ces $\theta$ parcours $\mathopen] 0 , \sin(\theta) \mathclose[$. La fonction à intégrer se note maintenant $f(r,\theta)=\sqrt{1-r^2}$. Donc l'intégrale à calculer est
    \begin{equation}		\label{PgOMRapIntMultFubiniBoutCercle}
        \int_{0}^{\pi/4}\left( \int_0^{\sin(\theta)}\sqrt{1-r^2}r\,rd \right).
    \end{equation}
    Remarquez la présence d'un $r$ supplémentaire pour le jacobien.

    Notez que les coordonnées du point $P$ sont $(1,1)$.
\end{example}

En pratique, lors du passage en coordonnées polaires, le «$dxdy$» devient «$r\,drd\theta$».

\begin{example}
    On veut évaluer l'intégrale de la fonction $f(x,y)= x^2+y^2$ sur la région $V$ suivante :
    \[
    V=\{(x,y) \in \eR^2\,\vert\, x^2+y^2\leq 1,\, x>0,\, y>0\}.
    \]
    On peut faire le calcul directement,
    \[
    \int_{V}f(x,y)\, dV=\int_0^1\int_0^{\sqrt{1-x^2}}x^2+y^2\, dy\,dx=\int_0^1\left(x^2\sqrt{1-x^2} + \frac{(1-x^2)^{3/2}}{3}\right) dx
    \]
    mais c'est un peu ennuyeux. On peut simplifier beaucoup les calculs avec un changement de variables vers les coordonnées polaires. Dans ce cas, on sait bien que le difféomorphisme à utiliser est $\phi(r,\theta)=(r\cos \theta, r\sin\theta)$. Le jacobien  $J_{\phi}$ est
    \begin{equation}
     J_{\phi}(r, \theta)= \left\vert\begin{array}{cc}
    \cos \theta & \sin \theta \\
    -r\sin \theta  & r\cos \theta
    \end{array}\right\vert= r,
    \end{equation}
    qui est toujours positif. D'une part, la fonction $f$ peut s'écrire sous la forme $f(\phi(r,\theta))=r^2$ et d'autre part, $\phi^{-1}(V)=]0,1]\times]0, \pi/2[$. Par conséquent, la formule du changement de variables nous donne
    \[
    \int_{V}f(x,y)\, dV=\int_0^{\pi/2}\int_0^{1}r^3 dr\,d\theta=\int_0^{\pi/2}\frac{1}{4}\,d\theta=\frac{\pi}{8}.
    \]
\end{example}

\begin{example}
    Montrons comment intégrer la fonction $f(x,y)=\sqrt{1-x^2-y^2}$ sur le domaine délimité par la droite $y=x$ et le cercle $x^2+y^2=y$, représenté sur la figure~\ref{LabelFigQXyVaKD}. Pour trouver le centre et le rayon du cercle $x^2+y^2=y$, nous commençons par écrire $x^2+y^2-y=0$, et ensuite nous reformons le carré : $y^2-y=(y-\frac{ 1 }{2})^2-\frac{1}{ 4 }$.
    \newcommand{\CaptionFigQXyVaKD}{Passage en polaire pour intégrer sur un morceau de cercle.}
\input{auto/pictures_tex/Fig_QXyVaKD.pstricks}

    Le passage en polaire transforme les équations du bord du domaine en
    \begin{equation}
        \begin{aligned}[]
            \cos(\theta)&=\sin(\theta)\\
            r^2&=r\sin(\theta).
        \end{aligned}
    \end{equation}
    L'angle $\theta$ parcours donc $\mathopen] 0 , \pi/4 \mathclose[$, et le rayon, pour chacun de ces $\theta$ parcours $\mathopen] 0 , \sin(\theta) \mathclose[$. La fonction à intégrer se note maintenant $f(r,\theta)=\sqrt{1-r^2}$. Donc l'intégrale à calculer est
    \begin{equation}		\label{PgRapIntMultFubiniBoutCercle}
        \int_{0}^{\pi/4}\left( \int_0^{\sin(\theta)}\sqrt{1-r^2}r\,rd \right).
    \end{equation}
    Remarquez la présence d'un $r$ supplémentaire pour le jacobien.

    Notez que les coordonnées du point $P$ sont $(1,1)$.
\end{example}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Coordonnées cylindriques}
%---------------------------------------------------------------------------------------------------------------------------

\begin{example}
    On veut calculer le volume de la région $A$ définie par  l'intersection entre la boule unité et le cylindre qui a pour base un disque de rayon $1/2$ centré en $(0, 1/2)$
    \[
    A=\{(x,y,z) \in\eR^3 \,\vert\, x^2+y^2+z^1\leq 1\}\cap\{(x,y,z) \in \eR^3\,\vert\, x^2+(y-1/2)^2\leq 1/4\}.
    \]
    On peut décrire $A$ en coordonnées cylindriques
    \begin{equation}
      \begin{aligned}
        A=\Big\{(r,\theta,z) &\in ]0, +\infty[\times [-\pi,\pi[\times \eR\,\vert\,\\
    & -\pi/2<\theta<\pi, \, 0<r\leq \sin\theta, \, -\sqrt{1-r^2}\leq z\leq\sqrt{1-r^2} \Big\}.
      \end{aligned}
    \end{equation}
    Le jacobien de ce changement de variables,  $J_{cyl}$, est
    \begin{equation}
     J_{cyl}(r, \theta), z= \left\vert\begin{array}{ccc}
    \cos \theta & \sin \theta & 0\\
    -r\sin \theta  & r\cos \theta &0 \\
    0&0&
    \end{array}\right\vert= r,
    \end{equation}
    qui est toujours positif. Le volume de $A$ est donc
    \[
    \int_{\eR^3}\chi_{A}(x,y,z)\, dV=\int_{-\pi/2}^{\pi/2}\int_0^{\sin\theta}\int_{-\sqrt{1-r^2}}^{\sqrt{1-r^2}} r dz\,dr\,d\theta=\frac{2\pi}{8}+\frac{8}{9}.
    \]
\end{example}

\begin{example}[Volume d'un solide de révolution]
Soit $g:[a,b]\to\eR_+$ une fonction continue et positive. On dit que le solide $A$ décrit par
\[
A=\left\{(x,y,z)\in\eR^3\, \vert \, z\in[a,b], \,\sqrt{x^2+y^2}\leq g^2(z) \right\}
\]
est un solide de révolution. Afin de calculer son volume, on peut décrire $A$ en coordonnées cylindriques,
\[
A=\left\{(r,\theta,z) \in ]0, +\infty[\times [-\pi,\pi[\times \eR\,\vert\, a\leq z\leq b, \, 0<r^2\leq g^2(z) \right\}.
\]
Le jacobien de ce changement de variables est  $J_{cyl}=r$, comme dans l'exemple précédent. Le volume de $A$ est donc
\[
\int_{\eR^3}\chi_{A}(x,y,z)\, dV=\int_a^{b}\int_{-\pi}^{\pi}\int_{0}^{g(z)} r  \,dr\,d\theta\, dz=\int_a^{b} \pi g^2(z) \, dz.
\]
Cette formule peut être utilisée pour tout solide de révolution.
\end{example}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Coordonnées sphériques}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Le calcul est un peu plus long :
\begin{equation}
    \begin{aligned}[]
        J(\rho,\theta,\varphi)&=\begin{vmatrix}
            \frac{ \partial x }{ \partial \rho }    &   \frac{ \partial x }{ \partial \theta }    &   \frac{ \partial x }{ \partial \varphi }    \\
            \frac{ \partial y }{ \partial \rho }    &   \frac{ \partial y }{ \partial \theta }    &   \frac{ \partial y }{ \partial \varphi }    \\
            \frac{ \partial z }{ \partial \rho }    &   \frac{ \partial z }{ \partial \theta }    &   \frac{ \partial z }{ \partial \varphi }
        \end{vmatrix}\\
        &=
        \begin{vmatrix}
            \sin\theta\cos\varphi    &   \rho\cos\theta\cos\varphi    &   -\rho\sin\theta\sin\varphi    \\
            \sin\theta\sin\varphi    &   \rho\cos\theta\sin\varphi    &   -\rho\sin\theta\cos\varphi    \\
            \cos\theta               &   -\rho\sin\theta              &   0
        \end{vmatrix}\\
        &=\rho^2\sin\theta.
    \end{aligned}
\end{equation}
Donc
\begin{equation}
    dx\,dy\,dz=\rho^2\sin(\theta)\,d\rho\,d\theta\,d\varphi.
\end{equation}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Coordonnées sphériques}
%---------------------------------------------------------------------------------------------------------------------------

\begin{example}
    On veut calculer le volume du cornet de glace  $A$
    \[
    A=\left\{(x,y,z)\in\eR^3\, \vert \, (x,y)\in \mathbb{S}^2, \,\sqrt{x^2+y^2}\leq z\leq \sqrt{1-x^2-y^2} \right\}.
    \]
    On peut décrire $A$ en coordonnées sphériques.
    \[
    A=\{(\rho,\theta,\phi) \in ]0, +\infty[\times [-\pi,\pi[\times [0,\pi[\,\vert\, 0<\phi\leq\pi/4, \, 0<\rho\leq 1 \}.
    \]
    Le jacobien de ce changement de variables  $J_{sph}$ est
    \begin{equation}
     J_{sph}(\rho, \theta, \phi)= \left\vert\begin{array}{ccc}
    \cos \theta \sin\phi & \sin \theta\sin\phi & \cos\phi\\
    -\rho\sin \theta\sin\phi  & \rho\cos \theta\sin\phi & 0 \\
    \rho\cos\theta\cos\phi&\rho\sin\theta\cos\phi& -\rho\sin\phi
    \end{array}\right\vert= \rho^2\sin\phi,
    \end{equation}
    Le volume de $A$ est donc
    \[
    \int_{\eR^3}\chi_{A}(x,y,z)\, dV=\int_{-\pi}^{\pi}\int_0^{\pi/4}\int_{0}^{1}\rho^2\sin\phi \,d\rho\,d\phi\,d\theta=\frac{2\pi}{3}\left(1-\frac{1}{\sqrt{2}}\right).
    \]
\end{example}

\begin{example}[Une petite faute à ne pas faire]
    Si nous voulons calculer le volume de la sphère de rayon $R$, nous écrivons donc
    \begin{equation}
        \int_0^Rdr\int_{0}^{2\pi}d\theta\int_0^{\pi}r^2 \sin(\phi)d\phi=4\pi R=\frac{ 4 }{ 3 }\pi R^3.
    \end{equation}
    Ici, la valeur absolue n'est pas importante parce que lorsque $\phi\in\mathopen] 0,\pi ,  \mathclose[$, le sinus de $\phi$ est positif.

    Des petits malins pourraient remarquer que le changement de variable \eqref{EqChmVarSpherique} est encore un paramétrage de $\eR^3$ si on intervertit le domaine des angles :
    \begin{equation}
        \begin{aligned}[]
            \theta&\colon 0 \to \pi\\
            \phi	&\colon 0\to 2\pi,
        \end{aligned}
    \end{equation}
    alors nous paramétrons encore parfaitement bien la sphère, mais hélas
    \begin{equation}		\label{EqVolumeIncorrectSphere}
        \int_0^Rdr\int_{0}^{\pi}d\theta\int_0^{2\pi}r^2 \sin(\phi)d\phi=0.
    \end{equation}
    Pourquoi ces «nouvelles» coordonnées sphériques sont-elles mauvaises ? Il y a que quand l'angle $\phi$ parcours $\mathopen] 0 , 2\pi \mathclose[$, son sinus n'est plus toujours positif, donc la \emph{valeur absolue} du jacobien n'est plus $r^2\sin(\phi)$, mais $r^2\sin(\phi)$ pour les $\phi$ entre $0$ et $\pi$, puis $-r^2\sin(\phi)$ pour $\phi$ entre $\pi$ et $2\pi$. Donc l'intégrale \eqref{EqVolumeIncorrectSphere} n'est pas correcte. Il faut la remplacer par
    \begin{equation}
        \int_0^Rdr\int_{0}^{\pi}d\theta\int_0^{\pi}r^2 \sin(\phi)d\phi- \int_0^Rdr\int_{0}^{\pi}d\theta\int_{\pi}^{2\pi}r^2 \sin(\phi)d\phi = \frac{ 4 }{ 3 }\pi R^3
    \end{equation}

\end{example}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Un autre système utile}
%---------------------------------------------------------------------------------------------------------------------------

Un changement de variables que l'on voit assez souvent est
\begin{subequations}
    \begin{numcases}{}
        u=x+y\\
        v=x-y.
    \end{numcases}
\end{subequations}
Afin de calculer son jacobien, il faut d'abord exprimer $x$ et $y$ en fonctions de $u$ et $v$ :
\begin{subequations}
    \begin{numcases}{}
        x=(u+v)/2\\
        y=(u-v)/2.
    \end{numcases}
\end{subequations}
La matrice jacobienne est
\begin{equation}
    \begin{pmatrix}
        \frac{ \partial x }{ \partial u }    &   \frac{ \partial x }{ \partial v }    \\
        \frac{ \partial y }{ \partial u }    &   \frac{ \partial y }{ \partial v }
    \end{pmatrix}=
    \begin{pmatrix}
        \frac{ 1 }{2}    &   \frac{ 1 }{2}    \\
        \frac{ 1 }{2}    &   -\frac{ 1 }{2}
    \end{pmatrix}.
\end{equation}
Le déterminant vaut $-\frac{1}{ 2 }$. Nous avons donc
\begin{equation}
    dxdy=\frac{ 1 }{2}dudv.
\end{equation}
Nous insistons sur le fait que c'est $\frac{ 1 }{2}$ et non $-\frac{ 1 }{2}$ qui intervient parce que que la formule du changement de variable demande d'introduire la \emph{valeur absolue} du jacobien.

\begin{example}
    Calculer l'intégrale de la fonction $f(x,y)=x^2-y^2$ sur le domaine représenté sur la figure~\ref{LabelFigVWFLooPSrOqz}. % From file VWFLooPSrOqz
\newcommand{\CaptionFigVWFLooPSrOqz}{Un domaine qui s'écrit étonnament bien avec un bon changement de coordonnées.}
\input{auto/pictures_tex/Fig_VWFLooPSrOqz.pstricks}

    Les droites qui délimitent le domaine d'intégration sont
    \begin{equation}
        \begin{aligned}[]
            y&=-x+2\\
            y&=x-2\\
            y&=x\\
            y&=-x
        \end{aligned}
    \end{equation}
    Le domaine est donc donné par les équations
    \begin{subequations}
        \begin{numcases}{}
            y+x<2\\
            y-x>-2\\
            y-x<0 \\
            y+x>0.
        \end{numcases}
    \end{subequations}
    En utilisant le changement de variables $u=x+y$, $v=x-y$ nous trouvons le domaine $0<u<2$, $0<v<2$. En ce qui concerne la fonction, $f(x,y)=(x+y)(x-y)$ et par conséquent
    \begin{equation}
        f(u,v)=uv.
    \end{equation}
    L'intégrale à calculer est simplement
    \begin{equation}
        \int_0^2\int_0^2 uv\,dudv=\int_0^2 u\,du\left[ \frac{ v^2 }{ 2 } \right]_0^2=2\int_0^2u\,du=4.
    \end{equation}
\end{example}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Aire d'une surface de révolution}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Soit $\gamma$ une courbe dans le plan $xy$, paramétrée par
\begin{equation}
    \gamma(u)=\begin{pmatrix}
        x(u)    \\
        y(u)    \\
        0
    \end{pmatrix}
\end{equation}
avec $u\in\mathopen[ a , b \mathclose]$. Nous supposons que la courbe est toujours positive, c'est-à-dire $y(u)>0$ pour tout $u$.

Nous voulons considérer la surface obtenue en effectuant une rotation de cette ligne autour de l'axe $X$. Chaque point de la courbe va parcourir un cercle de rayon $y(u)$ dans le plan $YX$ et centré en $(x(u),0,0)$. La surface est donc donnée par
\begin{equation}
    \varphi(u,\theta)=\begin{pmatrix}
        x(u)    \\
        y(u)\cos\theta    \\
        y(u)\sin\theta
    \end{pmatrix}
\end{equation}
avec $(u,\theta)\in\mathopen[ a , b \mathclose]\times \mathopen[ 0 , 2\pi \mathclose]$. Notez que la courbe de départ correspond à $\theta=0$.

Les vecteurs tangents à la surface pour ce paramétrage sont
\begin{equation}
    \begin{aligned}[]
        T_u&=\frac{ \partial \varphi }{ \partial u }=\begin{pmatrix}
            x'(u)    \\
            y'(u)\cos\theta    \\
            y'(u)\sin\theta
        \end{pmatrix}&
        T_{\theta}&=\frac{ \partial \varphi }{ \partial \theta }=\begin{pmatrix}
            0    \\
            -y(u)\sin\theta    \\
            y(u)\cos\theta
        \end{pmatrix}.
    \end{aligned}
\end{equation}
Le produit vectoriel de ces deux vecteurs vaut
\begin{equation}
    \begin{aligned}[]
        T_u\times T_{\theta}&=\begin{vmatrix}
            e_x    &   e_y    &   e_z    \\
            x'    &   y'\cos\theta    &   y'\sin\theta    \\
            0    &   -y\sin\theta    &   y\cos\theta
        \end{vmatrix}\\
        &=y'(u)y(u)\,e_x-x'(u)y(u)\cos\theta\, e_y+x'(u)y(u)\sin\theta\, e_z.
    \end{aligned}
\end{equation}
En ce qui concerne la norme :
\begin{equation}
    dS=\| T_u\times T_{\theta} \|=\sqrt{(y'y)^2+(x'y)^2}=| y(u) |\sqrt{y'(u)^2+x'(u)^2}.
\end{equation}
Étant donné que nous avons supposé que $y(u)>0$, nous pouvons supprimer les valeurs absolues, et l'aire de la surface de révolution devient :
\begin{equation}
    \begin{aligned}[]
        Aire(S)&=\int_0^{2\pi}d\theta\int_a^b y(u)\sqrt{x'(u)^2+y'(u)^2}du\\
        &=2\pi\int_a^b y(u)\sqrt{x'(u)^2+y'(u)^2}du.
    \end{aligned}
\end{equation}

\begin{example}     \label{EXooZCLXooVmXQgY}
    Calculons la surface du cône de révolution de rayon (à la base) $R$ et de hauteur $h$. La courbe de départ est le segment droite qui part de $(0,0)$ et qui termine en $(R,h)$ de la figure~\ref{LabelFigYHJYooTEXLLn}. % From file YHJYooTEXLLn
\newcommand{\CaptionFigYHJYooTEXLLn}{En faisant tourner cette droite autour de l'axe $X$, nous obtenons un cône.}
\input{auto/pictures_tex/Fig_YHJYooTEXLLn.pstricks}

    Ce segment peut être paramétré par
    \begin{equation}
        \gamma(u)=\begin{pmatrix}
            Ru    \\
            hu    \\
            0
        \end{pmatrix}
    \end{equation}
    avec $u\in\mathopen[ 0 , 1 \mathclose]$. Cela donne $x(u)=Ru$, $y(u)=hu$ et par conséquent
    \begin{equation}
        Aire=2\pi\int_0^1hu\sqrt{R^2+h^2}=\pi h\sqrt{R^2+h^2}.
    \end{equation}
    Ce résultat peut aussi être exprimé en fonction de l'angle, grâce à la formule \eqref{EQooEKZEooFeNImX}. En sachant que $h=\sqrt{h^2+R^2}\sin(\alpha)$, nous trouvons
    \begin{equation}
        Aire=\pi(R^2+h^2)\sin(\alpha).
    \end{equation}

\end{example}

\begin{example}
    Calculons la surface latérale du tore obtenu par révolution du cercle de la figure ~\ref{LabelFigROAOooPgUZIt}. % From file ROAOooPgUZIt
\newcommand{\CaptionFigROAOooPgUZIt}{Si nous tournons ce cercle autour de l'axe $X$, nous obtenons un tore de rayon «externe» $a$ et de rayon «interne» $R$.}
\input{auto/pictures_tex/Fig_ROAOooPgUZIt.pstricks}

    Le chemin qui détermine le cercle de départ est
    \begin{equation}
        \gamma(u)=\begin{pmatrix}
            R\cos(u)    \\
            a+R\sin(u)    \\
            0
        \end{pmatrix},
    \end{equation}
    c'est-à-dire $x(u)=R\cos(u)$, $y(u)=a+R\sin(u)$ avec $u\in\mathopen[ 0 , 2\pi \mathclose]$. Nous avons donc l'aire
    \begin{equation}
        \begin{aligned}[]
            Aire&=2\pi\int_0^{2\pi}\big( a+R\sin(u) \big)R\,du\\
            &=2\pi R\big( 2\pi a+R[-\cos(u)]_0^{2\pi} \big)\\
            &=4\pi^2aR.
        \end{aligned}
    \end{equation}
\end{example}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Table de caractères du groupe diédral}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\label{SecWMzheKf}
Cette section vient de \cite{KXjFWKA}; nous avons comme but d'établir la table des caractères des représentations complexes du groupe diédral \( D_n\).
\index{groupe!de permutation}
\index{groupe!diédral!générateurs (utilisation)}
\index{représentation!groupe diédral}
\index{caractère!groupe diédral}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Représentations de dimension un}
%---------------------------------------------------------------------------------------------------------------------------

Nous nous occupons des représentations de \( D_n\) sur \( \eC\). Les applications linéaires \( \eC\to \eC\) sont seulement les multiplications par des nombres complexes. Nous cherchons donc \( \psi\colon D_n\to \eC^*\).

Nous savons que \( D_n\) est généré\footnote{Voir proposition~\ref{PropLDIPoZ} et tout ce qui suit.} par \( s\) et \( r\). Vu que \( s^2=1\), nous avons
\begin{equation}
    \psi(s)^2=\psi(s^2)=\psi(1)=1,
\end{equation}
donc \( \psi(s)\in\{ -1,1 \}\). Nous savons aussi que \( srsr=1\), donc
\begin{equation}
    \psi(s)^2\psi(r)^2=1,
\end{equation}
ce qui donne \( \psi(r)\in\{ -1,1 \}\).

Nous avons donc quatre représentations de dimension un données par
\begin{equation*}
    \begin{array}[]{|c||c|c|}
        \hline
        &\psi(r)=1&\psi(r)=-1\\
        \hline\hline
        \psi(s)=1&\rho^{++}&\rho^{+-}\\
        \hline
        \psi(s)=-1&\rho^{-+}&\rho^{--}\\
        \hline
    \end{array}
\end{equation*}
Attention au fait que nous devons aussi avoir la relation \( \psi(r)^n=\psi(r^n)=1\). Donc \( \psi(r)\) doit être une racine \( n\)\ieme\ de l'unité. Nous allons donc devoir avoir un compte différent selon la parité de \( n\). Nous en reparlerons à la fin, au moment de faire les comptes. En ce qui concerne les caractères correspondants,
\begin{equation*}
    \begin{array}[]{|c||c|c|}
        \hline
        &r^k&sr^k\\
        \hline\hline
        \chi^{++}&1&1\\
        \hline
        \chi^{+-}&(-1)^k&(-1)^k\\
        \hline
        \chi^{-+}&1&-1\\
        \hline
        \chi^{--}&(-1)^k&(-1)^{k+1}\\
        \hline
    \end{array}
\end{equation*}
Étant donné qu'ils sont tous différents, ce sont des représentations deux à deux non équivalentes, lemme~\ref{LempUSOlo}.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Représentations de dimension deux}
%---------------------------------------------------------------------------------------------------------------------------

Nous cherchons maintenant les représentations \( \rho\colon D_n\to \End(\eC^2)\). Ici nous supposons connue la liste des éléments de \( D_n\) donnée par le corolaire~\ref{CorWYITsWW}. Soit \( \omega= e^{2i\pi/n}\) et \( h\in \eZ\); nous considérons la représentation \( \rho^{(h)}\) de \( D_n\) définie par
\begin{subequations}
    \begin{align}
        \rho^{(h)}(r^k)&=\begin{pmatrix}
            \omega^{hk}    &   0    \\
            0    &   \omega^{-hk}
        \end{pmatrix}\\
        \rho^{(h)}(st^k)&=\begin{pmatrix}
            0    &   \omega^{-hk}    \\
            \omega^{hk}    &   0
        \end{pmatrix}.
    \end{align}
\end{subequations}
Cela donne bien \( \rho^{(h)}\) sur tous les éléments de \( D_n\) par la proposition~\ref{PropLDIPoZ}. Nous pouvons restreindre le domaine de \( h\) en remarquant d'abord que \( \rho^{(h)}=\rho^{(h+n)}\), et ensuite que les représentations \( \rho^{(h)}\) et \( \rho^{(-h)}\) sont équivalentes. Un opérateur d'entrelacement est donné par \( T=\begin{pmatrix}
    0    &   1    \\
    1    &   0
\end{pmatrix}\), et il est facile de vérifier que \( T\rho^{(h)}(x)=\rho^{-h}(x)T\) avec \( x=r^k\) puis avec \( x=sr^k\).

Donc \( \rho^{(h)}\simeq\rho^{(-h)}\simeq\rho^{(n-h)}\) et nous pouvons restreindre notre étude à \( 0\leq h\leq \frac{ n }{2}\).

Nous allons séparer les cas \( n=0\), \( h=n/2\) et les autres. En effet si nous notons par commodité \( a=\omega^h\), alors un vecteur \( (x,y)\) est vecteur propre de \( \rho^{(h)}(s)\) et de \( \rho^{(h)}(r)\) si et seulement s'il vérifie les systèmes d'équations
\begin{subequations}        \label{SubEqsGXZoxLq}
    \begin{numcases}{}
        ax=\lambda x\\
        \frac{1}{ a }y=\lambda y
    \end{numcases}
\end{subequations}
et
\begin{subequations}    \label{SubEqsFYZmzhT}
    \begin{numcases}{}
        \frac{1}{ a }y=\mu x\\
        ax=\mu y
    \end{numcases}
\end{subequations}
avec \( \lambda\) et \( \mu\) des nombres non nuls. Une représentation sera réductible si et seulement si ces deux systèmes acceptent une solution non nulle commune. Il est vite vu que si \( x\neq 0\) et \( y\neq 0\), alors \( a^2=1\), ce qui signifie \( h=0\) ou \( h=n/2\). Sinon, il n'y a pas de solutions, et la représentation associée est irréductible.

\begin{enumerate}
    \item
        \( h=0\). Nous avons
        \begin{equation}
            \begin{aligned}[]
                \rho^{(0)}(r^k)&=\begin{pmatrix}
                    1    &   0    \\
                    0    &   1
                \end{pmatrix}& \rho^{(0)}(sr^k)=\begin{pmatrix}
                    0    &   1    \\
                    1    &   0
                \end{pmatrix},
            \end{aligned}
        \end{equation}
        donc le caractère de cette représentation est \( \chi^{(0)}(r^k)=2\) et \( \chi^{(0)}(sr^k)=0\). Donc nous avons
        \begin{equation}
            \chi^{(0)}=\chi^{++}+\chi^{-+}.
        \end{equation}
        Il y a maintenant (au moins) quatre façons de voir que la représentation \( \rho^{(0)}\) est réductible.
        \begin{description}

            \item[Première méthode]
                Trouver un opérateur d'entrelacement. Pour cela nous calculons les matrices :
        \begin{subequations}
            \begin{align}
                S(r)&=(\rho^{++}\oplus \rho^{-+})(r^k)=\begin{pmatrix}
                    \rho^{++}(r^k)    &   0    \\
                    0  &   \rho^{-+}(r^k)
                \end{pmatrix}=\begin{pmatrix}
                    1    &   0    \\
                    0    &   1
                \end{pmatrix}\\
                S(sr^k)&=(\rho^{++}\oplus \rho^{-+})(sr^k)=\begin{pmatrix}
                    \rho^{++}(sr^k)    &   0    \\
                    0  &   \rho^{-+}(sr^k)
                \end{pmatrix}=\begin{pmatrix}
                    1    &   0    \\
                    0    &   -1
                \end{pmatrix}\\
            \end{align}
        \end{subequations}
        Nous cherchons une matrice \( T\) telle que \( TS(r^k)=\rho^{(0)}(r^k)T\) et \( TS(sr^k)=\rho^{(0)}(sr^k)T\). Étant donné que \( S(r^k)=\mtu=\rho^{(0)}(r^k)\), la première contrainte n'en est pas une. Nous pouvons vérifier qu'avec \( T=\begin{pmatrix}
            1    &   1    \\
            1    &   -1
        \end{pmatrix}\), nous avons bien
        \begin{equation}
            T\begin{pmatrix}
                1    &   0    \\
                0    &   -1
            \end{pmatrix}=\begin{pmatrix}
                0    &   1    \\
                1    &   0
            \end{pmatrix}.
        \end{equation}
        Donc ce \( T\) entrelace \( \rho^{++}\oplus \rho^{-+}\) avec \( \rho^{(0)}\) qui sont donc deux représentations équivalentes. Donc \( \rho^{(0)}\) est réductible et ça ne nous intéresse pas de la lister.
            \item[Seconde méthode]
                Invoquer le théorème \ref{ThoWGkfADd}\ref{ItemZReOWoHi} et dire que les représentations sont équivalentes parce que les caractères sont égaux.

    \item[Troisième méthode]
        Utiliser le théorème~\ref{ThoWGkfADd}\ref{ItemZReOWoHii} et calculer \( \langle \chi^{(0)}, \chi^{(0)}\rangle \) :
        \begin{subequations}
            \begin{align}
                \langle \chi^{(0)}, \chi^{(0)}\rangle &=\frac{1}{ | D_n | }\sum_{g\in D_n}| \chi^{(0)}(g) |^2\\
                &=\frac{1}{ 2n }\big(4+0+4(n-1)\big)\\
                &=2.
            \end{align}
        \end{subequations}
        Ici le \( 4\) est pour le \( 1\), le zéro est pour les termes \( sr^k\) et \( 4(n-1)\) est pour les \( n-1\) termes \( r^k\). Vu que le résultat n'est pas \( 1\), la représentation \( \rho^{(0)}\) n'est pas irréductible.

    \item[Quatrième méthode]
        Regarder les solutions des systèmes \eqref{SubEqsGXZoxLq} et \eqref{SubEqsFYZmzhT} dont nous avons parlé plus haut.

    \end{description}

    La première méthode a l'avantage d'être simple et ne demander aucune théorie particulière à part les définitions. La seconde méthode est la plus rapide, mais demande un théorème très puissant. La troisième utilise également un théorème assez avancé, mais a l'avantage sur les deux autres méthodes de ne pas avoir besoin de savoir à priori un candidat décomposition de \( \rho^{0)}\); cette méthode est applicable même sans faire la remarque que \( \chi^{(0)}=\chi^{++}+\chi^{-+}\).

    Quoi qu'il en soit, nous ne listons pas \( \chi^{(0)}\) dans notre \href{http://fr.wikipedia.org/wiki/Aide:Unicode}{table de caractères}.

    \item
        \( h=n/2\). Vu que \( \omega^{n/2}= e^{i\pi}=-1\), nous avons
        \begin{equation}
            \begin{aligned}[]
                \rho^{(n/2)}(r^k)&=\begin{pmatrix}
                    (-1)^k    &   0    \\
                    0    &   (-1)^k
                \end{pmatrix}&
                \rho^{(n/2)}(sr^k)&=\begin{pmatrix}
                    0   &   (-1)^k    \\
                    (-1)^k    &  0
                \end{pmatrix}&
            \end{aligned},
        \end{equation}
        et donc
        \begin{subequations}
            \begin{align}
                \chi^{(n/2)}(r^k)&=2(-1)^k\\
                \chi^{(n/2)}(sr^k)&=0.
            \end{align}
        \end{subequations}
        Il est vite vu que \( \chi^{(n/2)}=\chi^{+-}+\chi^{-+}\). Ergo la représentation \( \rho^{(n/2)}\) n'est pas irréductible.

    \item
        \( 0<h<\frac{ n }{2}\). Dans ce cas nous avons \( \omega^h\neq \omega^{-h}\), et en regardant les systèmes d'équations donnés plus haut, nous voyons que \( \rho^{(h)}(s)\) et \( \rho^{(h)}(r)\) n'ont pas de vecteurs propres communs. Donc ces représentations sont irréductibles.

        Nous devons cependant encore vérifier si elles sont deux à deux non équivalentes. Supposons que pour \( h\neq h'\) nous ayons une matrice \( T\in \GL(2,\eC)\) telle que \( T\rho^{(h)}(r)T^{-1}=\rho^{(h')}(r)\). Cela impliquerait en particulier que les matrices \( \rho^{(h)}(r)\) et \( \rho^{(h')}(r)\) aient même valeurs propres. Nous aurions donc \( \{ \omega^h,\omega^{-h} \}=\{ \omega^{h'},\omega^{-h'} \}\). Mais cela est impossible avec \( 0<h<h'<\frac{ n }{2}\). Donc toutes ces représentations sont distinctes.

\end{enumerate}

Le caractère de la représentation \( \rho^{(h)}\) est \( \chi^{(h)}(r^k)=\omega^{hk}+\omega^{-hk}=2\cos\left( \frac{ 2\pi hk }{ n } \right)\).

Nous ajoutons donc la ligne suivante à notre liste :
\begin{equation*}
    \begin{array}[]{|c||c|c|}
        \hline
        &r^k&sr^k\\
        \hline\hline
        \chi^{(h)}&2\cos\left( \frac{ 2\pi hk }{ n } \right)&0\\
        \hline
    \end{array}
\end{equation*}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Le compte pour \texorpdfstring{$ n$}{n} pair}
%---------------------------------------------------------------------------------------------------------------------------

Nous avons \( 4\) représentations de dimension \( 1\) puis \( \frac{ n }{2}-1\) représentations de dimension \( 2\). En tout nous avons
\begin{equation}
 \frac{ n }{2}+3
\end{equation}
représentations irréductibles modulo équivalence. Cela fait le compte en vertu des classes de conjugaisons listées en~\ref{SubsubsecROVmHuM}. Pour rappel, le nombre de représentations non équivalentes est égal au nombre de classes de conjugaison par le corolaire~\ref{CorbdcVNC}. Notons que c'est cela qui justifie le fait que nous ne devons pas chercher d'autres représentations. Nous sommes sûrs de les avoir toutes trouvées.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Le compte pour \texorpdfstring{$ n$}{n} impair}
%---------------------------------------------------------------------------------------------------------------------------

Nous avions fait mention plus haut du fait que si \( \psi\) est une représentation de dimension \( 1\), le nombre \( \psi(r)\) devait être une racine \( n\)\ieme\ de l'unité. Donc en dimension \( 1\) nous avons seulement les représentations \( \rho^{++}\) et \( \rho^{-+}\). Pour celles de dimension \( 2\), nous en avons \( \frac{ n-1 }{2}\). En tout nous avons donc
\begin{equation}
    \frac{ n+3 }{2}
\end{equation}
représentations irréductibles modulo équivalence. Cela fait le compte en vertu des classes de conjugaisons listées en~\ref{GJIzDEP}.
