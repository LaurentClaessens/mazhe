% This is part of Mes notes de mathématique
% Copyright (c) 2011-2018
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.

Nous commençons par donner quelques éléments à propos de dérivée et de différentielle pour des fonctions \( \eC\to \eC\) parce que les séries entières vont souvent être des fonctions complexes. Le gros du chapitre sur les fonctions holomorphes est le chapitre \ref{ChapICHIooXbLccl}.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Différentielle et dérivée complexe}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\label{SECooJWNOooOgMiWR}

Nous identifions \( \eR^2\) à \( \eC\) par l'application
\begin{equation}
    \begin{aligned}
        \varphi\colon \eR^2&\to \eC \\
        (x,y)&\mapsto x+iy. 
    \end{aligned}
\end{equation}
Dans cette partie, nous désignons par \( \Omega\) un ouvert de \( \eC\). 

\begin{definition}      \label{DEFooVJVXooKlnFkh}
    Une fonction \( f\colon \Omega\to \eC\) est \defe{$\eC$-dérivable}{dérivable!au sens complexe} si la limite
    \begin{equation}
        \lim_{\substack{h\to0\\h\in \eC}} \frac{ f(a+h)-f(a) }{ h }
    \end{equation}
    existe. Dans ce cas, cette limite est la dérivée de \( f\) et est notée \( f'\).
\end{definition}

\begin{definition}  \label{DefMMpjJZ}
    Soit \( \Omega\) un ouvert dans \( \eC\). Une fonction \( f\colon \Omega\to \eC\) est \defe{holomorphe}{holomorphe}\index{fonction!holomorphe} si elle est \( \eC\)-dérivable sur \( \Omega\). 
\end{definition}

\begin{definition}
    Une matrice de la forme
    \begin{equation}
        \begin{pmatrix}
            \alpha    &   \beta    \\ 
            -\beta    &   \alpha    
        \end{pmatrix}
    \end{equation}
    avec \( \alpha,\beta\in \eR\) est une \defe{similitude}{matrice!de similitude}\index{similitude}.
\end{definition}

\begin{lemma}       \label{LEMooJNFEooZCbJMo}
    En tant qu'application linéaire \( \eC\to \eC\), l'opération de multiplication par \( \alpha+\beta i\) est la matrice
    \begin{equation}
        \begin{pmatrix}
            \alpha    &   -\beta    \\ 
            \beta    &   \alpha    
        \end{pmatrix}.
    \end{equation}
\end{lemma}

\begin{proof}
    Cela est vite remarqué en calculant explicitement \( (\alpha+\beta i)(u_1+iu_2)\).
\end{proof}

\begin{lemma}
    Une application \( A\colon \eC\to \eC\) est \( \eC\)-linéaire si et seulement si elle est une similitude en tant qu'application \( \eR^2\to \eR^2\).

    Dans ce cas, il existe \( z_0\in \eC\) tel que \( A(z)=z_0z\) pour tout \( z\in \eC\).
\end{lemma}

\begin{proof}
    Commençons par considérer l'application \( A\) sur \( \eR^2\). Elle est en particulier une application \( \eR\)-linéaire et par conséquent il existe une matrice \( \begin{pmatrix}
        \alpha    &   \beta    \\ 
        \gamma    &   \delta    
    \end{pmatrix}\) telle que 
    \begin{equation}
        A\begin{pmatrix}
            x    \\ 
            y    
        \end{pmatrix}=\begin{pmatrix}
            \alpha    &   \beta    \\ 
            \gamma    &   \delta    
        \end{pmatrix}\begin{pmatrix}
            x    \\ 
            y    
        \end{pmatrix}.
    \end{equation}
    Nous voulons maintenant imposer la \( \eC\)-linéarité, c'est à dire que nous voulons 
    \begin{equation}
        A\big( (a+bi)(x+iy) \big)=(a+bi)A(x+iy)
    \end{equation}
    pour tout \( a,b,x,y\in \eR\). À gauche nous avons
    \begin{equation}
        A\big( ax-by+i(bx+ay) \big)
    \end{equation}
    et à droite nous avons
    \begin{equation}
        (a+bi)\big( \alpha x+\beta y+i(\gamma x+\delta y) \big).
    \end{equation}
    En égalant les deux expressions nous obtenons les équations
    \begin{subequations}
        \begin{numcases}{}
            \beta b=-b\gamma\\
            -\alpha b+\beta a =a\beta -b\delta\\
            \delta b=b\alpha\\
            -\gamma b+\delta a=b\beta+a\delta,
        \end{numcases}
    \end{subequations}
    dont nous tirons immédiatement que \( \gamma=-b\beta\) et \( \delta=\alpha\). La matrice de \( A\) est donc de la forme demandée.

    Inversement nous devons prouver que la fonction 
    \begin{equation}        \label{EqOEWYooMaHCNb}
        f(x+iy)=\alpha x+\beta y+i(-\beta x+\alpha y)
    \end{equation}
    est \( \eC\)-linéaire, c'est à dire qu'elle vérifie \( f(z_0z)=z_0f(z)\) pour tout \( z_0,z\in \eC\). Cela est un simple calcul que nous confions à Sage : le code suivant affiche «\( 0\)».
    \lstinputlisting{tex/frido/code_sage3.py}

    Pour conclure, notons que la fonction \eqref{EqOEWYooMaHCNb} est la fonction de multiplication par \( \alpha-i\beta\).
\end{proof}

\begin{normaltext}      \label{NORMooMKNDooBeoGRN}
    Soient une fonction \( f\colon \eC\to \eC\) et l'isomorphisme canonique \( \varphi\colon \eC\to \eR^2\). La fonction \( f\) définit une la fonction
    \begin{equation}
        F=\varphi^{-1} \circ f\circ \varphi\colon \eR^2\to \eR^2.
    \end{equation}
    Cela est la fonction \( \eR^2\to \eR^2\) associée à \( f\). Il serait tentant de croire que tout ce qui est vrai pour \( F\) est également vrai pour \( f\). Eh bien non.

    Par exemple, \( F\) peut être différentiable sans que \( f\) le soit. La proposition suivant donne une condition sur \( dF\) pour que \( f\) soit différentiable.
\end{normaltext}

\begin{proposition}     \label{PropKJUDooJfqgYS}
    Une fonction \( f\colon \Omega\to \eC\) est $\eC$-dérivable en \( a\in\Omega\) si et seulement si elle est différentiable en \( a\) et si \( df_a\) est une similitude.

    Plus précisément avec les notations de \ref{NORMooMKNDooBeoGRN}, la fonction \( f\) est $\eC$-dérivable (donc holomorphe) au point \( z_0=x_0+iy_0\) si et seulement si la fonction \( F\) est différentiable en \( (x_0,y_0)\) et si la matrice de \( dF\) est de la forme
    \begin{equation}        \label{EQooWZGKooLDEHGr}
        dF=\begin{pmatrix}
            \alpha    &   \beta    \\ 
            -\beta    &   \alpha    
        \end{pmatrix},
    \end{equation}
    c'est à dire si \( dF_{(x_0,y_0)}\) fournit une application \( \eC\)-linéaire.

    Dans ce cas, le lien entre \( \eC\)-dérivée et différentielle est donné par
    \begin{equation}        \label{EqPAEFooYNhYpz}
        (df_{z_0})(z)=f'(z_0)z.
    \end{equation}
\end{proposition}

\begin{proof}
    Nous décomposons \( f\) en parties réelles et imaginaires :
    \begin{equation}
        f(x+iy)=P(x,y)+iQ(x,y)
    \end{equation}
    où \( P\) et \( Q\) sont des fonctions réelles. La jacobienne de \( F\) est la matrice
    \begin{equation}
        \begin{pmatrix}
            \frac{ \partial P }{ \partial x }    &   \frac{ \partial P }{ \partial y }    \\ 
            \frac{ \partial Q }{ \partial x }    &   \frac{ \partial Q }{ \partial y }    
        \end{pmatrix},
    \end{equation}
    et la condition dont nous parlons s'écrit comme le système
    \begin{subequations}    \label{EqFDUrXBP}
        \begin{numcases}{}
            \frac{ \partial P }{ \partial x }=\frac{ \partial Q }{ \partial y }\\
            \frac{ \partial P }{ \partial y }=-\frac{ \partial Q }{ \partial x}.
        \end{numcases}
    \end{subequations}
    Si \( F\) est différentiable en \( (x_0,y_0)\) alors nous avons
    \begin{equation}        \label{EqwlVfiR}
        F\big( (x_0,y_0)+(h,k) \big)=F(x_0,y_0)+dF_{(x_0,y_0)}\begin{pmatrix}
            h    \\ 
            k    
        \end{pmatrix}+s(| h |+| k |)
    \end{equation}
    où \( s\) est une fonction vérifiant \( \lim_{t\to 0} \frac{ s(t) }{ t }=0\). Soit
    \begin{equation}
        dF_{(x_0,y_0)}=\begin{pmatrix}
            \alpha    &   \beta    \\ 
            -\beta    &   \alpha    
        \end{pmatrix}.
    \end{equation}
    Si nous posons \( \sigma=\alpha-i\beta\) et \( w=h+ik\), l'équation \eqref{EqwlVfiR} s'écrit dans \( \eC\) sous la forme
    \begin{equation}        \label{EqYFmoiM}
        f(z_0+w)=f(z_0)+\sigma w+s(|w|),
    \end{equation}
    ce qui implique que \( f\) est $\eC$-dérivable en \( z_0\).

    Supposons maintenant que \( f\) soit $\eC$-dérivable en \( z_0\). Alors nous avons
    \begin{equation}
        f'(z_0)=\lim_{w\to 0} \frac{ f(z_0+w)-f(z_0) }{ w }=\sigma\in \eC,
    \end{equation}
    ce qui se récrit sous la forme
    \begin{equation}
        \lim_{w\to 0} \frac{ f(z_0+w)-f(z_0)-\sigma w }{ w }=0.
    \end{equation}
    Si nous posons \( z_0=x_0+iy_0\), \( w=h+ik\) et \( \sigma=\alpha-i\beta\) nous avons
    \begin{equation}
        \lim_{(h,k)\to (0,0)} \left| \frac{ F\big( (x_0,y_0)+(h,k) \big)-F(x_0,y_0)-\begin{pmatrix}
            \alpha    &   \beta    \\ 
            -\beta    &   \alpha    
        \end{pmatrix}\begin{pmatrix}
            h    \\ 
            k    
        \end{pmatrix}}{ | w | } \right| =0,
    \end{equation}
    ce qui signifie que \( F\) est différentiable et que sa différentielle est la matrice
    \begin{equation}    \label{EqMLtbLD}
       \begin{pmatrix}
           \alpha &   \beta    \\ 
           -\beta &   \alpha    
       \end{pmatrix}.
    \end{equation}

    La matrice \eqref{EqMLtbLD} est, vue dans \( \eR^2\), la matrice de multiplication dans \( \eC\) par \( \alpha-i\beta=f'(z_0)\). En d'autre termes, dans \( \eC\) nous avons
    \begin{equation}
        df_{z_0}(z)=f'(z_0)z,
    \end{equation}
    et en particulier la différentielle est donnée par
    \begin{equation}        \label{EqPropZOkfmO}
        df_{z_0}=f'(z_0)dz.
    \end{equation}
\end{proof}

\begin{example}[Une application \( C^{\infty}\) mais pas \( \eC\)-dérivable]
    Nous considérons la fonction
    \begin{equation}
        \begin{aligned}
            f\colon \eC&\to \eC \\
            x+iy&\mapsto x. 
        \end{aligned}
    \end{equation}
    Vu que c'est une application linéaire, elle est différentiable une infinité de fois et sa différentielle est elle-même. C'est donc une application \( C^{\infty}\).

    Elle n'est cependant pas \( \eC\)-dérivable. En effet le quotient différentiel est, pour \( \epsilon\in \eC\) :
    \begin{equation}
        \frac{ f(x+iy+\epsilon_x+i\epsilon_y)-f(x+iy) }{ \epsilon }=\frac{ \epsilon_x }{ \epsilon }.
    \end{equation}
    Cela n'a pas de limite lorsque \( \epsilon\to 0\). Pour voir cela nous invoquons la méthode des chemins du corollaire \ref{CorMethodeChemin} avec les chemins \( \epsilon_1(t)=t\) et \( \epsilon_2(t)=it\). Dans le premier cas, le quotient différentiel vaut \( 1\) pour tout \( t\), tandis que dans le second il vaut zéro pour tout \( t\).
\end{example}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Quelque règles de calcul}
%---------------------------------------------------------------------------------------------------------------------------

\begin{lemma}       \label{LEMooVDXOooUyFHXZ}
    Si \( f\) et \( g\) sont deux fonctions holomorphes sur un ouvert \( \Omega\subset \eC\) et si \( g\) ne s'annule pas sur \( \Omega\), alors \( f/g\) est holomorphe sur \( \Omega\).
\end{lemma}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Série de fonctions}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Les séries de fonctions sont des cas particuliers de suites, étant donné que, par définition,
\begin{equation}
    \sum_{n=1}^{\infty}f_n=\lim_{N\to \infty} \sum_{n=1}^{N}f_n.
\end{equation}

Il est bon de se rappeler des convergences absolues (définition \ref{DefVFUIXwU}) et uniforme (équation \ref{EqLNCJooVCTiIw}).

\begin{lemma}
    Soient des fonctions \( u_n\colon \Omega\to \eC\). Si il existe une suite réelle positive \( (a_n)_{n\in \eN}\) telle que
    \begin{enumerate}
        \item
            pour tout \( z\in \Omega\) et pour tout \( n\in \eN\) nous avons \( | u_n(z) |\leq a_n\) (c'est à dire \( a_n\geq \| u_n \|_{\infty}\)),
        \item
            la somme \( \sum_{n}a_n\) converge,
    \end{enumerate}
    alors la série de fonctions \( \sum_{n=0}^{\infty}u_n\) converge normalement\footnote{Définition \ref{DefVBrJUxo}.}.
\end{lemma}

\begin{proof}
    Découle du lemme de comparaison \ref{LemgHWyfG}.
\end{proof}

\begin{theorem}				\label{ThoSerCritAbel}
	Soit $\sum_{k=1}^{\infty}g_k(x)$, une série de fonctions complexes où $g_k(x)=\varphi_k(x)\psi_k(x)$. Supposons que
	\begin{enumerate}

		\item
			$\varphi_k\colon A\to \eC$ et $| \sum_{k=1}^K\varphi_k(x) |\leq M$ où $M$ est indépendant de $x$ et $K$,
		\item
			$\psi_k\colon A\to \eR$ avec $\psi_k(x)\geq 0$ et pour tout $x$ dans $A$, $\psi_{k+1}(x)\leq \psi_k(x)$, et enfin supposons que $\psi_k(x)$ converge uniformément vers $0$.

	\end{enumerate}
	Alors $\sum_{k=1}^{\infty}g_k$ est uniformément convergente.
\end{theorem}

\begin{theorem}		\label{ThoAbelSeriePuiss}
	Si la série de puissances (réelle) converge en $x=x_0+R$, alors elle converge uniformément sur $\mathopen[ x_0-R+\epsilon , x_0+R \mathclose]$ ($\epsilon>0$) vers une fonction continue.
\end{theorem}


\begin{proposition}     \label{PropUEMoNF}
    Soit \( (u_n)\) une suite de fonctions continues \( u_n\colon \Omega\subset\eC\to \eC\). Si la série \( \sum_nu_n\) converge normalement alors la somme est continue.
\end{proposition}

\begin{proof}
    Nous posons \( u(z)=\lim_{N\to \infty} \sum_{n=0}^N u_n(z)\), et nous vérifions que la fonction ainsi définie sur \( \Omega\) est continue. Soit \( z\in \Omega\). Prouvons la continuité de \( u\) au point \( z\). Pour tout \( z'\) dans un voisinage de \( z\) nous avons 
    \begin{subequations}
        \begin{align}
            \big| u(z)-u(z') \big|&=\left| \sum_{n=0}^{N}u_n(z)-\sum_{n=0}^{N}u_n(z')+\sum_{n=N+1}^{\infty}u_n(z)-\sum_{n=N+1}^{\infty}u_n(z') \right| \\
            &\leq \left| \sum_{n=0}^N u_n(z)-\sum_{n=0}^Nu_n(z') \right| +\sum_{n=N+1}^{\infty}| u_n(z) |+\sum_{n=N+1}^{\infty}| u_n(z') |.
        \end{align}
    \end{subequations}
    Étant donné que les sommes partielles sont continues, en prenant \( N\) suffisamment grand, le premier terme peut être rendu arbitrairement petit. Si \( N\) est suffisamment grand, le second terme est également petit. Par contre, cet argument ne tient pas pour le troisième terme parce que nous souhaitons une majoration pour tout \( z'\) dans une boule autour de \( z\). Nous devons donc écrire
    \begin{equation}
        \sum_{n=N}^{\infty}| u_n(z) |\leq \sum_{n=N+1}^{\infty}\| u_n \|_{\infty}.
    \end{equation}
    Ce dernier est arbitrairement petit lorsque \( N\) est grand. Notons que nous avons utilisé l'hypothèse de convergence normale.
\end{proof}

La même propriété, avec la même démonstration, tient dans le cas d'espaces vectoriels normée.
\begin{proposition} \label{PropOMBbwst}
    Soient \( E\) et \( F\), deux espaces vectoriels normés, \( \Omega\) une partie ouverte de \( E\) et une suite de fonctions \( u_n\colon \Omega\to F\) convergeant normalement sur \( \Omega\), c'est à dire que \( \sum_n\| u_n \|_{\infty}\) converge, la norme \( \| . \|_{\infty} \) devant être comprise comme la norme supremum sur \( \Omega\). Alors la fonction \( u=\sum_nu_n\) est continue sur \( \Omega\).
\end{proposition}

\begin{proof}
    Soit \( x,x'\in \Omega\) en supposant que \( \| x-x' \|\) est petit. Soit encore \( \epsilon>0\). Nous allons montrer la continuité en \( x\). Pour cela nous savons que pour tout \( N\) l'inégalité suivante est correcte :
    \begin{equation}
        \| u(x)-u(x') \|\leq \left\|  \sum_{n=0}^Nu_n(x)-\sum_{n=0}^{N}u_n(x') \right\|+\sum_{n=N+1}^{\infty}\| u_n(x) \|+\sum_{n=N+1}^{\infty}\| u_n(x') \|.
    \end{equation}
    Les deux derniers termes sont majorés par \( \sum_{n=N+1}^{\infty}\| u_n \|_{\infty}\) qui, par hypothèse, peut être rendu aussi petit que souhaité en choisissant \( N\) assez grand. Nous choisissons donc un \( N\) tel que ces deux termes soient plus petits que \( \epsilon\). Ce \( N\) étant fixé, la fonction \( \sum_{n=0}^{N}u_n\) est continue et nous pouvons choisir \( x'\) assez proche de \( x\) pour que le premier terme soit majoré par \( \epsilon\).
\end{proof}

\begin{theorem}			\label{ThoSerUnifCont}
	Si les $g_k$ sont continues et si $\sum g_k$ converge uniformément, alors $\sum g_k$ est continue.
\end{theorem}

Le corollaire suivant permet de considérer des séries de fonctions indexées par exemple par \( \eZ\) plutôt que par \( \eN\).
\begin{corollary}
    Une famille dénombrable de fonctions continues convergeant normalement converge vers une fonction continue.
\end{corollary}

\begin{proof}
    Soit \( I\) dénombrable. Considérons une famille de fonctions continues \( (f_n)_{n\in I}\) telles que la famille \( (\| f_i \|_{\infty})_{i\in I}\) soit sommable. Le proposition \ref{PropoWHdjw} nous permet d'utiliser une bijection entre \( I\) et \( \eN\). Le théorème \ref{PropUEMoNF} s'applique alors.
\end{proof}

\begin{theorem}[Critère de Weierstrass]\index{critère!Weierstrass!série de fonctions}		\label{ThoCritWeierstrass}
	Soit une suite de fonctions $f_k\colon A\to \eC$ telles que $| f_k(x) |\leq M_k\in\eR$, $\forall x\in A$. Si $\sum_{k=1}^{\infty}M_k$ converge, alors $\sum_{k=1}^{\infty}f_k$ converge absolument et uniformément.
\end{theorem}

\begin{proof}
    La convergence normale est facile : l'hypothèse dit que \( \| f_k \|_{\infty}\leq M_k\), et donc que
    \begin{equation}
        \sum_{k=1}^{\infty}\| f_k \|_{\infty}\leq \sum_kM_k<\infty.
    \end{equation}
    
    La convergence uniforme est à peine plus subtile. Nous nommons \( F\) la fonction somme. Pour tout \( x\) et pour tout \( N\), nous avons
    \begin{subequations}
        \begin{align}
            \left\| \sum_{n=1}^Nf_n(x)-F(x) \right\|&=\| \sum_{n=N}^{\infty}f_n(x) \|\\
            &\leq\sum_{n=N}^{\infty}\| f_k(x) \|\\
            &\leq \sum_{n=N}^{\infty}\| f_n \|_{\infty}.
        \end{align}
    \end{subequations}
    La convergence normale étant assurée, la série \( \sum_{n_1}^{\infty}\| f_n \|_{\infty}\) est finie, ce qui implique que la queue de somme \( \sum_{n=N}^{\infty}\| f_n \|_{\infty}\) tend vers zéro lorsque \( N\to \infty\). Pour tout \( \epsilon\), il existe donc un \( N\) (non dépendant de \( x\)) tel que
    \begin{equation}
        \| \sum_{n=1}^Nf_n(x)-F(x) \|\leq \epsilon.
    \end{equation}
    En prenant le supremum sur \( x\in A\) nous trouvons la convergence uniforme.
\end{proof}

\begin{remark}
    Il n'y a pas de critère correspondant pour les suites. Il n'est pas vrai que si \( \lim_{n\to \infty}\| f_n \| \) existe, alors \( \lim_{n\to \infty} f_n\) existe, comme le montre l'exemple
    \begin{equation}
        f_n(x)=\begin{cases}
            1    &   \text{si } x\in\mathopen[ 0 , 1 \mathclose]\text{ et } n\text{ est pair}\\
            1    &    \text{si } x\in\mathopen[ 1 , 2 \mathclose]\text{ et } n\text{ est impair}\\
             0   &    \text{sinon.}
        \end{cases}
    \end{equation}
\end{remark}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Intégration de séries de fonctions}
%---------------------------------------------------------------------------------------------------------------------------

\begin{theorem}      \label{ThoCciOlZ}
    La somme uniforme de fonctions intégrables sur un ensemble de mesure fini est intégrable et on peut permuter la somme et l'intégrale.

    En d'autres termes, supposons que \( \sum_{n=0}^{\infty}f_n\) converge uniformément vers \( F\) sur \( A\) avec \( \mu(A)<\infty\). Si \( F\) et \( f_n\) sont des fonctions intégrables sur \( A\) alors
    \begin{equation}
        \int_AF(x)d\mu(x)=\sum_{n=0}^{\infty}\int_Af_n(x)d\mu(x).
    \end{equation}
\end{theorem}
\index{permuter!somme et intégrale}

\begin{proof}
    Ce théorème est une conséquence du théorème \ref{ThoUnifCvIntRiem}. En effet nous définissons la suite des sommes partielles
    \begin{equation}
        F_N=\sum_{n=0}^Nf_n.
    \end{equation}
    La limite \( \lim_{N\to \infty} F_N=F\) est uniforme. Par conséquent la fonction \( F\) est intégrable et
    \begin{equation}
        \int_A F=\lim_{N\to \infty} \int_AF_N=\lim_{N\to \infty} \int_A\sum_{n=0}^Nf_n=\lim_{N\to \infty} \sum_{n=0}^N\int_Af_n=\sum_{n=0}^{\infty}\int_Af_n.
    \end{equation}
    La première égalité est le théorème \ref{ThoUnifCvIntRiem}, les autres sont de simples manipulations rhétoriques.
\end{proof}

Le théorème suivant est une paraphrase du théorème de la convergence dominée de Lebesgue (\ref{ThoConvDomLebVdhsTf}).
\begin{theorem}     \label{ThoockMHn}
    Soient des fonctions \( (f_n)_{n\in \eN}\) telles que \( \sum_{n=0}^Nf_n\) soit intégrable sur \( (\Omega,\tribA,\mu)\) pour chaque \( N\). Nous supposons que la somme converge simplement vers
    \begin{equation}
        f(x)=\sum_{n=0}^{\infty}f_n(x)
    \end{equation}
    et qu'il existe une fonction \( g\) telle que
    \begin{equation}
        \left| \sum_{n=0}^Nf_n \right| <g
    \end{equation}
    pour tout \( N\in \eN\). Alors
    \begin{enumerate}
        \item
            \( \sum_{n=0}^{\infty}f_n\) est intégrable,
        \item
            on peut permuter somme et intégrale :
            \begin{equation}
                \lim_{N\to \infty} \int_{\Omega}\sum_{n=0}^Nf_nd\mu=\int_{\Omega}\sum_{n=0}^{\infty}f_n,
            \end{equation}
        \item
            \begin{equation}
                \lim_{N\to \infty} \int_{\Omega}\left| \sum_{n=0}^Nf_n-\sum_{n=0}^{\infty}f_n \right| =\lim_{N\to \infty} \int_{\Omega}\left| \sum_{n=N}^{\infty}f_n \right| =0.
            \end{equation}
    \end{enumerate}
\end{theorem}


\begin{theorem} \label{ThoCSGaPY}
    Soit \( f_n\) des fonctions \( C^1\mathopen[ a , b \mathclose]\) telles que
    \begin{enumerate}
        \item
            la série \( \sum_n f_n(x_0)\) converge pour un certain \( x_0\in\mathopen[ a , b \mathclose]\),
        \item
            la série des dérivées \( \sum_n f'_n\) converge uniformément sur \( \mathopen[ a , b \mathclose]\).
    \end{enumerate}
    Alors la série \( \sum_n f_n\) converge vers une fonction \( F\) et
    \begin{enumerate}
        \item
            La convergence est uniforme sur \( \mathopen[ a , b \mathclose]\).
        \item
            La fonction \( F\) est dérivable
        \item
            \( F'(x)=\sum_nf'_n(x)\).
    \end{enumerate}
\end{theorem}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Différentiabilité}
%---------------------------------------------------------------------------------------------------------------------------

\begin{lemma}
    Soient \( E\) et \( F\) deux espaces vectoriels normés. Si la suite \( (T_n)\) converge vers \( T\) dans \( \aL(E,F)\), alors pour tout \( v\in E\) nous avons
    \begin{equation}
        \left( \sum_{n=0}^{\infty}T_n \right)(v)=\sum_{n=0}^{\infty}T_n(v).
    \end{equation}
\end{lemma}

\begin{theorem}[\cite{DHdwZRZ,DHdwZRZ}] \label{ThoLDpRmXQ}
    Soient \( E\) et \( F\) deux espaces vectoriels normés, \( \Omega\) un ouvert connexe par arcs de \( E\). Soit \( (u_n)\) une suite de fonctions \( u_n\colon \Omega\to F\) telle que
    \begin{enumerate}
        \item
            pour tout \( n\), la fonction \( u_n\) est de classe \( C^1\) sur \( \Omega\),
        \item
            la série \( \sum_nu_n\) converge simplement sur \( \Omega\),
        \item
            la série des différentielles \( \sum_n(du_n)\) converge normalement sur tout compact de \( \Omega\).
    \end{enumerate}
    Alors la somme \( u=\sum_nu_n\) est de classe \( C^1\) sur \( \Omega\) et sa différentielle est donnée par
    \begin{equation}
        du=\sum_{n=0}^{\infty}du_n.
    \end{equation}
\end{theorem}

\begin{proof}
    Pour chaque \( n\), la fonction \( du_n\colon \Omega\to \aL(E,F)\) est une fonction continue parce que \( u_n\) est de classe \( C^1\). La série convergeant normalement, la fonction \( \sum_{n=0}^{\infty}du_n\) est également continue par la proposition \ref{PropOMBbwst}. La difficulté de ce théorème est donc de prouver que cela est bien la différentielle de la fonction \( \sum_nu_n\).

    Soient \( a,x\in \Omega\) et \( \gamma\colon \mathopen[ 0 , 1 \mathclose]\to \Omega\) un chemin joignant \( a\) à \( x\). Nous considérons ce chemin en coordonnées normales et nous notons \( l\) sa longueur. Par définition \eqref{EqEFIZyEe},
    \begin{equation}
        \clubsuit=\int_{\gamma}\sum_{n=0}^{\infty}du_n=\int_0^l\sum_n(du_n)_{\gamma(t)}\big( \gamma'(t) \big)dt
    \end{equation}
    Si nous notons \( f_n(t)=(du_n)_{\gamma(t)}\big( \gamma'(t) \big)\), sachant que la paramétrisation est normale (\( \| \gamma'(t) \|=1\)) nous avons\footnote{Histoire de ne pas s'embrouiller, il faut se rendre compte que \( \| du_n \|_{\infty}=\sup_{x\in \Omega}\| (du_n)_x \|\).}
    \begin{equation}
        \| f_n(t) \|\leq \|   (du_n)_{\gamma(t)}  \|\leq \| du_n \|_{\infty}.
    \end{equation}
    Or la série des \( \| du_n \|_{\infty}\) converge par hypothèse. L'intervalle \( \mathopen[ 0 , l \mathclose]\) étant compact, les fonctions \( f_n\) sont uniformément (en \( n\)) bornées par le nombre \( \sum_n\| du_n \|_{\infty}\) qui est intégrable sur \( \mathopen[ 0 , 1 \mathclose]\). Par la convergence dominée (théorème \ref{ThoConvDomLebVdhsTf}) nous permutons la somme et l'intégrale :
    \begin{equation}
        \clubsuit=\sum_{n=0}^{\infty}\int_0^l(du_n)_{\gamma(t)}\big( \gamma'(t) \big)dt=\sum_{n=0}^{\infty}\big( u_n(x)-u_n(a)\big)=u(x)-u(a)
    \end{equation}
    où nous avons utilisé le théorème \ref{ThoUJMhFwU}. Jusqu'à présent nous avons montré que
    \begin{equation}
        u(x)=u(a)+\int_{\gamma}\sum_{n=0}^{\infty}du_n=u(a)+\int_0^l\sum_{n=0}^{\infty}(du_n)_{\gamma(t)}\big( \gamma'(t) \big)dt.
    \end{equation}
    Nous allons utiliser cela pour calculer \( du_x(v)\) selon la bonne vieille formule
    \begin{equation}
        du_x(v)=\Dsdd{ u(x+sv) }{s}{0}.
    \end{equation}
    Cela sera fait en considérant à nouveau un chemin \( \gamma_s \) joignant \( a\) à \( x+sv\) en paramétrisation normale; nous notons \( l_s\) sa longueur. Dans le calcul suivant, nous inversons la somme et l'intégrale de la même façon qu'avant. En piste maestro
    \begin{subequations}
        \begin{align}
            du_x(v)&=\frac{ d  }{ d s }\left.\int_0^{l_s}\sum_{n=0}^{\infty}(du_n)_{\gamma_s(t)}\big( \gamma'_s(t) \big)dt\right|_{s=0}\\
            &=\frac{ d  }{ d s }\left.\sum_{n=0}^{\infty}\int_{\gamma_s}du_n\right|_{s=0}\\
            &=\frac{ d  }{ d s }\sum_{n=0}^{\infty}\Big[ u_n\big( \gamma_s(l_s)\big)-u_n\big( \gamma_s(0) \big)  \Big]_{s=0}\\
            &=d\left( \sum_{n=0}^{\infty}u_n \right)_x(v).
        \end{align}
    \end{subequations}
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Séries entières}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Dans cette section nous allons parler de séries complexes autant que de séries réelles. L'étude des propriétés à proprement parler complexes des séries entières (holomorphie) sera effectuée dans le chapitre dédié, voir le théorème \ref{ThomcPOdd} et ses conséquences.

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Disque de convergence}
%---------------------------------------------------------------------------------------------------------------------------

Une \defe{série de puissance}{série!de puissance} est une série de la forme
\begin{equation}		\label{eqseriepuissance}
	\sum_{k=0}^{\infty}c_k(z-z_0)^k
\end{equation}
où $z_0\in \eC$ est fixé, $(c_k)$ est une suite complexe fixée, et $z$ est un paramètre complexe. Nous disons que cette série est \emph{centrée} en $z_0$.

\begin{definition}
    Une \defe{série entière}{série!entière} est une somme de la forme
    \begin{equation}
        \sum_{n=0}^{\infty}a_nz^n
    \end{equation}
    avec \( a_n,z\in\eC\).    
\end{definition}
Une série entière peut définir une fonction
\begin{equation}
    f(z)=\sum_na_nz^n.
\end{equation}
Le but de cette section est d'étudier des conditions sur la suite \( (a_n)\) qui assurent la continuité de \( f\) ou la possibilité de dériver ou intégrer la série terme à terme.

\begin{definition}  \label{DefZWKOZOl}
    Soit \( \sum_{n\in \eN}a_nz^n\) une série entière. Le \defe{rayon de convergence}{rayon!de convergence} de cette série est le nombre
    \begin{equation}
        R=\sup\{ r\in \eR^+\tq \text{la suite }(a_nr^n)\text{ est bornée} \}\in\mathopen[ 0 , \infty \mathclose].
    \end{equation}
    La boule \( B(0,R)\) est le \defe{disque de convergence}{disque de convergence} de la série.
\end{definition}
Le rayon de convergence d'une série ne dépend que des réels \( | a_n |\), même si à la base \( a_n\in \eC\).

\begin{remark}      \label{REMooYOTEooKvxHSf}
    Si pour tout \( n\) nous avons \( | b_n |\geq | a_n |\) alors le rayon de convergence de la série \( \sum_na_nz^n\) est au moins aussi grand que celui de la série \( \sum_nb_nz^n\). Cela y compris lorsque l'un ou l'autre des rayons de convergences est infini.
\end{remark}

\begin{lemma}[Critère d'Abel]\index{critère!Abel}   \label{LemmbWnFI}
    Soit \( R>0\) le rayon de convergence de la somme \( \sum_na_nz^n\) et \( z\in \eC\).
    \begin{enumerate}
        \item
            Si \( | z |<R\) alors la série converge absolument.
        \item
            Si \( R<\infty\) et si \( | z |>R\) alors la série diverge.
    \end{enumerate}
\end{lemma}

\begin{proof}
    Démonstration en deux parties.
    \begin{enumerate}
        \item

            Si \( | z |<R\) alors la suite \( (a_nz^n)\) est bornée et il existe un nombre \( M\in \eR\) tel que \( | a_n |r^n\leq M\) pour tout \( n\). Nous considérons alors un \( r\) tel que \( | z |<r<R\) et nous pouvons calculer :
            \begin{equation}
                | a_nz^n |=| a_n |r^n\big( \frac{ | z | }{ r } \big)^n\leq M\left( \frac{ | z | }{ r } \right)^n
            \end{equation}
            Vu que \( | z |<r\) nous tombons sur la série géométrique \eqref{EqZQTGooIWEFxL} qui converge. Par le critère de comparaison\footnote{Lemme \ref{LemgHWyfG}.} la série \( \sum_{n=0}^{\infty}| a_nz^n |\) converge.

        \item
            Par définition du rayon de convergence, la suite \( (a_nz^n)\) n'est donc pas bornée et la série ne peut pas converger à cause de la proposition \ref{PROPooYDFUooTGnYQg}.
    \end{enumerate}
\end{proof}

Le critère d'Abel parle bien de convergence absolue, et non de convergence normale. Pour chaque \( t\), la série \( \sum_k | a_nt^k |\) converge. Si par contre nous posons \( u_k(t)=a_kt^k\), nous n'avons a priori pas la convergence normale \( \sum_k\| u_k \|_{\infty}\), même pas si la norme est la norme supremum sur \( B(0,R)\)\quext{Il y aurait par contre bien convergence sur tout compact ? Cher lecteur, dites moi ce que vous en pensez}. Prenons comme exemple simplement \( a_k=1\) pour tout \( k\). Pour tout \( | t |<1\), la série \( \sum_k t^k\) converge absolument (série géométrique), mais nous aurions \( \| u_k \|_{\infty}=1\) et donc divergence évidente de \( \sum_k\| u_k \|_{\infty}\).

La proposition suivante sera surtout utile lorsqu'on parlera de dérivée.
\begin{proposition}[\cite{KOWMooXhcOoy}]        \label{PropHDIUooKTbVSX}
    Quel que soit le nombre \( \alpha\in \eR\), les séries \( \sum_na_nz^n\) et \( \sum_nn^{\alpha}a_nz^n\) ont même rayon de convergence.
\end{proposition}

\begin{proof}
    Nous posons
    \begin{subequations}
        \begin{align}
            E=\{ r\in \eR^+\tq \text{  } (a_nr^n)\text{ est borné } \}
            E'=\{ r\in \eR^+\tq \text{  } (n^{\alpha}a_nr^n)\text{ est borné } \}
        \end{align}
    \end{subequations}
    Et aussi \( R=\sup(E)\), \( R'=\sup(E')\). Le fait que \( E'\geq E\) est facile. Nous supposons \( R>0\) et nous considérons \( r<R\) (c'est à dire \( r\in E\)).  Nous allons montrer que \( r\in E'\). Pour cela nous prenons un nombre \( s\) tel que \( r<s<R\). Nous avons
    \begin{equation}
        n^{\alpha}a_nr^n=n^{\alpha}a_n\left( \frac{ r }{ s } \right)^ns^n=n^{\alpha}\left( \frac{ r }{ s } \right)^na_ns^n.
    \end{equation}
    Mais \( r/s<1\), donc le lemme \ref{LemLJOSooEiNtTs} dit que \( n^{\alpha}(r/s)^n\to 0\). Cela est donc borné par une constante \( M\). Donc
    \begin{equation}
        n^{\alpha}a_nr^n\leq Ma_ns^n.
    \end{equation}
    Mais la suite \( (a_ns^n)\) est bornée. Donc la suite \( n^{\alpha}a_nr^n\) est également bornée, ce qui prouve que \( r\in E'\).
\end{proof}

\begin{remark}
    Au fond, cette proposition n'est rien d'autre que dire que dans \( n^\alpha r^n\), l'effet «convergent» est \( r^n\) qui est une décroissance exponentielle tandis que l'effet «divergent» est \( n^{\alpha}\) qui a une croissance seulement polynomiale.

\end{remark}

\begin{theorem}[Formule de Hadamard]\index{formule!Hadamard}\index{Hadamard!formule}		\label{ThoSerPuissRap}
Le rayon de convergence de la série entière \( \sum_n c_n z^n\) est donné par une des deux formules
\begin{equation}		\label{EqRayCOnvSer}
	\frac{1}{ R } =\limsup\sqrt[k]{| a_k |}
\end{equation}
ou
\begin{equation}		\label{EqAlphaSerPuissAtern}
	\frac{1}{ R }=\limite k \infty \abs{\frac{a_{k+1}}{a_k}}
\end{equation}
lorsque $a_k$ est non nul à partir d'un certain $k$.
\end{theorem}

Le disque $| z-z_0 |\leq R$ est le \defe{disque de convergence}{disque de convergence} de la série \( \sum_n a_n(z-z_0)^n\). Notons que le critère d'Abel ne dit rien pour les points tels que $| z-z_0 |=R$. Il faut traiter ces points au cas par cas. Et le pire, c'est qu'une série donnée peut converger pour certain des points sur le bord du disque, et diverger en d'autres. Le théorème d'Abel radial (théorème \ref{ThoLUXVjs}) nous donnera quelques informations sur le sujet.

Il y a un dessin à la figure \ref{LabelFigDisqueConv}.
\newcommand{\CaptionFigDisqueConv}{À l'intérieur du disque de convergence, la convergence est absolue. En dehors, la série diverge. Sur le cercle proprement dit, tout peut arriver.}
\input{auto/pictures_tex/Fig_DisqueConv.pstricks}

Si les suites \( a_n\) et \( b_n\) sont équivalentes, alors les séries correspondantes auront le même rayon de convergence. Cela ne signifie pas que sur le bord du disque de convergence, elles aient même comportement. Par exemple nous avons
\begin{equation}
    \frac{1}{ \sqrt{n} }\sim \frac{1}{ \sqrt{n} }+\frac{ (-1)^n }{ n }.
\end{equation}
En même temps, en \( z=-1\) la série 
\begin{equation}
    \sum_{n\geq 1}\frac{ z^n }{ \sqrt{n} }
\end{equation}
converge par le critère des séries alternées (corollaire \ref{CoreMjIfw}). Par contre la série
\begin{equation}
    \sum_{n\geq 1}\left( \frac{1}{ \sqrt{n} }+\frac{ (-1)^n }{ n } \right)z^n
\end{equation}
ne converge pas pour \( z=-1\).

\begin{example}
    Soit \( \alpha\in \eR\) et considérons la série \( \sum_{n\geq 1}a_nz^n\) où \( a_n\) est la \( n\)-ième décimale de \( \alpha\). Si \( \alpha\) est un nombre décimal limité, la suite \( (a_n)\) est finie et le rayon de convergence est infini. Sinon, pour tout \( N\) il existe un \( n>N\) tel que \( a_n\neq 0\) et la suite \( (a_n)\) ne tend pas vers zéro. Par conséquent la série
    \begin{equation}
        \sum_{n}a_nz^n
    \end{equation}
    diverge pour \( z=1\) et le rayon de convergence satisfait \( R\leq 1\). Nous avons aussi \( | a_n |\leq 9\), de telle manière à ce que la série soit bornée et par conséquent majorée en module par \( 9z^n\), ce qui signifie que \( R\geq 1\). 

    Nous déduisons alors \( R=1\).
\end{example}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Propriétés de la somme}
%---------------------------------------------------------------------------------------------------------------------------

\begin{theorem}     \label{ThokPTXYC}
    Soient \( \sum_na_nz^n\) et \( \sum b_nz^n\) deux séries de rayon de convergences respectivement \( R_a\) et \( R_b\).
    \begin{enumerate}
        \item   \label{IteWlajij}
            Si \( R_s\) est le rayon de convergence de \( \sum_n(a_n+b_n)z^n\), nous avons
            \begin{equation}
                R_s\geq \min\{ R_a,R_b \}
            \end{equation}
            et nous avons l'égalité si pour tout \( |z |\leq\min\{ R_a,R_b \}\), \( \sum (a_n+b_n)z^n=\sum_n a_nz^n+\sum_nb_nz^n\).
        \item
            Si \( \lambda\neq 0\) la série \( \sum_n(\lambda a_n)z^n\) a le même rayon de convergence que la série \( \sum_na_nz^n\) et si \( | z |<R_a\) nous avons
            \begin{equation}
                \sum_{n=0}^{\infty}(\lambda a_n)z^n=\lambda\sum_{n=0}^{\infty}a_nz^n.
            \end{equation}
        \item
            Le \defe{produit de Cauchy}{Cauchy!produit}\index{produit!de Cauchy} des deux séries est donné par
            \begin{equation}        \label{EqFPGGooDQlXGe}
                \left( \sum_na_nz^n \right)\left( \sum_k b_kz^k \right)=       \sum_{n=0}^{\infty}\left( \sum_{i+j=n}a_ib_j \right)z^n=\sum_{n=0}^{\infty}\left( \sum_{k=0}^{n}a_kb_{n-k} \right)z^n.
            \end{equation}
            Si \( R_p\) est le rayon de convergence de ce produit nous avons
            \begin{equation}
                R_p\geq \min\{ R_a,R_b \}
            \end{equation}
            et si \( | z |<\min\{ R_a,R_b \}\) alors
            \begin{equation}
                \sum_{n=0}^{\infty}\left( \sum_{i+j=n}a_ib_j \right)z^n=\left( \sum_{n=0}^{\infty}a_nz^n \right)\left( \sum_{n=0}^{\infty}b_nz^n \right).
            \end{equation}
            
    \end{enumerate}
    
\end{theorem}

\begin{proof}
    Nous prouvons la partie sur le produit de Cauchy. En utilisant la propriété du produit de la somme par un scalaire nous avons
    \begin{subequations}
        \begin{align}
            \left( \sum_{n=0}^{\infty}a_nz^n \right)\left( \sum_{m=0}^{\infty}b_mz^m \right)&=\sum_{n=0}^{\infty}\left( \sum_{m=0}^{\infty}b_ma_nz^{m+n} \right)\\
            &=\lim_{N\to \infty} \lim_{M\to \infty} \sum_{n=0}^N\sum_{m=0}^Mb_ma_nz^{m+n}\\
            &=\lim_{N\to \infty} \lim_{M\to \infty} \sum_{k=0}^{N+M}\sum_{i+k=k}b_ia_jz^k\\
            &=\lim_{N\to \infty} \sum_{k=0}^{\infty}\sum_{i+k=k}b_ia_jz^k\\
            &=\sum_{k=0}^{\infty}\sum_{i+j=k}b_ia_jz^k.
        \end{align}
    \end{subequations}
\end{proof}

\begin{example}
    Montrons un produit de Cauchy dont le rayon de convergence est strictement plus grand que le minimum. D'abord nous considérons
    \begin{equation}
        A=1-z,
    \end{equation}
    c'est à dire \( a_0=1\), \( a_1=-1\), \( a_{n\geq 2}=0\) avec \( R_a=\infty\). Ensuite nous considérons
    \begin{equation}
        B=\sum_nz^n,
    \end{equation}
    c'est à dire \( B=(1-z)^{-1}\) et \( R_b=1\). Le produit de Cauchy de ces deux séries valant \( 1\), le rayon de convergence est infini.
\end{example}

\begin{example}
    Nous montrons que
    \begin{equation}
        \sum_{n=0}^{\infty}(n+1)x^n=\frac{1}{ (1-x)^2 }
    \end{equation}
    pour \( x\in\mathopen] -1 , 1 \mathclose[\).

    Étant donné que pour tout \( r\) dans \( \mathopen] -1 , 1 \mathclose[\) la suite \( (n+1)r^n\) est bornée, le rayon de convergence est correct. Pour les \( x\) dans ce domaine nous avons
    \begin{equation}        \label{EqIwbuTk}
        \frac{1}{ (1-x)^2 }=\frac{1}{ (1-x) }\frac{1}{ (1-x) }=\left( \sum_{n=0}^{\infty}x^n \right)\left( \sum_{m=0}^{\infty}z^m \right).
    \end{equation}
    Nous devons expliciter ce produit de Cauchy en utilisant le théorème \ref{ThokPTXYC}. Pour tout \( i\) nous avons \( a_i=b_i=1\). Par conséquent le produit \eqref{EqIwbuTk} devient
    \begin{equation}
        \sum_{n=0}^{\infty}\sum_{i+j=n}x^n=\sum_{n=0}^{\infty}(n+1)x^n.
    \end{equation}
\end{example}

\begin{theorem}
    Une série entière converge normalement sur tout disque fermé inclus au disque de convergence.
\end{theorem}

\begin{proof}
    Toute boule fermée inclue à \( B(0,R)\) est inclue à la boule \( \overline{ B(0,r) }\) pour un certain \( r<R\). Nous nous concentrons donc sur une telle boule fermée.

    Pour chaque \( n\) nous posons \( u_n(z)=a_nz^n\) que nous voyons comme une fonction sur \( \overline{ B(0,r) }\). Pour tout \( n\in \eN\) et tout \( z\in\overline{ B(0,r) }\) nous avons 
    \begin{equation}
        \| u_n \|_{\infty}\leq| a_nz^n |\leq | a_n |r^n.
    \end{equation}
    Étant donné que \( r<R\) la série \( \sum_n | a_n |r^n\) converge et la série \( \sum_n\| u_n \|\) est convergente. La série \( \sum_na_nz^n\) est alors normalement convergente.
\end{proof}

\begin{example}
    Encore une fois nous n'avons pas d'informations sur le comportement au bord. Par exemple la série \( \sum_nz^n\) a pour rayon de convergence \( R=1\), mais \( \sup_{z\in B(0,1)}| z^n |=1\) et nous n'avons pas de convergence normale sur la boule fermée.
\end{example}

La convergence normale n'est donc pas de mise sur tout l'intérieur du disque de convergence. La continuité, par contre est effective sur la boule. En effet si \( z_0\in B(0,R)\) alors il existe un rayon \( 0<r<R\) tel que \( B(z_0,r)\subset B(0,R)\). Sur \( B(z_0,r)\) nous avons convergence normale et donc continuité en \( z_0\).

La différence est que la continuité est une propriété locale tandis que la convergence normale est une propriété globale.

\begin{proposition}
    Soit \( f(z)=\sum_na_nz^n\) avec un rayon de convergence \( R\). Si \( \sum | a_n |R^n\) converge alors
    \begin{enumerate}
        \item
            la série \( \sum_na_nz^n\) converge normalement sur \( \overline{ B(0,R) }\),
        \item
            \( f\) est continue sur \( \overline{ B(0,R) }\).
    \end{enumerate}
\end{proposition}

\begin{proof}
    La conclusion est claire dans l'intérieur du disque de convergence. En ce qui concerne le bord, chacune des sommes partielles est une fonction continue. De plus nous avons \( \| u_n \|\leq | a_n |R^n\), dont la série converge. Par conséquent nous avons convergence normale sur le disque fermé.
\end{proof}

Le théorème suivant permet de donner, dans le cas de fonctions réelle, des informations sur la convergence en une des deux extrémités de l'intervalle de convergence.
\begin{theorem}[Convergene radiale de Abel]\index{Abel!convergence radiale} \label{ThoLUXVjs}
    Soit \( f(x)=\sum_na_nx^n\) une série réelle de rayon de convergence \( 0<R<\infty\).
    \begin{enumerate}
        \item
            Si \( \sum a_nR^n\) converge, alors \( f\) est continue sur \( \mathopen[ 0 , R \mathclose]\).
        \item
            Si \( \sum_na_n(-R)^n\) converge, alors \( f\) est continue sur \( \mathopen[ -R , 0 \mathclose]\).
    \end{enumerate}
\end{theorem}

L'exemple \ref{EXooKNTPooKiRExX} donnera un exemple d'utilisation pour la série de \( \ln(1-x)\) (qui n'est pas encore définie à ce moment).


Le résultat suivant permet d'identifier deux séries complexes lorsque leurs valeurs sur \( \eR\) sont identiques.
\begin{proposition}
    Soient les séries \( f(z)=\sum a_nz^n\) et \( g(z)=\sum b_n z^n\) convergentes dans \( B(0,R)\). Si \( f(x)=g(x)\) pour \( x\in \mathopen[ 0 , R [\) alors \( a_n=b_n\).
\end{proposition}

\begin{proof}
    Soit \( n_0\) le plus petit entier tel que \( a_{n_0}\neq b_{n_0}\). Pour tout \( z\in B(0,R)\) nous avons
    \begin{equation}
        f(z)-g(z)=\sum_{n=n_0}^{\infty}(a_n-b_n)z^n=z^{n_0}\varphi(z)
    \end{equation}
    où
    \begin{equation}
        \varphi(z)=\sum_{n\geq 0}(a_{n+n_0}-b_{n+n_0})z^n.
    \end{equation}
    Par le théorème \ref{ThokPTXYC}\ref{IteWlajij} le rayon de convergence de \( \varphi\) est plus grand que \( R\) et la fonction \( \varphi\) est continue en \( 0\). Étant donné que \( \varphi(0)=a_{n_0}-b_{n_0}\neq 0\) et que \( \varphi\) est continue nous avons un \( \rho\) tel que \( \varphi\neq 0\) sur \( B(0,\rho)\). Or cela n'est pas possible parce que au moins sur la partie réelle de cette dernière boule, \( \varphi\) doit être nulle.
\end{proof}


\begin{proposition}[\cite{GYDXooJJusGH,MonCerveau}]     \label{PropSNMEooVgNqBP} 
    Si la série entière \( \sum_{n\geq 0}a_nz^n\) a un rayon de convergence \( R\) alors
    \begin{enumerate}
        \item
            La somme est une fonction holomorphe dans le disque de convergence.
        \item       \label{ItemUULDooEGRNiA}
            La somme est différentiable et
            \begin{equation}
                du_{z_0}(z)=\sum_{n=1}^{\infty}na_nz_0^{n-1}z.
            \end{equation}
        \item
    De plus pour tout \( z_0\in B(0,R)\), on pose\footnote{Pour rappel, dans tout ce texte, \( B(a,r)\) est une boule \emph{ouverte}.}
    \begin{subequations}
        \begin{align}
            S(z)&=\sum_{n\geq 0}a_nz^n\\
            T(z)&=\sum_{n\geq 1}na_nz^{n-1}=\sum_{n=0}^{\infty}(n+1)a_{n+1}z^n.
        \end{align}
    \end{subequations}
    Alors  nous avons
    \begin{equation}    \label{EqVQDPooOPICwN}
        \lim_{z\to z_0}\frac{ S(z)-S(z_0) }{ z-z_0 }=T(z_0).
    \end{equation}
    \end{enumerate}
\end{proposition}

\begin{proof}
    Nous allons prouver, en utilisant le théorème \ref{ThoLDpRmXQ}, que la somme est une fonction différentiable et que la différentielle est \( \eC\)-linéaire. La proposition \ref{PropKJUDooJfqgYS} nous dira alors que la somme est \( \eC\)-dérivable.

    Nous posons \( u_n(z)=a_nz^n\), qui est une fonction de classe \( C^1\). En ce qui concerne sa différentielle nous considérons \( z_0\in B(0,R)\)  et nous avons    (si \( n=0\) alors la différentielle est nulle)
    \begin{subequations}
        \begin{align}
            (du_n)_{z_0}(z)&=\Dsdd{ u_n(z_0+tz) }{t}{0}\\
            &=\Dsdd{ a_n(z_0+tz)^n }{t}{0}\\
            &=\Dsdd{ na_n(z_0^{n-1}tz) }{t}{0}\\
            &=na_nz_0^{n-1}z.
        \end{align}
    \end{subequations}
    En cours de calcul nous avons développé \( (z_0+tz)^n\) et gardé seulement les termes de degré \( 1\) en \( t\). Il y en a \( n\) et ils sont tous égaux à \( z_0^{n-1}tz\).

    La convergence simple \( \sum_nu_n\) est dans les hypothèses. Il reste à prouver que la somme des différentielles converge uniformément sur tout compact autour de \( z_0\) ne débordant pas du disque ouvert de convergence. Soit \( K\) un compact autour de \( z_0\). Dans le calcul suivant nous utilisons une première fois la norme uniforme de \( du_n\) vu comme fonction de \( K\) vers \( \aL(\eC,\eC)\) et une fois la norme opérateur\footnote{Définition \ref{DefNFYUooBZCPTr}.} de \( (du_n)_{z_0}\) comme application linéaire \( \eC\to \eC\) :
    \begin{subequations}
        \begin{align}
            \| du_n \|_k&=\sup_{z_0\in K}\| (du_n)_{z_0} \|\\
            &=\sup_{z_0\in K}\sup_{| z |=1}\\
            &=\sup_{z_0\in K}\sup_{| z |=1}| na_nz_0^{n-1}z |\\
            &=\sup_{z_0\in K}n| a_n | |z_0 |^{n-1}.
        \end{align}
    \end{subequations}
    Vu que \( z\mapsto| z |^{n-1}\) est une application continue sur le compact \( K\), elle atteint son maximum (théorème \ref{ThoWeirstrassRn}.), nous considérons \( z_K\), un point qui réalise le supremum. Ce nombre est dans le disque de convergence parce que \( K\) est un compact autour de \( z_0\). 
    
    Nous devons prouver que \( \sum_nn| a_n | |z_K |^{n-1}\) converge. Vu que \( | z_K |\) est une constante (par rapport à \( n\)) nous pouvons étudier la convergence en écrivant \( | z_K |^n\) au lieu de \( | z_K |^{n-1}\).

    La suite \( (a_n| z_K |^n)\) est une suite bornée. Soit \( M\) tel que \( | a_n | |z_K |^n<M\) pour tout \( n\). Nous considérons de plus \( r\) de telle sorte que \( K\subset B(0,r)\subset B(0,R)\). En particulier \( | z_K |<r\) et nous avons
    \begin{equation}
        n| a_n | |z_K |^n\leq n| a_n |r^n\left( \frac{ | z_K | }{ r } \right)^n\leq nM\left( \frac{ | z_K | }{ r } \right)^n.
    \end{equation}
    Nous savons que ce qui est dans la parenthèse est plus petit que \( 1\), mais que \( \sum_nnx^n\) converge dès que \( | x |<1\). Par conséquent
    \begin{equation}
        \sum_n\| du_n \|_K
    \end{equation}
    converge et le théorème \ref{ThoLDpRmXQ} fonctionne : \( du=\sum_{n=1}^{\infty}du_n\) et la somme \( \sum_nu_n\) est de classe \( C^1\).

    La différentielle de \( \sum_nu_n\) s'exprime explicitement par
    \begin{equation}        \label{EqJBFMooMjSABz}
        du_{z_0}(z)=\sum_{n=1}^{\infty}na_nz_0^{n-1}z.
    \end{equation}
    Cette forme montre que \( du_{z_0}\) est une application \( \eC\)-linéaire et donc la somme est \( \eC\)-dérivable par la proposition \ref{PropKJUDooJfqgYS}. Ergo holomorphe sur le disque de convergence par définition \ref{DefMMpjJZ}.

    En ce qui concerne la formule \eqref{EqVQDPooOPICwN}, elle provient de la formule \eqref{EqPAEFooYNhYpz} : \( f'(z_0)\) est donné par la facteur multiplicatif de \( du_{z_0}\). En l'occurrence la formule \eqref{EqJBFMooMjSABz} nous donne
    \begin{equation}
        f'(z_0)=\sum_{n\geq 1}na_nz_0^{n-1}.
    \end{equation}
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Dérivation}
%---------------------------------------------------------------------------------------------------------------------------

\begin{lemma}       \label{LemFVMaSD}
    Soit une série entière \( \sum a_nz^n\) de rayon de convergence \( R\). Les séries
    \begin{equation}
        \sum \frac{ a_n }{ n+1 }z^{n+1}
    \end{equation}
    et
    \begin{equation}
        \sum_{n\geq 1}na_nz^{n-1}
    \end{equation}
    ont même rayon de convergence \( R\).
\end{lemma}

Notons toutefois que nonobstant ce lemme, les séries dont il est question peuvent se comporter différemment sur le bord du disque de convergence. En effet la série
\begin{equation}
    \sum \frac{1}{ n }z^n
\end{equation}
diverge pour \( z=1\) alors que 
\begin{equation}
    \sum\frac{1}{ n(n+1) }z^{n+1}
\end{equation}
converge pour \( z=1\).


Les théorèmes de dérivation et d'intégration de séries de fonctions (théorèmes \ref{ThoCciOlZ} et \ref{ThoCSGaPY}) fonctionnent bien dans le cas des séries entières. Ils donnent la proposition \ref{ProptzOIuG} pour la dérivation et \ref{PropfeFQWr} pour l'intégration.

\begin{proposition}     \label{ProptzOIuG}
    Soit la série entière
    \begin{equation}
        f(x)=\sum_{n=0}^{\infty}a_n x^n
    \end{equation}
    de rayon de convergence \( R\). Alors la fonction \( f\) est \( C^1\) sur \( \mathopen] -R , R \mathclose[\) et se dérive terme à terme :
    \begin{equation}
        f'(x)=\sum_{n=1}^{\infty}na_nx^{n-1}
    \end{equation}
    pour tout \( x\in\mathopen] -R , R \mathclose[\).
\end{proposition}
\index{permuter!série entière et dérivation}

\begin{proof}
    Nous savons que la série \( \sum_{n=1}^{\infty}na_nx^{n-1}\) a le même rayon de convergente que celui de la série \( f\). En particulier cette série des dérivées converge normalement sur tout compact dans \( \mathopen] -R , R \mathclose[\) et la somme est continue. Le théorème \ref{ThoCSGaPY} conclu.
\end{proof}

\begin{remark}
    À part lorsqu'on parle de fonction \( \eR\to \eR\), la notion de classe \( C^k\) s'entend au sens de la différentielle, et non de la dérivée, voir les définitions \ref{DefPNjMGqy}. C'est cela qui explique la structure de la démonstration de la proposition \ref{PropSNMEooVgNqBP}.
\end{remark}

\begin{corollary}[\cite{GYDXooJJusGH,MonCerveau}]       \label{CorCBYHooQhgara}
    La somme d'une série entière est de classe \( C^{\infty}\) sur le disque ouvert de convergence.
\end{corollary}

\begin{proof}
    La proposition \ref{PropSNMEooVgNqBP} a démontré en réalité nettement plus : sur le disque ouvert de convergence, la somme est une fonction holomorphe. Il est n'est cependant pas possible de conclure ainsi parce que le fait qu'une fonction holomorphe est \( C^{\infty}\) ne sera démontré qu'au coût de nombreux efforts dans le théorème \ref{ThomcPOdd}\ref{ItemMRRTooMChmuZ}.

    \begin{subproof}
    \item[Cas réel]
        Nous considérons la série entière \( \sum_na_nx^n\) pour \( x\in \eR\) de rayon de convergence \( R\). Une simple récurrence sur la proposition \ref{ProptzOIuG} donne le résultat.
    \item[Cas complexe]
        Attention : le fait d'être de classe \( C^k\) est le fait d'être \( k\) fois \emph{différentiable}. Rien à voir avec la \( \eC\)-dérivabilité.

        En ce qui concerne la différentiabilité nous avons la proposition \ref{PropSNMEooVgNqBP} qui dit que dans le disque de convergence, la fonction \( u(z)=\sum_na_nz^n\) a pour différentielle l'application \( du\colon \eC\to \aL_{\eC}(\eC,\eC)\),
        \begin{equation}
            du_{z_0}(z)=\big( \sum_{n=0}^{\infty}(n+1)a_{n+1}z_0^n \big)z.
        \end{equation}
        Nous allons éviter de considérer la différentielle seconde comme une application
        \begin{equation}
            d^2u\colon \eC\to \aL\big( \eC,\aL(\eC,\eC) \big)
        \end{equation}
        parce que ça nous mènerait trop loin pour parler de la différentielle \( k\)\ieme. Au lieu de cela nous allons considérer l'isomorphisme d'espace vectoriel
        \begin{equation}
            \begin{aligned}
                \psi\colon \eC&\to \aL_{\eC}(\eC,\eC) \\
                z_0&\mapsto \psi(z_0) z=z_0z.
            \end{aligned}
        \end{equation}
        Dans cette optique nous écrivons :
        \begin{equation}
            du_{z_0}=\psi\big( \sum_{n=0}^{\infty}(n+1)a_{n+1} z_0^n\big)
        \end{equation}
        ou encore :
        \begin{equation}
            (\psi^{-1}\circ d)u(z_0)=\sum_{n\geq 0}(n+1)a_{n+1}z_{0}^n.
        \end{equation}
        Nous allons prouver par récurrence que l'égalité suivante est vraie (y compris le fait que la somme converge) :
        \begin{equation}
            (\psi^{-1}\circ d)^ku(z_0)=\sum_{n=0}^{\infty}\frac{ (n+k)! }{ n! }a_{n+k}z_0^n.
        \end{equation}
        Prouvons d'abord que cette somme converge pour tout \( k\). Nous avons \( (n+k)!/n!<(n+k)^k\) et donc il suffit de prouver que la série de coefficients \( n^ka_n\) converge. C'est le cas par la proposition \ref{PropHDIUooKTbVSX}.

        Nous pouvons calculer la différentielle de \( (\psi^{-1}\circ d)^ku\) en dérivant terme à terme en utilisant (encore) la proposition \ref{PropSNMEooVgNqBP}\ref{ItemUULDooEGRNiA} :
        \begin{subequations}
            \begin{align}
                d\big( (\psi^{-1}\circ d)^k u\big)_{z_0}(z)&=\sum_{n=1}^{\infty}\frac{ (n+k)! }{ n! }a_{n+k}na_{0}^{n-1}z\\
                &=\sum_{n=0}^{\infty}\frac{ (n+k+1)! }{ n! }a_{n+k+1}z_{0}^nz.
            \end{align}
        \end{subequations}
        Nous appliquons \( \psi^{-1}\) à cela :
        \begin{equation}
            (\psi^{-1}\circ d)^{k+1}u(z_0)=\sum_{k=0}^{\infty}\frac{ (n+k+1)! }{ n! }a_{n+k+1}z_0^n.
        \end{equation}
        
    \item[Dérouler à l'envers]

        Nous allons maintenant utiliser la proposition \ref{PropEKLTooSvZjdW} pour montrer que \( u\) est de classe \( C^k\) pour tout \( k\). Nous avons démontré que \( (\psi^{-1}\circ d)^ku\) était différentiable. Par conséquent, \( d\big( (\psi^{-1}\circ d)^{k-1}u \big)\) est différentiable et donc \( (\psi^{-1}\circ d)^{k-1}\) est de classe \( C^1\). En continuant ainsi, \( (\psi^{-1}\circ d)^{k-l}u\) est de classe \( C^l\) et \( u\) est de classe \( C^k\).
    \end{subproof}
\end{proof}

Le lemme suivant est encore essentiellement valable dans un espace de Banach (proposition \ref{PropQAjqUNp}).
\begin{lemma}       \label{LemPQFDooGUPBvF}
    La série entière \( \sum_{n\geq 0}z^{nk}\) a un rayon de convergence \( 1\) et converge vers la fonction
    \begin{equation}
        \sum_{n\geq 0}z^{nk}=\frac{1}{ 1-z^k }.
    \end{equation}

    Lorsque \( | \omega |=1\) nous avons aussi un rayon de convergence \( 1\) pour la série
    \begin{equation}        \label{EqSSHZooLwCBAZ}
        \frac{1}{ \omega-z }=\sum_{k\geq 0}\omega^{-k-1}z^k.
    \end{equation}

    Sous les mêmes hypothèses sur \( \omega\) nous avons encore la série
    \begin{equation}
        \frac{1}{ (\omega-z)^k }=\frac{1}{ (k-1)! }\sum_{s=0}^{\infty}\omega^{-s-1-k}\frac{ (s+k-1)! }{ s! }z^s
    \end{equation}
    
\end{lemma}

\begin{proof}
    Les coefficients de la série sont \( a_n=1\) lorsque \( n\) est multiple de \( k\) et \( a_n=0\) autrement. Donc pour \( r=1\) la suite \( r^na_n\) reste bornée\footnote{Utilisation directe de la définition \ref{DefZWKOZOl}.}. Cela prouve que le rayon de convergence est au moins \( 1\). Par ailleurs si \( r>1\) alors clairement la suite \( (a_nr^n)\) n'est pas bornée. Cela prouve le rayon de convergence égal à \( 1\).

    Soit donc \( z\in B(0,1)\). Nous avons
    \begin{equation}
        \left( \sum_{n\geq 0}z^{nk} \right)(1-z^k)=\sum_{n\geq 0}z^{nk}-\sum_{n\geq 0}z^{(n+1)k}.
    \end{equation}
    Le premier terme de la première somme vaut \( 1\) tandis que tous les autres termes s'annulent deux à deux.

    En ce qui concerne la série \eqref{EqSSHZooLwCBAZ}, elle s'obtient facilement :
    \begin{equation}
        \frac{1}{ \omega-z }=\frac{1}{  \omega }\frac{1}{ 1-\frac{ z }{ \omega } }=\frac{1}{ \omega }\sum_{s=0}^{\infty}\left( \frac{ z }{ \omega } \right)^s=\sum_s\omega^{-s-1}z^s.
    \end{equation}
    
    La troisième série s'obtient en dérivant la seconde, ce qui est permis dans le disque de convergence par la proposition \ref{ProptzOIuG}.
\end{proof}

\begin{remark}
    Sur le bord du disque de convergence, la série \( \sum_nz^{nk}\) ne converge pas. En effet le rayon étant \( 1\), sur le bord nous avons la série \( \sum_n e^{ink\theta}\) dont la norme du terme général ne tend pas vers zéro.
\end{remark}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Intégration}
%---------------------------------------------------------------------------------------------------------------------------

\begin{proposition} \label{PropfeFQWr}
    Soit la série entière $\sum a_nx^n$ de rayon de convergence \( R\). 
    \begin{enumerate}
        \item
            Pour tout segment \( \mathopen[ a , b \mathclose]\subset\mathopen] -R , R \mathclose[\) nous pouvons intégrer terme à terme :
            \begin{equation}
                \int_a^b\left( \sum_{n=0}^{\infty}a_nx^n\right)dx=\sum_{n=0}^{\infty}a_n\int_a^bx^ndx.
            \end{equation}
        \item
            La série entière obtenue en intégrant terme à terme a le même rayon de convergence que celui de la série de départ.
    \end{enumerate}
\end{proposition}
\index{permuter!série entière et intégration}

\begin{proof}
    La première assertion est un cas particulier du théorème général \ref{ThoCciOlZ}. Pour le rayon de convergence, le lemme \ref{LemFVMaSD} fait le travail.
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Exponentielle sur une algèbre normée}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Dans ce qui suit, nous considérons une algèbre commutative.
\begin{propositionDef}[Exponentielle\cite{MonCerveau}]       \label{DEFooSFDUooMNsgZY}
    Soit \( (A,\| . \|)\) une algèbre\footnote{Définition \ref{DefAEbnJqI}.} commutative de dimension finie sur \( \eR\) munie d'une norme d'algèbre. Pour \( x\in A\) nous définissons
    \begin{equation}        \label{EQooCUVTooGNOrFj}
        \exp(x)=\sum_{k=0}^{\infty}\frac{ x^k }{ k! }.
    \end{equation}
    Cette définition a les propriétés suivantes :
    \begin{enumerate}
        \item
            C'est bien défini pour tout \( x\in A\). C'est à dire que pour chaque \( x\), la série \eqref{EQooCUVTooGNOrFj} converge.
        \item
            Cela donne une application continue \( \exp\colon A\to A\).
        \item       \label{ITEMooGGVAooVfhGuu}
            La fonction \( \exp\) est différentiable et
            \begin{equation}        \label{EQooKWBUooLUdBAw}
                (d\exp)_x(y)=\exp(x)y,
            \end{equation}
            le dernier produit étant la structure d'algèbre sur \( A\).
    \end{enumerate}
\end{propositionDef}

\begin{proof}
    Pour la différentiabilité de \( \exp\), nous voulons utiliser le théorème \ref{ThoLDpRmXQ}. Pour cela nous posons
    \begin{equation}
        u_k(x)=\frac{ x^k }{ k! }
    \end{equation}

    \begin{subproof}
        \item[Convergence simple]
            Nous prouvons la convergence simple, c'est à dire pour chaque \( x\) séparément, de la série \eqref{EQooCUVTooGNOrFj} dans deux buts. D'abord de nous assurer que la définition posée de \( \exp\) a un sens, et ensuite pour commencer à vérifier les hypothèses du théorème \ref{ThoLDpRmXQ}.

            Nous montrons que les sommes partielles forment une suite de Cauchy. Nous fixons \( x\in A\) et nous posons
            \begin{equation}
                s_n=\sum_{k=0}^{\infty}\frac{ x^k }{ k! }.
            \end{equation}
            Soient \( p>q\), deux entiers. Nous avons :
            \begin{equation}        \label{EQooYNZNooDaiPhU}
                \| s_p-s_q \|=\| \sum_{k=q+1}^p\frac{ x^k }{ k! } \|\leq \sum_{k=q+1}^p\frac{ \| x^k \| }{ k! }\leq \sum_{k=q+1}^p\frac{ \| x \|^k }{ k! }
            \end{equation}
            où nous avons utilisé le fait que la norme sur \( A\) soit une norme d'algèbre.

            C'est le moment d'utiliser la série exponentielle donnée dans l'exemple \ref{ExIJMHooOEUKfj} que nous appliquons avec \( t=\| x \|\). La série donnée par les coefficients \( a_k=\| x \|^k/k!\) converge et ses sommes partielles forment en particulier une suite de Cauchy. Donc ce que nous avons à droite dans \eqref{EQooYNZNooDaiPhU} peut être rendu arbitrairement petit lorsque \( p\) et \( q\) sont grands.

        \item[\( u_k\) est continue]
            Il s'agit de remarquer que \( (x+h)^k=x^k+hC(x,h)\) où \( C\) est une fonction bornée de \( h\) (lorsque \( h\) est dans un voisinage de \( 0\in A\)). Donc
            \begin{equation}
                \| (x+h)^k-x^k \|\leq \| h \|\| C(x,h) \|\to 0.
            \end{equation}
        \item[Candidat différentielle de \( u_k\)]
            Nous trouvons à présent un candidat à être différentielle de \( u_k\). Pour cela nous faisons le calcul suivant, sans trop nous soucier de la rigueur :
            \begin{equation}
                (du_k)_x(y)=\Dsdd{ u_k(x+ty) }{t}{0}=k\frac{1}{ k! }x^{k-1}y=u_{k-1}(x)y.
            \end{equation}
        \item[\( u_k\) est différentiable] 
            Nous fixons \( x\in A\) et nous posons \( T(y)=u_{k-1}(x)y\). Ensuite nous vérifions que cela vérifie la définition de la différentielle : nous devons calculer
            \begin{equation}        \label{EQooNPKGooVmEYAV}
                \lim_{h\to 0} \frac{ u_k(x+h)-u_k(x)-T(h) }{ \| h \| }=\lim_{h\to 0} \frac{ (x+h)^k-x^k-kx^{k-1}h }{ k! \| h \| }=\clubsuit.
            \end{equation}
            Vous vous souvenez de la formule pour \( (x+h)^k\) ? Essayez de vous en souvenir. Le premier terme est \( x^k\), et le second est \( kx^{k-1}h\). Pour le reste c'est un polynôme dont tous les termes contiennent au moins \( h^2\). Nous avons donc
            \begin{equation}
                \clubsuit=\lim_{h\to 0} \frac{ h^2P(x,h) }{ k!\| h \| }=0.
            \end{equation}
            Nous en concluons que \( u_k\) est différentiable et que
            \begin{equation}
                (du_k)_x(y)=u_{k-1}(x)y.
            \end{equation}
        \item[\( u_k\) est de classe \( C^1\)]
            Nous devons démontrer que la différentielle est continue; cela est la continuité de l'application
            \begin{equation}
                \begin{aligned}
                    du_k\colon A&\to \aL(A,A) \\
                    x&\mapsto (du_k)_x. 
                \end{aligned}
            \end{equation}
            La topologie sur \( A\) est celle de la norme, et celle sur \( \aL(A,A)\) est celle de la norme opérateur associée à la norme sur $A$. Nous avons\footnote{N'oubliez pas de faire à part le cas \( k=0\) parce que ce qui suit n'est correct que pour \( k\geq 1\).} :
            \begin{subequations}
                \begin{align}
                    \lim_{h\to 0} \| (du_k)_{x+h}-(du_k)_x \|&=\lim_{h\to 0} \sup_{\| y \|=1}\| u_{k-1}(x+h)y-u_{k-1}(x)y \|\\
                    &\leq\lim_{h\to 0} \sup_{\| y \|=1}\| u_{k+1}(x+h)-u_{k-1}(x) \|\| y \|\\
                    &=\lim_{h\to 0} \| u_{k+1}(x+h)-u_{k-1}(x) \|.
                \end{align}
            \end{subequations}
            Le fait que cette limite valle zéro est maintenant la continuité de \( u_{k-1}\).

        \item[Convergence normale sur tout compact]

            Soit un compact \( K\) de \( A\). Par le théorème de Borel-Lebesgue \ref{ThoXTEooxFmdI}, \( K\) est fermé et borné. C'est pour ceci que nous avons supposé que \( A\) était de dimension finie sur \( \eR\). Soit donc \( R>0\) tel que \( \| y \|<R\) pour tout \( y\in K\). Nous avons
            \begin{equation}
                \| du_k \|_K=\sup_{x\in K}\| (du_k)_x \|=\sup_{x\in K}\frac{ \| x^{k-1} \| }{ (k-1)! }\leq \sup_{x\in K}\frac{ \| x \|^{k-1} }{ (k-1)! }\leq \frac{ R^{k-1} }{ (k-1)! }.
            \end{equation}
            Mais la série \( \sum_{k=0}^{\infty}\frac{ R^k }{k!}\) converge. Nous avons donc la convergence normale demandée.

        \item[Conclusion]

            Le théorème \ref{ThoLDpRmXQ} conclu que l'exponentielle est de classe \( C^1\) et que sa différentielle est donnée par la formule
            \begin{equation}
                (d\exp)_x(y)=\sum_{k=0}^{\infty}(du_k)_x(y)=\sum_{k=1}^{\infty}(du_k)_x(y)=\sum_{k=0}^{\infty}u_k(x)y=\exp(x)y.
            \end{equation}
            Notez le jeu d'indices : \( du_k=0\) lorsque \( k=0\) (ce qui permet de faire commencer la somme à \( 1\)) et ensuite \( du_k\) fait intervenir \( u_{k-1}\) (ce qui fait revenir le départ de la somme à \( k=0\)).

    \end{subproof}
\end{proof}

\begin{normaltext}
    Lorsque nous disons que la différentielle de l'exponentielle est l'exponentielle elle-même, nous référons au point \ref{DEFooSFDUooMNsgZY}\ref{ITEMooGGVAooVfhGuu} : la différentielle de \( \exp\) en \( x\) est l'opérateur de multiplication par \( \exp(x)\).

    Nous pouvons comprendre maintenant que \( \exp\) est même de classe \(  C^{\infty}\) parce qu'à chaque différentiation nous tombons sur la même fonction, laquelle est de classe au moins \( C^1\).

    Cependant, pour formaliser ça, il faut un peut travailler. Le cauchemar des différentielles successives d'une application \( A\to A\) est que les espaces en jeu sont des emboîtements terribles de \( \aL(A,\aL(A,\aL(A,A)))\).

    Ce qui nous sauve est que l'espace \( \aL(A,V)\) est un \( A\)-module, quel que soit \( V\). En particulier lorsque \( V\) est lui-même déjà un emboîtement. Faisons un lemme pour voir comment ça fonctionne.
\end{normaltext}

\begin{lemma}[\cite{MonCerveau}]
    Soient deux espaces vectoriels normés \( E\) et \( V\) tels que \( V\) soit un \( E\)-module\footnote{Définition \ref{DEFooHXITooBFvzrR}.}. Nous supposons les normes soient telles que \( \| xv \|_{V}\leq \| x \|_E\| v \|_V\).

    Soit une fonction différentiable \( f\colon E\to V\) telle que la différentielle \( df\colon E\to \aL(E,V)\) soit de la forme
    \begin{equation}
        df_x(y)=yg(x)
    \end{equation}
    pour une certains fonction différentiable \( g\colon E\to V\).

    Alors \( f\) est \( C^1\), et deux fois différentiable telle que
    \begin{equation}
        \begin{aligned}
            d^2f\colon E&\to \aL\big( E,\aL(E,V) \big) \\
            (d^2f)_x(y)z&=z(dg_x)(y)
        \end{aligned}
    \end{equation}
    pour tout \( x,y,z\in E\).
\end{lemma}

\begin{proof}
    En plusieurs étapes.
    \begin{subproof}
        \item[\( f\) est \( C^1\)]
            Nous savons, par hypothèse, que \( f\) est différentiable. Il faut montrer que sa différentielle est continue, en remarquant déjà que \( g\) est continue parce que différentiable.

            Soit \( x_k\stackrel{E}{\longrightarrow}x\), et calculons \( \| df_{x_k}-df_x \|\) :
            \begin{equation}
                \begin{aligned}[]
                    \| df_{x_k}-df_x \|&=\sup_{\| y \|=1}\| df_{x_k}(y)-df_x(y) \|\\
                    &=\sup_{\| y \|=1}\| \big(g(x_k)-g(x)\big)y \|\\
                    &\leq\sup_{\| y \|=1}\| g(x_k)-g(x) \|\| y \|\\
                    &=\| g(x_k)-g(x) \|.
                \end{aligned}
            \end{equation}
            Donc nous avons bien \(df_{x_k}\stackrel{\aL(E,V)}{\longrightarrow}df_x\), ce qui signifie la continuité de \( df\). Donc \( f\) est de classe \( C^1\).

        \item[\( f\) est deux fois différentiable]

            Pour montrer que \( df\) est différentiable, nous mettons directement dans la définition \eqref{EqIQuRGmO} le candidat
            \begin{equation}
                \begin{aligned}
                    T_x(h)\colon R&\to V \\
                    T_x(h)z&=zdg_x(y). 
                \end{aligned}
            \end{equation}
            Nous devons vérifier la limite suivante :
            \begin{equation}        \label{EQooTBCKooRxBCum}
                \lim_{h\stackrel{E}{\longrightarrow} 0} \frac{ df_{x+h}-df_x-T_x(h) }{ \| h \| }=0.
            \end{equation}
            Étudions la norme du numérateur :
            \begin{subequations}
                \begin{align}
                    \| df_{x+h}-df_x-T_x(h) \|&=\sup_{\| y \|=1}\| df_{x+h}(y)-df_x(y)-T_x(h)y \|\\
                    &=\sup_{\| y \|=1}\| yg(x+h)-yg(x)-ydg_x(h) \|\\
                    &\leq \sup_{\| y \|=1}\| y \| \| g(x+h)-g(x)-dg_x(h) \|.
                \end{align}
            \end{subequations}
            La limite \eqref{EQooTBCKooRxBCum} se déduit donc de la différentiabilité de \( g\).
    \end{subproof}
    Note : la partie démontrant que \( f\) est \( C^1\) n'est pas strictement obligatoire parce qu'en vérifiant que \( f\) est deux fois différentiable, nous vérifions de facto que \( df\) est en particulier continue.
\end{proof}

\begin{lemma}[\cite{MonCerveau}]   \label{LEMooTUWQooMCCDcm}
    Soient des algèbres normées \( A\) et \( V\) telles que \( V\) soit un \( A\)-module vérifiant \( \| xv \|\leq \| x \|\| v \|\) pour tout \( x\in A\) et \( v\in V\). Alors \( \aL(A,V)\) est un \( A\)-module vérifiant \( \| x\alpha \|\leq \| x \|\|\alpha  \|\) pour tout \( x\in A\) et \( \alpha\in \aL(A,V)\).
\end{lemma}

\begin{proof}
    C'est un simple calcul utilisant la norme opérateur :
    \begin{equation}
            \| x\alpha \|=\sup_{\| y \|=1}\| (x\alpha)y \|
            =\sup_{\| y \|=1}\| x\alpha(y) \|
            \leq \sup_{\| y \|=1}\| x \|\| \alpha(y) \|
            =\| x \|\sup_{\| y \|=1}\| \alpha(y) \|
            =\| x \|\| \alpha \|.
    \end{equation}
\end{proof}

\begin{proposition}[\cite{MonCerveau}]      \label{PROPooTBDAooQouzSk}
    La fonction \( \exp\colon A\to A\) est de classe \(  C^{\infty}\) et vérifie, pour tout \( k\geq 1\) la récurrence
    \begin{equation}
        (d^k\exp)_x(y)=y(d^{k-1}\exp)_x.
    \end{equation}
\end{proposition}

\begin{proof}
    La formule proposée fonctionne avec \( k=1\) :
    \begin{equation}
        (d\exp)_x(y)=y\exp(x).
    \end{equation}
    C'est la relation \ref{EQooKWBUooLUdBAw}.

    Nous considérons \( k>1\), nous supposons que \( \exp\) est de classe \( C^{k-1}\) et \( k\) fois différentiable. Nous allons prouver que \( \exp\) est alors de classe \( C^k\) et \( k+1\) fois différentiable, et que la différentielle de \( d^k\exp\) est donné par la formule
    \begin{equation}
        (d^{k+1}\exp)_x(y)=y(d^{k}\exp)_x.
    \end{equation}

    Pour nous mettre au clair avec les espaces en présence, nous supposons que
    \begin{subequations}
        \begin{align}
            d^{k-1}\exp&\colon A\to \aL(A,V)\\
            d^{k}\exp&\colon A\to \aL\big( A,\aL(A,V) \big)
        \end{align}
    \end{subequations}
    pour un certain espace vectoriel normé \( V\), lequel est un de ces terrifiants emboîtement de type \( \aL\Big( A,\aL\big( A,\aL(A,A) \big) \Big)\). Il est bien un espace vectoriel normé, et également un \( A\)-module parce qu'on peut toujours définir la multiplication d'un élément \( v\in V\) par un élément \(x\in A\) comme étant la multiplication par \( x\) du résultat final de l'évaluation emboîtée, laquelle se termine par un élément de \( A\). Donc tout se met bien.

    Quoi qu'il en soit, nous posons
    \begin{equation}
        T_x(y)=y(d^{k}\exp)_x
    \end{equation}
    et nous vérifions ce que cela donne dans la définition de la différentielle. Si nous avons
    \begin{equation}
        \lim_{h\to 0} \frac{ (d^k\exp)_{x+h}-(d^k\exp)_x-T_x(h) }{ \| h \| }=0
    \end{equation}
    alors nous aurons prouvé tout ce qu'il nous faut.

    Le numérateur est une application \( A\to \aL(A,V)\); nous en écrivons la norme comme il se doit :
    \begin{subequations}
        \begin{align}
            \|   (d^k\exp)_{x+h}-(d^k\exp)_x-T_x(h) \|&=\sup_{\| y \|=1}\| (d^{k}\exp)_{x+h}(y)-(d^k\exp)_x(y)-h(d^{k}\exp)_xy \|\\
            &=\sup_{\| y \|=1}\| y(d^{k-1}\exp)_{x+h}-y(d^{k-1}\exp)_x-h(d^k\exp)_xy \|\\
            &=\sup_{\| y \|=1}\| y(d^{k-1}\exp)_{x+h}-y(d^{k-1}\exp)_x-hy(d^{k-1}\exp)_x \|\\
            &\leq \| (d^{k-1}\exp)_{x+h}-(d^{k-1}\exp)_x-h(d^{k-1}\exp)_x \|\\
            &=\| (d^{k-1}\exp)_{x+h}-(d^{k-1}\exp)_x-(d^{k}\exp)_x(h) \|.
        \end{align}
    \end{subequations}
    Dans ce calcul nous avons utilisé le lemme \ref{LEMooTUWQooMCCDcm} et \( T_x(h)y=h(d^{k}\exp)_xy\).
    Maintenant, la limite
    \begin{equation}
        \lim_{h\to 0} \frac{  \| (d^{k-1}\exp)_{x+h}-(d^{k-1}\exp)_x-(d^{k}\exp)_x(h) \|.}{ \| h \| }
    \end{equation}
    n'est rien d'autre que la limite arrivant dans la définition du fait que \( d^k\exp\) est la différentielle de \( d^{k-1}\exp\). Cette limite est donc zéro comme nous voulions le prouver.
\end{proof}


Le théorème suivant est très important parce qu'il permet de définir l'exponentielle d'une matrice. Et les exponentielles de matrices sont utiles, entre très nombreuses autres choses pour résoudre certaines équations différentielles.
\begin{theoremDef}[\cite{MonCerveau}]      \label{THOooFGTQooZPiVLO}
    Soit une algèbre normée \( A\) (pas spécialement commutative). La formule
    \begin{equation}
        \exp(x)=\sum_{k=0}^{\infty}\frac{ x^k }{ k! }
    \end{equation}
    définit une fonction différentiable dont la différentielle est donnée par\quext{La fonction exponentielle est, j'en suis quasiment certain, de classe \(  C^{\infty}\). Si vous connaissez un moyen pas trop douloureux de prouver cela, faites-le moi savoir.}
    \begin{equation}        \label{EQooFGPPooZKHeXU}
        (d\exp)_x(y)=\sum_{j,j\in \eN}\frac{ x^iyx^j }{ (i+j+1)! }
    \end{equation}
\end{theoremDef}

\begin{normaltext}
    Nous ne démontrons pas cela ici.
    
    Il s'agit d'une adaptation de la proposition \ref{DEFooSFDUooMNsgZY}. Là où il faut faire attention, c'est dans l'équation \eqref{EQooNPKGooVmEYAV} : il n'y a pas \( k\) termes \( x^{k-1}h\) dans \( (x+h)^k\), mais \( k\) termes de la forme \( x^ihx\). C'est pour cela que la différentielle n'est pas donnée par \( T(y)=u_{k-1}(x)y\), mais bien par la somme \eqref{EQooFGPPooZKHeXU}.

    M'est avis en réalité que toute la démonstration du théorème \ref{PropXFfOiOb} passe facilement au cas présent.
\end{normaltext}



%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Exponentielle et logarithme dans les réels}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

La méthode adoptée ici est la suivante :
\begin{itemize}
    \item L'exponentielle a déjà été définie par sa série en \ref{DEFooSFDUooMNsgZY}.
    \item Nous démontrons qu'elle vérifie l'équation différentielle \( y'=y\), \( y(0)=1\).
    \item Nous démontrons l'unicité de la solution à cette équation différentielle.
    \item Nous démontrons qu'elle est égale à \( x\mapsto y(1)^x\). Cela donne la définition du nombre \( e\) comme valant \( y(1)\).
    \item Nous définissons le logarithme comme l'application réciproque de l'exponentielle (définition \ref{DEFooELGOooGiZQjt}).
    \item Les fonctions trigonométriques (sinus et cosinus) sont définies par leurs séries. Il est alors montré que \(  e^{ix}=\cos(x)+i\sin(x)\).
\end{itemize}

\begin{theorem}[Existence de l'exponentielle] \label{ThoKRYAooAcnTut}
    La série entière
    \begin{equation}    \label{EqEIGZooKWSvPS}
        y(x)=\sum_{k=0}^{\infty}\frac{ x^k }{ k! }
    \end{equation}
    définit une fonction dérivable solution de
    \begin{subequations}
        \begin{numcases}{}
            y'=y\\
            y(0)=1.
        \end{numcases}
    \end{subequations}
\end{theorem}
\index{exponentielle!existence}

\begin{proof}
    La formule de Hadamard (théorème \ref{ThoSerPuissRap}) donne le rayon de convergence de la série \eqref{EqEIGZooKWSvPS} par
    \begin{equation}
        \frac{1}{ R }=\lim_{k\to \infty} \frac{ \frac{1}{ (k+1)! } }{ \frac{1}{ k! } }=\lim_{k\to \infty} \frac{1}{ k+1 }=0.
    \end{equation}
    Donc nous avons un rayon de convergence infini. La fonction \( y\) est définie sur \( \eR\) et la proposition \ref{ProptzOIuG} nous dit que \( y\) est dérivable. Nous pouvons aussi dériver terme à terme :
    \begin{equation}
            y'(x)=\sum_{k=0}^{\infty}\frac{ kx^{k-1} }{ k! }=\sum_{k=1}^{\infty}\frac{ kx^{k-1} }{ k! }=\sum_{k=1}^{\infty}\frac{ x^{k-1} }{ (k-1)! }=\sum_{k=0}^{\infty}\frac{ x^k }{ k! }=y(x).
    \end{equation}
    Notez le petit jeu d'indice de départ de \( k\). Dans un premier temps, nous remarquons que \( k=0\) donne un terme nul et nous le supprimons, et dans un second temps nous effectuons la simplification des factorielles (qui ne fonctionne pas avec \( k=0\)).
\end{proof}

Pour la suite nous notons \( y\) une solution de l'équation \( y'=y\), \( y(0)=1\), et nous allons en donner des propriétés indépendamment de l'existence, donnée par le théorème \ref{ThoKRYAooAcnTut}.

\begin{proposition} \label{PropTLECooEiLbPP}
    Quelques propriétés de \( y\) (si elle existe) :
    \begin{enumerate}
        \item
            Pour tout \( x\in \eR\) nous avons \( y(x)y(-x)=1\).
        \item
            \( y(x)>0\) pour tout \( x\).
        \item
            \( y\) est strictement croissante.
    \end{enumerate}
\end{proposition}

\begin{proof}
    Nous posons \( \varphi(x)=y(x)y(-x)\) et nous dérivons :
    \begin{equation}
        \varphi'(x)=y'(x)y(-x)-y(x)y'(-x)=0.
    \end{equation}
    Donc \( \varphi\) est constante\footnote{Proposition \ref{PropGFkZMwD}.}. Vu que \( \varphi(0)=1\) nous avons automatiquement \( y(x)y(-x)=1\) pour tout \( x\).

Les deux autres allégations sont simples : si \( y(x_0)<0\) alors il existe \( t\in\mathopen] x_0 , 1 \mathclose[\) tel que \( y(t)=0\), ce qui est impossible parce que \( y(t)y(-t)=1\). La stricte croissance de \( y\) s'ensuit.
\end{proof}

\begin{proposition}[Unicité de l'exponentielle] \label{PropDJQSooYIwwhy}
    Si elle existe, la solution au problème 
    \begin{subequations}
        \begin{numcases}{}
            y'=y\\
            y(0)=1
        \end{numcases}
    \end{subequations}
    est unique.
\end{proposition}
\index{exponentielle!unicité}

\begin{proof}
    Soient \( y\) et \( g\) deux solutions et considérions la fonction \( h(x)=g(x)y(-x)\). Un calcul immédiat donne
    \begin{equation}
        h'(x)=0
    \end{equation}
    et donc \( h\) est constante. Vu que \( h(0)=1\) nous avons \( g(x)y(-x)=1\) pour tout \( x\), c'est à dire
    \begin{equation}
        g(x)=\frac{1}{ y(-x) }=y(x).
    \end{equation}
\end{proof}

\begin{proposition}     \label{PROPooGGUIooExVHPM}
    Quelques formules pour tout \( a,b\in \eR\) et \( n\in \eZ\) :
    \begin{enumerate}
        \item       \label{ITEMooMPSUooWQpVQJ}
            \( y(a+b)=y(a)y(b)\)
        \item
            \( y(na)=y(a)^n\)
        \item
            \( y\left( \frac{ a }{ n } \right)=\sqrt[n]{y(a)}\).
    \end{enumerate}
\end{proposition}

\begin{proof}
    Nous posons \( h(x)=y(a+b-x)y(x)\) et nous avons encore \( h'(x)=0\) dont nous déduisons que $h$ est constante. De plus
    \begin{equation}
        h(0)=y(a+b)y(0)=y(a+b)
    \end{equation}
    et
    \begin{equation}
        h(b)=y(a)y(b).
    \end{equation}
    Vu que \( h\) est constante, ces deux expressions sont égales : \( y(a+b)=y(a)y(b)\).

    Forts de cette relation, une récurrence donne \( y(na)=y(a)^n\) pour tout \( n\in \eN\). De plus
    \begin{equation}
        y(a)=y\left( \frac{ a }{ n }\times n \right)=y\left( \frac{ a }{ n } \right)^n,
    \end{equation}
    ce qui donne \( y(a)=y(a/n)^n\) ou encore \( y(a/n)=\sqrt[n]{y(a)}\).

    Enfin pour les négatifs, si \( n\in \eN\),
    \begin{equation}
        y(-na)=\frac{1}{ y(na) }=\frac{1}{ y(a)^n }=y(a)^{-n}.
    \end{equation}
    Et de la même façon,
    \begin{equation}
        y\left( -\frac{ a }{ n } \right)=\frac{1}{ y\left( \frac{ a }{ n } \right) }=\sqrt[n]{\frac{1}{ y(a) }}=\sqrt[-n]{y(a)}.
    \end{equation}
\end{proof}

\begin{proposition} \label{PropCELWooLBSYmS}
    Pour tout \( x\in \eQ\), nous avons
    \begin{equation}        \label{EQooBFIHooKopcmf}
        y(x)=y(1)^x.
    \end{equation}
\end{proposition}

\begin{proof}
    Si \( q\in \eQ\) alors \( q=a/b\) et
    \begin{equation}
        y(q)=y\left( \frac{ a }{ b } \right)=y\left( a\times \frac{1}{ b } \right)=y\left( \frac{1}{ b } \right)^a=\big( \sqrt[b]{y(1)} \big)^a=y(1)^{a/b}=y(1)^{q}.
    \end{equation}
\end{proof}

\begin{remark}
    Il n'est pas possible de prétendre que la formule \eqref{EQooBFIHooKopcmf} fonctionne pour tout \( x\in\eR\). La bêtise serait de prétendre que les fonctions \( y\) et \( x\mapsto y(1)^x\) étant continues et égales sur \( \eQ\), elles sont égales sur \( \eR\) (proposition \ref{PropCJGIooZNpnGF}).

    Le fait est que la fonction \( x\mapsto a^x\) n'est pas définie pour les \( x\) non rationnels. Nous en avons déjà un peu parlé dans la section \ref{SUBSECooAYCLooNRvLEp}.
\end{remark}

Nous notons \( \exp\) la fonction nommée \( y\) jusqu'à présent. Sinon ça va être compliqué avec les notations.

\begin{propositionDef}    \label{DEFooELGOooGiZQjt}
    L'application \(\exp\colon \eR\to \mathopen] 0 , \infty \mathclose[\) est une bijection.  L'application réciproque
    \begin{equation}
        \ln\colon \mathopen] 0 , \infty \mathclose[\to \eR
    \end{equation}
    est le \defe{logarithme}{logarithme!sur les réels positifs}.
\end{propositionDef}

\begin{proof}
Le fonction exponentielle est dérivable, toujours strictement positive, donc strictement croissante. Les limites en \( \pm \infty\) sont \( 0\) et \( +\infty\). Le théorème des valeurs intermédiaires \ref{ThoValInter} nous dit que c'est une bijection. En effet, l'injectivité est la stricte croissance. En ce qui concerne la surjection, soit \( y\in \mathopen] 0 , \infty \mathclose[\). Vu que la limite en \( -\infty\) est zéro, il existe \( A\in \eR\) tel que \( \exp(x)<y\) pour tout \( x<A\), et de la même façon, il existe \( B\in \eR\) tel que \( \exp(x)>y\) pour tout \( x>B\). Si \( a<A\) et \( b>B\) alors \( \exp(a)<y\) et \( \exp(b)>y\), donc \( y\) est dans l'image de \( \mathopen[ a , b \mathclose]\) par l'exponentielle.
\end{proof}

\begin{definition}[Fonction puissance\cite{MonCerveau}]      \label{DEFooYHVNooLXbibY}
    Pour \( a,x\in \eR\), nous posons
    \begin{equation}
        x^a=\exp\big( a\ln(x) \big)
    \end{equation}
    pour toutes les valeurs de \( a\) et \( x\) pour lesquelles cela a un sens et pour lesquelles la puissance n'est pas encore définie.
\end{definition}

Avec cette définition, l'application \( x\mapsto a^x\) est continue.

\begin{lemma}[\cite{MonCerveau}]
    Nous avons
    \begin{equation}
        \exp(x)=e^x
    \end{equation}
    pour tout \( x\in \eR\). 
\end{lemma}

\begin{proof}
    Si \( x\in \eQ\), cela n'est autre que la proposition \ref{PropCELWooLBSYmS}. Si \( x\) est réel non rationnel, alors la définition de \( e^x\) est la définition \ref{DEFooYHVNooLXbibY} qui donne
    \begin{equation}        \label{EQooFDBNooCdhxLF}
        e^x=\exp\big( x\ln(e) \big).
    \end{equation}
    Vu que \( \ln\) est la fonction réciproque de \( \exp\) et que la définition du nombre \( e\) est que \( \exp(1)=1\), nous avons \( \ln(e)=1\). Donc \eqref{EQooFDBNooCdhxLF} se réduit bien à \( e^x=\exp(x)\).
\end{proof}

Une conséquence est que 
\begin{subequations}    \label{EqLOIUooHxnEDn}
    \begin{align}
        \lim_{x\to -\infty}  e^{x}=0\\
        \lim_{x\to +\infty}  e^{x}=+\infty,
    \end{align}
\end{subequations}
et en particulier, 
\begin{equation}
    \begin{aligned}
    \exp\colon \eR&\to \mathopen] 0 , \infty \mathclose[ \\
        x&\mapsto  e^{x} 
    \end{aligned}
\end{equation}
est une bijection.

Nous donnons maintenant quelques approximations numériques de \( e\), particulièrement inefficaces.

\begin{lemma}
    Nous avons
    \begin{equation}
        2<e<3.
    \end{equation}
\end{lemma}

\begin{proof}
    Nous savons que \( y(0)=1\) et \( y'(0)=1\). La fonction \( y\) est strictement croissante (et donc sa dérivée aussi). Nous avons donc \( y'(x)>1\) pour tout \( x\in\mathopen] 0 , 1 \mathclose]\), et donc
    \begin{equation}
        y(1)>1+1\times 1=2.
    \end{equation}
    Sachant que \( 2>y'(x)\) pour tout \( x\in \mathopen] 0 , 1 \mathclose[\) nous pouvons refaire le coup de l'approximation affine, cette fois en majorant :
        \begin{equation}
            y(1)<1+2\times 1=3.
        \end{equation}
\end{proof}

De la même façon nous savons que
\begin{equation}
    y(\frac{1}{ n })>1+\frac{1}{ n }
\end{equation}
parce que \( y'\) est minoré par \( 1\) sur \( \mathopen] 0 , \frac{1}{ n } \mathclose[\). Avec cela nous avons aussi la majoration
\begin{equation}
    y(\frac{1}{ n })<1+\frac{1}{ n }\times \left( 1+\frac{1}{ n } \right)=1+\frac{1}{ n }+\frac{1}{ n^2 }.
\end{equation}
Et enfin nous pouvons donner l'encadrement, valable pour tout \( n\) :
\begin{equation}
    \left( 1+\frac{1}{ n } \right)^n<y(1)<\left( 1+\frac{1}{ n }+\frac{1}{ n^2 } \right)^n.
\end{equation}
Pour \( n=10\) nous trouvons
\begin{equation}
    2.50<e<2.83.
\end{equation}

Bien que ce soit à mon avis humainement pas possible à faire à la main nous avons, pour \( n=100\) :
\begin{equation}
    2.70<e<2.7317
\end{equation}
Cela reste un encadrement très modeste.

Une méthode plus efficace consiste à calculer directement le développement de définition
\begin{equation}
    e=\exp(1)=\sum_{k=0}^{\infty}\frac{1}{ n! }.
\end{equation}
\lstinputlisting{tex/sage/sageSnip013.sage}

\begin{probleme}
    Comment trouver, avec cette méthode, un \emph{encadrement pour \( e\) ?}
\end{probleme}
    
Ce petit programme, avec \( 5\) termes donne \( e\simeq 65/24\simeq 2.708\). Avouez que c'est déjà bien mieux.

\begin{theorem}[Définition de l'exponentielle]  \label{ThoRWOZooYJOGgR}
    Les choses que nous savons sur l'exponentielle :
    \begin{enumerate}
        \item
            Il y a unicité de la solution à l'équation différentielle
            \begin{subequations}    \label{subeqBKJNooJQtbBD}
        \begin{numcases}{}
            y'=y\\
            y(0)=1.
        \end{numcases}
    \end{subequations}
    \item
        L'équation différentielle \eqref{subeqBKJNooJQtbBD} possède une solution donnée par la série entière\nomenclature[Y]{\( \exp\)}{exponentielle}
        \begin{equation}    \label{EqUARSooKXnQxu}
        \exp(x)=\sum_{k=0}^{\infty}\frac{ x^k }{ k! }
    \end{equation}
\item
    Cette solution est une bijection \( y\colon \eR\to \mathopen] 0 , \infty \mathclose[\).
    \item   \label{ItemYTLTooSnfhOu}
        La fonction \( y\) ainsi définie est de classe \(  C^{\infty}\).
\item
    Elle est également donnée par la formule
    \begin{equation}
        \exp(x)=e^x
    \end{equation}
    où \( e\) est définit par \( e=\exp(1)\).
\item
    Elle vérifie
    \begin{equation}        \label{EQooVFXUooBfwjJY}
        e^{a+b}= e^{a} e^{b}
    \end{equation}
    \end{enumerate}
\end{theorem}
Nous nommons \defe{exponentielle}{exponentielle} cette fonction.

\begin{proof}
    Point par point.
    \begin{enumerate}
        \item
            C'est la proposition \ref{PropDJQSooYIwwhy}.
        \item 
            C'est le théorème \ref{ThoKRYAooAcnTut}.
        \item
            Le rayon de convergence de la série \eqref{EqUARSooKXnQxu} est infini (théorème \ref{ThoKRYAooAcnTut}); elle est donc définie sur \( \eR\). Le fait que ce soit une bijection est dû au fait qu'elle est strictement croissante (proposition \ref{PropTLECooEiLbPP}) ainsi qu'aux limite \eqref{EqLOIUooHxnEDn}.
        \item
            Vu que \( y=y'\), \( y\) est dérivable. Mais comme \( y'\) est alors égale à une fonction dérivable, \( y'\) est dérivable. En dérivant l'égalité \( y'=y\) nous obtenons \( y''=y'\) et le jeu continue.
        \item
            C'est la proposition \ref{PropCELWooLBSYmS}.
        \item
            C'est la proposition \ref{PROPooGGUIooExVHPM}\ref{ITEMooMPSUooWQpVQJ}.
    \end{enumerate}
\end{proof}

\begin{example}[Un endomorphisme sans polynôme annulateur\cite{RombaldiO}]     \label{ExooLRHCooMYLQTU}
    l'exponentielle permet de donner un exemple d'un endomorphisme n'ayant pas de polynôme annulateur\footnote{Voir la définition \ref{DefooOHUXooNkPWaB} et ce qui suit.} : l'endomorphisme de dérivation
    \begin{equation}
        \begin{aligned}
            D\colon C^{\infty}(\eR,\eR)&\to  C^{\infty}(\eR,\eR) \\
            f&\mapsto f' 
        \end{aligned}
    \end{equation}
    n'a pas de polynôme annulateur. En effet supposons que \( P=\sum_{k=0}^{p}a_kX^k\) en soit un, et considérons les fonctions \( f_{\lambda}\colon t\mapsto  e^{\lambda t}\). Nous avons
    \begin{equation}
            0=P(D)f_{\lambda}
            =\sum_ka_kD^k(f_{\lambda})
            =\sum_ka_k\lambda^kf_{\lambda}
            =P(\lambda)f_{\lambda}.
    \end{equation}
    Par conséquent \( \lambda\) est une racine de \( P\) pour tout \( \lambda\in \eR\). Cela implique que \( P=0\).
    
    D'ailleurs si on y pense bien, cet exemple n'est qu'un habillage de l'exemple \ref{ExooDTUJooIMqSKn}.
\end{example}

\begin{proposition}\label{ExZLMooMzYqfK}
    Quelque propriétés du logarithme.
    \begin{enumerate}
        \item
            Le logarithme est une application dérivable et strictement croissante.
        \item
            Le logarithme est la primitive de \( x\mapsto\frac{1}{ x }\) qui s'annule en \( x=1\).
    \end{enumerate}
\end{proposition}

\begin{proof}
    Elle est donc bijective, d'inverse continue et dérivable par le théorème \ref{ThoKBRooQKXThd} et la proposition \ref{PropMRBooXnnDLq}. 

    La dérivée de la fonction logarithme peut être calculée en utilisant la formule \eqref{EqWWAooBRFNsv}, mais aussi de façon plus piettone en écrivant l'expression suivante, valable pour tout \( x\in \eR\) :
    \begin{equation}
        \ln\big( \exp(x) \big)=x,
    \end{equation}
    que nous pouvons dériver en utilisant le théorème de dérivation des fonctions composées :
    \begin{equation}
        \ln'\big( \exp(x) \big)\exp'(x)=1.
    \end{equation}
    Mais \( \exp'(x)=x\), donc
    \begin{equation}
        \ln'(y)=\frac{1}{ y }
    \end{equation}
    pour tout \( y\) dans l'image de \( \exp\), c'est à dire pour tout \( y\) dans l'ensemble de définition de \( \ln\).

    Par ailleurs, \( \exp(0)=1\) donc
    \begin{equation}
        \ln(1)=\ln\big( \exp(0) \big)=0.
    \end{equation}

    En ce qui concerne l'unicité d'une primitive s'annulant en \( x=1\), c'est le corollaire \ref{CorZeroCst}.
\end{proof}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Autres propriétés et petits calculs}
%---------------------------------------------------------------------------------------------------------------------------

\begin{lemma}
Si \( u\colon \eR\to \mathopen] 0 , \infty \mathclose[\) est dérivable alors \( \ln(u)'=\dfrac{ u' }{ u }\).
\end{lemma}

\begin{proof}
    Cela est une conséquence du théorème de dérivation des fonctions composées : si \( g(x)=\ln(u(x))\) alors
    \begin{equation}
        g'(x)=\ln'\big( u(x) \big)u'(x)=\frac{1}{ u(x) }u'(x).
    \end{equation}
\end{proof}

\begin{example}[Primitive du logarithme]\label{primln}
    La primitive de la fonction logarithme définie en \ref{DEFooELGOooGiZQjt} nous offre un bon moment d'intégration par partie.

    Trouver la primitive de la fonction \( x\mapsto \ln(x)\). Pour calculer
    \begin{equation}
        \int\ln(x)dx
    \end{equation}
    nous écrivons \( \ln(x)=1\times \ln(x)\) et nous posons \( u'=1\) et \( v=\ln(x)\), c'est à dire
    \begin{equation}
        \begin{aligned}[]
            u'&=1&v=\ln(x)\\
            u&=x&v'=\frac{1}{ x }.
        \end{aligned}
    \end{equation}
    La formule d'intégration par parties \eqref{EQooKISBooQvGMQT} donne donc 
    \begin{equation}
        \int \ln(x)=x\ln(x)-\int x\times \frac{1}{ x }=x\ln(x)-\int 1=x\ln(x)-x+C, \qquad C\in\eR.
    \end{equation}
    Il est facile de vérifier par un petit calcul que
    \begin{equation}
        \big( x\ln(x)-x \big)'=\ln(x).
    \end{equation}
\end{example}

\begin{lemma}   \label{LemPEYJooEZlueU}
Si \( a,b\in\mathopen] 0 , \infty \mathclose[\) alors
    \begin{equation}
        \ln(ab)=\ln(a)+\ln(b)
    \end{equation}
    et
    \begin{equation}    \label{EqOOZGooOWkGlA}
        \ln\left( \frac{1}{ b } \right)=-\ln(b).
    \end{equation}
\end{lemma}

\begin{proof}
    Nous posons \( f(x)=\ln(ax)\) qui est une fonction dérivable. Alors \( f'(x)=\frac{ a }{ ax }=\frac{1}{ x }\). Cette fonction \( f\) est donc une primitive de \( \frac{1}{ x }\) et il existe une constante \( K\) telle que
    \begin{equation}
        f(x)=\ln(x)+K.
    \end{equation}
    Vu que \( \ln(1)=0\) nous avons \( K=f(1)= \ln(a)\). Donc
    \begin{equation}
        \ln(ax)=\ln(x)+\ln(a).
    \end{equation}

    En ce qui concerne la seconde formule à démontrer, nous avons
    \begin{equation}
        \ln(1)=\ln\left( \frac{1}{ b }b \right)=\ln\left( \frac{1}{ b } \right)+\ln(b).
    \end{equation}
    Étant donné que $\ln(1)=0$ nous en déduisons la formule \eqref{EqOOZGooOWkGlA}.
\end{proof}

\begin{example}
    Montrons que la fonction\footnote{Pour la définition du logarithme, c'est la définition \ref{DEFooELGOooGiZQjt}.}
    \begin{equation}
        \begin{aligned}
            f\colon \eR_+\setminus\{ 0,1 \}&\to \eR \\
            x&\mapsto \frac{ \ln(x) }{ x-1 } 
        \end{aligned}
    \end{equation}
    admet un prolongement \( C^{\infty}\) sur \( \eR_+\setminus\{ 0 \}\).

    Nous allons étudier la fonction
    \begin{equation}
        f(x)=\frac{ \ln(1+x) }{ x }
    \end{equation}
    autour de \( x=0\). Le logarithme ne pose pas de problèmes à développer dans un voisinage :
    \begin{subequations}
        \begin{align}
            f(x)&=\frac{1}{ x }\sum_{n=1}^{\infty}\frac{ (-1)^{n+1} }{ n }x^n\\
            &=\sum_{n=1}^{\infty}\frac{ (-1)^{n+1} }{ n }x^{n-1}\\
            &=\sum_{n=0}^{\infty}\frac{ (-1)^k }{ k+1 }x^k.
        \end{align}
    \end{subequations}
    Cette série a un rayon de convergence égal à \( 1\), et donc définit sans problèmes une fonction \( C^{\infty}\) dans un voisinage de \( x=0\). Notons que par convention \( x^0=1\) même si \( x=0\).
\end{example}

\begin{example}     \label{EXooKNTPooKiRExX}
    Montrons que pour tout \( x\in\mathopen] -1 , 1 \mathclose[\) nous avons
    \begin{equation}        \label{EqweEZnV}
        -\ln(1-x)=\sum_{n=1}^{\infty}\frac{ x^n }{ n }.
    \end{equation}
    Nous calculerons ensuite la valeur de la série
    \begin{equation}    \label{EqKUQmOZ}
        \sum_{n=1}^{\infty}\frac{ (-1)^n }{ n }.
    \end{equation}

    La série \eqref{EqKUQmOZ} serait \( f(-1)=-\ln(2)\) où \( f\) est la série de fonctions \eqref{EqweEZnV}. Nous utilisons le théorème de convergence radiale d'Abel (théorème \ref{ThoLUXVjs}) pour justifier cette réponse :
    \begin{equation}
        \sum_n\frac{ (-1)^n }{ n }
    \end{equation}
    converge.
\end{example}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Vitesses de $x^{\alpha}$, de l'exponentielle et du logarithme}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Un peu de théorie}
%---------------------------------------------------------------------------------------------------------------------------

\begin{lemma}   \label{LemSYHKooUiSMFJ}
    Pour tout \( \alpha>0\), il existe \( N\) tel que \( \ln(n)\leq n^{\alpha}\) pour tout \( n\geq N\).
\end{lemma}

\begin{proof}
En effet, nous avons
\begin{equation}
    \lim_{x\to\infty} \frac{ x^{\alpha} }{ \ln(x) }=\lim_{x\to\infty} \frac{ \alpha x^{\alpha-1} }{ 1/x }=\lim_{x\to\infty} \alpha x^{\alpha}=\infty
\end{equation}
quand $\alpha>0$. 
\end{proof}
Cela tient également lorsque nous considérons $\ln(x)^p$ au lieu de $\ln(x)$. De cela, nous disons que le logarithme croit moins vite que n'importe quel polynôme. 

\begin{example}
    Par exemple nous avons \( \ln(1-x)\sim -x\) pour \( x\to 0\) parce que
    \begin{equation}    \label{EqGICpOX}
        \lim_{x\to 0} -\frac{ \ln(1-x) }{ x }=\lim_{x\to 0} -\frac{ \frac{ -1 }{ 1-x } }{ 1 }=\lim_{x\to 0} \frac{1}{ 1-x }=1
    \end{equation}
    où nous avons utilisé la règle de l'Hospital (proposition \ref{PROPooBZHTooHmyGsy}).
\end{example}

\begin{lemma}
    L'exponentielle croit plus vite que tout polynôme, et plus vite que que logarithme :
    \begin{equation}        \label{EqExpDecrtPlusVite}
        \lim_{t\to\infty} e^{-t}(\ln t)^{n}t^{\alpha}=0
    \end{equation}
    pour tout $n$ et pour tout $\alpha$.
\end{lemma}

\begin{lemma}       \label{LemVKDKooEftNzG}
    Nous avons aussi la limite utile suivante 
    \begin{equation}
        \lim_{n\to \infty} n^{\alpha}a^n
    \end{equation}
    pour tout \( \alpha>0\) et \( a<1\).
\end{lemma}

\begin{proof}
    En passant à l'exponentielle, pour chaque \( n\) nous avons
    \begin{equation}        \label{EqLKLQooLIlWgm}
        n^{\alpha}a^n= e^{\alpha\ln(n)+n\ln(a)}.
    \end{equation}
    Ce qui est dans l'exponentielle est
    \begin{equation}
        \alpha\ln(n)+n\ln(a)=n\big(\alpha \frac{ \ln(n) }{ n }+\ln(a) \big).
    \end{equation}
    Dans la parenthèse, \( \ln(a)<0\) et \( \frac{ \ln(n) }{ n }\to 0\). Donc ce qui est dans l'exponentielle \eqref{EqLKLQooLIlWgm} tend vers \( -\infty\) et au final l'expression demandée tend vers zéro.
\end{proof}

\begin{proposition} \label{PropBQGBooHxNrrf}
    Pour tout polynôme \( P\) et pour tout \( a>0\) la fonction \( f(x)=P(x) e^{-ax}\) est intégrable\footnote{Définition \ref{DefTCXooAstMYl}.} sur \( \mathopen[ 0 , \infty [\).
\end{proposition}

\begin{proof}
    Nous avons \( f(x)=P(x) e^{-ax/2} e^{-ax/2}\), et par la vitesse comparée des exponentielles et polynômes, pour un certain \( M>0\) nous pouvons affirmer que \( P(x) e^{-ax/2}<1\) sur \( \mathopen[ M , 0 [\). Dès lors
        \begin{equation}
            | f(x) |< e^{-ax/2},
        \end{equation}
        qui est intégrable.
\end{proof}

\begin{example}     \label{EXooAGEOooQdQkrS}
    La fonction logarithme (définition \ref{DEFooELGOooGiZQjt}) n'est pas définie pour \( x\leq 0\). Par conséquent la fonction \( f(x)=x\ln(|x|)\) n'est pas définie en \( x=0\). Elle est bien définie pour \( x<0\) et vérifie
    \begin{equation}
        \lim_{x\to 0} x\ln(|x|)=0.
    \end{equation}
    Nous pouvons donc définir la fonction
    \begin{equation}
        \begin{aligned}
            \tilde f\colon \eR&\to \eR \\
            x&\mapsto \begin{cases}
                x\ln(| x |)    &   \text{si } x\neq 0\\
                0    &    \text{si } x=0.
            \end{cases}
        \end{aligned}
    \end{equation}
    Contrairement à la fonction initiale \( f\), cette fonction \( \tilde f\) est définie et continue en \( 0\). 

    Notez que sur le graphe de la fonction \( \tilde f\), la courbe est bien régulière en \( x=0\).
    \begin{center}
       \input{auto/pictures_tex/Fig_XJMooCQTlNL.pstricks}
    \end{center}
\end{example}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Nombres premiers}
%---------------------------------------------------------------------------------------------------------------------------

\begin{theorem} \label{ThonfVruT}
    Soit \( P\), l'ensemble des nombres premiers. Alors la somme \( \sum_{p\in P}\frac{1}{ p }\) diverge et plus précisément,
    \begin{equation}
        \sum_{\substack{p\leq x\\p\in P}}\frac{1}{ p }\geq \ln(\ln(x))-\ln(2).
    \end{equation}
\end{theorem}
\index{nombre!premier}
\index{convergence!rapidité}
\index{série!numérique}

\begin{proof}
    Nous posons
    \begin{equation}
        S_x=\{  q\leq x\text{ avec } q\text{ sans facteurs carrés} \}
    \end{equation}
    et
    \begin{equation}
        P_x=\{ p\in P\tq p\leq x \}.
    \end{equation}
    Si
    \begin{equation}
        K_x=\{  (q,m)\text{ tels que } q\text{ n'a pas de facteurs carrés et } qm^2\leq x \},
    \end{equation}
    alors nous avons
    \begin{equation}
        K_x=\bigcup_{q\in S_x}\bigcup_{m\leq \sqrt{x/q}}(q,m).
    \end{equation}
    Par définition et par le lemme \ref{LemheKdsa} nous avons aussi
    \begin{equation}
        \{ n\leq x \}=\{ qm^2\tq (q,m)\in K_x \}.
    \end{equation}
    Tout cela pour décomposer la somme
    \begin{equation}        \label{EqpoJpuC}
        \sum_{n\leq x}\frac{1}{ n }=\sum_{q\in S_x}\sum_{m\leq\sqrt{x/q}}\frac{1}{ m^2 }\leq \sum_{q\in S_x}\frac{1}{ q }\underbrace{\sum_{m\geq 1}\frac{1}{ m^2 }}_{=C}.
    \end{equation}
    Nous avons aussi
    \begin{subequations}
        \begin{align}
            \prod_{p\in P_x}\left( 1+\frac{1}{ p } \right)&=1+\sum_{p\in P_x}\frac{1}{ p }+\sum_{\substack{p,q\in P_x\\p<q}}\frac{1}{ pq }+\sum_{\substack{p,q,r\in P_x\\p<q<r}}\frac{1}{ pqr }+\ldots\\
            &\geq 1+\sum_{p\in P_x}\frac{1}{ p }+\sum_{\substack{p,q\in P_x\\pq\leq x}}\frac{1}{ pq }+\sum_{\substack{p,q,r\in P_x\\pqr\leq x}}\frac{1}{ pqr }+\ldots
        \end{align}
    \end{subequations}
    Les sommes sont finies. Les sommes s'étendent sur toutes les façons de prendre des produits de nombres premiers distincts de telle sorte de conserver un produit plus petit que \( x\); c'est à dire que les sommes se résument en une somme sur les éléments de \( S_x\) :
    \begin{equation}        \label{EqooilOz}
        \exp\left( \sum_{p\in P_x}\frac{1}{ p } \right)\geq\prod_{p\in P_x}\left( 1+\frac{1}{ p } \right)\geq \sum_{q\in S_x}\frac{1}{ q }.
    \end{equation}
    La première inégalité est simplement le fait que \( 1+u\leq e^u\) si \( u\geq 0\) (directe de la définition \ref{ThoRWOZooYJOGgR}). Les inégalités suivantes proviennent du fait que le logarithme est une primitive de la fonction inverse (proposition \ref{ExZLMooMzYqfK}) :
    \begin{equation}
        \ln(x)\leq \sum_{n\geq x}\int_{n}^{n+1}\frac{dt}{ t }\leq \sum_{n\geq x}\frac{1}{ n }.
    \end{equation}
    Nous prolongeons ces inégalités avec les inégalités \eqref{EqpoJpuC} et \eqref{EqooilOz} :
    \begin{equation}
        \ln(x)\leq \sum_{n\geq x}\frac{1}{ n }\leq C\sum_{q\in S_x}\frac{1}{ q }\leq C\leq \exp\left( \sum_{p\in P_x}\frac{1}{ p } \right).
    \end{equation}
    En passant au logarithme,
    \begin{equation}
        \ln\big( \ln(x) \big)\leq\ln(C)+\sum_{p\in P_x}\frac{1}{ p }.
    \end{equation}
    Ceci montre la divergence de la série de droite. Nous cherchons maintenant une borne pour \( C\). Pour cela nous écrivons
    \begin{subequations}
        \begin{align}
            \sum_{n=1}^N\frac{1}{ n^2 }&\leq 1+\sum_{n=2}\frac{1}{ n(n-1) }\\
            &=1+\sum_{n=2}^N\left( \frac{1}{ n-1 }-\frac{1}{ n } \right)\\
            &=1+1-\frac{1}{ N }\\
            &\leq 2.
        \end{align}
    \end{subequations}
    Donc \( C\leq 2\).
\end{proof}
Ce théorème prend une nouvelle force en considérant le théorème de Müntz \ref{ThoAEYDdHp} qui dit qu'alors l'ensemble \( \Span\{ x^p\tq  p\text{ est premier} \}\) est dense dans les fonctions continues sur \( \mathopen[ 0 , 1 \mathclose]\) muni de la norme uniforme ou \( \| . \|_2\).

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Quelques limites}
%---------------------------------------------------------------------------------------------------------------------------

Nous voyons à présent quelques calculs de limite et de développements mettant en scène des logarithmes et exponentielles.

\begin{example}\label{compose1}
    Pour trouver le développement de la fonction \( f(x)= e^{-2x}\), il suffit d'écrire celui de \( e^t\) et de remplacer ensuite $t$ par \( -2x\). Le développement à l'ordre \( 3\) de la fonction exponentielle est :
    \begin{equation}
        e^t=1+t+\frac{ t^2 }{2}+\frac{ t^3 }{ 6 }+t^3\alpha(t).
    \end{equation}
    Le développement de \( f(x)= e^{-2x}\) sera donc 
    \begin{equation}
        f(x)=1-2x+\frac{ 4x^2 }{ 2 }-\frac{ 8x^3 }{ 6 }-8x^3\alpha(-2x).
    \end{equation}
    Donc le polynôme de degré \( 3\) partie régulière de \( g\) est :
    \begin{equation}
        1-2x+2x^2-\frac{ 4 }{ 3 }x^3,
    \end{equation}
    et la fonction reste correspondante est :
    \begin{equation}
        \alpha_g(x)=-8\alpha(-2x).
    \end{equation}
\end{example}

\begin{example}
    Nous savons les développements
    \begin{equation}
        f(x)=\ln(1+x)\sim x-\frac{ x^2 }{ 2 }+\frac{ x^3 }{ 3 }
    \end{equation}
    et
    \begin{equation}
        \sin(x)\sim x-\frac{ x^3 }{ 6 }.
    \end{equation}
    Nous obtenons le développement d'ordre \( 3\) de la fonction \( x\mapsto \ln\big( 1+\sin(x) \big)\) en écrivant
    \begin{equation}    \label{EqGXMooWKQkIL}
        \ln\big( 1+\sin(x) \big)\sim \big( x-\frac{ x^3 }{ 6 } \big)-\frac{ 1 }{2}\left( x-\frac{ x^3 }{ 6 } \right)^2+\frac{1}{ 3 }\left( x-\frac{ x^3 }{ 6 } \right)^3.
    \end{equation}
    Il s'agit maintenant de trouver les termes qui sont de degré inférieur ou égale à \( 3\).

    D'abord
    \begin{equation}
        \left( x-\frac{ x^3 }{ 6 } \right)^2=x^2-\frac{ x^4 }{ 3 }+\frac{ x^6 }{ 36 }\sim x^2
    \end{equation}
    Nous avons alors aussi
    \begin{equation}
        \left( x-\frac{ x^3 }{ 6 } \right)^6\sim x^2\left( x-\frac{ x^3 }{ 6 } \right)\sim x^3.
    \end{equation}
    En replaçant tout ça dans \eqref{EqGXMooWKQkIL} nous trouvons
    \begin{equation}
        \ln\big( 1+\sin(x) \big)\sim x-\frac{ x^2 }{2}+\frac{ x^3 }{ 6 }.
    \end{equation}
\end{example}

\begin{example}	\label{ExBCDookjljhjk}
    Calculer
    \begin{equation}\label{EqABCoolkjh}
        \lim_{x\to \infty}  e^{1/x}\sqrt{1+4x^2}-2x.
    \end{equation}
    Nous allons effectuer un développement asymptotique de la partie «difficile» de l'expression posant d'abord $x=1/h$. Si $f(x)=e^{1/x}\sqrt{1-4x^2}$ alors
    \begin{equation}
	g(h)=\frac{1}{|h|}e^h\sqrt{h^2+4}=\frac{1}{h}\big(  1+h+h\alpha(h) \big)\big( 2+h\beta(h) \big).
    \end{equation}
    La première parenthèse est le développement de $e^h$ et la seconde celui de $\sqrt{h^2+4}$. Nous nous apprêtons à faire la limite $x\to\infty$ qui correspond à $h\to 0^+$, nous pouvons donc supposer que $h>0$ et omettre la valeur absolue. En effectuant le produit et en regroupant tous les termes contenant $h^2$, $\alpha(h)$ ou $\beta(h)$ dans un seul terme $h\gamma(h)$,
    \begin{equation}
	f(h)=\frac{1}{h}\big(  2+2h+h\gamma(h) \big)=\frac{2}{h}+2+\gamma(h)=2x+2+\gamma(1/x)
    \end{equation}
    où $\gamma$ est une fonction vérifiant $\lim_{t\to 0}\gamma(t)=0$.

    Nous sommes maintenant en mesure de calculer la limite \eqref{EqABCoolkjh} :
    \begin{equation}
	\lim_{x\to\infty}e^{1/x}\sqrt{1+x^2}-2x= \lim_{x\to \infty}\big(  2x+2+\gamma(1/x)-2x \big)=2.
    \end{equation}
\end{example}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Trigonométrie hyperbolique}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{definition}
    Les fonctions \defe{sinus hyperbolique}{sinus!hyperbolique} et \defe{cosinus hyperbolique}{cosinus!hyperbolique} sont les fonctions définies sur $\eR$ par les formules suivantes :
    \begin{subequations}
        \begin{align}
            \cosh(x)&=\frac{  e^{x}+ e^{-x} }{2}\\
            \sinh(x)&=\frac{  e^{x}- e^{-x} }{2}
        \end{align}
    \end{subequations}
\end{definition}

Leurs principales propriétés sont :
\begin{enumerate}
    \item
        \( \cosh^2(x)-\sinh^2(x)=1\)
    \item
        \( \cosh'(x)=\sinh(x)\) 
    \item
        \( \sinh'(x)=\cosh\).
\end{enumerate}

Les représentations graphiques sont ceci :
\begin{center}
   \input{auto/pictures_tex/Fig_UNVooMsXxHa.pstricks}
\end{center}

La \defe{tangente hyperbolique}{tangente hyperbolique} est donnée par le quotient
\begin{equation}
    \tanh(x)=\frac{ \sinh(x) }{ \cosh(x) }.
\end{equation}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Séries entières de matrices}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Différentiabilité}
%---------------------------------------------------------------------------------------------------------------------------

\begin{proposition} \label{PropAMBXKgV}
    Soit \( (a_n)\) une suite dans \( \eC\) de rayon de convergence \( R\) et la fonction
    \begin{equation}
        \begin{aligned}
            f\colon \eM(n,\eR)&\to \eM(n,\eR) \\
            A&\mapsto \sum_{k=0}^{\infty}a_kA^k 
        \end{aligned}
    \end{equation}
    Alors
    \begin{enumerate}
        \item
            La différentielle de \( f\) sur \( B(0,R)\) est
            \begin{equation}    \label{EqRDVodDa}
                df_A(U)=\sum_{k=0}^{\infty}a_k\sum_{l=0}^{k-1}A^lUA^{k-1-l},
            \end{equation}
            c'est à dire que l'on peut différentier terme à terme. (Ici c'est \( A\) qui est dans \( B(0,R)\))
        \item
            La convergence de la somme \ref{EqRDVodDa} est absolue.
        \item
            La convergence de la somme \ref{EqRDVodDa} est normale sur tout compact.
        \item
            La fonction \( f\) est de classe \( C^1\) sur \( B(0,R)\), c'est à dire que la fonction \( A\mapsto df_A\) est continue.
    \end{enumerate}
\end{proposition}
Notons que \( df_A\) n'est pas tout à fait une série entière. Cependant, en ce qui concerne les normes, c'est tout comme si ça l'était.

\begin{proof}
    Nous posons \( u_k(A)=a_kA^k\), qui est une fonction de classe \(  C^{\infty}\) et dont la différentielle est donnée par
    \begin{equation}
        (du_k)_A(U)=\Dsdd{ u_k(A+tU) }{t}{0}=a_k\Dsdd{ (A+tU)^k }{t}{0};
    \end{equation}
    en distribuant le produit nous trouvons tout un tas de termes dont seuls ceux contenant exactement une fois \( tU\) ne vont pas s'annuler. Étant donné que \( U\) et \( A\) ne commutent pas nous avons l'expression un peu moche
    \begin{equation}
        (du_k)_A(U)=\sum_{l=0}^{k-1}a_kA^lUA^{k-1-l}.
    \end{equation}
    En ce qui concerne la norme, nous regardons celle de \( (du_k)_A\) pour un \( A\) fixé; c'est à dire que nous en regardons la norme opérateur :
    \begin{equation}
        \| (du_k)_A \|=\sup_{\| U \|=1}\| \sum_{l=0}^{k-1}a_kA^lUA^{k-1-l} \|\leq \sum_{l=0}^{k-1}| a_k |\| A \|^{l}\| A \|^{k-1-l}\leq k| a_k |\| A \|^{k-1}.
    \end{equation}
    Pour donner la convergence nous considérons un nombre \( r\) tel que \( \| A \|<r<R\), de telle sorte que la suite \( (a_nr^n)\) soit bornée par un nombre \( M\) et que nous puissions écrire
    \begin{equation}    \label{EqTGEwhnL}
        \| (du_k)_A \|\leq k| a_k |\| A \|^{k-1}=\frac{ k| a_k |\| A \|^k }{ \| A \| }=\frac{ k| a_k | }{ \| A \| }r^k\left( \frac{ \| A \| }{ r } \right)^k\leq \frac{ M }{ \| A \| }k\left( \frac{ \| A \| }{ r } \right)^k,
    \end{equation}
    dont la série converge. Nous avons donc convergence absolue de la série
    \begin{equation}
        \sum_{k=0}^{\infty}(du_k)_A.
    \end{equation}
    Passons à la convergence normale sur tout compact. Nous nous fixons \( r<R\) et nous nous intéressons à la norme de \( du_k\) sur \( \overline{ B(0,r) }\), c'est à dire
    \begin{equation}
        \| du_k \|_{\infty}=\sum_{x\in\overline{ B(0,r) }}\| (du_k)_A \|.
    \end{equation}
    Vu que \( \overline{ B(0,r) }\) est compact, ce supremum est un maximum et nous pouvons noter \( A_k\) la matrice qui le réalise. Nous réalisons alors les mêmes manipulations que pour \eqref{EqTGEwhnL} :
    \begin{equation}
        \| du_k \|_{\infty}=\| (du_k)_{A_k} \|\leq k| a_k |\| A_k \|^{k-1}\leq  k| a_k |r^{k-1}=\frac{1}{ r }k| a_k |r^k.
    \end{equation}
    Nous prenons maintenant \( r<r_0<R\) et \( M\), un majorant de \( (a_nr_0^n)\), de telle sorte qu'en multipliant et divisant par \( r_0^k\),
    \begin{equation}
        \| du_k \|_{\infty}\leq \frac{ k| a_k |r_0^k }{ r }\frac{ r^k }{ r_0^k }\leq \frac{ kM }{ r }\left( \frac{ r }{ r_0 } \right)^k,
    \end{equation}
    dont la série converge. Nous avons donc convergence normale sur tout compact. Par voie de \sout{fait} conséquences nous avons continuité de la série
    \begin{equation}
        \sum_{k=0}^{\infty}(du_k)_A
    \end{equation}
    et convergence vers \( df_A\) par le théorème \ref{ThoLDpRmXQ}.
\end{proof}

\begin{proposition} \label{PropQIIURAh}
    Si le rayon de convergence de la série \( u(A)=\sum_{k=0}^{\infty}a_kA^k\) est \( R\), alors 
    \begin{enumerate}
        \item
            elle converge normalement sur tout compact de \( B(0,R)\);
        \item
            la fonction \( u\) y est de classe \(  C^{\infty}\).
    \end{enumerate}
\end{proposition}

\begin{proof}
    Nous posons 
    \begin{equation}
        \begin{aligned}
            u_k\colon \eM(n,\eR)&\to \eM(n,\eR) \\
            A&\mapsto a_kA^k 
        \end{aligned}
    \end{equation}
    qui est évidemment une fonction de classe \(  C^{\infty}\). Nous étudions la \( j\)\ieme\ différentielle en \( m\), pour \( k>j\) (dans une série, nous ne nous intéressons pas aux premiers termes). La \( j\)\ieme\ différentielle appliquée à \( v_1\) appliquée à \( v_2\), etc s'exprime de la façon suivante :
    \begin{equation}
        (d^ju_k)_m(v_1,\ldots, v_j)=\frac{ d  }{ d t_1 }\ldots\frac{ d  }{ d t_j }\Big( u_k(m+t_1v_1+\cdots +t_jv_j)    \Big)_{t_i=0}.
    \end{equation}
    Dans le produit \( (m+t_1v_1+\cdots +t_jv_j)^k\), seuls les termes contenant exactement une fois chacun des \( t_i\) ne s'annulera pas après avoir fait la dérivée et évalué en \( t_i=0\). Combien de termes cela fait ? Parmi les \( k\) facteurs, il faut en placer \( j\) qui ne sont pas \( m\) (cela fait \( \binom{ k }{ j }\) possibilités), et puis il faut ordonner ces \( j\) termes, cela fait encore \( j!\) possibilités. Au final,
    \begin{equation}
        \| (d^ju_k)_m \|\leq | a_k | \binom{ k }{ j }j!\| m \|^{k-j}=| a_k |P(k)\| m \|^{k-j}
    \end{equation}
    où \( P(k)=\frac{ k! }{ (k-j)! }\) est un polynôme de degré \( j\).

    Afin d'étudier la convergence normale sur tout compact de la série des \( d^ju_k\), nous considérons \( r<r_0<R\) et nous allons prouver la convergence normale sur \( \overline{ B(0,r) }\). Vu que c'est un compact, il existe une matrice \( m_k\in\overline{ B(0,r) }\) telle que
    \begin{subequations}
        \begin{align}
            \| d^ju_k \|_{\infty}&=\| (d^ju_k)_{m_k} \|\\
            &\leq | a_k |P(k)\| m_k \|^{k-j}\\
            &\leq | a_k |P(k)r^{k-j}\\
            &=\frac{ | a_k |P(k) }{ r^j }r^k\\
            &=\frac{ | a_k |r_0^kP(k) }{ r^j }\left( \frac{ r }{ r_0 } \right)^k\\
            &\leq \frac{ M }{ r^j }P(k)\left( \frac{ r }{ r_0 } \right)^k
        \end{align}
    \end{subequations}
    où \( M\) est un majorant de \( a_nr^n\). Vu que \( r_0/r<1\), la somme sur \( k\) converge et nous avons convergence normale sur tout compact de
    \begin{equation}
        d^j\sum_{k=0}^{\infty}a_kA^k=\sum_{k=0}^{\infty}d^j(a_kA^k)
    \end{equation}
    avec un peu d'abus de notation.
\end{proof}

