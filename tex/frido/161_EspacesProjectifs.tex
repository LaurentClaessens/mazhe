% This is part of Mes notes de mathématique
% Copyright (c) 2011-2019, 2023-2024
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.

Sur les espaces projectifs : \cite{ProjRolland}.

\begin{definition}
	Soit \( E\) un espace vectoriel de dimension finie sur le corps commutatif \( \eK\). Nous définissons sur \( E\setminus\{ 0 \}\) la relation d'équivalence \( u\sim v\) si et seulement si \( u=\lambda v\) pour un certain \( \lambda\in\eK\). Cette relation est la relation de \defe{colinéarité}{colinéarité}. L'ensemble des classes d'équivalence de \( \sim\) est l'\defe{espace projectif}{espace!projectif}\index{projectif!espace} de \( E\) et sera noté \( P(E)\)\nomenclature[G]{$ P(E)$}{l'espace projectif de $E$}.
\end{definition}

\begin{definition}  \label{DEFooTPPMooTDxNpg}
	Si \( \dim E=2\), l'ensemble \( P(E)\) est la \defe{droite projective}{droite!projective}\index{projectif!droite}, et si \( \dim E=3\) nous parlons du \defe{plan projectif}{plan!projectif}\index{projectif!plan}.
\end{definition}

Étant donné que tous les \( \eK\)-espaces vectoriels de dimensions \( n+1\) sont isomorphes à \( \eK^{n+1}\), nous noterons \( P_n(\eK)\) ou \( P_n\) l'espace projectif \( P(\eK^{n+1})\). \label{PgNotimesjNtMoW}

\begin{example}
	Si \( n=1\) et \( \eK=\eR\), l'espace projectif est l'ensemble des droites vectorielles dans le plan usuel. Il y en a une pour chaque point du type \( (x,1)\) avec \( x\in\eR\) et ensuite une horizontale, passant par le point \( (1,0)\). Nous avons donc
	\begin{equation}
		P_1(\eR)=\{ (1,0) \}\cup\{ (x,1)\tq x\in \eR \}.
	\end{equation}
	Le point \( (1,0)\) est dit «point à l'infini».
\end{example}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Sous-espaces projectifs}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Un \defe{sous-espace projectif}{projectif!sous-espace} de \( P(E)\) est une partie de la forme \( P(F)\) où \( F\) est un sous-espace vectoriel de \( E\).

\begin{proposition}     \label{PropuqpWVx}
	Si \( F\) et \( G\) sont des sous-espaces vectoriels de \( E\), alors
	\begin{equation}
		P(F)\cap P(G)=P(F\cap G)
	\end{equation}
	et nous avons
	\begin{equation}        \label{EqNAdWfN}
		\dim P(F)+\dim P(G)=\dim P(F+G)+\dim P(F\cap G).
	\end{equation}
\end{proposition}

\begin{proof}
	Nous avons
	\begin{equation}
		P(F)=\{ [v]\tq v\in F \}
	\end{equation}
	où les crochets signifient la classe par rapport à la relation de colinéarité. Nous avons alors
	\begin{equation}
		P(F)\cap P(G)=\{ [v]\tq v\in F\cap G \}=P(F\cap G).
	\end{equation}
	Cela prouve le premier point.

	En ce qui concerne l'équation \eqref{EqNAdWfN}, en considérant \( \dim P(E)=\dim E-1\) nous devons prouver l'égalité
	\begin{equation}
		\dim F+\dim G=\dim (F+G)+\dim(F\cap G)
	\end{equation}
	concernant les dimensions des espaces vectoriels usuelles. Si nous considérons une base de \( E\) telle que \( B_1=\{ e_1,\ldots, e_{k_1} \}\) est une base de \( F\cap G\), \( B_2=\{ e_{k_1+1},\ldots, e_{k_2} \}\) complète \( B_1\) en une base de \( F\) et \( B_3=\{ e_{k_2+1},\ldots, e_n \}\) complète \( B_1\cup B_2\) en une base de \( G\).

	Nous avons alors
	\begin{subequations}
		\begin{align}
			\dim F+\dim G & =2\Card(B_1)+\Card(B_2)+\Card(b_3) \\
			\dim(F+G)     & =\Card(B_1)+\Card(b_2)+\Card(B_3)  \\
			\dim(F\cap G) & =\Card(B_1).
		\end{align}
	\end{subequations}
	De là la relation \eqref{EqNAdWfN} se déduit immédiatement.
\end{proof}

\begin{theorem}[incidence]\index{théorème!incidence}
	Soient \( F\) et \( G\) deux sous-espaces vectoriels de \( E\) tels que
	\begin{equation}
		\dim P(F)+\dim P(G)\geq \dim P(E).
	\end{equation}
	Alors \( P(F)\cap P(G)\neq \emptyset\).
\end{theorem}

\begin{proof}
	En utilisant les hypothèses et la proposition~\ref{PropuqpWVx} nous avons
	\begin{equation}
		\dim P(E)+\dim P(G)=\dim P(F+G)+\dim P(F\cap G)\geq \dim P(E).
	\end{equation}
	En passant aux espaces vectoriels correspondants,
	\begin{equation}
		\dim(F+G)+\dim(F\cap G)\geq \dim(E)+1.
	\end{equation}
	Mais nous avons aussi \( \dim(F+G)\leq \dim(E)\) et par conséquent \( \dim(F\cap G)\geq 1\). Au final, \( \dim P(F\cap G)\geq 0\). Cela prouve que \( P(F\cap G)\) contient au moins un élément (nous rappelons que lorsqu'un espace projectif contient un seul élément, sa dimension est zéro).
\end{proof}

\begin{example}
	Soient les plans \( \Pi_1\equiv x=0\) et \( \Pi_2\equiv y=0\). Nous avons
	\begin{subequations}
		\begin{align}
			P(\Pi_1) & =\{ [0,y,1] \}\cup\{ [0,1,0] \} \\
			P(\Pi_2) & =\{ [x,0,1] \}\cup\{ [1,0,0] \}
		\end{align}
	\end{subequations}
	où le crochet signifie la classe pour la colinéarité. Ces deux droites projectives ont comme point d'intersection le point \( [0,0,1]\).
\end{example}

\begin{definition}
	Un \defe{hyperplan projectif}{projectif!hyperplan} est un sous-espace projectif de \( P(E)\) de la forme \( P(V)\) où \( V\) est un hyperplan de \( E\).
\end{definition}

\begin{definition}      \label{DEFooBBMBooSVgTnn}
	Soit \( E\) un espace vectoriel de dimension au moins \( 3\). Nous disons que \( d\subset P(E)\) est une \defe{droite projective}{projectif!droite} de \( P(E)\) si \( d=P(D)\) pour un plan vectoriel \( D\subset E\).

	Nous disons que trois points de \( P(E)\) sont \defe{alignés}{alignement!dans un espace projectif} lorsqu'il existe une droite projective les contenant.
\end{definition}

\begin{normaltext}
	Dans la définition~\ref{DEFooBBMBooSVgTnn} nous voyons \( P(D)\) comme inclus dans \( P(E)\) dès que \( D\) est un sous-espace vectoriel de \( E\). Cela est possible parce que si la direction de \( v\in D\), c'est-à-dire la classe \( [v]\) est également une direction dans \( E\).
\end{normaltext}

Le lemme suivant peut paraitre idiot, mais ce qui serait surement idiot est de l'utiliser sans s'en rendre compte.

\begin{lemma}
	Deux points dans \( P(E)\) sont toujours alignés.
\end{lemma}

\begin{proof}
	Soient deux points \( A,B\in P(E)\). Si \( A=\pi(a)\) et \( B=\pi(b)\) alors le plan \( D\) passant par \( a\), \( b\) et \( 0\) est vectoriel et \( P(D)\) contient \( A\) et \( B\).

	Note : si \( a\), \( b\) et \( 0\) sont trois points alignés, alors \( A=B\). Il suffit de prendre les points \( a\), \( c\) et \( 0\) où \( c\in E\) est un point quelconque non aligné avec \( 0\) et \( a\). Nous avons de toutes façons \( A=B=\pi(a)\).
\end{proof}

\begin{lemma}
	Trois points distincts \( A\), \( B\), \( C\) dans \( P(E)\) sont alignés si et seulement si il existe trois points non alignés \( a,b,c\in E\) tels que
	\begin{enumerate}
		\item
		      le plan passant par \( a\), \( b\) et \( c\) est vectoriel (c'est-à-dire passe par \( 0\)),
		\item
		      \( A=\pi(a)\), \( B=\pi(b)\), et \( C=\pi(c)\).
	\end{enumerate}
\end{lemma}

\begin{proof}
	Deux implications à montrer.
	\begin{subproof}
		\spitem[Sens direct]
		Soient \( A\), \( B\), \( C\) distincts et alignés dans \( P(E)\). Alors il existe un plan vectoriel \( D\) tel que \( A,B,C\in P(D)\).

		La condition \( A\in P(D)\) implique qu'il existe \( a\in D\) tel que \( A=\pi(A)\). Idem pour \( B\) et \( C\). Les points \( a\), \( b\) et \( c\) ainsi construits sont distincts parce que \( A\), \( B\) et \( C\) sont distincts. Si par malheur ces trois points étaient alignés, ce n'est pas grave : il suffit de remplacer \( a\) par \( \lambda a\) avec \( \lambda\neq 0\) pour qu'ils ne le soient plus (cette manipulation ne change pas le fait que le nouveau choix de point \( a\) reste dans \( D\) parce que \( D\) est vectoriel). Nous avons donc trois points non alignés \( a\), \( b\) et \( c\) tous contenus dans \( D\). Le plan \( D\) répond à la question.

		\spitem[Sens réciproque]

		Soient \( a\), \( b\) et \( c\) non alignés dans \( E\) tels que \( A=\pi(a)\), \( B=\pi(b)\) et \( C=\pi(c)\). Le plan \( D\) les contenant tous trois est vectoriel par hypothèse. Nous avons \( A,B,C\in P(D)\) et donc \( A,B\) et \( C\) sont alignés dans \( P(E)\).
	\end{subproof}
\end{proof}

\begin{proposition}
	Soit \( H=P(V)\) un hyperplan projectif de \( P(E)\) et soit \( m\) hors de \( H\). Alors toute droite projective passant par \( m\) coupe \( H\) en un et un seul point.
\end{proposition}

\begin{proof}
	Si \( \dim E=n\) nous avons \( \dim V=n-1\). Soit \( d=P(D)\) une droite projective passant par \( m\), c'est-à-dire que \( D\) est de dimension \( 2\) dans \( E\). Si \( D\subset V\) alors \( m\in P(D)\subset P(V)\); or nous avons demandé que \( m\) soit hors de \( P(V)\). Par conséquent \( D\) n'est pas inclus dans \( V\) et en particulier \( \dim(D+V)=\dim(E)\).

	Nous recopions la formule \eqref{EqNAdWfN} pour notre cas :
	\begin{equation}
		\underbrace{\dim d}_{=1}+\underbrace{\dim H}_{=n-2}=\underbrace{\dim P(D+V)}_{=n-1}+\dim P(D\cap V).
	\end{equation}
	Nous avons donc \( \dim P(D\cap V)=0\), ce qui signifie que l'ensemble \( P(D\cap V)=P(D)\cap P(V)=d\cap H\) contient un et un seul point.
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Espace projectifs comme «complétés» d'espaces affines}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Soit \( E\) un espace vectoriel de dimension \( 2\) et \( P(E)\) la droite projective correspondante, et soit \( \{ e_1,e_2 \}\) une base de \( E\). Nous considérons la droite affine \( d\equiv y=1\). Nous avons la bijection
\begin{equation}        \label{EqvrfDLz}
	\begin{aligned}
		\phi\colon d\cup\{ \infty \} & \to P(E)                                                 \\
		(x,1)                        & \mapsto \text{la droite vectorielle passant par } (x,1)  \\
		\infty                       & \mapsto \text{la droite vectorielle passant par } (1,0).
	\end{aligned}
\end{equation}

\begin{lemma}
	Si nous munissons l'ensemble \( d\cup\{ \infty \}\) de la topologie compactifiée d'Alexandrov\footnote{Définition \ref{PROPooHNOZooPSzKIN}.}, la bijection \eqref{EqvrfDLz} est un homéomorphisme.
\end{lemma}

Soient maintenant les plans affines dans l'espace vectoriel \( E\) de dimension \( 3\)
\begin{subequations}
	\begin{align}
		\Pi_1\equiv z & =0  \\
		\Pi_2\equiv z & =1.
	\end{align}
\end{subequations}
Une droite (vectorielle) de \( E\) coupe \( \Pi_2\) en un et un seul point, sauf si elle est contenue dans \( \Pi_1\). Nous avons donc une bijection
\begin{equation}
	\begin{aligned}
		\phi\colon P(E) & \to \Pi_2\cup P(\Pi_1)                                          \\
		d               & \mapsto \begin{cases}
			                          \Pi_2\cap d & \text{si cette intersection est non vide} \\
			                          d           & \text{sinon.}
		                          \end{cases}
	\end{aligned}
\end{equation}
La droite projective \( P(\Pi_1)\) est la droite à l'infini du plan projectif \( P(E)\). Nous voyons que le plan projectif \( P(E)\) peut être vu comme un plan affine \( (\Pi_2)\) «complété»  par une droite affine \( P(\Pi_1)\). Cette dernière droite est elle-même une droite affine complétée par un point à l'infini.

Nous pouvons généraliser cette démarche en considérant un espace affine \( \affE\) de direction \( E\) sur le corps \( \eK\). Nous construisons \( F=E\times \eK\) et nous considérons un repère affine sur \( F\) tel que \( E\equiv x_{n+1}=0\). Nous pouvons donc identifier \( \affE\) à l'hyperplan affine d'équation \( x_{n+1}=1\) dans \( F\).

Une droite vectorielle de \( F\) non contenue dans \( E\) coupe \( \affE\) en un unique point; nous avons donc une bijection
\begin{equation}
	\affE\cup P(E)\to P(F).
\end{equation}
Dans ce cadre, \( P(E)\) est l'hyperplan à l'infini et nous disons que \( P(E)\) est la \defe{complétion projective}{complétion!projective}\index{projectif!complétion} de \( \affE\).

\begin{example}
	Nous considérons les plans affines
	\begin{subequations}
		\begin{align}
			\Pi_1 & \equiv z=0 \\
			\Pi_2 & \equiv z=1
		\end{align}
	\end{subequations}
	et nous avons la bijection
	\begin{equation}
		P(E)=\Pi_2\cup P(\Pi_1).
	\end{equation}
	Un plan vectoriel \( D\) a deux possibilités : soit il coupe \( \Pi_2\) en une droite, soit il est égal à \( \Pi_1\). Si \( D\cap\Pi_2=d\) (\( d\) est une droite affine), alors nous avons
	\begin{equation}
		P(D)=d\cup\{ \infty_D \},
	\end{equation}
	ce qui justifie la terminologie comme quoi \( P(D)\) est une droite dans \( P(E)\).
\end{example}

Soit \( E\) un espace vectoriel de dimension \( 3\) et le plan projectif \( P(E)\). Nous avons deux types de droites projectives :
\begin{enumerate}
	\item
	      D'abord nous avons la droite à l'infini, donnée\footnote{Dans notre représentation usuelle du plan projectif \( z=1\).} par \( P(z=0)\).
	\item
	      Ensuite nous avons toutes les droites affines du plan \( z=1\). Chacune de ces droites est complétée par un point à l'infini.
\end{enumerate}

\begin{example}     \label{ExempMyTmFp}
	Étudions un peu le second type de droites. D'abord si deux droites sont parallèles, leurs points à l'infini sont identiques. Prenons par exemple les droites \( d=\{ z=1,x=1 \}\) et \( d'=\{ z=1,x=2 \}\). Elles décrivent les directions des vecteurs
	\begin{equation}
		\begin{aligned}[]
			\begin{pmatrix}
				1 \\
				y \\
				1
			\end{pmatrix} &  & \text{et} &  &
			\begin{pmatrix}
				2 \\
				y \\
				1
			\end{pmatrix}.
		\end{aligned}
	\end{equation}
	En normalisant, ce sont les vecteurs
	\begin{equation}
		\begin{aligned}[]
			\frac{1}{ \sqrt{2+y^2} }\begin{pmatrix}
				                        1 \\
				                        y \\
				                        1
			                        \end{pmatrix} &  & \text{et} &  &
			\frac{1}{ \sqrt{5+y^2} }\begin{pmatrix}
				                        2 \\
				                        y \\
				                        1
			                        \end{pmatrix},
		\end{aligned}
	\end{equation}
	et toutes deux tendent vers le vecteur \( (0,1,0)\) pour \( y\to\infty\).
\end{example}

\begin{lemma}
	Deux droites d'un plan projectif ont toujours une intersection.
\end{lemma}

\begin{proof}
	Si les deux droites sont des droites affines non parallèles, le résultat est évident. Si elles sont parallèles, alors l'intersection est donnée par le point à l'infini comme indiqué dans l'exemple~\ref{ExempMyTmFp}.

	Supposons que \( d\) est la droite à l'infini tandis que \( d'\) est une droite affine. Dans notre représentation usuelle du plan affine, la droite à l'infini \( d\) a contient les vecteurs \( (1,y,0)\) et le point à l'infini \( (0,1,0)\). La droite affine \( d'\) a pour équation paramétriques
	\begin{subequations}
		\begin{numcases}{}
			x=at+c\\
			y=bt+d\\
			z=1.
		\end{numcases}
	\end{subequations}
	Les directions données par la droite \( d'\) sont donc
	\begin{equation}
		\frac{1}{ a^2t^2+b^2t^2+c^2+d^2}\begin{pmatrix}
			at+c \\
			bt+d \\
			1
		\end{pmatrix}
	\end{equation}
	Son point à l'infini est la direction du vecteur \( (a,b,0)\), qui est bien un point de la droite à l'infini (éventuellement son point à l'infini\footnote{D'accord, aller chercher le point à l'infini de la droite à l'infini, c'est chercher loin, mais n'empêche que ça existe.}).
\end{proof}

La plupart du temps nous considérons le plan projectif comme étant le plan affine \( z=1\) de l'espace affine de dimension \( 3\) complété par la droite affine \( x=1,z=0\), elle-même complétée par le point \( (0,1,0)\). Ce n'est évidemment pas la seule manière. Tout plan peut être considéré comme le plan à l'infini et pour une droite projective, tout point peut être considéré comme point à l'infini.

Sur la figure~\ref{LabelFigChoixInfinissLabelSubFigChoixInfini0}, le point à l'infini est la direction \( (1,0)\) tandis que la direction \( (1,1)\) n'a rien de spécial. À l'inverse sur la figure~\ref{LabelFigChoixInfinissLabelSubFigChoixInfini1}, la direction à l'infini est \( (1,1)\) tandis que la direction \( (1,0)\) est une direction usuelle.

%The result is on figure~\ref{LabelFigChoixInfini}.
\newcommand{\CaptionFigChoixInfini}{Deux façons de voir la droite projective. Étant donné que les points de la droite projective doivent être interprétés comme des directions (des classes d'équivalence), en réalité les deux dessins représentent les mêmes ensembles.}
\input{auto/pictures_tex/Fig_ChoixInfini.pstricks}

\begin{remark}
	Du point de vue de la topologie, si nous mettons celle de la compactification d'Alexandrov, tous les points de la droite projective sont équivalents.

	Du point de vue de la géométrie différentielle, c'est la même chose. En effet nous pouvons mettre sur la droite projective un système de deux cartes en pensant aux angles. La première sur \( \mathopen] -a , a \mathclose[\) avec par exemple \( a<\pi/4\). La seconde carte serait \( \mathopen] a/2 , \pi \mathclose[\). Dans ce cas la direction \( \theta=0\) semble jouer un rôle spécial, mais il n'en est rien.

		Nous pouvons également considérer les cartes \( \mathopen] \pi/4-a , \pi/4+a \mathclose[\) et \( \mathopen] \pi/4+a/2 , 5\pi/4 \mathclose[\). Dans ces cartes, c'est plutôt le point \( \theta=\pi/4\) qui semble différent (encore qu'il soit bien centré dans une carte).
\end{remark}


%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Théorème de Pappus}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{theorem}     \index{théorème!Pappus!affine}
	Soient deux droites \( d\) et \( d'\) dans un plan affine. Soient \( A,B,C\in d\) et \( A',B',C'\in d'\) tels que \( AB'\parallel BA'\) et \( BC'\parallel B'C\). Alors \( AC'\parallel A'C\).
\end{theorem}

\begin{proof}
	Si \( d\) et \( d'\) ne sont pas parallèles nous considérons \( o\), le point d'intersection. Les relations de parallélisme des hypothèses impliquent qu'il existe \( \lambda_1\) et \( \lambda_2\) tels que
	\begin{subequations}
		\begin{numcases}{}
			A=\lambda_1 B\\
			B'=\lambda_1 A'
		\end{numcases}
	\end{subequations}
	et
	\begin{subequations}
		\begin{numcases}{}
			B'=\lambda_2 C'\\
			C=\lambda_2 B.
		\end{numcases}
	\end{subequations}
	En substituant nous trouvons
	\begin{subequations}
		\begin{numcases}{}
			C=\frac{ \lambda_2 }{ \lambda_1 }A\\
			A'=\frac{ \lambda_2 }{ \lambda_1 }C',
		\end{numcases}
	\end{subequations}
	ce qui implique que \( A'C\parallel AC'\).

	Si les droites \( d\) et \( d'\) sont parallèles, alors nous avons les translations
	\begin{subequations}
		\begin{numcases}{}
			B=A+x\\
			A'=B'+x
		\end{numcases}
	\end{subequations}
	et
	\begin{subequations}
		\begin{numcases}{}
			B=C+y\\
			C'=B'+y,
		\end{numcases}
	\end{subequations}
	ce qui montre que
	\begin{subequations}
		\begin{numcases}{}
			C=A+x-y\\
			A'=C'+x-y,
		\end{numcases}
	\end{subequations}
	et donc que \( A'C\parallel AC'\).
\end{proof}

Le théorème suivant est une version projective.
\begin{theorem}     \index{théorème!Pappus!projectif}
	Soient \( d\) et \( d'\) deux droites projectives d'un plan projectif. Soient \( A,B,C\in d\) et \( A',B',C'\in d'\). Alors les points \( B'C\cap C'B\), \( C'A\cap A'C\) et \( A'B\cap B'A\) sont alignés.
\end{theorem}

\begin{proof}
	Soient \( E=B'C\cap C'B\) et \( E'=C'A\cap A'C\). Ces deux points existent parce que deux droites projectives distinctes ont toujours un unique point d'intersection. Nous allons prendre \( EE'\) comme droite à l'infini et prouver que le point \( A'B\cap B'A\) est dessus. Étant donné que le point d'intersection de \( B'C\) et \( C'B\) est à l'infini nous avons \( B'C\parallel C'B\) (cela est un exemple de la flexibilité de la notion de parallélisme en géométrie projective). De la même façon nous avons \( C'A\parallel A'C\).

	Par le théorème de Pappus affine nous avons alors \( A'B\parallel B'A\) et par conséquent le point d'intersection est sur la droite à l'infini, c'est-à-dire sur la droite \( EE'\).
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Homographies}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Homographies}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}      \label{DEFooKWSMooXvOeEP}
	Soient \( E\) et \( F\) deux espaces vectoriels avec leurs projections naturelles
	\begin{subequations}
		\begin{align}
			\pi_E\colon E\setminus\{ 0 \} & \to P(E)  \\
			\pi_F\colon F\setminus\{ 0 \} & \to P(F).
		\end{align}
	\end{subequations}
	Une application \( g\colon P(E)\to P(F)\) est une \defe{homographie}{homographie} si il existe un isomorphisme d'espaces vectoriels \( \bar g\colon E\to F\) tel que le diagramme
	\begin{equation}
		\xymatrix{%
			E\setminus\{ 0 \} \ar[r]^{\bar g}\ar[d]_{\pi_E}        &   F\setminus\{ 0 \}\ar[d]^{\pi_F}\\
			P(E) \ar[r]_{g}   &   P(F)
		}
	\end{equation}
	commute, c'est-à-dire si il existe \( \bar g\colon E\to F\) telle que
	\begin{equation}        \label{EQooSEFWooRpjLxt}
		\pi_F\big( \bar g(v) \big)=g\big( \pi_E(v) \big)
	\end{equation}
	pour tout \( v\in E\).
\end{definition}

\begin{lemma}
	Si \( \bar g\colon E\to F\) est linéaire et si \( \ker\bar g=\{ 0 \}\) alors l'application \( g\) définie par
	\begin{equation}        \label{EqRlGIJW}
		g\big( \pi_E(v) \big)=\pi_F\big( \bar g(v) \big)
	\end{equation}
	est une homographie.
\end{lemma}

\begin{proof}
	Nous devons simplement vérifier que l'équation \eqref{EqRlGIJW} définit bien une application. Soient \( v,w\in E\) tels que \( \pi_Ev=\pi_Ew\); nous devons montrer que
	\begin{equation}        \label{EqmoIUkH}
		\pi_F\bar gv=\pi_F\bar gw.
	\end{equation}
	L'équation \eqref{EqmoIUkH} sera vérifiée si et seulement si il existe \( \lambda\in\eR\) tel que \( \bar gv=\lambda\bar gw\), c'est-à-dire si et seulement si \( \bar g(v-\lambda w)=0\). Étant donné que nous supposons que le noyau de \( \bar g\) est réduit à \( \{ 0 \}\), l'équation \eqref{EqmoIUkH} sera vérifiée si et seulement si \( v=\lambda w\), ce qui signifie exactement \( \pi_E(v)=\pi_E(w)\).
\end{proof}

La proposition suivante donne les premières propriétés des homographies.
\begin{proposition}     \label{PROPooGVYXooDIiIbW}
	Quelques propriétés des homographies.
	\begin{enumerate}
		\item       \label{ITEMooTIONooSKjfny}
		      Une homographie est bijective.
		\item
		      Si deux espaces projectifs sont homographes, alors ils ont même dimension.
		\item       \label{ITEMooIZAPooNxEigb}
		      L'ensemble des homographies \( P(E)\to P(E)\) est un groupe (pour la composition).
		\item
		      Une homographie conserve l'alignement des points.
	\end{enumerate}
\end{proposition}

\begin{proof}
	Nous considérons une homographie \( g\colon P(E)\to P(F)\), et \( \bar g\) l'isomorphisme d'espaces vectoriels correspondant.
	\begin{enumerate}
		\item
		      Pour l'injectivité, si \( g\big( [v] \big)=g\big( [w] \big)\) alors en utilisant la définition d'une homographie, \( \pi_F\bar gv=\pi_F\bar gw\), ce qui implique que \( \bar gv=\lambda\bar gw\), et donc \( v=\lambda w\), ce qui signifie \( [v]=[w]\).

		      Pour la surjectivité, un élément général de \( P(F)\) prend la forme \( \pi_F\bar gv\) pour un certain \( v\in E\). Nous avons \( g\big( \pi_Ev \big)=\pi_F\bar gv\). Par conséquent l'élément \( \pi_F\bar gv\) est bien dans l'image de \( g\).

		\item
		      Une homographie \( P(E)\to P(F)\) n'existe que si il existe un isomorphisme \( E\to F\). Les dimensions sont donc automatiquement égales.
		\item
		      Il suffit de vérifier que l'application
		      \begin{equation}
			      \begin{aligned}
				      \varphi\colon P(E) & \to P(E)       \\
				      \pi_F\bar gv       & \mapsto \pi_Ev
			      \end{aligned}
		      \end{equation}
		      est bien définie et donne l'inverse de \( g\).
		\item
		      Soient les points \( A,B,C\) alignés dans \( P(E)\); ils correspondent à des directions de \( E\) qui sont données par des vecteurs situés sur la même droite affine. Autrement dit, il existe trois points \( a,b,c\in E\) situés sur la même droite affine tels que \( A,B,C=\pi_E(a,b,c)\). Les images par \( g\) sont données par \( \pi_F\bar ga\), \( \pi_F\bar gb\), et \( \pi_F\bar gc\).

		      Étant donné qu'un isomorphisme d'espaces vectoriels conserve l'alignement affin, les points \( \bar ga\), \( \bar gb\) et \( \bar gc\) sont alignés dans \( F\). Cela implique que les projections par \( \pi_F\) sont alignés dans \( P(F)\).
	\end{enumerate}
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Le groupe projectif}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}      \label{DEFooWUSDooSLVKwV}
	Le groupe des homographies de l'espace \( P(E)\) est le \defe{groupe projectif}{groupe!projectif}\index{projectif!groupe}, noté \( \PGL(E)\).\nomenclature[G]{\( \PGL(E)\)}{groupe projectif}
\end{definition}

Nous avons une surjection naturelle
\begin{equation}        \label{EqpqNEfe}
	\begin{aligned}
		\GL(E) & \to \PGL(E) \\
		\bar g & \mapsto g
	\end{aligned}
\end{equation}
qui s'avère être un morphisme de groupes.

\begin{proposition}
	Nous avons l'isomorphisme de groupes
	\begin{equation}
		\frac{ \GL(E) }{\{  \text{homothéties} \}}\simeq \PGL(E).
	\end{equation}

\end{proposition}

\begin{proof}
	Nous devons prouver que le noyau de l'application \eqref{EqpqNEfe} est constitué des homothéties. Considérons un automorphisme d'espace vectoriel \( f\colon E\to E\) dont l'homographie associée est l'identité, et prouvons que \( f\) est une homothétie. Nous avons le diagramme commutatif suivant :
	\begin{equation}
		\xymatrix{%
			E\setminus\{ 0 \} \ar[r]^{f}\ar[d]_{\pi_E}        &   E\setminus\{ 0 \}\ar[d]^{\pi_E}\\
			P(E) \ar[r]_{\id}   &   P(E).
		}
	\end{equation}
	Pour tout vecteur \( v\in E\) nous avons \( \pi_E(v)=\pi_E\big( f(v) \big)\). Cela implique qu'il existe \( \lambda\in\eR\) tel que \( f(v)=\lambda v\). Tous les vecteurs de \( E\) sont donc des vecteurs propres de \( f\). Cela n'est possible que si toutes les valeurs propres sont identiques, c'est-à-dire que \( f\) est une homothétie.
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Repères projectifs}
%---------------------------------------------------------------------------------------------------------------------------


\begin{definition}[\cite{BertrandProj}]
	Des éléments \( \{ P_i \}_{i\in I}\) sont \defe{projectivement independents}{indépendance!projective} si en choisissant \( v_i\in\pi^{-1}(P_i)\) nous obtenons des vecteurs \( \{ v_i \}_{i\in I}\) linéairement indépendants.
\end{definition}

\begin{definition}      \label{DEFooPZKFooDBXtEn}
	Soit \( E\) un espace vectoriel de dimension \( n+1\). Un \defe{repère projectif}{repère!projectif}\index{projectif!repère} de \( P(E)\) est la donnée de \( n+2\) points \( m_0,\ldots, m_{n+1}\) tels que
	\begin{enumerate}
		\item
		      les vecteurs \( m_i\), \( i\neq 0\), sont les images d'une base \( \{ e_i \}\) de \( E\)
		\item
		      \( m_0=\pi_E(e_1+e_2+\ldots +e_{n+1})\).
	\end{enumerate}
\end{definition}
Note que si \( m_k=\pi_E(v_k)\) (\( k=0,\ldots, n+1\)), alors tout choix de \( n+1\) vecteurs parmi les \( v_k\) est une base de \( E\).

\begin{example}
	Un repère projectif de l'espace \( P(\eR^3)\) est par exemple les éléments \( \{ m_i \}_{i=1,\ldots, 3}\) donnés par
	\begin{subequations}
		\begin{align}
			m_1=\pi(e_1) \\
			m_2=\pi(e_2) \\
			m_3=\pi(e_3) \\
			m_0=\pi(e_1+e_2+e_3).
		\end{align}
	\end{subequations}
\end{example}

\begin{example}
	Pour \( P(\eC^2)\), un repère projectif possible est \( m_1=[1,0]\), \( m_2=[0,1]\), \( m_0=[1,1]\).
\end{example}

\begin{normaltext}
	Pourquoi voulons nous des repères projectifs ? Pourquoi demander un quatrième élément alors que trois devraient suffire ? Le fait est que si \( E\) est de dimension \( 3\), nous voudrions pouvoir identifier \( E\) et \( P(\eR^3)\).

	Plus précisément, si \( E\) est de dimension \( n+1\) et possède une base \( \{ f_i \}_{i=1,\ldots, n+1}\), il existe un unique isomorphisme d'espaces vectoriels \( E\to \eR^{n+1}\) qui envoie cette base sur la base canonique de \( \eR^{n+1}\). La base de \( E\) étant fixée, nous pouvons donner à un point de \( E\) les coordonnées de son image dans \( \eR^{n+1}\) par cet isomorphisme \emph{qui est unique}.

	Dans le cas des espaces projectifs, nous voudrions avoir une unique homographie \( \phi\colon P(E)\to P(\eR^{n+1})\) qui permet de donner à un point \( A\in P(E)\) les coordonnées de \( \pi^{-1}\big( \phi(A) \big)\). Bien entendu ce dernier n'est pas un élément bien défini de \( \eR^{n+1}\) parce qu'il y a toute une droite d'éléments de \( \eR^n\) qui se projettent sur \( \phi(A)\).

	L'idée d'imposer un point de plus est la bonne. Si nous imposons un point de plus, nous pouvons dire que les coordonnées de \( A\in P(E)\) sont celles dans \( \eR^{n+1}\) de l'élément de \( \pi^{-1}\big( \phi(A) \big)\) dont la dernière coordonnée est par exemple \( 1\).

	Nous allons maintenant mettre ça en musique.
\end{normaltext}

D'abord nous donnons un exemple de non unicité.

\begin{example}
	Soit un espace vectoriel \( E\) de dimension \( 2\) et une base \(  \{ b_1,b_2 \}  \) de \( E\). Nous considérons également l'espace \( \eR^2\) muni de sa base canonique \( \{ e_1,e_2 \}\).

	Soit une homographie \( \phi\colon P(E)\to P(\eR^2)\) telle que
	\begin{equation}        \label{EQooPMARooXGuKDD}
		\phi\big( \pi(b_i) \big)=\pi(e_i)
	\end{equation}
	pour \( i=1,2\). Nous allons facilement construire une autre homographie qui vérifie les mêmes conditions.

	L'idée est la suivante. L'espace \( P(E)\) peut être vu comme la droite complétée \( \{ (  x,1   ) \}_{x\in \eR}\cup\{ (1,0) \} \) et l'espace \( P(\eR^2)\) également. Une homographie respectant \eqref{EQooPMARooXGuKDD} doit envoyer le \( (1,0)\) de \( E\) vers le \( (1,0)\) de \( \eR^2\) et le \( (1,1)\) de \( E\) vers le \( (1,1)\) de \( \eR^2\). Mais en ce qui concerne le reste de la droite, l'homographie peut la parcourir à la vitesse qu'elle veut.

	Il faut envoyer

	\begin{center}
		\input{auto/pictures_tex/Fig_QSKDooujUbDCsu.pstricks}
		sur
		\input{auto/pictures_tex/Fig_TIMYoochXZZNGP.pstricks}
	\end{center}

	Soit donc une homographie \( \phi\colon P(E)\to P(\eR^2)\), et nous définissons
	\begin{equation}
		\begin{aligned}
			\phi'\colon P(E) & \to P(\eR^2)                                   \\
			\pi(xb_1+yb2)    & \mapsto \phi\big( \pi(xb_1+\lambda yb_2) \big)
		\end{aligned}
	\end{equation}
	pour un certain \( \lambda\neq 1\). En ce qui concerne le relèvement, l'application \( \bar\phi'\colon E\to \eR^2\) donnée par
	\begin{equation}
		\bar\phi'(xb_1+yb_2)=\bar\phi(xb_1+\lambda yb_2)
	\end{equation}
	est bien définie et vérifie
	\begin{equation}
		\pi_{\eR^2}\circ\bar\phi'=\phi'\circ\pi_E.
	\end{equation}
	Donc \( \phi'\) est une homographie. De plus
	\begin{subequations}
		\begin{align}
			\phi'\big( \pi(b_1) \big)=\phi\big( \pi(b_1) \big) \\
			\phi'\big( \pi(b_2) \big)=\phi\big( \pi(\lambda b_2) \big)=\phi\big( \pi(b_2) \big)
		\end{align}
	\end{subequations}
	parce que \( \pi(\lambda b_2)=\pi(b_2)\).

	Nous n'avons donc pas l'unicité.
\end{example}

C'est pour rétablir cette unicité que nous demandons d'avoir un point de plus pour avoir un repère projectif. De cette façon nous aurons une unique homographie \( \phi\colon P(E)\to P(\eR^{n+1})\) vérifiant \( \phi\big( \pi_E(b_i) \big)=\pi_{\eR^{n+1}}(e_i)\) pour tout \( i=0,\ldots, n+1\).

\begin{lemma}
	Soit un espace vectoriel \( E\) de dimension \( n+1\) muni de deux bases \( \{ e_i \}_{i=1,\ldots, n+1}\) et \( \{ f_i \}_{i=1,\ldots, n+1}\). Soit un repère projectif \( \{ m_0,m_i \}_{i=1,\ldots, n+1}  \) de \( P(E)\).

	Si \( \pi(e_i)=\pi(f_i)=m_i\) pour tout \( i=1,\ldots, n+1\) et si
	\begin{equation}
		\pi(e_1+\ldots +e_{n+1})=\pi(f_1+\ldots +f_{n+1})
	\end{equation}
	alors les deux bases sont proportionnelles : il existe \( \lambda\) tel que \( f_i=\lambda e_i\) pour \( i=1,\ldots, n+1\).
\end{lemma}

\begin{proof}
	Nous avons \( \pi(e_i)=\pi(f_i)\) pour tout \( i=1,\ldots, n+1\). Donc pour chaque \( i=1,\ldots, n+1\) il existe \( \lambda_i\in \eK\) tel que \( e_i=\lambda f_i\). Nous devons voir que les \( \lambda_i\) sont en réalité tous égaux.

	Pour cela nous avons aussi l'égalité pour \( i=0\) :
	\begin{equation}
		\pi(e_1+\ldots +e_{n+1})=\pi(f_1+\ldots +f_{n+1}),
	\end{equation}
	ce qui donne un \( \mu\in \eK\) tel que \( e_1+\ldots +e_{n+1}=\mu(f_1+\ldots +f_{n+1})\), c'est-à-dire
	\begin{equation}
		\lambda_1 f_1+\ldots +\lambda_{n+1}f_{n+1}=\mu f_1+\ldots +\mu f_{n+1}.
	\end{equation}
	Du fait que les \( f_i\) forment une base, cette égalité impose à tous les \( \lambda_i\) d'être égal à \( \mu\).
\end{proof}

\begin{theorem}[\cite{ooDTHEooBAnkGP}]     \label{THOooTXPVooJGigne}
	Soient \( P(E)\) et \( P(F)\) deux espaces projectifs de dimensions \( n\).
	\begin{enumerate}
		\item       \label{ITEMooRSIWooXbEnlT}
		      Une homographie \( P(E)\to P(F)\) envoie un repère projectif sur un repère projectif.
		\item       \label{ITEMooQXQXooDyIsxsh}
		      Si \( (m_0,\ldots, m_{n+1})\) est un repère projectif de \( P(E)\), si \( (m'_0,\ldots, m'_{n+1})\) est un repère projectif de \( P(F)\) alors il existe une unique homographie \( g\colon P(E)\to P(F)\) telle que \( g(m_i)=m'_i\) pour tout \( i=0,1,\ldots, n+1\)
	\end{enumerate}
\end{theorem}

\begin{proof}

	Un point à la fois.

	\begin{subproof}
		\spitem[\ref{ITEMooRSIWooXbEnlT}]


		Soit une homographie \( \phi\colon P(E)\to P(F)\) et un repère projectif \( \{ m_0,m_1,\ldots, m_{n+1} \}\) de \( P(E)\). Nous posons \( m'_i=\phi(m_i)\) pour tout \( i=0,\ldots, n+1\). Nous devons prouver que ces \( m'_i\) forment un repère projectif de \( P(F)\).

		D'abord pour \( i=1,\ldots, n+1\) nous avons \( m'_i=\phi\big( \pi_E(e_i) \big)=\pi_F\big( \bar \phi(e_i) \big)\), mais \( \{ \bar\phi(e_i) \}_{i=1,\ldots, n+1}\) est une base de \( F\) parce que \( \bar \phi\) est un isomorphisme d'espaces vectoriels. Donc oui : les \( m'_i\)  (\( i=1,\ldots, n+1\)) sont les projetés d'une base de \( F\).

		Nous posons au passage \( f_i=\bar\phi(e_i)\).  En ce qui concerne \( m_0\) nous savons que \( m_0=\pi_E(e_1+\ldots +e_{n+1})\) et
		\begin{equation}
			m'_0=\phi\big( \pi_E(e_1+\ldots +e_{n+1}) \big)
			=\pi_F\big( \bar\phi(e_1+\ldots +e_{n+1}) \big)
			=\pi_F(f_1+\ldots +f_{n+1}),
		\end{equation}
		ce qui termine de montrer que \( \{ m'_i \}_{i=0,\ldots, n+1}\) est un repère projectif de \( P(F)\).

		\spitem[\ref{ITEMooQXQXooDyIsxsh}]

		Soient un repère projectif \( (m_0,\ldots, m_{n+1})\) de \( P(E)\) et un repère projectif \( (m'_0,\ldots, m'_{n+1})\) de \( P(F)\). Nous choisissons des bases \( \{ e_i \}\) de \( E\) et \(  \{ f_i \}\) de \( F\) telles que
		\begin{subequations}
			\begin{align}
				m_i  & =\pi_E(e_i) \\
				m'_i & =\pi_F(f_i)
			\end{align}
		\end{subequations}
		pour \( i=1,\ldots, n+1\) et
		\begin{subequations}
			\begin{align}
				m_0  & =\pi_E(e_1+\ldots +e_{n+1})  \\
				m'_0 & =\pi_F(f_1+\ldots +f_{n+1}).
			\end{align}
		\end{subequations}
		Nous considérons un isomorphisme d'espace vectoriel \( \bar\phi\colon E\to F\) tel que \( \bar\phi(e_i)=f_i\) pour tout \( i\), et nous voulons définir \( \phi\colon P(E)\to P(F)\) par
		\begin{equation}        \label{EQooRMYIooKcPZwD}
			\phi\big( \pi_E(v) \big)=\pi_F\big( \bar\phi(v) \big).
		\end{equation}
		Cela est bien défini parce que si \( \pi_E(v)=\pi_E(w)\) alors \( w=\lambda v\) et
		\begin{equation}
			\pi_F\big( \bar\phi(\lambda v) \big)=\pi_F\big( \lambda\bar\phi(v) \big)=\pi_F\big( \bar\phi(v) \big).
		\end{equation}
		L'application définie par \eqref{EQooRMYIooKcPZwD} est une homographie qui envoie \( m_i\) sur \( m'_i\) pour tout \( i=0,\ldots, n+1\). Ceci prouve la partie «existence» du point~\ref{ITEMooQXQXooDyIsxsh}.

		Pour l'unicité, soient des homographies
		\begin{subequations}
			\begin{align}
				\phi_1\colon P(E)\to P(F) \\
				\phi_2\colon P(E)\to P(F)
			\end{align}
		\end{subequations}
		telles que \( \phi_1(m_i)=\phi_2(m_i)\) pour tout \( i=0,\ldots, n+1\). Soit aussi une base \( \{ e_i \}_{i=1,\ldots, n+1}\) de \( E\) adaptée au repère projectif, c'est-à-dire \( m_i=\pi_E(e_i)\) pour \( i=1,\ldots, n+1\) et \( \pi_E(e_1+\ldots +e_{n+1})=m_0\). Nous considérons aussi les isomorphismes d'espaces vectoriels \( \bar\phi_1\) et \( \bar\phi_2\). Avec tout ce beau monde nous avons
		\begin{subequations}
			\begin{align}
				\phi_1(m_i) & =\pi_E\big( \bar\phi_1(e_i) \big)  \\
				\phi_2(m_i) & =\pi_E\big( \bar\phi_2(e_i) \big).
			\end{align}
		\end{subequations}
		Mais nous savons que \( \phi_1(m_i)=\phi_2(m_i)\), donc nous savons que \( \pi_E\big( \bar\phi_1(e_i) \big)=\pi_E\big( \bar\phi_2(e_i) \big)\), ce qui nous fait conclure que
		\begin{equation}
			\bar\phi_1(e_i)=\lambda_i\bar\phi_2(e_i)
		\end{equation}
		pour certaines constantes \( \lambda_i\in \eK\). Le même raisonnement appliqué à \( m_0\) nous donne un \( \mu\in \eK\) tel que
		\begin{equation}
			\bar\phi_1(e_1)+\ldots +\bar\phi_1(e_{n+1})=\mu\big( \bar\phi_2(e_1)+\ldots +\bar\phi_2(e_{n+1}) \big).
		\end{equation}
		En mettant l'un dans l'autre :
		\begin{equation}
			\lambda_1\bar\phi_2(e_1)+\ldots +\lambda_{n+1}\bar\phi_2(e_{n+1})=\mu\big( \bar\phi_2(e_1)+\ldots +\bar\phi_2(e_{n+1}) \big).
		\end{equation}
		Sachant que \( \{ \bar\phi_2(e_i) \}_{i=1,\ldots, n+1}\) est une base de \( F\) et nous souvenant de l'unicité de la décomposition d'un élément dans une base\footnote{Proposition~\ref{PROPooEIQIooXfWDDV}.}, nous en déduisons que tous les \( \lambda_i\) doivent être égaux à \( \mu\). Donc pour tout \( v\in E\) nous avons \( \bar\phi_1(v)=\lambda\bar\phi_2(v)\).

		Cela a pour conséquence que \( \phi_1=\phi_2\).
	\end{subproof}
\end{proof}

\begin{normaltext}
	Si nous avons une droite projective, trois points sont nécessaires pour créer un repère et donc pour construire une homographie de la droite sur elle-même. Soit \( E\) un espace vectoriel de dimension \( 2\) et \( P(E)\) la droite projective qui lui est associée. Soit une homographie \( f\colon P(E)\to P(E)\) et \( \bar f\colon E\to E\), l'isomorphisme d'espaces vectoriels associé (par \( f\circ\pi_E=\pi_E\circ \bar f\)). Si \( \{ e_1,e_2 \}\) est une base de \( E\) alors l'application \( \bar f\) a une matrice
	\begin{equation}
		A=\begin{pmatrix}
			a_{11} & a_{12} \\
			a_{21} & a_{22}
		\end{pmatrix}\in \eM(2,\eK)
	\end{equation}
	avec \( \det A\neq 0\) parce que \( \bar f\) est un isomorphisme.

	La plupart des points de \( P(E)\) sont représentés par des points de la forme \( (z,1)\). Nous voudrions savoir quelle est la direction représentée par le point \( \bar f(z,1)\); c'est-à-dire que nous voudrions savoir \( f([z,1])\) sous la forme \( [z',1]\) (si possible). Nous avons
	\begin{equation}
		\bar f(z,1)=(a_{11}z+a_{12},a_{21}z+a_{22}).
	\end{equation}
	Nous posons \( \lambda=a_{21}z+a_{22}\) et nous avons
	\begin{equation}
		\bar f(z,1)=\lambda\left( \frac{ a_{11}z+a_{12} }{ \lambda },1 \right).
	\end{equation}
	Il y a plusieurs possibilités suivant les valeurs de \( \lambda\) et de \( z\).

	\begin{enumerate}
		\item
		      Si \( \lambda=0\) c'est que nous avons \( \bar f(z,1)=(a_{11}z+a_{12},0)\). L'application \( f\) envoie donc le point \( (z:1)\) sur le point à l'infini.
		\item
		      Si \( \lambda\neq 0\), alors \( f\) envoie le point \( (z:1)\) vers un autre point «normal».
		\item
		      Si le point de départ est le point à l'infini alors \( \bar f(1,0)=(a_{11},a_{21})\). Cela peut être le point à l'infini ou non selon les valeurs des \( a_{ij}\).
	\end{enumerate}

	Dans tous les cas si nous posons
	\begin{subequations}
		\begin{numcases}{}
			\varphi_f(z)=\frac{ a_{11}z+a_{12} }{ a_{21}z+a_{22} }\\
			\varphi_f(\infty)=\frac{ a_{11} }{ a_{21} }
		\end{numcases}
	\end{subequations}
	alors nous avons
	\begin{equation}
		\bar f(z,1)=\big( \varphi_f(z),1 \big).
	\end{equation}
	Si nous prenons la convention que \( \frac{1}{ 0 }=\infty\) et que \( (\infty,0)\) est le point à l'infini, alors cette application \( \varphi_f\) donne bien toutes les valeurs de \( f\), y compris les cas à l'infini.
\end{normaltext}

\begin{lemma}[\cite{ooRARBooTtbPwJ}]       \label{LEMooXNKOooBKhzyt}
	Trois points distincts d'une droite projective forment un repère projectif.
\end{lemma}

\begin{proof}
	Soit une droite projective \( d=P(E)\) où \( E\) est un espace vectoriel de dimension \( 2\) sur le corps \( \eK\). Soient trois points distincts \( A\), \( B\) et \( C\) de \( d\). Nous avons \( a,b,c\in E\) tels que \( A=\pi(a)\), \( B=\pi(b)\) et \( C=\pi(c)\). Vu que \( A\neq B\), les vecteurs \( a\) et \( b\) ne sont pas proportionnels et la partie \( \{ a,b \}\) est libre dans \( E\). Autrement dit, c'est une base\footnote{Il convient de citer ici la proposition \ref{PROPooVEVCooHkrldw}.}.

	Il existe donc \( \alpha,\beta\in \eK\) tels que \( c=\alpha a+\beta b\). De plus \( \alpha\) et \( \beta\) ne sont pas nuls parce que \( C\neq A\) et \( C\neq B\). En prenant \( a'=\alpha a\), \( b'=\beta b\) et \( c'=c\) nous avons : \( A=\pi(a')\), \( B=\pi(b')\), \( C=\pi(c')\) en même temps que \( \{ a',b' \}\) est une base de \( E\) et \( c'=a'+b'\). Donc \( A,B,C\) est un repère projectif de \( d=P(E)\).
\end{proof}

\begin{corollary}[\cite{ooTZWQooBbWWpR}]        \label{CORooRFCZooGZiQBJ}
	Soient \( E\) et \( F\) des espaces vectoriels de dimension \( 2\). Soient \( A_i\) (\( i=1,2,3\)) des points distincts sur \( P(E)\) et \( B_i\) distincts sur \( P(F)\). Alors il existe une unique homographie \( P(E)\to P(F)\) portant \( A_i\) sur \( B_i\) pour tout \( i=1,2,3\).
\end{corollary}

\begin{proof}
	Il s'agit de mettre en conjonction le lemme~\ref{LEMooXNKOooBKhzyt} qui dit que les \( A_i\) forment un repère projectif de \( P(E)\) (idem : les \( B_i\) forment un repère projectif de \( P(F)\)) et le théorème~\ref{THOooTXPVooJGigne}\ref{ITEMooQXQXooDyIsxsh} qui dit que l'une va sur l'autre part une unique homographie.
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Identifications \texorpdfstring{\(  P(\eK^2)\)}{P(K2)} vers \texorpdfstring{\(  \eK\cup\{ \infty \}\)}{K u infinity}}
%---------------------------------------------------------------------------------------------------------------------------

Pour rappel, une droite projective est l'espace projectif modelé sur un espace vectoriel de dimension deux (définition~\ref{DEFooBBMBooSVgTnn}).

\begin{normaltext}      \label{NORMooUQRUooOMIzJD}
	Nous allons faire un usage assez intense de bijections entre \( P(\eK^2)\) et \( \hat\eK=\eK\cup\{ \infty \}\). Une possible est
	\begin{equation}        \label{EQooSIJDooTHPYMb}
		\begin{aligned}
			\varphi_0\colon P(\eK^2) & \to \eK\cup\{ \infty \}                            \\
			[k_1,k_2]                & \mapsto \begin{cases}
				                                   \frac{ k_1 }{ k_2 } & \text{si } k_2\neq 0 \\
				                                   \infty              & \text{si } k_2=0.
			                                   \end{cases}
		\end{aligned}
	\end{equation}
	Notons que nous utilisons ici le fait que \( \eK\) soit commutatif, sinon il aurait fallu choisir \( k_1k_2^{-1}\) ou \( k_2^{-1}k_1\) au lieu d'écrire gentiment \( k_1/k_2\).
\end{normaltext}

\begin{corollary}       \label{CORooFJSCooNOeAel}
	Soit une bijection \( \varphi\colon P(\eK^2)\to \hat\eK\). Les points \( \{ \varphi^{-1}(\infty), \varphi^{-1}(0), \varphi^{-1}(1) \}\) forment un repère projectif de \( P(\eK^2)\).
\end{corollary}

\begin{proof}
	Il s'agit seulement d'une application du lemme~\ref{LEMooXNKOooBKhzyt}.

	Juste pour l'amusement, nous allons le prouver explicitement pour la bijection \( \varphi=\varphi_0\) donnée en \eqref{EQooSIJDooTHPYMb}. Un repère projectif est la définition~\ref{DEFooPZKFooDBXtEn}. Nous avons
	\begin{subequations}
		\begin{align}
			\varphi_0^{-1}(\infty)=[1,0]=\pi_{\eK^2}\big( (1,0) \big) \\
			\varphi_0^{-1}(0)=[0,1]=\pi_{\eK^2}\big( (0,1) \big)      \\
			\varphi_0^{-1}(1)=[1,1]=\pi_{\eK^2}\big( (1,1) \big)
		\end{align}
	\end{subequations}
	Les points \( (1,0)\) et \( (0,1)\) forment un base de \( \eK^2\) et nous avons bien \( (1,1)=(1,0)+(0,1)\). Donc le tout vérifie bien la définition d'un repère projectif.
\end{proof}

D'autre part, comme il est plus agréable de travailler avec \( \hat\eK\) qu'avec \( P(\eK^2)\) nous avons envie de voir \( \hat\eK\) comme un espace projectif (qu'il n'est pas). Il y a cependant nombre d'autres identifications possibles. En voici un autre :
\begin{equation}
	\begin{aligned}
		\varphi_1\colon P(\eK^2) & \to \hat\eK                                         \\
		[k_1,k_2]                & \mapsto \begin{cases}
			                                   \frac{ k_2 }{ k_1 } & \text{si  } k_1\neq 0 \\
			                                   \infty              & \text{si } k_1=0.
		                                   \end{cases}
	\end{aligned}
\end{equation}

Vous en voulez une plus compliquée ? En voici une pour \( \eK=\eR\), basée sur le dessin suivant :
\begin{center}
	\input{auto/pictures_tex/Fig_ZOCNoowrfvQXsr.pstricks}
\end{center}

La bijection associée est :
\begin{equation}        \label{EQooMIGCooAtXPaS}
	\begin{aligned}
		\varphi_d\colon P(\eR^2) & \to \hat\eR                                            \\
		[k_1,k_2]                & \mapsto \begin{cases}
			                                   \frac{ k_1 }{ k_2 }  & \text{si } k_1k_2\leq 0 \\
			                                   2\frac{ k_1 }{ k_2 } & \text{si } k_1k_2>0     \\
			                                   \infty               & \text{si } k_2=0.
		                                   \end{cases}
	\end{aligned}
\end{equation}

Pour mettre un peu d'ordre dans toutes ces identifications possibles, nous introduisons une classe.

\begin{definition}      \label{DEFooMLQUooGwvQMh}
	Pour une bijection \( \varphi\colon P(\eK^2)\to \hat\eK\) nous définissons
	\begin{equation}
		\begin{aligned}[]
			A(\varphi)=\big\{  \varphi_a\colon P(\eK^2) & \to \hat\eK \tq \varphi_a^{-1}\circ\varphi
			\text{ soit une homographie } \big\}
		\end{aligned}
	\end{equation}
\end{definition}

Les classes sont assez larges parce que pour toute homographie \( \phi\colon P(\eK^2)\to P(\eK^2)\), nous avons \( \varphi\circ\phi^{-1}\in A(\varphi)\). Mieux, nous avons le lemme suivant.

\begin{lemma}
	L'application
	\begin{equation}
		\begin{aligned}
			\psi\colon A(\varphi) & \to \PGL(\eK^2)                    \\
			\varphi_a             & \mapsto \varphi_a^{-1}\circ\varphi
		\end{aligned}
	\end{equation}
	est une bijection.
\end{lemma}

\begin{proof}
	Pour rappel, \( \PGL(E)\) est le groupe des homographies de \( E\), voir la définition~\ref{DEFooWUSDooSLVKwV}.
	\begin{subproof}
		\spitem[Surjectif]
		Si \( \phi\in\PGL(\eK^2)\) nous avons \( \phi=\psi(\varphi\circ\phi^{-1})\).
		\spitem[Injectif]
		Si \( \psi(\varphi_a)=\psi(\varphi_b)\) alors
		\begin{equation}
			\varphi_a^{-1}\circ\varphi=\varphi_b^{-1}\circ\varphi,
		\end{equation}
		d'où nous déduisons \( \varphi_a^{-1}=\varphi_b^{-1}\) parce que \( \varphi\) est une bijection.
	\end{subproof}
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Birapport}
%---------------------------------------------------------------------------------------------------------------------------

\begin{normaltext}
	Tout le monde semble définir le birapport en identifiant \( P(\eK^2)\) à \( \hat\eK=\eK\cup\{ \infty \}\). Bien entendu, personne ne semble s'être attribué la mission d'expliciter la dépendance du birapport en le choix de l'identification. Je le fais à la définition~\ref{DEFooBFSKooDwzwmO}.

	Mais cette définition dépend du choix d'identification \( \varphi\colon P(\eK^2)\to \hat\eK\), comme le montre l'exemple~\ref{EXooYCOYooWFSfUv}. J'ai donc défini des classes d'identifications possibles \( A(\varphi)\) en~\ref{DEFooMLQUooGwvQMh}. Et je démontre la proposition~\ref{PROPooTFMQooIOQGvs} que si \( \varphi_a\in A(\varphi)\) alors les birapports construits à partir de \( \varphi\) et \( \varphi_a\) sont identiques.

	Question : pourquoi personne ne semble faire ce travail ? En quoi l'identification \( \varphi_0\) que tout le monde utilise est plus canonique qu'une autre ? Est-ce que l'on peut décrire simplement les classes \( A(\varphi)\) ? Le groupe qui conserve le birapport associé à \( \varphi\) est-il isomorphe au groupe qui conserve le birapport associé à \( \varphi'\) ? Quels que soient \( \varphi\) et \( \varphi'\) ?

	Suis-je la seule personne au monde à m'être demandé si le birapport était un objet canonique ?
\end{normaltext}

\begin{normaltext}
	Une utilisation très intéressante du birapport dans la vidéo «The Cross-Ratio» de numberphile: \url{https://www.youtube.com/watch?v=ffvojZONF_A}
\end{normaltext}

\begin{propositionDef}      \label{DEFooBFSKooDwzwmO}
	Soit une droite projective \( d=P(E)\) et trois points distincts \( A\), \( B\) et \( C\) sur cette droite. Soit une bijection \( \varphi\colon P(\eK^2)\to \hat\eK\). Si \( X\) est un point de \( d\) alors nous nommons le \defe{birapport}{birapport} de \( X\) par rapport à \( A\), \( B\) et \( C\) l'élément de \( \hat\eK\) donné par
	\begin{equation}
		[A,B,C,X]_{\varphi}=(\varphi\circ\phi)(X)
	\end{equation}
	où \( \phi\colon d\to P(\eK^2) \) est l'unique homographie telle que
	\begin{subequations}        \label{SUBEQooYWMSooYlFKQv}
		\begin{align}
			\phi(A) & =\varphi^{-1}(\infty) \\
			\phi(B) & =\varphi^{-1}(0)      \\
			\phi(C) & =\varphi^{-1}(1).
		\end{align}
	\end{subequations}
\end{propositionDef}

\begin{proof}
	Nous devons prouver qu'il existe effectivement une unique homographie vérifiant les conditions \eqref{SUBEQooYWMSooYlFKQv}.
	\begin{subproof}
		\spitem[\( A,B,C\) est un repère projectif de \( P(E)\)]
		Voir le lemme~\ref{LEMooXNKOooBKhzyt}.

		\spitem[\(   \varphi^{-1}(\infty), \varphi^{-1}(0), \varphi^{-1}(1)  \) est un repère projectif de \( P(\eK^2)\)]
		Lemme~\ref{LEMooXNKOooBKhzyt} ou corolaire~\ref{CORooFJSCooNOeAel} au choix.
		\spitem[Conclusion]
		Le théorème~\ref{THOooTXPVooJGigne}\ref{ITEMooQXQXooDyIsxsh} nous donne existence et unicité d'une homographie \( P(E)\to P(\eK^2) \) envoyant le premier repère sur le second.
	\end{subproof}
\end{proof}

\begin{remark}
	La majorité des sources ne parlent pas de la dependence du birapport en le choix de \( \varphi\) parce que tout le monde ne semble ne considérer que \( \varphi=\varphi_0\) définie en \eqref{EQooSIJDooTHPYMb}. Il est cependant naturel de se demander si la définition dépend effectivement du choix de \( \varphi\). La réponse est oui : ça dépend du choix.
\end{remark}

\begin{example}[Une autre identification qui ne va pas bien]        \label{EXooYCOYooWFSfUv}
	Nous montrons que l'identification \( \varphi_d\colon P(\eK^2)\to \hat\eK\) donnée en \eqref{EQooMIGCooAtXPaS} ne donne pas lieu au même birapport que celui de \( \varphi_0\).

	Nous travaillons le birapport sur la droite projective la plus simple : \( P(\eK^2)\) avec \( \eK=\eR\). Prenons pour la simplicité \( A=[1,0]\), \( B=[0,1]\) et \( C=[1,1]\). Alors l'homographie demandée dans la définition de \( [.,.,.,.]_{\varphi_0}\) est \( \phi_0=\id\). Par conséquent,
	\begin{equation}
		\big[ A,B,C,[k_1,k_2] \big]_{\varphi_0}=(\varphi_0\circ\phi_0)[k_1,k_2]=\varphi_0[k_1,k_2]=\frac{ k_1 }{ k_2 }.
	\end{equation}

	En ce qui concerne le birapport défini par \( \varphi_d\) nous avons
	\begin{subequations}
		\begin{align}
			\varphi_d^{-1}(\infty) & =[1,0]  \\
			\varphi_d^{-1}(0)      & =[0,1]  \\
			\varphi_d^{-1}(1)      & =[1,2],
		\end{align}
	\end{subequations}
	de telle sorte que nous cherchons une homographie \( \phi_d\colon P(\eK^2)\to P(\eK^2)\) telle que
	\begin{subequations}
		\begin{align}
			\phi_d[1,0] & =[1,0] \\
			\phi_d[0,1] & =[0,1] \\
			\phi_d[1,1] & =[1,2]
		\end{align}
	\end{subequations}
	L'homographie \( \phi_d[k_1,k_2]=[k_1,2k_2]\) convient et nous avons
	\begin{equation}
		\big[ A,B,C,D,[k_1,k_2] \big]_{\varphi_d}=(\varphi_d\circ\phi_d)[k_1,k_2]=\varphi_d[k_1,2k_2]=\frac{ k_1 }{ 2k_2 }
	\end{equation}
	dès que \( k_1k_2<0\). Nous avons donc bien trouvé
	\begin{equation}
		[A,B,C,X]_{\varphi_0}\neq [A,B,C,X]_{\varphi_d}.
	\end{equation}
\end{example}

Le birapport n'est pas un objet tout à fait canonique parce qu'il dépend effectivement du choix de l'identification entre \( P(\eK^2)\) et \( \hat\eK\).

\begin{proposition}     \label{PROPooTFMQooIOQGvs}
	Soit une bijection \( \varphi\colon P(\eK^2)\to \hat\eK\). Si \( \varphi_a\in A(\varphi)\)\footnote{\( A(\varphi)\) définie en~\ref{DEFooMLQUooGwvQMh}.} alors les birapports construits sur \( \varphi\) et \( \varphi_a\) coïncident.
\end{proposition}

\begin{proof}
	Soient trois points distincts \( A,B,C\in P(E)\), et \( X\in P(E)\). Nous avons
	\begin{equation}
		[A,B,C,X]_{\varphi}=(\varphi\circ\phi)(X)
	\end{equation}
	où \( \phi\colon P(E)\to P(\eK^2)\) est l'unique homographie telle que
	\begin{subequations}
		\begin{align}
			\phi(A) & =\varphi^{-1}(\infty) \\
			\phi(B) & =\varphi^{-1}(0)      \\
			\phi(C) & =\varphi^{-1}(1).
		\end{align}
	\end{subequations}
	Et
	\begin{equation}
		[A,B,C,X]_{\varphi_a}=(\varphi_a\circ\phi_a)(X)
	\end{equation}
	où \( \phi_a\colon P(E)\to P(\eK^2)\) est l'unique homographie telle que
	\begin{subequations}
		\begin{align}
			\phi_a(A) & =\varphi_a^{-1}(\infty) \\
			\phi_a(B) & =\varphi_a^{-1}(0)      \\
			\phi_a(C) & =\varphi_a^{-1}(1).
		\end{align}
	\end{subequations}
	Il est facile de voir que \( \phi_a=\varphi_a^{-1}\circ\varphi\phi\). En effet, cela est une homographie parce que \( \varphi_a\in A(\varphi)\), et parce que la composée d'homographies est une homographie. De plus,
	\begin{subequations}
		\begin{align}
			(\varphi_a^{-1}\circ\varphi\circ\phi)(A)=(\varphi_a^{-1}\circ\varphi)\phi^{-1}(\infty)=\varphi_a(\infty) \\
			(\varphi_a^{-1}\circ\varphi\circ\phi)(B)=(\varphi_a^{-1}\circ\varphi)\phi^{-1}(0)=\varphi_a(0)           \\
			(\varphi_a^{-1}\circ\varphi\circ\phi)(C)=(\varphi_a^{-1}\circ\varphi)\phi^{-1}(1)=\varphi_a(1).
		\end{align}
	\end{subequations}
	Au final nous avons :
	\begin{equation}
		[A,B,C,X]_{\varphi_a}=(\varphi_a\circ\varphi_a^{-1}\circ\varphi\circ\phi)(X)=(\varphi\circ\phi)(X)=[A,B,C,X]_{\varphi}.
	\end{equation}
\end{proof}

\begin{remark}
	Tout le monde semble ne considérer que l'identification usuelle \( \varphi_0\colon P(\eK^2)\to \hat\eK\) donnée par \( \varphi_0[k_1,k_2]=k_1/k_2\). Toute la discussion concernant la dépendance du birapport en le choix de l'identification (y compris la définition des classes \( A(\varphi)\)) peut être sautée en disant qu'on ne considéra que \( \varphi_0\).

	Et c'est ce que nous allons faire : sauf avis contraire, nous utiliserons le birapport associé à l'identification \( \varphi_0\).
\end{remark}

\begin{lemma}[\cite{ooDTHEooBAnkGP}]        \label{LEMooCOFTooVGKdVO}
	Nous avons
	\begin{equation}
		[A,B,C,X]_{\varphi}=\begin{cases}
			\infty & \text{si et seulement si } X=A \\
			0      & \text{si et seulement si }X=B  \\
			1      & \text{si et seulement si }X=C.
		\end{cases}
	\end{equation}
\end{lemma}

\begin{proof}
	Par définition \( [A,B,C,X]_{\varphi}=\varphi\circ\phi(X)\). Nous avons donc équivalence entre les affirmations suivantes :
	\begin{itemize}
		\item \( [A,B,C,X]_{\varphi}=\infty\)
		\item \( (\varphi\circ\phi)(X)=\infty\)
		\item \( \phi(X)=\varphi^{-1}(\infty)\)
		\item \( \phi(X)=\phi(A)\)
		\item \( A=X\)
	\end{itemize}
	parce que \( \phi\) et \( \varphi\) sont des bijections.

	Le même raisonnement tient pour les deux autres.
\end{proof}

\begin{proposition}     \label{PROPooKQZRooVCXPLW}
	Autres petites propriétés faciles \ldots\ Soit une droite projective \( d=P(E)\) et trois points distincts \( A,B,C\in d\).
	\begin{enumerate}
		\item       \label{ITEMooOIPZooQFFYIn}
		      Les points \( A\), \( B\), \( C\) et \( X\) sont distincts si et seulement si \( [A,B,C,X]\in \eK\setminus\{ 0,1 \}\).
		\item       \label{ITEMooBEBEooVfiJXY}
		      Pour tout \( k\in \hat\eK\), il existe un unique \( X\in d\) tel que \( [A,B,C,X]=k\).
	\end{enumerate}
\end{proposition}

\begin{proof}
	Notons pour le point~\ref{ITEMooOIPZooQFFYIn} que l'énoncé demande déjà que \( A\), \( B\) et \( C\) soient distincts. Sinon le birapport n'est pas défini.
	\begin{subproof}
		\spitem[\ref{ITEMooOIPZooQFFYIn}]

		Les points \( A\), \( B\) et \( C\) sont distincts par hypothèse. Vu le lemme~\ref{LEMooCOFTooVGKdVO}, pour que \( X\) soit distincts de \( A\), \( B\) et \( C\) il faut et il suffit que le birapport ne soit ni \( \infty\) ni \( 1\) ni \( 0\). Donc \( \eK\setminus\{ 0,1 \}\).

		\spitem[\ref{ITEMooBEBEooVfiJXY}]

		Nous avons \( [A,B,C,X]=\phi(X)\) où \( \phi\colon P(E)\to P(\eK^2)\) est une homographie et donc une bijection par la proposition~\ref{PROPooGVYXooDIiIbW}\ref{ITEMooTIONooSKjfny}. Donc oui, pour tout éléments de \( P(\eK^2)\) il existe un unique élément de \( P(E)\) dont le birapport par rapport à \( A\), \( B\) et \( C\) soit cet élément.

	\end{subproof}
	Notons encore une fois que nous avons identifié \( P(\eK^2)\) à \( \hat\eK\) par la bijection \eqref{EQooSIJDooTHPYMb}.
\end{proof}

\begin{proposition}[\cite{ooDTHEooBAnkGP}]      \label{PROPooMGYDooHqSoJs}
	Nous considérons deux droites projectives \( d\) et \( d'\) ainsi que \( 4\) points sur chacune. Nous les nommons \( A_1,A_2,A_3,A_4\in d\) et \( A'_1,A'_2,A'_3,A'_4\in d'\). Nous supposons que \( A_1,A_2,A_3\) sont distincts et que \( A'_1,A'_2,A'_3\) également. Alors il y a équivalence entre
	\begin{enumerate}
		\item       \label{ITEMooIDKBooXHnNDi}
		      Il existe une homographie \( \phi\colon d\to d'\) telle que \( \phi(A_i)=A'_i\) pour \( i=1,2,3,4\),
		\item       \label{ITEMooCDWAooIckJwT}
		      égalité des birapports :
		      \begin{equation}
			      [A_1,A_2,A_3,A_4]=[A'_1,A'_2,A'_3,A'_4].
		      \end{equation}
	\end{enumerate}
	Dans ce cas, l'homographie est unique.
\end{proposition}

\begin{proof}
	Nous divisons la preuve en trois parties évidentes.
	\begin{subproof}
		\spitem[\ref{ITEMooIDKBooXHnNDi} implique~\ref{ITEMooCDWAooIckJwT}]

		Nous avons une homographie \( \mu'\colon d'\to \hat\eK\) telle que \( \mu'(A'_1)=\infty\), \( \mu'(A'_2)=0\) et \( \mu'(A'_3)=1\). En composant\footnote{Proposition~\ref{PROPooGVYXooDIiIbW}\ref{ITEMooIZAPooNxEigb}, la composition est encore une homographie.} avec l'homographie \( \phi\colon d\to d'\) de l'hypothèse nous avons une homographie \( \mu'\circ \phi\colon d\to \hat\eK\) qui vérifie
		\begin{subequations}
			\begin{align}
				(\mu'\circ\phi)(A_1)=\mu'(A'_1)=\infty \\
				(\mu'\circ\phi)(A_2)=\mu'(A'_2)=0      \\
				(\mu'\circ\phi)(A_3)=\mu'(A'_3)=1,
			\end{align}
		\end{subequations}
		ce qui signifie que \( \mu'\circ\phi\) est l'homographie qui définie le birapport sur \( d\). Par conséquent
		\begin{equation}
			[A_1,A_2,A_3,A_4]=(\mu'\circ \phi)(A_4)=\mu'(A'_4)=[A'_1,A'_2,A'_3,A'_4].
		\end{equation}
		\spitem[\ref{ITEMooCDWAooIckJwT} implique~\ref{ITEMooIDKBooXHnNDi}]

		La partie \( \{ A_1,A_2,A_3 \}\) est un repère projectif de \( d\) par le lemme~\ref{LEMooXNKOooBKhzyt}. Idem pour \( \{ A'_1,A'_2,A'_3 \}\). Nous considérons les homographies \( \mu\colon d\to  \hat \eK\) et \( \mu'\colon d'\to \hat\eK\) définissant les birapports par rapport à ces repères. Ces homographies vérifient, en utilisant l'hypothèse :
		\begin{equation}
			\mu(A_4)=[A_1,A_2,A_3,A_4]=[A'_1,A'_2,A'_3,A'_4]=\mu'(A'_4).
		\end{equation}
		Et de plus
		\begin{subequations}
			\begin{align}
				\mu(A_1)=[A_1,A_2,A_3,A_1]=\infty=\mu'(A'_1) \\
				\mu(A_2)=[A_1,A_2,A_3,A_2]=0=\mu'(A'_2)      \\
				\mu(A_3)=[A_1,A_2,A_3,A_3]=1=\mu'(A'_3).
			\end{align}
		\end{subequations}
		Autrement dit : \( \mu(A_i)=\mu'(A'_i)\) pour tout \( i=1,2,3,4\). Nous nous inspirons de ce diagramme :
		\begin{equation}
			\xymatrix{%
				d \ar@{.>}[rr]^{\phi}\ar[dr]_{\mu}  &    &   d'\ar[dl]^{\mu'}\\
				&  \eK\cup\{ \infty \} &&
			}
		\end{equation}
		La composée \( \phi=\mu'^{-1}\circ\mu\) vérifie
		\begin{equation}
			(\mu'^{-1}\circ\mu)(A_i)=A'_i
		\end{equation}
		pour tout \( i\), et est une homographie.

		\spitem[Unicité]

		Le fait qu'une homographie vérifiant \( \phi(A_i)=A'_i\) pour \( i=1,2,3\) soit unique découle du fait qu'il existe une unique homographie portant un repère projectif sur un autre. A fortiori la condition \( \phi(A_4)=A'_4\) ne retire rien à l'unicité.

	\end{subproof}
\end{proof}

\begin{theorem}[\cite{ooDTHEooBAnkGP}]
	Une bijection entre deux droites projectives est une homographie si et seulement si elle conserve le birapport.
\end{theorem}

\begin{proof}
	Chacun des deux sens séparément.
	\begin{subproof}
		\spitem[\( \Rightarrow\)]

		Soit une homographie \( \phi\colon d\to d'\) entre deux droites projectives. Nous devons prouver que pour tout choix \( 4\) points \( A\), \( B\), \( C\), \( X\) dans \( d\) (dont \( A\), \( B\) et \( C\) sont distincts) nous avons
		\begin{equation}        \label{EQooVFIOooCdumAe}
			[A,B,C,X]=[\phi(A),\phi(B),\phi(C),\phi(X)].
		\end{equation}
		Nous nommons \( \mu\colon d\to \hat\eK\) l'homographie qui donne le birapport sur \( d\) par rapport à \( A\), \( B\) et \( C\), et \( \mu'\colon d'\to \hat\eK\) celle qui donne le birapport sur \( d'\) par rapport à \( \phi(A)\), \( \phi(B)\), \( \phi(C)\). Voici un diagramme de la situation :
		\begin{equation}
			\xymatrix{%
				d \ar@{.>}[rr]^{\phi}\ar[dr]_{\mu}  &    &   d'\ar[dl]^{\mu'}\\
				&  \eK\cup\{ \infty \} &&
			}
		\end{equation}
		Nous prouvons maintenant que \( \mu'=\mu\circ\phi^{-1}\). En effet :
		\begin{subequations}
			\begin{align}
				(\mu\circ\phi^{-1})\big( \phi(A) \big)=\mu(A)=\infty \\
				(\mu\circ\phi^{-1})\big( \phi(B) \big)=\mu(B)=0      \\
				(\mu\circ\phi^{-1})\big( \phi(C) \big)=\mu(C)=1.
			\end{align}
		\end{subequations}
		Par conséquent le birapport à droite dans \eqref{EQooVFIOooCdumAe} peut se calculer à l'aide de \( \mu\circ\phi^{-1}\) :
		\begin{equation}
			[\phi(A),\phi(B),\phi(C),\phi(X)]=\mu'\big( \phi(X) \big)=(\mu\circ\phi^{-1})\big( \phi(X) \big)=\mu(X)=[A,B,C,X].
		\end{equation}
		La première implication est prouvée.

		\spitem[\( \Leftarrow\)]

		Soit une bijection \( f\colon d\to d'\) conservant le birapport, ainsi que trois points distincts \( A\), \( B\) et \( C\) dans \( d\). Vu que \( f\) est une bijection les points \( f(A)\), \( f(B)\) et \( f(C)\) sont distincts dans \( d'\). Par le lemme~\ref{LEMooXNKOooBKhzyt} et le théorème~\ref{THOooTXPVooJGigne}\ref{ITEMooQXQXooDyIsxsh}, il existe une unique homographie \( \phi\colon d\to d'\) telle que \( \phi(A)=f(a)\), \( \phi(B)=f(B)\) et \( \phi(C)=f(C)\). Pour tout \( X\in d\) nous avons
		\begin{subequations}        \label{SUBEQSooVCSBooWvQLih}
			\begin{align}
				[f(A),f(B),f(C),f(X)] & =[A,B,C,X]   \label{SUBEQooIYQKooJFpnyo}                           \\
				                      & =[\phi(A),\phi(B),\phi(C),\phi(X)]     \label{SUBEQooWYUPooQMZrrU} \\
				                      & =[f(A),f(B),f(C),\phi(X)].
			\end{align}
		\end{subequations}
		Justifications :
		\begin{itemize}
			\item \eqref{SUBEQooIYQKooJFpnyo} parce que \( f\) conserve le birapport par hypothèse.
			\item \eqref{SUBEQooWYUPooQMZrrU} parce que \( \phi\) conserve le birapport étant une homographie (c'est le premier sens du présent théorème)
		\end{itemize}
		Nous nommons \( \mu'\colon d'\to \hat\eK\) l'homographie donnant le birapport par rapport aux points \( f(A)\), \( f(B)\), \( f(C)\). Alors le résultat \eqref{SUBEQSooVCSBooWvQLih} se lit
		\begin{equation}
			\mu'\big( f(X) \big)=\mu'\big( \phi(X) \big).
		\end{equation}
		Mais comme \( \mu'\) est une bijection (proposition~\ref{PROPooGVYXooDIiIbW}\ref{ITEMooTIONooSKjfny}) cela implique \( f(X)=\phi(X)\). Vu que nous avons fait ce raisonnement pour un \( X\) quelconque dans \( d\) nous avons \( f=\phi\), ce qui prouve que \( f\) est une homographie.
	\end{subproof}
\end{proof}

\begin{lemma}
	Soient \( a\), \( b\), \( c\) distincts sur la droite projective \( D=P(E)\). Soient \( x,y\in E\) tels que \( \pi_E(x)=a\), \( \pi_E(y)=b\), \( \pi_E(x+y)=c\). Alors
	\begin{equation}
		d=\pi_E(\lambda x+\mu y)
	\end{equation}
	si et seulement si
	\begin{equation}
		[a,b,c,d]=\pi_{\eK^2}(\lambda,\mu).
	\end{equation}
\end{lemma}

\begin{proof}
	Étant donné que \( a\) et \( b\) sont distincts, les vecteurs \( x\) et \( y\) forment une base de \( E\). Soit \( f\colon E\to \eK^2\) un isomorphisme qui envoie \( (x,y)\) sur \( e_1,e_2\) où \( e_i\) sont les vecteurs de base de \( \eK^2\). Ensuite nous considérons  \( g\colon P(E)\to P(\eK^2)\), l'homographie associée à \( f\). Par définition \( g\big( \pi_Ez \big)=\pi_{\eK^2}\big( f(z) \big)\). Par \( f\) nous avons
	\begin{equation}
		\begin{aligned}[]
			a & \mapsto \begin{pmatrix}
				            1 \\
				            0
			            \end{pmatrix}
			  & b                       & \mapsto\begin{pmatrix}
				                                     0 \\
				                                     1
			                                     \end{pmatrix}.
		\end{aligned}
	\end{equation}
	Donc par \( g\) nous avons
	\begin{equation}
		\begin{aligned}[]
			a & \mapsto\infty &
			b\mapsto 0.
		\end{aligned}
	\end{equation}
	Nous avons aussi \( f(\lambda x+\mu y)=(\lambda,\mu)\) et
	\begin{subequations}
		\begin{align}
			g(c) & =g\big( \pi_E(x+y) \big) \\
			     & =\pi_Ff(x+y)             \\
			     & =\pi_F(f(x)+f(y))        \\
			     & =\pi_F\begin{pmatrix}
				             1 \\
				             1
			             \end{pmatrix}     \\
			     & =1.
		\end{align}
	\end{subequations}
	La dernière égalité est le fait que la direction \( (1,1)\) dans \( \eR^2\) est représentée par le point \( x=1\) sur la droite \( y=1\) qui est notre «représentation» de la droite affine. L'application \( g\) a donc toutes les propriétés qu'il faut pour être l'application qui définit le birapport. Nous avons donc bien \( g(d)=[a,b,c,d]\).

	D'une part si \( d=\pi_E(\lambda x+\mu y)\) alors
	\begin{equation}
		g(d)=\pi_{\eK^2}f(\lambda x+\mu y)=\pi_{\eK^2}(\lambda,\mu).
	\end{equation}
	Dans l'autre sens si \( [a,b,c,d]=\pi_{\eK^2}(\lambda,\mu)\) alors supposons que \( g(d)=\pi_{\eK^2}(\lambda,\mu)\) avec \( d=\pi_E(v)\) alors
	\begin{equation}
		g\pi_Ev=\pi_{\eK^2}f(v),
	\end{equation}
	ce qui implique \( f(v)=\alpha(\lambda,\mu)\) pour un certain \( \alpha\in \eK\). Par conséquent \( v=\alpha(\lambda x+\mu y)\) et \( d=\pi_E(\lambda x+\mu y)\).
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Coordonnées homogènes}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Soit \( E\) un espace vectoriel de dimension \( n+1\) et une base \( \{ e_0,\ldots, e_n \}\) de \( E\). Soit \( M\in P(E)\) et \( u\in E\) un élément engendrant \( M\). Au point \( M\) nous voudrions associer les coordonnées \( (x_0,\ldots, x_n)\) de \( u\) dans \( E\). Notons que toutes les coordonnées de \( u\) ne sont jamais nulles en même temps parce que \( u\) doit indiquer une direction. Nous savons par ailleurs que les coordonnées \( (x_0,\ldots, x_n)\) indiquent le même point de \( P(E)\) que les coordonnées \( (x'_0,\ldots, x'_n)\) si et seulement si \( x_i=\lambda x_i\).

\begin{definition}      \label{DEFooLWMHooMWxAFq}
	La classe d'équivalence de \( (x_0,\ldots, x_n)\) est la \defe{coordonnée homogène}{coordonnées!homogène} de \( M\). Nous la notons \( (x_0:\ldots :x_n)\).\nomenclature[G]{\( (x_0:\ldots:x_n)\)}{coordonnées homogènes dans un espace projectif}
\end{definition}

Si nous avons une base \( \{ e_i \}\) de \( \eR^n\) nous associons à \( M\in P(E)\) les coordonnées \( (X:Y:T)\). Mais si on prend la base \( \{ 2e_1,e_2,\ldots, e_n \}\), les coordonnées du même point deviennent \( (X/2:Y:T)\) alors que du point de vue de l'espace projectif, rien n'a été changé : la classe de \( e_1\) est la même que celle de \( 2e_1\). Les coordonnées homogènes\footnote{Définition \ref{DEFooLWMHooMWxAFq}.} ne sont donc pas intrinsèques.

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Curiosité : matrice de translation}
%---------------------------------------------------------------------------------------------------------------------------

Si \( E\) est un espace vectoriel, l'espace projectif \( P(E)\) est l'ensemble des classes d'équivalence dans \( E\) pour la relation \( v\sim \lambda v\) pour tout \( \lambda\neq 0\).

Il se fait que l'étude de \( \eR^3\) peut être fait à partir de \( \eR^4\) en considérant les coordonnées homogènes sur \( P(\eR^4)\). Plus précisément, nous considérons
\begin{equation}
	\begin{aligned}
		\varphi\colon \eR^3 & \to P(\eR^4)                   \\
		(x,y,z)             & \mapsto \big[ (x,y,z,1) \big].
	\end{aligned}
\end{equation}
Cela est injectif mais pas surjectif parce que les éléments de la forme \( [(x,y,z,0)]\) ne sont pas atteints. Ces éléments sont alors dits «à l'infini» .

Nous aurions pu placer \( \eR^3\) dans \( \eR^4\) de nombreuses autres manières; chacune aurait donné une notion différente de «point à l'infini».

Nous allons maintenant montrer une petite curiosité qui a une grande importance en informatique, lors de la manipulation d'objets 3D. Nous considérons la bijection
\begin{equation}
	\begin{aligned}
		\varphi\colon \eR^3 & \to \eR^4          \\
		(x,y,z)             & \mapsto (x,y,z,1).
	\end{aligned}
\end{equation}
Soit l'opérateur de translation \( T_a\colon \eR^3\to \eR^3\). En considérant la matrice
\begin{equation}
	T^h_a=\begin{pmatrix}
		1 & 0 & 0 & a_x \\
		0 & 1 & 0 & a_y \\
		0 & 0 & 1 & a_z \\
		0 & 0 & 0 & 1
	\end{pmatrix},
\end{equation}
nous avons
\begin{equation}
	T_a=\varphi^{-1}\circ T_a^h\circ \varphi.
\end{equation}
Autrement dit, ce passage de \( \eR^3\) à \( \eR^4\) permet de voir les translations comme des matrices, et c'est bien pratique.

Si \( R\colon \eR^3\to \eR^3\) est une rotation, la matrice correspondante sur \( \eR^4\) est
\begin{equation}
	R^h=\begin{pmatrix}
		R & 0 \\
		0 & 1
	\end{pmatrix}.
\end{equation}
Elle se combine assez bien avec une translation parce que le produit donne
\begin{equation}
	T^h_aR^h=\begin{pmatrix}
		R               & \begin{pmatrix}
			                  a_x \\
			                  a_y \\
			                  a_z
		                  \end{pmatrix} \\
		\begin{pmatrix}
			0 & 0 & 0
		\end{pmatrix} & 1
	\end{pmatrix}.
\end{equation}
C'est-à-dire que la translation et la rotation restent assez visible dans la matrice composée.

Note : pour la composition \( R^hT^h_a\), c'est beaucoup moins vrai.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Dualité}
%---------------------------------------------------------------------------------------------------------------------------

Soit \( E\) un espace vectoriel de dimension \( n+1\). Une forme linéaire non nulle est un élément de \( E^*\), mais aussi un représentant d'un élément de \( P(E^*)\).

Le noyau d'une forme linéaire \( \omega\) est un hyperplan. Le noyau de la forme linéaire \( \lambda\omega\) étant le même hyperplan, l'hyperplan est donné par toute la classe de \( \omega\) dans \( P(E^*)\). Nous avons donc une bijection
\begin{equation}
	P(E^*)\leftrightarrow \{ \text{hyperplans vectoriels de } E \}.
\end{equation}

Soit un espace vectoriel \( E\) de dimension \( 3\) muni d'une base \( \{ e_1,e_2,e_3 \}\) à partir de laquelle nous construisons la base duale \( \{ e_1^*,e_2^*,e_3^* \}\) de l'espace dual \( E^*\). À un élément \( m\in P(E^*)\) nous associons la droite
\begin{equation}
	H_m=\{ (X:Y:T)\tq m(X,Y,T)=0 \}
\end{equation}
dans \( P(E)\). Si les coordonnées homogènes de \( m\) étaient \( (u:v:w)\) alors l'équation de la droite \( H_m\) est
\begin{equation}    \label{Eqezgpmk}
	uX+vY+wT=0.
\end{equation}
En effet si \( \omega\in E^*\) est un représentant de \( m\) alors \( \omega=\lambda(ue_1^*+ve_2^*+we_3^*)\) et l'équation \eqref{Eqezgpmk} est indépendante de \( \lambda\) ainsi que du choix du représentant dans \( E\) du point \( (X:Y:T)\) dans \( P(E)\).

Si les points \( m_1\) et \( m_2\) sont distincts dans \( P(E^*)\), ils donnent deux droites \( m_1(X,Y,T)=0\) et \( m_2(X,Y,T)=0\). Les points de la droite qui joint \( m_1\) à \( m_2\) dans \( P(E^*)\) sont de la forme \( \lambda m_1+\mu m_2\) et ils sont associés à l'équation
\begin{equation}
	\lambda m_1(X,Y,T)+\mu m_2(X,Y,T)=0
\end{equation}
qui sont encore des droites dans \( P(E)\). Toutes ces droites passent par le point d'intersection des droits associées à \( m_1\) et \( m_2\). Nous avons donc
\begin{equation}
	\bigcap_{\lambda,\mu}H_{\lambda m_1+\mu m_2}=H_{m_1}\cap H_{m_2}.
\end{equation}

\begin{lemma}
	L'application
	\begin{equation}
		\begin{aligned}
			P(E^*) & \to \{ \text{droites dans } P(E) \} \\
			m      & \mapsto H_m
		\end{aligned}
	\end{equation}
	est une bijection.
\end{lemma}

\begin{proof}
	Une droite dans \( P(E)\) est donnée en coordonnées homogènes par une équation \( aX+bY+cT=0\). Cette droite est décrite par le point \( (a:b:c)\) dans \( P(E^*)\). Ce dernier correspond à la direction de la forme \( ae_1^*+be_2^*+ce_3^*\). Cela prouve que l'application est surjective.

	Pour l'injectivité, si \( m_1\neq m_2\) dans \( P(E^*)\), les formes \( \omega_1\) et \( \omega_2\) associées dans \( E^*\) ne sont pas multiples l'une de l'autre. Donc les équations
	\begin{equation}
		a_1X+b_1Y+z_1T=0
	\end{equation}
	et
	\begin{equation}
		a_2X+b_2Y+z_2T=0
	\end{equation}
	n'ont pas de solutions communes et décrivent donc des droites distinctes.
\end{proof}

\begin{lemma}   \label{LemjXywjH}
	Trois points distincts \( m_1\), \( m_2\) et \( m_3\) dans \( P(E^*)\) sont alignés si et seulement si les droites \( H_{m_1}\), \( H_{m_2}\) et \( H_{m_3}\) sont distinctes et concourantes.
\end{lemma}

\begin{proof}
	Supposons avoir trois points alignés, c'est-à-dire
	\begin{equation}    \label{EqXyfbmF}
		m_3=m_1+\mu(m_2-m_1).
	\end{equation}
	Soit \( X:Y:T\) le point d'intersection de \( H_{m_1}\) avec \( H_{m_2}\). Alors \( m_1(X,Y,T)=m_2(X,Y,T)=0\). En tenant compte de \eqref{EqXyfbmF} nous avons alors évidemment \( m_3(X,Y,T)=0\).

	Supposons maintenant que les trois droites \( H_{m_i}\) soient concourantes. Nous avons donc un point \( (X:Y:T)\) dans \( P(E)\) tel que \( m_i(X,Y,T)=0\). Si \( m_i\) est la classe de \( a_ie_1^*+b_ie_2^*+c_ie^*_3\) alors nous avons le système
	\begin{subequations}
		\begin{numcases}{}
			a_1X+b_1Y+c_1T=0\\
			a_2X+b_2Y+c_2T=0\\
			a_3X+b_3Y+c_3T=0.
		\end{numcases}
	\end{subequations}
	Afin que cela ait une solution non triviale nous devons avoir
	\begin{equation}
		\det\begin{pmatrix}
			a_1 & b_1 & c_1 \\
			a_2 & b_2 & c_2 \\
			a_3 & b_3 & c_3
		\end{pmatrix}= 0,
	\end{equation}
	c'est-à-dire que les points \( (a_i,b_i,c_i)\) soient alignés.
\end{proof}

En tenant compte de ce qui a été dit, une droite dans \( P(E^*)\) est constituée de points qui fournissent des droites concourantes dans \( P(E)\). Donc une droite de \( P(E^*)\) se caractérise par un point de \( P(E)\) (l'intersection) de la façon suivante. Un point \( M_d\in P(E)\) donne lieu à un \defe{faisceau de droites}{faisceau de droites} passant par \( M_d\). Chacune de ces droites donne lieu à un point de \( P(E^*)\) et tous ces points sont alignés. Nous avons ainsi construit la droite \( d\) dans \( P(E^*)\) correspondante au point \( M_d\) de \( P(E)\).

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Polynômes}
%---------------------------------------------------------------------------------------------------------------------------

Soit l'espace projectif de dimension \( n\) avec ses coordonnées homogènes \( (X_0:\ldots :X_n)\). Nous considérons l'espace affine \( H\equiv X_n=1\) dans l'espace vectoriel \( E\) de dimension \( n+1\). Nous considérons pour \( H\) un repère affine ayant pour origine le point \( (0,\ldots, 0,1)\). Considérons un polynôme homogène \( P\) sur le corps \( \eK\). L'équation
\begin{equation}
	P(X_0,\ldots, X_n)=0
\end{equation}
sur l'espace vectoriel \( E\) descend immédiatement à l'espace projectif : étant donné que \( P\) est homogène nous avons \( P(u)=0\) si et seulement si \( P(\lambda u)=0\).

Nous essayons de décrire l'ensemble \( A\) des points de \( P(E)\) satisfaisant \( P(X_0,\ldots, X_n)=0\). Nous savons que les éléments de \( P(E)\) ont chacun un représentant soit dans \( H\) soit sur la droite à l'infini. Ceux de \( A\) ayant un représentant dans \( H\) sont d'équation
\begin{equation}
	Q(x_0,\ldots, x_{n-1})=0
\end{equation}
où \( Q\) est le polynôme donné par \( Q(x_0,\ldots, x_{n-1})=P(x_0,\ldots, x_{n-1},1)\). Les points de \( A\) ayant un représentant sur la droite à l'infini s'obtiennent par l'équation
\begin{equation}
	R(x_0,\ldots, x_{n-1})=0
\end{equation}
où \( R\) est le polynôme donné par \( R(x_0,\ldots, x_{n-1})=P(x_0,\ldots, x_{n-1},0)\).

\begin{example}
	Nous considérons la conique projective
	\begin{equation}    \label{EqpLeQIN}
		X^2-XT-Y^2-T^2=0.
	\end{equation}
	Elle est décomposée en deux parties : une dans l'espace affine «normale» et une à l'infini. La première s'obtient en posant \( T=1\) dans \eqref{EqpLeQIN} :
	\begin{equation}    \label{EqdGHzqJ}
		x^2-x-y^2-1=0.
	\end{equation}
	L'autre est obtenue en posant \( T=0\) :
	\begin{equation}
		x^2-y^2=0.
	\end{equation}
	La partie à l'infini est donc composée de deux points : \( (1:1:0)\) et \( (1:-1:0)\).

	Le graphique de l'équation \eqref{EqdGHzqJ} est donné à la figure~\ref{LabelFigProjPoly}. Nous y voyons que les asymptotes sont effectivement données par les directions \( (1,1)\) et \( (1,-1)\) dans le plan.
	\newcommand{\CaptionFigProjPoly}{Le graphique de \( x^2-x-y^2-1=0\).}
	\input{auto/pictures_tex/Fig_ProjPoly.pstricks}
\end{example}

Nous pouvons tenter de faire l'exercice inverse : considérer une conique dans \( \eR^2\), la voir comme une partie d'une conique dans l'espace projectif et trouver les points à l'infini qui la complètent.

\begin{example}
	La droite projective usuelle est donnée par la droite affine \( y-1=0\). L'homogénéisation donne \( y-z=0\) et par conséquent la partie à l'infini est donnée par \( y=0\), c'est-à-dire la direction \( (1,0)\) comme il se doit.
\end{example}

\begin{example}
	Prenons la conique
	\begin{equation}
		x^2+xy+y^3-2=0.
	\end{equation}
	D'abord nous homogénéisons cette équation pour la voir dans \( \eR^3\) :
	\begin{equation}
		x^2z+xyz+y^3-2z^3=0.
	\end{equation}
	Les points à l'infini sont ceux qui correspondent à \( z=0\), c'est-à-dire la droite donnée en coordonnées homogènes par \( (1:0:0)\).
\end{example}
