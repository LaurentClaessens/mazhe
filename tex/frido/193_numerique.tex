% This is part of Mes notes de mathématique
% Copyright (C) 2010-2018
%   Laurent Claessens
% See the file LICENCE.txt for copying conditions.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Problèmes de dimension un}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Soit \( u\colon \eR\to \eR\) une fonction et \( h>0\). Nous définissons les opérations suivantes (qui sont supposées approximer la dérivée \( u'(x)\) lorsqu'elle existe).

\begin{definition}
    La \defe{différence progressive}{différence!progressive} est
    \begin{equation}
        (D^+_hu)(x)=\frac{ u(x+h)-u(x) }{ h },
    \end{equation}
    la \defe{différence régressive}{différence!régressive} est
    \begin{equation}
        (D^-_hu)(x)=\frac{ u(x)-u(x-h) }{ h },
    \end{equation}
    la \defe{différence centrée}{différence!centrée} est
    \begin{equation}
        (D^0_hu)(x)=\frac{ u(x+h)-u(x-h) }{ 2h }.
    \end{equation}
\end{definition}
Nous ne noterons pas toujours la dépendance en \( h\), c'est-à-dire que nous noterons \( D^+u\) au lieu de \( D^+_hu\) lorsque cela ne pose pas de problèmes.

Notons que \( u''\) peut être approximé par \( D^+D^+u\), \( D^0D^+\), \( D^+D^-\), et encore de nombreuses autres possibilités.

Voici un lemme qui dit que tout cela n'est pas si mal, pourvu que \( u\) soit assez régulière.

\begin{lemma}       \label{LEMooZECZooVKxOZZ}
    Soit un ouvert connexe \( \Omega\) de \( \eR\), soit \( x\in \Omega\) et \( h>0\) tel que \( \overline{ B(x,h) }\subset \Omega\).
    \begin{enumerate}
        \item
            Si \( u\in C^2(\Omega)\) alors
            \begin{equation}
                | u'(x)-D^+u(x) |\leq \frac{ h }{2}\| u'' \|_{\bar\Omega}
            \end{equation}
            et
            \begin{equation}
                | u'(x)-D^-u(x) |\leq \frac{ h }{2}\| u'' \|_{\bar\Omega}.
            \end{equation}
        \item       \label{ITEMooSAWJooJUTWAb}
            Si \( u\in C^3(\bar\Omega)\) alors
            \begin{equation}
                | u'(x)-D^0(x) |\leq \frac{ h^2 }{2}\| u^{(3)} \|_{\bar\Omega}
            \end{equation}
        \item       \label{ITEMooRWUHooZJLKuL}
            Si \( u\in C^4(\bar \Omega)\) alors
            \begin{equation}
                | u''(x)-D^-D^+u(x) |\leq \frac{ h^2 }{ 12 }\| u^{(4)} \|_{\bar\Omega}.
            \end{equation}
    \end{enumerate}
\end{lemma}

\begin{proof}
    Nous prouvons le point~\ref{ITEMooRWUHooZJLKuL}. D'abord nous regardons de quoi nous avons besoin :
    \begin{equation}        \label{EQooBLIIooWHXbqD}
        D^-D^+u(x)=\frac{ (D^+u)(x)-(D^+u)(x-h) }{ h }=\frac{ u(x+h)-2u(x)+u(x-h) }{ h^2 }
    \end{equation}
    Nous allons y mettre les approximations de \( u(x+h)\) et \( u(x-h)\) par Taylor, proposition~\ref{PropResteTaylorc} :
    \begin{equation}
        u(x+h)=u(x)+hu'(x)+\frac{ h^2 }{2}u''(x)+\frac{ h^3 }{ 6 }u'''(x)+\frac{ h^4 }{ 24 }u^{(4)}(x+\theta_1h)
    \end{equation}
    avec \( \theta_1\in \mathopen[ 0 , 1 \mathclose]\). De même,
    \begin{equation}
        u(x-h)=u(x)-hu'(x)+\frac{ h^2 }{2}u''(x)-\frac{ h^3 }{ 6 }u'''(x)+\frac{ h^4 }{ 24 }u^{(4)}(x-\theta_2h)
    \end{equation}
    avec \( \theta_2\in \mathopen[ 0 , 1 \mathclose]\).

    Donc
    \begin{equation}
        u(x+h)+u(x-h)-2u(x)=h^2u''(x)+\frac{ h^4 }{ 4! }\Big( u^{(4)}(x+\theta_1h)+u^{(4)}(x-\theta_2h) \Big),
    \end{equation}
    ce qui donne
    \begin{equation}
        (D^-D^+u)(x)=u''(x)+\frac{ h^2 }{ 4! }\Big( u^{(4)}(x+\theta_1h)+u^{(4)}(x-\theta_2h) \Big).
    \end{equation}
    Chacun des deux termes dans la parenthèse peut être majoré par \( \| u^{(4)} \|_{\bar\Omega}\). Notons que c'est une majoration très sauvage parce que \( x+\theta_1h\) ne prend ses valeurs que dans \( \mathopen[ x , x+h \mathclose]\) avec \( h\) supposé petit. Quoi qu'il en soit nous ne pouvons pas dire mieux que
    \begin{equation}
        | u''(x)-D^-D^+u(x) |\leq \frac{ h^2 }{ 12 }\| u^{(4)} \|_{\bar\Omega}.
    \end{equation}
\end{proof}

\begin{remark}[\cite{MonCerveau}]
    Lorsque nous écrivons
    \begin{equation}        \label{EQooHSPFooTJIoFy}
        | u'(x)-D^+u(x) |\leq \delta
    \end{equation}
    pour tout \( x\), nous ne pouvons pas écrire
    \begin{equation}
        \| u'-D^+u \|_{\infty}\leq \delta
    \end{equation}
    parce que l'inégalité \eqref{EQooHSPFooTJIoFy} n'est valable que pour les \( x\) tels que \( \mathopen[ x-h , x+h \mathclose]\subset \Omega\), de telle sorte que l'inégalité n'est pas spécialement correcte sur \( \bar\Omega\).
\end{remark}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Un schéma à cinq points}
%---------------------------------------------------------------------------------------------------------------------------

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Poser le système}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Soit \( \Omega=\mathopen] 0 , 1 \mathclose[\) et l'équation différentielle
\begin{equation}        \label{EQooXJBWooRhCsLy}
     \begin{cases}
         -u''(x)+c(x)u(x)=f    &   \text{sur } \Omega\\
         u(0)=\alpha\\
         u(1)=\beta
     \end{cases}
\end{equation}
où \( c\) est une fonction positive et \( \alpha,\beta\in \eR\). Nous considérons \( h>0\) assez petit pour que le reste ait un sens. Si nous cherchons des solutions dans \( C^4(\bar\Omega)\), le lemme~\ref{LEMooZECZooVKxOZZ} nous dit que
\begin{equation}
    | u''(x)-D^-D^+u(x) |=\eta(h^2)
\end{equation}
où \( \eta\) est une fonction telle que \( \lim_{t\to 0} \eta(t)=0\). Nous pouvons récrire l'équation différentielle sous la forme
\begin{equation}
    -D^-D^+u(x)+c(x)u(x)=f(x)+\eta(h^2).
\end{equation}
Si nous négligeons le terme \( \eta(h^2)\) qui est supposé être petit nous pouvons tenter de résoudre pour la fonction \( u_h\)
\begin{equation}
    -D^-D^+u_h(x)+c(x)u_h(x)=f(x).
\end{equation}
Notons ici l'importance de la notion de problème bien posé parce que en remplaçant le paramètre (fonctionnel) \( f\) par \( f+\eta(h^2)\), nous modifions les solutions. Dans la mesure où le problème est bien posé, cette petite modification ne modifiera pas trop la solution et nous pouvons espérer que \( \| u-u_h \|\) soit petit pour une norme ou une autre.

Utilisant l'expression \eqref{EQooBLIIooWHXbqD} pour \( D^-D^+\) nous avons l'équation suivante pour \( u_h\) :
\begin{equation}        \label{EQooECLXooFxZEeA}
    \frac{1}{ h^2 }\Big( 2u_h(x)-u_h(x+h)-u_h(x-h) \Big)+c(x)u_h(x)=f(x).
\end{equation}
Avons-nous gagné quelque chose ? Pas encore. L'idée de la discrétisation est de ne considérer \( u_h\) qu'en certains points, et de prendre ces points à intervalles réguliers de taille \( h\). Soient donc \( N\) un nombre entier et \( h=1/(N+1)\). Nous posons
\begin{equation}
    x_k=kh
\end{equation}
pour \( i=0,\ldots, N+1\). Avec cela nous avons
\begin{subequations}
    \begin{align}
        \overline{ \Omega }&=\bigcup_{k=0}^{N-1}\mathopen[ x_k , x_{k+1} \mathclose]\\
        x_0&=0\\
        x_{N+1}&=1.
    \end{align}
\end{subequations}
Nous posons surtout
\begin{equation}
    \Omega_h=\{ x_i \}_{i=1,\ldots, N}
\end{equation}
et
\begin{equation}
    \bar\Omega_h=\{ x_i \}_{i=0,\ldots, N+1}.
\end{equation}
Enfin, nous ne considérons plus \( u_h\) que comme une fonction \( u_h\colon \bar\Omega_h\to \eR\). C'est-à-dire que \( u_h\) est un vecteur à \( N+2\) composantes.

L'équation \eqref{EQooECLXooFxZEeA} devient
\begin{equation}        \label{EQooZMVMooTqlpkF}
    \frac{1}{ h^2 }\big( 2u_h(x_i)-u_h(x_{i+1})-u_h(x_{i-1})+c(x_i)u_h(x_i) \big)=f(x_i)
\end{equation}
pour \( i=1,\ldots, N\). Sur les bords, cette équation n'est pas possible parce que \( x_{i-1}\) ou \( x_{i+1}\) n'existerait pas. Au contraire, sur les bords nous avons les conditions aux bords
\begin{equation}
    u_h(x_0)=\alpha
\end{equation}
et
\begin{equation}
    u_h(x_{N+1})=\beta.
\end{equation}

En posant \( c_i=c(x_i)\) et \( u_i=u_h(x_i)\), les inconnues du problème sont les nombres \( u_i\) (\( i=1,\ldots, N+1\)). Elles sont immédiatement résolues pour \( u_0\) et \( u_{N+1}\). Pour les autres, il faut écrire et résoudre un système d'équation linéaire.

L'écriture du système linéaire à résoudre consiste essentiellement à écrire \eqref{EQooZMVMooTqlpkF} en séparant les cas \( i=0\) et \( i=N\) parce que nous savons déjà les valeurs de \( u_0\) et \( u_N\). Le système que nous avons est :
\begin{subequations}
    \begin{numcases}{}
    \left( \frac{ 2 }{ h^2 }+c_1 \right)u_1-\frac{1}{ h^2 }u_2=f_1+\frac{ \alpha }{ h^2 }  & $i=1$\\
    \left( \frac{ 2 }{ h^2 }+c_N \right)u_N-\frac{1}{ h^2 }u_{N-1}=f_N+\frac{ \beta }{ h^2 }  &\( i=N\) \\
    \left( \frac{ 2 }{ h^2 }+c_i \right)u_i-\frac{1}{ h^2 }u_{i+1}-\frac{1}{ h^2 }u_i=f_i.& autres
    \end{numcases}
\end{subequations}
Cela se met sous la forme matricielle
\begin{equation}
    L_hU_h=F_h
\end{equation}
pour
\begin{equation}        \label{EQooMNTJooYPYoAj}
    F_h=\big( f_1+\frac{ \alpha }{ h^2 },f_2,\ldots, f_{N-1},f_N+\frac{ \beta }{ h^2 } \big)
\end{equation}
et les éléments non nuls de \( L_h\) sont :
\begin{subequations}
    \begin{align}
        (L_h)_{i,i-1}&=-\frac{1}{ h^2 }&\text{ pour }i&=2,\ldots, N\\
        (L_h)_{i,i+1}&=-\frac{1}{ h^2 }&\text{ pour }i&=1,\ldots, N-1\\
        (L_h)_{i,i}&=\frac{ 2 }{ h^2 }+c_i&\text{ pour }i&=1,\ldots, N.
    \end{align}
\end{subequations}
Cette matrice est pleine de zéros, à part les trois diagonales centrales, et il existe des méthodes efficaces pour résoudre le système d'équation correspondant.

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Propriétés du système}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

La matrice est la suivante :
\begin{equation}
    L_h=\begin{pmatrix}
        \frac{ 2 }{ h^2 }+c_1    &   -1/h^2    &   0    & 0     &    \cdots         &   0 \\
        -1/h^2    &   \frac{ 2 }{ h^2 }+c_2    &   -1/h^2   &   0 &    \cdots       &      0 \\
        0    &   -1/h^2    &   \frac{ 2 }{ h^2 }+c_3   & -1/h^2     &    \ddots &   \vdots  \\
        0   &      0    &     -1/h^2  & \ddots & \ddots     & 0\\
        \vdots&  \vdots   &  \ddots & \ddots & \ddots&-1/h^2\\
        0   &  0 & \cdots & 0 & -1/h^2 & \frac{ 2 }{ h^2 }+c_N
    \end{pmatrix}
\end{equation}
où nous avions déjà posé l'hypothèse \( c_i\geq 0\) pour tout \( i\).

\begin{lemma}       \label{LEMooGGHQooNnVsuu}
    La matrice \( L_h\) est irréductible\footnote{Caractérisation~\ref{PROPooZTYDooZAxQxF}.} à diagonale fortement dominante\footnote{Définition~\ref{DEFooLSUTooHuXabV}.}.
\end{lemma}

\begin{proof}
    Nous décomposons la preuve en plusieurs parties.
    \begin{subproof}
        \item[La première ligne]

            Sur la première ligne, seuls deux éléments sont non nuls et nous avons
            \begin{equation}
                L_{11}=\frac{ 2 }{ h^2 }+c_1\geq \frac{ 2 }{ h^2 }>\frac{1}{ h^2 }=L_{12}.
            \end{equation}

        \item[La dernière ligne]

            Elle est semblable à la première.

        \item[Les autres lignes]

            Sur les autres lignes nous avons trois éléments non nuls et
            \begin{equation}
                \sum_{j\neq i}| A_{ij} |=\frac{ 2 }{ h^2 }\leq \frac{ 2 }{ h^2 }+c_i=L_{ii}.
            \end{equation}

        \item[Diagonale fortement dominante]

            Nous avons prouvé jusqu'à présent que \( L_h\) était une matrice à diagonale fortement dominante.

        \item[Irréductible]

            Nous allons utiliser la caractérisation de la proposition~\ref{PROPooZTYDooZAxQxF}\ref{ITEMooVNOHooRUNpwG}. Pour cela nous considérons le chaine d'éléments non nuls
            \begin{equation}
                A_{12}, A_{23},\ldots, A_{N-1,N}=-\frac{1}{ h^2 }.
            \end{equation}
            Soient deux indices \( i\) et \( j\) avec \( i<j\). Cette suite d'indice (ou un sous-suite) rend \( i\) et \( j\) connectés.

            Si par contre \( i>j\), il faut considérer la suite inversée grâce au fait que \( L_h\) est symétrique :
            \begin{equation}
                A_{N,N-1},A_{N-1,N-2},\ldots, A_{32}, A_{21}=-\frac{ 1 }{ h^2 }.
            \end{equation}

    \end{subproof}
\end{proof}

\begin{proposition}     \label{PROPooOQJVooJMTkVM}
    Soit le problème
    \begin{equation}                \label{EQooEUHQooWHRelr}
         \begin{cases}
             -u''(x)+c(x)u(x)=f    &   \text{sur } \Omega\\
             u(0)=\alpha\\
             u(1)=\beta
         \end{cases}
    \end{equation}
    où \( c\) est une fonction positive et \( \alpha,\beta\in \eR\). Nous considérons \( h>0\) assez petit pour que le reste ait un sens. Et nous approximons \( u''\) par \( D^-D^+u\).

    La matrice \( L_h\) des différences finies associée à ce problème est
    \begin{enumerate}
        \item
            une M-matrice,
        \item
            strictement définie positive,
        \item
             d'inverse \( L_h^{-1}>0\).
    \end{enumerate}
\end{proposition}

\begin{proof}
    Le théorème~\ref{THOooLZGSooSevggj} dit que \( L_h\) est une M-matrice. La Proposition~\ref{PROPooQBWQooBbeZLO} nous donne aussi que \( L_h\) est strictement définie positive.

    Le lemme~\ref{LEMooGGHQooNnVsuu} dit que \( L_h\) est irréductible, ce qui permet à la proposition~\ref{PROPooZDMQooIZAbKK} de conclure que \( L_h^{-1}>0\).
\end{proof}



Cela étant rappelé, nous pouvons continuer.

\begin{lemma}       \label{LEMooDXPRooOhwqSZ}
    Soit \( \Omega=\mathopen] 0 , 1 \mathclose[\), soit \( N\in \eN\) et \( h=1/(N+1)\).  La solution \( w_h\colon \Omega_h \to \eR\) du problème discrétisé
        \begin{subequations}        \label{SUBEQooFJKIooLvzMBG}
            \begin{numcases}{}
                -(D^-D^+w_h)(x_i)=1\\
                w_h(0)=0\\
                w_h(1)=0
            \end{numcases}
        \end{subequations}
        pour tout \( x_i=ih\) (\( i=1,\ldots, N\)) donne les valeurs exactes des \( w(x_i)\) lorsque \( w\) est la solution de
        \begin{subequations}        \label{SUBEQooCRFWooJegcUk}
            \begin{numcases}{}
                -w''(x)=1\\
                w(0)=0\\
                w(1)=0.
            \end{numcases}
        \end{subequations}
\end{lemma}

\begin{proof}
    Un enseignement de la proposition~\ref{PROPooOQJVooJMTkVM} est que le système \eqref{SUBEQooFJKIooLvzMBG} peut être écrit sous la forme d'un système linéaire \( L^0_hw_h=F_h\) où \( L_h^0\) est inversible. Il y a donc unicité de la solution.

    D'autre part, la solution du système \eqref{SUBEQooCRFWooJegcUk} est \( w(x)=\frac{ 1 }{2}(x-x^2)\), qui est de classe \(  C^{\infty}\). Le lemme~\ref{LEMooZECZooVKxOZZ}\ref{ITEMooRWUHooZJLKuL} dit que \( D^-D^+w=w''\). Donc les valeurs \( w(x_i)\) résolvent aussi le système \eqref{SUBEQooFJKIooLvzMBG}.
\end{proof}

\begin{lemma}[Quelques estimations]
    La matrice \( L_h\) du problème sus-mentionné en \eqref{EQooEUHQooWHRelr} vérifie\quext{Dans le CTES d'analyse numérique de Marseille, l'estimation donnée est \(  \| L_h^{-1} \|_{\infty}\leq \frac{1}{ 4 } \).} :
    \begin{enumerate}
        \item
            \( \| L_h \|_{\infty}\leq \frac{4 }{ h^2 }+\| c \|_{\infty}\)
        \item
            \( \| L_h^{-1} \|_{\infty}\leq \frac{1}{ 8 }\).
    \end{enumerate}
\end{lemma}

\begin{proof}
    Nous nous souvenons de la formule \eqref{EQooPLCIooVghasD} :
    \begin{equation}
        \| A \|_{\infty}=\max_{i=1,\ldots, n}\sum_{j=1}^n| A_{ij} |.
    \end{equation}
    La première ligne a pour somme : \( \frac{ 3 }{ h^2 }+c_1\), la dernière a pour somme \( \frac{ 3 }{ h^2 }+c_n\) et les autres sont pour somme \( \frac{ 4 }{ h^2 }+c_i\). Elles sont donc toutes majorées par \( \frac{ 4 }{ h^2 }+\| c \|_{\infty}\).

    Pour l'estimation de \( \| L_h^{-1} \|_{\infty}\) nous allons nous appuyer sur le théorème~\ref{THOooWIFGooBQpddF}.

    Commençons par considérer le problème
    \begin{subequations}        \label{SUBEQSooRENKooZaRjvL}
        \begin{numcases}{}
            -w''=1\\
            w(0)=w(1)=0.
        \end{numcases}
    \end{subequations}
    La première équation dit que \( w\) est un polynôme de degré \( 2\). En écrivant \( w(x)=ax^2+bx+c\) et en imposante toutes les contraintes, nous trouvons l'unique solution
    \begin{equation}
        w(x)=-\frac{ 1 }{2}(x^2-x).
    \end{equation}
    Le lemme~\ref{LEMooDXPRooOhwqSZ} nous dit que la fonction \( w\) prise aux points \( x_i=ih\) donne les valeurs de \( w_h\).

    La matrice \( L^0_h\) est une M-matrice et le vecteur \( w_h\) vérifie \( L_h^0w_h=\mtu\). Donc le théorème~\ref{THOooWIFGooBQpddF} s'applique et
    \begin{equation}
        \| (L_h^0)^{-1} \|\leq \| w_h \|_{\infty}=\frac{1}{ 8 }.
    \end{equation}
    L'obtention de \( 1/8\) n'est rien d'autre que la recherche du maximum (en valeur absolue) de la parabole \( x\mapsto (x-x^2)/2\) pour \( x\in \mathopen[ 0 , 1 \mathclose]\). Le maximum est atteint pour \( x=1/2\); calcul de dérivée et tout ça \ldots

    Nous retournons maintenant à notre matrice originale \( L_h\). Nous avons
    \begin{equation}
        L_h-L_h^0=\diag(c_1,\ldots, c_n)\geq 0,
    \end{equation}
    et aussi
    \begin{equation}
        L_h^{-1}-(L_h^0)^{-1}=\underbrace{L_h^{-1}}_{\geq 0}\underbrace{(L_h^0-L_h)}_{\leq 0}\underbrace{(L_h^0)^{-1}}_{\geq 0}
    \end{equation}
    parce que \( L_h\) est une M-matrice. Donc tous les coefficients de \( L_h^{-1}-(L_h^0)^{-1}\) sont négatifs. Cela implique
    \begin{equation}
        L_h^{-1}\leq (L_h^0)^{-1}.
    \end{equation}
    Mais nous savons que les coefficients de \( L_h^{-1}\) sont positifs, donc le maximum de ses coefficients en valeur absolue est plus petit que ceux de \( (L_h^0)^{-1}\), c'est-à-dire
    \begin{equation}
        \| L_h^{-1} \|_{\infty}\leq\| (L_h^0)^{-1} \|_{\infty}\leq\frac{1}{ 8 }.
    \end{equation}

\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Exemple}
%---------------------------------------------------------------------------------------------------------------------------

Soit \( \Omega=\mathopen] 0 , 1 \mathclose[\) et une fonction \( u\colon \bar\Omega\to \eR\) de classe \( C^4\) vérifiant
\begin{subequations}
    \begin{numcases}{}
        -u''(x)+u(x)=\sin(x)\\
        u(0)=0\\
        u(1)=0.
    \end{numcases}
\end{subequations}
Nous allons écrire la méthode des différences finies pour \( h=1/4\). Nous posons donc les points
\begin{subequations}
    \begin{numcases}{}
        x_0=0\\
        x_1=1/4\\
        x_2=1/2\\
        x_3=3/4\\
        x_4=1.
    \end{numcases}
\end{subequations}

Vu que nous avons supposé \( u\) de classe \( C^4\), le lemme~\ref{LEMooZECZooVKxOZZ}\ref{ITEMooRWUHooZJLKuL} nous donne\footnote{Nous ferions n'importe quoi pour ne pas écrire \( u''(x)=(D^-D^+u)(x)+o(h^2)\). Notez que vous faites ce que vous voulez : écrivez avec la notation «petit \( o\)» si cela vous chante.}
\begin{equation}
    u''(x)=(D^-D^+u)(x)+\alpha(h)
\end{equation}
avec \( \lim_{h\to 0} \alpha(h)/h=0\). L'équation discrétisée serait alors
\begin{subequations}        \label{SYSTooNEQHooOWJSbT}
    \begin{numcases}{}
        -(D^-D^+u)(x)+u(x)=\sin(x)\\
        u(0)=u(1)=0.
    \end{numcases}
\end{subequations}
où nous n'avons pas précisé l'indice \( h\) au bas des opérateurs \( D^+\) et \( D^-\). Les équations \eqref{SYSTooNEQHooOWJSbT} ne doivent être posées que pour \( x_1\), \( x_2\) et \( x_3\) parce que les valeurs en \( x_0\) et \( x_4\) sont déjà connues.

\begin{subproof}
    \item[Pour \( x_1\)]
        \begin{equation}
            \frac{ u_2-2u_1+u_0 }{ h^2 }+u_1=\sin(x_1)
        \end{equation}
    \item[Pour \( x_2\)]
        \begin{equation}
            \frac{ u_3-2u_2+u_1 }{ h^2 }+u_2=\sin(x_2)
        \end{equation}
    \item[Pour \( x_3\)]
        \begin{equation}
            \frac{ u_4-2u_3+u_2 }{ h^2 }+u_3=\sin(x_3).
        \end{equation}
\end{subproof}
Nous tenons compte du fait que \( u_0=u_4=0\) et que \( h=1/4\) pour écrire le système
\begin{equation}
    \begin{pmatrix}
        -31    &   16    &   0    \\
        16    &   -31    &   16    \\
        0    &   16    &   -31
    \end{pmatrix}\begin{pmatrix}
        u_1    \\
        u_2    \\
        u_3
    \end{pmatrix}=\begin{pmatrix}
        s_1    \\
        s_2    \\
        s_3
    \end{pmatrix}
\end{equation}A
où les \( s_i\) sont des nombres parfaitement connus : par exemple \( s_1=\sin(x_1)=\sin(1/4)\simeq 0.247403959254523\).

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Problèmes de dimension deux}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


Nous allons considérer le système
\begin{equation}                \label{SYSooTANLooRgnIMp}
     \begin{cases}
         -\Delta u=f    &   \text{sur } \Omega\\
         u=g            &   \text{sur } \partial\Omega
     \end{cases}
\end{equation}
où \( \Omega=\mathopen] 0 , a \mathclose[\times \mathopen] 0 , b \mathclose[\).

\begin{remark}
    Pourquoi un signe moins devant le laplacien ? Pour avoir la proposition~\ref{PROPooOQJVooJMTkVM} qui dira que la matrice correspondant aux différences finies appliquées à ce système est une M-matrice. Sinon, c'est la matrice \(-L_h\) qui en serait une.
\end{remark}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Discrétisation en croix}
%---------------------------------------------------------------------------------------------------------------------------

Nous allons maintenant déduire une discrétisation du laplacien en discrétisant les opérations \( \partial^2_x\) et \( \partial^2_y\). Nous discrétisons \( \Omega\) en mailles carrés de côté \( h\) : \( x_k=kkh\) et \( y_k=kh\). L'opération de dérivée partielle \( \partial_x\) est discrétisée par
\begin{equation}
    (D_x^+u)(x,y)=\frac{ u(x+h)-u(x,y) }{ h }
\end{equation}
ou
\begin{equation}
    (D_x^-u)(x,y)=\frac{ u(x,y)-u(x-h,y) }{ h }
\end{equation}
ou
\begin{equation}
    (D^0_xu)(x,y)=\frac{ u(x+h,y)-u(x-h,y) }{ 2h }
\end{equation}
où le \( h\) est sous-entendu dans les opérateurs \( D^0\), \( D^+\) et \( D^-\).

La dérivée partielle seconde \( \partial^2_xu\) peut être approximée par toutes les combinaisons imaginable, par exemple
\begin{equation}
    (D^-_xD^+_xu)(x,y)=\frac{ u(x+h,y)-2u(x,y)+u(x-h,y) }{ h^2 }.
\end{equation}
Pour évaluer la différence entre \( (\partial^2_xu)(x,y)\) et \( (D^-D^+u)(x,y)\), il est possible de faire du Taylor en deux dimensions, mais nous pouvons également recycler ce qui a été fait. Nous posons \( u_y(x)=u(x,y)\) et alors \( (\partial_x^2u)(x,y)=u_y''(x)\) et le lemme~\ref{LEMooZECZooVKxOZZ}\ref{ITEMooRWUHooZJLKuL} donne, si \( u_y\) est de classe \( C^4\),
\begin{equation}
    | u_y''(x)-D^-D^+u_y(x) |\leq \frac{1}{ 12 }h^2\| u_y^{(4)} \|_{\infty}.
\end{equation}
Là, les opérateurs \( D^+\) et \( D^-\) sont ceux à une dimension. Mais nous avons \( (D^-D^+u_y)(x)=(D^-D^+u)(x,y)\) (à droite ce sont les opérateurs à deux dimensions), donc
\begin{equation}
    \big| (\partial^2_xu)(x,y)-(D^-D^+u)(x,y) \big|\leq \frac{1}{ 12 }h^2\| \partial^4_xu \|_{\infty}
\end{equation}
et nous pouvons écrire
\begin{equation}        \label{EQooCLSCooYLYJkU}
    (\partial^2_xu)(x,y)=(D^-D^+u)(x,y)+h^2R(x,y,h)
\end{equation}
où \( R\) est une fonction qui dépend de \( x\), \( y\) et \( h\), mais aussi de \( u\). Le point important est que \( R\) soit majoré par une quantité indépendante de \( h\), de telle sorte que nous ayons quelques garanties que négliger ce terme soit une bonne approximation lorsque \( h\to 0\).

Au niveau de la discrétisation, nous considérons \( x_i\) avec \( i=0,\ldots, N_x\) et \( y_j\) avec \( j=0,\ldots, N_y\). La discrétisation de \( -(\Delta u)(x,y)=f(x,y)\) donne, pour \( i=1,\ldots, N_x-1\) et \( j=1,\ldots, N_y-1\),
\begin{equation}        \label{EQooPWXBooPimUrU}
    \frac{1}{ h^2 }(-u_{i+1,j}+4u_{ij}-u_{i-1,j}-u_{i,j+1}+u_{i,j-1})=f_{ij}.
\end{equation}
Les équations avec \( i\) ou \( j\) valant \( 0\) ou \( N_x\), \( N_y\) sont les valeurs au bords.

\begin{normaltext}
    Nous notons pour référence ultérieure la discrétisation suivante du laplacien :
    \begin{equation}    \label{EQooQQUHooNYVqta}
        (\Delta_hu)(x_i,y_j)=\frac{1}{ h^2 }\big( -4u_{i,j}+u_{i+1,j}+u_{i-1,j}+u_{i,j-1}+u_{i,j+1} \big).
    \end{equation}
    Elle vérifie
    \begin{equation}
        \Delta_hf=\Delta f+h^2\alpha(h).
    \end{equation}
    Cette discrétisation est dite «en croix» parce que les points exploités forment une croix.
\end{normaltext}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Discrétisation en carré}
%---------------------------------------------------------------------------------------------------------------------------

L'opérateur laplacien est défini par \( \Delta=\partial_x^2+\partial_y^2\), mais il existe de nombreuses autres façons de l'écrire.

\begin{lemma}
    Le laplacien est invariant par changement de coordonnées orthogonales. Plus précisément, si \( A\) est une matrice orthogonale, en posant \( u_i=\sum_kA_{ik}e_k\) nous avons
    \begin{equation}
        \sum_i\frac{ \partial^2f }{ \partial u_i^2 }f=\Delta f.
    \end{equation}
\end{lemma}

\begin{proof}
Nous avons :
\begin{equation}
    \frac{ \partial f }{ \partial u_i }=\sum_kA_{ik}\frac{ \partial f }{ \partial x_k },
\end{equation}
et donc
\begin{equation}
    \sum_i\frac{ \partial^2f }{ \partial u_i^2 }=\sum_i\frac{ \partial  }{ \partial u_i }\left( \sum_kA_{ik}\frac{ \partial f }{ \partial x_k } \right)=\sum_{ijk}(A^t)_{ji}A_{ik}\partial^2f=\sum_{jk}(A^tA)_{jk}\partial^2_{jk}f.
\end{equation}
En particulier si \( A\) est une matrice orthogonale, \( (A^tA)_{jk}=\delta_{jk}\) et le résultat est prouvé.
\end{proof}

Les plus convaincus diront que \( \Delta=\nabla\cdot\nabla\) et que le produit scalaire est invariant sous changement de coordonnées orthogonales.

Nous avons déjà déduit la discrétisation \eqref{EQooQQUHooNYVqta} du laplacien :
\begin{equation}
    (\Delta_hu)(x_i,y_j)=\frac{1}{ h^2 }\big( -4u_{i,j}+u_{i+1,j}+u_{i-1,j}+u_{i,j-1}+u_{i,j+1} \big).
\end{equation}
Nous allons maintenant en déduire une par l'idée de décomposer le laplacien dans la base \( u=e_1+e_2\), \( v=e_1-e_2\). Pour cela nous introduisons les opérations (le nombre \( h\) dont dépendent ces opérateurs est sous-entendu)
\begin{subequations}
    \begin{align}
        (D^+_uf)(x,y)&=\frac{ f(x+h,y+h)-f(x,y) }{ h }\\
        (D^+_vf)(x,y)&=\frac{ f(x+h,y-h)-f(x,y) }{ h }\\
        (D^-_uf)(x,y)&=\frac{ f(x,y)-f(x-h,y-h) }{ h }\\
        (D^-_vf)(x,y)&=\frac{ f(x,y)-f(x-h,y+h) }{ h }.
    \end{align}
\end{subequations}
Vu que
\begin{equation}
    \partial_u^2+\partial_v^2=2\Delta,
\end{equation}
nous discrétisons le laplacien par
\begin{equation}
    \Delta'_h=\frac{ 1 }{2}\big( D_u^-D_u^++D_v^-D_v^+ \big).
\end{equation}
Un peu de calcul donne :
\begin{subequations}   \label{EQooLHBDooSBFkho}
    \begin{align}
    (\Delta'_hf)(x,y)=\frac{1}{ 2h^2 }\Big( -4f(x,y)&+f(x+h,y+h)+f(x-h,y+h)\\
    &+f(x+h,y-h)+f(x-h,y-h) \Big).
    \end{align}
\end{subequations}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Résolution de la discrétisation en croix}
%---------------------------------------------------------------------------------------------------------------------------

Les équations \eqref{EQooPWXBooPimUrU} forment un système d'équations linéaires à résoudre. Certaines peuvent être simplifiées parce qu'elles «touchent» le bord. Nous verrons cela un peu plus tard.

Nous allons d'abord numéroter correctement les équations de façon à ne pas avoir deux mais un seul indice. Notre fonction de numérotation sera
\begin{equation}
    \varphi(i,j)=(j-1)(N_x-1)+i
\end{equation}
avec \( i=1,\ldots, N_x-1\) et \( j=1,\ldots, N_y-1\). Cela correspond à numéroter les points de l'intérieur du quadrillage ligne par ligne en bas en haut et de gauche à droite. Avec cela les équations \eqref{EQooPWXBooPimUrU} vont être numérotées par un seul indice \( I\) allant de \( \varphi(1,1)=1\) à \( \varphi(N_x-1,N_y-1)=(N_x-1)(N_y-1)\).

Si \( I=\varphi(i,j)\) alors nous avons vite
\begin{subequations}
    \begin{align}
        \varphi(i+1,j)&=I+1\\
        \varphi(i,j+1)&=I+N_x-1\\
        \varphi(i-1,j)&=I-1\\
        \varphi(i,j-1)&=I-N_x+1.
    \end{align}
\end{subequations}
Nous posons \( U_I=u_{\varphi^{-1}(I)}\), et l'équation \eqref{EQooPWXBooPimUrU} devient
\begin{equation}
    \frac{1}{ h^2 }(-U_{I+1}+4U_I-U_{I-1}-U_{I+N_x-1}-U_{I-N_x+1})=f_I.
\end{equation}
Pour savoir la matrice représentant ce système, nous devons simplifier les équations qui doivent l'être. Par exemple avec \( I=1\), le terme \( U_{I-1}=U_0\) vaut \( u_{0,1}=f_01\). Ce n'est donc pas réellement une inconnue de notre problème.

Nous voulons mettre les équations sous la forme du système
\begin{equation}
    L_hU=F.
\end{equation}
Sur la ligne numéro \( I\) de \( L_h\), les éléments non nuls sont :
\begin{subequations}        \label{SUBEQQooSRQNooYrCNhj}
    \begin{align}
        L_{I,I}=4\\
        L_{I,I+1}=-1\\
        L_{I,I-1}=-1\\
        L_{I,I+N_x-1}=-1\\
        L_{I,I-N_x+1}=-1
    \end{align}
\end{subequations}
pour peu qu'ils existent. Par exemple pour \( I=1\), il n'y a pas d'éléments \( L_{I,I-1}\). Les indices \( I\) et \( J\) de \( L_{I,J}\) vont de \( 1\) à \( \varphi(N_x-1,N_y-1)=(N_y-1)(N_x-1)\).

Voici un dessin de notre situation :

\begin{center}
   \input{auto/pictures_tex/Fig_GMRNooCNBpIl.pstricks}
\end{center}

À chaque élément du quadrillage correspond une équation.
\begin{itemize}
    \item
        Aux points simples sur le bord, correspondent des équations triviales parce que la fonction \(u \) y est directement donnée par les conditions aux bords.
    \item
        Aux points étoilés entourés en traits continus correspondent des équations «incomplètes» parce que certains termes de l'équation \eqref{EQooPWXBooPimUrU} sont donnés par les conditions aux bords. Elle correspondent aussi aux lignes incomplète de la matrice \( L_h\) où certains éléments donnés en \eqref{SUBEQQooSRQNooYrCNhj} n'existent pas.

        Le membre de droite de ces équations est par contre enrichi de ce qui à gauche est «donné».

    \item
        Au points étoilés du centre entourés en traits discontinus correspondent des équations complètes.

\end{itemize}

Notons que \( f_{00}\) ne joue aucun rôle dans notre histoire parce que dans les équations \eqref{EQooPWXBooPimUrU}, chaque point \( (i,j)\) du maillage n'est liée qu'aux quatre points situés «à côté».


\begin{proposition} \label{PROPooWGTRooVjWhYY}
    La matrice \(L_h\) est
    \begin{enumerate}
        \item
            irréductible et à diagonale fortement dominante\footnote{Définition~\ref{DEFooLSUTooHuXabV}. Le cas \( 1\times 1\) est discutablement à diagonale fortement dominante, il faut avouer.},
        \item       \label{ITEMooOOHPooDsvUPP}
            une M-matrice,
        \item
            inversible avec \( L_{h}>0\),
        \item
            symétrique,
        \item
            strictement définie positive.
    \end{enumerate}
\end{proposition}

\begin{proof}

    On divise la preuve.
    \begin{subproof}
        \item[Irréductible]

    Une matrice \( n\times n\) dont les deux premières diagonales sont entièrement composées d'éléments non nuls est toujours irréductible. En effet, la première lie l'élément \( (1,2)\) à l'élément \( (n-1,n)\) et donc permet de dire que tous les \( i<j\) sont connectés.

    La seconde diagonale lie l'élément \( (n,n-1)\) à l'élément \( (2,1)\).

        \item[Diagonale fortement dominante]
    En ce qui concerne la dominance de la diagonale, il faut sommer sur les lignes. Or chaque ligne contient (en valeur absolue) un \( 4\) sur la diagonale et au plus quatre éléments qui valent \( 1\). D'où
    \begin{equation}
        | L_{II} |\geq \sum_{J\neq I}| L_{IJ} |.
    \end{equation}
    La première ligne n'est jamais complète : elle contient un \( 4\) sur l'élément \( (1,1)\) au au maximum deux \( 1\) plus à droite. Donc la matrice \( L_h\) est à diagonale fortement dominante.

\item[M-matrice]

    D'après ce que nous venons de voir (proposition~\ref{PROPooWGTRooVjWhYY}), le théorème~\ref{THOooLZGSooSevggj} fonctionne et \( L_h\) est une M-matrice\footnote{Notons que c'est ici que nous sommes content d'avoir posé \( -\Delta u=f\) dans le système \eqref{SYSooTANLooRgnIMp}, avec un signe négatif devant le laplacien. Sinon tous le signes auraient changé et la matrice \( -L_h\) aurait été une M-matrice au lieu de \( L_h\).}.

\item[Inverse strictement positif]
    La proposition~\ref{PROPooZDMQooIZAbKK} nous assure qu'une M-matrice irréductible est d'inverse strictement positif. Donc \( L_h^{-1}>0\).
\item[Symétrique]

    La ligne numéro \( I\) est
    \begin{equation}
        \big( \ldots ,\underbrace{-1}_{I-N_x+1},\ldots,-1,4,-1,\ldots,\underbrace{-1}_{I+N_x-1},\ldots \big)
    \end{equation}
    Prenons par exemple l'élément \( (I,I-N_x+1)\) qui vaut \( -1\). Son symétrique est l'élément \( (I-N_x+1,I)\) qui se trouve sur la ligne \( I-N_x+1\). Sur cette dernière ligne nous avons un \( -1\) sur la colonne \( I-N_x+1+N_x-1=I\). Donc l'élément \( (I-N_x+1,I)\) vaut bien \( -1\) et la matrice est symétrique.

\item[Strictement définie positive]
    Vu que la matrice \( L_h\) est symétrique, irréductible à diagonale fortement dominante (proposition~\ref{PROPooWGTRooVjWhYY}), vu que ses éléments diagonaux sont strictement positifs (ils valent \( 4\)), la proposition~\ref{PROPooQBWQooBbeZLO} nous dit que \( L_h\) est strictement définie positive.

    \end{subproof}
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Consistance, convergence}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Définitions, mise en place}
%---------------------------------------------------------------------------------------------------------------------------

Soit un ouvert \( \Omega\subset \eR^n\) et un opérateur différentiel \( L\) sur \( \Omega\). Nous considérons le problème qui consiste à trouver une fonction \( u\) sur \( \Omega\) telle que
\begin{equation}
    Lu=f
\end{equation}
pour une fonction \( f\) donnée.

\begin{probleme}
    La définition suivante est une invention personnelle, n'est pas précise et mérite des commentaires de la part du lecteur.
\end{probleme}
\begin{definition}[\cite{MonCerveau}]
    Un \defe{schéma numérique}{schéma numérique} de pas \( h\) pour \( Lu=f\) est la donnée de
    \begin{enumerate}
        \item
            un nombre \( h>0\) supposé petit,
        \item
            une quantité \( N\) de points \( x_i \) dans \( \Omega\) formant l'ensemble discret \( \Omega_h\),
        \item
            une matrice \( L_h\) de taille \( N\times N\),
        \item
            une solution \( u_h\colon \Omega_h\to \eR\) de l'équation \( (L_hu_h)(x_i)=f_i\) où nous avons posé \( f_i=f(x_i)\).
    \end{enumerate}
\end{definition}

\begin{normaltext}
Évidemment pour qu'un schéma mérite le nom de schéma de pas \( h\) pour l'équation \( Lu=f\), il faut que le nombre \( h\) soit lié au choix des points \( x_i\), et que la matrice \( L_h\) soit liée à l'opérateur \( L\). La définition n'impose pas formellement de tels liens, parce qu'il y a de nombreuses façons d'approximer une équation différentielle en un système linéaire, sans compter que même l'équation \( (L_hu_h)_i=f_i\) peut se résoudre de beaucoup de façons, exacte ou approchées.

Cela pour dire que le lien entre la solution exacte \( u\) et la solution approchée n'a rien d'évident, et va dépendre des choix faits lors de la discrétisation et lors de la résolution du système linéaire. Nous allons supposer dans un premier temps que l'équation \( L_hu_h=f\) est résolue exactement (nous avons un peu parlé de ces problème dans les sections~\ref{SECooQGLRooZQzzsA} et suivantes).
\end{normaltext}

\begin{definition}
    L'erreur \defe{de consistance}{erreur!de consistance} d'un schéma numérique est la fonction \( \tau_h\colon \Omega_h\to \eR\) définie par
    \begin{equation}        \label{EQooPFBBooJumDZO}
        \tau_h(x_i)=(L_hu)_i-(Lu)(x_i).
    \end{equation}
\end{definition}
Il y a un jeu de notation pas tout à fait évident dans la définition \eqref{EQooPFBBooJumDZO}. En effet, \( L_h\) est une matrice, et ne s'applique donc à priori pas immédiatement à une fonction. Ce que signifie la notation \( (L_hu)_i\) est que l'on applique la matrice \( L_h\) au vecteur \( j\mapsto u(x_j)\) et que l'on prend la composante \( i\) du résultat.

\begin{definition}
    Nous disons que le schéma est \defe{consistant}{schéma!consistant} avec l'opérateur différentiel \( L\) lorsque
    \begin{equation}        \label{EQooMPQYooCZsaAT}
        \lim_{h\to 0^+} \| \tau_h \|=0
    \end{equation}
    où la norme \( \| . \|\) est souvent la norme uniforme, c'est-à-dire \( \| \tau_h \|=\max_i\tau_h(x_i)\).
\end{definition}

Notons que le lien entre \( h\) et le choix des \( x_i\) fait partie de la définition des schéma. Sur un segment de longueur \( L\), lorsque \( h\) n'est pas un diviseur de \( L\), le schéma devrait expliquer ce que l'on fait pour que la limite \eqref{EQooMPQYooCZsaAT} ait un sens.

\begin{definition}
    Le schéma \( (\Omega_h,L_h)\) est \defe{consistant à l'ordre \( p\)}{consistance!ordre} avec l'opérateur différentiel \( L\) pour la norme \( \| . \|\) si il existe une constante \( C\) indépendante de \( h\) telle que
    \begin{equation}
        \| \tau_h \|\leq Ch^p.
    \end{equation}
\end{definition}

\begin{definition}
    L'\defe{erreur de discrétisation}{erreur!discrétisation} entre la solution \( u\) du problème \( Lu=f\) et la solution approchée \( u_h\) sur \( \Omega_h\) est la fonction
    \begin{equation}
        \begin{aligned}
            e_h\colon \Omega_h&\to \eR \\
            x_i&\mapsto u(x_i)-u_i.
        \end{aligned}
    \end{equation}
    où \( u_i=u_h(x_i)\) est la solution approchée.

    Le schéma discret \( (L_hu_h)(x_i)=f_i\) est \defe{convergeant}{convergeant!schéma discret} si \( \lim_{h\to 0} \| e_h \|=0\). Si de plus is existe une constante \( C\) et \( p>0\) tels que
    \begin{equation}
        \| e_h \|\leq Ch^p,
    \end{equation}
    alors nous disons que le schéma est convergence à l'\defe{ordre}{ordre!de convergence d'un schéma} \( p\).
\end{definition}

Si l'erreur de consistance est petite, le \emph{problème} est bien approximé par la système linéaire. Cela n'implique cependant pas que la solution trouvée soit bien approximée.

\begin{example}[Deux opérateurs différentiels proches dont les solutions sont loin]
    Soit la partie \( \Omega=\mathopen] 0 , \infty \mathclose[\), et les problèmes
    \begin{subequations}
        \begin{numcases}{}
            L_1u=u'=0\\
            u(0)=1
        \end{numcases}
    \end{subequations}
    et
    \begin{subequations}
        \begin{numcases}{}
            L_2v=v'-\epsilon v=0\\
            v(0)=1.
        \end{numcases}
    \end{subequations}
    Les solutions exactes sont \( u(x)=1\) et \( v(x)= e^{\epsilon x}\).

    En ce qui concerne les opérateurs, quelle que soit la norme utilisée nous avons
    \begin{subequations}
        \begin{align}
            \| L_1-L_2 \|&=\sup_{\| f \|=1}\| L_1(f)-L_2(f) \|\\
            &=\sup_{\| f \|=1}\| \epsilon f \|\\
            &=\epsilon.
        \end{align}
    \end{subequations}
    Donc lorsque \( \epsilon\) est petit, l'opérateur \( L_2\) approxime bien l'opérateur \( L_1\). Pour toutes les normes. Mais
    \begin{equation}
        \big| u(x)-v(x) \big|=| 1- e^{\epsilon x} |,
    \end{equation}
    donc quel que soit \( \epsilon\) nous avons \( \| u-v \|_{\infty}=\infty\). Et d'ailleurs, quelle que soit la norme raisonnable que nous mettons sur l'espace des fonctions, avoir \( \| u-v \|=\infty\) semble inévitable.

    Donc deux opérateurs différentiels proches peuvent avoir des solutions lointaines.
\end{example}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Exemple}
%---------------------------------------------------------------------------------------------------------------------------

Soit l'opérateur différentiel \( L\) donné par
\begin{equation}
    Lu=-u''+cu
\end{equation}
où \( c\) est une fonction. Nous considérons sur \( \Omega=\mathopen] 0 , 1 \mathclose[\) l'équation différentielle
\begin{equation}
    Lu=0.
\end{equation}
En ce qui concerne la discrétisation, nous définissons le maillage \( \Omega_h=\{x_i=ih\}\) avec \( i=0,\ldots, N+1\). La solution approchée discrètement sera le vecteur \( v\) qui peut être vu comme fonction \( v\colon \Omega_h\to \eR\). Les nombres \( v_0\) et \( v_{N+1}\) sont à priori donnés par les conditions aux bords. Pour les autres \( v_i\) nous avons les équations
\begin{equation}
    (L_hv)_i=-\frac{ v_{i+1}-2v_i+v_{i-1} }{ h^2 }+c(x_i)v_i.
\end{equation}
Cela est la définition de l'opérateur \( L_h\), et le vecteur \( v\) solution de \( L_hv=0\) est la solution du problème au sens de la méthode des différences finies (pour peu qu'il existe, soit unique et tout ça).

Pour calculer l'erreur de consistence, nous considérons une fonction \( u\) et nous posons \( u_i=u(x_i)\). Le vecteur \( (u_i)\) ainsi construit est approximé par \( v\) (on espère). Nous avons :
\begin{equation}
    \tau_h(x_i)=-\frac{ u_{i+1}-2u_i+u_{i-1} }{ h^2 }-c(x_i)u_i-(Lu)(x_i).
\end{equation}
Pour étudier cela nous développons \( u_{i+1}=u(x_i+h)\) et \( u_{i-1}=u(x_i-h)\) à l'ordre \( 4\) : il existe \( \alpha_i\in\mathopen[ x_i , x_i+h \mathclose]\) et \( \beta_i\in\mathopen[ x_i-h , x_i \mathclose]\) tels que
\begin{equation}
    u_{i+1}=u(x_i)+hu'(x_i)+\frac{ h^2 }{2}u''(x_i)+\frac{ h^3 }{ 3! }u^{(3)}(x_i)+\frac{ h^4 }{ 4! }u^{(4)}(\alpha_i)
\end{equation}
et
\begin{equation}
    u_{i-1}=u(x_i)-hu'(x_i)+\frac{ h^2 }{2}u''(x_i)-\frac{ h^3 }{ 3! }u^{(3)}(x_i)+\frac{ h^4 }{ 4! }u^{(4)}(\beta_i).
\end{equation}
Après simplification de plusieurs termes,
\begin{equation}
    \tau_h(x_i)=-\frac{ u_{i+1}-2u_i+u_{i-1} }{ h^2 }-c_iu_i+u''(x_i)+c_iu_i=\frac{ h^2 }{ 4! }\big( u^{(4)}(\alpha_i)+u^{(4)}(\beta_i) \big).
\end{equation}
Parler de la consistance du schéma demande d'étudier \( \lim_{h\to 0^+}\| \tau_h \| \), et pour cela, il faut préciser la norme avec laquelle nous voulons travailler. L'ordre de consistance va dépendre de la norme utilisée.

Pour la norme \(  \| . \|_{\infty}\), les nombres \( u^{(4)}(\alpha_i)\) et \( u^{(4)}(\beta_i)\) se majorent par \(  \| u^{(4)} \|_{\infty}\) et nous avons
\begin{equation}
    \| \tau_h \|_{\infty}\leq \frac{ h^2 }{ 12 }\| u^{(4)} \|_{\infty}.
\end{equation}
Nous avons consistance d'ordre \( 2\).

\begin{remark}
    La valeur de \( \| \tau_h \|_{\infty}\) dépend de la fonction \( u\) sur laquelle nous la calculons. Cependant nous avons convergence \( \| \tau_h \|_{\infty}\to 0\) pour toute fonction (de classe disons \( C^4\)).

    La constante \( C\) pour laquelle nous avons \( \| \tau_h \|\leq Ch^2\) et donc qui nous vaut de pouvoir dire que la consistance est d'ordre \( 2\) ne dépend pas de \( h\), ni des valeurs ponctuelles de \( u\) ou de ses dérivées, mais dépend des normes de \( u\) et de ses dérivées (en l'occurrence seulement de la norme de \( u^{(4)}\).)
\end{remark}

Étudions la consistance pour la norme \( L_1\) :
\begin{equation}
    \| \tau_h \|_1=\sum_i| \tau_h(x_i) |\leq \frac{ h^2 }{ 12 }\sum_i\| u^{(4)} \|_{\infty}
\end{equation}
où nous avons majoré chacun des \( u^{(4)}(\alpha_i)\) par \( \| u^{(4)} \|_{\infty}\). Combien de termes dans la somme ? Nous avons \( h=1/(N-1)\) et donc \( N=(1+h)/h\), ce qui donne
\begin{equation}
    \| \tau_h \|_1\leq N\frac{ h^2 }{ 12 }\| u^{(4)} \|_{\infty}=(1+h)Ch.
\end{equation}
La constante \( 1+h\) se majore par n'importe quelle constante strictement plus grande que \( 1\). Nous pouvons donc la rentrer dans \( C\) et écrire
\begin{equation}
    \| \tau_h \|_1\leq Ch
\end{equation}
et donc avoir la consistance à l'ordre \( 1\).

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Consistance, stabilité et convergence}
%---------------------------------------------------------------------------------------------------------------------------

\begin{lemma}       \label{LEMooUOUMooPCoAtA}
    Soit un opérateur différentiel \( L\), soit \( u\) la solution de \( Lu=f\) et un schéma numérique \( (L_h,\Omega_h)\) pour cette équation. Nous notons \( u_h\) la solution de \( L_hu_h=f\). Alors nous avons
    \begin{equation}
        L_he_h=\tau_h
    \end{equation}

    Et si de plus \( L_h\) est inversible,
    \begin{equation}
        \| e_h \|\leq \| L_h^{-1} \|\| \tau_h \|.
    \end{equation}
\end{lemma}

\begin{proof}
    Par définition \( u_h\) est solution de \( L_hu_h=f\) en tant que fonctions sur \( \Omega_h\). Nous avons donc
    \begin{equation}
        L_he_h=L_hu_h-L_hu
    \end{equation}
    où \( u\) doit être compris comme la restriction de \( u\) à \( \Omega\). En appliquant au point \( x_i\),
    \begin{equation}
        (L_he_h)(x_i)=\underbrace{(L_hu_h)(x_i)}_{=f_i}-(L_hu)(x_i),
    \end{equation}
    mais \( f_i=(Lu)(x_i)\) parce que \( u\) est solution de \( Lu=f\). Donc
    \begin{equation}
        (L_he_h)(x_i)=(Lu)(x_i)-(L_hu)(x_i)=\tau_h(x_i).
    \end{equation}

    Si la matrice \( L_h\) est inversible nous avons \( e_h=L_h^{-1}\tau_h\) et donc
    \begin{equation}
        \| e_h \|\leq \| L_h^{-1} \|\| \tau_h \|
    \end{equation}
    par le lemme~\ref{LEMooIBLEooLJczmu}.
\end{proof}

Bien entendu, en tant qu'opérateur linéaire sur un espace de dimension finie, l'opérateur \( L_h^{-1}\) est borné pour chaque \( h\). Mais si il n'y a pas une borne uniforme en \( h\), alors le lemme~\ref{LEMooUOUMooPCoAtA} dit qu'il n'y a pas d'espoir de majorer \( \| e_h \|\) de façon à passer à la limite \( \lim_{h\to 0} \| L_h^{-1} \|\).

\begin{definition}
    Un schéma numérique est \defe{stable}{stable!schéma numérique} si il existe une constante \( C>0\) indépendante de \( h\) telle que \( \| L_h^{-1} \|\leq C\).
\end{definition}

\begin{theorem}     \label{THOooEPQQooUQMcgF}
    En deux parties.
    \begin{enumerate}
        \item
            Si un schéma discret est consistant et stable, alors il est convergeant.
        \item
            Si de plus il est consistant à l'ordre \( p\), alors il est convergeant à l'ordre \( p\).
    \end{enumerate}
\end{theorem}

\begin{proof}
    Nous savons du lemme~\ref{LEMooUOUMooPCoAtA} (qui s'applique parce que l'inversibilité de \( L_h\) est dans la définition de la stabilité) que  \( \| e_h \|\leq \| L_h^{-1} \| \| \tau_h \|\) et que  \( \| L_h^{-1} \|\leq C  \). En passant à la limite\footnote{Toutes les limites \( h\to 0\) sont en réalité des limites \( h\to 0^+\), mais nous allégeons cette notation.},
    \begin{equation}
        \lim_{h\to 0} \| e_h \|\leq C\lim_{h\to 0} \| \tau_h \|=0.
    \end{equation}
    La dernière limite est le fait que le schéma soit consistant. Le schéma est donc convergeant.

    Si de plus il est consistant à l'ordre \( p\), alors
    \begin{equation}
        \| e_h \|\leq C\| \tau_h \|\leq C'h^p
    \end{equation}
    Il est donc également convergeant à l'ordre \( p\).
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Exemple : schéma à cinq points, laplacien en croix}
%---------------------------------------------------------------------------------------------------------------------------

Nous avions développé le schéma dont l'opérateur sur \( \Omega_h\) est (voir \eqref{EQooPWXBooPimUrU})
\begin{equation}
    (L_hu_h)(x_i,y_j)=\frac{1}{ h^2 }\big( -u_{i+1,j}-u_{i,j+1} +4u_{i,j}-u_{i-1,j}-u_{i,j-1}  \big).
\end{equation}

\begin{proposition}
    Le schéma est :
    \begin{enumerate}
        \item
            consistant à l'ordre \( 2\),
        \item
            stable pour la norme uniforme et
            \begin{equation}
                \| L_h^{-1} \|_{\infty}\leq \frac{1}{ 8 },
            \end{equation}
        \item
            convergeant à l'ordre \( 2\) pour la norme \( \| . \|_{\infty}\).
    \end{enumerate}
\end{proposition}

\begin{proof}
    Cet opérateur avait été construit de telle sorte à avoir (voir \eqref{EQooCLSCooYLYJkU})
    \begin{equation}
        (\Delta u)(x_i,y_j)=(L_hu)(x_i,y_i)+h^2R(x,y,h)
    \end{equation}
    où \( R\) peut être majoré indépendamment de \( h\). En tant que fonctions sur \( \Omega_h\) nous avons
    \begin{equation}
        \tau_h=\Delta u-L_hu=h^2R(x,y,h),
    \end{equation}
    et donc \( \| \tau_h \|_{\infty}\leq Ch^2\), parce que le lemme~\ref{LEMooZECZooVKxOZZ}\ref{ITEMooRWUHooZJLKuL} donne aussi
    \begin{equation}
        \| R \|_{\infty}\leq C\max\{ \| \frac{ \partial^4u }{ \partial x^4 } \|_{\infty},\| \frac{ \partial^4u }{ \partial y^4 } \|_{\infty} \}.
    \end{equation}

    En ce qui concerne la stabilité nous allons utiliser le théorème~\ref{THOooWIFGooBQpddF}. Nous considérons la fonction
    \begin{equation}
        g(x,y)=-\frac{1}{ 4 }(x^2+y^2),
    \end{equation}
    qui vérifie \( -\Delta g=1\) sur le carré \( \mathopen[ 0 , 1 \mathclose]^2\). Nous considérons le vecteur \( g_h\) d'indices \( (i,j)\mapsto g_{ij}=g(x_i,y_j)\) sur lequel nous calculons \( L_h\) :
    \begin{equation}
        (L_hg_h)_{ij}=\frac{1}{ h^2 }(-g_{i+1,j}-g_{i,j+1}+4g_{ij}-g_{i-1,j}-g_{i,j-1});
    \end{equation}
    en remplaçant les \( g\) par leurs valeurs en termes de \( x_i\), \( x_{i-1}\), \( x_{i+1}\), \( y_j\), \( y_{j-1}\) et \( y_{j+1}\), et ne tenant compte du fait que \( x_k=kh\) et \( y_l=lh\) nous avons :
    \begin{equation}
        (L_hg_h)_{ij}=\frac{1}{ 4 }\big( (i+1)^2-j^2+i^2+(j+1)^2-4i^2-4j^2+(i-1)^2+j^2+i^2+(j-1)^2 \big)=1.
    \end{equation}
    Donc \( L_hg_h=1\).

    Vu que \( L_h\) est une M-matrice (proposition~\ref{PROPooWGTRooVjWhYY}\ref{ITEMooOOHPooDsvUPP}), le théorème~\ref{THOooWIFGooBQpddF} nous dit alors que \( L_h^{-1}\) vérifie
    \begin{equation}
        \| L_h^{-1} \|_{\infty}\leq \| g_h \|_{\infty}.
    \end{equation}
    Mais
    \begin{equation}
        \| g_h \|_{\infty}\leq \| g \|_{\infty}=g\big( \frac{ 1 }{2},\frac{ 1 }{2} \big)=\frac{1}{ 8 }.
    \end{equation}
    Notons que cela est bien une inégalité et non une égalité parce que rien n'assure que le point \( (1/2,1/2)\) soit sur le maillage; donc rien n'assure que la valeur \( g(1/2,1/2)\) ne soit parmi les valeurs du vecteur discrétisé \( g_h\).

    Notre schéma numérique est stable et consistant à l'ordre \( 2\) pour la norme \( \| . \|_{\infty}\). Le théorème~\ref{THOooEPQQooUQMcgF} dit alors que le schéma est convergeant à l'ordre \( 2\) pour la même norme.
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Autres laplaciens}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


Nous avons vu le laplacien en croix \eqref{EQooQQUHooNYVqta}
\begin{subequations}\label{EQooOBWUooDEWKYv}
    \begin{align}
        (\Delta_hf)(x,y)=\frac{1}{ h^2 }\big( -4f(x,y)&+f(x+h,y)+f(x-h,y)\\
        &+f(x,y+h)+f(x,y-h) \big)
    \end{align}
\end{subequations}
qui vérifie
\begin{equation}        \label{EQooQITHooZVJlVa}
    \Delta_hf=\Delta f+Kh^2,
\end{equation}
ainsi que le laplacien en carré \eqref{EQooLHBDooSBFkho}
\begin{subequations}   \label{EQooUOYVooRpAMOC}
    \begin{align}
    (\Delta'_hf)(x,y)=\frac{1}{ 2h^2 }\Big( -4f(x,y)&+f(x+h,y+h)+f(x-h,y+h)\\
    &+f(x+h,y-h)+f(x-h,y-h) \Big)
    \end{align}
\end{subequations}
qui vérifie également \( \Delta_h'f=\Delta f+Kh^2\).

À priori toutes combinaisons de la forme
\begin{equation}
    a\Delta_h+b\Delta_h'
\end{equation}
avec \( a+b=1\) est valable comme tentative de discrétiser le laplacien. Ce sont des schémas à \( 9\) points. Évidemment la matrice \( L_h\) correspondante va être moins creuse, mais nous pouvons espérer ajuster \( a\) et \( b\) de telle sorte à obtenir une consistance d'un ordre supérieur à \( 2\).

Nous allons développer les \( \Delta_hf\) et \( \Delta_h'f\) à l'ordre \( 4\) (reste à l'ordre \( 6\)). Quelques remarques avant de commencer.
\begin{enumerate}
    \item
        Allez relire la proposition~\ref{PROPooQKZIooXTvkIr} et les notations qui vont avec pour comprendre les différentielles.
    \item
        Écrivez les formules du type \eqref{EQooXRWWooMoKoOB} pour \( d^2f\) et \( d^4f\).
    \item
        Allez relire le développement de Taylor du théorème~\ref{THOooTDFRooEkChgi}.
    \item
        À l'ordre zéro, il n'y a rien parce que le terme \( -4f(x,y)\) compense les quatre termes d'ordre zéro des autres termes.
    \item
        Aux ordres impairs, il n'y a rien. En effet, prenons un nombre impair \( l\) et la formule
        \begin{equation}
            (d^lf)_x(h,\ldots, h)=\sum_{i_1,\ldots, i_l}h_{i_1}\ldots h_{i_l}\frac{ \partial^lf }{ \partial x_{i_1}\ldots \partial x_{i_l} }(x).
        \end{equation}
        Nous avons
        \begin{equation}
            (d^lf)_x(h,\ldots, h)+(d^lf)_x(-h,\ldots, -h)=0.
        \end{equation}
        Or dans les expressions \eqref{EQooUOYVooRpAMOC} et \eqref{EQooOBWUooDEWKYv}, les termes arrivent par pair opposées.
\end{enumerate}

Commençons par calculer \( h^2(\Delta_hf)(x,y)\).
\begin{description}
    \item[Ordre \( 4\)]. Le premier terme est :
        \begin{equation}
            (d^2f)_{(x,y)}\big( (h,0),(h,0) \big)=h^2(d^2f)_{(x,y)}\big( (1,0),(1,0) \big).
        \end{equation}
        La formule \eqref{EQooXRWWooMoKoOB} à peine adaptée permet de calculer ça explicitement.

        Il y a encore les termes du même type avec \( (0,1)\), \( (-1,0)\) et \( (0,-1)\).

    \item[Ordre \( 4\)]
        Cette fois, ce sont \( 4\) termes du type
        \begin{equation}
            h^4(d^4f)_{(x,y)}\big( (1,0),(1,0),(1,0),(1,0) \big)
        \end{equation}
        à calculer.
\end{description}
Cela fait beaucoup de termes à calculer. Je vous laisse vous persuader que le programme suivant en Sage nous donne les coefficients.
\lstinputlisting{tex/sage/coefs.sage}

Le résultat est que, en utilisant la formule
\begin{equation}
    \partial^4_xf+2\partial_{xxyy}^4f+\partial^4_yf=\Delta\Delta f,
\end{equation}
nous avons
\begin{subequations}
    \begin{align}
    (\Delta_hf)(x,y)&=\frac{ 1 }{2}(2\partial_x^2f+2\partial_y^2f)(x,y)+\frac{1}{ 4! }2h^2(\partial^4_xf+\partial_y^4f)(x,y)+Kh^4\\
    &=(\Delta f)(x,y)+\frac{1}{ 12 }h^2(\partial_x^4f+\partial_y^4f)(x,y)+Kh^4\\
    &=\Delta f+\frac{ h^2 }{ 12 }\Delta\Delta f-\frac{ h^2 }{ 12 }2\partial^4_{xxyy}f+Kh^4\\
    &=\Delta f+\frac{ h^2 }{ 12 }\Delta\Delta f-\frac{ h^2 }{ 6 }\partial^4_{xxyy}f+Kh^4
    \end{align}
\end{subequations}
où \( K\) est une constante qui peut être majorée en termes des dérivées quatrièmes de \( f\). En particulier la plus grande des normes supremum de ces dérivées.

Le même genre de calculs donnent
\begin{equation}
        (\Delta'_hf)(x,y)=\frac{ 1 }{2}\Big[  \frac{ 1 }{2}4\Delta f+\frac{h^2}{ 4! }(4\partial_x^4f+24\partial_x^2\partial_y^2f+4\partial_y^2f)   \Big]+Kh^4.
\end{equation}
Ça donne :
\begin{equation}
    (\Delta'_hf)=\Delta f+\frac{ h^2 }{ 12 }\Delta\Delta f+\frac{ h^2 }{ 3 }\partial^4_{xxyy}f+Kh^4
\end{equation}
avec redéfinition du \( K\); nous ne le préciserons plus à chaque fois.


Nous avons donc le résultat proposé dans \cite{ooURUTooREoTyo} :
\begin{equation}
    a\Delta_hf+b\Delta_h'f=(a+b)\Delta f+(a+b)\frac{ h^2 }{ 12 }\Delta^2f+h^2\frac{1}{ 6 }(a-2b)\partial^4_{xxyy}f+Kh^4.
\end{equation}
L'idée est d'appliquer ça à une fonction \( u\) qui vérifie l'équation différentielle \( -\Delta u=f\) (attention au clash de notation pour \( f\)). Le mieux est de supprimer le terme en \( \partial_{xxyy}f\) en demandant \( a-2b=0\). Nous avons donc à résoudre le système
\begin{subequations}
    \begin{numcases}{}
        a+b=1\\
        a-2b=0.
    \end{numcases}
\end{subequations}
Qui propose une décomposition \( PLU\) pour résoudre ce système linéaire ? Quelle que soit la manière, la solution est
\begin{equation}
    \begin{aligned}[]
        a=\frac{ 2 }{ 3 },&&b=\frac{1}{ 3 }.
    \end{aligned}
\end{equation}
Nous allons donc étudier la discrétisation à neuf points
\begin{equation}        \label{EQooRFJVooVplhEr}
    L_h=\frac{ 2 }{ 3 }\Delta_h+\frac{1}{ 3 }\Delta'_h.
\end{equation}
En faisant quelques additions nous trouvons que l'opération
\begin{equation}        \label{EQooKBIIooDWciKl}
    \begin{aligned}[]
        (L_hu)(x_i,y_j)=\frac{1}{ 6h^2 }\Big( -20u_{ij}&+4\big( u_{i+1,j}+u_{i-1,j}+u_{i,j+1}+u_{i,j-1} \big)\\
        &+u_{i+1,j+1}+u_{i-1,j+1}+u_{i+1,j-1}+u_{i-1,j-1}\Big)
    \end{aligned}
\end{equation}
vérifie
\begin{equation}        \label{EQooTLHQooXgZGef}
    L_hf=\Delta f+\frac{ h^2 }{ 12 }\Delta^2 f+Kh^4.
\end{equation}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Travail avec le laplacien à 9 points}
%---------------------------------------------------------------------------------------------------------------------------

Nous allons écrire un schéma numérique pour l'équation différentielle \( -\Delta u=f\) utilisant la discrétisation à 9 points du laplacien. Nous recopions ses propriétés fondamentales \eqref{EQooRFJVooVplhEr}, \eqref{EQooKBIIooDWciKl}, \eqref{EQooTLHQooXgZGef} :
\begin{equation}
    L_h=\frac{ 2 }{ 3 }\Delta_h+\frac{1}{ 3 }\Delta'_h,
\end{equation}
et
\begin{equation}
    \begin{aligned}[]
        (L_hu)(x_i,y_j)=\frac{1}{ 6h^2 }\Big( -20u_{ij}&+4\big( u_{i+1,j}+u_{i-1,j}+u_{i,j+1}+u_{i,j-1} \big)\\
        &+u_{i+1,j+1}+u_{i-1,j+1}+u_{i+1,j-1}+u_{i-1,j-1}\Big),
    \end{aligned}
\end{equation}
et
\begin{equation}        \label{EQooSUKTooXyWQQm}
    L_hf=\Delta f+\frac{ h^2 }{ 12 }\Delta^2 f+Kh^4.
\end{equation}

Nous appliquons \eqref{EQooSUKTooXyWQQm} à \( u\) et nous isolons \( \Delta u\) :
\begin{equation}
    \Delta u=L_hu-\frac{ h^2 }{ 12 }\Delta^2u+Kh^4=\frac{1}{ 6h^2 }T_hu+\frac{ h^2 }{ 12 }\Delta f+Kh^4
\end{equation}
où nous avons utilisé \( \Delta^2u=-\Delta f\) et avons noté
\begin{equation}
    T_hu=-20u_{ij}+4( u_{i+1,j}+u_{i-1,j}+u_{i,j+1}+u_{i,j-1} )+u_{i+1,j+1}+u_{i-1,j+1}+u_{i+1,j-1}+u_{i-1,j-1}.
\end{equation}
Nous imposons maintenant \( \Delta u=-f\) en écrivant
\begin{equation}
    \frac{1}{ 6h^2 }T_hu=-f-\frac{ h^2 }{ 12 }\Delta f+\alpha(h)h^4.
\end{equation}
Une idée est de remplacer \( \Delta f\) par son approximation en croix \eqref{EQooQITHooZVJlVa} :
\begin{equation}
    T_hu=-6h^2f-\frac{ h^4 }{ 2 }(\Delta_hf+Kh^2)+\alpha(h)h^6
\end{equation}
Avec quelques calculs nous trouvons le schéma numérique suivant :
\begin{subequations}        \label{EQooKUMVooCVrzjt}
    \begin{align}
        20u_{ij}&-4( u_{i+1,j}+u_{i-1,j}+u_{i,j+1}-u_{i,j-1} )
        -u_{i+1,j+1}-u_{i-1,j+1}-u_{i+1,j-1}-u_{i-1,j-1}\\
        &=\frac{ h^2 }{2}(8f_{ij}+f_{i+1,j}+f_{i-1,j}+f_{i,j+1}+f_{i,j-1})+\alpha(h)h^6.
    \end{align}
\end{subequations}
En oubliant le terme en \( \alpha(h)h^6\), nous obtenons un système d'équations linéaires.

\begin{probleme}
    Il me semble que ce schéma donne une convergence d'ordre \( 6\). C'est correct ?
\end{probleme}

