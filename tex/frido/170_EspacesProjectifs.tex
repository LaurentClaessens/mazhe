% This is part of Mes notes de mathématique
% Copyright (c) 2011-2019, 2021, 2023
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{La sphère de Riemann \( P_1(\eC)\)}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{definition}      \label{DEFooSZGNooTzFYbh}
	La \defe{sphère de Riemann}{sphère!de Riemann} est l'espace projectif modelé sur \( \eC^2\) : en vertu des notations données à la page \pageref{PgNotimesjNtMoW}, c'est\nomenclature[G]{\( P_1(\eC)\)}{sphère de Riemann}
	\begin{equation}
		P_1(\eC)=P(\eC^2).
	\end{equation}
\end{definition}
\ifbool{isGiulietta}{Nous parlerons aussi de sphère de Riemann en tant que compactification à un point de \( \eC\) dans la sous-section~\ref{SEBSECooLJSEooNlyFYv}.}{}

L'ensemble \( P_1(\eC)\) est le quotient \( \eC^2\setminus\{ (0,0) \}/\sim\) où \( \sim\) est la relation d'équivalence de \( \eC\)-colinéarité dans \( \eC^2\).

\begin{lemma}       \label{LEMooKWZDooEIraSJ}
	L'application
	\begin{equation}        \label{EQooKJIZooZjhzuU}
		\begin{aligned}
			\varphi_0\colon P_1(\eC) & \to \eC\cup\{ \infty \}                            \\
			[z_1,z_2]                & \mapsto \begin{cases}
				                                   \frac{ z_1 }{ z_2 } & \text{si } z_2\neq 0 \\
				                                   \infty              & \text{si } z_2=0
			                                   \end{cases}
		\end{aligned}
	\end{equation}
	est une bijection qui respecte la conjugaison complexe : \( \varphi_0\big( [z_1,z_2]^* \big)=\varphi_0\big( [z_1,z_2] \big)^*\).
\end{lemma}

\begin{proof}
	Notons d'abord que la définition a un sens parce que si un représentant que \( [z_1,z_2]\) est de la forme \( (z,0)\) alors ils sont tous de cette forme. L'affirmation «\( z_1\neq 0\) dans \( [z_1,z_2]\)» a donc un sens.
	\begin{subproof}
		\spitem[Injectif]
		Supposons \( \varphi_0\big( [z_1,z_2] \big)=\varphi_0\big( [t_1,t_2] \big)\).

		Si les deux membres sont égaux à \( \infty\) alors nous avons \( z_2=t_2=0\), et alors avec \( \lambda=z_1/t_1\) nous avons \( (z_1,z_2)=\lambda (t_1,t_2)\), ce qui prouve que \( [z_1,z_2]=[t_1,t_2]\).

		Si les deux membres sont égaux à zéro alors \( z_1=t_1=0\) et le même raisonnement tient.

		Sinon nous avons \( z_1/z_2=t_1/t_2\) où tous les nombres sont non nuls. Cela donne
		\begin{equation}
			z_2=\frac{ t_2 }{ t_1 }z_1,
		\end{equation}
		et donc
		\begin{equation}
			\frac{ t_1 }{ z_1 }(z_1,z_2)=(t_1,t_2),
		\end{equation}
		qui montre qu'au niveau des classes, \( [z_1,z_2]=[t_1,t_2]\).

		\spitem[Surjectif]

		Nous avons
		\begin{equation}
			\infty=\varphi_0\big( [1,0] \big)
		\end{equation}
		et si \( z\neq \infty\) nous avons \( z=\varphi_0\big( [z,1] \big)\).
	\end{subproof}
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Éléments de géométrie dans \( P_1(\eC)\)}
%---------------------------------------------------------------------------------------------------------------------------
\label{SUBSECooQPRLooAjMNqp}

Étant donné que nous sommes partis pour faire de la géométrie dans \( \eC\) et même dans \( \hat \eC=\eC\cup \{ \infty \}\), autant nous armer des équations de cercles et de droites dans \( \eC\), ainsi que de quelques notions adjacentes.

\begin{remark}
	La définition~\ref{DEFooTPPMooTDxNpg} parle de plan et de droites projectives. Ici nous ne sommes pas dans ce cadre parce que nous travaillons sur \( P_1(\eC)\) où \( \eC\) n'est certainement pas un espace de dimension \( 3\). Les droites dont nous allons parler ne sont pas des droites projectives avec leur point à l'infini.
\end{remark}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Équation complexe d'une droite}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

L'équation d'une droite dans \( \eR^2\) est \( d\equiv ax+by=c\) avec \( a,b,c\in \eR\) et \( a,b\) non nuls en même temps. En posant \( z=x+iy\) nous voulons exprimer l'équation en termes de \( z\) au lieu de \( x\) et \( y\). Nous avons\cite{ooWNHWooGUnivi}
\begin{equation}
	\begin{aligned}[]
		x=\frac{ z+\bar z }{2}, &  & y & =\frac{ z-\bar z }{ 2i },
	\end{aligned}
\end{equation}
et nous pouvons écrire \( d\equiv a(z+\bar z)-ib(z-\bar z)=2c\), ou encore \( d\equiv (a-bi)z+(a+ib)\bar z=2c\). En posant \( \omega=a+bi\in \eC^*\) et \( k=2c\in \eR\) nous avons l'équation
\begin{equation}        \label{EQooPRCPooVvrHME}
	\bar \omega z+\omega z=k.
\end{equation}

\begin{definition}      \label{DEFooAQSMooWNOzAI}
	Une \defe{droite}{droite!dans la sphère de Riemann} est une partie de \( \hat\eC\) de la forme
	\begin{equation}
		d(\omega,k)=\{ z\in \eC\tq \bar\omega z+\omega\bar z=k \}\cup\{ \infty \}
	\end{equation}
	avec \( \omega\in \eC^*\) et \( k\in \eR\).
\end{definition}
Dans \( \hat \eC\), toutes les droites contiennent le point \( \infty\).

\begin{probleme}        \label{PROBooZHHTooIFNwxR}
	La proposition~\ref{PROPooMIMRooTbQRVI} montre que toute inversion transforme un cercle-droite en un cercle-droite, nonobstant d'accepter de prolonger toute droite par \( \infty\).

	Est-ce que l'on peut dire que toutes les droites contiennent le point \( \infty\) ?

	En donnant \( \infty\) à toutes les droites et à aucun cercle, la proposition~\ref{PROPooMIMRooTbQRVI} fonctionne partout en posant \( i_C(O)=\infty\) et \( i_C(\infty)=O\).

	De plus en pensant à la projection stéréographique, ce serait logique : quelle que soit la direction dans laquelle un point s'éloigne de \( z=0\), son image par l'inverse de la projection stéréographique s'approche du pôle nord.
\end{probleme}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Équation complexe d'un cercle}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Un cercle de centre \( \omega\in \eC\) et de rayon \( r\) a pour équation \( | z-\omega |=r\), et nous avons les équivalences suivantes :
\begin{equation}
	| z-\omega |=r\Leftrightarrow | z-\omega |^2=r^2\Leftrightarrow (z-\omega)(\bar z-\bar \omega)=r^2\Leftrightarrow r\bar r-\bar \omega z-\omega \bar z=r^2-| \omega |^2.
\end{equation}
Donc un cercle de centre \( \omega\in \eC\) et de rayon \( r\in \eR\) a pour équation
\begin{equation}        \label{EQooDIFRooKRZZoi}
	z\bar z-\bar\omega z-\omega\bar z=r^2-| \omega |^2.
\end{equation}

\begin{definition}      \label{DEFooAUDJooVqLDhe}
	Un \defe{cercle}{cercle!dans la sphère de Riemann} dans \( \hat\eC\) est une partie de la forme
	\begin{equation}
		C(\omega,r)=\{ z\in \eC\tq z\bar z-\bar\omega z-\omega\bar z=r^2-| \omega |^2 \}
	\end{equation}
	avec \( \omega\in \eC\) et \( r\in \eR\).
\end{definition}
Dans la sphère de Riemann, aucun cercle ne contient le point \( \infty\).

\begin{example}
	Trouvons le centre et le rayon du cercle d'équation
	\begin{equation}
		\bar\omega z+\omega\bar z=kz\bar z
	\end{equation}
	avec \( k\neq 0\). En divisant par \( k\) et en posant \( \sigma=\omega/k\) nous avons :
	\begin{equation}
		z\bar z-\bar\sigma z-\sigma\bar z=0.
	\end{equation}
	Cela est un cercle de centre \( \sigma\) et de rayon \( | \sigma |\). En effet si \( z\in \eC\) vérifie cette équation,
	\begin{equation}
		| z-\sigma |^2=(z-\sigma)(\bar z-\bar \sigma)=\underbrace{z\bar z-\bar \sigma z-\sigma \bar z}_{=0}+| \sigma |^2=| \sigma |^2,
	\end{equation}
	c'est-à-dire que tous les points de \( \eC\) qui vérifient l'équation donnée sont à la distance \( | \sigma |\) de \( \sigma\). En particulier \( z=0\) est sur le cercle.
\end{example}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Cercle-droite}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Une chose de bien avec les équations complexes, c'est que nous pouvons écrire les droites et les cercles avec le même type d'équations.

\begin{lemmaDef}[\cite{ooWNHWooGUnivi}]     \label{LEMooHKHOooHpBuBZ}
	Un \defe{cercle-droite}{cercle-droite} est l'ensemble des points \( z\in \eC\) tels que
	\begin{equation}        \label{EQooUJAKooEVQNqa}
		az\bar z-\bar\omega z-\omega\bar z=k
	\end{equation}
	avec \( a,k\in \eR\) et \( \omega\in \eC\).
	\begin{enumerate}
		\item
		      Si \( a=0\), cela est une droite;
		\item
		      si \( a\neq 0\), cela est un cercle.
		\item
		      Un cercle-droite peut être l'ensemble vide.
	\end{enumerate}
\end{lemmaDef}

\begin{proof}
	Si \( a=0\) alors nous tombons tout de suite sur l'équation \eqref{EQooPRCPooVvrHME}. Si \( a\neq 0\) alors nous pouvons diviser par \( a\), poser \( \sigma=\omega/a\) et \( l=k/a\) pour obtenir
	\begin{equation}        \label{EQooNBILooArHPCG}
		z\bar z-\bar\sigma z-\sigma\bar z=l,
	\end{equation}
	qui est l'équation \eqref{EQooDIFRooKRZZoi} d'un cercle \ldots{} ou pas tout à fait. En effet, \eqref{EQooNBILooArHPCG} serait l'équation du cercle de centre \( \sigma\) et de rayon \( r\) donné par \( l=r^2-| \sigma |^2\), c'est ) dire
	\begin{equation}
		r^2=l+| \sigma |^2,
	\end{equation}
	alors que rien n'assure que le nombre \( l+| \sigma |^2\) soit positif. Dans le cas où c'est positif, nous avons bien un cercle. Sinon c'est l'ensemble vide.
\end{proof}

\begin{remark}      \label{REMooBMAEooHDvNID}
	Lorsque nous parlons de cercle-droite, nous parlons de partie de \( \eC\) et non de \( \hat \eC\) parce que l'équation \eqref{EQooUJAKooEVQNqa} a du mal à traiter le cas \( z=\infty\). À cause du fait que nous avons décider de donner le point \( \infty\) à toutes les droites, la fusion des notions de droites et de cercles n'est pas totale; en tout cas pas en une seule équation.
\end{remark}

\begin{example}[\cite{ooWNHWooGUnivi}]      \label{EXooKFBIooOJKjGL}
	Soit le cercle de centre \( \omega=ir\) et de rayon \( r\). Quelle que soit la valeur de \( r>0\), ce cercle passe par le point \( 0\) et l'axe réel lui est tangent. L'équation de ce cercle est :
	\begin{equation}
		z\bar r+irz-ir\bar z=0.
	\end{equation}
	Vu que \( ir\neq 0\) nous pouvons diviser et obtenir
	\begin{equation}
		\frac{ z\bar z }{ ir }+z-\bar z=0.
	\end{equation}
	En faisant tendre \( r\) vers \( \infty\) nous obtenons \( z-\bar z=0\), c'est-à-dire l'équation de la droite réelle.

	Cela explique pourquoi il est souvent dit qu'une droite est un cercle dont le rayon est à l'infini.
\end{example}

\begin{normaltext}\label{NORMooCXVJooMTMqEU}
	Notons que l'exemple~\ref{EXooKFBIooOJKjGL} est générique : prenez une droite \( \ell\), un point \( P\) sur \( \ell\), et considérez un cercle dont le centre est situé sur la perpendiculaire à \( \ell\) passant par \( P\), et dont le rayon est tel que le cercle passe par \( P\). En prenant \( | \omega-P |\to \infty\), l'équation du cercle devient celle de la droite \( \ell\).

	Cela est particulièrement pratique lorsque nous travaillons dans \( \hat \eC\) parce nous y avons une notion précise du point à l'infini. Notons que (peut-être contre-intuitivement), il existe un seul point à l'infini dans \( \hat \eC\). Et ce point est le centre de tous les cercles que l'on veut transformer en droites. Cela pose évidemment la question de savoir comment on définit précisément un cercle dont le centre est réellement \( \infty\).
\end{normaltext}

\begin{center}
	\input{auto/pictures_tex/Fig_PLTWoocPNeiZir.pstricks}
\end{center}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Rotation-homothétie}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

\begin{definition}
	Une \defe{rotation-homothétie}{rotation-homothétie} est une application \(  \hat \eC \to \hat \eC\) de la forme \( z\mapsto \lambda z\) avec \( \lambda\in \eC\).
\end{definition}
Le nom provient du fait que si \( \lambda\) est réel, alors \( z\mapsto \lambda z\) est une vraie homothétie, et si \( \lambda= e^{i\theta}\) alors \( z\mapsto  e^{i\theta}z\) est une vraie rotation. Pour une valeur \( \lambda\in \eC\) générique, l'application \( z\mapsto \lambda z\) est une composée des deux.

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Application linéaire}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\label{SSUBSooRBCWooSCIQEL}

Nous nous en voudrions de ne pas parler d'applications linéaires lorsque nous parlons de géométrie sur \( \hat \eC\). Soit \( \alpha\in \eC^*\) et \( \beta\in \eC\). Lorsque nous parlons de l'application linéaire
\begin{equation}
	\begin{aligned}
		f\colon \hat\eC & \to \hat\eC             \\
		z               & \mapsto \alpha z+\beta,
	\end{aligned}
\end{equation}
nous entendons implicitement que \( f(\infty)=\infty\).

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Inversion}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\label{SSUBSooPOUNooTPilbE}

L'inversion d'un cercle de \( \eR^2\) est définie par la proposition~\ref{PROPDEFooVLIWooQgpLQa}. De nombreuses propriétés y sont décrites, y compris son écriture complexe dans la proposition~\ref{PROPooEWXNooNshvHq}. Tout cela était du temps de \( \eR^2\) ou de \( \eC\), mais maintenant nous sommes dans \( \hat \eC\) et nous voulons plus.

\begin{definition}[\cite{ooWNHWooGUnivi}]       \label{DEFooIUTZooWRaXts}
	Soient \( \omega\in \eC\) et \( R\in \eR^*\). L'\defe{inversion}{inversion dans \( \eC\cup\{ \infty \}\)} de centre \( \omega\) et de \defe{puissance}{puissance!d'une inversion} \( R^2\) est l'application
	\begin{equation}
		\begin{aligned}
			i\colon \hat \eC & \to \hat \eC                                                                                  \\
			z                & \mapsto \begin{cases}
				                           \dfrac{ R^2 }{ \bar z-\bar \omega }+\omega & \text{si } z\in \eC\setminus\{ \omega \} \\
				                           \infty                                     & \text{si } z=\omega                      \\
				                           \omega                                     & \text{si } z=\infty.
			                           \end{cases}
		\end{aligned}
	\end{equation}
\end{definition}
Notons que grâce aux conventions type \( 1/0=\infty\) et \( 1/\infty=0\), nous pouvons nous contenter de la première formule pour tout \( z\in \hat \eC\), et nous n'avons en réalité pas besoin de décrire \( i(\infty)\) et \( i(\omega)\) séparément.

\begin{example}
	L'inversion de cercle de centre \( 0\) et de rayon \( 1\) est l'application \( z\mapsto \frac{1}{ \bar z }\), que l'on prolonge avec \( 0\mapsto \infty\) et \( \infty\mapsto 0\).
\end{example}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Homographies}
%---------------------------------------------------------------------------------------------------------------------------

La notion d'homographie est la définition~\ref{DEFooKWSMooXvOeEP}. Pour une homographie \( \phi\colon P_1(\eC)\to P_1(\eC)\) nous avons un isomorphisme d'espace vectoriel \( \bar\phi\colon \eC^2\to \eC^2\). Vue la bijection \eqref{EQooKJIZooZjhzuU}, nous voulons plutôt travailler avec \( \hat \eC=\eC\cup\{ \infty \}\) qui est un ensemble avec lequel nous sommes plus familier. Nous allons donc travailler avec
\begin{equation}
	\begin{aligned}
		\tilde \phi & \colon \hat \eC\to \hat \eC             \\
		\tilde \phi & =\varphi_0\circ\phi\circ\varphi_0^{-1}.
	\end{aligned}
\end{equation}

\begin{proposition}     \label{PROPooTZJBooPpowOo}
	L'application \( \phi=\varphi_0^{-1}\circ\tilde \phi\circ\varphi_0\) est une homographie de \( P(\eC^2)\) si et seulement si l'application \( \tilde \phi\colon \hat \eC\to \hat \eC\) est de la forme
	\begin{equation}
		\tilde \phi(z)=\frac{ az+b }{ cz+d }
	\end{equation}
	avec \( a,b,c,d\in \eC\) tels que \( ad-bc\neq 0\).

	Par convention nous posons \( z/0=\infty\) dès que \( z\neq 0\); en particulier \( \tilde \phi(\infty)=a/c\) et \( \tilde \phi(-d/c)=\infty\).
\end{proposition}

\begin{proof}
	Nous séparons la condition suffisante de la condition nécessaire.
	\begin{subproof}
		\spitem[\( \Rightarrow\)]
		La condition \( \pi\circ\bar\phi=\phi\circ\pi\) (de \eqref{EQooSEFWooRpjLxt}) nous dit que
		\begin{equation}
			\big[ \bar \phi(z_1,z_2) \big]=\phi\big( [z_1,z_2] \big),
		\end{equation}
		et comme \( \bar \phi\) est un isomorphisme d'espace vectoriel nous avons \( a,b,c,d\in \eC\) vérifiant \( ad-cb\neq 0\) pour lesquels
		\begin{equation}
			\bar \phi(z_1,z_2)=\begin{pmatrix}
				az_1+bz_2 \\
				cz_1+dz_2
			\end{pmatrix}.
		\end{equation}

		Soit \( z\in \eC\). Alors nous avons
		\begin{equation}        \label{EQooNWVZooUClOSd}
			\tilde \phi(z)=(\varphi_0\circ\phi)[z,1]=\varphi_0\Big( \big[ \bar\phi(z,1) \big] \Big)=\varphi_0\big( [az+b,cz+d] \big)=\frac{ az+b }{ cz+d }.
		\end{equation}
		Il est important de comprendre que cette formule fonctionne pour tout \( z\in \eC\). En effet nous pourrions avoir un doute sur \( z=-d/c\). D'abord si \( c=0\) alors \( d\neq 0\) et ce problème n'existe pas : le dénominateur est toujours non nul. Nous avons donc seulement un doute lorsque \( c\neq 0\). Dans ce cas,
		\begin{equation}
			\tilde \phi(-d/c)=\frac{ -\frac{ ad }{ c }+b }{ 0 }.
		\end{equation}
		Mais \( c\neq 0\), donc le numérateur est non nul. Or lorsque \( z\neq 0\) nous avons posé \( z/0=\infty\), donc dans notre cas,
		\begin{equation}
			\tilde \phi(-d/c)=\infty
		\end{equation}
		automatiquement, et cela est encodé dans la formule \eqref{EQooNWVZooUClOSd}.

		Il nous reste à déterminer \( \tilde \phi(\infty)\). Nous avons :
		\begin{equation}
			\tilde \phi(\infty)=(\varphi_0\circ\phi)\big( [1,0] \big)=\varphi_0\big[ \bar\phi(1,1) \big]=\varphi_0\big( [a,c] \big)=\begin{cases}
				a/c    & \text{si } c\neq 0 \\
				\infty & \text{si }c=0
			\end{cases}
		\end{equation}
		où la distinction entre les deux cas n'est pas fondamentale parce que si \( c=0\) alors \( a\neq 0\) et \( a/c=\infty\).
		\spitem[\( \Leftarrow\)]


		En notant \( Z=[z_1,z_2]\) (pour \( z_1,z_2\in \eC\)) nous avons
		\begin{equation}
			\phi\big( [z_1,z_2] \big)=\varphi^{-1}\left( \frac{ a\varphi_0(Z)+b }{ c\varphi_0(Z)+d } \right)=\big[ a\varphi_0(Z)+b,c\varphi_0(Z)+d \big].
		\end{equation}
		Nous définissons \( \bar\phi\) par son action sur les vecteurs de base : \( \bar\phi(1,0)=(a,c)\) et \( \bar\phi(0,1)=(b,d)\). Nous avons bien l'isomorphisme d'espace vectoriel \( \bar\phi\colon \eC^2\to \eC^2\) dont nous avons besoin pour la définition~\ref{DEFooKWSMooXvOeEP}. D'abord le fait que \( ad-cb\) soit non nul assure que le \( \bar\phi\) ainsi défini  est bien bijectif\footnote{Si vous n'en êtes pas convaincu, écrivez la matrice de l'application qui envoie \( (1,0)\) sur \( (a,c)\) et \( (0,1)\) sur \( (b,d)\), et demandez-vous sous quelle condition elle est inversible.}. Et de plus ce \( \bar\phi\) vérifie la condition
		\begin{subequations}
			\begin{align}
				\pi\big( \bar\phi(z_1,z_2) \big) & =\pi\big( (az_1,cz_1)+(bz_2,dz_2) \big)      \\
				                                 & =[az_1+bz_2,cz_1+dz_2]                       \\
				                                 & =\big[ a\varphi_0(Z)+b,c\varphi_0(Z)+d \big] \\
				                                 & =\phi\big( \pi(z_1,z_2) \big).
			\end{align}
		\end{subequations}
		Nous avons utilisé la notion de classe pour diviser par \( z_2\) et faire apparaitre \( \varphi_0(Z)\).
	\end{subproof}
\end{proof}

\begin{remark}
	En prenant les conventions relativement claires \( \infty\times a=\infty\) (pour \( a\neq 0\)) et \( \infty\pm a=\infty\) (avec \( a\neq \infty\)), alors tout est dans la formule
	\begin{equation}
		\bar\phi(z)=\frac{ az+b }{ cz+d }
	\end{equation}
	avec \( ad-cb\neq 0\). Il n'y a pas besoin de traiter séparément le cas \( z=\infty\) ou \( z=-d/c\).
\end{remark}


\begin{definition}      \label{DEFooAMQHooPFUgIa}
	Nous aimons tellement l'identification \( \varphi_0\colon P(\eC^2)\to \hat \eC\) que nous allons parler d'\defe{homographie}{homographie!sur \( \eC\cup\{ \infty \}\)} sur \( \hat \eC\) pour les applications \( \tilde \phi\) de la forme
	\begin{equation}
		\tilde \phi(z)=\frac{ az+b }{ cz+d }
	\end{equation}
	avec \( ad-cb\neq 0\).
\end{definition}

\begin{normaltext}      \label{NORMooCVYKooYvjIeE}
	La proposition~\ref{PROPooTZJBooPpowOo} nous indique que les homographies de \( \hat \eC\) sont de la forme \( \phi=\varphi_0^{-1}\circ\tilde \phi\circ\varphi_0\) pour une homographie \( \phi\colon P(\eC^2)\to P(\eC^2)\).
\end{normaltext}

\begin{proposition}[\cite{ooWNHWooGUnivi}]      \label{PROPooSQFOooRginjJ}
	L'application \( h\colon \hat\eC\to \hat \eC\) associée à une homographie est soit linéaire, soit de la forme \( h=l_1\circ \iota\circ l_2\) où \( l_i\) sont linéaires et \( \iota\) est l'application \( z\mapsto 1/z\).
\end{proposition}

\begin{proof}
	Commençons par une remarque : lorsque nous parlons d'une application linéaire, c'est au sens de la note~\ref{SSUBSooRBCWooSCIQEL} qui explique qu'une application linéaire sur \( \eC\) est automatiquement prolongée à \( \hat \eC\) par \( f(\infty)=\infty\).

	Soit donc l'application
	\begin{equation}
		h(z)=\frac{ az+b }{ cz+d }.
	\end{equation}
	Si \( c=0\), alors c'est une application linéaire et la preuve est terminée. Nous supposons que \( c\neq 0\). Nous posons
	\begin{equation}
		l_2(z)=cz+d,
	\end{equation}
	et ensuite \( l_1(z)=\alpha z+\beta\) avec \( \alpha\) et \( \beta\) à déterminer. Un peu de calcul :
	\begin{equation}
		(l_1\circ \iota\circ l_2)(z)=l_1\left( \frac{1}{ cz+d } \right)=\frac{ \alpha+\beta c z+\beta d }{ cz+d },
	\end{equation}
	et en imposant que cela soit égal à \( \frac{ az+b }{ cz+d }\) nous trouvons \( \beta=a/c\) et \( \alpha=b-ad/c\). Il est vite vérifié que ces choix donnent le bon résultat.
\end{proof}

\begin{normaltext}      \label{NORMooMMKOooQlzjqJ}
	Vu que les applications linéaires sont des composées d'une translation et d'une rotation-homothétie, et que l'application \( i\) est une composée d'une inversion \( z\mapsto 1/\bar z\) et d'une réflexion \( z\mapsto \bar z\), toutes les homographies sont des composées des éléments suivants :
	\begin{itemize}
		\item inversion\footnote{Oui, c'est l'inversion de la géométrie hyperbolique, voir~\ref{SSUBSooPOUNooTPilbE}.} \( z\mapsto 1/\bar z\), prolongée par \( i(\infty)=0\) et \( i(0)=\infty\);
		\item réflexion \( z\mapsto \bar z\);
		\item translation \( z\mapsto z+\alpha\) avec \( \alpha\in \eC\);
		\item rotation-homothétie \( z\mapsto \lambda z\) avec \( \lambda\in \eC\).
	\end{itemize}

	Toutes ces opérations sont prolongées à \( \hat\eC\) par \( 1/\infty=0\), \( \lambda\cdot \infty=\omega\) (si \( \lambda\neq 0\)) et \( \infty+\lambda=\infty\). Nous ne définissons pas \( 0\cdot \infty\) et \( \infty-\infty\).
\end{normaltext}

Certes nous pouvons construire des homographies à partir d'ingrédients dont la conjugaison complexe. Il ne faudrait cependant pas déduire que cette conjugaison est une homographie.

\begin{lemma}       \label{LEMooGDDJooBpJlUf}
	La conjugaison complexe n'est pas une homographie.
\end{lemma}

\begin{proof}
	Si elle l'était nous aurions des nombres \( a,b,c,d\in \eC\) tels que \( ad-bc\neq 0\) et
	\begin{equation}        \label{EQooJMAZooVcJIAP}
		\frac{ az+b }{ cz+d }=\bar z
	\end{equation}
	pour tout \( z\in \eC\).

	En posant \( z=0\) nous avons déjà \( b/d=0\), c'est-à-dire \( b=0\). Avec \( z=1\) nous trouvons alors \( a/(c+d)=1\), c'est-à-dire
	\begin{equation}
		a=c+d.
	\end{equation}

	\begin{subproof}
		\spitem[Si \( ci+d\neq 0\)]

		Dans ce cas nous pouvons évaluer \eqref{EQooJMAZooVcJIAP} en \( z=i\) et avoir \( a=-ci+d\). Mais comme nous avions déjà \( a=c+d\) nous déduisons \( c=0\). Nous restons donc avec
		\begin{equation}
			\frac{ a }{ d }z=\bar z
		\end{equation}
		pour tout \( z\). En prenant \( z=1\) puis \( z=i\), il est vite remarqué que cela n'est pas possible.

		\spitem[Si \( ci+d =0\)]

		Nous rappelons que \( ad\neq 0\). Nous écrivons l'équation avec \( z=-i\) pour trouver
		\begin{equation}
			\frac{ -ai }{ -ci+d }=i,
		\end{equation}
		qui donne immédiatement \( a=ci-d\). Nous avons donc les trois équations
		\begin{subequations}
			\begin{numcases}{}
				c=id\\
				a=ci-d\\
				a=c+d.
			\end{numcases}
		\end{subequations}
		Une tentative de résolution tombe rapidement sur une impossibilité (en substituant la première dans les deux autres et en comparant les deux valeurs de \( a\) par exemple).
	\end{subproof}
\end{proof}

La proposition suivante ressemble à s'y méprendre à la proposition~\ref{PROPooMIMRooTbQRVI}, mais elle diffère en deux points. D'abord elle ne traite que de l'inversion par rapport à l'origine, mais surtout, elle traite le point \( z=\infty\). C'est un avantage de travailler sur \( \hat \eC\) plutôt que sur \( \eR^2\).
\begin{proposition}[Inversion de cercles et de droites]     \label{PROPooEAKXooUIqWEv}
	L'inversion dans \( \hat \eC\) envoie
	\begin{enumerate}
		\item
		      une droite passant par \( 0\) sur elle-même
		\item
		      une droite ne passant pas par \( 0\) sur un cercle passant par \( 0\).
		\item
		      un cercle ne passant pas par \( 0\) en un cercle ne passant pas par \( 0\).
		\item
		      un cercle passant par \( 0\) en une droite ne passant pas par \( 0\).
	\end{enumerate}
\end{proposition}

\begin{proof}

	Décomposition en tous les cas possibles.
	\begin{subproof}
		\spitem[Droite passant par \( 0\)]

		La façon la plus simple de traiter la droite passant par \( 0\) est de l'écrire sous forme paramétrique :
		\begin{equation}
			z(t)=t e^{i\theta}
		\end{equation}
		pour \( \theta\) fixé et \( t\in \eR\cup\{ \infty \}\). En appliquant l'inversion :
		\begin{equation}
			\iota\big( z(t) \big)=\frac{1}{ (t e^{i\theta})^* }=\frac{1}{ t } e^{i\theta}.
		\end{equation}
		Notons que les cas particuliers fonctionnent : pour \( t=0\) nous avons le point \( \infty\) et pour \( t=\infty\) nous avons \( 0\).

		\spitem[Droite ne passant pas par \( 0\)]

		Une droite ne passant par par \( z=0\) est un ensemble de la forme
		\begin{equation}
			d(\omega,k)=\{ z\in \eC^*\tq \bar\omega z+\omega\bar z=k \}\cup \{ \infty \}
		\end{equation}
		avec \( k\neq 0\). Étant donné que \( \iota\) est une bijection et même une involution nous avons \( z\in\iota\big( d(\omega,k) \big)\) si et seulement si \( \tau(z)\in d(\omega,k)\). L'équation est donc, pour \( z\neq 0\) :
		\begin{equation}
			\frac{ \bar\omega }{ z }+\frac{ \omega }{ \bar z }=k.
		\end{equation}
		Et comme \( z\neq 0\) nous pouvons multiplier par \( z\bar z\) pour trouver \( \bar z\bar \omega+z\omega=kz\bar z\). Donc
		\begin{equation}
			\iota\big( d(\omega,k) \big)=\{ z\in \eC^*\tq  \bar z\bar \omega+z\omega=kz\bar z\}\cup\{ 0 \}.
		\end{equation}
		Dans l'ensemble, nous pouvons renommer \( z\) et \( \bar z\) pour avoir une forme plus symétrique. De plus il se fait que \( z=0\) vérifie l'équation donnée; nous pouvons donc lever la condition \( z\in \eC^*\) et ne plus ajouter \( \{ 0 \}\) à côté :
		\begin{equation}
			\iota\big( d(\omega,k) \big)=\{ z\in \eC\tq  \bar \omega z+\omega\bar z=kz\bar z\}.
		\end{equation}
		Cela est l'équation d'un cercle passant par l'origine (définition~\ref{DEFooAUDJooVqLDhe}).

		\spitem[Cercle ne passant pas par \( 0\)]


		Nous considérons le cercle \( C(\omega,r)\) avec \( r^2\neq | \omega |^2\). Il ne contient ni \( \infty\) ni \( 0\) et nous avons alors
		\begin{equation}
			\iota\big( C(\omega,r) \big)=\{ z\in \eC^*\tq \frac{1}{ z\bar z }-\bar\omega\frac{1}{ \bar z }-\omega\frac{1}{ z }=r^2-| \omega |^2 \}.
		\end{equation}
		Vu que \( z\) n'est jamais nul nous pouvons multiplier l'équation par \( z\bar z\) :
		\begin{equation}
			\iota\big( C(\omega,r) \big)=\{ z\in \eC\tq \big( | \omega |^2-r^2 \big)z\bar z-\bar\omega z-\omega\bar z=-1 \}.
		\end{equation}
		Le coefficient \( | \omega |^2-r^2\) est non nul par hypothèse et cet ensemble est un cercle par le lemme~\ref{LEMooHKHOooHpBuBZ}. Il ne passe manifestement pas par \( z=0\).


		\spitem[Cercle passant par \( 0\)]

		Le cercle passe par \( 0\), et donc son image par \( \infty\). Nous écrivons alors
		\begin{equation}
			\iota\big( C(\omega,| \omega |) \big)=\iota\big( C(\omega,| \omega |)\setminus\{ 0 \} \big)\cup\{ \infty \}.
		\end{equation}
		Nous avons
		\begin{equation}
			C(\omega,| \omega |)\setminus \{ 0 \} =\{ z\in \eC^*\tq z\bar z-\bar \omega z-\omega\bar z=0 \},
		\end{equation}
		et un calcul usuel donne
		\begin{equation}
			\iota\big( C(\omega,| \omega |)\setminus \{ 0 \}  \big)=\{ z\in \eC^*\tq 1-\bar \omega z-\omega\bar z=0 \},
		\end{equation}
		et donc
		\begin{equation}
			\iota\big( C(\omega,| \omega |) \big)=d(\omega,1),
		\end{equation}
		en nous souvenant que le point \( \infty\) est contenu dans \( d(\omega,1)\).

	\end{subproof}
\end{proof}

\begin{proposition}     \label{PROPooYFJBooAWxFIs}
	Une homographie conserve l'ensemble des droites et cercles de \( \hat\eC\).
\end{proposition}
Attention : cela ne veut pas dire qu'une homographie transforme une droite en une droite et un cercle en un cercle. Ça veut dire qu'une homographie transforme une droite en une droite ou un cercle et un cercle en une droite ou un cercle.

\begin{proof}
	Nous savons par la proposition~\ref{PROPooMIMRooTbQRVI} et~\ref{NORMooMMKOooQlzjqJ} que les homographies se décomposent en inversion, réflexion, translation et rotation-homothétie.

	À part pour l'inversion, tout est clair comment ça fonctionne hein. En ce qui concerne l'inversion, nous avons la proposition~\ref{PROPooEAKXooUIqWEv} qui donne déjà toutes les réponses.

\end{proof}

\begin{normaltext}
	Les homographies préservent les angles, c'est l'objet du théorème suivant. Il ne faudrait cependant pas croire que si \( A\), \( B\) et \( C\) sont trois points distincts, l'angle entre \( \overline{ AC }\) et \( \overline{ BC }\) est le même que celui entre \( \overline{ f(A)f(C) }\) et \( \overline{ f(B)f(C) }\) dès que \( f\) est une homographie. Cela serait préserver les angles globalement, c'est-à-dire préserver les angles lorsque les points sont déplacés par \( f\).

	Nous allons regarder les angles locaux, c'est-à-dire lorsque les points sont déplacés par \( df\).
\end{normaltext}

\begin{definition}
	Nous disons qu'une application \( f\colon \eR^2\to \eR^2\) préserve localement les angles non orientés lorsque
	\begin{equation}
		\cos\big( df_a(u),df_a(v) \big)=\cos(u,v)
	\end{equation}
	pour tout \( a\in \eR^2\) et \( u,v\in \eR^2\). Ici il est mieux de penser à \( u,v\in T_a\eR^2\) pour qui sait les espaces tangents en géométrie différentielle.
\end{definition}
Voir la définition de l'angle~\ref{DEFooSVDZooPWHwFQ}.

\begin{theorem}
	Les homographies de \( P(\eC^2)\) préservent localement les angles non orientés.
\end{theorem}

\begin{proof}
	En ce qui concerne les translations, dilatations et rotations, les choses sont claires. Vérifions pour l'inversion, qu'il faut interpréter dans \( \eR^2\). Pour \( z=x+iy\) nous avons
	\begin{equation}
		\iota(z)=\frac{1}{ z }=\frac{ x }{ x^2+y^2 }-i\frac{ y }{ x^2+y^2 }.
	\end{equation}
	Nous devons donc étudier la fonction
	\begin{equation}
		\begin{aligned}
			F\colon \eR^2 & \to \eR^2                                                   \\
			(x,y)         & \mapsto \left( \frac{ x }{ r^2 },-\frac{ y }{ r^2 } \right)
		\end{aligned}
	\end{equation}
	où nous avons posé \( r^2=x^2+y^2\) pour simplifier les notations.

	Soient deux vecteurs \( u,v\in \eR^2\) et un point \( a\in \eR^2\). Nous devons prouver que
	\begin{equation}        \label{EQooRXSJooFnLVLC}
		\frac{ u\cdot v }{ \| u \|\| v \| }=\frac{ dF_a(u)\cdot dF_a(v)  }{ \| dF_a(u) \|\| dF_a(v) \| }.
	\end{equation}
	Pour cela, nous pourrions calculer \( dF_a\) et passer en coordonnées polaires\cite{ooDTHEooBAnkGP} mais nous préférons faire les calculs à la dure parce que nous avons Sage avec nous.

	Nous notons \( A\) la matrice de \( dF\) en \( a=(x,y)\) et nous avons
	\begin{equation}
		Au\cdot Av=A^tAu\cdot v
	\end{equation}
	ainsi que \( \| u \|=\sqrt{ u\cdot u }=\sqrt{ A^tAu\cdot u }\), de telle sorte qu'il devienne urgent de calculer \( A^tA\). Voici le calcul :

	\lstinputlisting{tex/sage/sageSnip009.sage}

	Le résultat est que
	\begin{equation}
		A^tA=\begin{pmatrix}
			\frac{1}{ r^4 } & 0               \\
			0               & \frac{1}{ r^4 }
		\end{pmatrix}=\frac{1}{ r^4 }\id.
	\end{equation}
	La vérification de \eqref{EQooRXSJooFnLVLC} est alors immédiate.
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Birapport}
%---------------------------------------------------------------------------------------------------------------------------

Nous introduisons maintenant quelque chose qui s'appelle le «birapport» et qui n'est à priori pas du tout lié au birapport défini en~\ref{DEFooBFSKooDwzwmO}.

\begin{definition}[Birapport dans \( \hat\eC\)\cite{ooZYLAooXwWjLa}]        \label{DEFooQYHVooMZwQMB}
	Soient \( a,b,c,x\in \hat\eC\) où \( a\), \( b\) et \( c\) sont distincts. Le \defe{birapport}{birapport dans \( \eC\cup\{ \infty \}\)} de ces quatre nombres est l'élément de \( \hat\eC\) donné par, si \( a,b,c\neq \infty\) :
	\begin{equation}        \label{EQooQJWZooOXKslh}
		[a,b,c,x]=\frac{ (a-c)(b-x) }{ (b-c)(a-x) },
	\end{equation}
	et
	\begin{subequations}
		\begin{align}
			[\infty,b,c,x] & =\frac{ b-x }{ b-c } \label{SUBEQooNSONooYUhuzB} \\
			[a,\infty,c,x] & =\frac{a-c}{a-x}                                 \\
			[a,b,\infty,x] & =\frac{ b-x }{ a-x }
		\end{align}
	\end{subequations}
\end{definition}

\begin{normaltext}
	Notons la «logique» des cas particuliers. Pour le premier%
	\ifbool{isGiulietta}{%
		\footnote{Pour avoir une notion de topologie sur \( \hat\eC\) vous pouvez aller voir la définition~\ref{DEFooMAHAooGUYyqU} et ce qui l'entoure. En particulier la compactification en un point~\ref{DEFooAKWJooWKcYav}.}}{}%
	, si \( a\to\infty\) tandis que les autres restent dans \( \eC\) alors \( a-c\) et \( a-x\) deviennent du même ordre de grandeur et se simplifient. Il reste les deux autres parties de la fraction.

	C'est cette même logique qui, partant de \( [a,b,\infty,x]=\frac{ b-x }{ a-x }\) donne
	\begin{equation}
		[a,b,\infty,\infty]=1
	\end{equation}
	comme il se doit si nous avons l'intention de ressembler au lemme~\ref{LEMooCOFTooVGKdVO}.
\end{normaltext}

L'objet «birapport» introduit ici est évidemment lié au birapport sur \( P(\eC^2)\) défini plus haut. Le lien est la proposition suivante.

\begin{proposition}     \label{PROPooLKQQooEOrjwC}
	Soit l'application \( \varphi_0\colon P(\eC^2)\to \hat\eC\) définie en~\ref{NORMooUQRUooOMIzJD}. Si \( A,B,C,X\in P(\eC^2) \) alors
	\begin{equation}        \label{EQooEOZZooMRHJfH}
		[A,B,C,X]_{\varphi_0}=[\varphi_0(A),\varphi_0(B),\varphi_0(C),\varphi_0(X)].
	\end{equation}
	Cela est une égalité dans \( \hat \eC\).
\end{proposition}

\begin{proof}
	Nous écrivons \( A=[a_1,a_2]\), \( B=[b_1,b_2]\), \( C=[c_1,c_2]\) avec \( a_1,a_2,b_2,b_2,c_1,c_2\in \eC\). Par définition \( [A,B,C,X]_{\varphi_0}=(\varphi_0\circ\phi)(X)\) où \( \phi\colon P(\eC^2)\to P(\eC^2)\) est l'unique homographie telle que
	\begin{subequations}        \label{SUBEQSooTFWTooRnijrY}
		\begin{align}
			\phi[a_1,a_2] & =[1,0] \\
			\phi[b_1,b_2] & =[0,1] \\
			\phi[c_1,c_2] & =[1,1]
		\end{align}
	\end{subequations}
	Une des difficultés de cette preuve va être de calculer ce \( \phi\). D'abord nous pouvons introduire \( \tilde \phi=\varphi_0\circ\phi\circ\varphi_0^{-1}\) qui est obligatoirement (proposition~\ref{PROPooTZJBooPpowOo}) de la forme
	\begin{equation}
		\tilde \phi(z)=\frac{ \alpha z+\beta }{ \gamma z+\delta }.
	\end{equation}
	Nous allons imposer les relations \eqref{SUBEQSooTFWTooRnijrY} pour déterminer les coefficients \( \alpha\), \( \beta\), \( \gamma\) et \( \delta\).

	D'abord
	\begin{subequations}
		\begin{align}
			(\varphi_0^{-1}\circ\tilde \phi\circ\varphi_0)\big( [a_1,a_2] \big) & =(\varphi_0^{-1}\circ\tilde \phi)(a_1/a_2)                                                                 \\
			                                                                    & =\varphi_0^{-1}\left( \frac{ \alpha\frac{ a_1 }{ a_2 }+\beta }{ \gamma\frac{ a_1 }{ a_2 }+\delta } \right) \\
			                                                                    & =\big[ \alpha\frac{ a_1 }{ a_2 }+\beta,\gamma\frac{ a_1 }{ a_2 }+\delta \big].
		\end{align}
	\end{subequations}
	Égaler cela à \( [1,0]\) donne
	\begin{subequations}
		\begin{numcases}{}
			\alpha\frac{ a_1 }{ a_2 }+\beta\neq 0\\
			\gamma\frac{ a_1 }{ a_2 }+\delta=0.
		\end{numcases}
	\end{subequations}
	Donc nous avons déjà
	\begin{equation}
		\tilde \phi(z)=\frac{ \alpha z+\beta }{  \gamma (z-\frac{ a_1 }{ a_2 })   }=\frac{ \alpha z+\beta }{ \gamma\big( z-\varphi_0(A) \big) }.
	\end{equation}
	En y imposant la contrainte \( (\varphi_0^{-1}\circ\tilde \phi\circ\varphi_0)([b_1,b_2])=[0,1]\) nous trouvons les contraintes
	\begin{subequations}
		\begin{numcases}{}
			\gamma \big( \varphi_0(B)-\varphi_0(A) \big)   \neq 0\\
			\beta=-\alpha\varphi_0(B).
		\end{numcases}
	\end{subequations}
	Nous avons décidé d'écrire \( \varphi_0(A)\) au lieu de \( a_1/a_2\) à la fois pour un soucis de simplification d'écriture et dans le but de ressembler à \eqref{EQooEOZZooMRHJfH}. En substituant :
	\begin{equation}
		\tilde \phi(z)=\frac{ \alpha\big( z-\varphi_0(B) \big) }{ \gamma\big( z-\varphi_0(A) \big) }.
	\end{equation}
	La condition pour \( [c_1,c_2]\) donne
	\begin{equation}
		\left[ \alpha\big( \varphi_0(C)-\varphi_0(B) \big),\gamma\big( \varphi_0(C)-\varphi_0(A) \big) \right]=[1,1],
	\end{equation}
	ce qui donne
	\begin{equation}
		\alpha\big( \varphi_0(C)-\varphi_0(B) \big)=\gamma\big( \varphi_0(C)-\varphi_0(A) \big).
	\end{equation}
	Nous avons alors
	\begin{equation}
		\gamma=\alpha\frac{ \varphi_0(C)-\varphi_0(B) }{ \varphi_0(C)-\varphi_0(A) },
	\end{equation}
	et les \( \alpha\) se simplifient dans la formule pour \( \tilde \phi\) :
	\begin{equation}
		\tilde \phi(z)=\frac{ \big( z- \varphi_0(B)   \big)\big( \varphi_0(C)-\varphi_0(A) \big) }{ \big( z-\varphi_0(A)\big)\big( \varphi_0(C)-\varphi_0(B) \big) }.
	\end{equation}
	Par la proposition~\ref{PROPooTZJBooPpowOo}, l'application \( \varphi_0^{-1}\circ\tilde \phi\circ\varphi_0\) est une homographie. Nous pouvons donc calmement calculer le birapport \( [A,B,C,X]_{\varphi_0}\) de la façon suivante :
	\begin{subequations}
		\begin{align}
			[A,B,C,X]_{\varphi_0} & =(\varphi_0\circ\phi)(X)                                                                                                                                           \\
			                      & =(\varphi_0\circ\varphi_0^{-1}\circ\tilde \phi\circ\varphi_0)(X)                                                                                                   \\
			                      & =\tilde \phi\big( \varphi_0(X) \big)                                                                                                                               \\
			                      & =\frac{ \big( \varphi_0(X)-\varphi_0(B) \big)\big( \varphi_0(C)-\varphi_0(A) \big) }{ \big( \varphi_0(X)-\varphi_0(A) \big)\big( \varphi_0(C)-\varphi_0(B) \big) } \\
			                      & =[\varphi_0(A),\varphi_0(B),\varphi_0(C),\varphi_0(A)].
		\end{align}
	\end{subequations}
\end{proof}

\begin{proposition}     \label{PROPooQGPFooReNaGq}
	Les homographies de \( \hat \eC\) conservent le birapport.
\end{proposition}

\begin{proof}
	Ici le mot «homographie» réfère à la définition~\ref{DEFooAMQHooPFUgIa} et le birapport à~\ref{DEFooQYHVooMZwQMB}. Soient \( a,b,c,x\in\hat\eC\) et une homographie \( \tilde \phi\colon \hat \eC\to \hat \eC\). Il existe une homographie \( \phi\colon P(\eC^2)\to P(\eC^2)\) telle que \( \tilde \phi=\varphi_0\circ\phi\varphi_0^{-1}\). Alors
	\begin{subequations}
		\begin{align}
			\big[ \tilde \phi(a), \tilde \phi(b),\tilde \phi(c),\tilde \phi(x) \big] & =\big[  (\phi\circ\varphi_0^{-1})(a), (\phi\circ\varphi_0^{-1})(b),(\phi\circ\varphi_0^{-1})(c),  (\phi\circ\varphi_0^{-1})(x),  \big]_{\varphi_0} \\
			                                                                         & =\big[  \varphi_0^{-1}(a), \varphi_0^{-1}(b),\varphi_0^{-1}(c), \varphi_0^{-1}(x),  \big]_{\varphi_0}                                              \\
			                                                                         & =[a,b,c,x].
		\end{align}
	\end{subequations}
	Justifications :
	\begin{itemize}
		\item Identification des birapports sur \( P(\eC^2)\) et sur \( \hat \eC\), proposition~\ref{PROPooLKQQooEOrjwC}.
		\item Invariance du birapport sour les homographies (dans \( P(\eC^2)\)), proposition~\ref{PROPooMGYDooHqSoJs}.
	\end{itemize}
\end{proof}

\begin{proposition}     \label{PROPooSGCJooLnOLCx}
	Soient des points \( a,b,c,x\) dans \( \hat\eC\) avec \( a,b,c\) distincts. Ils sont alignés ou cocycliques si et seulement si \( [a,b,c,x]\in \hat\eR\).
\end{proposition}

\begin{proof}
	Nous allons faire plusieurs cas. Mais dans tous les cas vous pouvez relire la définition des angles orientés~\ref{DEFooVBKIooWlHvod} et la partie sur les angles dans les nombres complexes~\ref{SUBSECooKNUVooUBKaWm}.
	\begin{subproof}
		\spitem[Tous les points sont distincts et dans \( \eC\)]

		D'une part, nous savons que le nombre complexe \( r e^{i\theta}\) est réel si et seulement si \( \theta\in[0]_{\pi}\), et d'autre part l'argument du birapport \eqref{EQooQJWZooOXKslh} est
		\begin{equation}
			[\vect{ ca },\vect{ cb }]+[\vect{ xb },\vect{ xa }].
		\end{equation}
		Le birapport est réel si et seulement si
		\begin{equation}
			[\vect{ ca },\vect{ cb }]-[\vect{ xa },\vect{ xb }]\in[0]_{\pi}.
		\end{equation}
		À gauche nous avons une classe modulo \( 2\pi\) et à droite une classe modulo \( \pi\). L'égalité signifie qu'il y a un représentant du membre de gauche qui appartient au membre de droite. Si vous aimez faire très attention à ce que signifient les notations, voici trois manières d'écrire la condition, par ordre croissant de précision :
		\begin{subequations}
			\begin{align}
				[\vect{ ca },\vect{ cb }]-[\vect{ xa },\vect{ xb }]=[0]_{\pi},   \\
				[\vect{ ca },\vect{ cb }]-[\vect{ xa },\vect{ xb }]\in[0]_{\pi}, \\
				[\vect{ ca },\vect{ cb }]-[\vect{ xa },\vect{ xb }]\subset[0]_{\pi}.        \label{SUBEQooEAGIooIKdPQV}
			\end{align}
		\end{subequations}
		Nous avons donc que le birapport est réel si et seulement si la condition \eqref{SUBEQooEAGIooIKdPQV} est vérifiée. D'après le théorème~\ref{THOooUDUGooTJKDpO}, cette dernière condition est équivalente à dire que les points \( a\), \( b\), \( c\) et \( x\) sont alignés.

		\spitem[Pas quatre points distincts, dans \( \eC\)]

		Nous supposons encore que \( a\), \( b\), \( c\) et \( x\) sont dans \( \eC\). Mais nous supposons que \( x\) est un de \( a\), \( b\) ou \( c\). Vu que par hypothèse \( a\), \( b\) et \( c\) sont distincts, c'est le seul cas à considérer dans la catégorie des \( 4\) points non distincts.

		Trois points sont toujours alignés ou cocycliques\footnote{Si ils ne sont pas alignés, prendre la médiatrice du segment \( [a,b]\) et celle de \( [b,c]\), et l'intersection vous donnera le centre d'un cercle passant par \( a\), \( b\) et \( c\).}. Donc nous devons seulement montrer que dans ce cas le birapport est toujours dans \( \hat \eR\). Par définition,
		\begin{itemize}
			\item Si \( x=a\) alors \( [a,b,c,x]=\infty\),
			\item Si \( x=b\) alors \( [a,b,c,x]=0\),
			\item Si \( a=c\) alors \( [a,b,c,x]=1\).
		\end{itemize}
		Dans tous les cas de figure le birapport est dans \( \hat \eR\).

	\end{subproof}

	À ce niveau de la preuve nous devons encore vérifier les cas où \( a\), \( b\), \( c\) ou \( x\) valent \( \infty\). Si l'un de \( a\), \( b\) ou \( c\) est \( \infty\) et si \( x\) l'est aussi, alors, comme \( \infty\) est aligné avec tout, nous avons seulement une droite passant par deux points. Il nous faut donc seulement regarder les cas où un seul des \( 4\) points est \( \infty\).

	\begin{subproof}
		\spitem[Si \( a=\infty\)]
		Le birapport est alors (par \eqref{SUBEQooNSONooYUhuzB})
		\begin{equation}
			[\infty,b,c,x]=\frac{ b-x }{ a-x },
		\end{equation}
		qui est un nombre à priori complexe dont le dénominateur est supposé non nul parce que le cas \( a=x\) est déjà traité. L'argument de ce nombre est dans la classe de l'angle orienté
		\begin{equation}
			\arg\left( \frac{ b-x }{ a-x } \right)\in[\vect{ xa },\vect{ xb }].
		\end{equation}
		Le birapport est réel si et seulement si le membre de gauche est dans \( [0]_{\pi}\). Et cela est justement le cas où le membre de droite donne des points alignés.
	\end{subproof}
	Les cas \( b=\infty\), \( c=\infty\) et \( x=\infty\) se traitent de la même manière.
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Division harmonique}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}
	Nous disons que les éléments \( a\), \( b\), \( c\) et \( x\) de \( \hat \eC\) sont en \defe{division harmonique}{division!harmonique} lorsque \( [a,b,c,x]=-1\).
\end{definition}

\begin{normaltext}      \label{NORMooUWYDooAZTTWu}
	Une chose qui sera utile par la suite est de remarquer que \( [a,b,c,\infty]=-1\) lorsque \( c=\frac{ a+b }{ 2 }\).
\end{normaltext}

Nous allons maintenant voir comment, pour \( a,b,c\in \eC\) donnés nous pouvons construire \( x\) tels que \( a,b,c,x\) soient en division harmonique. Vu que trois points sont soit cocycliques soit alignés nous divisons la construction en deux parties.

Notons que si nous trouvons une construction qui donne un point \( x\) vérifiant \( [a,b,c,x]=-1\) alors nous prouvons au passage que la construction ne dépend pas des choix intermédiaires parce que il n'existe qu'un unique \( x\) tel que \( [a,b,c,x]=-1\) lorsque \( a,b,c\) sont donnés.

\begin{lemma}[\cite{ooBVODooOTHLEk,ooSEHIooEkvXHJ}]     \label{LEMooAEDTooKsUoPw}
	Soient \( a,b,c\) cocycliques dans \( \eC\). Nous nommons \( \mC\) le cercle contenant \( a\), \( b\) et \( c\) ainsi que \( T_a\) et \( T_b\) les tangentes à \( \mC\) en \( a\) et \( b\). Soit \( m=T_a\cap T_b\) et la droite \( L=(mc)\). Alors le point
	\begin{equation}
		x=(mc)\cap \mC
	\end{equation}
	vérifie \( [a,b,c,x]=-1\).

	Si \( m=\infty\) (arrive lorsque \( T_a\parallel T_b\)) alors en guise de \( L\) nous prenons la parallèle à \( T_a\) passant par \( c\).
\end{lemma}

\begin{proof}
	Nous séparons les cas suivant que \( m=\infty\) ou non.
	\begin{subproof}
		\spitem[\( m=\infty\)]

		Les tangentes à \( \mC\) en \( a\) et en \( b\) sont parallèles, c'est-à-dire que ces points sont diamétralement opposés sur \( \mC\). Les homographies préservent le birapport (proposition~\ref{PROPooQGPFooReNaGq}), et les rotations, dilatations et translations sont des homographies (voir~\ref{NORMooMMKOooQlzjqJ}).

		Nous pouvons donc nous ramener au cas où \( \mC\) est centré en \( 0\) et de rayon \( 1\) avec \( a=i\) et \( b=-i\). Dans ce cas, \( c= e^{i\theta}\). Vu que \( x\) est donné par l'intersection entre le cercle et la droite horizontale passant par \( c\) nous avons \( x= e^{i(\pi-\theta)}\). Le birapport se calcule explicitement :
		\begin{equation}
			[a,b,c,x]=\frac{ (i- e^{i\theta})(-i- e^{i(\pi-\theta)}) }{ (-i- e^{i\theta})(i- e^{i(\pi-\theta)}) }=-1.
		\end{equation}

		\spitem[\( m\neq\infty\)]

		Nous sommes dans la situation suivante où à une translation près nous supposons \( x=0\) :


		\begin{center}
			\input{auto/pictures_tex/Fig_SJAWooRDGzIkrj.pstricks}
		\end{center}

		Nous allons prouver que dans ce cas, \( [a,b,c,x]=-1\). Pour cela nous considérons l'inversion de centre \( x\) (qui est \( x=0\) par translation). Soit \( \tilde \phi\) cette homographie. Elle conserve le birapport, il nous allons voir que calculer \( [\tilde \phi(a),\tilde \phi(b),\tilde \phi(c),\tilde \phi(x)]\) se révèle être plus facile\footnote{Si vous n'avez peur d'aucun calculs, il suffit de poser \( a= e^{i\theta}\), \( b= e^{-i\theta}\) et \( c= e^{i\sigma}\) et vous êtes théoriquement capable de calculer les coordonnées de tous les points, y compris de \( x\) en termes de \( \theta\) et \( \sigma\). Ensuite le calcul du birapport est explicite.}.

		Nous nommons \( A=(am)\), \( B=(bm)\), \( C=(cm)\) et \( \mC\), le cercle. Nous allons maintenant faire intensément usage de la proposition~\ref{PROPooEAKXooUIqWEv}. Nous avons :
		\begin{itemize}
			\item \( \tilde \phi(A)\) est un cercle passant par \( 0\).
			\item \( \tilde \phi(B)\) est un cercle passant par \( 0\).
			\item \( \tilde \phi(C)\) est la droite \( C\).
			\item \( \tilde \phi(\mC)\) est une droite ne passant pas par \( 0\).
		\end{itemize}

		Les droites \( A\) et \( B\) se coupent en \( m\) et en \( \infty\) (qui sont des points distincts). Donc les cercles \( \tilde \phi(A)\) et \( \tilde \phi(B)\) se coupent en \( 0\) et \( \tilde \phi(m)\), aucun de ces deux points n'est sur la droite \( \tilde \phi(\mC)\).

		Par tangence, la droite \( A\) et le cercle \( \mC\) se coupent en un seul point (\( a\)). Donc \( \tilde \phi(A)\) coupe \( \tilde \phi(\mC)\) en un seul point, \( \tilde \phi(a)\). Idem pour le cercle \( \tilde \phi(B)\).

		Nous avons donc que les cercles \( \tilde \phi(A)\) et \( \tilde \phi(B)\) sont tangents à la droite \( \tilde \phi(\mC)\) et se coupent en exactement deux points distincts (qui sont donc du même côté de la droite).

		Nous nous intéressons à la droite \( \tilde \phi(C)\). C'est une droite parce que c'est l'image d'une droite passant par \( 0\). Elle passe par \( 0\), par \( \tilde \phi(c)\) et \( \tilde \phi(m)\). Le fait qu'elle passe par \( 0\) et \( \tilde \phi(m)\) fait que c'est la droite passant par les deux intersections des cercles. Vu que \( c\in \mC\cap C\), le point d'intersection \( \tilde \phi(C)\cap \tilde \phi(\mC)\) est \( \tilde \phi(c)\).

		Quelle est la puissance du point \( \tilde \phi(c)\) par rapport au cercle \( \tilde \phi(A)\) ? En la calculant avec la droite \( \tilde \phi(C)\), qui intersecte les deux cercles aux points déjà étudiés, la puissance est :
		\begin{equation}
			k=d\big( \tilde \phi(c),0 \big)\times d\big( \tilde \phi(c),\tilde \phi(m) \big).
		\end{equation}
		Vu que ces points sont également sur le cercle \( \tilde \phi(B)\), la puissance de \( \tilde \phi(c)\) par rapport à ce second point est la même.

		Tout cela justifie le dessin suivant\quext{Bien que ce ne soit pas strictement nécessaire à la preuve, est-ce que vous savez si les deux cercles ont le même rayon ? Et si par hasard la droite \( \big( \tilde \phi(m)\tilde \phi(c) \big)\) n'arrive pas perpendiculairement à \( \tilde \phi(\mC)\) ?} :

		\begin{center}
			\input{auto/pictures_tex/Fig_IOCTooePeHGCXH.pstricks}
		\end{center}

		Mais la droite passant par \( \tilde \phi(a)\) et \( \tilde \phi(c)\) (qui est tangente au cercle) permet également de calculer cette puissance :
		\begin{equation}
			k=d\big( \tilde \phi(a),\tilde \phi(c) \big).
		\end{equation}
		Idem pour la puissance par rapport à l'autre cercle :
		\begin{equation}
			k=d\big( \tilde \phi(b),\tilde \phi(c) \big).
		\end{equation}
		Nous en déduisons que \( \tilde \phi(c)\) est le milieu entre \( \tilde \phi(a)\) et \( \tilde \phi(b)\).

		Du coup
		\begin{equation}
			\big[ \tilde \phi(a),\tilde \phi(b), \tilde \phi(c),\tilde \phi(x) \big]=\big[ \tilde \phi(a),\tilde \phi(b), \tilde \phi(c), \infty \big]=-1
		\end{equation}
		en vertu de ce que nous avons raconté en~\ref{NORMooUWYDooAZTTWu}.

	\end{subproof}
\end{proof}

\begin{lemma}[\cite{ooSEHIooEkvXHJ}]        \label{LEMooYBTHooABWkeo}
	Soit \( a,b,c\in \eC\) colinéaires. Soit \( m\) un point hors de cette droite. Nous considérons une droite issue de \( c\) coupant \( [ma]\) en \( p\) et \( [mb] \) en \( q\).

	Nous construisons \( n=(aq)\cap (pb)\) et finalement \( x=(mn)\cap (ab)\).

	À la fin nous avons
	\begin{equation}
		[a,b,c,x]=-1.
	\end{equation}
\end{lemma}

\begin{proof}
	Commençons par un dessin de la situation :

	\begin{center}
		\input{auto/pictures_tex/Fig_EELKooMwkockxB.pstricks}
	\end{center}

	Les points \( a\), \( b\) et \( m\) ne sont pas alignés, et nous pouvons les utiliser comme repère barycentrique (voir~\ref{NORMooOGHBooMjmouu} pour savoir en deux mots ce que c'est). Nous nommons \( (\alpha,\beta,\gamma)\) les coordonnées de \( n\) dans ce système, c'est-à-dire que
	\begin{equation}
		\alpha \vect{ na }+\beta\vect{ nb }+\gamma\vect{ nm }=0.
	\end{equation}
	Dans notre contexte, nous pouvons voir le vecteur \( \vect{ st }\) comme une façon d'écrire le nombre \( t-s\). Par la proposition~\ref{PROPooBCUVooWKttiH} nous savons les coordonnées barycentriques de \( p\), \( x\) et \( q\) en regardant le triangle \( acb\). Voici les coordonnées et les relations qu'elles signifient :
	\begin{subequations}        \label{SUBEQSooKKIXooZbWyHe}
		\begin{align}
			n & =(\alpha,\beta,\gamma), & \alpha\vect{ na }+\beta\vect{ nb }+\gamma\vect{ nm } & =0                               \\
			p & =(\alpha,0,\gamma),     & \alpha\vect{ pa }+\gamma\vect{ pm }                  & =0                               \\
			q & =(0,\beta,\gamma),      & \beta\vect{ qb }+\gamma\vect{ qm }                   & =0                               \\
			x & =(\alpha,\beta,0).      & \alpha\vect{ xa }+\beta\vect{ xb }                   & =0  \label{SUBEQooRUUDooDGsMoq}.
		\end{align}
	\end{subequations}
	Nous voudrions maintenant voir les coordonnées de \( c\). Nous posons \( c=(\lambda,\mu,\sigma)\) :
	\begin{equation}        \label{EQooZKBSooZOzqrV}
		\lambda\vect{ ca }+\mu\vect{ cb}+\sigma\vect{ cm }=0.
	\end{equation}
	Mais \( a\), \( b\) et \( c\) sont alignés, donc \( \vect{ ca }\) et \( \vect{ cb }\) sont colinéaires, alors que \( \vect{ cm }\) n'est pas aligné avec les deux autres. L'annulation \eqref{EQooZKBSooZOzqrV} demande donc l'annulation séparément
	\begin{subequations}
		\begin{numcases}{}
			\sigma\vect{ cm }=0\\
			\lambda\vect{ ca }+\mu\vect{ cb }=0         \label{SUBEQooOTAOooQLndsd}.
		\end{numcases}
	\end{subequations}
	Nous en déduisons que \( \sigma=0\) et aussi que \( \lambda\) et \( \mu\) ne sont pas nuls. Nous posons arbitrairement \( \lambda=1\) parce que les coordonnées barycentriques sont définies à coefficient multiplicatif près.

	Nous imposons à présent le fait que \( p\), \( q\) et \( c \) sont alignés. Pour cela nous devons faire apparaitre les vecteurs \( \vect{ pq }\), \( \vect{ pc }\), \( \vect{ pc }\). Vu le dessin et les relations disponibles \eqref{SUBEQSooKKIXooZbWyHe} le mieux est d'utiliser les relations de Chasles  (proposition~\ref{PROPooCOZCooCghwaR}) pour faire \( \vect{ ca }=\vect{ cp }+\vect{ pa }\) et \( \vect{ cb }=\vect{ cq }+\vect{ qb }\).  La relation \eqref{SUBEQooOTAOooQLndsd} devient :
	\begin{equation}
		\vect{ cp }+\vect{ pa }+\mu(\vect{ cq }+\vect{ qb })=0.
	\end{equation}
	Les vecteurs \( \vect{ cp }\) et \( \vect{ cq }\) sont alignés, donc nous les écrivons ensemble. Les vecteurs \( \vect{ pa }\) et \( \vect{ qb }\) se transforment en utilisant les relations \eqref{SUBEQSooKKIXooZbWyHe} :
	\begin{equation}
		\vect{ cp }+\mu\vect{ cq }-\frac{ \gamma }{ \alpha }\vect{ pm }-\mu\frac{ \gamma }{ \beta }\vect{ qm }.
	\end{equation}
	Enfin nous voulons faire la somme du terme \( \vect{ pm }\) avec le terme \( \vect{ qm }\). D'abord on change le signe :
	\begin{equation}
		\vect{ cp }+\mu\vect{ cq }-\frac{ \gamma }{ \alpha }\vect{ pm }+\frac{ \mu\gamma }{ \beta }\vect{ mq }
	\end{equation}
	ensuite nous écrivons
	\begin{equation}
		\frac{ \mu\gamma }{ \beta }=\frac{ \mu\gamma }{ \beta }+\frac{ \gamma }{ \alpha }-\frac{ \gamma }{ \alpha },
	\end{equation}
	et
	\begin{equation}
		\vect{ cp }+\mu\vect{ cq }-\frac{ \gamma }{ \alpha }(\vect{ pm }+\vect{ mq })+\left( \frac{ \mu\gamma }{ \beta }+\frac{ \gamma }{ \alpha } \right)\vect{ mq }=0.
	\end{equation}
	Tout cela pour
	\begin{equation}
		\vect{ cp }+\mu\vect{ cq }-\frac{ \gamma }{ \alpha }\vect{ pq }+\left( \frac{ \mu\gamma }{ \beta }+\frac{ \gamma }{ \alpha } \right)\vect{ mq }=0.
	\end{equation}
	Le dernier terme n'est pas colinéaire aux deux premiers et s'annule donc séparément :
	\begin{equation}
		\frac{ \mu\gamma }{ \beta }+\frac{ \gamma }{ \alpha }=0.
	\end{equation}
	Cela donne \( \mu=-\beta/\alpha\).

	Au final nous avons
	\begin{equation}
		\vect{ ca }-\frac{ \beta }{ \alpha }\vect{ cb }=0
	\end{equation}
	et donc
	\begin{equation}        \label{EQooWKBWooEWhDiM}
		\alpha\vect{ ca }-\beta\vect{ cb }=0,
	\end{equation}
	ce qui donne les coordonnées \( (\alpha,-\beta,0)\) pour le point \( c\).

	Vu que nous somme dans l'espace vectoriel \( \eC\), ce que nous notons \( \vect{ AB }\) n'est rien d'autre que la différence \( B-A\) dans \( \eC\)\footnote{Les mauvaise langues diront que tout le chapitre sur les espaces affines, et surtout la partie sur les barycentres ne sont rien d'autres que le snobisme d'écrire \( \vect{ xy }\) au lieu de \( y-x\). C'est aussi une facilité d'écriture.}. La relation \eqref{EQooWKBWooEWhDiM} signifie donc
	\begin{equation}
		\alpha(a-c)=\beta(b-c).
	\end{equation}
	Nous avons alors :
	\begin{equation}
		\frac{ a-c }{ b-c }=\frac{ \beta }{ \alpha }.
	\end{equation}
	Par ailleurs, la relation \eqref{SUBEQooRUUDooDGsMoq} à propos des coordonnées de \( x\) donne
	\begin{equation}
		\frac{ a-x }{ b-x }=-\frac{ \beta }{ \alpha }.
	\end{equation}
	En égalisant les deux valeurs de \( \beta/\alpha\) nous trouvons :
	\begin{equation}
		\frac{ a-c }{ b-c }=\frac{ x-a }{ b-x },
	\end{equation}
	ce qui donne (via un petit jeu de signes)
	\begin{equation}
		\frac{ (c-a)(x-b) }{ (c-b)(x-a) }=-1.
	\end{equation}
	C'est cela que nous voulions.
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Groupe circulaire}
%---------------------------------------------------------------------------------------------------------------------------

Nous avons vu que les homographies préservent l'ensemble des cercles et droites. Nous pouvons nous demander quel est le groupe maximum préservant l'ensemble des cercles et droites.

\begin{definition}
	Le \defe{groupe circulaire}{groupe!circulaire} de \( \eC\) est le groupe de transformations de \( \hat \eC  \) engendré\footnote{Définition \ref{DefooRDRXooEhVxxu}.} par les homographies\footnote{Homographie de \( \hat\eC\) : définition~\ref{DEFooAMQHooPFUgIa}.} et la conjugaison complexe. Le groupe circulaire de l'espace projectif est l'ensemble des applications de la forme \( \varphi_0^{-1}\circ f\circ\varphi_0\) où \( f\) est un élément du groupe circulaire de \( \eC\).
\end{definition}

Vu le lemme~\ref{LEMooGDDJooBpJlUf}, la conjugaison complexe n'est pas une homographie. Donc cette définition n'est pas stupide : le groupe circulaire est strictement plus grand que le groupe des homographies.

\begin{lemma}       \label{LEMooOPOMooWZLSeH}
	Soit une application \( \alpha\colon \eC\to \eC\) fixant \( 1\) et \( 0\) et préservant les divisions harmoniques (c'est-à-dire tel que son prolongement à \( \hat\eC\) donné par \( \alpha(\infty)=\infty\) préserve les divisions harmoniques). Alors \( \alpha\) est un automorphisme de corps\footnote{Définition~\ref{DEFooSPHPooCwjzuz}.}.
\end{lemma}

\begin{proof}
	Nous savons que si \( a,b,c\in \eC\) nous avons \( c=(a+b)/2\) si et seulement si \( [a,b,c,\infty]=-1\). Vu que \( \alpha\) préserve les divisions harmoniques nous avons équivalence entre les affirmations suivantes :
	\begin{subequations}
		\begin{align}
			c=\frac{ a+b }{ 2 }                               \\
			[a,b,c,\infty]=-1                                 \\
			[\alpha(a),\alpha(b),\alpha(c),\alpha(\infty)]=-1 \\
			\frac{ \alpha(a)+\alpha(b) }{2}=\alpha(c).
		\end{align}
	\end{subequations}
	Donc \( \alpha\) préserve les milieux : pour tout \( a,b\in \eC\) nous avons
	\begin{equation}        \label{EQooZCWFooZkwVVW}
		\alpha\left( \frac{ a+b }{2} \right)=\frac{ \alpha(a)+\alpha(b) }{2}.
	\end{equation}
	En particulier, cette relation avec \( b=0\) donne (parce que \( \alpha(0)=0\)) : \( \alpha(a/2)=\alpha(a)/2\). Nous avons au final, en utilisant cela en conjonction avec \eqref{EQooZCWFooZkwVVW} :
	\begin{equation}
		\frac{ \alpha(a)+\alpha(b) }{2}=\alpha\left( \frac{ a+b }{2} \right)=\frac{ \alpha(a+b) }{ 2 }.
	\end{equation}
	Cela démontre déjà que
	\begin{equation}
		\alpha(a+b)=\alpha(a)+\alpha(b).
	\end{equation}
	En particulier \( \alpha(-a)=\alpha(0-a)=\alpha(0)-\alpha(a)=-\alpha(a)\).

	Nous passons maintenant à la démonstration du fait que \( \alpha(ab)=\alpha(a)\alpha(b)\). Pour tout \( a\) différent de \( 0\) et \( \pm 1\) nous avons
	\begin{equation}        \label{EQooUPTOooOsEXjp}
		[a,-a,a^2,1]=\frac{ (a-a^2)(-a-1) }{ (-a-a^2)(a-1) }=-1.
	\end{equation}
	Et en prenant \( \alpha(a)\) en guise de \( a\) nous avons aussi
	\begin{equation}        \label{EQooXYKYooQJAiMB}
		[\alpha(a),-\alpha(a),\alpha(a)^2,\alpha(1)]=-1.
	\end{equation}
	Vu que \( \alpha\) préserve les divisions harmoniques, l'équation \eqref{EQooUPTOooOsEXjp} donne aussi
	\begin{equation}
		\big[ \alpha(a),\alpha(-a),\alpha(a^2),\alpha(1) \big]=-1,
	\end{equation}
	c'est-à-dire
	\begin{equation}    \label{EQooYYHLooSELBfl}
		\big[ \alpha(a),-\alpha(a),\alpha(a^2),1 \big]=-1.
	\end{equation}
	Comparant \eqref{EQooXYKYooQJAiMB} avec \eqref{EQooYYHLooSELBfl} et en tenant compte de l'unicité du birapport\footnote{C'est-à-dire que si trois éléments du birapport sont donnés, le quatrième est fixé. C'est une variation sur la thème de la proposition~\ref{PROPooKQZRooVCXPLW}\ref{ITEMooBEBEooVfiJXY}.} nous avons
	\begin{equation}
		\alpha(a^2)=\alpha(a)^2.
	\end{equation}

	Avec cela nous pouvons y aller en remarquant que
	\begin{equation}
		ab=\left( \frac{ a+b }{2} \right)^2-\left( \frac{ a-b }{2} \right)^2.
	\end{equation}
	Nous appliquons \( \alpha\) à cette dernière équations en tenant compte de ce que nous savons déjà
	\begin{equation}
		\alpha(ab)=\left( \frac{ \alpha(a)+\alpha(b) }{2} \right)^2-\left( \frac{ \alpha(a)-\alpha(b) }{2} \right)^2=\alpha(a)\alpha(b).
	\end{equation}
\end{proof}

\begin{theorem}[\cite{ooSEHIooEkvXHJ,ooERDDooFeasGD}]       \label{THOooKMKWooZPIDaK}
	Le groupe circulaire de \( \eC\) est le groupe des bijections \( \hat\eC\to\hat \eC\) préservant l'ensemble des cercles-droites.
\end{theorem}

\begin{proof}
	L'inclusion dans un sens est facile : les homographies conservent l'ensemble des cercles et droites par la proposition~\ref{PROPooYFJBooAWxFIs}. Et la conjugaison complexe aussi.

	Soit une bijection \( f\colon \hat \eC\to \hat\eC\) préservant les cercles-droites. Nous supposons dans un premier temps que \( f(0)=0\), \( f(1)=1\) et \( f(\infty)=\infty\).

	\begin{subproof}
		\spitem[Pour \( f\) vérifiant \( f(0,1,\infty)=0,1,\infty\)]

		Si \( \mC\) est un cercle alors \( f(\mC)\) est un cercle ou une droite, mais vu que \( \mC\) ne contient pas \( \infty\), l'ensemble \( f(\mC)\) ne le contient pas non plus. Donc \( f\) transforme un cercle en un cercle et une droite en une droite.

		\begin{subproof}
			\spitem[\( f\) préserve les divisions harmoniques]

			Soient \( a\), \( b\), \( c\), \( x\) dans \( \hat\eC\) tels que \( [a,b,c,x]=-1\). Nous allons prouver que \( [f(a),f(b),f(c),f(x)]=-1\).


			Si \( a\), \( b\) et \( c\) sont colinéaires, nous suivons la construction du lemme~\ref{LEMooYBTHooABWkeo}. Soit \( m\) hors de la droite \( (ab)\) et une droite \( D\) passant par \( c\) et coupant \( [ma]\) en \( p\) et \( [mb]\) en \( q\). Nous posons \( n=(pb)\cap(qa)\). Alors \( x=(mn)\cap(ac)\).

			L'application \( f\) est une bijection qui respecte les intersectons, les tangences, les cercles et les droites). Le point \( f(m)\) est hors de la droite \( \big( f(a)f(b) \big)\). La droite \( f(D)\) passe par \( f(c)\) et coupe les segments \( [f(m)f(a)]\) en \( f(p)\) et \( [f(m)f(b)]\) en \( f(q)\). Alors nous avons
			\begin{equation}
				f(n)=\big( f(p)f(b) \big)\cap\big( f(q)f(a) \big)
			\end{equation}
			et aussi
			\begin{equation}
				f(x)=\big( f(m)f(n) \big)\cap\big( f(a)f(c) \big)
			\end{equation}
			Donc \( f(x)\) se construit à partir de \( f(a)\), \( f(b)\) et \( f(c)\) en suivant la même construction que \( x\) à partir de \( a\), \( b\) et \( c\). Nous en concluons que \( [f(a), f(b),f(c),f(x)]=-1\).

			Si \( a\), \( b\) et \( c\) sont cocycliques, le même raisonnement, en suivant le lemme~\ref{LEMooAEDTooKsUoPw} nous donne le même résultat.

			\spitem[\( f\) est un automorphisme du corps \( \eC\)]

			C'est le lemme~\ref{LEMooOPOMooWZLSeH}.

			\spitem[Et enfin \ldots]

			Notre application \( f\) est un automorphisme du corps \( \eC\) qui fixe \( \eR\) parce qu'elle laisse invariante les droites dans \( \eC\). Donc la proposition~\ref{PROPooEATMooIPPrRV} nous dit que \( f\) est soit l'identité soit la conjugaison complexe. Dans les deux cas, \( f\) est dans le groupe circulaire.

		\end{subproof}

		\spitem[Pour \( f\) plus générale]

		Nous ne supposons plus que \( f\) fixe \( 0\), \( 1\) et \( \infty\). En tout cas les nombres \( f^{-1}(1)\), \( f^{-1}(0)\) et \( f^{-1}(\infty)\) sont distincts parce que \( f\) est une bijection. Nous pouvons considérer une homographie\footnote{Attention : ici nous parlons d'homographies de \( \hat \eC\), pas de \( P(\eC^2)\). L'existence d'une telle application demande de composer le corolaire~\ref{CORooRFCZooGZiQBJ} avec l'application \( \varphi_0\) et la définition~\ref{DEFooAMQHooPFUgIa} et~\ref{NORMooCVYKooYvjIeE}.} \( \phi\colon \hat \eC\to \hat \eC\) telle que \( \phi(1)=f^{-1}(1)\), \( \phi(0)=f^{-1}(0)\) et \( \phi(\infty)=f^{-1}(\infty)\). Dans ce cas l'application
		\begin{equation}
			g=f\circ\phi
		\end{equation}
		vérifie \( g(1)=1\), \( g(0)=1\) et \( g(\infty)=\infty\) tout en continuant à transformer un cercle-droite en un cercle-droite. Donc \( f\circ\phi\) est soit l'identité soit la conjugaison complexe. Avec ça, l'application
		\begin{equation}
			f=g\circ\phi^{-1}
		\end{equation}
		est la composée d'une homographie avec soit l'identité soit la conjugaison complexe. Elle est donc dans le groupe circulaire.
	\end{subproof}
\end{proof}

% TODO : Regarder si c'est possible de mettre les représentations de SL(2,C) et SO(1,3)

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Action du groupe modulaire}
%---------------------------------------------------------------------------------------------------------------------------
\index{groupe!modulaire}

Le \defe{demi-plan de Poincaré}{Poincaré (demi-plan)} est l'ensemble
\begin{equation}
	P=\{ z\in \eC\tq \Im(z)>0 \}.
\end{equation}
Le \defe{groupe modulaire}{groupe!modulaire}\index{modulaire (groupe)} est le quotient de groupes
\begin{equation}
	\PSL(2,\eZ)=\frac{ \SL(2,\eZ) }{ \eZ_2 }.
\end{equation}
Ce sont donc les matrices au signe près de la forme
\begin{equation}
	\begin{pmatrix}
		a & b \\
		c & d
	\end{pmatrix}
\end{equation}
où \( a\), \( b\), \( c\) et \( d\) sont entiers tels que \( ad-cb=1\).

\begin{theorem}[\cite{NsoHIL}] \label{ThoItqXCm}
	Le groupe modulaire agit fidèlement (définition~\ref{DefuyYJRh}) sur le demi-plan de Poincaré par
	\begin{equation}    \label{EqVXvwlB}
		\begin{pmatrix}
			a & b \\
			c & d
		\end{pmatrix}*z=\frac{ az+b }{ cz+d }.
	\end{equation}
	L'ensemble \(D= D_1\cup D_2\) avec
	\begin{subequations}
		\begin{align}
			D_1 & =\{ z\in P\tq | z |>1,\,-\frac{ 1 }{2}\leq \Re(z)<\frac{ 1 }{2} \} \\
			D_2 & =\{ z\in P\tq | z |=1,\,-\frac{ 1 }{2}\leq \Re(z)\leq0 \}
		\end{align}
	\end{subequations}
	est un domaine fondamental (définition~\ref{DefcSuYxz}) de cette action.

	De plus si nous notons
	\begin{equation}
		\begin{aligned}[]
			S & =\begin{pmatrix}
				     0 & -1 \\
				     1 & 0
			     \end{pmatrix}, & T & =\begin{pmatrix}
				                           1 & 1 \\
				                           0 & 1
			                           \end{pmatrix},
		\end{aligned}
	\end{equation}
	alors pour tout \( z\in P\), il existe \( A\in \gr(S,T)\) telle que \( A*z\in D\).
	%TODO : faire un dessin
\end{theorem}
\index{groupe!action}
\index{groupe!partie génératrice}
\index{groupe!et géométrie}
\index{racine!de l'unité}
\index{matrice}
\index{homographie}
\index{géométrie!avec nombres complexes}
\index{géométrie!avec des groupes}

\begin{proof}

	Nous divisions la preuve en plusieurs étapes.
	\begin{subproof}
		\spitem[Bien définie]

		D'abord il faut remarquer que l'action \eqref{EqVXvwlB} est bien définie par rapport au quotient : \( A*z=(-A)*z\). La vérification est immédiate.

		\spitem[Interne]

		Montrons que si \( A\in \PSL(2,\eZ)\) et \( z\in P\) alors \( A*z\in P\). Nous avons
		\begin{equation}
			A*z=\frac{ az+b }{ cz+d }=\frac{ (az+b)(c\bar z+d) }{ | cz+d |^2 }=\frac{ a| z |c+azd+bc\bar z+bd }{ | cz+d |^2 },
		\end{equation}
		et donc en décomposant \( z=\Re(z)+i\Im(z)\),
		\begin{equation}
			\Im(A*z)=\Im\left( \frac{ azd+bc\bar z }{ | cz+d |^2 } \right)=\frac{ ad-bc }{ | cz+d |^2 }\Im(z)=\frac{ \Im(z) }{ | cz+d |^2 }
		\end{equation}
		où nous avons tenu compte de \( ad-bc=1\). Donc l'action respecte la (stricte) positivité de la partie imaginaire.

		\spitem[Action]

		Nous vérifions maintenant que la formule donne bien une action : \( A*(B*z)=(AB)*z\). Cela est un bon calcul :
		\begin{subequations}
			\begin{align}
				A*(B*z) & =A*\left( \frac{ a'z+b' }{ c'z+d' } \right)                                                          \\
				        & =\frac{ a\left( \frac{ a'z+b' }{ c'z+d' } \right)+b }{ c\left( \frac{ a'z+b' }{ c'z+d' } \right)+d } \\
				        & =\frac{ a(a'z+b')+b(c'z+d') }{ c(a'z+b')+d(c'z+d') }                                                 \\
				        & =\frac{ (aa'+bc')z+(ab'+bd') }{ (ca'+dc')z+(cb'+dd') }                                               \\
				        & =\begin{pmatrix}
					           aa'+bc' & ab'+bd' \\
					           a'c+dc' & cb'+dd'
				           \end{pmatrix}*z                                                                                   \\
				        & =(AB)*z.
			\end{align}
		\end{subequations}
		\spitem[Fidèle]

		Soit \( A\in\PSL(2,\eZ)\) tel que pour tout \( z\in P\) nous ayons
		\begin{equation}
			\frac{ az+b }{ cz+d }=z.
		\end{equation}
		Alors nous avons
		\begin{equation}
			cz^2+(d-a)z+b=0.
		\end{equation}
		Cela est donc un polynôme en \( z\) qui s'annule sur un ouvert\footnote{On ne peut pas dire que \( b=0\) simplement en justifiant qu'on l'obtient en posant \( z=0\) parce que \( z=0\) n'est pas dans le demi-plan de Poincaré.} (le demi-plan de Poincaré). Il doit donc être identiquement nul, donc \( c=b=a-d=0\). Si vous n'y croyez pas, écrivez pour \( z=\epsilon i\) (avec \( \epsilon>0\)) :
		\begin{equation}
			-c\epsilon^2+\epsilon(d-a)i+b=0
		\end{equation}
		pour tout \( \epsilon\). Le fait d'avoir \( c\epsilon^2=b\) pour tout \( \epsilon\) implique que \( c=b=0\). Donc \( A\) est de la forme
		\begin{equation}
			A=\begin{pmatrix}
				a & 0 \\
				0 & d
			\end{pmatrix},
		\end{equation}
		avec la contrainte supplémentaire que \( ad=1\), les nombres \( a\) et \( b\) étant entiers. Nous avons donc soit \( a=d=1\) soit \( a=d=-1\). Étant donné le quotient par \( \eZ_2\), ces deux possibilités donnent le même élément de \( \PSL(2,\eZ)\).


		\spitem[Les orbites intersectent \( D\)]

		Soit \( z\in P\). Nous devons trouver \( A\in\PSL(2,\eZ)\) tel que \( A*z\in D\). Nous savons déjà que
		\begin{equation}
			\Im(A*z)=\frac{ \Im(z) }{ | cz+d |^2 }.
		\end{equation}
		Nous notons \( \mO_z\) l'orbite de \( z\) sous le groupe modulaire et nous posons
		\begin{equation}
			I_z=\{ \Im(u)\tq u\in \mO_z \}=\{ \Im(A*z)\tq A\in\PSL(2,\eZ) \},
		\end{equation}
		l'ensemble des parties imaginaires des éléments de l'orbite de \( z\). Nous allons montrer que cet ensemble est borné vers le haut en montrant que la quantité \( | cz+d |\) ne peut, à \( z\) donné, prendre qu'un nombre fini de valeurs plus grandes que \( \Im(z)\)\footnote{Bien que cela ne soit pas indispensable pour la preuve, remarquons que \( I_z\) ne comprend qu'une quantité au plus dénombrable de valeurs. Le fait que, à \( z\) donné, la quantité \( | cz+d |^2\) puisse être rendue aussi grande que l'on veut est évident. Donc \( I_z\) est borné vers le bas par zéro (qui n'est pas atteint, mais qui est une valeur d'adhérence).}. Nous cherchons donc les couples \( (c,d)\in \eZ^2\) tels que \( | cz+d |<1\).

		Nous avons \( \Im(cz+d)=c\Im(z)\), donc \( | cz+d |\geq |c \Im(z) |\), mais il n'y a qu'un nombre fini de \( c\in \eZ\) tels que \( | c\Im(z) |<1\). De la même façon, pour la partie réelle nous avons
		\begin{equation}
			\Re(cz+d)=c\Re(z)+d,
		\end{equation}
		et pour chaque \( c\),  il n'y a qu'un nombre fini de \( d\in \eZ\) qui laissent cette quantité plus petite que \( 1\) (en valeur absolue).

		Donc \( I_z\) possède un maximum. Soit \( A_1\in\PSL(2,\eZ)\) tel que \( \Im(A_1*z)=\max I_z\). Nous notons \( z_1=A_1*z\), et que nous n'avons à priori pas l'unicité. Nous allons maintenant agir sur \( z_1\) avec l'élément
		\begin{equation}
			T=\begin{pmatrix}
				1 & 1 \\
				0 & 1
			\end{pmatrix}
		\end{equation}
		pour ramener \( z_1\) dans le domaine \( D\). Si \( u\in P\) nous avons \( T*u=u+1\) et donc
		\begin{equation}
			T^n*u=u+n.
		\end{equation}
		Vu que \( D\) est de largeur \( 1\), il existe un \( n\) (éventuellement négatif) tel que
		\begin{equation}
			\Re(T^n*z_1)\in\mathopen[ -\frac{ 1 }{2} , \frac{ 1 }{2} [.
		\end{equation}
		Notons qu'ici le fait d'être ouvert d'un côté et fermé de l'autre joue de façon essentielle (pour l'unicité aussi). Nous notons \( z_2=T^n*z_1\).

		Supposons un instant que \( | z_2 |<1\). Nous considérons l'élément
		\begin{equation}
			S=\begin{pmatrix}
				0 & -1 \\
				1 & 0
			\end{pmatrix}
		\end{equation}
		qui fait
		\begin{equation}
			\Im(S*z)=\frac{ \Im z }{| z |^2}.
		\end{equation}
		Donc si \( | z_2 |<1\) alors \( \Im(S*z_2)>\Im(z_2)\), ce qui contredit la maximalité de \( \Im(z_2)\) dans \( I_z\). Nous en déduisons que \( | z_2 |\geq 1\).

		Si \( | z_2 |>1\), alors \( z_2\in D_1\) et c'est bon. Si \( | z_2 |=1\), alors il faut encore un peu travailler. Si \( z_2\pm 1\) est à l'intérieur du disque, alors en agissant avec \( T\) ou \( T^{-1}\) nous retrouvons la même contradiction que précédemment. En écrivant \( z_2= e^{i\theta}\), nous devons donc avoir \( 2\cos(\theta)\leq 1\) ou encore \( |\Re(z_2)|\leq \frac{ 1 }{2}\). Donc si \( \Re(z_2)\leq 0\) alors \( z_2\in D_2\).

		Le dernier cas à traiter est \( \Re(z_2)\in\mathopen] 0 , \frac{ 1 }{2} \mathclose]\), c'est-à-dire \( \theta\in \mathopen[ \frac{ \pi }{ 3 } , \frac{ \pi }{2} [\). Dans ce cas l'action avec \( S\) ramène l'angle dans la bonne zone parce que \( S*z=-\frac{1}{ z }\) et donc \( S*(\rho e^{-i\theta})=-\frac{1}{ \rho } e^{-i\theta}\).

		\spitem[Unicité]

		Nous voulons à présent montrer que si \( z\in D\), alors \( A*z\) n'est plus dans \( D\) (sauf si \( A=\pm\mtu\)). Nous supposons que \( z\in D\) et \( A\in \PSL(2,\eZ)\) soient tels que \( A*z\in D\), et nous prouvons qu'alors soit nous arrivons à une contradiction soit nous arrivons à \( A=\mtu\). Pour cela nous allons décomposer en de nombreux cas.

		\begin{enumerate}
			\item
			      Nous commençons par \( \Im(A*z)\geq \Im(z)\). Dans ce cas nous avons \( | cz+d |\leq 1\) et en particulier \( | c | |\Im(z) |\leq 1\). Étant donné que le point de \( D\) qui a la partie imaginaire la plus petite est \( -\frac{ 1 }{2}+\frac{ 2 }{ \sqrt{3} }i\), nous trouvons \( | c |\leq 2/\sqrt{3}\). Vu que \( c\) doit être entier, nous avons trois cas : \( c=-1,0,1\).
			      \begin{enumerate}
				      \item
				            Soit \( c=0\). Alors \( A=\begin{pmatrix}
					            a & b \\
					            0 & d
				            \end{pmatrix}\) et la condition de déterminant est \( ad=1\), ce qui signifie \( a=d=1\) (la possibilité \( a=b=-1\) est «éliminée» le quotient par \( \eZ_2\) définissant \( \PSL(2,\eZ)\)). La matrice \( A\) doit alors être de la forme
				            \begin{equation}
					            A=\begin{pmatrix}
						            1 & b \\
						            0 & 1
					            \end{pmatrix}
				            \end{equation}
				            et \( A*z=z+b\). Si \( z\in D\), alors le seul \( z+b\) à être (peut-être) encore dans \( D\) est \( b=0\), mais alors \( A\) est l'identité.

				      \item
				            Soit \( c=1\). Alors la condition \( | cz+d |\leq 1\) nous donne trois possibilités\footnote{Je ne rigolais pas quand je disais qu'on allait avoir de nombreux cas.} : \( d=-1,0,1\).

				            \begin{enumerate}
					            \item
					                  Si \( d=-1\), alors nous devons avoir \( | z-1 |\leq 1\). Il est instructif de faire un dessin, mais le point d'intersection entre les cercles \( | z |=1\) et \( | z-1 |=1\) est le point \( \frac{ 1 }{2}+\frac{ \sqrt{3} }{2}i\), qui n'est pas dans \( D\). Bref, il n'y a pas de points dans \( D\) vérifiant \( | z-1 |\leq 1\).

					            \item
					                  Si \( d=1\), alors (et c'est maintenant que la dissymétrie de \( D\) intervient) nous avons le point
					                  \begin{equation}
						                  z=-\frac{ 1 }{2}+\frac{ \sqrt{3} }{2}i
					                  \end{equation}
					                  qui est dans \( D\) et qui vérifie \( | z+1 |\leq 1\). Voyons à quoi ressemble la matrice \( A\) dans ce cas. Son déterminant est \( a-b=1\). Nous écrivons donc
					                  \begin{equation}
						                  A=\begin{pmatrix}
							                  b+1 & b \\
							                  1   & 1
						                  \end{pmatrix},
					                  \end{equation}
					                  et en tenant compte du fait que \( z\bar z=| z+1 |=1\), nous calculons
					                  \begin{subequations}
						                  \begin{align}
							                  A*z & =\frac{ (b+1)z+b }{ z+1 }                 \\
							                      & =\frac{ (bz+z+b)(\bar z+1) }{ | z+1 |^2 } \\
							                      & =z+b+1.
						                  \end{align}
					                  \end{subequations}
					                  La seule façon de ne pas quitter \( D\) est d'avoir \( b=-1\), mais alors nous avons
					                  \begin{equation}
						                  A=\begin{pmatrix}
							                  0 & -1 \\
							                  1 & 1
						                  \end{pmatrix}
					                  \end{equation}
					                  et \( A*z=z\). Donc au final \( z\) est quand même le seul de son orbite à être dans \( D\).

					                  Notons au passage cette très intéressante propriété du point
					                  \begin{equation}
						                  z_0=-\frac{ 1 }{2}+\frac{ \sqrt{3} }{2}i.
					                  \end{equation}
					                  C'est un point de qui vérifie \( z_0=A*z_0\) pour un élément non trivial \( A\) de \( \PSL(2,\eZ)\). L'existence d'un tel élément est ce qui va nous coûter un peu de sueur pour prouver que \( PSL(2,\eZ)\) est engendré par \( S\) et \( T\).

					            \item
					                  Le cas \( d=0\) nous fait écrire \(1= \det A=-b\), donc \( b=-1\) et
					                  \begin{equation}
						                  A=\begin{pmatrix}
							                  a & -1 \\
							                  1 & 0
						                  \end{pmatrix}.
					                  \end{equation}
					                  Nous avons alors \( A*z=a-\frac{1}{ z }\). De plus la condition \( | z |\leq 1\) revient à \( | z=1 |\). Pour les nombres complexes de module \( 1\), l'opération \( z\to -1/z\) est la symétrie autour de l'axe des imaginaires purs. Le seul à ne pas sortir de \( D\) est le fameux \( z=-\frac{ 1 }{2}+\frac{ \sqrt{3} }{2}i\), qui revient sur lui-même avec \( a=-1\).
				            \end{enumerate}

			      \end{enumerate}

			      Nous passons à la possibilité \( c=-1\). Dans ce cas la matrice est de la forme
			      \begin{equation}
				      A=\begin{pmatrix}
					      a  & b \\
					      -1 & d
				      \end{pmatrix},
			      \end{equation}
			      et nous revenons au cas \( c=1\) en prenant \( -A\) au lieu de \( A\).


			\item
			      Nous passons au cas \( \Im(A*z)<\Im(z)\). Nous récrivons cette condition avec
			      \begin{equation}
				      \Im(A*z)<\Im\big( A^{-1}*(A*z) \big).
			      \end{equation}
			      Si nous supposons que \( z\) et \( A\) sont tels que \( z\) et \( A*z\) soient tous deux dans \( D\), alors \( z'=A*z\) est un élément de \( D\) tel que
			      \begin{equation}
				      \Im(z')<\Im(A^{-1}*z').
			      \end{equation}
			      Or nous avons vu qu'aucun élément de \( D\) vérifiant cette condition n'existait sans être trivial (celui qui ne bouge pas). Pour cela il suffit d'appliquer tout ce que nous venons de dire avec \( A^{-1}\) au lieu de \( A\).
		\end{enumerate}

		\spitem[Quelques conclusions]

		Après avoir passé tous les cas en revue, le fameux point \( z_0=-\frac{ 1 }{2}+\frac{ \sqrt{3} }{2}i\) est l'unique point de \( D\) à accepter une matrice non triviale \( A\in \PSL(2,\eZ)\) telle que \( z_0=A*z_0\).

		Nous remarquons aussi que tous les points de \( P\) sont ramenés dans \( D\) par une matrice obtenue comme produit de \( T\), \( S\), \( T^{-1}\) et \( S^{-1}\).

	\end{subproof}
\end{proof}

\begin{corollary}[\cite{SjxoHK}]    \label{CorJQwgNp}
	Les matrices \( S\) et \( T\) génèrent le groupe modulaire au sens où toute matrice de \( \PSL(2,\eZ)\) s'écrit comme
	\begin{equation}
		T^{m_1}S^{p_1}\ldots T^{m_k}S^{p_k}
	\end{equation}
	pour un certain \( k\) et des nombres \( m_i,p_i\in \eZ\). Autrement dit, \( \PSL(2,\eZ)=\gr(S,T)\).
\end{corollary}

\begin{proof}
	Soit \( z\), un point de \( D\) autre que \( z_0\). Alors si \( A\in \PSL(2,\eZ)\) est non trivial nous avons \( A*z\) hors de \( D\). Du coup, comme vu dans la démonstration du théorème~\ref{ThoItqXCm}, il existe \( B\in \gr(S,T)\) tel que \( B*(A*z)\in D\). Vu que \( D\) ne contient qu'un seul point de chaque orbite, nous avons
	\begin{equation}
		B*A*z=z,
	\end{equation}
	et donc \( BA=\pm\mtu\), ce qui prouve que\footnote{Dans \( \PSL(2,\eZ)\), nous n'avons pas besoin de mettre \( \pm\) parce qu'il est compris dans la définition.} \( A=B^{-1}\), c'est-à-dire que \( A\in\gr(S,T)\).
\end{proof}

% TODO : Regarder si c'est possible de mettre les représentations de SL(2,C) et SO(1,3)
