% This is part of Mes notes de mathématique
% Copyright (c) 2006-2025
%   Laurent Claessens, Carlotta Donadello
% See the file fdl-1.3.txt for copying conditions.

%++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Fonctions de classe \texorpdfstring{\(  C^1\)}{C1}}
%++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

La définition des fonctions de classe \( C^k\) est la définition \ref{DefPNjMGqy}.

Soit \( f\) une fonction différentiable de \( U\), ouvert de \( \eR^m\), dans \( \eR^n\). L'application différentielle de \( f\) est une application  de \( \eR^m\) dans \( \aL(\eR^m, \eR^n)\)
\begin{equation}
	\begin{aligned}
		df\colon \eR^m & \to \aL(\eR^m,\eR^n) \\
		a              & \mapsto df_a
	\end{aligned}
\end{equation}
Nous savons que \( \aL(\eR^m, \eR^n)\) est un espace vectoriel normé avec la définition~\ref{DefDQRooVGbzSm}. Si \( T\) est un élément dans \( \aL(\eR^m, \eR^n)\) alors la norme de \( T\) est définie par
\[
	\|T\|_{\aL(\eR^m, \eR^n)}=\sup_{x\in\eR^m} \frac{\|T(x)\|_n}{\|x\|_m}=\sup_{\begin{subarray}{l}
			x\in\eR^m\\
			\|x\|_m\leq 1
		\end{subarray}} \|T(x)\|_n.
\]

Lorsqu'il existe un \( M>0\) tel que \( \| df(a) \|_{\aL(\eR^m,\eR^n)}<M\) pour tout \( a\) dans \( U\), nous disons que la différentielle de \( f\) est \defe{bornée}{bornée!différentielle} sur \( U\).

\begin{normaltext}      \label{NORMooDAZZooDiGFoW}
	Quelques précisions sur l'énoncé de la proposition \ref{PROPooUDJLooHwzjQF}. Lorsque nous parlons de \( \partial_if\), nous supposons donnée une base de \( V\). Il n'y a aucune raison que la norme sur \( V\) soit adaptée à cette base. Nous allons donc utiliser une norme «euclidienne» adaptée à la base, et invoquer l'équivalence de toutes les normes pour dire que si une fonction est différentiable pour une norme elle l'est pour toutes les normes.
\end{normaltext}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Différentielle et dérivées partielles}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

\begin{proposition}[\cite{TrenchRealAnalisys}]     \label{PROPooUDJLooHwzjQF}
	Soient des espaces vectoriels normés de dimensions finies \( V\) et \( E\) ainsi qu'une application \( f\colon V\to E\). Nous supposons que les dérivées partielles \( \frac{ \partial f }{ \partial x_i }\) existent sur un voisinage de \( a\in V\) et qu'elles sont continues en \( a\).

	Alors
	\begin{enumerate}
		\item
		      l'application \( f\) est différentiable en \( a\),
		\item
		      la différentielle est donnée par\footnote{Voir la définition \ref{DEFooLULCooYjBEaZ} pour \( \times_n\).}
		      \begin{equation}
			      df_a=\sum_{j=1}^n\frac{ \partial f }{ \partial x_j }(a)\times_1\omega_j.
		      \end{equation}
	\end{enumerate}
\end{proposition}

\begin{proof}
	L'espace \( V\) a une norme que nous notons \( \| . \|_V\); nous n'allons presque pas l'utiliser. Nous nommons \( \{ e_i \}\) la base de \( V\) sous-entendue lorsque nous parlons des dérivées partielles, et nous considérons la norme \( \|  \|\) sur \( V\) donnée par \( \| v \|=\sqrt{ \sum_{i=1}^n }x_i^2\) pour \( x=\sum_ix_ie_i\). Toutes les normes et boules dont nous allons parler dans la suite seront par rapport à cette norme.

	Nous posons \( \epsilon>0\). La continuité des dérivées partielles en \( a\) nous permet de considérer \( \delta>0\) tel que
	\begin{equation}        \label{EQooPBYDooAtPkGl}
		\| \frac{ \partial f }{ \partial x_j }(s)-\frac{ \partial f }{ \partial x_j }(a) \|<\epsilon
	\end{equation}
	pour tout \( s\in  B(a,\delta)\), et pour tous les \( j\) en même temps\footnote{Ce qui peut n'être pas possible en dimension infine. Je dis ça comme ça, juste pour faire remarquer que cette proposition n'est peut-être pas vraie en dimension infine. Voir aussi l'exemple de la fonction \eqref{EqCJVooJOuXdN}.}.

	Soit \( x\in B(a,\delta)\). Nous considérons les points
	\begin{equation}
		s_j=(x_1,\ldots, x_j,a_{j+1},\ldots, a_n).
	\end{equation}
	Précision : \( s_n=x\).

	\begin{subproof}
		\spitem[Un peu de convexité]
		Nous montrons que le segment \( [s_j,s_{j-1}]\) est dans \( B(a,\delta)\). Nous avons \( s_j-a=(x_1-a_1,\ldots, x_j-a_j,0,\ldots, 0)\), et donc
		\begin{equation}
			\| s_j-a \|\leq \| x-a \|<\delta,
		\end{equation}
		et donc \( s_j\in B(a,\delta)\) pour tout \( j\). Vu que la sphère \( B(a,\delta)\) est convexe\footnote{Proposition \ref{PROPooUQLUooDQfYLT}.}, tout le segment entre \( s_j\) et \( s_{j-1}\) est dedans.
		\spitem[Accroissements finis]
		En nous souvenant que \( x\) et \( a\) ont été fixés, nous considérons les fonctions intermédiaires suivantes :
		\begin{subequations}
			\begin{numcases}{}
				g_1(t)=f(t,a_2,\ldots, a_n)\\
				g_j(t)=f(x_1,\ldots, x_{j-1},t,a_{j+1},\ldots, a_n)\\
				g_n(t)=f(x_1,\ldots, x_{n-1},t).
			\end{numcases}
		\end{subequations}
		Elles vérifient en particulier \( g_j(x_j)=f(s_j)\) et \( g_j(a_j)=f(s_{j-1})\). Donc le théorème des accroissements finis \ref{ThoAccFinis} nous donne l'existence de \( \tau_j\) entre \( x_j\) et \( a_j\) tel que
		\begin{equation}        \label{EQooVALVooXmUmwR}
			f(s_j)-f(s_{j-1})=g_j(x_j)-g_j(a_j)=g_j'(\tau_j)(x_j-a_j).
		\end{equation}
		\spitem[Dérivées partielles]
		Les fonctions \( g_j\) ont été construites de telle sorte à donner les dérivées partielles de \( f\) via une simple dérivation :
		\begin{equation}
			g'_j(t_0)=\frac{ \partial f }{ \partial x_j }(x_1,\ldots, x_{j-1},t_0,a_{j+1},\ldots, a_n).
		\end{equation}
		Or lorsque\footnote{Retournez éventuellement les intervalles sur \( a_j<x_j\).} \( t_0\in [x_j,a_{j}]\), le point \( (x_1,\ldots, x_{j-1},t_0,a_{j+1},\ldots, a_n)\) est dans \( \mathopen[ s_j , s_{j-1} \mathclose]\). Cela est le cas pour \( t_0=\tau_j\). Nous notons
		\begin{equation}
			\bar s_j=(x_1,\ldots, x_{j-1},\tau_j,a_{j+1},\ldots, a_n)
		\end{equation}
		et nous avons
		\begin{equation}
			g'_j(\tau_j)=\frac{ \partial f }{ \partial x_j }(\bar s_j)
		\end{equation}
		avec \( \bar s_j\in\mathopen[ s_{j-1} , s_j \mathclose]\). Tout cela pour récrire \eqref{EQooVALVooXmUmwR} sous la forme
		\begin{equation}
			f(s_j)-f(s_{j-1})=\frac{ \partial f }{ \partial x_j }(\bar s_j)(x_j-a_j).
		\end{equation}
		\spitem[Une belle somme télescopique]
		En nous souvenant que \( s_0=a\) et que \( s_n=x\), nous avons cette somme télescopique
		\begin{subequations}
			\begin{align}
				f(x)-f(a) & =\sum_{j=1}^n\big( f(s_j)-f(s_{j-1}) \big)                                                                        \\
				          & =\sum_{j=1}^n\frac{ \partial f }{ \partial x_j }(\bar s_j)(x_j-a_j)                                               \\
				          & =\sum_{j=1}^n\big[ (\partial_jf)(\bar s_j)-(\partial_jf)(a) \big](x_j-a_j)+\sum_{j=1}^n(\partial_jf)(a)(x_j-a_j).
			\end{align}
		\end{subequations}
		Nous isolons les termes qui nous intéressent dans la définition de la différentielle :
		\begin{equation}
			f(x)-f(a)-\sum_{j=1}^n(\partial_jf)(a)(x_j-a_j)=\sum_{j=1}^n\big[ (\partial_jf)(\bar s_j)-(\partial_jf)(a) \big](x_j-a_j).
		\end{equation}
		\spitem[Et enfin : le quotient différentiel]
		En utilisant la majoration \eqref{EQooPBYDooAtPkGl}, et en remarquant que \( \| x-a \|\) majore \( | x_j-a_j |\) pour chaque \( j\), nous avons l'inégalité
		\begin{equation}
			\| f(x)-f(a)-\sum_{j=1}^n\frac{ \partial f }{ \partial x_j }(a)(x_j-a_j) \|\leq n\epsilon\| x-a \|.
		\end{equation}
		Autrement dit, en posant \( T=\sum_{j=1}^n\frac{ \partial f }{ \partial x_j }(a)\omega_j\) nous avons
		\begin{equation}
			\| f(a+h)-f(a)-T(h) \|\leq n\epsilon\| h \|,
		\end{equation}
		et donc
		\begin{equation}        \label{EQooVBYTooEYutva}
			\lim_{h\to 0} \frac{ \| f(a+h)-f(a)-T(h) \| }{ \| h \| }=0.
		\end{equation}
		\spitem[Et donc ?]
		La limite \eqref{EQooVBYTooEYutva} nous indique que \( f\) serait différentiable de différentielle \( T\) si \( \| . \|\) était la norme sur \( V\). C'est l'équivalence de toutes les normes\footnote{Sur un espace de dimension finie, \ref{ThoNormesEquiv}.} qui fait en sorte que la norme sur \( V\) n'est pas importante.
	\end{subproof}
\end{proof}

\begin{proposition}     \label{PROPooUUOSooPuXJjQ}
	Soient des espaces vectoriels normés de dimensions finies \( V\) et \( E\) ainsi qu'une application \( f\colon V\to E\). Nous supposons que les dérivées partielles \( \frac{ \partial f }{ \partial x_i }\) existent et sont continues sur un ouvert \( \mU\) de \( V\).

	Alors \( f\) est de classe \( C^1\) sur \( \mU\).
\end{proposition}

\begin{proof}
	Nous notons \( \mU\) le voisinage sur lequel les dérivées partielles de \( f\) existent et sont continues. Il s'agit d'appliquer la proposition \ref{PROPooUDJLooHwzjQF} en chaque point de \( \mU\). Nous avons alors
	\begin{equation}
		df_x=\sum_{j=1}^n\frac{ \partial f }{ \partial x_j }(x)\times_1\omega_j
	\end{equation}
	pour tout \( x\in \mU\). Pour \( a\in V\) et \( h\in V\) supposé petit, nous avons
	\begin{subequations}
		\begin{align}
			\| df_a-df_{a+h} \|_{\aL(V,E)} & =\sup_{\| v \|=1}\| df_a(v)-df_{a+h}(v) \|_E                                                                                                                              \\
			                               & =\sup_{\| v \|=1}\| \sum_{j=1}^n\big( \frac{ \partial f }{ \partial x_j }(a)-\frac{ \partial f }{ \partial x_j }(a+h) \big)v_j \|                                         \\
			                               & \leq \sup_{\| v \|=1}\| \sum_{j=1}^n\big( \frac{ \partial f }{ \partial x_j }(a)-\frac{ \partial f }{ \partial x_j }(a+h) \big) \| |v_i |     \label{SUBEQooHMUIooNSjoxZ} \\
			                               & \leq\| \sum_{j=1}^n\big( \frac{ \partial f }{ \partial x_j }(a)-\frac{ \partial f }{ \partial x_j }(a+h) \big) \|      \label{SUBEQooPBLWooUqNlhV}
		\end{align}
	\end{subequations}
	Justifications :
	\begin{itemize}
		\item
		      Pour \eqref{SUBEQooPBLWooUqNlhV}, nous avons majoré \( | v_i |\leq \| v \|=1\).
		\item
		      Pour \eqref{SUBEQooHMUIooNSjoxZ}, nous avons utilisé le lemme \ref{LEMooIBLEooLJczmu}.
	\end{itemize}
	La continuité de \( \partial_jf\) conclut que \( \lim_{h\to 0}\|  df_a-df_{a+h}  \|=0\), ce qui signifie que \( df\) est continue et donc que \( f\) est de classe \( C^1\).
\end{proof}

\begin{theorem}     \label{THOooBEAOooBdvOdr}
	Soient des espaces vectoriels normés de dimensions finies \( V\) et \( E\). Soit un ouvert \( \mU\) de \( V\). Une application \( f\colon V\to E\) est de classe \( C^1\) sur \( \mU\) si et seulement si ses dérivées partielles existent et sont continues sur \( \mU\).

	Dans ce cas, nous avons la formule
	\begin{equation}        \label{EQooPREWooVHVIAF}
		df_a=\sum_i\frac{ \partial f }{ \partial x_i }(a)\times_1 \omega_i.
	\end{equation}
\end{theorem}

\begin{proof}
	Le premier sens, y compris la formule \eqref{EQooPREWooVHVIAF}, a été fait dans la proposition \ref{PROPooUUOSooPuXJjQ}. Nous supposons maintenant que \( f\) est de classe \( C^1\) sur \( \mU\) et nous allons prouver que ses dérivées partielles existent et sont continues. Pour tout \( t\neq 0\) nous avons l'égalité
	\begin{equation}
		\frac{ f(a+te_i)-f(a) }{ t }=\frac{ f(a+te_i)-f(a)-df_a(te_i) }{ t }+df_a(e_i).
	\end{equation}
	Par définition de la différentielle, prendre la limite \( t\to 0\) à droite donne \( df_a(e_i)\) parce que la fraction tend vers zéro. La limite définissant la dérivée partielle existe donc et vaut
	\begin{equation}
		\frac{ \partial f }{ \partial x_i }(a)=df_a(e_i).
	\end{equation}

	Il nous reste à prouver que les dérivées partielles sont continues :
	\begin{subequations}
		\begin{align}
			\| \frac{ \partial f }{ \partial x_i }(a+h)-\frac{ \partial f }{ \partial x_i }(a) \| & =\| df_{a}(e_i)-df_{a+h}(e_i) \|  \\
			                                                                                      & =\| (df_{a+h}-df_a)(e_i) \|       \\
			                                                                                      & \leq \| df_{a+h}-df_a \|\| e_i \| \\
			                                                                                      & = \| df_{a+h}-df_a \|.
		\end{align}
	\end{subequations}
	Vu que \( f\) est de classe \( C^1\), la limite \( h\to 0\) de cela donne zéro.
\end{proof}

Voici une version du même théorème, démontré dans le cas seulement de dimension deux. Il rend peut-être aussi plus clairement pourquoi ça ne marche pas en dimension infinie.

\begin{proposition}		\label{Diff_totale}     % Il ne faut pas référentier cette proposition, mais le théorème THOooBEAOooBdvOdr.
	Soit \( U\) un ouvert dans \( \eR^m\) et \( a\) un point dans \( U\). Soit \( f\) une application de \( U\) dans \( \eR^n\). Si toutes les dérivées partielles de \( f\) existent sur \( U\) et sont continues au point \( a\) alors \( f\) est différentiable au point \( a\).
\end{proposition}

\begin{proof}
	On se limite au cas \( m=2\).  Pour rendre les calculs plus simples on utilise ici la norme \( \|\cdot\|_\infty\) dans l'espace \( \eR^2\), mais comme on a vu plus en haut, cela ne peut pas avoir des conséquences sur la différentiabilité de \( f\). Si la différentielle de \( f\) au point \( a\) existe alors elle est définie par la formule
	\[
		df_a(v)=\frac{ \partial f }{ \partial x }(a)v_1+\frac{ \partial f }{ \partial y }(a)v_2
	\]
	pour tout \( v\) dans \( \eR^m\).

	On commence par prouver le résultat en supposant que les dérivées partielles de \( f\) au point \( a\) sont nulles. La différentiabilité de \( f\) signifie que pour toute constante  \( \varepsilon> 0\) il y a une constante \( \delta>0\) telle que si \( \|v\|_\infty\leq \delta \) alors
	\[
		\frac{\|f(a_1+v_1, a_2+v_2)-f(a_1, a_2)\|_n}{\|v\|_\infty}\leq \varepsilon.
	\]
	On écrit alors
	\begin{equation}
		\begin{aligned}
			 & \|f(a_1+v_1, a_2+v_2)-f(a_1, a_2)\|_n=                                            \\
			 & =\|f(a_1+v_1, a_2+v_2)-f(a_1+v_1, a_2)+f(a_1+v_1, a_2)-f(a_1, a_2)\|_n\leq        \\
			 & \leq \|f(a_1+v_1, a_2+v_2)-f(a_1+v_1, a_2)\|_n+\|f(a_1+v_1, a_2)-f(a_1, a_2)\|_n.
		\end{aligned}
	\end{equation}
	Comme la dérivée partielle \( \partial_x f\) est nulle au point \( a\)  on sait que  pour toute constante  \( \varepsilon> 0\) il y a une constante \( \delta_1>0\) telle que si \( |v_1|\leq \delta_1 \) alors
	\[
		\|f(a_1+v_1, a_2)-f(a_1, a_2)\|_n\leq \varepsilon |v_1|.
	\]
	Pour l'autre terme on a, par la proposition~\ref{val_medio_1},
	\begin{equation}
		\|f(a_1+v_1, a_2+v_2)-f(a_1+v_1, a_2)\|_n\leq \sup\{\|\partial_yf(x)\|_n\,\vert\, x\in S\}|v_2|.
	\end{equation}
	où \( S\) est le segment d'extrémités  \( (a_1+v_1, a_2)\) et \(  (a_1+v_1, a_2+v_2)\). Comme la  dérivée partielle \( \partial_y f\) est continue et nulle au point \( a\) on sait que  pour toute constante  \( \varepsilon> 0\) il existe une constante \( \delta_2>0\) telle que si \( \|(u_1,u_2)\|_\infty\leq \delta_2 \) alors \( \|\partial_yf(a_1+u_1,a_2+u_2)\|_n\leq \varepsilon\). Si on choisit \( \delta = \min\{\delta_1,\,\delta_2\}\) le segment \( S\) est contenu dans la boule de rayon \( \delta\) centrée au point \( a\) et on obtient
	\[
		\|f(a_1+v_1, a_2+v_2)-f(a_1, a_2)\|_n\leq \varepsilon |v_1|+\varepsilon |v_2|\leq 2\varepsilon \|v\|_\infty.
	\]
	Cela prouve que \( f\) est différentiable en \( (a_1,a_2)\) et que la différentielle est nulle :
	\begin{equation}
		df_{(a_1,a_2)}=0.
	\end{equation}

	Dans le cas général, où les dérivées partielles de \( f\) au point \( a\) ne sont pas spécialement nulles, on peut considérer la fonction\footnote{Vous verrez dans la discussion à propos de la fonction \eqref{EqCJVooJOuXdN} pourquoi cette fonction ne fonctionne pas dans le cas de la dimension infinie.}
	\begin{equation}    \label{EqXHVooJeQKrB}
		g(x,y)=f(x,y)-\partial_1 f(a)x-\partial_2 f(a)y,
	\end{equation}
	qui a dérivées partielles nulles au point \( a\). La fonction \( g\) est donc différentiables. La fonction \( f\) est maintenant la somme de \( g\) et de la fonction linéaire et continue \( (x,y)\mapsto \partial_1 f(a)x-\partial_2 f(a)y\). On verra dans la prochaine section que la somme de deux fonctions différentiables est une fonction différentiable. Par conséquent, la fonction \( f\) est différentiable.
\end{proof}

\begin{remark}
	En dimension infinie, il n'est pas vrai que l'existence et la continuité de toutes les dérivées partielles en un point implique la différentiabilité en ce point. Pour donner un exemple, nous allons continuer l'exemple~\ref{ExHKsIelG}
	avec la fonction~\ref{EqCJVooJOuXdN} sur un espace de Hilbert.

	En dimension infinie nous aurons le théorème~\ref{ThoOYwdeVt} qui donnera quelque chose de moins fort.
\end{remark}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Dérivée partielle de fonctions composées}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

\begin{normaltext}
	Une petite note sur les notations du théorème de dérivation partielle de fonctions composées. La formule \eqref{EQooZMAUooIusxgD} est plus souvent écrite sous la forme
	\begin{equation}
		\frac{ \partial (f\circ g) }{ \partial x_i }(a)=\sum_{k=1}^n\frac{ \partial f }{ \partial y_k }\big( g(a) \big)\frac{ \partial g_k }{ \partial x_i }(a).
	\end{equation}
	Du point de vue du névrosé des notations précises que je suis, cette façon d'écrire est délicate à exprimer parce qu'il faudrait décider ce que signifie «noter \( x\) les variables de \( \eR^n\) et \( y\) celles de \( \eR^m\)».

	Et je ne vous parle même pas des problèmes que ça pose si \( x\) est justement le nom d'une fonction quand on considère un changement de variable.
\end{normaltext}

\begin{normaltext}
	À propos de changement de variables \ldots{} J'ai une bonne nouvelle : il n'y a pas de notions de «différentielle partielle» et de «différentielle totale». Ces notions sont introduites par les personnes qui utilisent de mauvaises notations pour distinguer deux notions différentes qu'ils sont incapables de distinguer par des notations claires\footnote{Là je vise la quasi totalité des sources parlant de changement de variable dans les équations différentielles et les physiciens, en particulier les mécaniciens.}.
\end{normaltext}

\paragraph{Les choses mal faites en une dimension}

Voici comment on présente (mal) les choses. Soit une fonction \( y(x)\). Si on effectue un changement de variables \( x=x(t)\), on peut voir \( y\) comme une fonction de \( t\) au lieu de \( x\), et parler de la dérivée de \( y\) à travers \( x\).

Si \( y(x)=x^2\) et si \( x(t)=\sin(t)\), on se retrouve à écrire
\begin{equation}        \label{EQooNGFYooCJDmNq}
	y'(t)=2\sin(t)\cos(t)
\end{equation}
et
\begin{equation}        \label{EQooYXJEooQYfCYQ}
	y'(x)=2x.
\end{equation}
Comment l'objet \( y'\) peut dépendre du nom de la variable ?!? Notez qu'en substituant \( x=\sin(t)\) dans \eqref{EQooYXJEooQYfCYQ}, le compte n'est pas bon : on n'a pas \eqref{EQooNGFYooCJDmNq}.

Pour résoudre ce problème, on peut dire que la bonne quantité à regarder n'est pas \( y'\) mais bien \( dy\). Alors on doit en fait regarder non \( y'(x)\) mais \( y'(x)dx\) où \( dx=\cos(t)dt\). Avec ça, on a en effet
\begin{equation}
	dy=\frac{ dy }{ dx }\frac{ dx }{ dt }dt=2\sin(t)\cos(t)dt,
\end{equation}
et
\begin{equation}
	dy=\frac{ dy }{ dt }dt=2\sin(t)\cos(t)dt.
\end{equation}

Il faut alors bien comprendre que le «\( y\)» dans \( \frac{ dy }{ dt }\) n'est pas le même que le \( y\) dans \( \frac{ dy }{ dx }\).

\paragraph{Les choses bien faites en une dimension}

Soit une fonction \( y\colon \eR\to \eR\). Nous considérons une application (appelée «changement de variable» si on veut, mais surtout appelée «difféomorphisme de \( \eR\) vers \( \eR\)») \( x\colon \eR\to \eR\).

Maintenant que la notation «\( x\)» est prise pour désigner une fonction, il n'est plus possible d'écrire \( y(x)\), parce que \( y\) est une application qui prend en argument un élément de \( \eR\) et non de \(  C^{\infty}(\eR)\).

On introduit donc une nouvelle fonction \( z=y\circ x\). Donc \( z(t)=y\big( x(t) \big)=\sin(t)^2\). Le nom de la variable importe peu tant que ce n'est pas un nom déjà utilisé. Nous avons alors aucune ambigüité :
\begin{equation}
	y'(u)=2u
\end{equation}
et
\begin{equation}
	z'(u)=2\sin(u)\cos(u).
\end{equation}
Notez que les égalités suivante sont parfaitement correctes et ne souffrent d'aucun problème d'interprétation :
\begin{itemize}
	\item
	      \( y(t)=t^2\)
	\item
	      \( z(\xi)=\sin(\xi)^2\)
	\item
	      \( x(s)=\sin(s)\)
	\item
	      \( x\big( y(u) \big)=\sin\big( y(u) \big)=\sin(u^2)\).
\end{itemize}
Si les fonctions \( y\) et \( x\) représentent des quantités physiques, certaines de ces formules sont peut-être idiotes à écrire, mais elles sont correctes.

\paragraph{Les choses mal faites en dimension 2}

Soit une fonction \( f\) de la position et du temps qu'on note \( f(x,t)\). Cette fonction vérifie une équation aux dérivées partielles, mettant en jeu \( \frac{ \partial f }{ \partial x }\) et \( \frac{ \partial f }{ \partial t }\).

Coup de théâtre : on veut savoir la valeur de \( f\) le long d'une trajectoire \( x(t)\). Nous voici avec
\begin{equation}
	f\big( x(t), t \big).
\end{equation}
Et là quand on veut parler de la dérivée de \( f\) par rapport à \( t\), on doit distinguer la dérivée partielle \( \frac{ \partial f }{ \partial t }\) qui consiste à ne dériver l'expression \( f\big( x(t),t \big)\) que par rapport aux \( t\) qui apparaissent «vraiment», de la «dérivée totale» qui consiste à dériver par rapport à toutes les occurrences de \( t\), y compris à travers \( x\).

\paragraph{Les choses bien faites en dimension 2}

Soit une fonction \( f\colon \eR^2\to \eR\). Prenons par exemple \( f(x,t)=x\sin(t)\). Soit une trajectoire \( s\colon \eR\to \eR\) que nous nous gardons bien de noter «\( x\)». Ce qu'on entend par «voir \( f\) sur la trajectoire \( s\)»  signifie en réalité considérer la fonction
\begin{equation}
	\begin{aligned}
		\varphi\colon \eR & \to \eR                       \\
		t                 & \mapsto f\big( s(t), t \big).
	\end{aligned}
\end{equation}

Ce qu'on aurait appelé la dérivée totale de \( f\) par rapport à \( t\) est simplement la dérivée usuelle \( \varphi'\) de \( \varphi\) en tant que bête fonction \( \eR\to \eR\). Si par exemple \( s(t)=t^2\), nous avons
\begin{equation}
	\varphi(t)=t^2\sin(t).
\end{equation}
Nous avons donc toutes les dérivées sans ambigüité :
\begin{subequations}
	\begin{align}
		\frac{ \partial f }{ \partial x }(x,t) & =\sin(t)               \\
		\frac{ \partial f }{ \partial t }(x,t) & =x\cos(t)              \\
		\varphi'(t)                            & =2t\sin(t)+t^2\cos(t).
	\end{align}
\end{subequations}

Le mieux serait même d'écrire \( \partial_1f\) et \( \partial_2f\) au lieu de \( \frac{ \partial f }{ \partial x }\) et \( \frac{ \partial f }{ \partial t }\), parce que ce sont des fonctions complètement déterminées par \( f\) et non par la notation \( x\) et \( t\) qu'on a choisie pour nommer les variables au moment d'écrire \( f(x,t)=x\sin(t)\).

\begin{normaltext}
	Et d'ailleurs en mathématique, il n'y a rien qui s'appelle «changement de variable». Il y a seulement des choses qui s'appellent «composition de fonction».

	Cela n'est pas limité à l'analyse. Il n'y a par exemple pas de concept de «choisir une base dans laquelle une matrice est diagonale». Si \(S\) est une matrice symétrique, il existe une matrice diagonale \( D\) et une matrice orthogonale \( A \) telles que \( D=ASA^{-1}\). Quand on veut démontrer une théorème sur \( S\), on commence par démontrer le théorème dans le cas particulier où \( S\) est diagonale, puis on espère que le résultat se généralise facilement aux matrices de la forme \( ADA^{-1}\) où \( D\) est diagonale et \( A\) est orthogonale.
\end{normaltext}

\begin{normaltext}
	Tout cela pour dire que nous allons maintenant prouver le théorème de dérivation partielle de fonctions composées. C'est ce théorème qui est utilisé chaque fois qu'on fait un «changement de variables» dans une équation aux dérivées partielles.
\end{normaltext}


\begin{theorem}[\cite{MonCerveau,BIBooKWZDooWnWJWO}]     \label{THOooKBTYooWFtoSF}
	Soient :
	\begin{enumerate}
		\item
		      trois espaces vectoriels normés \( U\), \( V\) et \( W\) de dimension finie
		\item
		      \( a\in V\), un voisinage \( \Omega\) de \( a\)
		\item
		      des applications \( g\colon \Omega\to U\) et \( f\colon g(\Omega)\to W\)
		\item
		      des bases de \( U\), \( V\) et \( W\) de telle sorte que parler des dérivées partielles ait un sens. Toutes les bases vont être notées \( \{ e_i \}\) sans précisions. Sinon, on ne va pas s'en sortir.
	\end{enumerate}
	Nous supposons que
	\begin{enumerate}
		\item
		      \( f\) est de classe \( C^1\) sur un voisinage de \( g(a)\)\footnote{Classe \( C^1\), définition \ref{DefPNjMGqy}.},
		\item
		      \( g\) admet une dérivée partielle dans la direction de \( e_i\) en \( a\).
	\end{enumerate}
	Alors
	\begin{enumerate}
		\item
		      La fonction \( f\circ g\) a une dérivée partielle dans la direction de \( e_i\) en \( a\),
		\item
		      nous avons la formule
		      \begin{equation}        \label{EQooZMAUooIusxgD}
			      \partial_i(f\circ g)(a)=\sum_{k}(\partial_kf)\big( g(a) \big)(\partial_ig_k)(a).
		      \end{equation}
	\end{enumerate}
\end{theorem}

\begin{proof}
	Vu que \( f\) est différentiable en \( g(a)\), nous pouvons y utiliser le lemme \ref{LemdfaSurLesPartielles} et écrire
	\begin{subequations}   \label{EQooFZBVooTwNexc}
		\begin{align}
			df_{g(a)}\left( \frac{ \partial g }{ \partial x_i }(a) \right) & =\Dsdd{ f\big( g(a)+t\frac{ \partial g }{ \partial x_i }(a) \big) }{t}{0}                                                     \\
			                                                               & =\lim_{\epsilon\to 0}\frac{ f\big( g(a)+\epsilon\frac{ \partial g }{ \partial x_i }(a) \big)-f\big( g(a) \big) }{ \epsilon }.
		\end{align}
	\end{subequations}

	Maintenant, le jeu est de travailler \( f\big( g(a)+\epsilon\partial_ig(a) \big)\) de deux façons différentes. D'une part en effectuant un développement de \( f\) autour de \( g(a)\) et d'autre part dé-développant \( g(a)+\epsilon\partial_ig(a)\) pour le changer en \( g(a+\epsilon e_i)\).

	\begin{subproof}
		\spitem[Développer \( f\)]
		En utilisant le lemme \ref{LEMooNMTAooLgMkgH} pour \( f\) autour de \( g(a)\), nous avons
		\begin{subequations}
			\begin{align}
				f\big( g(a)+\epsilon\partial_ig(a) \big) & =f\big( g(a)+\epsilon\sum_k(\partial_ig_k)(a)e_k \big)                                      \\
				                                         & =f\big( g(a) \big)+\epsilon\sum_k(\partial_ig_k)(a)(\partial_kf)\big(g(a)+\epsilon u_k\big)
			\end{align}
		\end{subequations}
		où \( u_k=\sum_{l=k+1}^n(\partial_ig_l)(a)e_l\). La forme exacte de \( u_k\) n'est pas importante pour notre histoire.

		En mettant cela dans la dernière fraction de \eqref{EQooFZBVooTwNexc},
		\begin{subequations}
			\begin{align}
				 & \frac{ f\big( g(a)+\epsilon(\partial_ig)(a) \big)-f\big( g(a) \big) }{ \epsilon }                                                                               \\
				 & =\frac{ f\big( g(a) \big)  +\epsilon\sum_k(\partial_ig_k)(a)(\partial_kf)\big(g(a)+\epsilon u_k\big)+\epsilon\alpha(\epsilon)-f\big( g(a) \big)   }{ \epsilon } \\
				 & =\sum_k(\partial_ig_k)(a)(\partial_kf)\big( g(a)+\epsilon u_k\big)+\alpha(\epsilon).
			\end{align}
		\end{subequations}
		Nous prenons la limite \( \epsilon\to 0\) en tenant compte du fait que \( \lim_{\epsilon\to 0}\alpha(\epsilon)=0\) et du fait que les dérivées partielles de \( f\) sont continues en \( g(a)\) (théorème \ref{THOooBEAOooBdvOdr}). Nous avons
		\begin{equation}
			df_{g(a)}\big( (\partial_ig)(a) \big)=\sum_k(\partial_ig_k)(a)(\partial_kf)\big( g(a) \big).
		\end{equation}
		\spitem[Développer \( g\)]
		Nous développons maintenant \( g\) à l'intérieur de \( f\). Pour cela nous utilisons les accroissements finis \ref{PROPooYYSMooUDxtlB} pour \( g\) :
		\begin{equation}
			g(a)+\epsilon\frac{ \partial f }{ \partial x_i }(a)=g(a+\epsilon e_i)-\epsilon\alpha(\epsilon).
		\end{equation}
		Pour avancer dans \eqref{EQooFZBVooTwNexc}, nous considérons le terme
		\begin{equation}
			f\big( g(a)+\epsilon\frac{ \partial g }{ \partial x_i }(a) \big)=
			f\big( g(a+\epsilon e_i)-\epsilon \alpha(\epsilon) \big)
		\end{equation}
		dans lequel nous allons développer \( f\) autour de \( g(a+\epsilon e_i)\). Vu que la fonction \( \epsilon\mapsto g(a+\epsilon e_i)\) est continue (elle est dérivable par hypothèse), pourvu que \( \epsilon\) soit assez petit, le point \( g(a+\epsilon e_i)\) est encore dans le voisinage de \( g(a)\) sur lequel \( f\) est de classe \( C^1\), de telle sorte qu'un développement de \( f\) ne pose pas de problèmes. Nous pouvons appliquer le lemme \eqref{LEMooNMTAooLgMkgH} :
		\begin{equation}
			f\big( g(a+\epsilon e_i)-\epsilon\alpha(\epsilon) \big)=f\big( g(a+\epsilon e_i) \big)-\sum_k\epsilon\alpha(\epsilon)_k(\partial_kf)\big( g(a+\epsilon e_i)+\epsilon u_k \big)+\epsilon\beta(\epsilon).
		\end{equation}
		Ce que nous avons dans la limite dans \eqref{EQooFZBVooTwNexc} est
		\begin{subequations}
			\begin{align}
				 & \frac{ f\big( g(a+\epsilon e_i)\big)-\sum_k\epsilon\alpha(\epsilon)_k (\partial_kf)\big( g(a+\epsilon e_i)+\epsilon u_k \big)-f\big( g(a) \big) }{ \epsilon } \\
				 & \quad=\frac{ (f\circ g)(a+\epsilon e_i)-(f\circ g)(a) }{ \epsilon }
				-\sum_k\alpha(\epsilon)_k(\partial_kf)\big( f(a+\epsilon e_i)+\epsilon u_k \big).
			\end{align}
		\end{subequations}
		Nous allons passer à la limite. Vu que \( f\) est de classe \( C^1\), ses dérivées partielles sont continue. Le vecteur \( u_k\) ne dépendant pas de \( \epsilon\), toute la partie \( (\partial_kf)\big( g(a+\epsilon e_i)+\epsilon u_k \big)\) peut être majorée uniformément en \( \epsilon\). Et comme \( \alpha(\epsilon)\to 0\), tout le second terme disparait.

		Ce qui reste à la limite est
		\begin{equation}
			df_{g(a)}\left( \frac{ \partial g }{ \partial x_i }(a) \right)=\frac{ \partial (f\circ g) }{ \partial x_i }(a).
		\end{equation}
	\end{subproof}
\end{proof}

\begin{corollary}		\label{CORooNQURooAWjfcA}
	Soient \( a\in \eR\), un voisinage ouvert \( I\) de \( a\), une application \(\gamma \colon I\to \eR^n  \) et une fonction \(f \colon \gamma(I)\to \eR  \). Nous supposons que \( f\) est de classe \( C^1\) sur \( \gamma(I)\) et que \( \gamma\) est dérivable en \( a\).

	Alors
	\begin{enumerate}
		\item
		      La fonction \( f\circ \gamma\) est dérivable en \( a\).
		\item
		      Nous avons la formule
		      \begin{equation}
			      (f\circ \gamma)'(a)=\gamma'(a)\cdot (\nabla f)\big( \gamma(a) \big).
		      \end{equation}
	\end{enumerate}
\end{corollary}

\begin{proof}
	Toutes les hypothèses sont calquées sur celles du théorème \ref{THOooKBTYooWFtoSF}. L'application \( f\circ \gamma\) est donc dérivable en \( a\). Pour les applications sur \( \eR\), la seule dérivée partielle est la dérivée usuelle, donc la formule \eqref{EQooZMAUooIusxgD} s'écrit
	\begin{equation}
		(f\circ \gamma)'(t)=\sum_k(\partial_kf)\big( \gamma(a) \big)\gamma_k'(a)=(\nabla f)\big( \gamma(a) \big)\cdot \gamma'(a).
	\end{equation}
\end{proof}

Donnons un exemple d'utilisation de cette formule. Si
\begin{equation}
	\begin{aligned}[]
		g\colon \eR^2\to \eR^3 \\
		f\colon \eR^3\to \eR,
	\end{aligned}
\end{equation}
nous avons \( \varphi\colon \eR^2\to \eR\). Les dérivées partielles de \( \varphi\) sont données par les formules
\begin{equation}
	\frac{ \partial \varphi }{ \partial x }(x,y)=
	\frac{ \partial f }{ \partial x_1 }\big( g(x,y) \big)\frac{ \partial g_1 }{ \partial x }(x,y)
	+\frac{ \partial f }{ \partial x_2 }\big( g(x,y) \big)\frac{ \partial g_2 }{ \partial x }(x,y)
	+\frac{ \partial f }{ \partial x_3 }\big( g(x,y) \big)\frac{ \partial g_3 }{ \partial x }(x,y)
\end{equation}
et
\begin{equation}
	\frac{ \partial \varphi }{ \partial y }(x,y)=\frac{ \partial f }{ \partial x_1 }\big( g(x,y) \big)\frac{ \partial g_1 }{ \partial y }(x,y)+\frac{ \partial f }{ \partial x_2 }\big( g(x,y) \big)\frac{ \partial g_2 }{ \partial y }(x,y)+\frac{ \partial f }{ \partial x_3 }\big( g(x,y) \big)\frac{ \partial g_3 }{ \partial y }(x,y)
\end{equation}
Notez que les dérivées de \( \varphi\) et des composantes de \( g\) sont calculées en \( (x,y)\), tandis que celles de \( f\) sont calculées en \( g(x,y)\).

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Différentielle et dérivée complexe}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\label{SECooJWNOooOgMiWR}

\begin{normaltext}
	Nous commençons par donner quelques éléments à propos de dérivée et de différentielle pour des fonctions \( \eC\to \eC\) parce que les séries entières vont souvent être des fonctions complexes. Le gros du chapitre sur les fonctions holomorphes est le chapitre~\ref{ChapICHIooXbLccl}.
\end{normaltext}

Nous identifions \( \eR^2\) à \( \eC\) par l'application
\begin{equation}
	\begin{aligned}
		\varphi\colon \eR^2 & \to \eC       \\
		(x,y)               & \mapsto x+iy.
	\end{aligned}
\end{equation}
Dans cette partie, nous désignons par \( \Omega\) un ouvert de \( \eC\).

\begin{definition}      \label{DEFooVJVXooKlnFkh}
	Une fonction \( f\colon \Omega\to \eC\) est \defe{\( \eC\)-dérivable}{dérivable!au sens complexe} si la limite
	\begin{equation}
		\lim_{\substack{h\to0\\h\in \eC}} \frac{ f(a+h)-f(a) }{ h }
	\end{equation}
	existe. Dans ce cas, cette limite est la dérivée de \( f\) et est notée \( f'\).
\end{definition}

\begin{definition}  \label{DefMMpjJZ}
	Soit \( \Omega\) un ouvert dans \( \eC\). Une fonction \( f\colon \Omega\to \eC\) est \defe{holomorphe}{holomorphe}\index{fonction!holomorphe} si elle est \( \eC\)-dérivable sur \( \Omega\).
\end{definition}

Une avalanche de conditions équivalentes à l'holomorphie est donnée dans le théorème \ref{THOooOGOCooUalFaG}.

\begin{definition}      \label{DEFooQSMCooOoWVZk}
	Si \( K\) est un compact de \( \eC\), nous disons qu'une fonction est \defe{holomorphe}{holomorphe!sur un compact} sur \( K\) si il existe un ouvert contenant \( K\) sur lequel \( f\) est holomorphe.

	Et si \( f\) n'est réellement définie que sur \( K\), elle est holomorphe sur \( K\) si il existe une extension holomorphe de \( f\) vers un ouvert contenant \( K\).
\end{definition}

\begin{definition}[Similitude] \label{DEFooSRKYooLkGVUe}
	Une matrice de la forme
	\begin{equation}
		\begin{pmatrix}
			\alpha & \beta  \\
			-\beta & \alpha
		\end{pmatrix}
	\end{equation}
	avec \( \alpha,\beta\in \eR\) est une \defe{similitude}{matrice!de similitude}\index{similitude}.
\end{definition}

\begin{lemma}       \label{LEMooJNFEooZCbJMo}
	En tant qu'application linéaire \( \eC\to \eC\), l'opération de multiplication par \( \alpha+\beta i\) est la matrice
	\begin{equation}
		\begin{pmatrix}
			\alpha & -\beta \\
			\beta  & \alpha
		\end{pmatrix}.
	\end{equation}
\end{lemma}

\begin{proof}
	Cela est vite remarqué en calculant explicitement \( (\alpha+\beta i)(u_1+iu_2)\).
\end{proof}

\begin{lemma}       \label{LEMooKIOZooEUxfsB}
	Une application \( A\colon \eC\to \eC\) est \( \eC\)-linéaire si et seulement si elle est une similitude en tant qu'application \( \eR^2\to \eR^2\).

	Dans ce cas, il existe \( z_0\in \eC\) tel que \( A(z)=z_0z\) pour tout \( z\in \eC\).
\end{lemma}

\begin{proof}
	Commençons par considérer l'application \( A\) sur \( \eR^2\). Elle est en particulier une application \( \eR\)-linéaire et par conséquent il existe une matrice \( \begin{pmatrix}
		\alpha & \beta  \\
		\gamma & \delta
	\end{pmatrix}\) telle que
	\begin{equation}
		A\begin{pmatrix}
			x \\
			y
		\end{pmatrix}=\begin{pmatrix}
			\alpha & \beta  \\
			\gamma & \delta
		\end{pmatrix}\begin{pmatrix}
			x \\
			y
		\end{pmatrix}.
	\end{equation}
	Nous voulons maintenant imposer la \( \eC\)-linéarité, c'est-à-dire que nous voulons
	\begin{equation}
		A\big( (a+bi)(x+iy) \big)=(a+bi)A(x+iy)
	\end{equation}
	pour tout \( a,b,x,y\in \eR\). À gauche nous avons
	\begin{equation}
		A\big( ax-by+i(bx+ay) \big)
	\end{equation}
	et à droite nous avons
	\begin{equation}
		(a+bi)\big( \alpha x+\beta y+i(\gamma x+\delta y) \big).
	\end{equation}
	En égalant les deux expressions nous obtenons les équations
	\begin{subequations}
		\begin{numcases}{}
			\beta b=-b\gamma\\
			-\alpha b+\beta a =a\beta -b\delta\\
			\delta b=b\alpha\\
			-\gamma b+\delta a=b\beta+a\delta,
		\end{numcases}
	\end{subequations}
	dont nous tirons immédiatement que \( \gamma=-\beta\) et \( \delta=\alpha\). La matrice de \( A\) est donc de la forme demandée.

	Inversement nous devons prouver que la fonction
	\begin{equation}        \label{EqOEWYooMaHCNb}
		f(x+iy)=\alpha x+\beta y+i(-\beta x+\alpha y)
	\end{equation}
	est \( \eC\)-linéaire, c'est-à-dire qu'elle vérifie \( f(z_0z)=z_0f(z)\) pour tout \( z_0,z\in \eC\). Cela est un simple calcul que nous confions à Sage : le code suivant affiche «\( 0\)».
	\lstinputlisting{tex/frido/code_sage3.py}

	Pour conclure, notons que la fonction \eqref{EqOEWYooMaHCNb} est la fonction de multiplication par \( \alpha-i\beta\).
\end{proof}

\begin{normaltext}      \label{NORMooMKNDooBeoGRN}
	Soient une fonction \( f\colon \eC\to \eC\) et l'isomorphisme canonique \( \varphi\colon \eC\to \eR^2\). La fonction \( f\) définit la fonction
	\begin{equation}
		F=\varphi \circ f\circ \varphi^{-1}\colon \eR^2\to \eR^2.
	\end{equation}
	Cela est la fonction \( \eR^2\to \eR^2\) associée à \( f\). Il serait tentant de croire que tout ce qui est vrai pour \( F\) est également vrai pour \( f\). Eh bien non.

	Par exemple, \( F\) peut être différentiable sans que \( f\) le soit. La proposition suivante donne une condition sur \( dF\) pour que \( f\) soit différentiable.
\end{normaltext}

La proposition suivante donne le lien entre \( df\) et la dérivée complexe \( f'\). Pour avoir le lien avec \( \partial_zf\), il faudra voir la proposition \ref{PROPooCHUEooYsGcQK}.
\begin{proposition}     \label{PropKJUDooJfqgYS}
	Une fonction \( f\colon \Omega\to \eC\) est \( \eC\)-dérivable en \( a\in\Omega\) si et seulement si elle est différentiable en \( a\) et si \( df_a\) est une similitude.

	Plus précisément avec les notations de~\ref{NORMooMKNDooBeoGRN}, la fonction \( f\) est \( \eC\)-dérivable (donc holomorphe) au point \( z_0=x_0+iy_0\) si et seulement si la fonction \( F\) est différentiable en \( (x_0,y_0)\) et si la matrice de \( dF\) est de la forme
	\begin{equation}        \label{EQooWZGKooLDEHGr}
		dF=\begin{pmatrix}
			\alpha & \beta  \\
			-\beta & \alpha
		\end{pmatrix},
	\end{equation}
	c'est-à-dire si \( dF_{(x_0,y_0)}\) fournit une application \( \eC\)-linéaire.

	Dans ce cas, le lien entre \( \eC\)-dérivée et différentielle est donné par
	\begin{equation}        \label{EqPAEFooYNhYpz}
		(df_{z_0})(z)=f'(z_0)z.
	\end{equation}
\end{proposition}

\begin{proof}
	Nous décomposons \( f\) en parties réelles et imaginaires :
	\begin{equation}
		f(x+iy)=P(x,y)+iQ(x,y)
	\end{equation}
	où \( P\) et \( Q\) sont des fonctions réelles. La jacobienne de \( F\) est la matrice
	\begin{equation}
		\begin{pmatrix}
			\frac{ \partial P }{ \partial x } & \frac{ \partial P }{ \partial y } \\
			\frac{ \partial Q }{ \partial x } & \frac{ \partial Q }{ \partial y }
		\end{pmatrix},
	\end{equation}
	et la condition dont nous parlons s'écrit comme le système
	\begin{subequations}    \label{EqFDUrXBP}
		\begin{numcases}{}
			\frac{ \partial P }{ \partial x }=\frac{ \partial Q }{ \partial y }\\
			\frac{ \partial P }{ \partial y }=-\frac{ \partial Q }{ \partial x}.
		\end{numcases}
	\end{subequations}
	Si \( F\) est différentiable en \( (x_0,y_0)\) alors nous avons
	\begin{equation}        \label{EqwlVfiR}
		F\big( (x_0,y_0)+(h,k) \big)=F(x_0,y_0)+dF_{(x_0,y_0)}\begin{pmatrix}
			h \\
			k
		\end{pmatrix}+s(| h |+| k |)
	\end{equation}
	où \( s\) est une fonction vérifiant \( \lim_{t\to 0} \frac{ s(t) }{ t }=0\). Soit
	\begin{equation}
		dF_{(x_0,y_0)}=\begin{pmatrix}
			\alpha & \beta  \\
			-\beta & \alpha
		\end{pmatrix}.
	\end{equation}
	Si nous posons \( \sigma=\alpha-i\beta\) et \( w=h+ik\), l'équation \eqref{EqwlVfiR} s'écrit dans \( \eC\) sous la forme
	\begin{equation}        \label{EqYFmoiM}
		f(z_0+w)=f(z_0)+\sigma w+s(|w|),
	\end{equation}
	ce qui implique que \( f\) est \( \eC\)-dérivable en \( z_0\).

	Supposons maintenant que \( f\) soit \( \eC\)-dérivable en \( z_0\). Alors nous avons
	\begin{equation}
		f'(z_0)=\lim_{w\to 0} \frac{ f(z_0+w)-f(z_0) }{ w }=\sigma\in \eC,
	\end{equation}
	ce qui se récrit sous la forme
	\begin{equation}
		\lim_{w\to 0} \frac{ f(z_0+w)-f(z_0)-\sigma w }{ w }=0.
	\end{equation}
	Si nous posons \( z_0=x_0+iy_0\), \( w=h+ik\) et \( \sigma=\alpha-i\beta\) nous avons
	\begin{equation}
		\lim_{(h,k)\to (0,0)} \left| \frac{ F\big( (x_0,y_0)+(h,k) \big)-F(x_0,y_0)-\begin{pmatrix}
				\alpha & \beta  \\
				-\beta & \alpha
			\end{pmatrix}\begin{pmatrix}
				h \\
				k
			\end{pmatrix}}{ | w | } \right| =0,
	\end{equation}
	ce qui signifie que \( F\) est différentiable et que sa différentielle est la matrice
	\begin{equation}    \label{EqMLtbLD}
		\begin{pmatrix}
			\alpha & \beta  \\
			-\beta & \alpha
		\end{pmatrix}.
	\end{equation}

	La matrice \eqref{EqMLtbLD} est, vue dans \( \eR^2\), la matrice de multiplication dans \( \eC\) par \( \alpha-i\beta=f'(z_0)\). En d'autre termes, dans \( \eC\) nous avons
	\begin{equation}
		df_{z_0}(z)=f'(z_0)z,
	\end{equation}
	et en particulier la différentielle est donnée par
	\begin{equation}        \label{EqPropZOkfmO}
		df_{z_0}=f'(z_0)dz.
	\end{equation}
\end{proof}

\begin{example}[Une application \( C^{\infty}\) mais pas \( \eC\)-dérivable]
	Nous considérons la fonction
	\begin{equation}
		\begin{aligned}
			f\colon \eC & \to \eC    \\
			x+iy        & \mapsto x.
		\end{aligned}
	\end{equation}
	Vu que c'est une application linéaire, elle est différentiable une infinité de fois et sa différentielle est elle-même. C'est donc une application \( C^{\infty}\).

	Elle n'est cependant pas \( \eC\)-dérivable. En effet le quotient différentiel est, pour \( \epsilon\in \eC\) :
	\begin{equation}
		\frac{ f(x+iy+\epsilon_x+i\epsilon_y)-f(x+iy) }{ \epsilon }=\frac{ \epsilon_x }{ \epsilon }.
	\end{equation}
	Cela n'a pas de limite lorsque \( \epsilon\to 0\). Pour voir cela nous invoquons la méthode des chemins du corolaire~\ref{CorMethodeChemin} avec les chemins \( \epsilon_1(t)=t\) et \( \epsilon_2(t)=it\). Dans le premier cas, le quotient différentiel vaut \( 1\) pour tout \( t\), tandis que dans le second il vaut zéro pour tout \( t\).
\end{example}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Quelques règles de calcul}
%---------------------------------------------------------------------------------------------------------------------------

\begin{lemma}       \label{LEMooVDXOooUyFHXZ}
	Si \( f\) et \( g\) sont deux fonctions holomorphes sur un ouvert \( \Omega\subset \eC\) et si \( g\) ne s'annule pas sur \( \Omega\), alors \( f/g\) est holomorphe sur \( \Omega\).
\end{lemma}


%++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Théorèmes des accroissements finis}		\label{SecThoAccrsFinis}
%++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Nous avons déjà démontré (lemme~\ref{LemdfaSurLesPartielles}) que si \( f\) est différentiable au point \( x\) alors  \( df_x(u)=\partial_uf(x)\). Une importante conséquence est le théorème des accroissements finis
\begin{theorem}[Accroissements finis, inégalité de la moyenne]\label{val_medio_2}
	Soit \( U\) un ouvert dans \( \eR^m\) et soit \( f:U\to\eR^n\) une fonction différentiable. Soient \( a\) et \( b\) deux points dans \( U\), \( a\neq b\), tels que le segment \( [a,b]\) soit contenu dans \( U\). Alors
	\begin{equation}
		\|f(b)-f(a)\|_n\leq \sup_{x\in[a,b]}\|df_x\|_{\aL(\eR^m,\eR^n)}\|b-a\|_m.
	\end{equation}
\end{theorem}
\index{application!différentiable}
\index{inégalité!de la moyenne}
\index{théorème!accroissements finis!forme générale}

\begin{proof}
	On utilise le théorème~\ref{val_medio_1} et le fait que
	\[
		\|\partial_u f(x)\|_n\leq \|df_x\|_{\aL(\eR^m,\eR^n)}\|u\|_m,
	\]
	pour tout \( u\) dans \( \eR^m\).
\end{proof}

La proposition suivante est une application fondamentale du théorème des accroissements finis~\ref{val_medio_2}.
\begin{proposition}		\label{PropAnnulationEtConstance}
	Soit \( U\) un ouvert connexe par arcs de \( \eR^m\) et une fonction \( f\colon U\to \eR^n\). Les conditions suivantes sont équivalentes :
	\begin{enumerate}
		\item\label{ItemPropCstDiffZeroi}
		\( f\) est constante;
		\item\label{ItemPropCstDiffZeroii}
		\( f\) est différentiable et \( df(a)=0\) pour tout \( a\in U\);
		\item\label{ItemPropCstDiffZeroiii}
		les dérivées partielles \( \partial_1f,\ldots,\partial_mf\) existent et sont nulles sur \( U\).
	\end{enumerate}
\end{proposition}
\index{connexité!par arc!fonction différentiable}
\index{différentiabilité}

\begin{proof}
	Nous allons démonter les équivalences en plusieurs étapes. D'abord~\ref{ItemPropCstDiffZeroi} \( \Rightarrow\)~\ref{ItemPropCstDiffZeroii}, puis~\ref{ItemPropCstDiffZeroii} \( \Rightarrow\)~\ref{ItemPropCstDiffZeroiii}, ensuite~\ref{ItemPropCstDiffZeroiii} \( \Rightarrow\)~\ref{ItemPropCstDiffZeroii} et enfin~\ref{ItemPropCstDiffZeroii} \( \Rightarrow\)~\ref{ItemPropCstDiffZeroi}.

	Commençons par montrer que la condition~\ref{ItemPropCstDiffZeroi} implique la condition~\ref{ItemPropCstDiffZeroii}. Si \( f(x)\) est constante, alors la condition \eqref{EqCritereDefDiff} est vite vérifiée en posant \( T(h)=0\).

	Afin de voir que la condition~\ref{ItemPropCstDiffZeroii} implique la condition~\ref{ItemPropCstDiffZeroiii}, remarquons d'abord que la différentiabilité de \( f\) implique que les dérivées partielles existent (proposition~\ref{diff1}) et que nous avons l'égalité \( df(a).u=\sum_iu_i\partial_if(a)\) pour tout \( u\in\eR^m\) (lemme~\ref{LemdfaSurLesPartielles}). L'annulation de \( \sum_iu_i\partial_if(a)\) pour tout \( u\) implique l'annulation des \( \partial_if(a)\) pour tout \( i\).

	Prouvons maintenant que la propriété~\ref{ItemPropCstDiffZeroiii} implique la propriété~\ref{ItemPropCstDiffZeroii}. D'abord, par le théorème \ref{THOooBEAOooBdvOdr}, l'existence et la continuité des dérivées partielles \( \partial_if(a)\) implique la différentiabilité de \( f\). Ensuite, la formule \( df(a).u=\sum_i u_i\partial_if(a)\) implique que \( df(a)=0\).


	Il reste à montrer que~\ref{ItemPropCstDiffZeroii} implique la condition~\ref{ItemPropCstDiffZeroi}, c'est-à-dire que l'annulation de la différentielle implique la constance de la fonction. C'est ici que nous allons utiliser le théorème des accroissements finis. En effet, si \( a\) et \( b\) sont des points de \( U\), le théorème~\ref{val_medio_2} nous dit que
	\begin{equation}
		\|f(b)-f(a)\|_n\leq \sup_{x\in[a,b]}\|df(x)\|_{\aL(\eR^m,\eR^n)}\|b-a\|_m.
	\end{equation}
	Mais \( \| df(x) \|=0\) pour tout \( x\in U\), donc ce supremum est nul et \( f(b)=f(a)\), ce qui signifie la constance de la fonction.
\end{proof}

%\begin{proof}
%  \begin{itemize}
%  \item Le théorème~\ref{val_medio_2} nous dit que si la différentielle de \( f\) est nulle alors \( f\) est constante sur chaque segment contenu dans \( U\). Cela nous dit que \( f\) est constante sur chaque boule contenue dans \( U\), donc \( f \) est localement constante. Il est possible de démontrer que toute fonction localement constante sur un connexe est constante.
%\item Si toutes les dérivées partielles \( \partial_1 f, \ldots, \partial_m f \) existents et sont identiquement nulles sur \( U\) alors \( f\) est différentiable et sa différentielle est identiquement nulle. On utilise la première partie de la preuve pour conclure.
%  \end{itemize}
%\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Fonctions lipschitziennes}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


\begin{definition}      \label{DEFooQHVEooDbYKmz}
	Soient \( (E,d_E)\) et \( (F,d_F)\) deux espaces métriques\footnote{Pour rappel, les espaces métriques sont définis par la définition~\ref{DefMVNVFsX} et le théorème~\ref{ThoORdLYUu}; je précise que nous ne supposons pas que \( E\) soit vectoriel; en particulier il peut être un ouvert de \( \eR^n\).}, \( f\colon E\to F\) une application et un réel \( k\) strictement positif. Nous disons que \( f\) est \defe{lipschitzienne}{lipschitzienne} de constante \( k\) sur \( E\) si pour tout \( x,y\in E\),
	\begin{equation}
		d_F\big( f(x),f(y) \big)\leq kd_E(x,y).
	\end{equation}
\end{definition}

Soit \( f\) une fonction \( k\)-lipschitzienne. Si \( y\in \overline{ B(x,\delta)}\) alors \( \| x-y \|\leq\delta\) et donc \( \big\| f(x)-f(y) \big\|\leq k\delta\). Cela signifie que la condition de Lipschitz peut s'énoncer en termes de boules fermées par
\begin{equation}    \label{EqDZvtUbn}
	f\big( \overline{ B(x,\delta) } \big)\subset \overline{  B\big( f(x),k\delta \big) }
\end{equation}
tant que \( \overline{ B(x,\delta) } \) est contenue dans le domaine sur lequel \( f\) est lipschitzienne.

\begin{proposition}
	Soit  \( U\) un ouvert convexe  de \( \eR^m\), et soit \( f:U\to \eR^n\) une fonction différentiable. La fonction \( f\) est lipschitzienne sur \( U\) si et seulement si \( df\) est bornée sur \( U\).
\end{proposition}
\begin{proof}
	Le fait que l'application différentielle \( df\) soit bornée signifie qu'il existe un \( M>0\) dans \( \eR\) tel que \( \|df_a\|_{\aL(\eR^m,\eR^n)}\leq M\), pour tout \( a\) dans \( U\). Si cela est le cas, alors le théorème~\ref{val_medio_2} et la convexité\footnote{La convexité de \( U\) sert à assurer que la droite reliant \( a\) à \( b\) est contenue dans \( U\); c'est ce que nous utilisons dans la démonstration du théorème~\ref{val_medio_2}.} de \( U\) impliquent évidemment que \( f\) est de Lipschitz de constante plus petite ou égale à \( M\).

	Inversement, si \( f\) est lipschitzienne de constante \( k\), alors pour tout \( a\) dans \( U\) et \( u\) dans \( \eR^m\) on a
	\[
		\left\|\frac{f(a+tu)-f(a)}{t}\right\|_n\leq k \|u\|_m,
	\]
	En passant à la limite pour \( t\to 0\) on a
	\[
		\|\partial_u f(a)\|_n=\|df_a(u)\|_n\leq k \|u\|_m,
	\]
	donc la norme de \( df_a\) est majorée par \( k\) pour tout \( a\) dans \( U\).
\end{proof}

Notez cependant qu'une fonction peut être lipschitzienne sans être différentiable.

\begin{proposition} \label{PropFZgFTEW}
	Une fonction lipschitzienne \( f\colon \eR\to \eR\) est continue.
\end{proposition}

\begin{proof}
	Nous utilisons la caractérisation de la continuité donnée par le théorème~\ref{ThoESCaraB}. Prouvons donc la continuité en \( a\in \eR\). Pour tout \( x\) nous avons
	\begin{equation}
		\big| f(x)-f(a) \big|\leq k| x-a |.
	\end{equation}
	Si \( \epsilon>0\) est donné, il suffit de prendre \( \delta<\frac{ \epsilon }{ k }\) pour avoir
	\begin{equation}
		\big| f(x)-f(a) \big|\leq k\frac{ \epsilon }{ k }=\epsilon.
	\end{equation}
	Donc \( f\) est continue en \( a\).
\end{proof}

\begin{definition}      \label{DefJSFFooEOCogV}
	Une fonction
	\begin{equation}
		\begin{aligned}
			f\colon \eR^n\times \eR^m & \to \eR^p      \\
			(t,y)                     & \mapsto f(t,y)
		\end{aligned}
	\end{equation}
	est \defe{localement lipschitzienne}{lipschitzienne!localement} en \( y\) au point \( (t_0,y_0)\) si il existe des voisinages \( V\) de \( t_0\) et \( W\) de \( y_0\) et un nombre \( k>0\) tels que pour tout \( (t,y)\in V\times W\) on ait
	\begin{equation}
		\big\| f(t_0,y_0)-f(t,y) \big\|\leq k\| y-y_0 \|.
	\end{equation}
	La fonction est localement lipschitzienne sur un ouvert \( U\) de \( \eR^n\times \eR^m\) si elle est localement lipschitzienne en chaque point de \( U\).
\end{definition}

\begin{normaltext}      \label{NORMooYNRAooBgobcK}
	Autrement dit, une fonction est localement lipschitzienne en sa deuxième variable lorsque tout point admet un voisinage sur lequel elle est lipschitzienne.
\end{normaltext}

\begin{proposition} \label{PROPooVZSAooUneOQK}
	Toute application lipschitzienne\footnote{Définition~\ref{DEFooQHVEooDbYKmz}.} est uniformément continue\footnote{Définition \ref{DEFooYIPXooQTscbG}.}.
\end{proposition}

\begin{proof}
	Soit une application \( k\)-lipschitzienne \( f\colon E\to F\) entre deux espaces métriques. Soient \( \epsilon>0\) ainsi que \( a\in E\). Nous considérons \( \delta=\epsilon/k\). Si \( x\in B(a,\delta)\) nous avons
	\begin{equation}
		d_F\big( f(a),f(x) \big)\leq kd_E(a,x)\leq k\delta\leq \epsilon.
	\end{equation}
\end{proof}

\begin{proposition}     \label{PropGIBZooVsIqfY}
	Si \( f\) et \( g\) sont deux fonctions localement lipschitziennes alors \( f+g\) l'est.
\end{proposition}

\begin{proof}
	Il s'agit d'un simple calcul avec une majoration standard :
	\begin{subequations}
		\begin{align}
			\| (f+g)(t_0,y_0)-(f+g)(t,y) \| & \leq \|  f(t_0,y_0)-f(t,y)  \|+\| g(t_0,y_0)-g(t,y) \| \\
			                                & \leq k_f\| y-y_0 \|+k_g\| y-y_0 \|                     \\
			                                & =(k_f+k_g)\| y-y_0 \|.
		\end{align}
	\end{subequations}
\end{proof}

\begin{lemma}   \label{LemCFZUooVqZmpc}
	La fonction donnée par
	\begin{equation}
		f(t, (x,y) )=xy
	\end{equation}
	est localement lipschitzienne en tout point.
\end{lemma}

\begin{proof}
	Nous avons la majoration classique
	\begin{equation}
		| f\big(t,(x_0,y_0)\big)-f\big( t,(x,y) \big) |=| x_0y_0-xy |\leq| x_0y_0-x_0y |+| x_0y-xy |\leq | x_0 || y_0-y |+| y || x_0-x |.
	\end{equation}
	Vu que nous parlons de fonction \emph{localement lipschitzienne}, nous pouvons majorer \( | y |\) et \( | x_0 |\) par un même nombre \( k\) dans un voisinage de \( (x_0,y_0)\). Cela donne
	\begin{equation}
		| f\big(t,(x_0,y_0)\big)-f\big( t,(x,y) \big) |\leq k\big( | y_0-y |+| x_0-x | \big)\leq \sqrt{2}k\| \begin{pmatrix}
			x_0-x \\
			y_0-y
		\end{pmatrix}\|.
	\end{equation}
	Nous avons utilisé l'équivalence de norme de la proposition~\ref{PropLJEJooMOWPNi}\ref{ItemABSGooQODmLNi}.
\end{proof}

%++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Différentielles d'ordre supérieur}		\label{SecDiffOrdSup}
%++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Différentielle et dérivées partielles}
%---------------------------------------------------------------------------------------------------------------------------

La définition des applications de classe \( C^k\) est \ref{DefPNjMGqy}. C'est également le moment de relire la définition \ref{DEFooJYOPooBzditG} des espaces emboîtés.

\begin{definition}
	Une sorte de projection. Pour \( u\in V\) nous définissons
	\begin{equation}
		\begin{aligned}
			\pr_u\colon \aL^n(V,E)             & \to \aL^{n-1}(V,E)              \\
			\pr_u(\omega)(v_1,\ldots, v_{n-1}) & =\omega(u,v_1,\ldots, v_{n-1}).
		\end{aligned}
	\end{equation}
\end{definition}

\begin{lemma}[\cite{MonCerveau,BIBooLWVSooOZSJBR}]      \label{LEMooSMZQooJBVySP}
	À propos de dimensions\footnote{\( E_n\), définition \ref{DEFooJYOPooBzditG}.},
	\begin{enumerate}
		\item       \label{ITEMooUWEBooSzFseN}
		      \( \dim(E_n)=\dim(V)^n\dim(E)\).
		\item       \label{ITEMooFMKQooFSMpgF}
		      \( \dim\big( \aL^n(V,E) \big)=\dim(E)\dim(V)^n\).
	\end{enumerate}
\end{lemma}

\begin{lemma}[\cite{MonCerveau}]        \label{LEMooTDLNooTcPkLg}
	Nous définissons les \( \phi_k\) par récurrence. D'abord
	\begin{equation}
		\begin{aligned}
			\phi_1\colon \aL^n(V,E) & \to \aL\big( V,\aL^{n-1}(V,E) \big) \\
			\phi_1(\omega)u         & =\pr_u(\omega),
		\end{aligned}
	\end{equation}
	et ensuite
	\begin{equation}
		\begin{aligned}
			\phi_k\colon \aL^n(V,E) & \to \aL^{n-k}(V,E)_{k}                \\
			\phi_k(\omega)u         & =\phi_{k-1}\big( \pr_u(\omega) \big).
		\end{aligned}
	\end{equation}
	Les applications \( \phi_k\) sont bijectives.
\end{lemma}

\begin{proof}
	Nous prouvons par récurrence.
	\begin{subproof}
		\spitem[Injective, \( k=1\)]
		Soit \( \omega\in \aL^n(V,E)\) tel que \( \phi_1(\omega)=0\). Pour tout \( u\in V\) nous avons \( \phi_1(\omega)u=0\), ce qui signifie que \( \pr_u(\omega)=0\) ou encore que pour tout \( v_1,\ldots, v_{n-1}\in V\) nous avons \( \omega(u,v_1,\ldots, v_{n-1})=0\). Nous avons donc bien \( \omega=0\).
		\spitem[Surjective, \( k=1\)]
		Soit \( \alpha\in\aL\big( V,\aL^{n-1}(V,E) \big)\). Nous allons construire \( \omega\in \aL^n(V,E)\) tel que \( \phi_1(\omega)=\alpha\). Nous posons
		\begin{equation}
			\omega(v_0,\ldots, v_{n-1})=\alpha(v_0)(v_1,\ldots, v_{n-1}).
		\end{equation}
		Avec lui nous avons bien \( \pr_{v_0}(\omega)=\alpha(v_0)\).
		\spitem[Injective, \( k=k\)]
		Nous supposons que \( \phi_k(\omega)=0\), c'est-à-dire que pour tout \( u\in V\) nous avons
		\begin{equation}
			\phi_{k-1}\big( \pr_u(\omega) \big)=0.
		\end{equation}
		Cela implique \( \pr_u(\omega)=0\) parce que \( \phi_{k-1}\) est injective par hypothèse de récurrence. Nous déduisons que \( \omega=0\), et que \( \phi_k\) est injective.

		\spitem[Surjective, \( k=k\)]
		Nous allons montrer que \(   \phi_k\colon \aL^n(V,E)\to \aL^{n-k}(V,E)_k  \) est une application linéaire injective entre deux espaces de même dimension.

		Il s'agit d'utiliser le lemme \ref{LEMooSMZQooJBVySP}. D'abord
		\begin{equation}
			\dim\big( \aL^{n-k}(V,E)_k \big)=\dim(V)^k\dim\big( \aL^{n-k}(V,E) \big)=\dim(V)^n\dim(E).
		\end{equation}
		Ensuite \( \dim\big( \aL^n(V,E) \big)=\dim(V)^n\dim(E)\). Le compte est bon.

		Le théorème du rang (formule \eqref{EQooUEOQooLySRiE}) avec \( \dim\big( \ker(\phi_k) \big)=0\) nous dit que le rang de \( \phi_k\) est maximal et donc que \( \phi_k\) est surjective.
	\end{subproof}
\end{proof}

\begin{lemma}       \label{LEMooLTYCooAoMJKD}
	Soit \( w\in W\). Nous avons
	\begin{equation}
		\big[ w\times_k\phi_k(\omega_I) \big]\times_1\omega_l=w\times_{k+1}\phi_{k+1}(\omega_{l,I}).
	\end{equation}
\end{lemma}

\begin{proof}
	Il s'agit d'appliquer les deux membres à un élément \( v\in V\). D'abord
	\begin{subequations}
		\begin{align}
			\big[ w\times_k\phi_k(\omega_I) \big]\times_1\omega_l(v) & =\omega_l(v)w\times_k\phi_k(\omega_I)                                      \\
			                                                         & =w\times_k\big( \phi_k(\omega_I)v_l \big)      \label{SUBEQooMWPMooYAsYCB}
		\end{align}
	\end{subequations}
	Pour \eqref{SUBEQooMWPMooYAsYCB} nous avons utilisé le fait que \( \omega_{l,I}(v)=v_l\in\eR\) et que le produit \( \times_k\) est linéaire. De l'autre côté, en utilisant les définitions de \( \times_{k}\) et de \( \phi_k\), nous avons
	\begin{subequations}
		\begin{align}
			\big[ w\times_{k+1}\phi_{k+1}(\omega_{l,I}) \big]v & =w\times_k\big( \phi_{k+1}(\omega_{l,I})v \big) \\
			                                                   & =w\times_k\phi_k\big( \pr_v(\omega_{l,I}) \big) \\
			                                                   & =w\times_k\phi_k(v_l\omega_I)
		\end{align}
	\end{subequations}
	parce que \( \pr_v(\omega_{l,I})=v_l\omega_I\).
\end{proof}

\begin{proposition}[\cite{MonCerveau}]      \label{PROPooVGRRooHSwcPl}
	Soit une application \( f\colon V\to E\) de classe \( C^n\). Alors
	\begin{enumerate}
		\item
		      pour tout \( n\)-multiindice \( I\), la dérivée partielle \( \partial^n_If\) existe,
		\item
		      nous avons la formule
		      \begin{equation}
			      (d^nf)_a=\sum_{i_1,\ldots, i_n}\frac{ \partial^nf }{ \partial x_{i_1}\ldots \partial x_{i_n} }(a)\times_n\phi_n(\omega_{i_1,\ldots, i_n})
		      \end{equation}
		      où la somme porte sur tous les multiindices de taille \( n\), le produit \( \times_n\) est la définition \ref{DEFooLULCooYjBEaZ} et l'application \( \phi_n\) est donnée dans l'énoncé du lemme \ref{LEMooTDLNooTcPkLg}.
	\end{enumerate}
\end{proposition}

\begin{proof}
	Nous faisons tout cela par récurrence. Le cas \( n=1\) est déjà fait par le théorème \ref{THOooBEAOooBdvOdr} parce que \( \phi_1(\omega)=\omega\). Nous supposons que le résultat est démontré pour une valeur \( k\), et nous considérons \( f\) de classe \( C^n\) avec \( n\geq k+1\). L'hypothèse de récurrence dit que
	\begin{equation}        \label{EQooBOZUooCiEIYR}
		(d^kf)_a=\sum_{I}(\partial_{I}f)(a)\times_k\phi_k(\omega_{I})
	\end{equation}
	est continuement différentiable par rapport à \( a\). Nous pouvons donc utiliser la formule \eqref{EQooPREWooVHVIAF} pour calculer la différentielle de \eqref{EQooBOZUooCiEIYR} :
	\begin{subequations}
		\begin{align}
			(d^{k+1}f)_a & =\sum_l\frac{ \partial (d^kf) }{ \partial x_l }(a)\times_1\omega_l                                     \\
			             & =\sum_l\sum_{I}\big[ (\partial_l\partial_{I}f)(a)\times_k\phi_k(\omega_{I}) \big]\times_1\omega_l      \\
			             & =\sum_{l,I}(\partial_{l,I}f)(a)\times_{k+1}\phi_{k+1}(\omega_{l,I})        \label{SUBEQooOXUHooFDJiow}
		\end{align}
	\end{subequations}
	où nous avons utilisé le lemme \ref{LEMooLTYCooAoMJKD} pour obtenir \eqref{SUBEQooOXUHooFDJiow}.
\end{proof}

\begin{proposition}     \label{PROPooKOBVooQhrAeJ}
	Soit une application \( f\colon V\to E\) telle que les dérivées partielles \( \frac{ \partial f }{ \partial x_{i_1}\ldots \partial x_{i_n} }\) existent et sont continues sur un ouvert \( \mU\). Alors \( f\) est de classe \( C^n\) sur \( \mU\).
\end{proposition}

\begin{proof}
	Pour \( n=1\), cette proposition est déjà contenue dans le théorème \ref{THOooBEAOooBdvOdr}. Nous pouvons donc directement passer au pas de récurrence. Nous définissons les objets
	\begin{equation}
		T_k(a)=\sum_I(\partial_If)(a)\times_k\phi_k(\omega_{I})
	\end{equation}
	où la somme porte sur tous les \( k\)-multiindices. Ces applications \( T_k\) existent et sont continues par hypothèse.

	Le théorème \ref{THOooBEAOooBdvOdr} nous indique que \( T_1(a)=df_a\). Nous supposons maintenant que \( (d^kf)_a=T_k(a)\) et nous allons prouver que \( T_{k+1}\) est la différentielle de \( d^kf\). Pour cela nous devons prouver que
	\begin{equation}        \label{EQooPKXDooWWVikT}
		\lim_{h\to 0} \frac{ T_k(a+h)-T_k(a)-T_{k+1}(a)h }{ \| h \| }=0.
	\end{equation}
	En utilisant le lemme \ref{LEMooLTYCooAoMJKD} nous pouvons dégrossir le terme \( T_{k+1}(a)h\) :
	\begin{subequations}
		\begin{align}
			T_{k+1}(a)h & =\sum_{l,I}\big[ (\partial_{l,I}f)(a)\times_{k+1}\phi_{k+1}(\omega_{l,I}) \big]h                                   \\
			            & =\sum_{l,I}\big[ (\partial_{l,I}f)(a)\times_k\phi_k(\omega_I) \big]\times_1\omega_l(h)                             \\
			            & =\sum_{l,I}h_l(\partial_{l,I}f)(a)\times_k\phi_k(\Omega_I)                                                         \\
			            & =\sum_lh_l\big[ \partial_l\sum_I(\partial_If)(a) \big]\times_k\phi_k(\omega_I).        \label{SUBEQooACCZooXrxHpY}
		\end{align}
	\end{subequations}
	Vu que \( \partial_If\) est une fonction dont les dérivées partielles existent et sont continues, le théorème \ref{THOooBEAOooBdvOdr} (toujours lui) nous dit qu'elle est différentiable et que
	\begin{equation}
		d(\partial_If)_a(h)=\sum_lh_l\partial_l(\partial_If)(a).
	\end{equation}
	En mettant la somme sur \( I\) tout devant dans \eqref{SUBEQooACCZooXrxHpY}, nous trouvons
	\begin{equation}
		T_{k+1}(a)h=\sum_Id(\partial_If)_a(h)\times_k\phi_k(\omega_I).
	\end{equation}
	C'est pas beau la vie ? Nous pouvons écrire le numérateur du quotient différentiel \eqref{EQooPKXDooWWVikT} :
	\begin{subequations}
		\begin{align}
			T_k(a+h)-T_k(a)-T_{k+1}(a)h & =\sum_I\big[ (\partial_If)(a+h)-(\partial_If)(a) \big]\times_k\phi_k(\omega_I)                     \\
			                            & \qquad-\sum_Id(\partial_If)_a(h)\times_k\phi_k(\omega_I)                                           \\
			                            & =\sum_I\big[ (\partial_If)(a+h)-(\partial_If)(a)-d(\partial_If)(a)h \big]\times_l\phi_k(\omega_I).
		\end{align}
	\end{subequations}
	Nous utilisons le fait que l'application \( w\mapsto w\times_k\phi_k(\omega_I)\) est linéaire et commute avec la limite, c'est-à-dire que
	\begin{equation}
		\lim_{h\to 0} \big( w(h)\times_k\phi_k(\omega_I) \big)=\big( \lim_{h\to 0} w(h) \big)\times_k\phi_k(\omega_I).
	\end{equation}
	Et bien sûr, la somme sur les multiindices \( I\) commute également avec la limite. Donc
	\begin{subequations}
		\begin{align}
			\lim_{h\to 0} \frac{ T_k(a+h)-T_k(a)-T_{k+1}(a)h }{ \| h \| } & =\sum_I\left( \lim_{h\to 0} \frac{ (\partial_If)(a+h)-(\partial_If)(a)-d(\partial_If)_ah }{ \| h \| } \right)\times_k\phi_k(\omega_I) \\
			                                                              & =0.
		\end{align}
	\end{subequations}
	Cela prouve que \( T_{k+1}\) est bien la différentielle de \( T_k\). Par récurrence, la fonction \( f\) est bien \( n\) fois continuement différentiable.
\end{proof}

Maintenant que nous avons plein de lemmes et de résultats, il est facile de démontrer un très gros résultat en peu de lignes.

\begin{theorem}     \label{THOooPZTAooTASBhZ}
	Soit une application \( f\colon V\to E\) entre deux espaces vectoriels normés de dimension finies. Nous avons équivalence entre
	\begin{enumerate}
		\item       \label{ITEMooBOWTooXgxhpS}
		      \( f\) est de classe \( C^n\)
		\item       \label{ITEMooPVZHooHihSRD}
		      les dérivées partielles \( \partial_if\) sont de classe \( C^{n-1}\)
		\item       \label{ITEMooVBQMooBleazN}
		      les dérivées partielles \( \partial^n_If\) existent et sont continues pour tout multiiindice de longueur \( n\).
	\end{enumerate}
\end{theorem}

\begin{proof}
	En plusieurs implications.
	\begin{subproof}
		\spitem[\ref{ITEMooVBQMooBleazN} implique \ref{ITEMooBOWTooXgxhpS}]
		C'est la proposition \ref{PROPooKOBVooQhrAeJ}.
		\spitem[\ref{ITEMooBOWTooXgxhpS} implique \ref{ITEMooVBQMooBleazN}]
		C'est la proposition \ref{PROPooVGRRooHSwcPl}.
		\spitem[\ref{ITEMooVBQMooBleazN} implique \ref{ITEMooPVZHooHihSRD}]
		En posant \( g_i=\partial_if\), l'hypothèse est que les \( \partial^{n-1}_Ig_i\) existent et sont continues pour tout multiindices \( I\) de longueur \( n-1\). En appliquant «\ref{ITEMooVBQMooBleazN} implique \ref{ITEMooBOWTooXgxhpS}» à la fonction \( g_i\), la fonction \( g_i\) est de classe \( C^{n-1}\).
		\spitem[\ref{ITEMooPVZHooHihSRD} implique \ref{ITEMooVBQMooBleazN}]
		Les fonctions \( g_i\) déjà définies sont de classe \( C^{n-1}\). Nous leur appliquons «\ref{ITEMooBOWTooXgxhpS} implique \ref{ITEMooVBQMooBleazN}», nous savons que les fonctions \( \partial^{n-1}_Ig_i\) sont continues, c'est-à-dire que les \( \partial_I\partial_if\). Vu que tout multiiindice de longueur \( n\) peut être écrit sous la forme \( iI\) où \( I\) est de longueur \( n-1\), nous avons prouvé que les \( \partial^n_Jf\) existent et sont continues pour tout multiindice \( J\) de longueur \( n\).
	\end{subproof}
\end{proof}

\begin{proposition}[\cite{MonCerveau}]		\label{PROPooCKROooYutfEX}
	Soit un espace vectoriel \( V\) de dimension finie \( n\) sur \( K\) (\( =\eC\) ou \( \eR\)). Soit une base \( \{ e_i \}_{i\in I}\) de \( V\). Pour chaque \( i\), la projection
	\begin{equation}
		\begin{aligned}
			\pr_i\colon V & \to \eK     \\
			\sum_ke_k     & \mapsto a_i
		\end{aligned}
	\end{equation}
	est de classe \( C^{\infty}\).
\end{proposition}
% TODOooTGIQooWzpMaQ. Prouver ça.
% C'est presque certainement une conséquence de THOooPZTAooTASBhZ.
\ssdem

\begin{proposition}[\cite{MonCerveau}]		\label{PROPooMOMMooDYIayv}
	Soient deux espaces vectoriels normés de dimension finie \( V\) et \( W\). Soient des bases \( \{ e_i \}\) et \( \{ e'_j \}\) de \( V\) et \( W\). Une application \(f \colon V\to W  \) est de classe \( C^p\) si et seulement si chacune de ses composantes le sont, c'est-à-dire si en écrivant
	\begin{equation}
		f(s)=\sum_jf_j(s)e'_j,
	\end{equation}
	les applications \(f_j \colon V\to \eR  \) sont de classe \( C^p\).
\end{proposition}

\begin{proof}
	En deux parties.
	\begin{subproof}
		\spitem[Sens direct]
		%-----------------------------------------------------------
		Considérant la proposition \ref{PROPooCKROooYutfEX}, la projection
		\begin{equation}
			\begin{aligned}
				\pr_i\colon W & \to \eR     \\
				\sum_ka_ke'_k & \mapsto a_i
			\end{aligned}
		\end{equation}
		est de classe \( C^{\infty}\). Vu que \( f\) est de classe \( C^p\), la composée \( \pr_i\circ f\) est de classe \( C^p\) par la proposition \ref{PROPooLRRMooRzrTNE}.

		\spitem[Sens réciproque]
		%-----------------------------------------------------------
		Si \( I\) est un multiindice de longueur \( p\), nous avons
		\begin{equation}
			(\partial^p_If)(s)=\sum_k(\partial^p_If_k)(s)e'_k,
		\end{equation}
		qui est continue parce que les \( f_k\) sont de classe \( C^p\). Donc \( f\) est de classe \( C^p\) par le théorème \ref{THOooPZTAooTASBhZ}\ref{ITEMooVBQMooBleazN}.
	\end{subproof}
\end{proof}

\begin{proposition}[\cite{MonCerveau}]	\label{PROPooWOYSooVERAAx}
	Soit un ouvert \( U\) de \( \eR^n\). Soit une application \(s \colon U\to \eR^n  \) de classe \( C^k\). Alors
	\begin{equation}
		\begin{aligned}
			f\colon U & \to U\times \eR^n          \\
			x         & \mapsto \big( x,s(x) \big)
		\end{aligned}
	\end{equation}
	est de classe \( C^k\).
	%TODOooXZLIooSmzsZg. Prouver ça.
\end{proposition}



%-------------------------------------------------------
\subsection{Application à valeurs dans les opérateurs}
%----------------------------------------------------

\begin{proposition}[\cite{MonCerveau}]		\label{PROPooUCRNooaqsebj}
	Soient des espaces vectoriels normés \( V\) et \( W\). Soient un ouvert \( U\subset \eR^n\) et une application \(A \colon U\to \End(V,W)  \). L'application \( A\) est de classe \( C^k\) si et seulement si toutes les applications \( s\mapsto A(s)_{ij}\) sont de classe \( C^k\).
\end{proposition}

\begin{proof}
	Nous utilisons les applications \( f_{ij}\) de la proposition \ref{PROPooRIFBooGOvsfb}, en nous souvenant que les éléments de matrice de \( A(s)\) sont les coordonnées de \( A(s)\in\End(V,W)\) dans ces coordonnées (proposition \ref{PROPooPNQNooAZpojm}). Le résultat est alors seulement un cas particulier de la proposition \ref{PROPooMOMMooDYIayv}.
\end{proof}

\begin{proposition}[\cite{MonCerveau}]		\label{PROPooYORGooDmwrJg}
	Soient des espaces vectoriels normés \( V\) et \( W\). Soient un ouvert \( U\subset \eR^n\) et une application \(A \colon U\to \End(V,W)  \). Nous supposons que pour chaque \( v\in V\) , l'application \( s\mapsto A(s)v\) est \( C^k\).

	Alors \( A\) est \( C^k\).
\end{proposition}

\begin{proof}
	Soient une base \( \{ e_i \}\) de \( V\) et \( \{ e'_j \}\) de \( W\). Nous considérons les applications
	\begin{equation}
		\begin{aligned}
			f_i\colon U & \to W            \\
			s           & \mapsto A(s)e_i.
		\end{aligned}
	\end{equation}
	Par hypothèse, \( f_i\) est une application \( C^k\). Nous avons
	\begin{equation}
		f_i(s)=A(s)e_i=\sum_jA(s)_{ji}e'_j
	\end{equation}
	Nous profitons de la proposition \ref{PROPooCKROooYutfEX} qui dit que la projection est de classe \( C^{\infty}\), et de la proposition \ref{PROPooLRRMooRzrTNE} à propos des composées, l'application \( (\pr_j\circ f_i)\) est de classe \( C^p\). Or nous avons
	\begin{equation}
		(\pr_j\circ f_i)(s)=A(s)_{ji}.
	\end{equation}
	La proposition \ref{PROPooUCRNooaqsebj} conclut que \( f\) est de classe \( C^p\).
\end{proof}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Espaces d'applications multilinéaires et identifications}
%---------------------------------------------------------------------------------------------------------------------------

Si \( V\) et \( E\) sont des espaces vectoriels de dimensions finies, la différentielle de \( f\colon V\to E\) est une application \( df\colon V\to \aL(V,E)\). La différentielle seconde est une application \( d(df)\colon V\to \aL\big( V,\aL(V,E) \big)\) et ainsi de suite.

Une grande difficulté de la manipulation des différentielles d'ordre supérieurs provient de cet emboîtement d'espaces d'applications linéaires. Nous nous attaquons à présent à la description de ces espaces emboîtés\footnote{Toutes les constructions, tous les énoncés et les preuves qui suivent sont de l'invention personnelle de l'auteur de ces lignes. Je n'ai trouvé nulle part une source qui s'attaque réellement à la récurrence.}.

Pour la suite, nous considérerons des espaces vectoriels normés \( V\) et \( E\) de dimension finie. Nous notons \( \aL^n(V,E)\) l'espace des applications multilinéaires \( V^n\to E\).

Nous introduisons le produit suivant\cite{MonCerveau} :
\begin{equation}
	\begin{aligned}
		\cdot\colon W\times \aL\big( V,\aL(V,\eR) \big) & \to \aL\big( V,\aL(V,W) \big) \\
		\big( (w\cdot \psi)(u) \big)v                   & =\big( \psi(u)v \big)w.
	\end{aligned}
\end{equation}
Dans la suite, pour économiser des parenthèses et des maux de tête, nous allons noter \( \psi(u,v)\) le nombre \( \psi(u)v\). Il n'est cependant pas question de dire que \( \psi\) est une application bilinéaire. En effet, identifier \( \aL\big( V,\aL(V,W) \big)\) à l'espace des applications bilinéaires \( V\times V\to W\) ne sert pas à grand chose pour l'instant parce qu'une telle identification a le prix de devoir prouver que toutes les propriétés des différentielles passent à travers l'identification, tâche qui est à priori (conservation de la difficulté) de la même nature que celle à laquelle nous nous attachons à présent.

\begin{lemma}[\cite{MonCerveau}]        \label{LEMooHCUSooXYHuBR}
	Soient deux espaces vectoriels normés \( V\) et \( E\) ainsi que \( \psi\in\aL\big( V,\aL(V,\eR) \big)\). Pour tout \( a\in E\) nous avons
	\begin{equation}
		\| a\cdot \psi \|_{\aL\big( V,\aL(V,E) \big)}= \| \psi \|_{\aL\big( V,\aL(V,\eR) \big)}\| a \|_E.
	\end{equation}
\end{lemma}

\begin{proof}
	Il s'agit seulement d'un calcul :
	\begin{subequations}
		\begin{align}
			\| a\cdot \psi \| & =\sup_{\| v \|=1}\| (a\cdot \psi)(v) \|_{\aL(V,E)}                                          \\
			                  & =\sup_{\| v \|=1}\sup_{\| w \|=1}\| (a\cdot\psi)(v)w \|_E                                   \\
			                  & =\sup_{\| v \|=1}\sup_{\| w \|=1}\| \big( \psi(v)w \big)a \|_E  \label{SUBEQooDVSVooFkgDQb} \\
			                  & =\sup_{\| v \|=1}\sup_{\| w \|=1}| \psi(v)w |\,\| a \|_{E} \label{SUBEQooBJQDooDyZMOy}      \\
			                  & =\sup_{\| v \|=1}\| \psi(v) \|\,\| a \|                                                     \\
			                  & =\| \psi \|\| a \|.
		\end{align}
	\end{subequations}
	Notez que dans \eqref{SUBEQooDVSVooFkgDQb}, \( | \psi(v)w |\) est un simple réel; c'est pourquoi nous le retrouvons hors de la norme \( \| . \|_E\) dans \eqref{SUBEQooBJQDooDyZMOy}, muni d'une simple valeur absolue.
\end{proof}

\begin{lemma}[\cite{MonCerveau}]
	Soient \( \psi\in\aL\big( V,\aL(V,\eR) \big)\) et une fonction continue \( f\colon V\to E\). Alors la fonction
	\begin{equation}
		\begin{aligned}
			g\colon V & \to \aL\big( V,\aL(V,E) \big) \\
			x         & \mapsto f(x)\cdot \psi
		\end{aligned}
	\end{equation}
	est continue.
\end{lemma}

\begin{proof}
	Pour des raisons de notations, nous allons écrire \( g_x\) pour \( g(x)\). Cela étant dit nous considérons \( a\in E\), une suite \( x_k\stackrel{E}{\longrightarrow}a \) et nous calculons :
	\begin{subequations}
		\begin{align}
			\| g_a-g_{x_k} \| & =\sup_{\| u \|=1}\| g_a(u)-g_{x_k}(u) \|_{\aL(V,E)}                    \\
			                  & =\sup_{\| u \|=1}\sup_{\| v \|=1}\| g_a(u)v-g_{x_k}(u)v \|_{E}         \\
			                  & =\sup_{\| u \|=1}\sup_{\| v \|=1}\| f(a)\psi(u)v-f(x_k)\psi(u)v \|     \\
			                  & =\sup_{\| u \|=1}\sup_{\| v \|=1}\| f(a)-f(x_k) \|\big| \psi(u)v \big| \\
			                  & =\big\| f(a)-f(x_k) \big\|\sup_{u,v}| \psi(u)v |                       \\
			                  & =\| f(a)-f(x_k) \|\,\| \psi \|.
		\end{align}
	\end{subequations}
	En prenant la limite \( k\to \infty\), et en considérant que \( f\) est continue en \( a\), nous obtenons
	\begin{equation}
		\lim_{k\to \infty} \| g_a-g_{x_k} \|=0.
	\end{equation}
\end{proof}

\begin{lemma}[\cite{MonCerveau}]
	Soient une application différentiable \( f\colon V\to E\) ainsi que \( \psi\in\aL\big( V,\aL(V,\eR) \big)\). Soit
	\begin{equation}
		\begin{aligned}
			g\colon V & \to \aL\big(V, \aL(V,E) \big) \\
			x         & \mapsto f(x)\cdot \psi.
		\end{aligned}
	\end{equation}
	Alors \( g\) est différentiable et pour tout \( a\in V\) nous avons
	\begin{equation}
		dg_a(h)=df_a(h)\cdot \psi.
	\end{equation}
\end{lemma}

Notons que nous n'avons pas \( dg_a=df_a\cdot \psi\). En effet, \( df_a\in \aL( V,W )\), de telle sorte que \( df_a\cdot\psi\in \aL\big( V,\aL\big( V,\aL(V,W) \big) \big)\). Les espaces ne s'emboîtent pas dans le bon ordre.

\begin{proof}
	Il s'agit de vérifier que \( h\mapsto df_a(h)\cdot \psi\) vérifie la condition de la définition \ref{DefDifferentiellePta}. En utilisant le fait que \( (a+b)\cdot \psi = a\cdot \psi+b\cdot \psi\) ainsi que le lemme \ref{LEMooHCUSooXYHuBR} nous écrivons
	\begin{subequations}
		\begin{align}
			\frac{ \| f(a+h)\cdot \psi-f(a)\cdot\psi-df_a(h)\cdot \psi\|  }{ \| h \| } & =\| \frac{ f(a+h)-f(a)-df_a(h) }{ h  }\cdot \psi\|  \\
			                                                                           & =\| \frac{ f(a+h)-f(a)-df_a(h) }{ h } \|\| \psi \|.
		\end{align}
	\end{subequations}
	Vu que \( f\) est différentiable en \( a\) et que \( df_a\) est la différentielle, nous avons bien
	\begin{equation}
		\lim_{h\to 0}  \| \frac{ f(a+h)-f(a)-df_a(h) }{ h } \|\| \psi \|=0.
	\end{equation}
\end{proof}


\begin{proof}
	Nous faisons \ref{ITEMooUWEBooSzFseN} par récurrence. D'abord \( \dim(E_0)=\dim(E)\) et ensuite
	\begin{equation}
		\dim(E_{k+1})=\dim\aL(V,E_k)=\dim(V)\dim(E_k)=\dim(V)^{n+1}\dim(E).
	\end{equation}

	Pour \ref{ITEMooFMKQooFSMpgF}, si \( \{ e_i \}\) est une base de \( V\), un élément \( \omega\in \aL^n(V,E)\) est déterminé par les valeurs de \( \omega(e_{i_1},\ldots, e_{i_n})\) qui peuvent être n'importe quel vecteur de \( E\). Donc la dimension est \( \dim(V)^n\dim(E)\).
\end{proof}

\begin{lemma}[\cite{MonCerveau}]
	Soit \( n\in \eN\) nous définissons par récurrence
	\begin{equation}
		\begin{aligned}
			\psi_{n,0}\colon E_n & \to E_n         \\
			\alpha               & \mapsto \alpha.
		\end{aligned}
	\end{equation}
	et
	\begin{equation}
		\begin{aligned}
			\psi_{n,k}\colon E_n                & \to \aL^k(V,E_{n-k})                                       \\
			\psi_{n,k}(\alpha)(v_1,\ldots, v_k) & =\big( \psi_{n,k-1}(\alpha)(v_1,\ldots, v_{k-1}) \big)v_k.
		\end{aligned}
	\end{equation}
	L'application
	\begin{equation}
		\psi_{n,n}\colon E_n\to \aL^n(V,E)
	\end{equation}
	est un isomorphisme isométrique.
\end{lemma}

\begin{proof}
	Nous allons démontrer par récurrence sur \( k\) que tous les \( \psi_{n,k}\) sont des isomorphismes isométriques. Pour \( k=0\) c'est évident parce que \( \psi_{n,0}\) est l'identité.

	\begin{subproof}
		\spitem[Injective]
		Soient \( \alpha\in E_n\) tels que \( \psi_{n,k+1}(\alpha)=0\). Cela signifie que pour tout \( v_1,\ldots, v_{k+1}\) nous avons
		\begin{equation}
			\psi_{n,k}(\alpha)(v_1,\ldots, v_k)v_{k+1}=0.
		\end{equation}
		c'est-à-dire \( \psi_{n,k}(\alpha)(v_1,\ldots, v_{k})=0\). Vu que \( \psi_{n,k}\) est injective (hypothèse de récurrence), nous avons \( \alpha=0\).

		\spitem[Surjective]
		Soit \( \omega\in \aL^{k+1}(V,E_{n-k})\); nous cherchons \( \alpha\in E_n\) tel que \( \psi_{n,k+1}(\alpha)=\omega\), c'est-à-dire tel que
		\begin{equation}        \label{EQooACUOooKCKame}
			\psi_{n,k+1}(\alpha)(v_1,\ldots, v_{k+1})=\psi_{n,k}(\alpha)(v_1,\ldots, v_k)v_{k+1}=\omega(v_1,\ldots, v_{k+1}).
		\end{equation}
		Notez que
		\begin{equation}
			\psi_{n,k}(\alpha)\in \aL^k(V,E_{n-k})=\aL^k\big( V,\aL(V,E_{n-k-1}) \big).
		\end{equation}
		En considérant \( \sigma\in \aL^k\big( V,\aL(V,E_{n-k-1}) \big)\) donné par
		\begin{equation}
			\sigma(v_1,\ldots, v_k)v_{k+1}=\omega(v_1,\ldots, v_{k+1}),
		\end{equation}
		il existe (hypothèse de récurrence sur \( k\)) un \( \alpha\in E_n\) tel que \( \psi_{n,k}(\alpha)=\sigma\).

		Pour ce \( \alpha\), la condition \eqref{EQooACUOooKCKame} est satisfaite.

		\spitem[Isométrique]
		Encore une fois par récurrence. Soit \( \alpha\in E_n\). Nous avons
		\begin{subequations}
			\begin{align}
				\| \psi_{n,k}(\alpha) \|_{\aL^k(V,E_{n-k})} & =\sup_{\| v_i \|=1}\| \psi_{n,k}(\alpha)(v_1,\ldots, v_k) \|_{E_{n-k}}          \\
				                                            & =\sup_{\| v_i \|=1}\| \psi_{n,k-1}(\alpha)(v_1,\ldots, v_{k-1})v_k \|_{E_{n-k}} \\
				                                            & =\sup_{\substack{\| v_i \|=1                                                    \\i=1,\ldots, k-1}}\| \psi_{n,k-1}(v_1,\ldots, v_{k-1}) \|_{\aL(V,E_{n-k-1})}\\
				                                            & =\| \psi_{n,k-1}(\alpha) \|                                                     \\
				                                            & =\| \alpha \|.
			\end{align}
		\end{subequations}
		La dernière égalité est l'hypothèse de récurrence. Notez la subtile utilisation du lemme \ref{LEMooQLVAooICaPvR} qui permet de donner un sens aux supremums, grace au fait que \( \{ v\in V\tq \| v \|=1 \}\) est compact.
	\end{subproof}
\end{proof}

\begin{lemma}       \label{LEMooFBEGooCqrzxH}
	Nous avons \( \psi_{n,n}=\phi_n^{-1}\).
\end{lemma}

\begin{proof}
	Pour nous échauffer nous posons \( \omega\in\aL^n(V,\eR)\), et nous calculons
	\begin{subequations}        \label{EQooPBQIooUValDA}
		\begin{align}
			\psi_{n,2}\big( \phi_n(\omega) \big)(v_1,v_2) & =\Big( \psi_{n,1}\big( \phi_n(\omega) \big)v_1 \Big)v_2 \\
			                                              & =\big( \phi_n(\omega)v_1 \big)v_2                       \\
			                                              & =\phi_{n-1}\big( \pr_{v_1}(\omega) \big)                \\
			                                              & =\phi_{n-2}\big( \pr_{v_2}\pr_{v_1}(\omega) \big).
		\end{align}
	\end{subequations}
	Cela étant dit, nous allons prouver ceci par récurrence :
	\begin{equation}
		\psi_{n,k}\big( \phi_n(\omega) \big)(v_1,\ldots, v_k)=\phi_{n-k}\Big( \prod_{i=1}^k\pr_{v_i}(\omega) \Big).
	\end{equation}
	Notez l'ordre du produit des projections. En ce qui concerne cet ordre, pour fixer les idées voici un exemple :
	\begin{equation}
		\pr_{v_2}\pr_{v_1}(\omega)=\big( \pr_{v_1}(\omega) \big)(v_2)=\omega(v_1,v_2).
	\end{equation}

	Faisons maintenant la récurrence.
	\begin{subproof}
		\spitem[Pour \( k=2\)]
		C'est le calcul \eqref{EQooPBQIooUValDA}.
		\spitem[Pour \( k+1\)]
		C'est encore un calcul, en faisant attention à l'ordre dans lequel viennent les projections :
		\begin{subequations}
			\begin{align}
				\psi_{n,k+1}\big( \phi_n(\omega) \big)(v_1,\ldots, v_{k+1}) & =\Big( \psi_{n,k}\big( \phi_n(\omega) \big)(v_1,\ldots, v_k) \Big)v_{k+1} \\
				                                                            & =\Big( \phi_{n-k}\big( \prod_{i=1}^k\pr_{v_i}(\omega) \big) \Big)v_{k+1}  \\
				                                                            & =\phi_{n-k-1}\big( \pr_{v_{k+1}}\prod_{i=1}^k\pr_{v_i}(\omega) \big)      \\
				                                                            & =\phi_{n-(k+1)}\big( \prod_{i=1}^{k+1}\pr_{v_i}(\omega) \big).
			\end{align}
		\end{subequations}
	\end{subproof}
	Il ne reste qu'à écrire la formule démontrée avec \( k=n\) :
	\begin{equation}
		\psi_{n,n}\big( \phi_n(\omega) \big)(v_1,\ldots, v_n)=\phi_{n-n}\big( \prod_{i=1}^n\pr_{v_i}(\omega) \big)=\omega(v_1,\ldots, v_n).
	\end{equation}
	Donc nous avons bien que \( \psi_{n,n}\big( \phi_n(\omega) \big)=\omega\).
\end{proof}

\begin{lemma}       \label{LEMooDGUGooTXOtih}
	Soient deux espaces vectoriels normés \( V\) et \( E\). Nous considérons une application linéaire \( A\colon V\to E\), une forme \( \omega\in\aL^n(V,\eR)\) ainsi que la forme
	\begin{equation}
		\begin{aligned}
			\alpha\colon V & \to E_n                        \\
			u              & \mapsto A(u)\psi^{-1}(\omega).
		\end{aligned}
	\end{equation}
	Alors
	\begin{equation}
		\psi_{n+1,n+1}(\alpha)(v_1,\ldots, v_{n+1})=A(v_1)\omega(v_2,\ldots, v_{n+1}).
	\end{equation}
\end{lemma}

\begin{proof}
	Nous prouvons la formule suivante par récurrence :
	\begin{equation}
		\psi_{n+1,k}(\omega)(v_1,\ldots, v_k)=A(v_1)\phi_{n-k+1}\big( \prod_{i=2}^k\pr_{v_i}(\omega) \big).
	\end{equation}
	Nous commençons la récurrence avec \( k=2\), en tenant compte que \( \psi^{-1}=\phi_n\) (lemme \ref{LEMooFBEGooCqrzxH}) :
	\begin{subequations}
		\begin{align}
			\psi_{n+1,2}(\alpha)(v_1,v_2) & =\big( \psi_{n+1,1}(\alpha)v_1 \big)v_2         \\
			                              & =\alpha(v_1)v_2                                 \\
			                              & =A(v_1)\big( \psi^{-1}(\omega)v_2 \big)         \\
			                              & =A(v_1)\big( \phi_n(\omega)v_2 \big)            \\
			                              & =A(v_1)\phi_{n-1}\big( \pr_{v_2}(\omega) \big).
		\end{align}
	\end{subequations}
	C'est bon pour \( k=2\). Nous passons à la récurrence :
	\begin{subequations}
		\begin{align}
			\psi_{n+1,k+1}(\omega)(v_1,\ldots, v_{k+1}) & =\big( \phi_{n+1,k}(\omega)(v_1,\ldots, v_k) \big)v_{k+1}                      \\
			                                            & =A(v_1)\Big( \phi_{n-k+1}\big( \prod_{i=2}^k\pr_{v_i}\omega \big) \Big)v_{k+1} \\
			                                            & =A(v_1)\phi_{n-k}\big( \pr_{v_{k+1}}\prod_{i=2}^k\pr_{v_i}\omega \big)         \\
			                                            & =A(v_1)\phi_{n-(k+1)}\big( \prod_{i=2}^{k+1}\pr_{v_i}\omega \big).
		\end{align}
	\end{subequations}
	La récurrence est terminée. Nous écrivons la formule pour \( k=n+1\) en tenant compte de \( \phi_0=\id\) pour terminer la preuve de ce lemme :
	\begin{equation}
		\psi_{n+1,n+1}(\omega)(v_1,\ldots, v_{n+1})=A(v_1)\phi_0\big( \prod_{i=2}^{n+1}\pr_{v_i}\omega \big)=A(v_1)\omega(v_2,\ldots, v_{n+1}).
	\end{equation}
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Fonctions différentiables plusieurs fois}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}
	Un \defe{\( C^k\)-difféomorphisme}{difféomorphisme!de classe \( C^k\)} est une application inversible de classe \( C^k\) dont l'inverse est également de classe \( C^k\).
\end{definition}

\begin{example}\label{bilin_2diff}
	Soit \( B:\eR^m\times \eR^m\to\eR^n\) une application bilinéaire. On définit \( f:\eR^m\to\eR^n\) par \( f(x)=B(x,x)\). Le lemme~\ref{bilin_diff} nous dit que \( B\) est différentiable. Cela implique la différentiabilité de \( f\). Pour trouver la différentielle de la fonction \( f\), nous écrivons \( f=B\circ s\) où \( s\colon \eR^m\to \eR^m\times\eR^m\) est l'application \( s(x)=(x,x)\). En utilisant la règle de différentiation de fonctions composées,
	\begin{equation}
		df(a)=dB\big( s(a) \big)\circ ds(a).
	\end{equation}
	Mais \( ds(a).u=(u,u)\) parce que \( s(a+h)-s(a)-(h,h)=0\). Par conséquent,
	\begin{equation}		\label{EqdBsaExp}
		df(a).u=dB\big( s(a) \big)(u,u)=B(u,a)+B(a,u)
	\end{equation}
	où nous avons utilisé la formule du lemme~\ref{bilin_diff}. La formule \eqref{EqdBsaExp} peut être écrite sous la forme compacte
	\begin{equation}
		df(a)=B(\cdot,a)+B(a,\cdot)
	\end{equation}
	La fonction \( df(a)\) ainsi écrite est linéaire par rapport à \( a\), donc différentiable. En outre elle coïncide avec sa différentielle, comme on a vu dans le lemme \ref{LEMooZSNMooCfjzOB}, au sens que la différentielle de \( df\) au point \( a\) sera l'application que à chaque \( x\) dans \( \eR^m\) associe l'application linéaire \( B(x,\cdot)+B(\cdot, x)\). On voit bien que \( d^2f\) au point \( a\) est une application de \( \eR^m\) vers l'espace des applications linéaires \( \aL(\eR^m, \eR^n)\). On peut utiliser d'autre part l'isomorphisme des espaces \( \aL(\eR^m,\aL(\eR^m, \eR^n) )\) et \( \aL(\eR^m\times\eR^m, \eR^n )\) et dire que, une fois que \( a\) est fixé, l'application \( d^2f(a)\) est une application bilinéaire sur \( \eR^m\times\eR^m\). On écrit alors \( d^2f(a)(x,y)=B(x,y)+B(y,x)\).
\end{example}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Différentielle seconde, fonction de classe \texorpdfstring{\(  C^2\)}{C2}}
%---------------------------------------------------------------------------------------------------------------------------

La différentielle seconde dans l'exemple ~\ref{bilin_2diff} est symétrique, c'est-à-dire que \( d^2f(a)(x_1,x_2)=d^2f(a)(x_2,x_1)\). En fait toute différentielle seconde est symétrique.

Le théorème de Schwarz permet de permuter les dérivées partielles d'ordre \( 2\) dans le cas d'une fonction de classe \( C^2\). Il y aura une généralisation pour les fonctions de classe \( C^m\) dans la proposition \ref{PROPooYGJDooOqibbh}.
\begin{theorem}[Schwarz]\label{Schwarz}
	Soit \( U\) un ouvert de \( \eR^m\) et  \( f:U\subset\eR^m\to \eR^n\) une fonction de classe \( \mathcal{C}^2\). Alors, pour tout couple \( i,j\) d'indices dans \( \{1,\ldots, m\}\) et pour tout point \( a\) dans \( U\), on a
	\[
		\frac{\partial^2 f}{\partial  x_i\partial x_j}(a)=\frac{\partial^2 f}{\partial  x_j\partial x_i}(a).
	\]
\end{theorem}
\begin{proof}
	Pour simplifier nous nous limitons ici au cas \( m=2\). Soit \( (h,g)\) un vecteur fixé dans \( \eR^2\). Pour tout  \( v=(x,y)\) dans \( \eR^2\) on note
	\begin{equation}
		\begin{array}{c}
			\Delta_h f(v)=f(v+he_1) -f(v) = f(x+h,y)-f(x,y), \\
			\Delta_g f(v)=f(v+ge_2) -f(v) = f(x,y+g)-f(x,y), \\
		\end{array}
	\end{equation}
	Nous avons
	\begin{equation}
		\begin{array}{c}
			\Delta_g   \Delta_h f(v)=\left(f(x+h,y+g)-f(x,y+g)\right)-\left(f(x+h,y)-f(x,y)\right), \\
			\Delta_h   \Delta_g f(v)=\left(f(x+h,y+g)-f(x+h,y)\right)-\left(f(x,y+g)-f(x,y)\right),
		\end{array}
	\end{equation}
	donc,
	\begin{equation}
		\frac{1}{g} \Delta_g  \left(\frac{1}{h} \Delta_h f(v)\right) = \frac{1}{h} \Delta_h \left(\frac{1}{g} \Delta_g f(v)\right).
	\end{equation}
	On utilise alors le théorème des accroissements finis~\ref{ThoAccFinis}
	\begin{equation}
		\frac{1}{h} \Delta_h f(v)=\frac{1}{h}\big(f(x+h,y)-f(x,y)\big)=\frac{1}{h}\partial_1f(x+t_1h,y )h=\partial_1f(x+t_1h, y),
	\end{equation}
	pour un certain \( t_1\) dans \( ]0,1[\). De même on obtient
	\[
		\frac{1}{g} \Delta_g f(v)= \partial_2 f(x, y+t_2g),
	\]
	pour un certain \( t_2\) dans \( ]0,1[\). Alors
	\begin{equation}
		\frac{1}{g} \Delta_g  \big(\partial_1f(x+t_1h, y)\big) = \frac{1}{h} \Delta_h \big(\partial_2 f(x, y+t_2g)\big).
	\end{equation}
	En appliquant encore une fois le théorème des accroissements finis on a
	\begin{equation}
		\partial_2\partial_1f(x+t_1h, y+s_1g) = \partial_1\partial_2 f(x+s_2h, y+t_2g).
	\end{equation}
	Il suffit maintenant de passer à la limite pour \( (h,g) \to (0,0)\) et de se souvenir du fait que \( f\) est \( \mathcal{C}^2\) seulement si ses dérivées partielles secondes sont continues\footnote{Théorème \ref{THOooPZTAooTASBhZ}.} pour avoir \( \partial_2\partial_1f(v)=\partial_1\partial_2 f(v)\).
\end{proof}
Si \( f\) est deux fois différentiable \( d^2f(a)\) est l'application bilinéaire associée avec la matrice symétrique
\begin{equation}
	H_f(a)= \begin{pmatrix}
		\partial^2_1f(a)          & \ldots & \partial_1\partial_m f(a) \\
		\vdots                    & \ddots & \vdots                    \\
		\partial_1\partial_m f(a) & \ldots & \partial^2_mf(a),
	\end{pmatrix}
\end{equation}
Cette matrice est dite la matrice \defe{hessienne}{hessienne} de \( f\).

\begin{example}
	Montrons qu'il n'existe pas de fonctions \( f\) de classe \( \mathcal{C}^2\) telles que
	\begin{subequations}
		\begin{numcases}{}
			\partial_xf(x,y)= 5\sin x\\
			\partial_y(x,y)=6x+y.
		\end{numcases}
	\end{subequations}
	Ceci est vite fait en appliquant le théorème de Schwarz,~\ref{Schwarz}; ce que nous trouvons est
	\[
		\partial_y (\partial_xf)= 0
	\]
	alors que
	\begin{equation}
		\partial_x(\partial_yf)= 6.
	\end{equation}
	Vu que \( \partial_x(\partial_yf)\neq \partial_y(\partial_xf)\), le théorème \ref{Schwarz} dit que \( f\) ne peut pas être de classe \( C^2\).
\end{example}

\begin{normaltext}      \label{NORMooKSAVooCeILmI}
	Soit une fonction de classe \( C^2\) \( f\colon V\to \eR\) où \( V\) est un espace vectoriel de dimension \( n<\infty\). Nous avons
	\begin{subequations}
		\begin{align}
			f    & \colon V\to \eR                          \\
			df   & \colon V\to \aL(V,\eR)                   \\
			d^2f & \colon V\to \aL\Big( V,\aL(V,\eR) \Big),
		\end{align}
	\end{subequations}
	avec, en suivant les différentes formules du lemme~\ref{LemdfaSurLesPartielles},
	\begin{equation}
		df_a(u)=\Dsdd{ f(a+tu) }{t}{0}
	\end{equation}
	et
	\begin{equation}
		(d^2f)_a(u)=\Dsdd{ df_{a+tu} }{t}{0}
	\end{equation}
	pour tout \( a,u\in V\). Notons que dans le deuxième cas, il s'agit d'une limite dans \( \aL(V,\eR)\). Si \( \dim(V)=n\), alors \( \dim\aL(V,\eR)=n\) et avec un choix de base, nous pouvons trouver une matrice \( n\times n\) pour \( (d^2f)_a\).
\end{normaltext}

Soit une base \( \{ e_i \}\) de \( V\) et la base duale \( \{ e_i^* \}\) de \( \aL(V,\eR)\). Nous allons chercher la matrice de \( (d^2f)_a\) pour ces bases. L'élément de matrice
\begin{equation}
	\big[ (d^2f)_a \big]_{ij}
\end{equation}
est la composante \( e_j^*\) de \( (d^2f)_a\) appliqué à \( e_i\). Trouver cette composante \( e_j^*\) revient à appliquer l'élément \( (d^2f)_ae_i\) de \( \aL(V,\eR)\) à \( e_j\). Le calcul est donc :
\begin{subequations}
	\begin{align}
		\big[ (d^2f)_{a} \big]_{ij} & =\big( (d^2f)_ae_i \big)(e_j)                                      \\
		                            & =\Dsdd{ df_{a+te_i}(e_j) }{t}{0}       \label{SUBEQooDRZFooAuuaad} \\
		                            & =\Dsdd{    \Dsdd{ f(a+te_i+se_j) }{s}{0}    }{t}{0}                \\
		                            & =\frac{ \partial^2f }{ \partial x_i\partial x_j }(a).
	\end{align}
\end{subequations}
Attention : le passage à \eqref{SUBEQooDRZFooAuuaad} n'est pas une trivialité. Le fait est que si \( t\mapsto A(t)\) est une application continue \( \eR\to \aL(V,\eR)\) alors
\begin{equation}
	\lim_{t\to 0} \big( A(t)v \big)=\big( \lim_{t\to 0} A(t) \big)v.
\end{equation}

Donc la matrice de \( d^2f  \) est la matrice des dérivées secondes. Il s'agit d'une matrice symétrique par le théorème de Schwarz~\ref{Schwarz}.

\begin{normaltext}      \label{NORMooZAOEooGqjpLH}
	Si \( a\in V\), nous pouvons aussi voir \( (d^2f)_a\) comme une forme bilinéaire sur \( V\) grâce à la proposition~\ref{isom_isom}. Si \( u,v\in V\) nous notons
	\begin{equation}
		(d^2f)_a(u,v)=(d^2f)_a(u)v.
	\end{equation}
	À droite, il s'agit de la définition réelle de \( d^2f\) sans abus de notations, et à gauche, il s'agit d'une notation. Cette application bilinéaire \( (d^2f)_a\in \aL^{(2)}(V,\eR)\) a pour matrice symétrique la matrice des dérivées secondes calculées en \( a\).
\end{normaltext}

\begin{example} \label{ExZHZYcNH}
	Voyons comment la différentielle seconde fonctionne entre deux espaces vectoriels. Soient deux espaces vectoriels de dimension finie \( V\) et \( W\). Pour que les choses soient claires, nous avons :
	\begin{subequations}
		\begin{align}
			f    & \colon V\to W                          \\
			df   & \colon V\to \aL(V,W)                   \\
			d^2f & \colon V\to \aL\Big( V,\aL(V,W) \Big).
		\end{align}
	\end{subequations}
	Si \( a\in V\), alors \( (d^2f)_a\) est une application \( V\to \aL(V,W)\). Il faut donc l'appliquer à \( u\in V\) et ensuite à \( v\in V\) pour obtenir un élément de \( W\) :
	\begin{subequations}
		\begin{align}
			(d^2f)_a(u)v & =\Dsdd{ df_{a+tu} }{t}{0}v                        \\
			             & =\Dsdd{ df_{a+tu}(v) }{t}{0}                      \\
			             & =\Dsdd{ \Dsdd{ f(a+tu+sv) }{s}{0} }{t}{0}         \\
			             & =\frac{ \partial^2f }{ \partial u\partial v }(a).
		\end{align}
	\end{subequations}


	Par conséquent nous voyons
	\begin{equation}\label{EqQHINNtD}
		\begin{aligned}
			d^2f\colon V & \to \aL^{(2)}(V,W)                                 \\
			d^2f_a(u,v)  & =\frac{ \partial^2f  }{ \partial u\partial v }(a).
		\end{aligned}
	\end{equation}

	Dans le cas d'une fonction \( f\colon \eR\to \eR\), nous avons une seule direction et par linéarité de \eqref{EqQHINNtD} par rapport à \( u\) et \( v\), nous avons
	\begin{equation}        \label{EQooSOCGooIiNGmG}
		d^2f_a(u,v)=f''(a)uv
	\end{equation}
	où les produits sont des produits usuels dans \( \eR\) et \( f''\) est la dérivée seconde usuelle.
\end{example}

Tout ceci est un peu résumé dans la proposition suivante.
\begin{proposition}     \label{PROPooFWZYooUQwzjW}
	Soit une fonction \( f\colon \eR^n\to \eR\) de classe \( C^2\). Alors en désignant par \( H_af\) sa matrice hessienne au point \( a\) nous avons
	\begin{equation}
		(d^2f)_a(u,v)=\frac{ \partial^2f }{ \partial u\partial v }(a)=\langle (H_af)u, v\rangle
	\end{equation}
	pour tout \( u,v\in \eR^n\).
\end{proposition}

\begin{proof}
	La première égalité est l'équation \eqref{EQooSOCGooIiNGmG} déjà faite. Pour la seconde, il faut se rappeler du lien entre dérivée partielle et dérivée directionnelle, donné en le lemme~\ref{LemdfaSurLesPartielles}. En particulier ici nous avons
	\begin{equation}
		\frac{ \partial^2f }{ \partial u\partial v }=\sum_{kl}\frac{ \partial^2f }{ \partial x_k\partial x_l  }(a)u_kv_l=\langle (H_af)u, v\rangle .
	\end{equation}
\end{proof}

En particulier, la matrice hessienne \( H_af\) est symétrique et donc diagonalisable (théorème spectral~\ref{ThoeTMXla}). Si \( e_i\) est un vecteur propre unitaire pour la valeur propre \( \lambda_i\) nous avons
\begin{equation}
	(d^2f)_a(e_i,e_i)=\langle (H_af)e_i, e_i\rangle =\lambda\langle e_i, e_i\rangle =\lambda.
\end{equation}

Enfin pour celles qui aiment les notations matricielles de tout poil, il y a cette façon-ci d'écrire :
\begin{equation}
	(d^2f)_a(\alpha,\beta)=\begin{pmatrix}
		\alpha & \beta
	\end{pmatrix}\begin{pmatrix}
		\partial^2_xf(a)    & \partial^2_{xy}f(a) \\
		\partial^2_{xy}f(a) & \partial^2_yf(a)
	\end{pmatrix}\begin{pmatrix}
		\alpha \\
		\beta
	\end{pmatrix}.
\end{equation}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Ordre supérieur}
%---------------------------------------------------------------------------------------------------------------------------

Intuitivement, une fonction est de classe \( C^p\) si elle est \( p\) fois continûment différentiable. Cela est la définition \ref{DefPNjMGqy}.


Ce qui est terrible avec les différentielles d'ordre supérieurs, c'est l'emboîtement des espaces. Pour une fonction \( f\colon E\to F\), nous allons souvent poser
\begin{subequations}
	\begin{align}
		V_0     & =F           \\
		V_{k+1} & =\aL(E,V_k),
	\end{align}
\end{subequations}
de telle sorte à avoir
\begin{equation}
	df\colon E\to \aL(E,F)=V_1
\end{equation}
et
\begin{equation}
	d^2f\colon E\to \aL(E,V_1)=V_2,
\end{equation}
ce qui donne en général
\begin{equation}
	d^kf\colon E\to \aL(E,v_{k-1})=V_k.
\end{equation}

La proposition suivante lie une bonne fois pour toute dérivée et différentielle dans le cadre de fonctions \( \eR\to \eR\).
\begin{proposition}[\cite{MonCerveau}]      \label{PROPooCNDHooKRwils}
	Une fonction \( f\colon \eR\to \eR\) est de classe \( C^p\) si et seulement si elle est \( p\) fois continûment dérivable.
\end{proposition}

\begin{proof}
	Nous commençons par poser un certain nombre de notations. Comme souvent nous posons \( V_0=\eR\) et
	\begin{equation}
		V_{k+1}=\aL(\eR,V_k).
	\end{equation}
	De plus nous considérons \( M_1\in \aL(\eR,\eR)\) donnée par \( M_1(t)=t\). Et par récurrence
	\begin{equation}
		M_{k+1}(t)=tM_{k}.
	\end{equation}
	Nous avons \( M_1\in V_1\) et \( M_k\colon \eR\to V_{k-1}\), c'est-à-dire \( M_k\in V_k\).

	Les formules que nous allons prouver sont que d'une part,
	\begin{equation}
		df_a=f'(a)M_1.
	\end{equation}
	et que d'autre part, plus généralement,
	\begin{equation}
		(d^kf)_a=f^{(k)}(a)M_k.
	\end{equation}

	En plusieurs parties et par récurrence.
	\begin{subproof}
		\spitem[Si \( f\) est continûment dérivable, alors \( f\) est \( C^1\) ]
		Nous montrons que l'application \( T\) donnée par \( T(h)=hf'(a)\) vérifie la condition pour être la différentielle de \( f\) en \( a\) :
		\begin{equation}        \label{EQooCPWKooWdgbED}
			\frac{ f(a+h)-f(a)-f'(a)h }{ \| h \| }=\frac{ f(a+h)-f(a) }{ \| h \| }-1_hf'(a).
		\end{equation}
		où nous avons noté \( 1_h\) le vecteur unité dans la direction de \( h\), c'est-à-dire \( 1_h=h/\| h \|\). Vu que \( h\in \eR\), c'est simplement
		\begin{equation}
			1_h=\begin{cases}
				1  & \text{si } h>0 \\
				-1 & \text{si }h<0
			\end{cases}
		\end{equation}
		et nous ne définissons pas \( 1_h\) si \( h=0\).

		C'est le moment de prendre la limite de \eqref{EQooCPWKooWdgbED} pour \( h\to 0^+\) et \( h\to 0^-\) séparément. Lorsque \( h\to 0^+\), nous avons \( \| h \|=h\) et \( 1_h=1\). Vu que \( f\) est supposée dérivable, la limite du quotient existe et vaut \( f'(a)\). Donc le tout a une limite nulle :
		\begin{equation}
			\lim_{h\to 0^+} \frac{ f(a+h)-f(a)-f'(a)h }{ \| h \| }=\lim_{h\to 0^+}\frac{ f(a+h)-f(a) }{  h  }-f'(a)=0.
		\end{equation}
		En ce qui concerne la limite \( h\to 0^-\), nous avons \( \| h \|=-h\) et \( 1_h=-1\), et à nouveau une limite nulle. La proposition \ref{PROPooGDDJooDCmydE} nous permet alors de conclure que la limite existe et est nulle. Les limites à gauche et à droite étant nulles, la limite existe et est nulle par la proposition \ref{PROPooGDDJooDCmydE}.

		\spitem[Si \( f^{(p)}\) est continue alors \( d^pf\) aussi]
		Nous passons à la récurrence de notre preuve. Sous l'hypothèse que \( f^{(p)}\) existe et est continue, nous allons montrer que \( d^pf\) existe, est continue et vaut
		\begin{equation}
			(d^pf)_a=f^{(p)}(a)M_p.
		\end{equation}
		Soit \( k<p\) tel que ce soit bon (pour \( k=1\) c'est déjà fait). Nous avons \( (d^kf)_a=f^{(k)}(a)M_k\), et pour prouver que \( (d^{k+1}f)_a=f^{(k+1)}(a)M_{k+1}\) nous l'y mettons dans la définition de la différentielle. Nous avons :
		\begin{equation}
			\frac{ (d^kf)_{a+h}-(d^kf)_a-f^{(k+1)}(a)M_{k+1}(h) }{ \| h \| }=\frac{ f^{(k)}(a+h)M_k-f^{(k)}(a)M_k-hf^{(k+1)}(a)M_k }{ \| h \| }.
		\end{equation}
		La limite \( h\to 0\) est une limite dans \( V_k\), et elle se traite comme précédemment. Elle vaut zéro parce que \( f^{(k+1)}\) est la dérivée de \( f^{(k)}\). Cela justifie les faits que \( d^kf\) est différentiable en \( a\) et que la différentielle est donné par la formule voulue.

		Par hypothèse, \( k+1\leq p\), donc \( f^{(k+1)}\) est continue. Par conséquent l'application \( a\mapsto f^{(k+1)}(a)M_{k+1}\) est continue.

		\spitem[Si \( f\) est de classe \( C^1\) alors \( f'\) existe et est continue]
		Dire que \( f\) est de classe \( C^1\) revient à dire que la différentielle \( df\colon \eR\to \aL(\eR,\eR)\) existe et est continue. Soyons conscient que \( df_a(\epsilon)=\epsilon df_a(1)\) et calculons
		\begin{equation}
			\frac{ f(a+\epsilon)-f(a)-df_a(\epsilon) }{ \epsilon }=\frac{ f(a+\epsilon)-f(a) }{ \epsilon }-df_a(1).
		\end{equation}
		La définition de la différentielle est que la limite de cela pour \( \epsilon\to 0\) soit nulle. Cela implique que la limite suivante existe et vaut
		\begin{equation}
			\lim_{\epsilon\to 0}\frac{ f(a+\epsilon)-f(a) }{ \epsilon }=df_a(1).
		\end{equation}
		Nous avons prouvé que \( f'(a)=df_a(1)\).

		La fonction \( a\mapsto df_a\) est continue. Pouvons-nous en déduire que \( f'\) est continue ? Nous avons
		\begin{equation}
			f'=ev_1\circ df
		\end{equation}
		où \( ev_1\) est l'application d'évaluation dont le lemme \ref{LEMooWFNXooLyTyyX} a déjà donné la continuité. Donc \( f'\) est continue comme composée d'applications continues.
		\spitem[\( f\) est \( C^p\). Récurrence]
		Nous supposons que \( f\) est de classe \( C^p\), et nous allons montrer par récurrence que \( f^{(k)}\) existe et est continue pour tout \( k\leq p\). Posons exactement l'énoncé de notre récurrence.

		Pour \( k=1\) c'est fait. Nous supposons que la formule soit correcte pour un certain \( k< p\) et nous y allons pour \( k+1\). Nous avons
		\begin{subequations}        \label{SUBEQSooUPLAooQhueCl}
			\begin{align}
				\frac{ (d^kf)(a+h)-(d^kf)(a)-f^{(k+1)}(a)M_{k+1}(h) }{ \| h \| } & =\frac{ \big[ f^{(k)}(a+h)-f^k(a)-hf^{(k+1)}(a) \big]M_k  }{ \| h \| }       \\
				                                                                 & =\big[ \frac{ f^{(k)}(a+h)-f^{(k)}(a) }{ \| h \| }-1_hf^{(k+1)}(a) \big]M_k.
			\end{align}
		\end{subequations}
		où nous avons aussi tenu compte que \( M_{k+1}(h)=hM_k\).

		C'est le moment de calculer séparément les limites \( h\to 0^+\) et \( h\to 0^-\). Cela fonctionne comme toutes les autres fois.
	\end{subproof}
\end{proof}

Soit une fonction \( f\colon \eR^n\to \eR\) différentiable \( l\) fois. L'application
\begin{equation}
	d^lf\colon \eR^n\to \aL\Big( \eR^n,\aL\big( \eR^n,\aL(\ldots) \big) \Big)
\end{equation}
au point \( x\) appliquée à \( v^{(1)}\) appliquée au point \( v^{(2)}\), \ldots, appliquée à \( v^{(l)}\) est notée
\begin{equation}        \label{EQooITOLooQllUlJ}
	(d^lf)_x(v^{(1)},\ldots ,v^{(l)})\in \eR.
\end{equation}

\begin{proposition}     \label{PROPooQKZIooXTvkIr}
	Soit une fonction \( f\colon \eR^n\to \eR\) différentiable \( l\) fois. Avec la notation \eqref{EQooITOLooQllUlJ} nous avons
	\begin{equation}
		(d^lf)_x(v^{(1)},\ldots v^{(l)})=\sum_{k_1,\ldots, k_l}v^{(1)}_{k_1}\ldots, v_{k_l}^{(l)}\frac{ \partial^lf }{ \partial x_{k_1}\ldots \partial x_{k_l} }(x).
	\end{equation}
\end{proposition}

\begin{proof}
	La preuve se fait par récurrence sur \( l\), en sachant que la formule est déjà vraie pour \( l=1\) et \( l=2\). Si la formule est valable pour \( l\), nous avons
	\begin{subequations}
		\begin{align}
			(d^{l+1}f)_x(v^{(1)},\ldots, v^{(l+1)}) & =\Dsdd{ (d^lf)_{x+tv^{(l+1)}}(v^{(1)},\ldots, v^{(l)}) }{t}{0}                                                                                                \\
			                                        & =\sum_{k_1\ldots k_l}v_{k_1}^{(1)}\ldots v_{k_l}^{(l)}\Dsdd{   \frac{ \partial^lf }{ \partial x_{k_1}\ldots \partial x_{k_l} }(x+tv^{l+1})   }{t}{0}          \\
			                                        & =\sum_{k_1\ldots k_l}v_{k_1}^{(1)}\ldots v_{k_l}^{(l)}\sum_i\frac{ \partial  }{ \partial x_i }\frac{ \partial^lf }{ \partial x_{k_1}\ldots \partial x_k }(x).
		\end{align}
	\end{subequations}
	Cela donne le résultat attendu.
\end{proof}

\begin{normaltext}
	La formule de la proposition~\ref{PROPooQKZIooXTvkIr} nous permet d'écrire de jolies formules comme
	\begin{equation}        \label{EQooXRWWooMoKoOB}
		(d^3f)_x(h,h,h)=\sum_{ijk}h_ih_jh_k(\partial^3_{ijk}f)(x).
	\end{equation}
\end{normaltext}

À mon avis la proposition \ref{PROPooYGJDooOqibbh} se fait par récurrence avec \ref{Schwarz}.		%ooKETRooWoFqfK

\begin{proposition}[\cite{MonCerveau}]		\label{PROPooYGJDooOqibbh}
	Soit un espace vectoriel \( V\). Si \(f \colon \eR^n\to  V  \) est une application de classe \( C^m\), alors pour tout \( p\leq m\) nous pouvons permuter les dérivées partielles. Plus précisément, si \( i_1,\ldots, i_p\) sont dans \(\{ 1,\ldots,n \} \) et si \( \sigma\in S_p\), nous avons
	\begin{equation}
		\partial_{i_1}\ldots \partial_{i_p}f=\partial_{i_{\sigma(1)}}\ldots \partial_{i_{\sigma(p)}}f.
	\end{equation}
	% quand c'est prouvé, retirer la ligne ooKETRooWoFqfK.
	% à mon avis ça se démontre avec une récurrence avec \ref{Schwarz}.
	% TODOooSNREooUoYTGp. Prouver ça.
\end{proposition}


\ssdem
