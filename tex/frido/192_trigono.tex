% This is part of (everything) I know in mathematics
% Copyright (c) 2011-2022
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Pavages du plan}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}      \label{DEFooHPKFooSIDhCM}
	Une application affine \( f\colon \eR^n\to \eR^n\) est un \defe{déplacement}{déplacement} lorsqu'elle est une isométrie de \( (\eR^n,d)\) qui préserve l'orientation\footnote{Définition \ref{DEFooOTFPooIVkHFP}.}.
\end{definition}

\begin{definition}[\cite{NHXUsTa}]      \label{DEFooJPHKooRgCBJs}
	Un \defe{pavage}{pavage du plan} de \( \eR^2\) est une paire \( (G,K)\) où \( G\) est un groupe de déplacements\footnote{Définition \ref{DEFooHPKFooSIDhCM}.} de \( \eR^2\) et \( K\) un compact de \( \eR^2\) d'intérieur non vide telle que
	\begin{enumerate}
		\item
		      \( G\cdot K=\eR^2\),
		\item       \label{ITEMooOIJZooZMKLUm}
		      Si \( g_1,g_2\in G\) satisfont \( g_1\cdot \Int(K)\cap g_2\cdot\Int(K)\neq 0\), alors \( g_1\cdot K=g_2\cdot K\).
	\end{enumerate}
	Nous disons qu'un groupe \( G\) de déplacements de \( \eR^2\) est un \defe{groupe de pavage}{groupe de pavage} de \( \eR^2\) si il existe un compact \( K\) tel que la paire \( (G,K)\) soit un pavage.
\end{definition}

En termes de notations,
\begin{equation}
	G\cdot K=\bigcup_{g\in G}g(K)=\bigcup_{g\in G}\bigcup_{k\in K}g(k).
\end{equation}

\begin{lemma}[\cite{MonCerveau}]        \label{LEMooWZSWooZYkICn}
	Soient une bijection affine \( \varphi\colon \eR^2\to \eR^2\) ainsi qu'une droite \( d\) et un point \( A\). Nous notons \( S\) la partie de \( \eR^2\) située du côté de \( d\) contenant \( A\).

	Alors \( \varphi(S)\) est la partie de \( \eR^2\) située du côté de \( \varphi(d)\) contenant \( \varphi(A)\).
\end{lemma}

\begin{proof}
	La droite \( d\) est donnée par une application affine \( f\colon \eR^2\to \eR\) et la définition
	\begin{equation}
		f=\{ x\in \eR^2\tq f(x)=0 \}.
	\end{equation}
	Nous supposons que \( f(A)>0\); sinon, nous pouvons utiliser \( -f\) au lieu de \( f\). Donc
	\begin{equation}
		S=\{ x\in \eR^2\tq f(x)>0 \}.
	\end{equation}
	La partie \( \varphi(S)\) est alors donnée par
	\begin{equation}
		\varphi(S)=\{ \varphi(x)\tq f(x)>0 \}.
	\end{equation}
	Comme \( \varphi\) est une bijection, cela s'écrit aussi bien
	\begin{equation}
		\varphi(S)=\{ y\in \eR^2\tq f\big( \varphi^{-1}(y) \big)>0 \}.
	\end{equation}
	De même
	\begin{equation}
		\varphi(d)=\{ s\in \eR^2\tq f\big( \varphi^{-1}(s) \big)=0 \}.
	\end{equation}
	Donc les deux côtés de la droite \( \varphi(d)\) sont donnés par le signe de \( f\circ \varphi^{-1}\). Nous avons
	\begin{equation}
		(f\circ\varphi^{-1})\big( \varphi(A) \big)=f(A)>0.
	\end{equation}
	Donc \( \varphi(A)\in \varphi(S)\).
\end{proof}

\begin{lemma}           \label{LEMooZOXVooTJiLTF}
	Le groupe
	\begin{equation}
		G=\gr(\tau_{e_1}, \tau_{e_2})
	\end{equation}
	est un groupe de pavage du plan.
\end{lemma}

\begin{proof}
	Il suffit de prendre le carré \( K=\mathopen[ 0 , 1 \mathclose]\times \mathopen[ 0 , 1 \mathclose]\). En appliquant les translations, nous recouvrons tout le plan, sans intersection des intérieurs des carrés. Notons toutefois qu'il y a un recouvrement des bords.
\end{proof}

\begin{lemma}[\cite{MonCerveau, BIBooWIEGooJlwsCW}]    \label{LEMooTMRGooChBzZg}
	Le groupe
	\begin{equation}
		G=\gr(\tau_{e_1}, \tau_{e_2}, R_0(\pi))
	\end{equation}
	est un groupe de pavage du plan.
\end{lemma}

\begin{proof}
	Le compact à considérer est \( K=\mathopen[ 0 , \frac{ 1 }{2} \mathclose]\times \mathopen[ 0 , 1 \mathclose]\). Le compact \( K\) et son image par \( R_0(\pi)\) sont représentés sur la figure \ref{LabelFigATJSooefYkmCbP}. % From file ATJSooefYkmCbP

	En agissant sur \( K\) avec les translations verticales et horizontales, nous recouvrons des bandes verticales de largeur \( 1/2\). En agissant de même sur \( R_0(\pi)(K) \), nous recouvrons les autres bandes verticales.

	Donc \( G\cdot K\) recouvre bien \( \eR^2\). Il serait cependant un peu présomptueux de croire en avoir fini. Il faut vérifier la condition \ref{ITEMooOIJZooZMKLUm} de la définition \ref{DEFooJPHKooRgCBJs} d'un pavage.

	Supposons que \( g_1\cdot\Int(K)\cap g_2\cdot \Int(K)\neq \emptyset\). Cela signifie qu'il existe \( k_1,k_2\in \Int(K)\) tels que \( g_1(k_1)=g_2(k_2)\), ou encore que
	\begin{equation}        \label{EQooITJEooUkUKuu}
		(g_2^{-1}g_1)k_1=k_2\in \Int(K).
	\end{equation}

	Quelle est la forme d'un élément général de \( G\) ? Le lemme \ref{LemFUIZooBZTCiy} nous indique qu'un élément général de \( G\) est un produit fini de \( \tau_{e_1}\), \( \tau_{e_2}\) et \( R_0(\pi)\). Mais nous savons que si \( \alpha\) est linéaire,
	\begin{equation}
		\alpha\circ \tau_u=\tau_{\alpha(u)}\circ \alpha.
	\end{equation}
	Dans notre cas, dans un produit général, nous pouvons déplacer tous les facteurs \( R_0(\pi)\) à droite en changeant des \( \tau_{e_i}\) en \( \tau_{R_0(\pi)e_i}=\tau_{-e_i}\). Les translations par contre commutent sans faire d'histoires. Donc un élément général de \( G\) est de la forme
	\begin{equation}
		g=\tau_{e_1}^k\tau_{e_2}^lR_0(\pi)^m
	\end{equation}
	Nous pouvons évidemment restreindre \( m\) à \( \{ 0,1 \}\). Supposons \( k\in \Int(K)\) et \( g(k)\in \Int(K)\). Nous avons \( 0<k_x<0.5\). Si \(m=1 \), alors \( g(k)_x\in\mathopen] -1/2 , 0 \mathclose[\) et aucun \( \tau_{e_1}^kg(k)_x\) ne pourra plus être entre \( 0\) et \( 1/2\). Donc \( m=0\). À partir de là, pour avoir \( g(k)\in \Int(K)\) nous devons avoir également \( k=l=0\). Donc \( g=\id\).

	Deux éléments \( g_1\) et \( g_2\) vérifiant la condition \eqref{EQooITJEooUkUKuu} doivent donc vérifier \( g_2^{-1}g_1=\id\), et donc \( g_1=g_2\). Par conséquent \( g_1\cdot K=g_2\cdot K\).
\end{proof}

\newcommand{\CaptionFigATJSooefYkmCbP}{Le compact \( K\) et son image par \( R_0(\pi)\) pour le lemme \ref{LEMooTMRGooChBzZg}.}
\input{auto/pictures_tex/Fig_ATJSooefYkmCbP.pstricks}

\begin{lemma}[\cite{MonCerveau, BIBooWIEGooJlwsCW}]         \label{LEMooJPNDooHDCLnY}
	Le groupe
	\begin{equation}
		\gr(\tau_{e_1}, \tau_{e_2}, R_0(\pi/2))
	\end{equation}
	est un groupe de pavage.
\end{lemma}

\begin{proof}
	Le pavé à considérer est
	\begin{equation}
		K=\mathopen[ -\frac{ 1 }{2} , 0 \mathclose]\times \mathopen[ 0 , \frac{ 1 }{2} \mathclose].
	\end{equation}
	En lui appliquant trois fois la rotation \( R_0(\pi/2)\), nous reconstituons le carré \( \mathopen[ -\frac{ 1 }{2} , \frac{ 1 }{2} \mathclose]\times \mathopen[ -\frac{ 1 }{2} , \frac{ 1 }{2} \mathclose]\). Ensuite, avec les translations, nous pavons tout le plan.

	Pour la seconde condition, nous procédons comme dans la démonstration du lemme \ref{LEMooTMRGooChBzZg}. D'abord \( R_0(\pi/2)e_1=e_2\) et \( R_0(\pi/2)e_2=-e_1\). Donc dans un produit général de \( \tau_{e_1}\), \( \tau_{e_2}\) et \( R_0(\pi/2)\) (et de leurs inverses), toutes les rotations peuvent être mises à droite; nous avons donc un élément général de \( G\) sous la forme
	\begin{equation}
		g=\tau_a\circ R_0(\pi/2)^k
	\end{equation}
	avec \( a\in \eZ e_1+\eZ e_2\) et \( k\in \{ 0,1,2,3 \}\).

	Vu que les translations se font par nombres entiers tandis que les différences de coordonnées entre les \( R_0(\pi/2)^kK\) sont demi-entiers, si \( k\in \Int(K)\), alors aucun \( \tau_a\) ne permet d'avoir \( (\tau_a\circ R_0(\pi/2))k\in \Int(K)\).

	Bref, si \( (g_2^{-1}g_1)k\in K\), alors encore une fois \( g_2^{-1}g_1=\id\).
\end{proof}

Et c'est maintenant que les choses compliquées commencent.

\begin{lemma}       \label{LEMooMWWEooEbZXtb}
	Le groupe
	\begin{equation}
		\gr\big( \tau_{e_1},\tau_{(-\frac{ 1 }{2},\frac{ \sqrt{ 3 } }{2})},R_0(\pi/3) \big)
	\end{equation}
	est un groupe de pavage.
\end{lemma}

\begin{proof}
	Ici le compact \( K\) est le triangle de sommets \( A=(0,0)\), \( B=(\frac{ 1 }{2},\frac{ \sqrt{ 3 } }{ 6 })\) et \( C=(1,0)\). Plus précisément il s'agit de l'intersection des trois parties suivantes :
	\begin{itemize}
		\item le côté de la droite \( (AB)\) où est \( C\),
		\item le côté de la droite \( (AC)\) où est \( B\),
		\item le côté de la droite \( (BC)\) où est \( A\).
	\end{itemize}
	Il est bon d'écrire ces trois conditions sous forme d'inéquations.
	\begin{itemize}
		\item La droite \( AB\) est donnée par l'équation \( f_{AB}(x,y)=0\) pour \( f_{AB}(x,y)=x-\sqrt{ 3 }y\). Puisque \( f_{AB}(C)=1\), la première inéquation pour \( K\) est
		      \begin{equation}
			      x-\sqrt{ 3 }y\geq 0.
		      \end{equation}
		\item
		      Pour la droite \( (BC)\) nous avons \( f_{BC}(x,y)=-x-\sqrt{ 3 }y+1\) et \( f_{BC}(A)=1\). Donc la seconde inéquation pour \( K\) est
		      \begin{equation}
			      -x-\sqrt{ 3 }y+1\geq 0
		      \end{equation}
		\item
		      La droite \( AC\) est donnée par l'application \( f_{AC}(x,y)=y\). Vu que \( f_{AC}(B)=\sqrt{ 3 }/6\), nous avons la troisième inéquation pour \( K\):
		      \begin{equation}
			      y\geq 0.
		      \end{equation}
	\end{itemize}
	En résumé, la définition de \( K\) est le système
	\begin{subequations}        \label{SUBEQSooECKFooOdneOA}
		\begin{numcases}{}
			x-\sqrt{ 3 }y\geq 0\\
			-x-\sqrt{ 3 }y+1\geq 0\\
			y\geq 0.
		\end{numcases}
	\end{subequations}

	La figure  \ref{LabelFigPWMCooGWYCczZnssLabelSubFigPWMCooGWYCczZn0} nous montre ce triangle et l'action des puissances de \( R_0(\pi/3)\) sur lui. Pour votre gouverne, la matrice de cette rotation est
	\begin{equation}        \label{EQooMRRXooTebLlt}
		R_0(\pi/3)=\begin{pmatrix}
			1/2          & -\sqrt{ 3 }/2 \\
			\sqrt{ 3 }/2 & 1/2
		\end{pmatrix}.
	\end{equation}
	La figure \ref{LabelFigPWMCooGWYCczZnssLabelSubFigPWMCooGWYCczZn2} vous montre une partie de ce pavage dans toute sa splendeur.

	Puisque les translations sont \( u_1=e_1\) et \( u_2=(\frac{ 1 }{2}, \frac{ \sqrt{ 3 } }{2})\), il est suffisant de montrer que notre pavage pave réellement le parallélogramme construit sur ces deux vecteurs. Nous vous avons très obligeamment dessiné ce parallélogramme pavé sur la figure  \ref{LabelFigPWMCooGWYCczZnssLabelSubFigPWMCooGWYCczZn1}.

	Pour montrer que les triangles dessinés pavent effectivement le parallélogramme, nous allons procéder à une exhaustion de cas. Soit \( (x,y)\) dans le parallélogramme.

	Nous commençons par couper le parallélogramme en deux parties suivant la diagonale allant de \( u_1\) à \( u_2\). Dans la vie mon p'ti gars, il y a deux types de points : ceux qui vérifient \( x+\frac{1}{ \sqrt{ 3 }}y-1\leq 0\) et les autres.

	\begin{subproof}
		\item[Si \( x+y/\sqrt{ 3 }-1\leq 0\)]
		Ceci est le côté de \( (0,0)\). Nous subdivisons suivant la petite barre verticale (suivez le dessin), c'est-à-dire suivant les deux cas : \( x\geq \frac{ 1 }{2}\) et \( x\leq \frac{ 1 }{2}\).
		\begin{subproof}
			\item[Si \( x\leq \frac{ 1 }{2}\)]
			Enfin nous coupons avec la droite diagonale partant de \( (0,0)\), c'est-à-dire selon que \( x-\sqrt{ 3 }y\leq 0\) ou \( x-\sqrt{ 3 }y\geq 0\).
			\begin{subproof}
				\item[Si \( x-\sqrt{ 3 }y\leq 0\)]
				Les points dont nous parlons sont les \( (x,y)\in \eR^2\) vérifiant
				\begin{subequations}        \label{SUBEQSooNYWDooYMNVad}
					\begin{numcases}{}
						x+\frac{1}{ \sqrt{ 3 } }y-1\leq 0\\
						x\leq \frac{ 1 }{2}\\
						x-\sqrt{ 3 }y\leq 0.
					\end{numcases}
				\end{subequations}
				En suivant le dessin, vous remarquerez que l'élément de \( G\) à considérer est
				\begin{equation}
					g=\tau_{e_1}\circ \tau_{(-\frac{ 1 }{2},\frac{ \sqrt{ 3 } }{2})}\circ R_0(\pi/3)^4.
				\end{equation}
				Nous avons
				\begin{subequations}        \label{EQSooOJBFooCTaTtu}
					\begin{align}
						g(A) & =\big( \frac{ 1 }{2},\frac{ \sqrt{ 3 } }{2} \big)   \\
						g(B) & =\big( \frac{ 1 }{2},\frac{ \sqrt{ 3 } }{ 6 } \big) \\
						g(C) & =(0,0).
					\end{align}
				\end{subequations}
				Ce que les équations \eqref{SUBEQSooNYWDooYMNVad} décrivent est l'intersection des trois parties suivanteas\quext{Personnellement, je n'ai pas vérifié, mais ça m'étonnerait que ce soit faux. Vérifiez et écrivez-moi.} :
				\begin{itemize}
					\item le côté de la droite \( \big( g(A)g(B)\big)\) contenant \( g(C)\),
					\item le côté de la droite \( \big( g(A)g(C)\big)\) contenant \( g(B)\),
					\item le côté de la droite \( \big( g(B)g(C)\big)\) contenant \( g(A)\),
				\end{itemize}
				Le lemme \ref{LEMooWZSWooZYkICn} nous permet d'exprimer ces trois parties en termes de \( K\) :
				\begin{itemize}
					\item l'image par \( g\) du côté de la droite \( (AB)\) contient \( C\),
					\item l'image par \( g\) du côté de la droite \( (AC)\) contient \( B\),
					\item l'image par \( g\) du côté de la droite \( (BC)\) contient \( A\),
				\end{itemize}
				Comme \( g\) est une bijection, l'intersection des images par \( g\) est l'image par \( g\) de l'intersection. Bref, les équations \eqref{EQSooOJBFooCTaTtu} décrivent l'image par \( g\) de \( K\).

				Cette partie est donc pavée par \( (G,K)\).
				\item[Si \( x-\sqrt{ 3 }y\geq 0\)]
                    hop, même calculs avec des petites variations. Nous laissons \randomGender{le lecteur}{la lectrice} s'en occuper.
			\end{subproof}

			\item[Si \( x\geq \frac{ 1 }{2}\)]
			hop.
		\end{subproof}
		\item[Si \( x+y/\sqrt{ 3 }-1\geq 0\)]
		hop.
	\end{subproof}
	Les cas listés se traitent surement de la même façon. Nous tenons pour prouvé que \( (G,K)\) est bien surjectif sur \( \eR^2\).

	Nous devons encore montrer la condition \ref{ITEMooOIJZooZMKLUm} de la définition \ref{DEFooJPHKooRgCBJs}. Commençons par déterminer la forme générale d'un élément de \( G\) sous la forme \( \tau_a\circ r_0\) où \( r_0\) est une application linéaire. Le lemme \ref{LemFUIZooBZTCiy} nous indique qu'un élément général de \( G=\gr(\tau_{e_1}, \tau_{(\frac{ 1 }{2},\frac{ \sqrt{ 3 } }{2})}, R_0(\pi/3))\) est un produit arbitraire (mais fini) de \( \tau_{e_1}\), \( \tau_{(\frac{ 1 }{2},\frac{ \sqrt{ 3 } }{2})}\) et de \( R_0(\pi/3)\) et de leurs inverses.

	Comme toujours nous avons \( \alpha\circ\tau_v=\tau_{\alpha(v)}\circ \alpha\). Donc nous pouvons passer toutes les rotations \( R_0(\pi/3)\) et \( R_0(\pi/3)^{-1}\) à droite du produit, quitte à produire des translations des formes suivantes :
	\begin{subequations}
		\begin{align}
			R_0(\pi/3)^ke_1                                              \\
			R_0(\pi/3)^k\big( \frac{ 1 }{2},\frac{ \sqrt{ 3 } }{2} \big) \\
			R_0(\pi/3)^{-k}e_1                                           \\
			R_0(\pi/3)^{-k}\big( \frac{ 1 }{2},\frac{ \sqrt{ 3 } }{2} \big).
		\end{align}
	\end{subequations}
	En utilisant la matrice \eqref{EQooMRRXooTebLlt} nous trouvons assez vite que
	\begin{subequations}        \label{SUBEQooEMVIooNaaMqk}
		\begin{align}
			R_0(\pi/3)e_1   & =\begin{pmatrix}
				1/2 \\
				\sqrt{ 3 }/2
			\end{pmatrix} \\
			R_0(\pi/3)^2e_1 & =\begin{pmatrix}
				-1/2 \\
				\sqrt{ 3 }/2
			\end{pmatrix} \\
			R_0(\pi/3)^3e_1 & =-e_1.
		\end{align}
	\end{subequations}
	Les applications suivantes de \( R_0(\pi/3)\) ne donnent rien de nouveau, si ce n'est le signe. Les puissances de \( R_0(\pi/3)\) appliquées à \( \big( \frac{ 1 }{2},\frac{ \sqrt{ 3 } }{2} \big)\) sont déjà parmi celles listées en \eqref{SUBEQooEMVIooNaaMqk}. Quant aux inverses, \( R_0(\pi/3)^{-1}=R_0(\pi/3)^5\); donc rien de nouveau non plus.

	Un élément général de \( G\) est donc dans
	\begin{equation}
		\tau_v\circ R_0(\pi/3)^k
	\end{equation}
	avec \( v\) dans
	\begin{equation}
		\eZ e_1+\eZ\begin{pmatrix}
			1/2 \\
			\frac{ \sqrt{ 3 } }{2}
		\end{pmatrix}
		+\eZ\begin{pmatrix}
			-1/2 \\
			\frac{ \sqrt{ 3 } }{2}
		\end{pmatrix}.
	\end{equation}
	Remarquons que
	\begin{equation}
		\begin{pmatrix}
			-1/2 \\
			\sqrt{ 3 }/2
		\end{pmatrix}=-e_1+\begin{pmatrix}
			1/2 \\
			\sqrt{ 3 }/2
		\end{pmatrix}.
	\end{equation}
	Donc un élément général de \( G\) est
	\begin{equation}
		\tau_{e_1}^k\circ \tau_{(-\frac{ 1 }{2},\frac{ \sqrt{ 3 } }{2})}^l\circ R_0(\pi/3)^m.
	\end{equation}

	Nous pouvons maintenant prouver notre point. Pour cela nous allons successivement considérer les \( 5\) rotations de \( K \) présentées dans la sous-figure \ref{LabelFigPWMCooGWYCczZnssLabelSubFigPWMCooGWYCczZn0}. Pour chacune nous allons montrer qu'aucune translation ne permet d'obtenir une intersection avec \( K\).

	Nous allons en faire un seul en détail.
	\begin{subproof}
		\item[Pour \( L=R_0(\pi/3)K\)]
            hop. les détails sont laissés à notre aimable \randomGender{lecteur}{lectrice} qui ne pourra pas ne pas compléter tous les cas.
		\item[Pour \( L=R_0(\pi/3)^2K\)]
		Nous allons prouver que si \( (x,y)\in \Int(L)\), alors
		\begin{equation}
			\tau_{e_1}^k\circ \tau_{(-\frac{ 1 }{2},\frac{ \sqrt{ 3 } }{2})}^l(x,y)
		\end{equation}
		ne peut pas être dans \( \Int(K)\). Pour la simplicité des notations nous notons \( r=R_0(\pi/3)^2\); nous avons
		\begin{equation}
			r=\begin{pmatrix}
				-1/2         & -\sqrt{ 3 }/2 \\
				\sqrt{ 3 }/2 & -1/2
			\end{pmatrix}.
		\end{equation}
		Nous considérons \( g=\tau_{e_1}^k\circ\tau_{(-\frac{ 1 }{2},\frac{ \sqrt{ 3 } }{2})}\circ r\). Un calcul nous donne l'image de \( (x,y)\) par \( g\) :
		\begin{equation}
			g(x,y)=\tau_{e_1}^k\circ\tau_{(-\frac{ 1 }{2},\frac{ \sqrt{ 3 } }{2})}^l\begin{pmatrix}
				-\frac{ 1 }{2}x-\frac{ \sqrt{ 3 } }{2}y \\
				-\frac{ \sqrt{ 3 } }{2}x-\frac{ 1 }{2}y
			\end{pmatrix}=\begin{pmatrix}
				-\frac{ 1 }{2}x-\frac{ \sqrt{ 3 } }{2}y+k-\frac{ 1 }{2}l \\
				\frac{ \sqrt{ 3 } }{2}x-\frac{ 1 }{2}y+\frac{ \sqrt{ 3 } }{2}l
			\end{pmatrix}.
		\end{equation}
		Nous considérons \( (x,y)\in \Int(K)\) tel que \( g(x,y)\in \Int(K)\), et nous allons trouver une contradiction. Le fait que \( (x,y)\in \Int(K)\) signifie que \( (x,y)\) satisfait les inéquations \eqref{SUBEQSooECKFooOdneOA} mais avec des inégalités strictes. Le fait que \( g(x,y)\in\Int(K)\) nous donne trois inéquations de plus. Assez rapide calcul :
		\begin{subequations}
			\begin{align}
				f_{AB}\big( g(x,y) \big) & =-2x+k-2l,                                                       \\
				f_{BC}\big( g(x,y) \big) & =-x-\sqrt{ 3 }y-k-l+1,                                           \\
				f_{AC}\big( g(x,y) \big) & =\frac{ \sqrt{ 3 } }{2}x-\frac{ 1 }{2}y+\frac{ \sqrt{ 3 } }{2}l.
			\end{align}
		\end{subequations}
		Au final, notre point \( (x,y)\) doit satisfaire le système suivant :
		\begin{subequations}
			\begin{numcases}{}
				x-\sqrt{ 3 }y> 0\label{SUBEQooQJBRooSvcvfW}\\
				-x-\sqrt{ 3 }y+1> 0\label{SUBEQooLWJQooAIQhCh}\\
				y> 0        \label{SUBEQooYCVNooHJHVWt}\\
				-2x+k-2l>0      \label{SUBEQooYYVUooORxLnp}\\
				-x-\sqrt{ 3 }y-k-l+1>0  \label{SUBEQooRRGQooYtSxso}\\
				\frac{ \sqrt{ 3 } }{2}x-\frac{ 1 }{2}y+\frac{ \sqrt{ 3 } }{2}l>0        \label{SUBEQooSNVNooVrIVVy}.
			\end{numcases}
		\end{subequations}
		Les inéquations \ref{SUBEQooYCVNooHJHVWt} et \ref{SUBEQooQJBRooSvcvfW} donnent déjà \( x>0\). De même avec \ref{SUBEQooLWJQooAIQhCh} nous trouvons \( x<1\). Voilà déjà \( x\in \mathopen] 0 , 1 \mathclose[\) qui est directement visible sur le dessin du triangle \( K\).

		Puisque \( x>0\), l'inéquation \eqref{SUBEQooYYVUooORxLnp} donne
		\begin{equation}
			k-2l>-2x+k-2l>0.
		\end{equation}
		Donc \( k-2l>0\).

		Comme \( x<1\) et \( y>0\), l'inéquation \eqref{SUBEQooSNVNooVrIVVy} donne
		\begin{equation}
			\frac{ \sqrt{ 3 } }{ 2 }+\frac{ \sqrt{ 3 } }{2}l> \frac{ \sqrt{ 3 } }{2}x-\frac{ 1 }{2}y+\frac{ \sqrt{ 3 } }{2}l>0.
		\end{equation}
		Donc \( \frac{ \sqrt{ 3 } }{2}(1+l)>0\). Comme \( l\) est entier, cela donne \( l\geq 0\).

		Enfin, de \eqref{SUBEQooRRGQooYtSxso} nous tirons
		\begin{equation}
			-k+1>-x-\sqrt{ 3 }y-k-l+1>0,
		\end{equation}
		Ce qui donne \( k<1\) et donc \( k\leq 0\).

		En résumé nous avons trouvé trois inéquations pour \( k\) et \( l\) :
		\begin{subequations}
			\begin{numcases}{}
				k\leq 0\\
				l\geq 0\\
				k-2l>0.
			\end{numcases}
		\end{subequations}
		Ce système est impossible.

		Il n'existe donc pas de translation qui, appliquée à \( \Int(L)\), donne une intersection avec \( \Int(K)\).

		\item[Pour \( L=R_0(\pi/3)^3K\)]
		hop.
		\item[Pour \( L=R_0(\pi/3)^4K\)]
		hop.
		\item[Pour \( L=R_0(\pi/3)^5K\)]
		hop.
	\end{subproof}
	Voilà. J'espère que toutes les idées sont en place, et que les parties manquantes sont seulement des vérifications qui se font mécaniquement, de la même manière\quext{Je n'ai pas vérifié. Faites-le et écrivez-moi pour me dire ce qu'il en est.}.
\end{proof}

\newcommand{\CaptionFigPWMCooGWYCczZn}{Illustrations pour le pavage du lemme \ref{LEMooMWWEooEbZXtb}.}
\input{auto/pictures_tex/Fig_PWMCooGWYCczZn.pstricks}

\begin{lemma}       \label{LEMooGSQSooGSfkaL}
	Le groupe
	\begin{equation}
		\gr\big(\tau_1,\tau_{(-\frac{ 1 }{2},\frac{ \sqrt{ 3 } }{2})},R_0(\pi/3\big))
	\end{equation}
	est un groupe de pavage.
\end{lemma}

D'après \cite{BIBooWIEGooJlwsCW}, la démonstration du lemme \ref{LEMooGSQSooGSfkaL} demande d'utiliser le losange de sommets \( (0,0)\), \( (1,0)\), \( (\frac{ 1 }{2},\frac{ \sqrt{ 3 } }{ 6 })\) et \( (\frac{ 1 }{2}, -\frac{  \sqrt{ 3 } }{ 6 })\)\quext{Je n'ai pas vérifié, mais à mon avis une preuve doit prendre les mêmes idées que celles du lemme \ref{LEMooMWWEooEbZXtb}.}.

\begin{lemma}[\cite{MonCerveau}]        \label{LEMooEKWZooYbcGBp}
	Soient \( u_1,u_2\in \eR^2\) non colinéaires, ainsi que \( \alpha,\beta\in \mathopen[ 0 , 1 \mathclose]\). Nous considérons \( v=\alpha u_1+\beta u_2\).

	Nous supposons pour fixer les idées, que \( \| u_1 \|\geq \| u_2 \|\). Alors
	\begin{equation}
		\min\{ \| v \|, \| u_1+u_2-v \| \}\leq \| u_1 \|.
	\end{equation}
	Autrement dit, tout point intérieur d'un parallélogramme est plus proche d'un angle que la longueur du plus long côté.
\end{lemma}

\begin{proof}
	Les points \( \alpha u_1+\beta u_2\) (\( \alpha,\beta\in \mathopen[ 0 , 1 \mathclose]\)) se divisent en deux parties : ceux avec \( 0\leq\alpha+\beta\leq 1\) et ceux avec \( 1\leq\alpha+\beta\leq 2\).

	Si \( \alpha+\beta\leq 1\) alors
	\begin{equation}
		\| \alpha u_1+\beta u_2 \|<\| \alpha u_1 \|+\beta\| u_2 \|= \alpha\| u_1 \|+\beta\| u_2 \|\leq (\alpha+\beta)\| u_1 \|\leq \| u_1 \|.
	\end{equation}
	L'inégalité est stricte parce que \( u_1\) et \( u_2\) ne sont pas colinéaires.

	Si au contraire \( \alpha+\beta\geq 1\) nous avons
	\begin{equation}
		\| u_1+u_2-\alpha u_1-\beta u_2 \|<\| (1-\alpha)u_1 \|+\| (1-\beta)u_2 \|<(2-\alpha-\beta)\| u_1 \|\leq \| u_1 \|.
	\end{equation}
\end{proof}

\begin{lemma}       \label{LEMooWKTGooQlfuxm}
	Soient un ensemble \( E\), et deux bijections \( r,s\colon E\to E\) ayant chacune un unique point fixe. Si elles commutent, alors leurs points fixes sont égaux.
\end{lemma}

\begin{proof}
	Nous nommons \( a\) le point fixe de \( r\) et \( b\) celui de \( s\). Pour tout \( x\in E\) nous avons \( (rs)(x)=(sr)(x)\). En particulier pour \( x=s^{-1}(a)\). D'une part
	\begin{equation}
		(rs)(x)=r(a)=a.
	\end{equation}
	Et d'autre part,
	\begin{equation}
		(sr)(a)=(srs^{-1})(a)
	\end{equation}
	Si nous imposons \( (srs^{-1})(a)=a\), nous avons, en appliquant \( s^{-1}\) des deux côtés : \( (rs^{-1})(a)=s^{-1}(a)\). Cela prouve que \( s^{-1}(a)\) est un point fixe de \( r\). Donc \( s^{-1}(a)=a\).

	Nous en déduisons que \( a\) est un point fixe de \( s\) et donc que \( a=b\).
\end{proof}

\begin{lemma}       \label{LEMooDGSJooCiBhZz}
	Soit un sous-groupe fini \( T\) de \( (\eR^2,+)\) tel que \( \| v \|>\delta \) pour tout \( v\neq 0\) dans \( T\).

	Alors si \( u_1\) et \( u_2\) sont les plus petits éléments en norme de \( T\), nous avons
	\begin{equation}
		T=\eZ u_1+\eZ u_2.
	\end{equation}
\end{lemma}

\begin{proof}
	Nous décomposons en plusieurs parties.

	\begin{subproof}
		\item[\( \eR^+v\cap T=\eN v_m\)]
		Soit \( v\in T\). L'ensemble \( \{ \lambda \in \eR^+\tq \lambda v\in T\}\) a un minimum parce que tous les éléments de \( T\) sont en norme plus grands que \( \delta>0\). Soit \( \lambda_m\) ce minimum et \( v_m=\lambda_mv\).

		Nous prétendons à présent que \( \eR^+v\cap T=\eN v_m\). Nous ne faisons d'ailleurs pas que prétendre; nous \emph{prouvons}. En effet, soit \( \lambda v\in T\). Nous devons prouver que \( \lambda = l\lambda_m\) pour un certain \( l\in \eN\). Soit \( k\in \eN\) tel que \( k\leq \lambda<k+1\).

		Nous avons
		\begin{equation}
			(k+1)\lambda_m-\lambda\leq (k+1)\lambda_m-k\lambda_m=\lambda_m.
		\end{equation}
		Vu que \( T\) est un groupe pour l'addition, et que \( \lambda_mv\in T\) et \( \lambda v\in T\), cela implique que \( \big( (k+1)\lambda_m-\lambda \big)v\in T\). Mais
		\begin{equation}
			| \big( (k+1)\lambda_m-\lambda \big)v |\leq \lambda_m.
		\end{equation}
		Vue la propriété de minimalité de \( \lambda_m\), nous avons forcément
		\begin{equation}
			(k+1)\lambda_m-\lambda = \lambda_m.
		\end{equation}
		Cela prouve que \( \lambda=k\lambda_m\).

		Jusqu'ici nous avons prouvé que
		\begin{equation}
			\eR^+v\cap T=\eN v_m
		\end{equation}
		pour un certain multiple \( v_m\) de \( v\).

		\item[\( \| u_1 \|\leq \| v \|\) pour tout \( v\)]

		Nous montrons à présent qu'il existe \( u_1\in T\) tel que \( \| u_1 \|\leq \| v \|\) pour tout \( v\in T\). Si tel n'était pas le cas, il existerait une suite \( v_k\in T\) telle que \( \| v_{k+1} \|<\| v_k \|\). Toute cette suite serait contenue dans le couronne (compacte) de rayons \( \delta\) et \( \| u_1 \|\). Quitte à prendre une sous-suite, nous pouvons supposer que \( (v_k)\) converge\footnote{Proposition \ref{THOooRDYOooJHLfGq}.}. Cette suite serait de Cauchy et pour tout \( \epsilon\) (en particulier \( \epsilon<\delta\)), il existerait \( p,q\) tels que \( \| v_p-v_q \|<\epsilon\). Puisque \( T\) est un groupe pour l'addition, nous aurions \( v_p-v_q\in T\) avec \( \| v_p-v_q \|<\epsilon\leq \delta\).

		\item[Première pause]

		Si \( T\) est engendré seulement par \( u_1\), nous avons fini. Autrement dit, si tout \( T\) est dans un sous-espace de dimension \( 1\) de \( \eR^2\), nous avons terminé.

		Dans la suite, nous supposons donc que \( T\) n'est pas contenu dans un sous-espace de dimension \( 1\).

		\item[\( T=\eZ u_1 + \eZ u_2\)]
		Soient \( u_1\) et \( u_2\) les deux plus petits éléments de \( T\) en norme (peut-être ex-aequo). Ces deux éléments ne sont pas colinéaires, sinon leur différence serait plus petite. Ils forment donc une base de \( \eR^2\).

		Soit \( v\in T\). Comme \( \{ u_1,u_2 \}\) est une base de \( \eR^2\), il existe \( \alpha,\beta\in \eR\) tels que
		\begin{equation}
			v=\alpha u_1+\beta u_2.
		\end{equation}
		Notre but est à présent de prouver que \( \alpha,\beta\in \eZ\).

		Si ce n'était pas le cas, une simple translation nous mènerait dans les circonstances du lemme \ref{LEMooEKWZooYbcGBp}. Nous aurions alors que, soit \( \| v \|\), soit \(\| u_1+u_2-v \|\) serait strictement plus petit que le plus grand entre \( \| u_1 \|\) et \( \| u_2 \|\). Cela contredirait le fait que \( \| u_1 \|\) et \( \| u_2 \|\) étaient les deux plus petits.
	\end{subproof}
\end{proof}

\begin{proposition}[\cite{MonCerveau}]      \label{PROPooPQYXooIDZlHy}
	Si \( G\) est un groupe de pavage\footnote{Définition \ref{DEFooJPHKooRgCBJs}.} de \( \eR^2\) et si \( f\colon \eR^2\to \eR^2\) est une isométrie affine, alors le groupe
	\begin{equation}
		G'=f\circ G\circ f^{-1}=\{f\circ g\circ f^{-1}\tq g\in G\}
	\end{equation}
	est un groupe de pavage.
\end{proposition}

\begin{proof}
	Soit un compact \( K\) tel que \( (G,K)\) soit un pavage. Nous notons \( K'=f(K)\). Nous devons prouver deux choses :
	\begin{itemize}
		\item \( f\circ G\circ f^{-1}\) est un groupe de déplacements;
		\item \( (G',K')\) est un pavage.
	\end{itemize}

	Ceci mène à prouver trois éléments.
	\begin{subproof}
		\item[\( G'\) est constitué de déplacements]
		Les éléments de \( G\) sont des isométries, ainsi que \( f\) et \( f^{-1}\). Donc les éléments de \( G'\) sont des isométries.

		Soit \( g\in G\). Comme \( g\) est affine, il existe une décomposition \( g=\tau_v\circ g_0\) où \( g_0\) est linéaire. De même \( f=\tau_w\circ f_0\). Les règles du produit et de l'inverse de la proposition \ref{PROPooBPKKooJRAMeT}\ref{ITEMooGUFRooMuhXds}\ref{ITEMooYOMSooRUDSdm} nous indiquent que la partie linéaire de \( fgf^{-1}\) est \( f_0g_0f_0^{-1}\).

		En ce qui concerne le déterminant de \( f_0g_0f_0^{-1}\), c'est la proposition \ref{PropYQNMooZjlYlA} qui nous indique que
		\begin{equation}
			\det(f_0g_0f_0^{-1})=\det(f_0)\det(g_0)\det(f_0^{-1})=\det(f_0)\det(g_0)\det(f_0)^{-1}=\det(g_0)=1.
		\end{equation}

		\item[\( G'\cdot K'=\eR^2\)]
		Comme \( f\) est affine, \( K'\) est encore compact\footnote{Il suffit de prouver que \( f(K)\) est fermé et borné par le théorème de Borel-Lebesgue \ref{ThoXTEooxFmdI}.} Nous avons :
		\begin{subequations}
			\begin{align}
				(f\circ G\circ f^{-1})\big( f(K) \big) & =\bigcup_{g\in G}\bigcup_{k\in K}(f\circ g\circ f^{-1})\big( \alpha(k) \big) \\
				                                       & =\bigcup_{g\in G}\bigcup_{k\in K}(f\circ g)(k)                               \\
				                                       & =\bigcup_{g\in G}f\big( \bigcup_{k\in K}g(k) \big)                           \\
				                                       & =\bigcup_{g\in G}(f\circ g)(K)                                               \\
				                                       & =f\big( \bigcup_{g\in G}g(K) \big)                                           \\
				                                       & =f\big( G\cdot K \big)                                                       \\
				                                       & =\eR^2.
			\end{align}
		\end{subequations}
		Pour la dernière égalité, nous avons utilisé le fait que \( f\) est bijective et que \( G\cdot K=\eR^2\).

		\item[L'autre condition]
		Deux éléments de \( G'\) s'écrivent \( fg_1f^{-1}\) et \( fg_2f^{-1}\). Nous les supposons tels que
		\begin{equation}
			(fg_1f^{-1})\cdot \Int(K')\cap(f g_2 f^{-1})\cdot\Int(K')\neq \emptyset.
		\end{equation}
		Nous avons :
		\begin{subequations}
			\begin{align}
				(fg_1f^{-1})\cdot \Int(K')\cap(f g_2 f^{-1})\cdot\Int(K') & =f\big( g_1\cdot\Int(K) \big)\cap f\big( g_2\cdot\Int(K) \big) \label{SUBEQooWPMUooWvfdAw}                           \\
				                                                          & =f\big(  \underbrace{g_1\cdot\Int(K)\cap g_2\cdot\Int(K)}_{\neq \emptyset}  \big)        \label{SUBEQooTOGSooNrArAk} \\
				                                                          & \neq \emptyset.
			\end{align}
		\end{subequations}
		Justifications :
		\begin{itemize}
			\item Égalité \eqref{SUBEQooWPMUooWvfdAw} parce qu'un peu de topologie nous enseigne que \( f^{-1}\big( \Int(K') \big)=  \Int\big( f^{-1}(K') \big)=\Int(K)  \) parce que \( f\) est affine.
			\item Égalité \eqref{SUBEQooTOGSooNrArAk} parce que, \( f\) étant bijective, \( f(A)\cap f(B)=f(A\cap B)\);
		\end{itemize}
	\end{subproof}
\end{proof}

\begin{theorem}[\cite{NHXUsTa,BIBooWIEGooJlwsCW}]       \label{THOooUPHQooYfeHAy}
	Nous notons \( \tau_v\) la translation de vecteur \( v\), \( r_{A,\theta}\) la rotation de centre \( A\) et d'angle \( \theta\) ainsi que \( \tau_i=\tau_{e_i}\).

	Un groupe \( G\) est un groupe de pavage de \( \eR^2\) si et seulement si il existe une bijection affine \( f\colon \eR^2\to \eR^2\) telle que \( f\circ G\circ f^{-1}\) est un groupe de la liste suivante :
	\begin{enumerate}
		\item
		      \( \gr\big(\tau_1,\tau_2)\)
		\item
		      \( \gr\big(\tau_1,\tau_2,R_0(\pi)\big)\)
		\item
		      \( \gr\big(\tau_1,\tau_{(\frac{ 1 }{2},\frac{ \sqrt{ 3 } }{ 2 })},R_0(2\pi/3)\big)\)
		\item
		      \( \gr\big(\tau_1,\tau_2,R_0(\pi/2)\big)\)
		\item
		      \( \gr\big(\tau_1,\tau_{(-\frac{ 1 }{2},\frac{ \sqrt{ 3 } }{2})},R_0(\pi/3\big))\).
	\end{enumerate}
\end{theorem}

\begin{proof}
	Les lemmes \ref{LEMooZOXVooTJiLTF},    \ref{LEMooTMRGooChBzZg},    \ref{LEMooJPNDooHDCLnY},    \ref{LEMooMWWEooEbZXtb}, et    \ref{LEMooGSQSooGSfkaL} montrent que les groupes listés sont des groupes de pavage. La proposition \ref{PROPooPQYXooIDZlHy} nous montre alors que si \( H=f Gf^{-1}\) est dans la liste, alors \( G\) est un groupe de pavage. Il nous reste à montrer que si \( G\) est un groupe de pavage, alors il existe une application affine \( \alpha\) telle que \( \alpha G\alpha^{-1}\) est un groupe de la liste.

	Soit \( (G,K)\) un pavage de \( \eR^2\).  Nous notons \( T\) l'ensemble des translations dans \( G\), plus précisément,
	\begin{equation}
		T=\{ v\in \eR^2\tq  \tau_v\in G\}.
	\end{equation}
	\begin{subproof}
		\item[Une borne pour \( T\)]
		Nous prouvons qu'il existe \( \delta>0\) tel que \( \| v \|>\delta\) pour tout \( v\neq 0\in T\). En effet, soit \( m\in \Int(K)\) ainsi que \( r\) tel que \( B(m,r)\subset \Int(K)\). Alors si \( v\in T\) est tel que \( \| v \|<r\) nous avons \( \tau_v(m)\in \Int(K)\), ce qui donnerait
		\begin{equation}
			m\in\tau_v\big( \Int(K) \big)\cap\Int(K)
		\end{equation}
		par hypothèse, cette intersection est non vide seulement si \( v=0\).

		Donc il existe \( \delta\) tel que \( \| v \|\geq \delta\) pour tout \( v\in T\).
		\item[Utilisation du lemme]

		La partie \( T\) est donc dans la position du lemme \ref{LEMooDGSJooCiBhZz} et nous avons
		\begin{equation}
			T=\eZ u_1+\eZ u_2
		\end{equation}
		pour les vecteurs \( u_1\) et \( u_2\) les plus petits en norme de \( T\).

		En réalité, il se peut que \( T\) soit plus petit que ça, parce que \( G\) peut par exemple ne contenir aucune translation. Nous avons trois possibilités :
		\begin{itemize}
			\item \( T=\{ 0 \}\),
			\item \( T=\eZ u\) pour un certain \( u\neq 0\) dans \( \eR^2\),
			\item \( T=\eZ u_1+\eZ u_2\) pour certains \( u_1,u_2\in \eR^2\setminus\{ 0 \}\).
		\end{itemize}

		\item[Translation]
		Si \( r,s\in G\), alors l'élément \( rsr^{-1}s^{-1}\) est une translation. En effet, puisque les éléments de \( G\) sont des déplacements, ce sont des applications affines et donc il existe des applications linéaires \( A_r,A_s\) et des translations \( \tau_r,\tau_s\) telles que \( r=A_r\circ \tau_r\) et \( s=A_s\circ \tau_s\). Le lemme \ref{LEMooUBGZooBIlmAN} nous donne les inverses. Nous avons
		\begin{equation}
			rsr^{-1}s^{-1}=(A_r\circ \tau_r)(A_s\circ \tau_s)(A_r^{-1}\circ \tau_{-A_rv_r})(A_s^{-1}\circ \tau_{-A_sv_s}).
		\end{equation}
		La partie linéaire de cela est
		\begin{equation}
			A_r\circ A_s\circ A_r^{-1}\circ A_s^{-1}.
		\end{equation}
		C'est donc une composée de rotations centrées en \( (0,0)\). Mais ces rotations forment un groupe abélien (proposition \ref{PROPooWMESooNJMdxf}). Donc nous pouvons écrire
		\begin{equation}
			A_r\circ A_s\circ A_r^{-1}\circ A_s^{-1}=A_r\circ A_r^{-1}\circ A_s\circ A_s^{-1}=\id.
		\end{equation}

		Tout ceci pour dire que dès que \( r,s\in G\), l'élément \( rsr^{-1} s^{-1}\) est une translation.

		\item[Les parties linéaires\cite{MonCerveau}]
		Nous savons de l'exemple \ref{EXooAGINooYmvPML} que les éléments de \( G\) s'écrivent sous la forme \( f=\tau_v\circ \alpha\) où \( v\in \eR^2\) et \( \alpha\colon \eR^2\to \eR^2\) est linéaire.

		De plus, \( f\) étant une isométrie de \( (\eR^2,d)\), l'application \( \alpha\) est une isométrie de \( (\eR^2,\| . \|)\). Puisque \( \alpha\) est une isométrie, \( \det(\alpha)=\pm1\). Mais les déplacements conservent l'orientation; donc \( \alpha\) doit conserver l'orientation, et la proposition \ref{PROPooNBAXooKNUrnk} nous dit que \( \det(\alpha)>0\). Donc
		\begin{equation}
			\det(\alpha)=1.
		\end{equation}
		Le théorème \ref{THOooWBIYooCtWoSq} dit que \( \alpha\) est la composition d'un nombre pair de réflexions. Mais comme il y en a au plus trois (théorème \ref{THOooRORQooTDWFdv}), l'application \( \alpha\) est composée de zéro ou deux réflexions.

		Donc les parties linéaires des éléments de \( G\) sont des rotations.

		\item[Les autres]

		Les parties linéaires des éléments de \( G\) sont des rotations. Mais les éléments de \( G\) eux-mêmes ne sont pas tellement mystérieux. Puisque ce sont des isométries de \( (\eR^2,d)\), elles sont composées de \( 0\), \( 1\), \( 2\) ou \( 3\) réflexions.

		Mais ce sont des déplacements, donc ils préservent l'orientation et le théorème \ref{THOooWBIYooCtWoSq} dit qu'ils sont des composées de zéro ou deux réflexions (nombre pair). Ce sont donc des rotations.

		\item[Hein ?]
		Les éléments linéaires de \( G\) sont des rotations. Et les autres aussi ? Les linéaires sont des rotations autour de \( (0,0)\); les autres sont des rotations autour de points autres que \( (0,0)\).

		C'est pourquoi dans la suite, nous préciserons «rotation linéaire» pour une rotation autour de \( (0,0)\) et nous dirons «rotation» pour une rotation en général. Dans le contexte affine, il faut toujours faire attention à ça : une rotation peut très bien n'être pas linéaire\footnote{Lorsque, ailleurs dans le Frido, nous disons «rotation», souvent nous pensons «rotation linéaire». Gardez cependant à l'esprit qu'une rotation peut très bien être centrée ailleurs qu'en l'origine, et soyez toujours capable de préciser le cas échéant.}.

		\item[Les rotations linéaires stabilisent \( T\)]
		Nous prouvons maintenant que les rotations linéaires de \( G\) stabilisent \( T\), c'est-à-dire que si \( v\in T\) et si \( \alpha\) est une rotation linéaire de \( G\), alors \( \alpha(v)\in T\). La transformation \( \alpha\tau_v\alpha^{-1}\) est dans \( G\). Mais pour tout \( x\in \eR^2\) nous avons
		\begin{equation}        \label{EQooLLZVooUuabir}
			(\alpha\tau_v\alpha^{-1})(x)=\alpha\big( \alpha^{-1}(x)+v \big)=x+\alpha(v)=\tau_{\alpha(v)}(x).
		\end{equation}
		Donc \( \alpha\tau\alpha^{-1}=\tau_{\alpha(v)}\) et \( \alpha(v)\in T\).

		\item[Exclusion de \( T=\{ 0 \}\)]
		Le fait que \( T=\{ 0 \}\) ne signifie pas que tous les éléments de \( G\) sont des rotations; il peut encore y avoir des composées de rotations et de translations \( A\circ \tau\). Cela étant dit, si \( T=\{ 0 \}\), il n'en reste pas moins que \( rsr^{-1}s^{-1}\) est une translation, c'est-à-dire est égal à \( \id\). Mais \( rsr^{-1}s^{-1}=e\) implique \( rs=sr\).

		Donc \( G\) est abélien. Les éléments de \( G\) sont donc des rotations qui commutent deux à deux. Puisqu'une rotation a son centre comme unique point fixe, le lemme \ref{LEMooWKTGooQlfuxm} nous dit que tous les éléments de \( G\) sont des rotations de même centre.

		Soit \( c\) le centre commun de tous les éléments de \( G\). Vu que \( K\) est compact dans \( \eR^2\), il existe \( r>0\) tel que \( K\subset B(c,r)\). Puisque \( G\) stabilise toutes les boules centrées en \( c\), nous avons
		\begin{equation}
			G\cdot K\subset B(c,r).
		\end{equation}
		Donc nous n'avons pas un recouvrement de \( \eR^2\). Le cas \( T=\{0 \}\) est exclu.

		\item[Exclusion de \( T=\eZ u\)]
		Nous supposons à présent que \( T=\eZ u\) pour un certain \( u\in \eR^2\).

		\begin{subproof}
			\item[\( r_0=\pm\id\)]
			Nous savons que tous les éléments de \( G\) sont des rotations; soit un élément \( r\) de \( G\). La proposition
			\ref{PROPooTFNSooFjiWHG}\ref{ITEMooSIHZooBEJhdu} nous indique qu'il existe un point \( a\in \eR^2\) ainsi qu'une rotation linéaire \( r_0\) telle que \( r=\tau_a^{-1}r_0\tau_a\). Nous allons prouver que \( r_0\) est \( \pm\id\). D'abord,
			\begin{equation}
				r\tau_u r^{-1}=\tau_a^{-1}r_0\tau_a\tau_u\tau_a^{-1}r_0^{-1}\tau_a=\tau_a^{-1}r_0\tau_ur_0^{-1}\tau_a.
			\end{equation}
			Ensuite, nous appliquons cela à \( x\in \eR^2\) :
			\begin{subequations}
				\begin{align}
					(\tau_a^{-1}r_0\tau_ur_0^{-1}\tau_a)(x) & =(\tau_a^{-1}r_0\tau_u)\big( r_0^{-1}(x+a) \big) \\
					                                        & =(\tau_a^{-1}r_0)\big( r_0^{-1}(x+a)+u \big)     \\
					                                        & =\tau_a^{-1}\big( x+a+r_0(u) \big)               \\
					                                        & =x+r_0(u).
				\end{align}
			\end{subequations}
			Donc \( r\circ\tau_u\circ r^{-1}=\tau_{r_0(u)}\), ce qui prouve que \( r_0(u)\in T\). Comme \( \| r_0(u) \|=\| u \|\) nous avons forcément \( r_0(u)=\pm u\).

			Si \( r_0(u)=u\), alors \( r_0=\id\) (parce que \( r_0\) est une rotation fixant plus qu'un seul point). Dans ce cas, \( r=\id\).

			Si au contraire \( r_0(u)=-u\), alors \( r_0=-\id\).

			\item[Forme générale]
			Donc si \( r\) est un élément non trivial de \( G\) nous avons \( r=\tau_a^{-1}\circ(-\id)\circ\tau_a\), et alors
			\begin{equation}
				\big( \tau_a^{-1}\circ(-\id)\circ\tau_a \big)(x)=\tau_a^{-1}  (-\id)(x+a)=\tau_a^{-1}(-x-a)=-x-2a.
			\end{equation}
			Donc pour tout \( r\in G\), il existe \( a\in \eR^2\) tel que
			\begin{equation}        \label{EQooQGNVooKyCCYW}
				r(x)=-x-2a.
			\end{equation}
			Pour information, le centre de cette rotation est \( -a\) (c'est le seul point fixe).

			\item[Les centres sont alignés]
			Soit \( r\) une rotation de centre \( -a\) et \( s\) de centre \( -b\). Alors
			\begin{equation}
				(rs)(x)=r(-x-2b)=x+2b-2a=x+2(b-a).
			\end{equation}
			Donc \( rs=\tau_{2(b-a)}\).

			Cela prouve que \(2(b-a)\in \eZ u\).

			\item[Une bande]
			Soit la droite \( D=\eR u\). Nous considérons la bande
			\begin{equation}
				B_r=\{ x\in \eR^2\tq d(x,D)<r \}.
			\end{equation}

			\item[Une inclusion]
			Nous prouvons à présent que pour tout \( r\), nous avons
			\begin{equation}
				G\cdot B_r \subset B_r.
			\end{equation}
			Nous savons qu'un élément général de \( G\) est une rotation centrée en un point de \( D\), et que l'action d'une telle rotation est donnée par \eqref{EQooQGNVooKyCCYW}. Nous avons
			\begin{subequations}
				\begin{align}
					d\big( r(x),D \big) & =d(x+2a,D)      \label{EQooNCQGooGGAhCR}                                        \\
					                    & =d\big( \tau_{2a}^{-1}(x+2a),\tau_{2a}^{-1}(D) \big)   \label{EQooNFJNooSAYtBD} \\
					                    & =d(x,D)        \label{SUBEQooMGTMooAlRwWT}.
				\end{align}
			\end{subequations}
			Justifications :
			\begin{itemize}
				\item Pour \eqref{EQooNCQGooGGAhCR}, nous avons \( D=-D\) et \(d(x,y)=d(-x,-y) \).
				\item Pour \eqref{EQooNFJNooSAYtBD}, invariance par translation de la distance dans \( \eR^2\).
				\item Pour \eqref{SUBEQooMGTMooAlRwWT}, les éléments de \( D\) sont les multiples de \( a\); donc cette droite est invariante par cette translation.
			\end{itemize}
			Bref, \( d(x,D)=d\big( r(x),D \big) \). Donc, pour tout \( r>0\)\footnote{Remarquez la notation malheureuse pour \( r\) qui est maintenant une distance alors que trois mots plus tôt, c'était un élément de \( G\).} et pour tout \( g\in G\), si \( x\in B_r\), alors \( g(x)\in B_r\).

			\item[Exclusion]

			Comme \( K\) est compact et que la fonction \( x\mapsto d(x,D)\) est continue, il existe \( r>0\) tel que \( K\subset B_r\). Avec ça, \( G\cdot K\subset G\cdot B_r\subset B_r\). Donc \( G\cdot K\) ne recouvre par tout \( \eR^2\) et \( G\) n'est pas un groupe de pavage.
		\end{subproof}
	\end{subproof}

	Et nous voilà avec seulement \( T=\eZ u_1+\eZ u_2\) en lice.

	\begin{subproof}
		\item[Pause : quelques parties de \( G\) à ne pas confondre]
		Il convient de ne pas se perdre entre différentes parties de \( G\). Je vous laisse méditer quelque temps sur la liste suivante :
		\begin{enumerate}
			\item \( G\) est le groupe que nous cherchons à déterminer;
			\item \( T\) est le groupe des translations de \( G\);
			\item le groupe des rotations linéaires dans \( G\);
			\item l'ensemble des \( \tau_A^{-1}\circ r\circ\tau_A\) où \( r\) est une rotation de \( G\) centrée en \( A\).     \label{ITEMooFWWMooNzLUGy}
			\item \( L\) est l'ensemble des parties linéaires des éléments de \( G\).      \label{ITEMooIEJZooNaSKpc}
		\end{enumerate}
		En particulier les deux derniers points ne sont pas les mêmes.

		Dans le cas \ref{ITEMooFWWMooNzLUGy}, il s'agit de dire que \( r\) est une rotation centrée en \( A\in \eR^2\) et écrire \( r=\tau_A\circ r_0\circ \tau_A^{-1}\) (proposition \ref{PROPooTFNSooFjiWHG}\ref{ITEMooSIHZooBEJhdu}) et considérer \( r_0\). Dans ce cas, \( r_0\) est une rotation, mais elle n'est pas ce que nous appelons la «partie linéaire» de \( r\). Il n'y a pas de garantie que cela forme un groupe.

		Si \( r\) est une rotation dans \( G\), dans le cas \ref{ITEMooIEJZooNaSKpc} il s'agit de décomposer \( r=\tau_v\circ\alpha\) (lemme \ref{LEMooYJCDooOGAHkF}) et considérer \( \alpha\). Dans ce cas, \( \alpha\) est linéaire, mais il n'y a pas de garantie que \( \alpha\) soit une rotation.

		\item[\( L\) est un groupe]
		En trois conditions.
		\begin{itemize}
			\item
			      Si \( \alpha,\beta\in L\), il existe \( v,w\in \eR^2\) tels que \( \tau_v\circ \alpha\in G\) et \( \tau_w\circ \beta\in G\). La loi de produit \ref{PROPooBPKKooJRAMeT}\ref{ITEMooGUFRooMuhXds} dit que \( \tau_v\circ \alpha\circ\tau_w\circ \beta=\tau_{\alpha(w)+v}\circ \alpha\beta\). Donc \( \alpha\beta\) est la partie linéaire d'un élément de \( G\).
			\item
			      De la même façon, en utilisant l'inverse \ref{PROPooBPKKooJRAMeT}\ref{ITEMooYOMSooRUDSdm}, \( (\tau_v\circ\alpha)^{-1}= \tau_{-\alpha^{-1}(v)}\circ \alpha^{-1}   \). Donc \( \alpha^{-1}\) est la partie linéaire d'un élément de \( G\).
			\item
			      Et enfin \( \id=\tau_0\circ \id\). Donc l'identité est dans \( L\).
		\end{itemize}
		Ok : \( L\) est un groupe.

		\item[Précision]
		L'ensemble \( L\) est un groupe, certes. Mais rien ne dit que \( L\) soit un sous-groupe de \( G\).

		\item[\( L\) préserve le réseau]
		Soit \( \alpha\in L\). Il existe \( v\in \eR^2\) tel que \( g=\tau_v\circ \alpha\in G\). Soit \( u\in T\). Nous allons montrer que \( \alpha(u)\in T\). Vu que \( g\) et \( \tau_u\) sont dans \( G\), l'élément \( g\tau_ug^{-1}\) est également dans \( G\). Nous l'appliquons à \( x\in \eR^2\) :
		\begin{subequations}
			\begin{align}
				(\tau_v\alpha\tau_u\alpha^{-1}\tau_v^{-1})(x) & =(\tau_v\alpha\tau_u\alpha^{-1})(x-v)            \\
				                                              & =(\tau_v\alpha)\big( \alpha^{-1}(x-v)+u \big)    \\
				                                              & =\tau_v\big( x-v+\alpha(u) \big)                 \\
				                                              & =x+\alpha(u)                                     \\
				                                              & =\tau_{\alpha(u)}(x).
			\end{align}
		\end{subequations}
		Donc \( g\tau_ug^{-1}=\tau_{\alpha(u)}\in G\).

		\item[Question de trace]
		Soit \( \alpha\in L\); dans la base \( \{ u_1,u_2 \}\) la matrice de \( \alpha\) est
		\begin{equation}
			\begin{pmatrix}
				a & b \\
				c & d
			\end{pmatrix}
		\end{equation}
		avec \( a,b,c,d\in \eZ\). La trace de cette matrice est \( a+d\in \eZ\). Dans la base canonique de \( \eR^2\) par contre, la proposition \ref{PROPooOTIVooZpvLnb} nous dit qu'il existe \( \theta\in \mathopen[ 0 , 2\pi \mathclose[\) tel que la matrice de \( \alpha\) soit
		\begin{equation}
			\begin{pmatrix}
				\cos(\theta) & -\sin(\theta) \\
				\sin(\theta) & \cos(\theta)
			\end{pmatrix}.
		\end{equation}
		La trace est \( 2\cos(\theta)\). La trace est invariante par changement de base\footnote{Proposition \ref{PROPooRMYQooWkEpJJ}.}, donc \( 2\cos(\theta)=a+d\in \eZ\). Les possibilités pour \( \cos(\theta)\) sont donc \( -1\), \( -1/2\), \( 0\), \( 1/2\) et \( 1\).

		\item[Les angles possibles]
		Nous savons que \( \cos(\frac{ \pi }{2})=0\) et \( \cos(\pi/3)=1/2\) (proposition \ref{PROPooMWMDooJYIlis}\ref{ITEMooWFNUooYAybDB} et lemme \ref{LEMooRMHAooDEAPMw}). La proposition \ref{PROPooTUUUooVrAGQo} nous dit alors que, dans notre cas, les valeurs possibles pour \( \theta\) dans \( \mathopen[ 0 , 2\pi \mathclose[\) sont
		\begin{equation}        \label{EQooLMPIooPQoHUI}
			\{ 0,\frac{ \pi }{ 3 },\frac{ \pi }{ 2 }, \frac{ 2\pi }{ 3 }, \pi,\frac{ 4\pi }{ 3 }, \frac{ 3\pi }{ 2 },\frac{ 5\pi }{ 3 } \}.
		\end{equation}
		Donc les rotations possibles dans \( L\) sont les rotations de ces angles.

		Nous devons trouver quels sont les groupes qui peuvent être formés seulement avec ces éléments.

		\item[Quelques combinaisons impossibles]

		Puisque \( L\) est un groupe, il y a des combinaisons impossibles. Par exemple si \( R_0(\pi/3)\) et \( R_0(\pi/2)\) sont dans \( L\), alors la composée\footnote{Proposition \ref{PROPooISUCooRYJcwo} pour l'addition des angles.} \( R_0(\pi/2)R_0(\pi/3)=R_0(5\pi/6)\) est également dans \( L\). Mais comme \( 5\pi/6\) n'est pas dans la liste \eqref{EQooLMPIooPQoHUI}, \( R_0(5\pi/6)\) n'est pas dans \( L\).

		En raisonnant de la sorte, nous voyons que si \( R_0(\pi/2)\in L\), alors \( L=\gr\big( R_0(\pi/2) \big)\).

		\item[La liste]
		Plus généralement, les possibilités pour \( L\) sont
		\begin{itemize}
			\item \( \{ \id \}\)
			\item \( \gr\big( R_0(\pi/2) \big)\)
			\item \( \gr\big( R_0(\pi/3) \big)\)
			\item \( \gr\big( R_0(\pi) \big)\)
			\item \( \gr\big( R_0(2\pi/3) \big)\)
		\end{itemize}
		Une justification plus courte pour cette liste est d'invoquer le théorème \ref{THOooKDMUooUxQqbB}\ref{ITEMooGELWooFFAqkc} qui dit que \( L\) étant un sous-groupe fini des isométries de \( (\eR^2,d)\), il est cyclique et donc monogène. Notons pour cela que \( \gr\big( R_0(4\pi/3) \big)=\gr\big( R_0(2\pi/3) \big)\) parce que \( R_0(4\pi/3)=R_0(2\pi/3)^{-1}\). De la même manière \( R_0(3\pi/2)=R_0(\pi/2)^{-1}\) et \( R_0(5\pi/3)=R_0(\pi/3)^{-1}\).

		\item[Le cas un peu générique]

		Nous supposons que \( L=\gr\big( R_0(\theta) \big)\) pour un certain \( \theta\). Nous allons voir qu'à part dans les cas \( \theta=0\) et \( \theta=\pi\), il est possible de trouver une application affine \( \alpha\) telle que le groupe \( \alpha G\alpha^{-1}\) soit alors dans la liste.

		Nous considérons un élément de \( G\) de la forme \( \tau_{v_0}\circ R_0(\theta)\). Pour être bien clair, il n'est absolument pas garanti que \( v_0\) soit dans \( T\). Nous allons chercher un élément \( w_0\in \eR^2\) tel que le groupe de pavage\footnote{Proposition \ref{PROPooPQYXooIDZlHy}.} \( G'=\tau_{w_0}G\tau_{w_0}^{-1}\) contienne \( R_0(\theta)\). Le groupe \( G'\) contient l'élément \( g=\tau_{w_0}\tau_{v_0}R_0(\theta)\tau_{w_0}^{-1}\); nous l'appliquons à \( x\in \eR^2\) :
		\begin{equation}
			g(x)=R_0(\theta)x-R_0(\theta)w_0+w_0+v_0.
		\end{equation}
		Nous avons \( g(x)=R_0(\theta)x\) lorsque
		\begin{equation}
			w_0=\big( R_0(\theta)-\mtu \big)^{-1}v_0.
		\end{equation}
		Voilà pourquoi le cas \( \theta=0\) sera traité à part : dans le cas \( \theta=0\), l'opérateur \( R_0(\theta)-\mtu\) n'est pas inversible. Dans les autres cas, nous avons un groupe \( G'=\tau_{w_0}G\tau_{w_0}^{-1}\) qui contient \( R_0(\theta)\).

		Puisqu'un élément général de \( G\) est de la forme \( \tau_v\circ R_0(\theta)^k\), un élément général de \( G' \) est de la forme
		\begin{equation}
			\tau_{w_0}\circ \tau_v\circ R_0(\theta)^k\circ \tau_{w_0}=\tau_{w_0+v-R_0(\theta)^kw}\circ R_0(\theta)^k.
		\end{equation}
		Donc tous les éléments de \( G'\) sont encore de la forme
		\begin{equation}
			\tau_v\circ R_0(\theta)^k.
		\end{equation}
		Mais dans \( G'\) nous avons une information capitale : \( R_0(\theta)^k\) lui-même est dans \( G\). Donc si \( \tau_v\circ R_0(\theta)^k\in G'\), alors \( \tau_v\in G'\).

		Vu que \( G'\) est encore un groupe de pavage, tout ce qui a été dit précédemment tient, et le groupe des translations dans \( G'\) est un réseau \( T'=\eZ u_1+\eZ u_2\) où \( u_1\) et \( u_2\) peuvent être choisis arbitrairement parmi les deux plus petits vecteurs non colinéaires de \( T\).

		Tous les éléments de \( G'\) sont de la forme \( \tau_v\circ R_0(\theta)^k\) avec \( v\in T'\). Donc
		\begin{equation}        \label{EQooUUDQooQpRcIi}
			G'=\gr\big(\tau_{u_1}, \tau_{u_2}, R_0(\theta)\big).
		\end{equation}
		Nous savons que \( R_0(\theta)\) fixe \( T'\). Or l'élément \( R_0(\theta)u_1\) a la même norme que \( u_1\); donc nous pouvons choisir \( u_2=R_0(\theta)\) pour peu que \( R_0(\theta)u_1\) soit non colinéaire à \( u_1\). Et c'est ici que nous laissons le cas \( \theta=\pi\) de côté.

		Nous écrivons donc sans vergogne que
		\begin{equation}
			G'=\gr\big(\tau_{u_1}, \tau_{R_0(\theta)u_1}, R_0(\theta)\big).
		\end{equation}

		Nous allons maintenant nous occuper de \( u_1\). Pour cela nous considérons une rotation suivie d'une homothétie \( \alpha\) telle que \( \alpha(u_1)=e_1\). Une telle opération \( \alpha\) d'une part, commute avec \( R_0(\theta)\) et d'autre part, réalise \( \alpha\circ \tau_v\circ\alpha^{-1}=\tau_{\alpha(v)}\). Donc le groupe \( G''=\alpha G'\alpha^{-1}\) est, par le lemme \ref{LEMooCFTVooKvmyKN},
		\begin{equation}
			G''=\gr\big( \tau_{e_1}, \tau_{\alpha R_0(\theta)u_1}, R_0(\theta) \big).
		\end{equation}
		Cela s'écrit aussi bien
		\begin{equation}
			G''=\gr\big( \tau_{e_1}, \tau_{R_0(\theta)e_1}, R_0(\theta) \big).
		\end{equation}
		Et voilà, ce groupe \( G''\) est un de ceux de la liste.

		\item[Le cas \( L=\{ \id \}\)]
		Dans ce cas, tous les éléments de \( G\) sont de la forme \( \tau_v\) avec \( v\in T\). Nous considérons l'application linéaire \( \alpha\colon \eR^2\to \eR^2\) telle que \( \alpha(u_1)=e_1\) et \( \alpha(u_2)=e_2\). Nous avons
		\begin{equation}
			(\alpha\circ \tau_{u_i}\circ \alpha^{-1})(x)=(\alpha\tau_{u_i})\alpha^{-1}(x)=\alpha\big( \alpha^{-1}(x)+u_i \big)=x+\alpha(u_i)=\tau_i(x).
		\end{equation}
		Donc \( \alpha\circ \tau_{u_i}\circ \alpha^{-1}=\tau_i\). De la même façon, si \( a\in \eZ\) nous avons \( \alpha\tau_{au_i}\alpha^{-1}=\tau_{ae_i}\). Et avec tout ça, si \( v\in T\), alors \( v=au_1+bu_2\) et nous avons
		\begin{equation}
			\alpha\tau_v\alpha^{-1}=\alpha\tau_{au_1}\tau_{bu_2}\alpha^{-1}=\alpha\tau_{au_1}\alpha^{-1}\alpha\tau_{bu_2}\alpha^{-1}=\tau_{ae_1}\tau_{be_2}.
		\end{equation}
		Nous avons donc
		\begin{equation}
			\alpha G\alpha^{-1}=\gr(\tau_1,\tau_2).
		\end{equation}
		Cela est un des groupes de la liste.

		Notez qu'à la place de ces calculs, nous pouvions aussi invoquer la proposition \ref{LEMooCFTVooKvmyKN}.

		\item[Le cas \( L=\{ -\id \}\)]
		Dans le cas \( \theta=\pi\), nous pouvons aller jusqu'à \eqref{EQooUUDQooQpRcIi} et écrire
		\begin{equation}
			G'=\gr\big( \tau_{u_1}, \tau_{u_2}, R_0(\pi) \big).
		\end{equation}
		Puisque \( R_0(\pi)=-\id\) commute avec toutes les applications linéaires et que \( u_1\) et \( u_2\) ne sont pas colinéaires, nous pouvons considérer une application linéaire \( \alpha\colon \eR^2\to \eR^2\) telle que \( \alpha(u_1)=e_1\), \( \alpha(u_2)=e_2\). Nous avons alors
		\begin{equation}
			G''=\alpha G'\alpha^{-1}=\gr\big( \tau_{e_1}, \tau_{e_2},-\id \big),
		\end{equation}
		qui est encore dans la liste.
	\end{subproof}
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Un peu de structure de \texorpdfstring{\( \gO(n)\)}{O(n)}}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Valeurs propres dans \( \gO(n)\)}
%---------------------------------------------------------------------------------------------------------------------------

\begin{proposition}[\cite{ooPWOHooHwgPzO}]      \label{PROPooVEJGooWnqtMm}
	Soit une matrice \( A\in O(n)\). Si \( \lambda\in \eC\) est une valeur propre de \( A\), alors \( \bar\lambda\) est également une valeur propre de \( A\), et de plus \( | \lambda |=1\).
\end{proposition}

\begin{proof}
	Dire que \( \lambda\in \eC\) est une valeur propre de \( A\) signifie qu'il existe \( x\in \eC^n\) (non nul) tel que \( Ax=\lambda x\). Comme les éléments de la matrice \( A\) sont réels,
	\begin{equation}
		A\bar x=\bar A\bar x=\overline{ Ax }=\overline{ \lambda x }=\bar \lambda\bar x.
	\end{equation}
	Donc \( \bar \lambda\) est une valeur propre de \( A\) pour le vecteur propre \( \bar x\).

	Soit \( \lambda\)  une valeur propre de \( A\) de vecteur propre \( x\). Alors nous avons d'une part
	\begin{equation}
		\langle \overline{ Ax }, Ax\rangle =\langle A^tA\bar x, x\rangle =\langle x, \bar x\rangle ,
	\end{equation}
	et d'autre part
	\begin{equation}
		\langle \overline{ Ax }, Ax\rangle =\langle \bar \lambda \bar x, \lambda x\rangle =| \lambda |^2\langle \bar x, x\rangle .
	\end{equation}
	Puisque \( x\neq 0\) nous avons aussi \( \langle \bar x, x\rangle \neq 0\). Par conséquent \( | \lambda |^2=1\) et \( | \lambda |=1\).
\end{proof}

\begin{lemma}[\cite{ooPWOHooHwgPzO}]        \label{LEMooNEDQooNRmASH}
	Soient un espace vectoriel euclidien \( E\) de dimension finie et une isométrie \( f\) de \( E\). Soit \( F\) un sous-espace de \( E\) stable par \( f\). Alors \( F^{\perp}\) est stable par \( f\).
\end{lemma}

\begin{proof}
	La restriction \( f_F\colon F\to F\) est encore une isométrie; elle est donc inversible : pour tout \( y\in F\), il existe \( x\in F\) tel que \( y=f(x)\). Soit \( a\in F^{\perp}\); nous montrons que \( f(a)\in F^{\perp}\). Soit donc \( y\in F\) et calculons :
	\begin{equation}
		\langle y, f(a)\rangle =\langle f(x), f(a)\rangle =\langle x,a \rangle =0
	\end{equation}
	parce que \( x\in F^{\perp}\).
\end{proof}

\begin{proposition}[\cite{ooPWOHooHwgPzO}]      \label{PROPooOMORooWzsrDB}
	Soit une isométrie \( f\colon \eR^3\to \eR^3\).
	\begin{enumerate}
		\item
		      L'application linéaire \( f\) possède au moins une valeur propre réelle qui vaut \( \pm 1\).
		\item
		      Il existe une base orthonormée de \( \eR^3\) dans laquelle la matrice de \( f\) est de la forme
		      \begin{equation}
			      \begin{pmatrix}
				      \lambda & 0            & 0                      \\
				      0       & \cos(\theta) & -\epsilon\sin(\theta)  \\
				      0       & \sin(\theta) & \epsilon\cos(\theta)
			      \end{pmatrix}
		      \end{equation}
		      avec \( \epsilon,\lambda=\pm 1\) et \( \theta\in \mathopen[ 0 , 2\pi \mathclose[\).
	\end{enumerate}
\end{proposition}

\begin{proof}
	Le polynôme caractéristique de \( f\), donné par \( \det(f-\lambda\id)\), est à coefficients réels et de degré \( 3\). Il possède donc au moins une solution réelle, par le corolaire~\ref{CORooKKNWooWEQukb}. Soit donc une valeur propre réelle \( \lambda\) de \( \chi_f\); par le lemme~\ref{PROPooVEJGooWnqtMm} nous avons \( \lambda=\pm 1\). Soit \( u_1\) le vecteur propre correspondant. Nous notons \( F\) l'espace engendré par \( u_1\).

	Nous avons \( f(F)=F\) et donc \( f(F^{\perp})=F^{\perp}\) par le lemme~\ref{LEMooNEDQooNRmASH}. Soit une base orthonormée \( \{ u_2,u_3 \}\) de \( F^{\perp}\) et la matrice \( B\) de la restriction \( f_{p}\) à \( F^{\perp}\). Comme l'application \( f_p\) est une isométrie de \( F^{\perp}\), la matrice \( B\) est, par le lemme~\ref{LEMooAJMAooXPSKtS}, de la forme
	\begin{equation}
		B=\begin{pmatrix}
			\cos(\theta) & -\epsilon\sin(\theta)  \\
			\sin(\theta) & \epsilon\cos(\theta)
		\end{pmatrix}
	\end{equation}
	pour un certain \( \theta\in\mathopen[ 0 , 2\pi \mathclose[\) et \( \epsilon=\pm 1\).

	Dans la base \( \{u_1,u_2,u_3\}\) de \( \eR^3\), la matrice de \( f\) est alors
	\begin{equation}
		\begin{pmatrix}
			\lambda & 0 \\
			0       & B
		\end{pmatrix},
	\end{equation}
	comme annoncé.
\end{proof}

Pour classifier les isométries de \( \eR^3\), nous pouvons nous baser sur les possibilités de la matrice donnée dans le lemme~\ref{PROPooOMORooWzsrDB}. Il y a essentiellement quatre possibilités suivant les valeurs de \( \lambda=\pm 1\) et \( \epsilon=\pm 1\).

\begin{subproof}
	\item[Si \( \epsilon=\lambda=1\)] Alors la matrice est
	\begin{equation}
		A=\begin{pmatrix}
			1 & 0            & 0             \\
			0 & \cos(\theta) & -\sin(\theta) \\
			0 & \sin(\theta) & \cos(\theta)
		\end{pmatrix}
	\end{equation}
	et l'isométrie correspondante est la rotation d'angle \( -\theta\) autour de la droite de \( u_1\).

	\item[Si \( \epsilon=\lambda=-1\)]
	Alors la matrice est
	\begin{equation}
		A=\begin{pmatrix}
			-1 & 0            & 0             \\
			0  & \cos(\theta) & \sin(\theta)  \\
			0  & \sin(\theta) & -\cos(\theta)
		\end{pmatrix}
	\end{equation}
	Cette application est plus subtile, parce que même dans le plan \( \Span(u_2,u_3)\), ce n'est pas une rotation. Nous allons montrer qu'il s'agit d'une réflexion autour de la droite d'angle \( \theta/2\) dans le plan \( \Span(u_2,u_3)\). Nous nommons \( D\) cette droite. Dans la base \( \{ u_1,u_2,u_3 \}\), les points de cette droite sont de la forme\footnote{Les plus acharnés remarqueront que \( \{ u_1,u_2,u_3 \}\) est un ensemble, qui est une base. Mais un ensemble n'est pas ordonné, alors que pour écrire l'équation de droite qui suit, nous supposons un ordre. Je laisse au tel lecteur le soin de trouver une bonne notation.}
	\begin{equation}
		\big( 0,\cos(\theta/2),\sin(\theta/2) \big).
	\end{equation}

	L'image de \( u_1\) par cette réflexion est \(-u_1\), c'est clair.

	Étudions en détail l'image de \( u_3\). Nous devons démontrer que la droite \( D\) coupe le segment \( \mathopen[ u_3 , A(u_3) \mathclose]\) perpendiculairement en son milieu.

	Nous considérons la base \( (u_2, u_3)\) du plan \( \Span(u_2,u_3)\). En utilisant les coordonnées dans cette base, nous avons \( u_3=\begin{pmatrix}
		0 \\
		1
	\end{pmatrix}\) et \( A(u_3)=\begin{pmatrix}
		\sin(\theta) \\
		-\cos(\theta)
	\end{pmatrix}\). Le milieu du segment \( \mathopen[ u_3 , A(u_3) \mathclose]\) est le point
	\begin{equation}
		M=\left( \frac{ \sin(\theta) }{2},\frac{ 1-\cos(\theta) }{2} \right).
	\end{equation}
	Les formules de duplication d'angle du corolaire~\ref{CORooQZDQooWjMXTF} nous permettent d'écrire \( \sin(\theta)\) et \( \cos(\theta)\) en fonction de \( \sin(\theta/2)\) et \( \cos(\theta/2)\), et donc d'exprimer le point \( M\) de la façon suivante :
	\begin{subequations}
		\begin{align}
			M & =\left( \cos(\theta/2)\sin(\theta/2),\frac{ 1-\big( \cos^2(\theta/2)-\sin^2(\theta/2) \big) }{2} \right) \\
			  & =\big( \cos(\theta/2)\sin(\theta/2),\sin^2(\theta/2) \big)                                               \\
			  & =\sin(\theta/2)\big( \cos(\theta/2),\sin(\theta/2) \big).
		\end{align}
	\end{subequations}
	Ce point fait donc partie de la droite \( D\). La droite \( D\) coupe le segment \( \mathopen[ u_3 , A(u_3) \mathclose]\) en son milieu.

	En ce qui concerne l'orthogonalité, nous calculons le produit scalaire
	\begin{equation}
		\big( A(u_3)-u_3 \big)\cdot\begin{pmatrix}
			\cos(\theta/2) \\
			\sin(\theta/2)
		\end{pmatrix}
		=\sin(\theta)\cos(\theta/2)-\big( 1+\cos(\theta) \big)\sin(\theta/2)=0
	\end{equation}
	où nous avons encore utilisé les duplications d'angles et le fait que \( 1=\cos^2(\theta/2)+\sin^2(\theta/2)\) (lemme~\ref{LEMooAEFPooGSgOkF}).

	\item[Si \( \epsilon=-1\) et \( \lambda=1\)] Alors la matrice est
	\begin{equation}
		A=\begin{pmatrix}
			1 & 0            & 0             \\
			0 & \cos(\theta) & \sin(\theta)  \\
			0 & \sin(\theta) & -\cos(\theta)
		\end{pmatrix}.
	\end{equation}
	C'est la symétrie orthogonale par le plan engendré par \( u_1\) et \( v=\cos(\theta/2)u_2+\sin(\theta/2)u_3\).

	Le vecteur \( u_1\) est bien évidemment préservé par \( A\). En ce qui concerne le vecteur \( v\),
	\begin{equation}
		A(v)=\cos(\theta/2)\begin{pmatrix}
			0            \\
			\cos(\theta) \\
			\sin(\theta)
		\end{pmatrix}+\sin(\theta/2)\begin{pmatrix}
			0             \\
			-\sin(\theta) \\
			\cos(\theta)
		\end{pmatrix}=
		\begin{pmatrix}
			0              \\
			\cos(\theta/2) \\
			\sin(\theta/2)
		\end{pmatrix}=v.
	\end{equation}
	Nous avons sauté quelques étapes de calcul mettant en scène les formules de duplication d'angle : exprimer \( \cos(\theta)=\cos^2(\theta/2)-\sin^2(\theta/2)\) et \( \sin(\theta)=2\cos(\theta/2)\sin(\theta/2)\).

	Pour achever, nous devons trouver un vecteur \( w\) perpendiculaire au plan, et montrer qu'il est envoyé par \( A\) sur \( -w\). Un vecteur \( w=xu_1+yu_2+zu_3\) est perpendiculaire au plan si les deux égalités suivantes sont satisfaites :
	\begin{subequations}
		\begin{align}
			\big( \cos(\theta/2)u_2+\sin(\theta/2)u_3 \big)\cdot (xu_1+yu_2+zu_3)=0 \\
			u_1\cdot(xu_1+yu_2+zu_3)=0.
		\end{align}
	\end{subequations}
	Nous avons immédiatement \( x=0\) et ensuite la relation
	\begin{equation}        \label{EQooXQMDooTvwrWk}
		y\cos(\theta/2)+z\sin(\theta/2)=0.
	\end{equation}
	En ne regardant que les deux dernières composantes pour alléger l'écriture,
	\begin{equation}
		A(w)=y\begin{pmatrix}
			\cos(\theta) \\
			\sin(\theta)
		\end{pmatrix}+z\begin{pmatrix}
			\sin(\theta) \\
			-\cos(\theta)
		\end{pmatrix}.
	\end{equation}
	Le but est de montrer que cela est égal à \( -y\cos(\theta/2)-z\sin(\theta/2)\).

	Notons \( c=\cos(\theta/2)\) et \( s=\sin(\theta/2)\). Alors \( A(w)_2=y(c^2-s^2)+2zcs\). Évacuons tout de suite les deux cas limite : si \( c=0\) alors \( A(w)_2=-y\) (parce que \( s=\pm1\)) et c'est bon. Si \( s=0\), alors \( A(w)_2=y\), mais la relation \eqref{EQooXQMDooTvwrWk} donne \( y=0\), donc c'est bon aussi. Dans le cas générique, \( z=-yc/2\) et
	\begin{equation}
		A(w)_2=y(c^2-s^2)-2cs\frac{ yc }{ s }=-y(c^2+s^2)=-y.
	\end{equation}

	En ce qui concerne \( A(w)_3\), c'est très similaire :
	\begin{equation}
		A(w)_3=2ysc-z(c^2-s^2).
	\end{equation}
	Avec \( z=0\) c'est \( -z\), donc c'est bon. Avec \( c=0\) c'est \( z\) mais \( z=0\). Et pour le cas générique, la substitution \( y=-zs/c\) donne le résultat.

	\item[Si \( \epsilon=1\) et \( \lambda=-1\)] Alors la matrice est
	\begin{equation}
		A=\begin{pmatrix}
			-1 & 0            & 0             \\
			0  & \cos(\theta) & -\sin(\theta) \\
			0  & \sin(\theta) & \cos(\theta)
		\end{pmatrix}.
	\end{equation}
	Cela est la composition entre la symétrie de plan \( \Span(u_2,u_3)\) et la rotation d'angle \( \theta\) dans ce plan.
\end{subproof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Sous-groupes finis de \( \SO(3)\)}
%---------------------------------------------------------------------------------------------------------------------------

\begin{lemma}[\cite{MonCerveau}]       \label{LEMooWIMMooXOCfSt}
	Points fixes pour \( \SO(3)\).
	\begin{enumerate}
		\item
		      Tout élément de \( \SO(3)\) possède une droite de points fixes.
		\item
		      Tout élément non trivial de \( \SO(3)\) possède une seule droite de points fixes.
	\end{enumerate}
\end{lemma}

\begin{proof}
	Le polynôme caractéristique d'un élément de \( \SO(3)\) est de degré trois et possède donc (en comptant les multiplicités), trois racines dont une réelle par le corolaire~\ref{CORooKKNWooWEQukb}. Comme nous sommes en dimension impaire, le coefficient du terme de degré \( 3\) est \( -1\) et le polynôme caractéristique de \( g\in\SO(3)\) s'écrit
	\begin{equation}
		\chi_g(X)=-(X-\lambda_1)(X-\bar\lambda_1)(X-s)
	\end{equation}
	avec \( s=\pm1 \) que nous allons tout de suite fixer. Nous savons que \( \det(g)=\chi_g(0)\) mais aussi que \( \det(g)=1\). Donc
	\begin{equation}
		1=\det(g)=\chi_g(0)=\lambda_1\bar\lambda_1 s=s.
	\end{equation}
	Tout cela pour dire que tout élément de \( \SO(3)\) possède une valeur propre égale à \( 1\), et donc une droite de points fixes.

	Pour continuer, supposons que \( g\) possède deux droites distinctes de points fixes. En particulier \( g\) fixe un plan. Une base orthonormée de \( \eR^3\) peut être choisie en prenant deux vecteurs \( e_1\), \( e_2\) dans ce plan et un vecteur \( e_3\) perpendiculaire au plan.

	Puisque \( g\) est une isométrie, la base reste orthonormée sous l'action de \( g\). Donc \( g\) a pour matrice
	\begin{equation}
		\begin{pmatrix}
			1 & 0 & 0     \\
			0 & 1 & 0     \\
			0 & 0 & \pm 1
		\end{pmatrix}.
	\end{equation}
	Pour que le déterminant soit \( 1\), il faut que la matrice soit l'identité.
\end{proof}

\begin{proposition}[\cite{MonCerveau,ooYODPooHeNKiQ,fJhCTE,ooBWVZooJiWRvf,ytMOpe}]      \label{PROPooBHPNooHPlgwH}
	Les sous-groupes finis de \( \SO(3)\) sont :
	\begin{multicols}{2}
		\begin{enumerate}
			\item
			      les groupes cycliques \( \eZ/n\eZ\),
			\item
			      les groupes diédraux \( D_n\),
			\item
			      le groupe alterné \( A_4\),
			\item
			      le groupe alterné \( A_5\)
			\item
			      le groupe symétrique \( S_4\).
		\end{enumerate}
	\end{multicols}
\end{proposition}

\begin{proof}
	Soit \( G\), un sous-groupe fini de \( \SO(3)\). Par la proposition~\ref{PropKBCXooOuEZcS}, les éléments de \( G\) sont des isométries de \( \eR^3\), et le lemme~\ref{LEMooWIMMooXOCfSt} dit que tout élément de \( G\) possède une droite de points fixes.

	Un point de la sphère unité fixé par \( g\in G\) est un \defe{pôle}{pôle} de \( g\). Nous nommons \( \Omega\) l'ensemble des pôles des éléments non triviaux de \( G\).
	\begin{subproof}
		\item[Une action]
		Le groupe \( G\) agit sur \( \Omega\). En effet si \( x\in \Omega\), alors \( x\) est fixé par un élément \( g\). Montrons que \( h(x)\) est également fixé par un élément de \( G\). Pas dur : \( (hgh^{-1})h(x)=h(x)\); donc \( h(x)\) est un pôle de \( h gh^{-1}\).

		\item[Les fixateurs sont cycliques]
		Nous montrons à présent que pour tout \( x\in\Omega\), le sous-groupe \( \Fix(x)\) est cyclique. Soit donc \( x\in\Omega\), le plan orthogonal \( \sigma=\Span(x)^{\perp}\) et \( h\in \Fix(x)\). Nous avons \( h(\sigma)=\sigma\). En effet si \( y\in \sigma\) nous avons
		\begin{equation}
			0=y\cdot x=h(y)\cdot h(x)=h(y)\cdot x,
		\end{equation}
		donc \( h(y)\) est perpendiculaire à \( x\). L'inclusion inverse se démontre de même : si \( y\in \sigma\) alors \( y=h\big( h^{-1}(y) \big)\) alors que \( h^{-1}(y)\in \sigma\).

		La restriction de \( h\) à \( \sigma\) est une isométrie de \( \sigma\). Prenant une isométrie \( f\colon \sigma\to \eR^2\), l'application
		\begin{equation}
			\begin{aligned}
				\varphi\colon \Fix(x) & \to \SO(2)                    \\
				h                     & \mapsto f\circ h\circ f^{-1}.
			\end{aligned}
		\end{equation}
		est un morphisme injectif de groupes. En effet nous avons d'une part
		\begin{equation}
			\varphi(hh')=f\circ h\circ h'\circ f^{-1}=fhf^{-1}fh'f^{-1}=\varphi(h)\varphi(h'),
		\end{equation}
		d'où le morphisme. Et d'autre part, si \( \varphi(h)=\varphi(h')\) alors \( f\circ h\circ f^{-1}=f\circ h'\circ f^{-1}\), qui donne immédiatement \( h=h'\).

		Nous en déduisons que \( \Fix(x)\) est isomorphe à un sous-groupe de \( SO(2)\) (l'image de \( \varphi\)). Le lemme~\ref{LEMooUKEVooAEWvlM} en fait un groupe cyclique.

		\item[Taille des fixateurs]
		Soient \( \Omega_i\) les orbites. Si \( x,y\in \Omega_i\) alors nous montrons que \( | \Fix(x) |=| \Fix(y) |\) avec la bijection
		\begin{equation}
			\begin{aligned}
				\varphi\colon \Fix(x) & \to \Fix(y)       \\
				h                     & \mapsto g^{-1} hg
			\end{aligned}
		\end{equation}
		où \( g\) est choisie de façon à avoir \( y=g(x)\) (possible parce que \( x\) et \( y\) sont dans la même orbite). Cela est surjectif parce que si \( k\in\Fix(x)\) alors \( k=\varphi(gkg^{-1})\) et l'on vérifie que \( gkg^{-1}\in\Fix(y)\). L'application \( \varphi\) est également injective parce que si \( ghg^{-1}=gh'g^{-1}\) alors \( h=h'\).

		\item[Un peu de notations]
		Puisque tous les fixateurs des éléments d'une orbite ont la même taille (finie), nous pouvons noter
		\begin{equation}
			n_i=| \Fix(x_i) |
		\end{equation}
		pour \( x_i\in \Omega_i\). Nous notons également \( r\) le nombre d'orbites de \( G\).

		La formule de Burnside du théorème~\ref{THOooEFDMooDfosOw}, avec les notations d'ici, donne
		\begin{equation}
			r=\frac{1}{ | G | }\sum_{g\in G}| \Fix(g) |.
		\end{equation}

		\item[Une belle formule]
		Soit l'ensemble
		\begin{equation}
			A=\{ (g,x)\tq g\in G\setminus\{ e \}, x\in \Fix(g) \}
		\end{equation}
		où par \( \Fix(g)\) nous entendons les pôles de \( G\) fixés par \( g\).

		Il y a \( | G |-1\) possibilités pour la composante \( g\), mais chaque élément \( g\neq e\) possède exactement deux pôles, donc l'ensemble \( A\) contient exactement \( 2(| G |-1)\) éléments.

		Nous pouvons calculer le nombre d'éléments dans \( A \) d'une autre façon : pour chaque \( x\in \Omega\) nous avons \( | \Fix(x) |-1\) éléments de \( G\setminus\{ e \}\) qui fixent \( x\). Donc
		\begin{equation}
			| A |=\sum_{x\in\Omega}\big( | \Fix(x) |-1 \big).
		\end{equation}
		Mais \( | \Fix(x) |\) est constant sur les orbites. Nous coupons donc la somme sur \( \Omega\) en plusieurs sommes sur les orbites \( \Omega_i\) :
		\begin{equation}
			| A |=\sum_{i=1}^r\sum_{x\in \Omega_i}\big( | \Fix(x) |-1 \big)=\sum_i| \Omega_i |(n_i-1).
		\end{equation}
		En égalisant les deux façons de calculer \( | A |\), nous déduisons la formule
		\begin{equation}        \label{EQooHMLJooTGRBAl}
			2\big( | G |-1 \big)=\sum_i| \Omega_i |(n_i-1).
		\end{equation}

		Nous utilisons ensuite la relation orbite-stabilisateur, proposition~\ref{Propszymlr} : \( | \Fix(x_i) | |\Omega_i |=| G |\); la formule \eqref{EQooHMLJooTGRBAl} devient
		\begin{equation}
			2\big( | G |-1 \big)=\sum_i| G |-\sum_i\frac{ | G | }{ n_i }=r| G |+| G |\sum_i\frac{1}{ n_i },
		\end{equation}
		ou encore, en simplifiant par \( | G |\) :
		\begin{equation}        \label{EQooAMVBooDVcYeG}
			2-\frac{ 2 }{ | G | }=r-\sum_i\frac{1}{ n_i }=\sum_{i=1}^r\left( 1-\frac{1}{ n_i } \right).
		\end{equation}

		Nous pouvons aussi repartir de \eqref{EQooHMLJooTGRBAl} et sommer de façon plus simple \( \sum_i| \Omega_i |=| \Omega |\) pour obtenir
		\begin{equation}        \label{EQooTHUIooUEXsNl}
			2\big( | G |-1 \big)=r| G |-| \Omega |
		\end{equation}
		où \( \Omega\) est l'ensemble des pôles de \( G\setminus\{ e \}\).

		\item[Quelles sont les possibilités ?]
		Les nombres \( | G |\), \( r\) et \( n_i\) sont des entiers. Nous allons voir qu'il n'y a pas des centaines de possibilités pour satisfaire la relation \eqref{EQooAMVBooDVcYeG}. D'abord, pour toute valeur de \( | G |\) (strictement plus grande que \( 1\)),
		\begin{equation}
			1\leq 2-\frac{ 2 }{ | G | }<2.
		\end{equation}
		Ensuite, si \( g\) fixe \( x\) alors \( g^{-1}\) fixe également \( x\), de sorte que \( n_i=| \Fix(x_i) |\geq 2\) pour tout \( i\). Donc tous les termes dans la somme à droite de \eqref{EQooAMVBooDVcYeG} sont dans \( \mathopen[ \frac{ 1 }{2} , 1 \mathclose[\). Nous avons donc au minimum deux termes, et au maximum trois. Autrement dit : \( r=2\) ou \( r=3\).

		\item[Si \( r=2 \)]
		Le plus simple est de repartir de \eqref{EQooTHUIooUEXsNl}. En posant \( r=2\) nous trouvons tout de suite \( | \Omega |=2\). Il y a donc exactement deux pôles pour l'action de \( G\) sur la sphère unité.

		Tous les éléments de \( G\) laissent donc le même axe invariant et \( G\) est un sous-groupe des isométries du plan qui lui est perpendiculaire. Autrement dit, \( G\) est un sous-groupe fini de \( \SO(2)\) et donc cyclique par le lemme~\ref{LEMooUKEVooAEWvlM}.
    \end{subproof}
    Nous étudions à présent le cas \( r=3\). Vu que ça va être un peu long, nous sautons un niveau d'indentation.
    \begin{subproof}

		\item[Les possibilités pour \( r=3 \)]
		Nous devons voir les solutions entières \( (n_1,n_2,n_3,| G |)\) de
		\begin{equation}
			2-\frac{ 2 }{ | G | }=3-\frac{1}{ n_1 }-\frac{1}{ n_2 }-\frac{1}{ n_3 }<2.
		\end{equation}
		Il faut en particulier que
		\begin{equation}
			\frac{1}{ n_1 }+\frac{1}{ n_2 }+\frac{1}{ n_3 }>1,
		\end{equation}
		ce qui signifie qu'au moins un des \( n_i\) doit être \( 1\) ou \( 2\), mais qu'il n'est pas possible que tous les \( n_i\) soient plus grands ou égaux à \( 3\). Puisque \( n_i=| \Fix(x_i) |\geq 2\), nous en déduisons qu'au moins un des \( n_i\) doit valoir \( 2\). Nous posons donc \( n_1=2\).

		De plus, nous savons que les \( n_i\) doivent diviser \( | G |\). Donc \( | G |\) est pair.

		\item[Si \( n_2=2 \)]
		Nous sommes dans le cas \( r=3\), \( n_1=2\), \( n_2=2\). Nous avons
		\begin{equation}
			\frac{1}{ n_3 }=\frac{ 2 }{ | G | },
		\end{equation}
		mais aussi \( n_3=| G |/| \Omega_3 |\) d'où nous déduisons que \( | \Omega_3 |=2\). Nous avons donc une orbite à deux éléments. Soit \( \Omega_3=\{ x,y \}\) avec \( x\neq y\).

		Le groupe \( \Fix(x)\) est un groupe à \( | G |/2\) éléments. Il est donc normal par le lemme~\ref{LemSkIOOG}. Si \( g\in G\) est tel que \( g(x)=y\) alors nous avons \( \Fix(y)=g\Fix(x)g^{-1}\), mais comme \( \Fix(x)\) est normal nous avons \( \Fix(x)=\Fix(y)\). Donc tous les éléments de \( \Fix(x)\) fixent \( x\) et \( y\). Le groupe \( \Fix(x)\) est donc un sous-groupe de \( \SO(2)\) et est cyclique, comme vu plus haut.

		Mais de plus nous avons forcément \( y=-x\) parce qu'un élément de \( G\) qui fixe un point fixe également l'opposé. Vu que \( \Omega_3=\{ x,-x \}\), il existe \( s\in G\) tel que \( s(x)=-x\). Évidemment, \( s\) n'est pas dans \( \Fix(x)\) et les points fixes de \( s\) ne sont pas parmi \( x\) et \( -x\). Donc l'élément \( s^2\) a au moins \( 4\) points fixes : les deux de \( s\) ainsi que \( x\) et \( -x\). Il a donc au moins deux droites de points fixes, et est donc l'identité : \( s^2=e\).

		De plus, vu que \( s(y)\) doit être égal soit à \( x\) soit à \( y\), et que \( s(x)=y\), l'injectivité de \( s\) donne \( s(y)=x\).

		Soit \( a\), un générateur de \( \Fix(x)\). Nous allons montrer que \( G=\gr(s,sa)\). Nous avons déjà
		\begin{subequations}
			\begin{align}
				(sa)(x) & =s(x)=y \\
				(sa)(y) & =s(y)=x.
			\end{align}
		\end{subequations}
		Donc \( sa\) inverse \( x\) et \( y\). Mais \( sa\) a ses propres deux points fixes (qui ne sont ni \( x\) ni \( y\)). L'élément \( (sa)^2\) a donc quatre points fixes sur la sphère unité : \( x\), \( y\) et les deux de \( sa\). Nous en déduisons que \( (sa)^2=e\).

		Nous nous souvenons que \( a\) est un générateur \( \Fix(x)\). Mais \( a=s\cdot sa\), donc \( a^k=(ssa)^k\). Nous en déduisons que \( \gr(s,sa)\) contient au moins \( \Fix(x)\).

		D'autre part si \( h\) et \( h'\) sont des éléments distincts dans \( \Fix(x)\), alors \( sh\) et \( sh'\) sont des éléments distincts de \( \gr(s,sa)\) qui ne sont pas dans \( \Fix(x)\). Autrement dit, la partie
		\begin{equation}
			A=\{ sh\tq h\in Fix(x) \}
		\end{equation}
		est une partie de même cardinal que \( \Fix(x)\) tout en n'ayant aucune intersection avec \( \Fix(x)\) (note : l'identité n'est pas dans \( A\)). Mais \( | \Fix(x) |=| G |/2\), donc \( A\cup\Fix(x)=G\). Et justement \( A\cup G\subset \gr(s,sa)\). Nous en déduisons que \( \gr(s,sa)=G\).

		Le théorème~\ref{THOooYITHooTNTBuG} nous assure que le groupe \( G\) est alors le groupe diédral parce que les éléments \( s\) et \( sa\) vérifient les relations données en~\ref{NORMooCCUEooRRENed}.

		\item[Si \( r=3\), les autres cas possibles]
		Nous repartons de \eqref{EQooAMVBooDVcYeG} en posant \( r=3\). Nous obtenons ceci :
		\begin{equation}
			1+\frac{ 2 }{ | G | }=\frac{1}{ n_1 }+\frac{1}{ n_2 }+\frac{1}{ n_3 }.
		\end{equation}
		Nous avons déjà vu que \( n_1=2\) était obligatoire, et que tous les cas où deux des \( n_i\) sont égaux à \( 2\) sont déjà couverts. Donc \( n_2\) et \( n_3\) valent \( 3\) ou plus.

		Nous trions les \( n_i\) dans l'ordre croissant. Si \( n_2=4\) ou plus, alors \( n_3\) vaut \( 4\) ou plus. Mais
		\begin{equation}
			\frac{ 1 }{2}+\frac{1}{ 4 }+\frac{1}{ 4 }=1<1+\frac{ 2 }{ | G | }.
		\end{equation}
		Donc \( n_3=3\) est obligatoire. Nous avons alors l'inégalité suivante qui restreint \( n_3\) :
		\begin{equation}
			\frac{1}{ n_3 }=\frac{1}{ 6 }+\frac{ 3 }{ | G | }>\frac{1}{ 6 }.
		\end{equation}
		Donc \( n_3\) est \( 3\), \( 4\) ou \( 5\).

		Les derniers cas à couvrir sont :
		\begin{itemize}
			\item \( (n_1,n_2,n_3)=(2,3,3)\). Dans ce cas, \( \frac{ 7 }{ 6 }=1+\frac{ 2 }{ | G | }\), donc \( | G |=12\).
			\item \( (n_1,n_2,n_3)=(2,3,4)\). Dans ce cas, \( | G |=24\).
			\item \( (n_1,n_2,n_3)=(2,3,5)\). Dans ce cas, \( | G |=60\).
		\end{itemize}

		\item[Le cas \( (2,3,3)\)]

		Nous utilisons les relations \( n_i| \Omega_i |=| G |\) pour connaître la taille des orbites. Nous avons :
		\begin{enumerate}
			\item
			      \( 2| \Omega_1 |=12\), donc \( | \Omega_1 |=6\),
              \item
			      \( 3| \Omega_2 |=12\), donc \( | \Omega_2 |=4\),
              \item
			      \( 3| \Omega_3 |=12\), donc \( | \Omega_3 |=4\).
		\end{enumerate}

		Nous avons \( G\cdot \Omega_2=\Omega_2\). D'une part parce que, par définition d'une orbite, \( G\cdot\Omega_2\subset\Omega_2\), et d'autre part parce que si \( x\in\Omega_2\), alors \( g^{-1}(x)\in\Omega_2\) et \( g\big( g^{-1}(x) \big)=x\); donc \( \Omega_2\) est bien dans l'image de \( \Omega_2\) par \( G\). Nous avons donc un morphisme \( s\colon G\to S_{\Omega_2}\) que nous allons immédiatement voir comme
		\begin{equation}
			s\colon G\to S_4
		\end{equation}
		où \( S_4\) est le groupe des permutations de \( \{ 1,2,3,4 \}\).

		Voyons que \( s\) est injective. Si \( s(g)=s(h)\), alors \( s(gh^{-1})=\id\). Autrement dit, l'élément \( sh^{-1}\) de \( G\) est l'identité sur \( \Omega_2\) qui contient \( 4\) éléments. Fixant \( 4\) points (au moins), l'élément \( sh^{-1}\) est l'identité. Par conséquent
		\begin{equation}
			s\colon G\to s(G)\subset S_4
		\end{equation}
		est un isomorphisme entre \( G\) et un sous-groupe de \( S_4\). Mais \( | G |=12\) et \( | S_4 |=24\), donc \( G\) est d'indice deux dans \( S_4\) et est donc le groupe alterné \( A_4\) par la proposition~\ref{PROPooCPXOooVxPAij}\ref{ITEMooGGAHooRYgNqq}.

		\item[Le cas \( (2,3,4)\)]
		Nous avons \( | G=24 |\) et les orbites ont pour taille :
		\begin{itemize}
			\item \( 2| \Omega_1 |=24\), donc \( | \Omega_1 |=12\),
			\item \( 3| \Omega_2 |=24\), donc \( | \Omega_2 |=8\),
			\item \( 4| \Omega_3 |=24\), donc  \( | \Omega_3 |=6\).
		\end{itemize}

		\begin{subproof}
			\item[\( \Omega_2\) vient par paires]
			Soit \( x\in \Omega\) tel que \( | \Fix(x) |=3\). Alors \( x\in\Omega_2\) parce que \( x\) est forcément dans un des \( \Omega_i\) et tout élément \( x_i\) de \( \Omega_i\) vérifie \( | \Fix(x_i) |=n_i\). Mais comme les éléments de \( \SO(3)\) sont des applications linéaires, ceux qui fixent \( x\) fixent également \( -x\). Cela pour dire que si \( x\in\Omega_2\), alors \( -x\in\Omega_2\). Nous avons donc quatre éléments distincts \( a_1\), \( a_2\), \( a_3\) et \( a_4\) tels que
			\begin{equation}
				\Omega_2=\{ \pm a_1,\pm a_2,\pm a_3,\pm a_4 \}.
			\end{equation}

			\item[Action sur les couples]
			Nous prétendons que \( G\) agit sur l'ensemble des couples \( \{ \pm a_i \}\). C'est encore la linéarité qui joue : l'élément \( g(a_i)\) est forcément un des \( \pm a_k\) (éventuellement \( k=i\)). Si \( g(a_i)=a_k\), alors \( g(-a_i)=-a_k\). Autrement dit, pour tout \( i\), il existe un \( k\) tel que \( g\big( \{ a_i,-a_i \} \big)=\{ a_k,-a_k \}\). Cette association \( i\mapsto k\) est bijective (sinon \( g\) ne serait pas bijective), et fournit donc un morphisme de groupes
			\begin{equation}
				s\colon G\to S_4.
			\end{equation}

			\item[\( s\) est injective]
			Nous prouvons à présent que \( s(g)=\id\) si et seulement si \( g=e\). Dans un sens c'est évident : \( g(e)=\id\). Dans l'autre sens, nous devons prouver que si \( g(a_i)\in \pm a_i\) pour tout \( i\) alors \( g=e\).

			Si \( g(a_i)=a_i\) pour tout \( i\), alors \( g\) stabilise \( 4\) points et l'affaire est pliée. Nous supposons qu'au moins un des \( a_i\) n'est pas stabilisé par \( g\). Pour fixer les idées nous disons que c'est \( a_1\). Nous avons donc \( g(a_1)=-a_1\). (oui : \( g(a_1)=-a_1\) et non \( \pm a_k\) pour un autre \( k\) parce que nous sommes sous l'hypothèse que \( g\) stabilise les couples)

			L'élément \( g^2\) fixe tout \( \Omega_2\); donc \( g^2=e\). Nommons \( \pm b\) les points fixes de \( g\). Si \( b\in \Omega_2\) alors \( | \Fix(b) |=3\), c'est-à-dire que les éléments de \( G\) qui fixent \( b\) sont dans un groupe d'ordre \( 3\), et le corolaire~\ref{CorpZItFX} nous indique que ces éléments ne peuvent être que d'ordre \( 1\) ou \( 3\), pas deux. Nous en déduisons que \( b\) n'est pas dans \( \Omega_2\) et donc que \( g(a_i)=-a_i\) pour tout \( i\).

			Jusqu'à présent nous avons prouvé que si \( g\in \ker(s)\) est non trivial,  alors \( g(a_i)=-a_i\) pour tout \( i\).

			Soit maintenant \( h\in G\). Comme \( \Omega_2\) est une orbite, \( h(a_i)\in \Omega_2\) et nous notons \( h(a_i)=\epsilon a_k\) avec \( \epsilon=\pm 1\) et éventuellement \( k=i\) ou éventuellement pas. Nous avons :
			\begin{equation}
				(h^{-1}gh)(a_i)=\epsilon (h^{-1} g)(a_k)=-\epsilon h^{-1}(a_k)=-\epsilon^2 a_i=-a_i.
			\end{equation}
			Donc \( g\) et \( h^{-1} g h\) ont même restriction à \( \Omega_2\). En particulier \( h^{-1} ghg^{-1}\) est l'identité sur \( \Omega_2\) et est donc l'identité.

			Pour tout \( h\) nous avons \( g=h^{-1} gh\). Les points fixes de \( h^{-1}g h\) sont \( \pm h^{-1}(b)\), mais aussi \( \pm b\). Nous avons donc égalité d'ensemble \( \{ h(b),-h(b) \}=\{ b,-b \}\) pour tout \( h\in G\) (notez le changement de notation \( h\to h^{-1}\)). Cela signifie que \( \{ b,-b \}\) est une orbite de \( G\). Maizon'a pas d'orbites de cardinal deux; contradition. Nous en déduisons que \( e\) est l'unique élément de \( \ker(s)\).

			\item[Conclusion]
			La partie \( s(G)\) est un sous-groupe de \( S_4\) isomorphe à \( G\). Mais au niveau des cardinaux, \( | G |=24\) en même temps que \( | S_4 |=24\). Donc \( G\simeq s(G)\simeq S_4\).
		\end{subproof}
	\end{subproof}

	Nous passons au cas \( (2,3,5)\), et comme ça va être long et douloureux\footnote{Mais pas autant que le théorème~\ref{THOooSTHXooXqLBoT}, cependant.}, nous sautons un niveau d'indentation.

	Au niveau du cardinal de \( G\),
	\begin{equation}
		\frac{1}{ 2 }+\frac{1}{ 3 }+\frac{1}{ 5 }=1+\frac{ 2 }{ | G | },
	\end{equation}
	donc \( | G |=60\). Et pour les orbites, \( | \Omega_1 |=30\), \( | \Omega_2 |=20\), \( | \Omega_3 |=12\).

	La proposition~\ref{PROPooUBIWooTrfCat} nous indique que le seul groupe simple d'ordre \( 60\) est le groupe \( A_5\). Nous allons donc nous atteler à prouver que \( G\) est simple. Vous êtes prêts ?

	\begin{subproof}
		\item[Fixateurs et ordres]
		Tous les éléments de \( G\) sont dans un fixateur de type \( \Fix(x)\), et comme l'ordre d'un élément divise l'ordre du groupe (corolaire~\ref{CorpZItFX}), tous les éléments de \( G\) ont un ordre \( 2\), \( 3\) ou \( 5\). Nous sommes dans un cas très particulier parce que
		\begin{itemize}
			\item Les trois nombres \( 2\), \( 3\) et \( 5\) sont des nombres premiers distincts. Donc «diviser \( n_i\)» signifie pratiquement «être égal à \( n_i\)», surtout lorsqu'on parle de l'ordre d'un élément, qui ne peut pas être \( 1\).
			\item Il existe une seule orbite de chaque taille.
		\end{itemize}
		Nous notons \( G(n_i)\) l'ensemble des éléments de \( G\) d'ordre \( n_i\). Les parties \( G(n_i)\) ne contiennent pas l'identité.

		\item[\( g\in G(n_i)\) implique \( \Fix(g)\subset \Omega_i\)]
		Si \( g\in G(n_i)\) et \( x\in\Fix(g)\) alors \( x\in \Omega_i\). En effet \( x\in Fix(g)\) signifie \( g(x)=x\) et donc aussi \( g\in\Fix(x)\). Donc l'ordre de \( g\) divise \( | Fix(x) |\), alors que l'ordre de \( g\) est \( n_i\) et que les possibilités pour \( | \Fix(x) |\) sont exactement les \( n_i\), lesquels sont premiers entre eux. Donc \( | \Fix(x) |=n_i\) et \( x\in \Omega_i\).

		\item[\( | \Fix(x) |=n_i\) implique \( x\in \Omega_i\)]
		Comme plus haut, \( g\in\Fix(x)\) implique que l'ordre de \( g\) divise \( n_i\) et est donc égal à \( n_i\). Autrement dit, \( g\in G(n_i)\). De plus \( g\in\Fix(x)\) implique \( x\in\Fix(g)\). Par le cas juste au-dessus nous déduisons \( x\in\Omega_i\).

		\item[\( a\) et \( -a\) dans la même orbite]

		Nous avons évidemment \( \Fix(a)=\Fix(-a)\) parce que les éléments de \( G\) sont des applications linéaires. Si \( | \Fix(a) |=n_i\) alors \( a\in\Omega_i\) et aussi \( | \Fix(-a) |=| \Fix(a) |=n_i \) et encore \( -a\in \Omega_i\).

		\item[Nombre de \( \Fix(x_i)\)]
		Soient \( a,b\in \Omega_i\). Nous avons \( | \Fix(a) |=| \Fix(b) |=n_i\) et \( \Fix(a)=\Fix(b)\) si et seulement si \( b=-a\) parce qu'un élément qui fixe \( a\) et \( b\) fixe automatiquement \( a\), \( b\), \( -a\), et \( -b\). Aucun élément non trivial ne peut fixer quatre points distincts. Autrement dit,
		\begin{equation}
			\Fix(a)\cap\Fix(b)=\begin{cases}
				\Fix(a) & \text{si } a=\pm b \\
				\{ e \} & \text{sinon. }
			\end{cases}
		\end{equation}
		Chaque élément \( x_i\in \Omega_i\) a son fixateur (il y en aurait \( | \Omega_i |=60/n_i\)), mais ces fixateurs sont égaux deux à deux, donc il y a seulement \( \frac{ 60 }{ 2n_i }\) groupes distincts de la forme \( | \Fix(x_i) |\) avec \( x_i\in \Omega_i\).

		\item[Récapitulatif]
		En reprenant ce que nous venons de dire avec \( i=1,2,3\) nous trouvons :
		\begin{enumerate}
			\item
			      \( n_1=2\), avec \( | \Omega_1 |=30\) et \( 15\) groupes du type \( \Fix(x_1)\) avec \( x_1\) parcourant \( \Omega_1\).
			\item
			      \( n_2=3\), avec \( | \Omega_2 |=20\) et \( 10\) groupes du type \( \Fix(x_2)\) avec \( x_2\) parcourant \( \Omega_2\).
			\item
			      \( n_3=5\), avec \( | \Omega_3|=12\) et \( 6\) groupes du type \( \Fix(x_3)\) avec \( x_3\) parcourant \( \Omega_3\).
		\end{enumerate}
		Un élément non trivial de \( G\) se trouve forcément dans un et un seul de ces sous-groupes. Plus précisément, si \( g\in G(n_i)\) alors \( g\) est dans un des \( \Fix(x_i)\) avec \( x_i\in \Omega_i\).

		Comptons pour être sûr de ne pas s'être trompé. Chacune des lignes décrit \( 30\) éléments de \( G\); par exemple, la seconde ligne donne \( 10\) groupes de taille \( | \Fix(x_2) |=n_2=3\). Mais tous ces groupes ont pour intersection exactement \( \{ e \}\). Donc le comptage des éléments se fait comme suit :
		\begin{equation}
			3\times 30-15-10-6+1.
		\end{equation}
		Le dernier \( +1\) est parce que nous aurions décompté l'identité une fois de trop. Bref, on a bien \( 60\) éléments comme il se doit.

		\item[Un ensemble à calculer deux fois]
		Soient les ensembles \( A_2\), \( A_3\) et \( A_5\) définis par
		\begin{equation}
			A_i=\{ (g,a)\in G(n_i)\times \Omega_i\tq g(a)=a  \}
		\end{equation}
		où \( G(n_i)\) est la partie de \( G\) des éléments d'ordre \( n_i\).

		Nous avons
		\begin{equation}
			| A_i |=\sum_{g\in G(n_i)}| \Fix(g)\cap \Omega_i |.
		\end{equation}
		Mais les éléments de \( G(n_i)\) sont d'ordre \( n_i\), et par ce que nous avons dit plus haut, tous les éléments de \( \Fix(g)\) sont dans \( \Omega_i\). Donc \( \Fix(g)\cap \Omega_i=\Fix(g)\). Nous avons alors
		\begin{equation}
			| A_i |=\sum_{g\in G(n_i)}| \Fix(g) |=2|G(n_i)|
		\end{equation}
		parce que \( | \Fix(g) |=2\) pour tout \( g\).

		En comptant \( | A_i |\) dans l'autre sens, nous avons
		\begin{equation}        \label{EQooBHIIooVcGgFd}
			| A_i |=\sum_{x\in \Omega_i}|  \Fix(x)\cap G(n_i) |
		\end{equation}
		Vu que \( x\in \Omega_i\), les éléments de \( \Fix(x)\) sont d'ordre \( n_i\)\footnote{Encore et toujours parce que les éléments de \( \Fix(x)\) ont un ordre qui divise \( | \Fix(x) |=n_i\) et que \( n_i\) est premier, et que nous avons exclu l'identité.} (sauf \( e\)), et comme \( G(n_i)\) est justement l'ensemble des éléments d'ordre \( n_i\) dans \( G\) nous avons \( \Fix(x)\cap G(n_i) = \Fix(x)\setminus\{ e \}\). Cela pour dire que
		\begin{subequations}
			\begin{align}
				| A_i | & =\sum_{x\in \Omega_i}\Big( |\Fix(x)|-1\Big)                                                       \\
				        & =\sum_{x\in \Omega_i}| \Fix(x) |-\sum_{x\in \Omega_i}1                                            \\
				        & =\sum_{x\in \Omega_i}n_i-| \Omega_i |                  & | \Fix(x) |=n_i \text{ pcq }x\in\Omega_i \\
				        & =| \Omega_i |n_i-| \Omega_i |=| G |-| \Omega_i |.
			\end{align}
		\end{subequations}
		En égalisant cela à la valeur \( 2|G(n_i)|\) déjà trouvée, nous déduisons les valeurs des \( | G(n_i) |\) :
		\begin{equation}
			| G(n_i) |=\frac{ | G |-| \Omega_i | }{2}.
		\end{equation}
		Nous avons alors
		\begin{enumerate}
			\item
			      \( | G(2) |=15\)
			\item
			      \( | G(3) |=20\)
			\item
			      \( | G(5) |=24\)
		\end{enumerate}

		\item[Les Sylow de \( G\)]
		Les \( p\)-Sylow sont définis en~\ref{DEFooPRCHooVZdwST}, et le super théorème qui répond à toutes les questions est le théorème~\ref{ThoUkPDXf}. Dans notre cas, les diviseurs premiers de \( | G |=60\) sont \( 2\), \( 3\) et \( 5\). Il faut faire attention au \( 2\) parce que sa plus haute puissance dans la décomposition de \( 60\) est \( 4\) et non \( 2\). Nous avons :
		\begin{enumerate}
			\item
			      Un \( 2\)-Sylow est un sous-groupe d'ordre \( 4\).
			\item
			      Un \( 3\)-Sylow est un sous-groupe d'ordre \( 3\).
			\item
			      Un \( 5\)-Sylow est un sous-groupe d'ordre \( 5\).
		\end{enumerate}
		Entre autres :
		\begin{enumerate}
			\item
			      Les \( 10\) sous-groupes \( \Fix(x_2)\) avec \( x_2\in \Omega_2\) sont des \( 3\)-Sylow de \( G\).
			\item
			      Les \( 6\) sous-groupes \( \Fix(x_3)\) avec \( x_3\in \Omega_3\) sont des \( 5\)-Sylow de \( G\).
			\item
			      Les \( 15\) sous-groupes \( \Fix(x_1)\) avec \( x_1\in \Omega_1\) sont d'ordre \( 2\) et ne sont donc pas des \( 2\)-Sylow de \( G\).
		\end{enumerate}

		\item[Tous les \( 3\)-Sylow et les \( 5\)-Sylow]
		Nous avons déjà trouvé \( 10\) \( 3\)-Sylow et \( 6\) \( 5\)-Sylow. Nous montrons à présent qu'il n'y en a pas d'autres. Le théorème de Sylow~\ref{ThoUkPDXf}\ref{ItemkYbdzZ} nous indique que le nombre \( n_3\) de \( 3\)-Sylow est :
		\begin{itemize}
			\item diviseur de \( 60\),
			\item dans \( [1]_3\)
			\item au moins \( 10\).
		\end{itemize}
		Les diviseurs de \( 60\) sont :
		\begin{equation}
			1,5,3,15,2,10,6,30,4,20,12,60.
		\end{equation}
		Le seul qui vérifie toutes les conditions est \( 10\). Donc \( G\) possède seulement \( 10\) \( 3\)-Sylow et ils sont tous de la forme \( \Fix(x_2)\) avec \( x_2\in \Omega_2\).

		Même raisonnement pour les \( 5\)-Sylow : il faut
		\begin{itemize}
			\item diviseur de \( 60\),
			\item dans \( [1]_5\)
			\item au moins \( 6\).
		\end{itemize}
		La seule possibilité est \( 6\).

		\item[Sous-groupe normal]
		Soit \( H\), un sous-groupe normal de \( G\). Notre but étant de prouver que \( G\) est simple, nous voulons prouver que \( H\) est soit \( \{ e \}\) soit \( G\). Nous supposons que \( H\) est non trivial, et nous allons prouver que \( H=G\).

		Le théorème de Lagrange~\ref{ThoLagrange}\ref{ITEMooDPKSooNpOusd} nous dit que \( | H |\) divise \( | G |\). Le nombre \( | H |\) ne peut donc avoir que \( 2\), \( 3\) et \( 5\) comme facteurs premiers. Avec une mention spéciale pour le \( 2\) : \( | H |\) pourrait être divisible aussi par \( 4\).

		\item[Diviseurs de \( | H |\)]

		Soit un sous-groupe normal \( H\) de \( G\). Puisque c'est un sous-groupe, son ordre divise celui de \( G\) (encore et toujours le théorème de Lagrange~\ref{ThoLagrange}), et donc les facteurs premiers de \( | H |\) ne peuvent être que \( 2\), \( 3\) et \( 5\).

		\item[Si \( | H |\) est divisible en \( 3\)]
		Alors \( H\) contient au moins un \( 3\)-Sylow. Mais nous avons vu que les \( 3\)-Sylow de \( H\) sont les \( 3\)-Sylow de \( G\). Donc \( H\) contient tous les \( 3\)-Sylow de \( G\), parce que les \( 3\)-Syow sont conjugués et \( H\) est normal.

		Soit \( E\) l'ensemble des sous-groupes de \( H\). Puisqu'il est normal, \( H\) agit sur \( E\) par conjugaison, et les \( 3\)-Sylow forment une orbite. Si \( \alpha\) est un \( 3\)-Sylow, la formule des classes (proposition~\ref{Propszymlr}\ref{ITEMooCWUGooCOFHYk}) nous donne
		\begin{equation}
			| H |=| \Fix(\alpha) | |\mO_{\alpha} |.
		\end{equation}
		Mais l'orbite \( \mO_{\alpha}\) de \( \alpha\) est l'ensemble des \( 3\)-Sylow, de sorte que \( | \mO_{\alpha} |=10\). Donc \( | H |\) est divisible en \( 10\).

		Mais il y a pire : \( H\) contient au moins les \( 10\) sous-groupes \( \Fix(x_2)\) pour \( x_2\in \Omega_2\). Ce sont \( 10\) groupes de \( | \Fix(x_2) |=3\) éléments. En décomptant \( e\) qui est dans l'intersection, cela fait
		\begin{equation}
			10\times | \Fix(x_2) |-10+1=21
		\end{equation}
		éléments. Donc \( H\) contient au moins \( 21\) éléments. Le nombre \( | H |\) est donc :
		\begin{itemize}
			\item diviseur de \( 60\)
			\item multiple de \( 10\)
			\item au moins \( 21\).
		\end{itemize}
		Donc c'est \( 30\) ou \( 60\).

		\item[Si \( | H |\) est divisible en \( 5\)]
		Le même raisonnement tient et \( | H |\) est \( 30\) ou \( 60\).
	\end{subproof}

	Nous restons avec les possibilités \( | H |\) égal à \( 2\), \( 4\), \( 30\) ou \( 60\).

	\begin{subproof}
		\item[Si \( | H | = 4\)]

		Alors \( H\) contient au moins un \( 2\)-Sylow. Un \( 2\)-Sylow de \( H\) est un sous-groupe contenant \( 4\) éléments qui sont d'ordre \( 2^m\). Le seul \( m\) possible dans \( G\) est \( m=1\). Vu qu'un \( 2\)-Sylow de \( H\) contient \( 4\) éléments, nous sommes dans le cas où \( H\) est un \( 2\)-Sylow. Il est donc le seul \( 2\)-Sylow de \( H\) parce que \( H\) est normal, et que tous les \( 2\)-Sylow sont conjugués.

		Mais tous les sous-groupes d'ordre \( 2\) sont contenus dans un \( 2\)-Sylow. En particulier tous les \( 15\) groupes \( \Fix(x_1)\) sont dans l'unique \( 2\)-Sylow \( H\) qui est soit-disant d'ordre \( 4\). IL y a là une belle impossibilité.

		Donc, le cas \( | H |=4\) est hors-concours.

		\item[Si \( | H |=2\)]
		Alors \( H=\{ e,g \}\) avec \( g^2=e\). Si \( h\in G\), l'élément \( hgh^{-1}\) ne peut être que \( e\) ou \( g\) (parce que \( H\) est normal). Le premier cas est \( g=e\), et le second donne \( gh=hg\). Donc \( g\) est dans le centre de \( G\) : il commute avec tous les éléments de \( G\).

		Comme \( g\in G(2)\), nous savons que les éléments \( a\in\Fix(g)\) sont forcément dans \( \Omega_1\) parce que les points dont les fixateurs sont formés d'éléments d'ordre \( 2\) sont dans \( \Omega_1\). Soit \( h\in G\). Nous avons \( g=hgh^{-1}\) et donc aussi
		\begin{equation}
			\big( hgh^{-1} \big)\big( h(a) \big)=hg(a)=h(a),
		\end{equation}
		donc \( h(a)\) et \( -h(a)\) sont des points fixes de \( hgh^{-1}\). Ce sont donc également des points fixes de \( g\). Nous en déduisons que \( g\) a pour points fixes les points \( a\), \( -a\), \( h(a)\) et \( -h(a)\). Puisque \( g\) n'est pas \( e\), ces quatre points ne peuvent pas être distincts. Comme \( h(a)\) ne peut pas être \( -h(a)\), nous avons forcément \( h(a)=\pm a\).

		Donc l'orbite de \( a\) ne contiendrait que \( 2\) éléments. Pas possible.

		\item[Si \( | H |=30\)]
		À part \( | H |=60\), le dernier cas à traiter est \( | H |=30\). Nous rappelons obligeamment que
		\begin{enumerate}
			\item
			      \( | G(2) |=15\)
			\item
			      \( | G(3) |=20\)
			\item
			      \( | G(5) |=24\).
		\end{enumerate}
		Si \( H\) possède \( 30\) éléments, le théorème de Sylow dit que \( H\) contient au moins un \( 3\)-Sylow et un \( 5\)-Sylow, et donc tous. Puisque pour \( 3\) et \( 5\), les Sylow de \( H\) et de \( G\) sont les mêmes et bien identifiés, nous allons nous baser dessus. Le sous-groupe \( H\) contient tous les \( 3\) et \( 5\)-Sylow, donc le comptage des éléments est :
		\begin{equation}
			10\times | \Fix(x_2) |+6\times | \Fix(x_3) |-15=45.
		\end{equation}
		Nous aurions aussi pu ajouter \( +4-1\) pour compter au moins un \( 2\)-Sylow.

		Donc dès que \( H\) compte \( 30\) éléments, il en compte au moins \( 45\). Autrement dit le cas \( | H |=30\) est impossible.
	\end{subproof}
\end{proof}

\begin{probleme}
	La démonstration des groupes finis de \( \SO(3)\) est longue. Je me demande si il n'y a pas moyen de faire plus court. Par exemple \cite{ooYODPooHeNKiQ} utilise le théorème de Cauchy~\ref{THOooSUWKooICbzqM} que je n'utilise pas. D'autre part, toutes les références me semblent utiliser plus ou moins implicitement le fait que si le sous-groupe normal \( H\) contient un élément de \( G(n_i)\), alors il les contiennent tous. J'avoue ne pas trop comprendre pourquoi.
\end{probleme}
