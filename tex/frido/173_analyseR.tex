% This is part of Mes notes de mathématique
% Copyright (c) 2006-2019
%   Laurent Claessens, Carlotta Donadello
% See the file fdl-1.3.txt for copying conditions.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Formes différentielles}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\label{SecFormDiffRappel}

Nous parlerons de formes différentielles exactes et fermées dans la section~\ref{DefEFKQmPs}.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Décomposition dans la base duale}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}      \label{DEFooMGXSooWioKie}
	Soit $U$, un ouvert dans $\eR^n$. Une $1$-\defe{forme différentielle}{forme!différentielle} $\omega$ sur $U$ est une application
	\begin{equation}
		\begin{aligned}
				\omega\colon U&\to (\eR^n)^* \\
				x&\mapsto \omega_x.
			\end{aligned}
		\end{equation}
\end{definition}

\begin{remark}
	L'ensemble des $1$-formes différentielles forment un espace vectoriel avec les définitions
	\begin{equation}
		\begin{aligned}[]
			(\lambda\omega)_x(v)&=\lambda\omega_x(v)\\
			(\omega+\mu)_x(v)&=\omega_x(v)+\mu_x(v).
		\end{aligned}
	\end{equation}
\end{remark}

Nous connaissons la de $(\eR^n)^*$ définie en \ref{DEFooTMSEooZFtsqa}. Nous allons noter ces formes par $dx_i$ :
\begin{equation}        \label{EQooITHKooDzigPY}
	\begin{aligned}[]
		e^*_1&=dx_1\colon v\mapsto v_1	\\
			&\vdots			\\
		e^*_n&=dx_n\colon v\mapsto v_n
	\end{aligned}
\end{equation}
Toute forme différentielle s'écrit
\begin{equation}
  \omega_x = \sum_{i=0}^n a_i(x) d x_i
\end{equation}
où $a_1,\ldots,a_n$ sont les composantes de $\omega$ dans la base usuelle, et sont des fonctions à valeurs réelles.

\begin{lemma}
    Une $1$-forme différentielle est \defe{continue}{continue!forme différentielle} si les fonctions $a_i$ sont continues. La forme sera $C^k$ quand les $a_i$ seront $C^k$.
\end{lemma}

Pour un vecteur $v = (v_1,\ldots,v_n)$ on a donc par définition de $d x_i$
\begin{equation}
  \omega_x (v) = \sum_{i=0}^n a_i(x) v_i.
\end{equation}
Ces fonctions $a_i$ peuvent être trouvées en appliquant $\omega$ aux éléments de la base canonique de $\eR^n$ :
\begin{equation}
	a_j(x)=\omega_x(e_j)
\end{equation}
parce que $\omega_x(e_j)=\sum_ia_i(x)dx_i(e_i)=\sum_ia_i(x)\delta_{ij}=a_j(x)$.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{L'isomorphisme musical}
%---------------------------------------------------------------------------------------------------------------------------

Si $G$ est un champ de vecteur sur $\eR^n$, et si $x\in\eR^n$, nous pouvons définissons
\begin{equation}		\label{EqDefBemol}
	\begin{aligned}[]
		G^{\flat}_x\colon \eR^n&\to \eR \\
			v&\mapsto \langle G(x), v\rangle
	\end{aligned}
\end{equation}

Pour chaque $x$, l'application $G_x^{\flat}$ est une forme sur $\eR^n$, c'est-à-dire une application linéaire de $\eR^n$ vers $\eR$. Nous écrivons que
\begin{equation}
	G_x^{\flat}\in\big( \eR^n \big)^*.
\end{equation}

Nous pouvons ainsi déterminer le développement de $G^{\flat}$ dans la base des $dx_i$ en faisant le calcul
\begin{equation}
	G_x^{\flat}(e_i)=\langle G(x), e_i\rangle =G_i(x),
\end{equation}
donc les composantes de $G^{\flat}$ dans la base $dx_i$ sont exactement les composantes de $G$ dans la base $e_i$ :
\begin{equation}
	G^{\flat}_x=G_1(x)dx_1+\cdots+G_n(x)dx_n.
\end{equation}

La construction inverse existe également. Si $\omega$ est une $1$-forme différentielle, nous pouvons définir le champ de vecteur $\omega^{\sharp}$ par la formule (implicite)
\begin{equation}
	\omega_x(v)=\langle \omega^{\sharp}(x), v\rangle
\end{equation}
pour tout $v\in\eR^n$. Par définition, $(\omega^{\sharp})^{\flat}=\omega$.

\begin{lemma}
    En composantes nous avons :
	\begin{equation}
		\omega^{\sharp}(x)=\big( a_1(x),\ldots,a_n(x) \big).
	\end{equation}
	Si $G$ est un champ de vecteurs, alors $(G^{\flat})^{\sharp}=G$.
\end{lemma}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Différentielle}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Nous avons déjà donné une définition abstraite de la différentielle dans la définition \ref{DefDifferentiellePta}. Nous en voyons maintenant quelque motivations dans le cas de fonctions sur \( \eR^2\) ou \( \eR^n\).

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Exemples introductifs}
%---------------------------------------------------------------------------------------------------------------------------
\label{SEBSECooLPRQooJRQCFL}

La notion de dérivée est associée à la recherche de la droite tangente à une courbe. Reprenons rapidement le cheminement. La dérivée de $f\colon \eR\to \eR$ au point $a$ est un nombre $f'(a)$, qui définit donc une application linéaire dont le coefficients angulaire est $f'(a)$, et que nous notons $df_a$ :
\begin{equation}
    \begin{aligned}
        df_a\colon \eR&\to \eR \\
        u&\mapsto f'(a)u.
    \end{aligned}
\end{equation}
La droite donnée par l'équation
\begin{equation}
    y(a+u)=f'(a)u
\end{equation}
est parallèle à la tangente en $a$. Pour trouver la tangente, il suffit de la décaler de la hauteur qu'il faut. L'équation de la droite tangente au graphe de $f$ au point $\big( a,f(a) \big)$ devient
\begin{equation}        \label{EqDiffRapTgDer}
    y(x)=f(a)+f'(a)(x-a)=f(a)+df_a(x-a).
\end{equation}
Nous nous proposons de généraliser cette formule au cas de la recherche du plan tangent à une surface.

\begin{example}
    Considérons $f(x,y)=x^2y+y^2 e^{x}$. Les dérivées partielles sont
    \begin{equation}
        \begin{aligned}[]
            \frac{ \partial f }{ \partial x }&=2xy+y^2e^x\\
            \frac{ \partial f }{ \partial y }&=x^2+2ye^x.
        \end{aligned}
    \end{equation}
\end{example}

Cet exemple était l'exemple facile où tout se passe bien.

\begin{example}
    Les choses sont moins simples lorsqu'on considère la fonction suivante :
    \begin{equation}
        f(x,y)=\begin{cases}
            \frac{ xy }{ x^2+y^2 }    &   \text{si }(x,y)\neq(0,0)\\
            0    &    \text{si }(x,y)=(0,0).
        \end{cases}
    \end{equation}
    On voit que pour tout $x$ et tout $y$, nous avons $f(x,0)=f(0,y)=0$. Donc cette fonction est nulle sur les axes horizontaux et verticaux. Nous avons en particulier
    \begin{equation}
        \begin{aligned}[]
            \frac{ \partial f }{ \partial x }(0,0)&=0\\
            \frac{ \partial f }{ \partial y }(0,0)&=0.
        \end{aligned}
    \end{equation}
    Donc ces dérivées partielles existe.

    Il n'est par contre pas question de dire que cette fonction «va bien» autour du point $(0,0)$. En effet si nous regardons sa valeur sur la droite diagonale $y=x$, nous avons
    \begin{equation}
        f(x,x)=\frac{ x^2 }{ 2x^2 }=\frac{ 1 }{2}.
    \end{equation}
    Par conséquent si nous suivons la fonction le long de la droite $y=x$, la hauteur vaut $\frac{ 1 }{2}$ en permanence, sauf juste en $(0,0)$ où la fonction fait un grand plongeon !
    \begin{verbatim}
    sage: var('x,y')
    (x, y)
    sage: f(x,y)=(x*y)/(x**2+y**2)
    sage: plot3d(f,(x,-2,2),y(-2,2))
    \end{verbatim}

    D'ailleurs elle fait un plongeon le long de toutes les droites (sauf verticale et horizontale). En effet si nous regardons la fonction le long de la droite $y=mx$, nous avons
    \begin{equation}
        f(x,mx)=\frac{ mx^2 }{ x^2+m^2x^2 }=\frac{ m }{ 1+m^2 }.
    \end{equation}
    La fonction est donc \emph{constante} sur chacune de ces droites. Il n'est donc pas question de dire que cette fonction est «dérivable» en $(0,0)$, vu qu'elle fait des grands sauts dans presque toutes les directions.
\end{example}

Nous devons donc trouver mieux que les dérivées partielles pour étudier le comportement des fonctions un peu problématiques.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Différentielle}
%---------------------------------------------------------------------------------------------------------------------------

Nous nous souvenons de l'équation \eqref{EqCodeDerviffxam} qui nous dit que pour une fonction d'une variable la dérivabilité signifiait qu'il existait un nombre $\ell$ et une fonction $\alpha$ tels que
\begin{equation}
    f(x)=f(a)+\ell(x-a)+(x-a)\alpha(x-a)
\end{equation}
et $\lim_{t\to 0} \alpha(t)=0$.

En nous inspirant de cela, nous comprenons peut-être un peu le pourquoi de la définition \ref{DefDifferentiellePta}.

\begin{normaltext}
    L'objet $df_a$ est \emph{en soi} une application $df_a\colon \eR^m\to \eR^n$. Nous notons $df_a(u)$\nomenclature{$df_a(u)$}{Application de la différentielle de $f$ sur le vecteur $u$} la valeur de $df_a$ sur le vecteur $u\in\eR^m$. En particulier, l'application \( df\) est une forme différentielle au sens de la définition~\ref{DEFooMGXSooWioKie}.
\end{normaltext}

\begin{normaltext}
    Les propositions~\ref{PropExistDiffUn} et~\ref{PropExistDiffDeux} vont montrer qu'en étudiant bien les dérivées partielles, nous pouvons conclure à la différentiabilité d'une fonction.
    Attention cependant, nous verrons dans l'exemple~\ref{Exemple0046Diff} que l'existence des dérivées directionnelles partielles ne permettait pas de conclure à la différentiabilité.
\end{normaltext}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Matrice de la différentielle}
%---------------------------------------------------------------------------------------------------------------------------

La différentielle est une application linéaire. Elle possède donc une matrice lorsque des bases sont fixées.
\begin{proposition}     \label{PROPooBMROooThgLuU}
    Soient une application différentiable \( f\colon \eR^m\to \eR^n\) et \( a\in \eR^m\). Dans les bases canoniques de \( \eR^m\) et \( \eR^n\), la matrice de \( df_a\) est
    \begin{equation}
        (df_a)_{ij}=\frac{ \partial f_i }{ \partial x_j }(a).
    \end{equation}
\end{proposition}

\begin{proof}
    Le lien entre matrice et application linéaire est fait dans la proposition \ref{PROPooGXDBooHfKRrv}. Dans le cas des bases canoniques de \( \eR^m\) et \( \eR^n\) nous savons qu'extraire une composante revient à prendre le produit scalaire. Nous avons donc
    \begin{equation}
        (df_a)_{ij}=\big( df_a(e_j) \big)_i=df_a(e_j)\cdot e_i.
    \end{equation}
    La linéarité de la dérivation donne alors
    \begin{equation}
        (df_a)_{ij}=df_a(e_j)\cdot e_i=\Dsdd{ f(a+te_j) }{t}{0}\cdot e_i=\Dsdd{ f_i(a+te_j) }{t}{0}=\frac{ \partial f_i }{ \partial x_j }(a).
    \end{equation}
\end{proof}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Quelques propriétés}
%---------------------------------------------------------------------------------------------------------------------------

\begin{lemma}       \label{LEMooZSNMooCfjzOB}
    La différentielle d'une application linéaire est l'application elle-même. Plus précisément : soit une application linéaire \( f\colon E\to F\). Alors nous avons, pour tout \( a\in E\) et \( u\in E\) :
    \begin{equation}
        df_a(u)=f(u).
    \end{equation}
\end{lemma}

\begin{proof}
    Pour rappel, toujours bon à avoir en tête : \( df\colon E\to \aL(E,F)\). En posant \( T(u)=f(u)\) nous avons :
    \begin{equation}
        \lim_{h\to 0} \frac{ \| f(a+h)-f(a)- T(h) \|_F }{ \| h \|_E }=0
    \end{equation}
    parce que le numérateur est nul pour tout \( h\).
\end{proof}

\begin{lemma}[\cite{MonCerveau}]       \label{LEMooDDUZooLwXkRp}
    Soit une fonction \( g\colon \eR\to \eR\) de classe \(  C^{\infty}\). Nous posons
    \begin{equation}
        \begin{aligned}
            f\colon \eR^2&\to \eR \\
            (x,y)&\mapsto g(x). 
        \end{aligned}
    \end{equation}
    Alors \( f\) est de classe \(  C^{\infty}\) sur \( \eR^2\).
\end{lemma}

\begin{proof}
    Le problème lorsqu'il faut démontrer qu'une fonction est de classe \(  C^{\infty}\), c'est que \( d^kf\) sera une application de \( \eR^2\) vers un espace qui est un terrible emboîtement de \( \aL(\eR^2,\ldots)\). Pour traiter cette difficulté, nous considérons les espaces suivants: \( V_0=\eR\) et par récurrence \( V_{k+1}=\aL(\eR^2,V_k)\). 

    Et nous considérons également les éléments
    \begin{equation}
        \begin{aligned}
            \alpha_1\colon \eR^2&\to \eR \\
            (u,v)&\mapsto u 
        \end{aligned}
    \end{equation}
    et plus généralement \( \alpha_k\in V_k\) donné par
    \begin{equation}
        \begin{aligned}
            \alpha_k\colon \eR^2&\to V_{k-1} \\
            (u,v)&\mapsto u\alpha_{k-1}. 
        \end{aligned}
    \end{equation}
    Notons que dans l'expression \( u\alpha_{k-1}\), il s'agit d'un produit entre un scalaire \( u\in \eR\) et un vecteur \( \alpha_{k+1}\in V_{k-1}\).

    Nous prouvons maintenant par récurrence que \( d^{k}f_{(a,b)}=g^{(k)}(a)\alpha_k\), en utilisant directement la définition.

    \begin{subproof}
        \item[Initialisation]

    Pour \( k=1\), nous calculons
    \begin{equation}
        \frac{ |f(a+h_1,b+h_2)-f(a,b)-g'(a)\alpha_1(h)| }{ \| h \| }=\frac{ |g(a+h_1)-g(a)-g'(a)h_1| }{ \| h \| }
    \end{equation}
    Notre but est de calculer la limite de cela lorsque \( h\stackrel{\eR^2}{\longrightarrow}0\) avec \( h\neq 0\). L'hypothèse sur la dérivabilité de \( g\) nous indique que si \( 0<| t |<\delta\), alors
    \begin{equation}        \label{EQooQLWNooLRKhUv}
        \frac{ | g(a+t)-g(a)-tg'(a) | }{ | t | }<\epsilon.
    \end{equation}
    Nous considérons donc la boule épointée de \( \eR^2\) de rayon \( \delta\) : \( B=B\big( (0,0),\delta \big)\setminus\{(0,0)\}\), et nous considérons \( h\in B\). Deux cas sont à distinguer : \( h_1=0\) et \( h_1\neq 0\). 

    Si \( h_1=0\), alors
    \begin{equation}
        \frac{ |g(a+h_1)-g(a)-g'(a)h_1| }{ \| h \| }=0.
    \end{equation}
    Sinon nous avons \( 0<h_1\leq\| h \|<\delta\) et donc
    \begin{equation}
        \frac{ |g(a+h_1)-g(a)-g'(a)h_1| }{ \| h \| }\leq\frac{ |g(a+h_1)-g(a)-g'(a)h_1| }{ | h_1 | }<\epsilon
    \end{equation}
    par la relation \eqref{EQooQLWNooLRKhUv}. Nous avons donc bien
    \begin{equation}
        \lim_{h\to 0}\frac{ |f(a+h_1,b+h_2)-f(a,b)-g'(a)\alpha_1(h)| }{ \| h \| }=0.
    \end{equation}

\item[Récurrence]

    Nous supposons que \( d^kf_{a,b}=g^{(k)}(a)\alpha_k\), et nous devons prouver que \( d^kf\) est différentiable et que \( d^{k+1}f_{(a,b)}=g^{(k+1)}(a)\alpha_{k+1}\). Pour cela nous introduisons tout dans la définition de la différentielle pour voir ce qui arrive.

    Nous avons :
    \begin{equation}
        \frac{ d^kf_{(a+h_1,b+h_2)}-d^kf_{(a,b)}-g^{(k+1)}(a)\alpha_{k+1}(h_1,h_2) }{ \| h \| }=
        \frac{ g^{(k)}(a+h_1)\alpha_k-g^{(k)}(a)\alpha_k-g^{(k+1)}(a)h_1\alpha_k }{ \| h \| }.
    \end{equation}
    Cela est, pour chaque \( h\neq 0\), un élément \( V_k\), mais le coefficient \( \alpha_k\) se factorise de telle sorte que nous devons seulement calculer la limite (si elle existe)
    \begin{equation}
        \lim_{h\to 0} \frac{ g^{(k)}(a+h_1)-g^{(k)}(a)-h_1g^{(k+1)}(a) }{ \| h \| }.
    \end{equation}
    Le même jeu de séparation entre \( h_1=0\) et \( h_1\neq 0\) que dans le cas \( k=1\) nous permet de déduire que cette limite existe et vaut zéro, grace à la définition de \( g^{(k+1)}\).
    \end{subproof}

    Nous avons donc prouvé que \( f\) est différentiable autant que fois que souhaité. Elle est donc de classe \(  C^{\infty}\) comme annoncé.
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Différentielle, dual et forme différentielle}
%---------------------------------------------------------------------------------------------------------------------------

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Dans la base duale}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Nous avons déjà parlé en \eqref{EQooITHKooDzigPY} de la base \( \{ dx_i \}_{i=1,\ldots, n}\) des formes différentielles sur \( \eR^n\).

\begin{proposition}
    La forme de base \( dx_i\) est la différentielle de la fonction de projection
    \begin{equation}
        \begin{aligned}
            \pr_i\colon \eR^n&\to \eR \\
            v&\mapsto v_i.
        \end{aligned}
    \end{equation}
    Autrement dit nous avons
    \begin{equation}
        d(\pr_i)_a=dx_i
    \end{equation}
    pour tout \( i\) et pour tout \( a\).
\end{proposition}

\begin{proof}
    Le quotient
    \begin{equation}
        \frac{ \pr_i(a+h)-\pr_i(a)-dx_i(h) }{ \| h \| }
    \end{equation}
    est toujours nul. La limite est a fortiori nulle.
\end{proof}

Nous avons donc \( (d\pr_i)_a=dx_i\) pour tout \( a\). Notons que les fonctions \( dx_i\) et \( \pr_i\) sont les mêmes. Cela justifie la notation «\( dx_i\)» pour les formes différentielles de base, parce que ce sont les différentielles des fonctions «coordonnées» que nous pouvons noter \( x_i\).

Étant donné une fonction \( f\), il est légitime de nous demander comment (si elle existe) la différentielle se décompose en chaque point dans la base duale. C'est-à-dire fixer les fonctions \( a_i\) en termes des dérivées de \( f\) pour avoir
\begin{equation}
    df_a=\sum_{i=1}^n\frac{ \partial f }{ \partial x_i }(a)dx_i.
\end{equation}
C'est ce que nous allons faire dans le corollaire~\ref{CORooXURPooQMKvBl}.

\begin{example}
    Si $F\colon \eR^2\to \eR$ est une fonction $C^2$, sa différentielle est la forme
    \begin{equation}
        dF=\frac{ \partial F }{ \partial x }dx+\frac{ \partial F }{ \partial y }dy.
    \end{equation}
    Si nous nommons $f$ et $g$ les fonctions $\partial_xF$ et $\partial_yF$, nous avons donc
    \begin{equation}
        Df=fdx+gdy,
    \end{equation}
    qui vérifie
    \begin{equation}
        \partial_yf=\partial_xg,
    \end{equation}
    parce que $\frac{ \partial f }{ \partial y }=\frac{ \partial^2F  }{ \partial x\partial y }=\frac{ \partial^2F  }{ \partial y\partial x }=\frac{ \partial g }{ \partial x }$. Ce que nous avons donc prouvé, c'est que
\end{example}

\begin{lemma}
    Si $fdx+gdy$ est la différentielle d'une fonction de classe $C^2$ sur \( \eR^2\), alors $\partial_yf=\partial_xg$.
\end{lemma}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Ce n'est pas la différentielle extérieure}
%---------------------------------------------------------------------------------------------------------------------------

Il existe une notion de différentielle extérieure, mais ce n'est pas celle-là que nous utilisons la majorité du temps. En particulier si \( E\) et \( F\) sont des espaces vectoriels normés, lorsque \( f\colon E\to F\) est une fonction, \( df\) est une application
\begin{equation}
    df\colon E\to \aL(E,F)
\end{equation}
et la différentielle seconde est la différentielle de cette application-là. Chose faisable parce que \( \aL(E,F)\) est un espace vectoriel on ne peut plus respectable.

Soit $D\subset\eR^n$. Par définition de la différentielle extérieure d'une $1$-forme, nous avons une formule de Leibnitz
\begin{equation}
    d(f\omega)=df\wedge\omega+fd\omega.
\end{equation}
En particulier,
\begin{equation}
    d(fdx)=df\wedge dx+f\underbrace{d(dx)}_{=0}=\frac{ \partial f }{ \partial x }dx\underbrace{dx\wedge dx}_{=0}+\frac{ \partial f }{ \partial y }dy\wedge dx.
\end{equation}

Attention : la différentielle extérieure n'est pas la différentielle usuelle. Certes dans le cas d'une \( 0\)-forme (c'est-à-dire d'une fonction), les deux notions coïncident, mais ça ne va pas plus loin. La différentielle extérieure vérifie \( d^2\omega=0\) pour tout \( \omega\), y compris pour les fonctions : si \( \omega=df\) alors \( d\omega=0\).

%TODO : donner la définition et quelques exemples de différentielle extérieure.


Nous mentionnerons la différentielle extérieure dans le cas de
\begin{enumerate}
    \item
        Théorème de Stockes~\ref{ThoATsPuzF}.
\end{enumerate}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Fonctions composées}
%---------------------------------------------------------------------------------------------------------------------------

Cette façon de voir la différentielle nous permet de jeter un nouveau regard sur la formule de différentiation des fonctions composées. Soient
\begin{equation}
    \begin{aligned}[]
        f\colon \eR^p&\to \eR^n\\
        g\colon \eR^n&\to \eR,
    \end{aligned}
\end{equation}
et $h\colon \eR^p\to \eR$ définie par
\begin{equation}
    h(u)=h\big( f(u) \big)=(g\circ f)(u).
\end{equation}
Nous allons noter $x$ les coordonnées de $\eR^p$, $a$ un point de $\eR^p$ et $u$, un vecteur de $\eR^p$ accroché au point $a$. Pour $\eR^n$, les notations seront que les coordonnées sont $y$, $b$ est un point de $\eR^n$ et $v$ est un vecteur «accroché» au point $b$.

Nous avons
\begin{equation}
    dg_b(v)=\sum_{i=1}^n\frac{ \partial g }{ \partial y_i }(b)dy_i(v).
\end{equation}
Ici $dy_i(v)$ signifie la $i$ème composante de $v$. C'est simplement $v_i$. Cette formule étant valable pour tout point $b\in\eR^n$ et pour tout vecteur $v$, nous pouvons l'écrire en particulier pour
\begin{subequations}
    \begin{numcases}{}
        b=f(a)\\
        v=df_a(u).
    \end{numcases}
\end{subequations}
Cela donne
\begin{equation}        \label{Eqdgfadfau}
    dg_{f(a)}\big( df_a(u) \big)=\sum_{i=1}^n\frac{ \partial g }{ \partial y_i }\big( f(a) \big)dy_i\big( df_a(u) \big).
\end{equation}
Mais
\begin{equation}
    df_a(u)=\sum_{j=1}^p\frac{ \partial f }{ \partial x_j }(a)dx_j(u),
\end{equation}
donc la $i$ème composante de ce vecteur est
\begin{equation}
     \big( df_a(u)\big)_i=\sum_{j=1}^p\frac{ \partial f_i }{ \partial x_j }(a)dx_j(u).
\end{equation}
En remplaçant $dy_i\big( df_a(u) \big)$ par cela dans l'expression \eqref{Eqdgfadfau}, nous trouvons
\begin{equation}
    dg_{f(a)}\big( df_a(u) \big)=\sum_{i=1}^n\frac{ \partial g }{ \partial y_i }\big( f(a) \big)\sum_{j=1}^p\frac{ \partial f_i }{ \partial x_j }(a)dx_j(u).
\end{equation}
Nous pouvons vérifier que cela est la différentielle de $g\circ f$ au point $a$ appliquée au vecteur $u$. En effet
\begin{equation}
    d(g\circ f)_a(u)=\sum_{j=1}^p\frac{ \partial (g\circ f) }{ \partial x_j }(a)dx_j(u),
\end{equation}
tandis que, par la dérivation de fonctions composées,
\begin{equation}        \label{EqDerCompofg}
    \frac{ \partial (g\circ f) }{ \partial x_j }(a)=\sum_{i=1}^n\frac{ \partial g }{ \partial y_i }\big( f(a) \big)\frac{ \partial f_i }{ \partial x_j }(a).
\end{equation}
Au final, ce que nous avons prouvé est que
\begin{equation}        \label{EQooWSIYooBmsBDU}
    d(g\circ f)_a(u)=dg_{f(a)}\big( df_a(u) \big).
\end{equation}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Continuité, dérivabilité et différentiabilité}
%---------------------------------------------------------------------------------------------------------------------------

Le théorème suivant reprend les principales propriétés d'une fonction différentiable. Il est à ne pas confondre avec la proposition~\ref{Diff_totale} qui dira que si les dérivées partielles sont continues sur un voisinage de $a$, alors $f$ est différentiable en $a$.
\begin{proposition}\label{diff1}\label{ThoRapPropDiffSi}
    Si $f$ est différentiable au point $a\in \eR^n$ alors
    \begin{enumerate}
        \item
            elle est continue en \( a\),
        \item
            elle admet une dérivée dans toutes les directions de \( \eR^m\),
\item  toutes les dérivées directionnelles $\partial_uf(a)$ existent et nous avons l'égalité
\begin{equation}        \label{EqDiffPartRap}
    \begin{aligned}
        df_a\colon \eR^n&\to \eR^m \\
        u&\mapsto df_a(u)=\frac{ \partial f }{ \partial u }(a)=\sum_i \frac{ \partial f }{ \partial x_i }(a)u_i,
    \end{aligned}
\end{equation}
si les $u^i$ sont les composantes de $u$ dans la base canonique de $\eR^n$.

    \end{enumerate}
\end{proposition}
\index{application!différentiable}

La dernière égalité sera de temps en temps utilisée sous la forme
\begin{equation}    \label{EqOWQSoMA}
    df_a(u)=\Dsdd{ f(a+tu) }{t}{0}.
\end{equation}

\begin{proof}
  La limite
\[
\lim_{h\to 0_m}\frac{\|f(a+h)-f(a)-T(h)\|_n}{\|h\|_m}=0,
\]
implique que
 \[
\lim_{h\to 0_m}\|f(a+h)-f(a)-T(h)\|_n=0.
\]
Comme $T$ est dans $\mathcal{L}(\eR^m,\eR^n)$, on a $\lim_{h\to 0}T(h)=0$, d'où la continuité de $f$ au point $a$.

Si $u$ est un vecteur non nul, la différentiabilité de $f$ au point $a$ implique
\[
\lim_{t\to 0}\frac{\|f(a+tu)-f(a)-T(tu)\|_n}{\|tu\|_m}=0,
\]
par la linéarité de $T$ et par l'égalité $\|tu\|_m=|t|\|u\|_m$ on obtient
\[
\lim_{t\to 0}\frac{f(a+tu)-f(a)}{|t|}= T(u).
\]
Donc $f$ est dérivable suivant le vecteur $u$ et $\partial_uf(a)=T(u)=df_a(u)$.
\end{proof}

\begin{corollary}       \label{CORooXURPooQMKvBl}
    Si \( f\) est différentiable, alors la forme différentielle \( df_a\) se décompose en
    \begin{equation}
        df_af=\sum_i(\partial_if)(a)dx_i.
    \end{equation}
\end{corollary}

\begin{proof}
    Vue la définition des formes \( dx_i\) nous pouvons remplacer \( u_i\) par \( dx_i(u)\) dans l'égalité \eqref{EqDiffPartRap} et écrire
    \begin{equation}
        df_a(u)=\sum_i(\partial_if)(a)dx_i(u)
    \end{equation}
    et donc écrire l'égalité demandée.
\end{proof}

Le lemme suivant regroupe quelques égalités avec lesquelles nous allons souvent travailler. Il explique comment sont liés les dérivées directionnelles, les dérivées partielles et la différentielle.
\begin{lemma}		\label{LemdfaSurLesPartielles}
	Si $f\colon \eR^m\to \eR^n$ est une fonction différentiable, alors
	\begin{equation}
        df_a(u)=\frac{ \partial f }{ \partial u }(a)=\Dsdd{ f(a+tu) }{t}{0}=\sum_{i=1}^mu_i\frac{ \partial f }{ \partial x_i }(a)=\nabla f(a)\cdot u
	\end{equation}
	pour tout vecteur $u\in\eR^m$
\end{lemma}

\begin{proof}
La première égalité est la proposition~\ref{diff1}, et la seconde est seulement la définition de la dérivée directionnelle avec des notations un peu plus snob. En particulier nous avons
\begin{equation}
    df_a(e_i)=\frac{ \partial f }{ \partial x_i }(a).
\end{equation}
Pour le reste c'est la linéarité de la différentielle qui joue : le vecteur $u$ peut être écrit de façon unique comme combinaison linéaire des vecteurs de base
\[
u=\sum_{i=1}^{m}u_i e_i, \qquad  u_i\in\eR,\, \forall i\in\{1,\ldots, m\}.
\]
Alors, la linéarité de $df_a$ nous donne
\begin{equation}
     df_a(u)= df_a\left(\sum_{i=1}^{m}u_i e_i\right)
=\sum_{i=1}^{m}u_i \left(df_ae_i\right)
=\sum_{i=1}^{m}u_i \frac{ \partial f }{ \partial x_i }(a).
 \end{equation}
Le lien avec le gradient est la définition du produit scalaire \eqref{DefYNWUFc}.
\end{proof}

La formule $df_a(u)=\Dsdd{ f(a+tu) }{t}{0}$ est bien utile pour calculer des différentielles, mais elle ne permet pas de prouver que \( f\) est différentiable. Autrement dit, même si le calcul de la dérivée \( \Dsdd{ f(a+tu) }{t}{0}\) donne un résultat pour tout \( u\), nous ne pouvons pas en déduire que \( f\) est différentiable au point \( a\).


\begin{proposition} \label{PropExistDiffUn}
    Soient $f$ une fonction de $x$ et $y$ et un point $(a,b)\in\eR^2$. Si les nombres $\partial_xf(a,b)$ et $\partial_yf(a,b)$ existent et s'il existe une fonction $\alpha\colon \eR\to \eR$ telle que
    \begin{equation}        \label{eqCritDifffabsrt}
        \begin{aligned}[]
            f(x,y)=f(a,b)&+\frac{ \partial f }{ \partial x }(a,b)(x-a)+\frac{ \partial f }{ \partial y }(a,b)(y-b)\\
            &+\| (x,y)-(a,b) \| \alpha\Big( \| (x,y)-(a,b) \| \Big)
        \end{aligned}
    \end{equation}
    et
    \begin{equation}
        \lim_{t\to 0} \alpha(t)=0,
    \end{equation}
    alors $f$ est différentiable en $(a,b)$.
\end{proposition}
Dans cet énoncé nous avons écrit $d\big( (x,y),(a,b) \big)$ la distance entre $(x,y)$ et $(a,b)$, c'est-à-dire le nombre $\sqrt{(x-a)^2+(y-b)^2}$. Afin d'écrire l'équation \eqref{eqCritDifffabsrt} sous forme plus compacte, nous introduisons le vecteur
\begin{equation}
    \nabla f(a,b)=\begin{pmatrix}
        \frac{ \partial f }{ \partial x }(a,b)    \\
        \frac{ \partial f }{ \partial y }(a,b).
    \end{pmatrix}
\end{equation}
L'équation \eqref{eqCritDifffabsrt} devient alors
\begin{equation}        \label{EqdiffComp}
    f(X)=f(P)+\nabla f(a,b)\cdot (X-P)+\| X-P \|\alpha\big( \| X-P \| \big).
\end{equation}
Le vecteur $\nabla f(a,b)$ est appelé le \defe{gradient}{gradient} de $f$ au point $(a,b)$.

\begin{proposition} \label{PropExistDiffDeux}
    Soit $f$ une fonction de deux variables admettant des dérivées partielles $\partial_xf(x,y)$ et $\partial_yf(x,y)$ qui sont elles-mêmes des fonctions continues de $x$ et $y$. Alors la fonction $f$ est différentiable partout.
\end{proposition}

\begin{proposition}
    Si $f$ est différentiable en $(a,b)$ alors pour tout vecteur \( u\), la fonction
    \begin{equation}
        \begin{aligned}
            \varphi\colon \eR&\to \eR \\
            t&\mapsto   f(a+tu_1,b+tu_2)
        \end{aligned}
    \end{equation}
    est dérivable en $0$ et on a
    \begin{equation}
        \varphi'(0)=\nabla f(p)\cdot u
    \end{equation}
    où nous avons noté $p=(a,b)$.
\end{proposition}

\begin{proof}
    Récrivons la formule \eqref{EqdiffComp} sous la forme
    \begin{equation}
        f(x)=f(p)+\nabla f(p)\cdot (x-p)+\| x-p \|\alpha(\| x-p \|).
    \end{equation}
    Cela étant vrai pour tout $x$, nous l'écrivons en particulier pour $x=p+tu$ où $t$ est un réel et $u$ est le vecteur unitaire choisi. Nous avons donc
    \begin{equation}
        f(p+tu)=f(p)+t\nabla f(p)\cdot u+\| tu \|\alpha(\| tu \|).
    \end{equation}
    En utilisant le fait que $u$ est unitaire, $\| tu \|=| t |\| u \|=| t |$. La dérivée de $\varphi$ en $0$ est alors donnée par
    \begin{equation}
        \lim_{t\to 0} \frac{ f(p+tu)-f(p) }{ t }=\lim_{t\to 0} \nabla f(p)\cdot u+\alpha(| t |).
    \end{equation}
    Lorsque nous prenons la limite, le membre de gauche devient $\varphi'(0)$ tandis que dans le membre de droite, le second terme disparaît. Nous avons finalement
    \begin{equation}
        \varphi'(0)=\nabla f(p)\cdot u
    \end{equation}
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Calcul de valeurs approchées}
%---------------------------------------------------------------------------------------------------------------------------

Si nous remplaçons les accroissements $x-a$ et $y-b$ par $h$ et $k$, le critère de différentiabilité s'écrit
\begin{equation}
    \begin{aligned}[]
        f(a+h,b+k)=f(a,b)+\frac{ \partial f }{ \partial x }(a,b)h&+\frac{ \partial f }{ \partial y }(a,b)k\\
        &+\sqrt{h^2+k^2}\alpha\big( \sqrt{h^2+k^2} \big).
    \end{aligned}
\end{equation}
Le dernier terme du membre de droite tend vers zéro à une vitesse double lorsque $h$ et $k$ tendent vers zéro : d'une part parce que $\sqrt{h^2+k^2}$ tend vers zéro et d'autre part parce que $\alpha\big( \sqrt{h^2+k^2} \big)$ tend vers zéro. Nous avons donc la «bonne» approximation
\begin{equation}        \label{EqFormApproxfxyab}
    f(x,y)\simeq f(a,b)+\frac{ \partial f }{ \partial x }(a,b)(x-a)+\frac{ \partial f }{ \partial y }(a,b)(y-b).
\end{equation}
lorsque $(x,y)$ n'est pas trop loin de $(a,b)$. Cette expression est évidemment une généralisation immédiate de l'équation \eqref{EqfxdxSimeqfxfpx}. Elle exprime que l'on peut obtenir des informations sur la valeur d'une fonction en $(x,y)$ si on peut calculer la fonction et ses dérivées en un point $(a,b)$ non loin de $(x,y)$.

Cette formule peut aussi être vue sous la forme suivante, plus pratique dans certains calculs :
\begin{equation}        \label{EqFormApproxfxyabDF}
    f(a+\Delta x,b+\Delta y)\simeq f(a,b)+\Delta x\frac{ \partial f }{ \partial x }(a,b)+\Delta y\frac{ \partial f }{ \partial y }(a,b).
\end{equation}

\begin{example}
    Prenons la fonction $f(x,y)=\cos(x)\sin(y)$ et calculons une approximation de
    \begin{equation}
        f\big( \frac{ \pi }{ 3 }+0.01,\frac{ \pi }{ 2 }+0.03 \big).
    \end{equation}
    D'abord les dérivées partielles sont
    \begin{equation}
        \begin{aligned}[]
            \frac{ \partial f }{ \partial x }(x,y)=-\sin(x)\sin(y)\\
            \frac{ \partial f }{ \partial y }(x,y)=\cos(x)\cos(y).
        \end{aligned}
    \end{equation}
    Nous allons utiliser l'approximation
    \begin{equation}
        f\big( \frac{ \pi }{ 3 }+0.01,\frac{ \pi }{ 2 }+0.03 \big)\simeq f\big( \frac{ \pi }{ 3 },\frac{ \pi }{2} \big)+0.01\frac{ \partial f }{ \partial x }\big( \frac{ \pi }{ 3 },\frac{ \pi }{2} \big)+0.03\frac{ \partial f }{ \partial y }\big( \frac{ \pi }{ 3 },\frac{ \pi }{2} \big).
    \end{equation}
    Nous avons
    \begin{equation}
        \begin{aligned}[]
            \frac{ \partial f }{ \partial x }\big( \frac{ \pi }{ 3 },\frac{ \pi }{2} \big)&=-\sin\frac{ \pi }{ 3 }\sin\frac{ \pi }{ 2 }=-\frac{ \sqrt{3} }{2}\\
            \frac{ \partial f }{ \partial y }\big( \frac{ \pi }{ 3 },\frac{ \pi }{2} \big)&=\cos\frac{ \pi }{ 3 }\cos\frac{ \pi }{ 2 }=0.
        \end{aligned}
    \end{equation}
    Par conséquent
    \begin{equation}
        f\big( \frac{ \pi }{ 3 }+0.01,\frac{ \pi }{ 2 }+0.03 \big)\simeq \frac{ 1 }{2}-0.01\frac{ \sqrt{3} }{2}=\frac{ 1 }{2}-\frac{ \sqrt{3} }{ 200 }.
    \end{equation}

    \begin{verbatim}
sage: var('x,y')
(x, y)
sage: f(x,y)=cos(x)*sin(y)
sage: a=f(pi/3+0.01,pi/2+0.03)
sage: numerical_approx(a)
0.491093815387986
sage: b=1/2-sqrt(3)/200
sage: numerical_approx(b)
0.491339745962156
sage: numerical_approx(a-b)
-0.000245930574169814
    \end{verbatim}
    Cela fait une erreur de l'ordre du dix millième.

\end{example}

\begin{remark}
    Les esprits les plus critiques diront que cette vérification pas Sage n'en est pas une parce que Sage a certainement utilisé un algorithme d'approximation qui se base sur la même idée que ce que nous venons de faire, et que par conséquent le fait qu'il obtienne le même résultat que nous est un peu tautologique.

    Ils n'auront pas tort. Cependant, le code source de Sage est disponible publiquement\footnote{Voir \url{http://www.sagemath.org}}; vous pouvez aller le lire et vérifier qu'il y a effectivement une \emph{preuve} que le résultat fourni par Sage possède une bonne dizaine de décimales correctes.

    Cette disponibilité publique du code source est une des nombreuses différences fondamentales entre Sage et votre calculatrice\footnote{et les autres logiciels de type fenêtre, pomme ou feuille d'érable.}. Dois-je vous rappeler qu'un des principes fondamentaux de l'éthique scientifique est que les résultats et les méthodes utilisés doivent être absolument ouverts à la vérification et à la critique de tous ?
\end{remark}

\begin{equation}        \label{Eqdfpunfpdu}
    df_p(u)=\nabla f(p)\cdot u.
\end{equation}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Différentielle et tangente}
%---------------------------------------------------------------------------------------------------------------------------

La notion de dérivée partielle (ou de dérivée suivant un vecteur) pour une fonction de plusieurs variables n'est pas une  généralisation de la notion de dérivée en une variable d'espace. En fait, du point de vue géométrique, la dérivée de la fonction $g:\eR\to\eR$ au point $a$ est la pente de la ligne droite tangente au graphe de $g$ au point $(a, g(a))$. Cette ligne, d'équation $r(x)=g'(a)x+g(a)$, est la meilleure approximation affine du graphe de $g$ au point $a$, comme à la figure~\ref{LabelFigTangentSegment}.
\newcommand{\CaptionFigTangentSegment}{Tangentes au graphe d'une fonction d'une variable}
\input{auto/pictures_tex/Fig_TangentSegment.pstricks}

Le graphe d'une fonction $f$ de $\eR^2$ dans $\eR$ est une surface de deux paramètres dans $\eR^3$. Si l'approximation affine d'une telle surface au point $(x,y,f(x,y))$ existe, alors elle est un plan tangent. En dimension plus haute, le graphe de la fonction $f:\eR^m\to\eR$ est une surface de $m$ paramètres dans $\eR^{m+1}$ et son approximation affine (si elle existe) est un hyperplan de $\eR^m$.

Nous allons voir que si $f$ prend ses valeurs dans $\eR^n$ l'approximation affine de $f$ au point $a$ est l'élément de $ f(a)+\mathcal{L}(\eR^m,\eR^n)$ qui ressemble le plus à $f$ au voisinage de $a$. Plus précisément, on utilise les définitions suivantes.
\begin{definition}
  Soient $f$ et $g$ deux applications d'un ouvert $U$ de $\eR^m$ dans $\eR^n$. On dit que $g$ est \defe{tangente}{application!tangente} à $f$ au point $a\in U$ si $f(a)=g(a)$ et
\[
\lim_{\begin{subarray}{l}
    x\to a\\ x\neq a
  \end{subarray}}\frac{\|f(x)-g(x)\|_n}{\|x-a\|_m}=0.
\]
\end{definition}
La relation de tangence est une relation d'équivalence. Nous sommes particulièrement intéressés par le cas où $f$ admet une application  affine tangente au point $a$.


\newcommand{\CaptionFigDifferentielle}{Interprétation géométrique de la différentielle.}
\input{auto/pictures_tex/Fig_Differentielle.pstricks}
En ce qui concerne l'interprétation géométrique, si nous regardons la figure~\ref{LabelFigDifferentielle}, et d'ailleurs aussi en voyant la définition~\ref{EqCritereDefDiff}, la fonction est différentiable et la différentielle est \( T\) s'il existe une fonction \( \alpha\) telle que
\begin{equation}
    f(a+u)-f(a)-T(u)=\alpha(u)
\end{equation}
où la fonction \( \alpha\) satisfait
\begin{equation}		\label{EqPresqueTa}
	\lim_{u\to 0} \frac{ \| \alpha(u)\| }{\| u \|}=0
\end{equation}
C'est cela qui fait écrire \( f(a+u)-f(a)-df_a(u)=o(\| u \|)\) à ceux qui n'ont pas peur de la notation \( o\).

La différentielle $df_a$ est donc la partie linéaire de l'application affine qui approxime au mieux la fonction $f$ autour du point $a$. La notion de différentielle est la vraie généralisation du concept de dérivée pour fonctions de plusieurs variables, en outre elle nous permet d'expliciter la relation qui associe au vecteur $u$ la dérivée $\partial_u f(a)$, pour $f$ et $a$ fixés.

\begin{remark}
	Si on remplace les normes $\|\cdot\|_m$  et $\|\cdot\|_n$ par d'autres normes, l'existence et la valeur de la différentielle de $f$ au point $a$ ne sont pas remises en cause. En effet, soient  $\|\cdot\|_M$  une norme sur $\eR^m$ et $\|\cdot\|_N$ une norme sur $\eR^n$. Par le théorème~\ref{ThoNormesEquiv}, ces normes sont équivalentes à $\| . \|_m$ et $\| . \|_n$ respectivement; il existe donc des constantes $k,\, K,\, l,\,L >0$ telles que  pour tout vecteur $u$ de $\eR^m$ et tout vecteur $v$ de $\eR^n$
\[
k\|u\|_M\leq \|u\|_m\leq K\|u\|_M,
\]
\[
l\|v\|_N\leq \|v\|_n\leq L\|v\|_N.
\]
Les éléments de $\mathcal{L}(\eR^m, \eR^n)$ sont les mêmes et on a
\begin{equation}
  \begin{aligned}
 & \frac{l}{K}  \frac{\|f(a+h)-f(a)-T(h)\|_N}{\|h\|_M}\leq \frac{\|f(a+h)-f(a)-T(h)\|_n}{\|h\|_m}\leq\\
&\leq\frac{L}{k} \frac{\|f(a+h)-f(a)-T(h)\|_N}{\|h\|_M}.
  \end{aligned}
\end{equation}
Il est donc possible, pour démontrer la différentiabilité ou pour calculer la différentielle, d'utiliser le critère \eqref{EqCritereDefDiff} avec une norme au choix. Parfois c'est utile.
\end{remark}

%---------------------------------------------------------------------------------------------------------------------------
                    \subsection{Prouver qu'une fonction n'est pas différentiable}
%---------------------------------------------------------------------------------------------------------------------------

Chacun des points du théorème~\ref{ThoRapPropDiffSi} est en soi un critère pour montrer qu'une fonction n'est pas différentiable en un point.

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
                    \subsubsection{Continuité}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////


Le premier critère à vérifier est donc la continuité. Si une fonction n'est pas continue en un point, alors elle n'y sera pas différentiable. Pour rappel, la continuité en $a$ se teste en vérifiant si $\lim_{x\to a}f(x)=f(a)$.

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
                    \subsubsection{Linéarité}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Un second test est la linéarité de la dérivée directionnelle par rapport à la direction : l'application $u\mapsto\frac{ \partial f }{ \partial u }(a)$ doit être linéaire, sinon $df_a$ n'existe pas.

\begin{example}     \label{Exemple0046Diff}
Examinons la fonction
\begin{equation}
    \begin{aligned}
        f\colon \eR^2&\to \eR \\
        (x,y)&\mapsto \begin{cases}
    \frac{ xy^2 }{ x^2+y^4 }    &   \text{si }(x,y)\neq (0,0)\\
    0   &    \text{sinon}.
\end{cases}
    \end{aligned}
\end{equation}
Prenons $u=(u_1,u_2)$ et calculons la dérivée de $f$ dans la direction de $u$ au point~$(0,0)$ :
\begin{equation}
    \begin{aligned}[]
        \frac{ \partial f }{ \partial u }(0,0)
            &=\lim_{t\to 0}\frac{ f(tu_1,tu_2)-f(0,0) }{ t }\\
            &=\lim_{t\to 0}\frac{1}{ t }\left( \frac{ tu_1t^2u_2 }{ t^2u_1^2+t^4u_2^4 } \right)\\
            &=\lim_{t\to 0}\left( \frac{ u_1u_2^2 }{ u_1^2+t^2u_2^4 } \right)\\
            &=\begin{cases}
    \frac{ u_2^2 }{ u_1 }   &   \text{si }u_1\neq 0\\
    0   &    \text{si }u_1=0.
\end{cases}
    \end{aligned}
\end{equation}
Cette application n'est pas linéaire par rapport à $u$. En effet, notons
\begin{equation}
    \begin{aligned}
        A\colon \eR^n&\to \eR \\
        u&\mapsto \frac{ \partial f }{ \partial u }(0,0),
    \end{aligned}
\end{equation}
et vérifions que pour tout $u$ et $v$ dans $\eR^n$ et $\lambda\in\eR$, nous ayons $A(\lambda u)=\lambda A(u)$ et $A(u+v)=A(u)+A(v)$. Le premier fonctionne parce que
\begin{equation}
    A(\lambda u)=A(\lambda u_1,\lambda u_2)=\frac{ \lambda^2 u_2^2 }{ \lambda u_1 }=\lambda\frac{ u_2^2 }{ u_1 }=\lambda A(u).
\end{equation}
Mais nous avons par exemple
\begin{equation}
    A\big( (0,1)+(2,3) \big)=A(2,4)=\frac{ 16 }{ 2 }=8,
\end{equation}
tandis que
\begin{equation}
    A(0,1)+A(2,3)=0+\frac{ 9 }{ 2 }\neq 8.
\end{equation}
La fonction $f$ n'est donc pas différentiable en $(0,0)$, parce que la candidate différentielle, $df_{(0,0)}(u)=\frac{ \partial f }{ \partial u }(0,0)$, n'est même pas linéaire.

\end{example}

Voici une autre façon de traiter la fonction de l'exemple~\ref{Exemple0046Diff}.

\begin{example} \label{ExeFHmCLII}
    La figure~\ref{LabelFigFWJuNhU} représente le domaine d'une fonction $f\colon \eR^2\to \eR$, et sur chacune des parties, elle est définie différemment.
    \newcommand{\CaptionFigFWJuNhU}{La fonction de l'exemple~\ref{ExeFHmCLII}.}
\input{auto/pictures_tex/Fig_FWJuNhU.pstricks}

L'expression de $f$ est ici
\begin{equation}
  f(x,y) =
  \begin{cases}
      xy & \text{si } x < 0 \text{ et } y > 0\\
      x-y & \text{si } x \geq 0 \text{ et } y \geq 0\\
      x^2y & \text{si } x > 0 \text{ et } y < 0\\
    x+y & \text{sinon.}
  \end{cases}
\end{equation}

On note que les deux axes forment une zone à problèmes. La zone hors
des axes est un ouvert sur lequel $f$ est différentiable car composée
de polynômes. Analysons chacun des points de la forme $(a,b)$ dans la
zone à problèmes (c'est-à-dire si $ab = 0$).

\subparagraph{Si $a = 0$ et $b > 0$} Un tel point $(0,b)$ est sur
l'axe verticale, dans la moitié supérieure. Pour calculer la limite de
$f$ en ce point, on peut restreindre notre étude au demi-plan ouvert
$y > 0$, ce qui revient à comparer la limite
\begin{equation*}
  \limite[y>0\\x\geq 0] {(x,y)} {(0,b)} f(x,y) =   \limite[y>0\\x\geq
  0] {(x,y)} {(0,b)} x-y = 0 - b = -b
\end{equation*}
avec la limite
\begin{equation*}
  \limite[y>0\\x<0] {(x,y)} {(0,b)} f(x,y) =   \limite[y>0\\x<0]
  {(x,y)} {(0,b)} xy = 0 b = 0
\end{equation*}
qui sont différentes puisque $b$ est supposé non nul.

\conclusion $f$ n'est pas continue en un point du type $(0,b)$ avec $b
> 0$.

\subparagraph{Si $a = 0$ et $b < 0$} Un tel point $(0,b)$ est sur
l'axe verticale, dans la moitié inférieure. Pour calculer la limite de
$f$ en ce point, on peut restreindre notre étude au demi-plan ouvert
$y < 0$, ce qui revient à comparer la limite
\begin{equation*}
  \limite[y<0\\x\geq 0] {(x,y)} {(0,b)} f(x,y) =   \limite[y<0\\x\geq
  0] {(x,y)} {(0,b)} x^2 y = 0^2 b = 0
\end{equation*}
avec la limite
\begin{equation*}
  \limite[y<0\\x<0] {(x,y)} {(0,b)} f(x,y) =   \limite[y<0\\x<0]
  {(x,y)} {(0,b)} x+y = 0 + b = b
\end{equation*}
qui sont différentes puisque $b$ est supposé non nul.

\conclusion $f$ n'est pas continue en un point du type $(0,b)$ avec $b
< 0$.

\subparagraph{Si $a > 0$ et $b = 0$} Un tel point $(a,0)$ est sur
l'axe horizontal, dans la moitié droite. Pour calculer la limite de
$f$ en ce point, on peut restreindre notre étude au demi-plan ouvert
$x > 0$, ce qui revient à comparer la limite
\begin{equation*}
  \limite[x>0\\y \geq 0] {(x,y)} {(a,0)} f(x,y) =   \limite[x>0\\y \geq
  0] {(x,y)} {(a,0)} x-y = a - 0 = a
\end{equation*}
avec la limite
\begin{equation*}
  \limite[x>0\\y < 0] {(x,y)} {(a,0)} f(x,y) =   \limite[x>0\\y < 0]
  {(x,y)} {(a,0)} x^2y = a^2 0 = 0
\end{equation*}
qui sont différentes puisque $a$ est supposé non nul.

\conclusion $f$ n'est pas continue en un point du type $(a,0)$ avec $a
> 0$.

\subparagraph{Si $a < 0$ et $b = 0$} Un tel point $(a,0)$ est sur
l'axe horizontal, dans la moitié gauche. Pour calculer la limite de
$f$ en ce point, on peut restreindre notre étude au demi-plan ouvert
$x < 0$, ce qui revient à comparer la limite
\begin{equation*}
  \limite[x<0\\y> 0] {(x,y)} {(a,0)} f(x,y) =   \limite[x<0\\y>
  0] {(x,y)} {(a,0)} x y = a 0 = 0
\end{equation*}
avec la limite
\begin{equation*}
  \limite[x<0\\y\leq 0] {(x,y)} {(a,0)} f(x,y) =   \limite[x<0\\y\leq0]
  {(x,y)} {(a,0)} x+y = a + 0 = a
\end{equation*}
qui sont différentes puisque $a$ est supposé non nul.

\conclusion $f$ n'est pas continue en un point du type $(a,0)$ avec $a
< 0$.

\subparagraph{Si $a = 0$ et $b = 0$} Le cas du point $(0,0)$ est
particulier, puisque il est adhérent aux quatre composantes du
domaine où la fonction est définie différemment. Pour étudier la
continuité, il faut donc étudier quatre limites. Ces limites ont déjà
été étudiées ci-dessus et valent toutes $0$, ce qui prouve la
continuité de $f$ en $(0,0)$.

En ce qui concerne la différentiabilité, on sait qu'il est nécessaire
que toutes les dérivées directionnelles existent. Calculons la dérivée
dans la direction $(0,1)$ (au point $(0,0)$)~:
\begin{equation*}
  \limite[t\neq0] t 0 \frac{f((0,0) + t(0,1)) - f(0,0)}{t} =%
  \limite[t\neq0] t 0 \frac{f(0,t)}{t} = \ldots
\end{equation*}
qu'on sépare en deux cas, car $f(0,t)$ possède une formule différente
si $t < 0$ ou si $t \geq 0$~:
\begin{equation*}
  \limite[t\neq0] t 0 \frac{f(0,t)}{t} = %
  \begin{arrowcases}
    \limite[t<0] t 0 \frac{f(0,t)}{t} = \limite[t<0] t 0 \frac{0+t}{t} = 1\\
    \limite[t\geq0] t 0 \frac{f(0,t)}{t} = \limite[t\geq0] t 0
    \frac{0-t}{t} = -1
  \end{arrowcases}
\end{equation*}
ce qui prouve que la limite n'existe pas, donc que la dérivée
directionnelle n'existe pas, et finalement que la fonction n'est pas
différentiable.

\conclusion La fonction donnée est continue hors des axes et au point
$(0,0)$, mais discontinue partout ailleurs sur les axes. Elle est
différentiable hors des axes, mais ne l'est pas sur les axes.

\end{example}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
                    \subsubsection{Cohérence des dérivées partielles et directionnelle}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Dans la pratique, nous pouvons calculer $\partial_uf(a)$ pour une direction $u$ générale, et puis en déduire $\partial_xf$ et $\partial_yf$ comme cas particuliers en posant $u=(1,0)$ et $u=(0,1)$. Une chose incroyable, mais pourtant possible est qu'il peut arriver que
\begin{equation}
    \frac{ \partial f }{ \partial u }(a)\neq \sum_i\frac{ \partial f }{ \partial x_i }(a)u^i.
\end{equation}
Ceci se produit lorsque $f$ n'est pas différentiable en $a$. En voici un exemple.

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
                    \subsubsection{Un candidat dans la définition (marche toujours)}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Lorsqu'une fonction est donné, un candidat différentielle au point $(a_1,a_2)$ est souvent assez simple à trouver en un point :
\begin{equation}
    T(u_1,u_2)=\frac{ \partial f }{ \partial x }(a_1,a_2)u_1+\frac{ \partial f }{ \partial y }(a_1,a_2)u_2.
\end{equation}
L'application $T$ est la candidate différentielle en ce sens que si la différentielle existe, alors elle est égale à $T$. Ensuite, il faut vérifier si
\begin{equation}        \label{EqLimDefDiff}
    \lim_{(x,y)\to (a_1,a_2)} \frac{f(x,y) - f(a_1,a_2) - T\big( (x,y)-(a_1,a_2) \big)}{\| (x,y)-(a_1,a_2) \|}=0
\end{equation}
ou non. Si oui, alors la différentielle existe et $df_{(a,b)}(u)=T(u)$, sinon\footnote{y compris si la limite \eqref{EqLimDefDiff} n'existe même pas.}, la différentielle n'existe pas.

Attention : dans la ZAP, les dérivées partielles $\partial_xf$ et $\partial_yf$ ne peuvent en général pas être calculées en utilisant les règles de calcul (c'est bien pour ça que la ZAP est une zone à problèmes). Il faut d'office utiliser la définition
\begin{equation}
    \frac{ \partial f }{ \partial x }(a_1,a_2)=\lim_{t\to 0}\frac{ f(a_1+t,a_2)-f(a_1,a_2) }{ t },
\end{equation}
et la définition correspondante pour $\partial_yf$.

\subsubsection*{Conclusion}
Soient $f:A\subset \eR^n \rightarrow \eR^m$, et $a\in int\,A$. Si $f$ est différentiable en $a$, $$ (df_a (e_j))_i = d(f_i)_a(e_j) =\frac{\partial f_i}{\partial x_j}(a)= [Jac(f)_{|a}]_{ij}$$ et la matrice de l'application linéaire $df_a$ est la matrice jacobienne $m\times n$ de $f$ en $a$ notée $Jac(f)_{|a}$.
