% This is part of Le Frido
% Copyright (c) 2006-2024
%   Laurent Claessens, Carlotta Donadello
% See the file fdl-1.3.txt for copying conditions.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Formes différentielles}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\label{SecFormDiffRappel}

Nous parlerons de formes différentielles exactes et fermées dans la section~\ref{DefEFKQmPs}.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Décomposition dans la base duale}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}      \label{DEFooMGXSooWioKie}
	Soit \( U\), un ouvert dans \( \eR^n\). Une \( 1\)-\defe{forme différentielle}{forme!différentielle} \( \omega\) sur \( U\) est une application
	\begin{equation}
		\begin{aligned}
			\omega\colon U & \to (\eR^n)^*     \\
			x              & \mapsto \omega_x.
		\end{aligned}
	\end{equation}

	Une \defe{\( k\)-forme différentielle}{\( k\)-forme différentielle} est une application
	\begin{equation}
		\omega \colon U\to \aL_k(\eR^n,\eR)
	\end{equation}
	telle que \( \omega_x\) est alternée pour tout \( x\).

	Étant donné que \( \aL_k(\eR^n,\eR)\) est un espace vectoriel normé (définition \ref{DefKPBYeyG}), nous savons ce qu'est une forme différentielle continue ou de classe \( C^k\).
\end{definition}

\begin{remark}      \label{REMooSKKSooDZFMAr}
	L'ensemble des \( 1\)-formes différentielles devient un espace vectoriel avec les définitions
	\begin{equation}
		\begin{aligned}[]
			(\lambda\omega)_x(v) & =\lambda\omega_x(v)    \\
			(\omega+\mu)_x(v)    & =\omega_x(v)+\mu_x(v).
		\end{aligned}
	\end{equation}
\end{remark}

Nous connaissons la base de \( (\eR^n)^*\) définie en \ref{DEFooTMSEooZFtsqa}. Nous allons noter ces formes par \( dx_i\) :
\begin{equation}        \label{EQooITHKooDzigPY}
	\begin{aligned}[]
		e^*_1 & =dx_1\colon v\mapsto v_1 \\
		      & \vdots                   \\
		e^*_n & =dx_n\colon v\mapsto v_n
	\end{aligned}
\end{equation}
Toute forme différentielle s'écrit
\begin{equation}
	\omega_x = \sum_{i=0}^n a_i(x) d x_i
\end{equation}
où \( a_1,\ldots,a_n\) sont les composantes de \( \omega\) dans la base usuelle, et sont des fonctions à valeurs réelles.

\begin{lemma}		\label{LEMooNSFKooLOKGGy}
	Une \( 1\)-forme différentielle est \defe{continue}{continue!forme différentielle} si les fonctions \( a_i\) sont continues. La forme sera \( C^k\) quand les \( a_i\) seront \( C^k\).
\end{lemma}

Pour un vecteur \( v = (v_1,\ldots,v_n)\) on a donc par définition de \( d x_i\)
\begin{equation}
	\omega_x (v) = \sum_{i=0}^n a_i(x) v_i.
\end{equation}
Ces fonctions \( a_i\) peuvent être trouvées en appliquant \( \omega\) aux éléments de la base canonique de \( \eR^n\) :
\begin{equation}
	a_j(x)=\omega_x(e_j)
\end{equation}
parce que \( \omega_x(e_j)=\sum_ia_i(x)dx_i(e_i)=\sum_ia_i(x)\delta_{ij}=a_j(x)\).

%---------------------------------------------------------------------------------------------------------------------------
\subsection{L'isomorphisme musical}
%---------------------------------------------------------------------------------------------------------------------------

Si \( G\) est un champ de vecteurs sur \( \eR^n\), et si \( x\in\eR^n\), nous pouvons définir
\begin{equation}		\label{EqDefBemol}
	\begin{aligned}[]
		G^{\flat}_x\colon \eR^n & \to \eR                        \\
		v                       & \mapsto \langle G(x), v\rangle
	\end{aligned}
\end{equation}

Pour chaque \( x\), l'application \( G_x^{\flat}\) est une forme sur \( \eR^n\), c'est-à-dire une application linéaire de \( \eR^n\) vers \( \eR\). Nous écrivons que
\begin{equation}
	G_x^{\flat}\in\big( \eR^n \big)^*.
\end{equation}

Nous pouvons ainsi déterminer le développement de \( G^{\flat}\) dans la base des \( dx_i\) en faisant le calcul
\begin{equation}
	G_x^{\flat}(e_i)=\langle G(x), e_i\rangle =G_i(x),
\end{equation}
donc les composantes de \( G^{\flat}\) dans la base \( dx_i\) sont exactement les composantes de \( G\) dans la base \( e_i\) :
\begin{equation}
	G^{\flat}_x=G_1(x)dx_1+\cdots+G_n(x)dx_n.
\end{equation}

La construction inverse existe également. Si \( \omega\) est une \( 1\)-forme différentielle, nous pouvons définir le champ de vecteurs \( \omega^{\sharp}\) par la formule (implicite)
\begin{equation}
	\omega_x(v)=\langle \omega^{\sharp}(x), v\rangle
\end{equation}
pour tout \( v\in\eR^n\). Par définition, \( (\omega^{\sharp})^{\flat}=\omega\).

\begin{lemma}
	En composantes nous avons :
	\begin{equation}
		\omega^{\sharp}(x)=\big( a_1(x),\ldots,a_n(x) \big).
	\end{equation}
	Si \( G\) est un champ de vecteurs, alors \( (G^{\flat})^{\sharp}=G\).
\end{lemma}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Différentielle}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Nous avons déjà donné une définition abstraite de la différentielle dans la définition \ref{DefDifferentiellePta}. Nous en voyons maintenant quelques motivations dans le cas de fonctions sur \( \eR^2\) ou \( \eR^n\).

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Exemples introductifs}
%---------------------------------------------------------------------------------------------------------------------------
\label{SEBSECooLPRQooJRQCFL}

La notion de dérivée est associée à la recherche de la droite tangente à une courbe. Reprenons rapidement le cheminement. La dérivée de \( f\colon \eR\to \eR\) au point \( a\) est un nombre \( f'(a)\), qui définit donc une application linéaire dont le coefficient angulaire est \( f'(a)\), et que nous notons \( df_a\) :
\begin{equation}
	\begin{aligned}
		df_a\colon \eR & \to \eR         \\
		u              & \mapsto f'(a)u.
	\end{aligned}
\end{equation}
La droite donnée par l'équation
\begin{equation}
	y(a+u)=f'(a)u
\end{equation}
est parallèle à la tangente en \( a\). Pour trouver la tangente, il suffit de la décaler de la hauteur qu'il faut. L'équation de la droite tangente au graphe de \( f\) au point \( \big( a,f(a) \big)\) devient
\begin{equation}        \label{EqDiffRapTgDer}
	y(x)=f(a)+f'(a)(x-a)=f(a)+df_a(x-a).
\end{equation}
Nous nous proposons de généraliser cette formule au cas de la recherche du plan tangent à une surface.

\begin{example}
	Considérons \( f(x,y)=x^2y+y^2 e^{x}\). Les dérivées partielles sont
	\begin{equation}
		\begin{aligned}[]
			\frac{ \partial f }{ \partial x } & =2xy+y^2e^x \\
			\frac{ \partial f }{ \partial y } & =x^2+2ye^x.
		\end{aligned}
	\end{equation}
\end{example}

Cet exemple était l'exemple facile où tout se passe bien.

\begin{example}
	Les choses sont moins simples lorsqu'on considère la fonction suivante :
	\begin{equation}
		f(x,y)=\begin{cases}
			\frac{ xy }{ x^2+y^2 } & \text{si }(x,y)\neq(0,0) \\
			0                      & \text{si }(x,y)=(0,0).
		\end{cases}
	\end{equation}
	On voit que pour tout \( x\) et tout \( y\), nous avons \( f(x,0)=f(0,y)=0\). Donc cette fonction est nulle sur les axes horizontaux et verticaux. Nous avons en particulier
	\begin{equation}
		\begin{aligned}[]
			\frac{ \partial f }{ \partial x }(0,0) & =0  \\
			\frac{ \partial f }{ \partial y }(0,0) & =0.
		\end{aligned}
	\end{equation}
	Donc ces dérivées partielles existent.

	Il n'est par contre pas question de dire que cette fonction «va bien» autour du point \( (0,0)\). En effet si nous regardons sa valeur sur la droite diagonale \( y=x\), nous avons
	\begin{equation}
		f(x,x)=\frac{ x^2 }{ 2x^2 }=\frac{ 1 }{2}.
	\end{equation}
	Par conséquent si nous suivons la fonction le long de la droite \( y=x\), la hauteur vaut \( \frac{ 1 }{2}\) en permanence, sauf juste en \( (0,0)\) où la fonction fait un grand plongeon !
	\begin{verbatim}
    sage: var('x,y')
    (x, y)
    sage: f(x,y)=(x*y)/(x**2+y**2)
    sage: plot3d(f,(x,-2,2),y(-2,2))
    \end{verbatim}

	D'ailleurs elle fait un plongeon le long de toutes les droites (sauf verticale et horizontale). En effet si nous regardons la fonction le long de la droite \( y=mx\), nous avons
	\begin{equation}
		f(x,mx)=\frac{ mx^2 }{ x^2+m^2x^2 }=\frac{ m }{ 1+m^2 }.
	\end{equation}
	La fonction est donc \emph{constante} sur chacune de ces droites. Il n'est donc pas question de dire que cette fonction est «dérivable» en \( (0,0)\), vu qu'elle fait des grands sauts dans presque toutes les directions.
\end{example}

Nous devons donc trouver mieux que les dérivées partielles pour étudier le comportement des fonctions un peu problématiques.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Différentielle}
%---------------------------------------------------------------------------------------------------------------------------

Nous nous souvenons de l'équation \eqref{EqCodeDerviffxam} qui nous dit que pour une fonction d'une variable la dérivabilité signifiait qu'il existait un nombre \( \ell\) et une fonction \( \alpha\) tels que
\begin{equation}
	f(x)=f(a)+\ell(x-a)+(x-a)\alpha(x-a)
\end{equation}
et \( \lim_{t\to 0} \alpha(t)=0\).

En nous inspirant de cela, nous comprenons peut-être un peu le pourquoi de la définition \ref{DefDifferentiellePta}.

\begin{normaltext}
	L'objet \( df_a\) est \emph{en soi} une application \( df_a\colon \eR^m\to \eR^n\). Nous notons \( df_a(u)\)\nomenclature{\( df_a(u)\)}{Application de la différentielle de \( f\) sur le vecteur \( u\)} la valeur de \( df_a\) sur le vecteur \( u\in\eR^m\). En particulier, l'application \( df\) est une forme différentielle au sens de la définition~\ref{DEFooMGXSooWioKie}.
\end{normaltext}

\begin{normaltext}
	Les propositions~\ref{PropExistDiffUn} et~\ref{THOooBEAOooBdvOdr} vont montrer qu'en étudiant bien les dérivées partielles, nous pouvons conclure à la différentiabilité d'une fonction.
	Attention cependant, nous verrons dans l'exemple~\ref{Exemple0046Diff} que l'existence des dérivées directionnelles partielles ne permettait pas de conclure à la différentiabilité.
\end{normaltext}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Matrice de la différentielle}
%---------------------------------------------------------------------------------------------------------------------------

La différentielle est une application linéaire. Elle possède donc une matrice lorsque des bases sont fixées.
\begin{proposition}     \label{PROPooBMROooThgLuU}
	Soient une application différentiable \( f\colon \eR^m\to \eR^n\) et \( a\in \eR^m\). Dans les bases canoniques de \( \eR^m\) et \( \eR^n\), la matrice de \( df_a\) est
	\begin{equation}
		(df_a)_{ij}=\frac{ \partial f_i }{ \partial x_j }(a).
	\end{equation}
\end{proposition}

\begin{proof}
	Le lien entre matrice et application linéaire est vu dans la proposition \ref{PROPooGXDBooHfKRrv}. Dans le cas des bases canoniques de \( \eR^m\) et \( \eR^n\) nous savons qu'extraire une composante revient à prendre le produit scalaire. Nous avons donc
	\begin{equation}
		(df_a)_{ij}=\big( df_a(e_j) \big)_i=df_a(e_j)\cdot e_i.
	\end{equation}
	La linéarité de la dérivation donne alors
	\begin{equation}
		(df_a)_{ij}=df_a(e_j)\cdot e_i=\Dsdd{ f(a+te_j) }{t}{0}\cdot e_i=\Dsdd{ f_i(a+te_j) }{t}{0}=\frac{ \partial f_i }{ \partial x_j }(a).
	\end{equation}
	%TODOooQNEYooCoDxjQ il faut justifier le lien entre différentielle et dérivées partielles. Ce sont les propositions PROPooYCLBooOLoDnM et PROPooZOFLooBmcZqN.
\end{proof}


\begin{lemma}[\cite{MonCerveau}]       \label{LEMooDDUZooLwXkRp}
	Soit une fonction \( g\colon \eR\to \eR\) de classe \(  C^{\infty}\). Nous posons
	\begin{equation}
		\begin{aligned}
			f\colon \eR^2 & \to \eR       \\
			(x,y)         & \mapsto g(x).
		\end{aligned}
	\end{equation}
	Alors \( f\) est de classe \(  C^{\infty}\) sur \( \eR^2\).
\end{lemma}

\begin{proof}
	Le problème lorsqu'il faut démontrer qu'une fonction est de classe \(  C^{\infty}\), c'est que \( d^kf\) sera une application de \( \eR^2\) vers un espace qui est un terrible emboîtement de \( \aL(\eR^2,\ldots)\). Pour traiter cette difficulté, nous considérons les espaces suivants: \( V_0=\eR\) et par récurrence \( V_{k+1}=\aL(\eR^2,V_k)\).

	Et nous considérons également les éléments
	\begin{equation}
		\begin{aligned}
			\alpha_1\colon \eR^2 & \to \eR   \\
			(u,v)                & \mapsto u
		\end{aligned}
	\end{equation}
	et plus généralement \( \alpha_k\in V_k\) donné par
	\begin{equation}
		\begin{aligned}
			\alpha_k\colon \eR^2 & \to V_{k-1}            \\
			(u,v)                & \mapsto u\alpha_{k-1}.
		\end{aligned}
	\end{equation}
	Notons que dans l'expression \( u\alpha_{k-1}\), il s'agit d'un produit entre un scalaire \( u\in \eR\) et un vecteur \( \alpha_{k+1}\in V_{k-1}\).

	Nous prouvons maintenant par récurrence que \( d^{k}f_{(a,b)}=g^{(k)}(a)\alpha_k\), en utilisant directement la définition.

	\begin{subproof}
		\spitem[Initialisation]

		Pour \( k=1\), nous calculons
		\begin{equation}
			\frac{ |f(a+h_1,b+h_2)-f(a,b)-g'(a)\alpha_1(h)| }{ \| h \| }=\frac{ |g(a+h_1)-g(a)-g'(a)h_1| }{ \| h \| }
		\end{equation}
		Notre but est de calculer la limite de cela lorsque \( h\stackrel{\eR^2}{\longrightarrow}0\) avec \( h\neq 0\). L'hypothèse sur la dérivabilité de \( g\) nous indique que si \( 0<| t |<\delta\), alors
		\begin{equation}        \label{EQooQLWNooLRKhUv}
			\frac{ | g(a+t)-g(a)-tg'(a) | }{ | t | }<\epsilon.
		\end{equation}
		Nous considérons donc la boule épointée de \( \eR^2\) de rayon \( \delta\) : \( B=B\big( (0,0),\delta \big)\setminus\{(0,0)\}\), et nous considérons \( h\in B\). Deux cas sont à distinguer : \( h_1=0\) et \( h_1\neq 0\).

		Si \( h_1=0\), alors
		\begin{equation}
			\frac{ |g(a+h_1)-g(a)-g'(a)h_1| }{ \| h \| }=0.
		\end{equation}
		Sinon nous avons \( 0<h_1\leq\| h \|<\delta\) et donc
		\begin{equation}
			\frac{ |g(a+h_1)-g(a)-g'(a)h_1| }{ \| h \| }\leq\frac{ |g(a+h_1)-g(a)-g'(a)h_1| }{ | h_1 | }<\epsilon
		\end{equation}
		par la relation \eqref{EQooQLWNooLRKhUv}. Nous avons donc bien
		\begin{equation}
			\lim_{h\to 0}\frac{ |f(a+h_1,b+h_2)-f(a,b)-g'(a)\alpha_1(h)| }{ \| h \| }=0.
		\end{equation}

		\spitem[Récurrence]

		Nous supposons que \( d^kf_{a,b}=g^{(k)}(a)\alpha_k\), et nous devons prouver que \( d^kf\) est différentiable et que \( d^{k+1}f_{(a,b)}=g^{(k+1)}(a)\alpha_{k+1}\). Pour cela nous introduisons tout dans la définition de la différentielle pour voir ce qui arrive.

		Nous avons :
		\begin{equation}
			\begin{aligned}[]
				\frac{ d^kf_{(a+h_1,b+h_2)}-d^kf_{(a,b)}-g^{(k+1)}(a)\alpha_{k+1}(h_1,h_2) }{ \| h \| } \\
				\qquad=
				\frac{ g^{(k)}(a+h_1)\alpha_k-g^{(k)}(a)\alpha_k-g^{(k+1)}(a)h_1\alpha_k }{ \| h \| }.
			\end{aligned}
		\end{equation}
		Cela est, pour chaque \( h\neq 0\), un élément \( V_k\), mais le coefficient \( \alpha_k\) se factorise de telle sorte que nous devons seulement calculer la limite (si elle existe)
		\begin{equation}
			\lim_{h\to 0} \frac{ g^{(k)}(a+h_1)-g^{(k)}(a)-h_1g^{(k+1)}(a) }{ \| h \| }.
		\end{equation}
		Le même jeu de séparation entre \( h_1=0\) et \( h_1\neq 0\) que dans le cas \( k=1\) nous permet de déduire que cette limite existe et vaut zéro, grace à la définition de \( g^{(k+1)}\).
	\end{subproof}

	Nous avons donc prouvé que \( f\) est différentiable autant que fois que souhaité. Elle est donc de classe \(  C^{\infty}\) comme annoncé.
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Différentielle, dual et forme différentielle}
%---------------------------------------------------------------------------------------------------------------------------

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Dans la base duale}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Nous avons déjà parlé en \eqref{EQooITHKooDzigPY} de la base \( \{ dx_i \}_{i=1,\ldots, n}\) des formes différentielles sur \( \eR^n\).

\begin{proposition}
	La forme de base \( dx_i\) est la différentielle de la fonction de projection
	\begin{equation}
		\begin{aligned}
			\pr_i\colon \eR^n & \to \eR      \\
			v                 & \mapsto v_i.
		\end{aligned}
	\end{equation}
	Autrement dit nous avons
	\begin{equation}
		d(\pr_i)_a=dx_i
	\end{equation}
	pour tout \( i\) et pour tout \( a\).
\end{proposition}

\begin{proof}
	Le quotient
	\begin{equation}
		\frac{ \pr_i(a+h)-\pr_i(a)-dx_i(h) }{ \| h \| }
	\end{equation}
	est toujours nul. La limite est a fortiori nulle.
\end{proof}

Nous avons donc \( (d\pr_i)_a=dx_i\) pour tout \( a\). Notons que les fonctions \( dx_i\) et \( \pr_i\) sont les mêmes. Cela justifie la notation «\( dx_i\)» pour les formes différentielles de base, parce que ce sont les différentielles des fonctions «coordonnées» que nous pouvons noter \( x_i\).

Étant donnée une fonction \( f\), il est légitime de nous demander comment (si elle existe) la différentielle se décompose en chaque point dans la base duale. C'est-à-dire fixer les fonctions \( a_i\) en termes des dérivées de \( f\) pour avoir
\begin{equation}
	df_a=\sum_{i=1}^n\frac{ \partial f }{ \partial x_i }(a)dx_i.
\end{equation}
C'est ce que nous allons faire dans le corolaire~\ref{CORooXURPooQMKvBl}.

\begin{example}
	Si \( F\colon \eR^2\to \eR\) est une fonction \( C^2\), sa différentielle est la forme
	\begin{equation}
		dF=\frac{ \partial F }{ \partial x }dx+\frac{ \partial F }{ \partial y }dy.
	\end{equation}
	Si nous nommons \( f\) et \( g\) les fonctions \( \partial_xF\) et \( \partial_yF\), nous avons donc
	\begin{equation}
		Df=fdx+gdy,
	\end{equation}
	qui vérifie
	\begin{equation}
		\partial_yf=\partial_xg,
	\end{equation}
	parce que \( \frac{ \partial f }{ \partial y }=\frac{ \partial^2F  }{ \partial x\partial y }=\frac{ \partial^2F  }{ \partial y\partial x }=\frac{ \partial g }{ \partial x }\). Ce que nous avons donc prouvé, c'est que
\end{example}

\begin{lemma}
	Si \( fdx+gdy\) est la différentielle d'une fonction de classe \( C^2\) sur \( \eR^2\), alors \( \partial_yf=\partial_xg\).
\end{lemma}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Ce n'est pas la différentielle extérieure}
%---------------------------------------------------------------------------------------------------------------------------

Il existe une notion de différentielle extérieure, mais ce n'est pas celle-là que nous utilisons la majorité du temps. En particulier si \( E\) et \( F\) sont des espaces vectoriels normés, lorsque \( f\colon E\to F\) est une fonction, \( df\) est une application
\begin{equation}
	df\colon E\to \aL(E,F)
\end{equation}
et la différentielle seconde est la différentielle de cette application-là. Chose faisable parce que \( \aL(E,F)\) est un espace vectoriel on ne peut plus respectable.

Soit \( D\subset\eR^n\). Par définition de la différentielle extérieure d'une \( 1\)-forme, nous avons une formule de Leibniz
\begin{equation}
	d(f\omega)=df\wedge\omega+fd\omega.
\end{equation}
En particulier,
\begin{equation}
	d(fdx)=df\wedge dx+f\underbrace{d(dx)}_{=0}=\frac{ \partial f }{ \partial x }\underbrace{dx\wedge dx}_{=0}+\frac{ \partial f }{ \partial y }dy\wedge dx.
\end{equation}

Attention : la différentielle extérieure n'est pas la différentielle usuelle. Certes dans le cas d'une \( 0\)-forme (c'est-à-dire d'une fonction), les deux notions coïncident, mais ça ne va pas plus loin. La différentielle extérieure vérifie \( d^2\omega=0\) pour tout \( \omega\), y compris pour les fonctions : si \( \omega=df\) alors \( d\omega=0\).

Nous mentionnerons la différentielle extérieure dans le cas de
\begin{enumerate}
	\item
	      Théorème de Stockes~\ref{ThoATsPuzF}.
\end{enumerate}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Continuité, dérivabilité et différentiabilité}
%---------------------------------------------------------------------------------------------------------------------------

Le théorème suivant reprend les principales propriétés d'une fonction différentiable. Il est à ne pas confondre avec le théorème \ref{THOooBEAOooBdvOdr} qui dira que si les dérivées partielles sont continues sur un voisinage de \( a\), alors \( f\) est différentiable en \( a\).
\begin{proposition}\label{diff1}\label{ThoRapPropDiffSi}
	Soit un espace vectoriel normé \( V\) et une fonction \( f\colon \eR^n\to V\). Si \( f\) est différentiable au point \( a\in \eR^n\) alors
	\begin{enumerate}
		\item
		      elle est continue en \( a\),
		\item
		      elle admet une dérivée dans toutes les directions de \( \eR^n\),
		\item  toutes les dérivées directionnelles \( \partial_uf(a)\) existent et nous avons l'égalité
		      \begin{equation}        \label{EqDiffPartRap}
			      \begin{aligned}
				      df_a\colon \eR^n & \to \eR^m                                                                                              \\
				      u                & \mapsto df_a(u)=\frac{ \partial f }{ \partial u }(a)=\sum_i \frac{ \partial f }{ \partial x_i }(a)u_i,
			      \end{aligned}
		      \end{equation}
		      si les \( u_i\) sont les composantes de \( u\) dans la base canonique \( \eR^n\).
	\end{enumerate}
\end{proposition}
\index{application!différentiable}

La dernière égalité sera de temps en temps utilisée sous la forme
\begin{equation}    \label{EqOWQSoMA}
	df_a(u)=\Dsdd{ f(a+tu) }{t}{0}.
\end{equation}

\begin{proof}
	La limite
	\[
		\lim_{h\to 0_m}\frac{\|f(a+h)-f(a)-T(h)\|_n}{\|h\|_m}=0,
	\]
	implique que
	\[
		\lim_{h\to 0_m}\|f(a+h)-f(a)-T(h)\|_n=0.
	\]
	Comme \( T\) est dans \( \mathcal{L}(\eR^m,\eR^n)\), on a \( \lim_{h\to 0}T(h)=0\), d'où la continuité de \( f\) au point \( a\).

	Si \( u\) est un vecteur non nul, la différentiabilité de \( f\) au point \( a\) implique
	\[
		\lim_{t\to 0}\frac{\|f(a+tu)-f(a)-T(tu)\|_n}{\|tu\|_m}=0,
	\]
	par la linéarité de \( T\) et par l'égalité \( \|tu\|_m=|t|\|u\|_m\) on obtient
	\[
		\lim_{t\to 0}\frac{f(a+tu)-f(a)}{|t|}= T(u).
	\]
	Donc \( f\) est dérivable suivant le vecteur \( u\) et \( \partial_uf(a)=T(u)=df_a(u)\).
\end{proof}

\begin{corollary}[Différentielle et dérivée]       \label{CORooTBUMooHPncPH}
	Soit une application différentiable \( f\colon \eR\to V\) où \( V\) est un espace vectoriel normé. Alors \( f'(u)=df_u(1)\).
\end{corollary}

\begin{proof}
	En vertu de la proposition \ref{ThoRapPropDiffSi}, nous avons
	\begin{equation}
		df_u(1)=\Dsdd{ f(u+t1) }{t}{0}=f'(u).
	\end{equation}
	Nous avons utilisé le fait que pour une fonction sur \( \eR\), l'unique dérivée partielle est la dérivée normale.
\end{proof}

\begin{corollary}       \label{CORooXURPooQMKvBl}
	Si \( f\) est différentiable, alors la forme différentielle \( df_a\) se décompose en
	\begin{equation}
		df_a=\sum_i(\partial_if)(a)dx_i.
	\end{equation}
\end{corollary}

\begin{proof}
	Vue la définition des formes \( dx_i\) nous pouvons remplacer \( u_i\) par \( dx_i(u)\) dans l'égalité \eqref{EqDiffPartRap} et écrire
	\begin{equation}
		df_a(u)=\sum_i(\partial_if)(a)dx_i(u)
	\end{equation}
	et donc écrire l'égalité demandée.
\end{proof}

Le lemme suivant regroupe quelques égalités avec lesquelles nous allons souvent travailler. Il explique comment sont liées les dérivées directionnelles, les dérivées partielles et la différentielle.
\begin{lemma}		\label{LemdfaSurLesPartielles}
	Si \( f\colon \eR^m\to \eR^n\) est une fonction différentiable, alors
	\begin{equation}
		df_a(u)=\frac{ \partial f }{ \partial u }(a)=\Dsdd{ f(a+tu) }{t}{0}=\sum_{i=1}^mu_i\frac{ \partial f }{ \partial x_i }(a)=\nabla f(a)\cdot u
	\end{equation}
	pour tout vecteur \( u\in\eR^m\)
\end{lemma}

\begin{proof}
	La première égalité est la proposition~\ref{diff1}, et la seconde est seulement la définition de la dérivée directionnelle avec des notations un peu plus snob. En particulier nous avons
	\begin{equation}
		df_a(e_i)=\frac{ \partial f }{ \partial x_i }(a).
	\end{equation}
	Pour le reste c'est la linéarité de la différentielle qui joue : le vecteur \( u\) peut être écrit de façon unique comme combinaison linéaire des vecteurs de base
	\[
		u=\sum_{i=1}^{m}u_i e_i, \qquad  u_i\in\eR,\, \forall i\in\{1,\ldots, m\}.
	\]
	Alors, la linéarité de \( df_a\) nous donne
	\begin{equation}
		df_a(u)= df_a\left(\sum_{i=1}^{m}u_i e_i\right)
		=\sum_{i=1}^{m}u_i \left(df_ae_i\right)
		=\sum_{i=1}^{m}u_i \frac{ \partial f }{ \partial x_i }(a).
	\end{equation}
	Le lien avec le gradient est la définition du produit scalaire \eqref{PROPooSKVRooDGVCYj}.
\end{proof}

La formule \( df_a(u)=\Dsdd{ f(a+tu) }{t}{0}\) est bien utile pour calculer des différentielles, mais elle ne permet pas de prouver que \( f\) est différentiable. Autrement dit, même si le calcul de la dérivée \( \Dsdd{ f(a+tu) }{t}{0}\) donne un résultat pour tout \( u\), nous ne pouvons pas en déduire que \( f\) est différentiable au point \( a\).

\begin{proposition}[\cite{MonCerveau}]	\label{PROPooJMBJooQzjXYf}
	Si \(f \colon \eR^n\to \eR^m  \) est une application différentiable, alors sa matrice est donnée par
	\begin{equation}
		(df_a)_{ij}=df_a(e_j)\cdot e_i=(\partial_jf_i)(a).
	\end{equation}
\end{proposition}

\begin{proof}
	En suivant la formule de la proposition \ref{PROPooGXDBooHfKRrv}\ref{ITEMooKZYYooZPTkpq}, nous devons calculer
	\begin{equation}
		(df_a)_{ij}=\big( df_a(e_j) \big)_i.
	\end{equation}
	En utilisant les formules du lemme \ref{LemdfaSurLesPartielles}, nous avons \( df_a(e_i)=(\partial_if)(a)\), et donc
	\begin{equation}
		(df_a)_{ij}=\big( dfa_a(e_j) \big)_i=(\partial_jf)(a)_i=(\partial_jf_i)(a).
	\end{equation}
\end{proof}

\begin{proposition} \label{PropExistDiffUn}
	Soient \( f\) une fonction de \( x\) et \( y\) et un point \( (a,b)\in\eR^2\). Si les nombres \( \partial_xf(a,b)\) et \( \partial_yf(a,b)\) existent et si il existe une fonction \( \alpha\colon \eR\to \eR\) telle que
	\begin{equation}        \label{eqCritDifffabsrt}
		\begin{aligned}[]
			f(x,y)=f(a,b) & +\frac{ \partial f }{ \partial x }(a,b)(x-a)+\frac{ \partial f }{ \partial y }(a,b)(y-b) \\
			              & +\| (x,y)-(a,b) \| \alpha\Big( \| (x,y)-(a,b) \| \Big)
		\end{aligned}
	\end{equation}
	et
	\begin{equation}
		\lim_{t\to 0} \alpha(t)=0,
	\end{equation}
	alors \( f\) est différentiable en \( (a,b)\).
\end{proposition}


\begin{normaltext}
	Dans cet énoncé nous avons écrit \( d\big( (x,y),(a,b) \big)\) la distance entre \( (x,y)\) et \( (a,b)\), c'est-à-dire le nombre \( \sqrt{(x-a)^2+(y-b)^2}\). Afin d'écrire l'équation \eqref{eqCritDifffabsrt} sous forme plus compacte, nous introduisons le vecteur
	\begin{equation}
		\nabla f(a,b)=\begin{pmatrix}
			\cfrac{ \partial f }{ \partial x }(a,b) \\
			\cfrac{ \partial f }{ \partial y }(a,b).
		\end{pmatrix}
	\end{equation}
	L'équation \eqref{eqCritDifffabsrt} devient alors
	\begin{equation}        \label{EqdiffComp}
		f(X)=f(P)+\nabla f(a,b)\cdot (X-P)+\| X-P \|\alpha\big( \| X-P \| \big).
	\end{equation}
	Le vecteur \( (\nabla f)(a,b)\) est appelé le \defe{gradient}{gradient} de \( f\) au point \( (a,b)\).
\end{normaltext}

\begin{remark}
	Nous avons introduit la notation \( \nabla f\) pour le gradient d'une fonction \( f\). Nous allons par la suite introduire \( \nabla\cdot F\) pour la divergence du champ de vecteurs \( F\) et \( \nabla\times F\) pour son rotationnel.

	Toutes les formules pour \( \nabla f\), \( \nabla\cdot F\) et \( \nabla\times F\) peuvent facilement être mémorisées en pensant à \( \nabla\) comme étant le vecteur
	\begin{equation}        \label{EQooQKGQooOPeFoo}
		\nabla=\begin{pmatrix}
			\partial_x \\
			\partial_y \\
			\partial_z
		\end{pmatrix}.
	\end{equation}
	Nous allons ici cependant seulement penser à \eqref{EQooQKGQooOPeFoo} comme un moyen mnémotechnique; nous ne donnons pas de définition à «\( \nabla\)» tout seul.
\end{remark}

\begin{proposition}		\label{PROPooEYPKooAVjJRF}
	Si \( f\) est différentiable en \( (a,b)\) alors pour tout vecteur \( u\), la fonction
	\begin{equation}
		\begin{aligned}
			\varphi\colon \eR & \to \eR                    \\
			t                 & \mapsto   f(a+tu_1,b+tu_2)
		\end{aligned}
	\end{equation}
	est dérivable en \( 0\) et on a
	\begin{equation}
		\varphi'(0)=\nabla f(p)\cdot u
	\end{equation}
	où nous avons noté \( p=(a,b)\).
\end{proposition}

\begin{proof}
	Réécrivons la formule \eqref{EqdiffComp} sous la forme
	\begin{equation}
		f(x)=f(p)+\nabla f(p)\cdot (x-p)+\| x-p \|\alpha(\| x-p \|).
	\end{equation}
	Cela étant vrai pour tout \( x\), nous l'écrivons en particulier pour \( x=p+tu\) où \( t\) est un réel et \( u\) est le vecteur unitaire choisi. Nous avons donc
	\begin{equation}
		f(p+tu)=f(p)+t\nabla f(p)\cdot u+\| tu \|\alpha(\| tu \|).
	\end{equation}
	En utilisant le fait que \( u\) est unitaire, \( \| tu \|=| t |\| u \|=| t |\). La dérivée de \( \varphi\) en \( 0\) est alors donnée par
	\begin{equation}
		\lim_{t\to 0} \frac{ f(p+tu)-f(p) }{ t }=\lim_{t\to 0} \nabla f(p)\cdot u+\alpha(| t |).
	\end{equation}
	Lorsque nous prenons la limite, le membre de gauche devient \( \varphi'(0)\) tandis que dans le membre de droite, le second terme disparaît. Nous avons finalement
	\begin{equation}
		\varphi'(0)=\nabla f(p)\cdot u
	\end{equation}
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Calcul de valeurs approchées}
%---------------------------------------------------------------------------------------------------------------------------

Si nous remplaçons les accroissements \( x-a\) et \( y-b\) par \( h\) et \( k\), le critère de différentiabilité s'écrit
\begin{equation}
	\begin{aligned}[]
		f(a+h,b+k)=f(a,b)+\frac{ \partial f }{ \partial x }(a,b)h & +\frac{ \partial f }{ \partial y }(a,b)k         \\
		                                                          & +\sqrt{h^2+k^2}\alpha\big( \sqrt{h^2+k^2} \big).
	\end{aligned}
\end{equation}
Le dernier terme du membre de droite tend vers zéro à une vitesse double lorsque \( h\) et \( k\) tendent vers zéro : d'une part parce que \( \sqrt{h^2+k^2}\) tend vers zéro et d'autre part parce que \( \alpha\big( \sqrt{h^2+k^2} \big)\) tend vers zéro. Nous avons donc la «bonne» approximation
\begin{equation}        \label{EqFormApproxfxyab}
	f(x,y)\simeq f(a,b)+\frac{ \partial f }{ \partial x }(a,b)(x-a)+\frac{ \partial f }{ \partial y }(a,b)(y-b).
\end{equation}
lorsque \( (x,y)\) n'est pas trop loin de \( (a,b)\). Cette expression est évidemment une généralisation immédiate de l'équation \eqref{EqfxdxSimeqfxfpx}. Elle exprime que l'on peut obtenir des informations sur la valeur d'une fonction en \( (x,y)\) si on peut calculer la fonction et ses dérivées en un point \( (a,b)\) non loin de \( (x,y)\).

Cette formule peut aussi être vue sous la forme suivante, plus pratique dans certains calculs :
\begin{equation}        \label{EqFormApproxfxyabDF}
	f(a+\Delta x,b+\Delta y)\simeq f(a,b)+\Delta x\frac{ \partial f }{ \partial x }(a,b)+\Delta y\frac{ \partial f }{ \partial y }(a,b).
\end{equation}

\begin{example}
	Prenons la fonction \( f(x,y)=\cos(x)\sin(y)\) et calculons une approximation de
	\begin{equation}
		f\big( \frac{ \pi }{ 3 }+0.01,\frac{ \pi }{ 2 }+0.03 \big).
	\end{equation}
	D'abord les dérivées partielles sont
	\begin{equation}
		\begin{aligned}[]
			\frac{ \partial f }{ \partial x }(x,y)=-\sin(x)\sin(y) \\
			\frac{ \partial f }{ \partial y }(x,y)=\cos(x)\cos(y).
		\end{aligned}
	\end{equation}
	Nous allons utiliser l'approximation
	\begin{equation}
		f\big( \frac{ \pi }{ 3 }+0.01,\frac{ \pi }{ 2 }+0.03 \big)\simeq f\big( \frac{ \pi }{ 3 },\frac{ \pi }{2} \big)+0.01\frac{ \partial f }{ \partial x }\big( \frac{ \pi }{ 3 },\frac{ \pi }{2} \big)+0.03\frac{ \partial f }{ \partial y }\big( \frac{ \pi }{ 3 },\frac{ \pi }{2} \big).
	\end{equation}
	Nous avons
	\begin{equation}
		\begin{aligned}[]
			\frac{ \partial f }{ \partial x }\big( \frac{ \pi }{ 3 },\frac{ \pi }{2} \big) & =-\sin\frac{ \pi }{ 3 }\sin\frac{ \pi }{ 2 }=-\frac{ \sqrt{3} }{2} \\
			\frac{ \partial f }{ \partial y }\big( \frac{ \pi }{ 3 },\frac{ \pi }{2} \big) & =\cos\frac{ \pi }{ 3 }\cos\frac{ \pi }{ 2 }=0.
		\end{aligned}
	\end{equation}
	Par conséquent
	\begin{equation}
		f\big( \frac{ \pi }{ 3 }+0.01,\frac{ \pi }{ 2 }+0.03 \big)\simeq \frac{ 1 }{2}-0.01\frac{ \sqrt{3} }{2}=\frac{ 1 }{2}-\frac{ \sqrt{3} }{ 200 }.
	\end{equation}

	\begin{verbatim}
sage: var('x,y')
(x, y)
sage: f(x,y)=cos(x)*sin(y)
sage: a=f(pi/3+0.01,pi/2+0.03)
sage: numerical_approx(a)
0.491093815387986
sage: b=1/2-sqrt(3)/200
sage: numerical_approx(b)
0.491339745962156
sage: numerical_approx(a-b)
-0.000245930574169814
    \end{verbatim}
	Cela fait une erreur de l'ordre du dix millième.

\end{example}

\begin{remark}
	Les esprits les plus critiques diront que cette vérification par Sage n'en est pas une parce que Sage a certainement utilisé un algorithme d'approximation qui se base sur la même idée que ce que nous venons de faire, et que par conséquent le fait qu'il obtienne le même résultat que nous est un peu tautologique.

	Ils n'auront pas tort. Cependant, le code source de Sage est disponible publiquement\footnote{Voir \url{http://www.sagemath.org}}; vous pouvez aller le lire et vérifier qu'il y a effectivement une \emph{preuve} que le résultat fourni par Sage possède une bonne dizaine de décimales correctes.

	Cette disponibilité publique du code source est une des nombreuses différences fondamentales entre Sage et votre calculatrice\footnote{et les autres logiciels de type fenêtre, pomme ou feuille d'érable.}. Dois-je vous rappeler qu'un des principes fondamentaux de l'éthique scientifique est que les résultats et les méthodes utilisés doivent être absolument ouverts à la vérification et à la critique de tous ?
\end{remark}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Différentielle et tangente}
%---------------------------------------------------------------------------------------------------------------------------

La notion de dérivée partielle (ou de dérivée suivant un vecteur) pour une fonction de plusieurs variables n'est pas une  généralisation de la notion de dérivée en une variable d'espace. En fait, du point de vue géométrique, la dérivée de la fonction \( g:\eR\to\eR\) au point \( a\) est la pente de la ligne droite tangente au graphe de \( g\) au point \( (a, g(a))\). Cette ligne, d'équation \( r(x)=g'(a)x+g(a)\), est la meilleure approximation affine du graphe de \( g\) au point \( a\), comme à la figure~\ref{LabelFigTangentSegment}.
\newcommand{\CaptionFigTangentSegment}{Tangentes au graphe d'une fonction d'une variable}
\input{auto/pictures_tex/Fig_TangentSegment.pstricks}

Le graphe d'une fonction \( f\) de \( \eR^2\) dans \( \eR\) est une surface de deux paramètres dans \( \eR^3\). Si l'approximation affine d'une telle surface au point \( (x,y,f(x,y))\) existe, alors elle est un plan tangent. En dimension plus haute, le graphe de la fonction \( f:\eR^m\to\eR\) est une surface de \( m\) paramètres dans \( \eR^{m+1}\) et son approximation affine (si elle existe) est un hyperplan de \( \eR^m\).

Nous allons voir que si \( f\) prend ses valeurs dans \( \eR^n\) l'approximation affine de \( f\) au point \( a\) est l'élément de \(  f(a)+\mathcal{L}(\eR^m,\eR^n)\) qui ressemble le plus à \( f\) au voisinage de \( a\). Plus précisément, on utilise les définitions suivantes.
\begin{definition}
	Soient \( f\) et \( g\) deux applications d'un ouvert \( U\) de \( \eR^m\) dans \( \eR^n\). On dit que \( g\) est \defe{tangente}{application!tangente} à \( f\) au point \( a\in U\) si \( f(a)=g(a)\) et
	\[
		\lim_{\begin{subarray}{l}
				x\to a\\ x\neq a
			\end{subarray}}\frac{\|f(x)-g(x)\|_n}{\|x-a\|_m}=0.
	\]
\end{definition}
La relation de tangence est une relation d'équivalence. Nous sommes particulièrement intéressés par le cas où \( f\) admet une application  affine tangente au point \( a\).


\newcommand{\CaptionFigDifferentielle}{Interprétation géométrique de la différentielle.}
\input{auto/pictures_tex/Fig_Differentielle.pstricks}
En ce qui concerne l'interprétation géométrique, si nous regardons la figure~\ref{LabelFigDifferentielle}, et d'ailleurs aussi en voyant la définition~\ref{EqCritereDefDiff}, la fonction est différentiable et la différentielle est \( T\) si il existe une fonction \( \alpha\) telle que
\begin{equation}
	f(a+u)-f(a)-T(u)=\alpha(u)
\end{equation}
où la fonction \( \alpha\) satisfait
\begin{equation}		\label{EqPresqueTa}
	\lim_{u\to 0} \frac{ \| \alpha(u)\| }{\| u \|}=0
\end{equation}
C'est cela qui fait écrire \( f(a+u)-f(a)-df_a(u)=o(\| u \|)\) à ceux qui n'ont pas peur de la notation \( o\).

La différentielle \( df_a\) est donc la partie linéaire de l'application affine qui approxime au mieux la fonction \( f\) autour du point \( a\). La notion de différentielle est la vraie généralisation du concept de dérivée pour fonctions de plusieurs variables, en outre elle nous permet d'expliciter la relation qui associe au vecteur \( u\) la dérivée \( \partial_u f(a)\), pour \( f\) et \( a\) fixés.

\begin{remark}
	Si on remplace les normes \( \|\cdot\|_m\)  et \( \|\cdot\|_n\) par d'autres normes, l'existence et la valeur de la différentielle de \( f\) au point \( a\) ne sont pas remises en cause. En effet, soient  \( \|\cdot\|_M\)  une norme sur \( \eR^m\) et \( \|\cdot\|_N\) une norme sur \( \eR^n\). Par le théorème~\ref{ThoNormesEquiv}, ces normes sont équivalentes à \( \| . \|_m\) et \( \| . \|_n\) respectivement; il existe donc des constantes \( k,\, K,\, l,\,L >0\) telles que  pour tout vecteur \( u\) de \( \eR^m\) et tout vecteur \( v\) de \( \eR^n\)
	\[
		k\|u\|_M\leq \|u\|_m\leq K\|u\|_M,
	\]
	\[
		l\|v\|_N\leq \|v\|_n\leq L\|v\|_N.
	\]
	Les éléments de \( \mathcal{L}(\eR^m, \eR^n)\) sont les mêmes et on a
	\begin{equation}
		\begin{aligned}
			 & \frac{l}{K}  \frac{\|f(a+h)-f(a)-T(h)\|_N}{\|h\|_M}\leq \frac{\|f(a+h)-f(a)-T(h)\|_n}{\|h\|_m}\leq \\
			 & \leq\frac{L}{k} \frac{\|f(a+h)-f(a)-T(h)\|_N}{\|h\|_M}.
		\end{aligned}
	\end{equation}
	Il est donc possible, pour démontrer la différentiabilité ou pour calculer la différentielle, d'utiliser le critère \eqref{EqCritereDefDiff} avec une norme au choix. Parfois c'est utile.
\end{remark}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Prouver qu'une fonction n'est pas différentiable}
%---------------------------------------------------------------------------------------------------------------------------

Chacun des points du théorème~\ref{ThoRapPropDiffSi} est en soi un critère pour montrer qu'une fonction n'est pas différentiable en un point.

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Continuité}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////


Le premier critère à vérifier est donc la continuité. Si une fonction n'est pas continue en un point, alors elle n'y sera pas différentiable. Pour rappel, la continuité en \( a\) se teste en vérifiant si \( \lim_{x\to a}f(x)=f(a)\).

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Linéarité}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Un second test est la linéarité de la dérivée directionnelle par rapport à la direction : l'application \( u\mapsto\frac{ \partial f }{ \partial u }(a)\) doit être linéaire, sinon \( df_a\) n'existe pas.

\begin{example}     \label{Exemple0046Diff}
	Examinons la fonction
	\begin{equation}
		\begin{aligned}
			f\colon \eR^2 & \to \eR                                                       \\
			(x,y)         & \mapsto \begin{cases}
				                        \cfrac{ xy^2 }{ x^2+y^4 } & \text{si }(x,y)\neq (0,0) \\
				                        0                         & \text{sinon}.
			                        \end{cases}
		\end{aligned}
	\end{equation}
	Prenons \( u=(u_1,u_2)\) et calculons la dérivée de \( f\) dans la direction de \( u\) au point~\( (0,0)\) :
	\begin{equation}
		\begin{aligned}[]
			\frac{ \partial f }{ \partial u }(0,0)
			 & =\lim_{t\to 0}\frac{ f(tu_1,tu_2)-f(0,0) }{ t }                                      \\
			 & =\lim_{t\to 0}\frac{1}{ t }\left( \frac{ tu_1t^2u_2^2 }{ t^2u_1^2+t^4u_2^4 } \right) \\
			 & =\lim_{t\to 0}\left( \frac{ u_1u_2^2 }{ u_1^2+t^2u_2^4 } \right)                     \\
			 & =\begin{cases}
				    \cfrac{ u_2^2 }{ u_1 } & \text{si }u_1\neq 0 \\
				    0                      & \text{si }u_1=0.
			    \end{cases}
		\end{aligned}
	\end{equation}
	Cette application n'est pas linéaire par rapport à \( u\). En effet, notons
	\begin{equation}
		\begin{aligned}
			A\colon \eR^n & \to \eR                                         \\
			u             & \mapsto \frac{ \partial f }{ \partial u }(0,0),
		\end{aligned}
	\end{equation}
	et vérifions que pour tout \( u\) et \( v\) dans \( \eR^n\) et \( \lambda\in\eR\), nous ayons \( A(\lambda u)=\lambda A(u)\) et \( A(u+v)=A(u)+A(v)\). La première égalité est vraie, parce que
	\begin{equation}
		A(\lambda u)=A(\lambda u_1,\lambda u_2)=\frac{ \lambda^2 u_2^2 }{ \lambda u_1 }=\lambda\frac{ u_2^2 }{ u_1 }=\lambda A(u).
	\end{equation}
	Mais nous avons par exemple
	\begin{equation}
		A\big( (0,1)+(2,3) \big)=A(2,4)=\frac{ 16 }{ 2 }=8,
	\end{equation}
	tandis que
	\begin{equation}
		A(0,1)+A(2,3)=0+\frac{ 9 }{ 2 }\neq 8.
	\end{equation}
	La fonction \( f\) n'est donc pas différentiable en \( (0,0)\), parce que la candidate différentielle, \( df_{(0,0)}(u)=\frac{ \partial f }{ \partial u }(0,0)\), n'est même pas linéaire.

\end{example}

Voici une autre façon de traiter la fonction de l'exemple~\ref{Exemple0046Diff}.

\begin{example} \label{ExeFHmCLII}
	La figure~\ref{LabelFigFWJuNhU} représente le domaine d'une fonction \( f\colon \eR^2\to \eR\), et sur chacune des parties, elle est définie différemment.
	\newcommand{\CaptionFigFWJuNhU}{La fonction de l'exemple~\ref{ExeFHmCLII}.}
	\input{auto/pictures_tex/Fig_FWJuNhU.pstricks}

	L'expression de \( f\) est ici
	\begin{equation}
		f(x,y) =
		\begin{cases}
			xy   & \text{si } x < 0 \text{ et } y > 0       \\
			x-y  & \text{si } x \geq 0 \text{ et } y \geq 0 \\
			x^2y & \text{si } x > 0 \text{ et } y < 0       \\
			x+y  & \text{sinon.}
		\end{cases}
	\end{equation}

	On note que les deux axes forment une zone à problèmes. La zone hors
	des axes est un ouvert sur lequel \( f\) est différentiable car composée
	de polynômes. Analysons chacun des points de la forme \( (a,b)\) dans la
	zone à problèmes (c'est-à-dire si \( ab = 0\)).
	\begin{subproof}

		\spitem[Si \( a = 0\) et \( b > 0\)]
		% -------------------------------------------------------------------------------------------- 
		Un tel point \( (0,b)\) est sur
		l'axe vertical, dans la moitié supérieure. Pour calculer la limite de
		\( f\) en ce point, on peut restreindre notre étude au demi-plan ouvert
		\( y > 0\), ce qui revient à comparer la limite
		\begin{equation*}
			\limite[y>0\\x\geq 0] {(x,y)} {(0,b)} f(x,y) =   \limite[y>0\\x\geq
				0] {(x,y)} {(0,b)} x-y = 0 - b = -b
		\end{equation*}
		avec la limite
		\begin{equation*}
			\limite[y>0\\x<0] {(x,y)} {(0,b)} f(x,y) =   \limite[y>0\\x<0]
			{(x,y)} {(0,b)} xy = 0 b = 0
		\end{equation*}
		qui sont différentes puisque \( b\) est supposé non nul.

		\conclusion \( f\) n'est pas continue en un point du type \( (0,b)\) avec \( b
		> 0\).

		\spitem[Si \( a = 0\) et \( b < 0\)]
		% -------------------------------------------------------------------------------------------- 
		Un tel point \( (0,b)\) est sur
		l'axe vertical, dans la moitié inférieure. Pour calculer la limite de
		\( f\) en ce point, on peut restreindre notre étude au demi-plan ouvert
		\( y < 0\), ce qui revient à comparer la limite
		\begin{equation*}
			\limite[y<0\\x\geq 0] {(x,y)} {(0,b)} f(x,y) =   \limite[y<0\\x\geq
				0] {(x,y)} {(0,b)} x^2 y = 0^2 b = 0
		\end{equation*}
		avec la limite
		\begin{equation*}
			\limite[y<0\\x<0] {(x,y)} {(0,b)} f(x,y) =   \limite[y<0\\x<0]
			{(x,y)} {(0,b)} x+y = 0 + b = b
		\end{equation*}
		qui sont différentes puisque \( b\) est supposé non nul.

		\conclusion \( f\) n'est pas continue en un point du type \( (0,b)\) avec \( b
		< 0\).

		\spitem[Si \( a > 0\) et \( b = 0\)]
		% -------------------------------------------------------------------------------------------- 
		Un tel point \( (a,0)\) est sur
		l'axe horizontal, dans la moitié droite. Pour calculer la limite de
		\( f\) en ce point, on peut restreindre notre étude au demi-plan ouvert
		\( x > 0\), ce qui revient à comparer la limite
		\begin{equation*}
			\limite[x>0\\y \geq 0] {(x,y)} {(a,0)} f(x,y) =   \limite[x>0\\y \geq
				0] {(x,y)} {(a,0)} x-y = a - 0 = a
		\end{equation*}
		avec la limite
		\begin{equation*}
			\limite[x>0\\y < 0] {(x,y)} {(a,0)} f(x,y) =   \limite[x>0\\y < 0]
			{(x,y)} {(a,0)} x^2y = a^2 0 = 0
		\end{equation*}
		qui sont différentes puisque \( a\) est supposé non nul.

		\conclusion \( f\) n'est pas continue en un point du type \( (a,0)\) avec \( a
		> 0\).

		\spitem[Si \( a < 0\) et \( b = 0\)]
		% -------------------------------------------------------------------------------------------- 
		Un tel point \( (a,0)\) est sur
		l'axe horizontal, dans la moitié gauche. Pour calculer la limite de
		\( f\) en ce point, on peut restreindre notre étude au demi-plan ouvert
		\( x < 0\), ce qui revient à comparer la limite
		\begin{equation*}
			\limite[x<0\\y> 0] {(x,y)} {(a,0)} f(x,y) =   \limite[x<0\\y>
				0] {(x,y)} {(a,0)} x y = a 0 = 0
		\end{equation*}
		avec la limite
		\begin{equation*}
			\limite[x<0\\y\leq 0] {(x,y)} {(a,0)} f(x,y) =   \limite[x<0\\y\leq0]
			{(x,y)} {(a,0)} x+y = a + 0 = a
		\end{equation*}
		qui sont différentes puisque \( a\) est supposé non nul.

		\conclusion \( f\) n'est pas continue en un point du type \( (a,0)\) avec \( a
		< 0\).

		\spitem[Si \( a = 0\) et \( b = 0\)]
		% -------------------------------------------------------------------------------------------- 
		Le cas du point \( (0,0)\) est
		particulier, puisque il est adhérent aux quatre composantes du
		domaine où la fonction est définie différemment. Pour étudier la
		continuité, il faut donc étudier quatre limites. Ces limites ont déjà
		été étudiées ci-dessus et valent toutes \( 0\), ce qui prouve la
		continuité de \( f\) en \( (0,0)\).

		En ce qui concerne la différentiabilité, on sait qu'il est nécessaire
		que toutes les dérivées directionnelles existent. Calculons la dérivée
		dans la direction \( (0,1)\) (au point \( (0,0)\))~:
		\begin{equation*}
			\limite[t\neq0] t 0 \frac{f((0,0) + t(0,1)) - f(0,0)}{t} =%
			\limite[t\neq0] t 0 \frac{f(0,t)}{t} = \ldots
		\end{equation*}
		qu'on sépare en deux cas, car \( f(0,t)\) possède une formule différente
		si \( t < 0\) ou si \( t \geq 0\)~:
		\begin{equation*}
			\limite[t\neq0] t 0 \frac{f(0,t)}{t} = %
			\begin{arrowcases}
				\limite[t<0] t 0 \frac{f(0,t)}{t} = \limite[t<0] t 0 \frac{0+t}{t} = 1\\
				\limite[t\geq0] t 0 \frac{f(0,t)}{t} = \limite[t\geq0] t 0
				\frac{0-t}{t} = -1
			\end{arrowcases}
		\end{equation*}
		ce qui prouve que la limite n'existe pas, donc que la dérivée
		directionnelle n'existe pas, et finalement que la fonction n'est pas
		différentiable.

		\conclusion La fonction donnée est continue hors des axes et au point
		\( (0,0)\), mais discontinue partout ailleurs sur les axes. Elle est
		différentiable hors des axes, mais ne l'est pas sur les axes.
	\end{subproof}

\end{example}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Cohérence des dérivées partielles et directionnelle}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Dans la pratique, nous pouvons calculer \( \partial_uf(a)\) pour une direction \( u\) générale, et puis en déduire \( \partial_xf\) et \( \partial_yf\) comme cas particuliers en posant \( u=(1,0)\) et \( u=(0,1)\). Une chose incroyable, mais pourtant possible est qu'il peut arriver que
\begin{equation}
	\frac{ \partial f }{ \partial u }(a)\neq \sum_i\frac{ \partial f }{ \partial x_i }(a)u_i.
\end{equation}
Ceci se produit lorsque \( f\) n'est pas différentiable en \( a\).

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Un candidat dans la définition (marche toujours)}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Lorsqu'une fonction est donnée, un candidat différentielle au point \( (a_1,a_2)\) est souvent assez simple à trouver en un point :
\begin{equation}
	T(u_1,u_2)=\frac{ \partial f }{ \partial x }(a_1,a_2)u_1+\frac{ \partial f }{ \partial y }(a_1,a_2)u_2.
\end{equation}
L'application \( T\) est la candidate différentielle en ce sens que si la différentielle existe, alors elle est égale à \( T\). Ensuite, il faut vérifier si
\begin{equation}        \label{EqLimDefDiff}
	\lim_{(x,y)\to (a_1,a_2)} \frac{f(x,y) - f(a_1,a_2) - T\big( (x,y)-(a_1,a_2) \big)}{\| (x,y)-(a_1,a_2) \|}=0
\end{equation}
ou non. Si oui, alors la différentielle existe et \( df_{(a,b)}(u)=T(u)\), sinon\footnote{y compris si la limite \eqref{EqLimDefDiff} n'existe même pas.}, la différentielle n'existe pas.

Attention : dans la ZAP, les dérivées partielles \( \partial_xf\) et \( \partial_yf\) ne peuvent en général pas être calculées en utilisant les règles de calcul (c'est bien pour ça que la ZAP est une zone à problèmes). Il faut d'office utiliser la définition
\begin{equation}
	\frac{ \partial f }{ \partial x }(a_1,a_2)=\lim_{t\to 0}\frac{ f(a_1+t,a_2)-f(a_1,a_2) }{ t },
\end{equation}
et la définition correspondante pour \( \partial_yf\).

\subsubsection*{Conclusion}
Soient \( f:A\subset \eR^n \rightarrow \eR^m\), et \( a\in \Int(A)\). Si \( f\) est différentiable en \( a\),
\begin{equation}
	(df_a (e_j))_i = d(f_i)_a(e_j) =\frac{\partial f_i}{\partial x_j}(a)= [Jac(f)_{|a}]_{ij}
\end{equation}
et la matrice de l'application linéaire \( df_a\) est la matrice jacobienne \( m\times n\) de \( f\) en \( a\) notée \( Jac(f)_{|a}\).
