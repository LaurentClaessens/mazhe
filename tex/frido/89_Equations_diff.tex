% This is part of Mes notes de mathématique
% Copyright (c) 2008-2009,2011-2015,2018-2019, 2023-2025
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.

Une équation différentielle ordinaire est la recherche de toutes les fonctions définies sur une partie de \( \eR\) satisfaisant à une certaine égalité, faisant intervenir les dérivées de la fonction recherchée.

\begin{definition}
	Si \( I\) est un intervalle de \( \eR\), une fonction sera \defe{dérivable sur $I$}{dérivable!fonction} si elle est dérivable au sens usuel sur l'intérieur de \( I\), et si elle est dérivable à droite (resp. à gauche) sur l'éventuel bord gauche (resp. droit) de \( I\).
\end{definition}

\begin{definition}
	Une \defe{équation différentielle ordinaire d'ordre $n$ sur $I$}{equation@équation!différentielle!ordinaire d'ordre 1} est la recherche d'une fonction \( y : I \to \eR\) dérivable \( n\) fois, satisfaisant à une équation du type
	\begin{equation}\label{eqequadiff}
		F(t, y(t), y^\prime(t), \ldots, y^{n\prime}(t)) = 0 \quad \text{pour tout }t \in I
	\end{equation}
	où \( I\) est un intervalle de \( \eR\) et \begin{math}F : (I \times D) \subset (\eR\times\eR^{n+1})\to \eR\end{math} est une fonction donnée.
\end{definition}

\begin{remark}
	L'équation différentielle~(\ref{eqequadiff}) sera raccourcie sous la forme
	\begin{equation}
		F(t, y, y^\prime, \ldots, y^{n\prime}) = 0
	\end{equation}
	où la dépendance en \( t\) est sous-entendue.
\end{remark}

\begin{example}
	Soit \( f : I \to \eR\) une fonction continue fixée. L'équation différentielle
	\begin{equation}
		y^\prime = f(t)
	\end{equation}
	se ramène à la recherche des primitives de \( f\) sur l'intervalle \( I\).
\end{example}

Le lemme suivant sert de temps en temps.
\begin{lemma}[Lemme de Grönwall]\label{LemuBVozy}
	Soient \( \phi\) et \( \psi\) deux fonctions telles que pour tout \( t\in\mathopen[ t_0 , t_1 \mathclose]\), \( \phi(t)\geq 0\), \( \psi(t)\geq 0\) et
	\begin{equation}
		\phi(t)\leq K +L\int_{t_0}^t\psi(s)\phi(s)ds
	\end{equation}
	où \( K\) et \( L\) sont des constantes positives. Alors
	\begin{equation}
		\phi(t)\leq K\exp\big( L\int_{t_0}^t\psi \big).
	\end{equation}
\end{lemma}
\index{Grönwall (lemme)}
\index{lemme!Grönwall}
%TODO : la preuve.

\begin{lemma}[Lemme de Grönwall\cite{ooBSUCooIKClhZ}]        \label{LEMooUGZGooCczAmKa}
	Si \( u,a,b\in C^0\big( \mathopen[ 0 , T \mathclose],\eR^+ \big)\) sont telles que
	\begin{equation}
		u(t)\leq b(t)+\int_0^ta(s)u(s)ds
	\end{equation}
	pour tout \( t\in \mathopen[ 0 , T \mathclose]\) alors pour tout \( t\in \mathopen[ 0 , T \mathclose]\) nous avons aussi
	\begin{equation}
		u(t)\leq b(t)+\int_0^tb(s)a(s) e^{\int_s^ta(u)du}ds.
	\end{equation}
\end{lemma}
\index{Grönwall (lemme)}
\index{lemme!Grönwall}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Équation homogène, solution particulière}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Voici un petit morceau d'algèbre linéaire. Soient des espaces vectoriels \( V\) et \(W\) ainsi qu'une application linéaire \( D\colon V\to W\). Nous voulons résoudre \( D(u)=v\), c'est-à-dire déterminer l'ensemble
\begin{equation}
	D^{-1}(v)=\{ u\in V\tq Du=v \}.
\end{equation}

\begin{lemma}       \label{LEMooEWUPooXNJMcc}
	Soient des espaces vectoriels \( V\) et \(W\) ainsi qu'une application linéaire \( D\colon V\to W\). Si \( u_P\in V\) satisfait à \( Du_P=v\) alors
	\begin{equation}
		D^{-1}(v)=\ker(D)+u_P.
	\end{equation}
\end{lemma}

\begin{proof}
	Si \( u\in \ker(D)+u_p\) alors \( u=k+u_p\) avec \( Dk=0\), ce qui donne tout de suite \( Du=Dk+Du_P=v\). Donc \( u\in D^{-1}(v)\).

	Dans l'autre sens, si \( u\in D^{-1}(v)\) alors nous pouvons écrire \( u=(u-u_P)+u_P\). Vu que \( u-u_P\in\ker(D)\) nous avons bien \( u\in\ker(D)+u_P\).
\end{proof}

Ce petit lemme explique pourquoi la résolution d'équation différentielles passe par le principe «générale de l'homogène plus particulière de la non-homogène». Cela marche autant pour les équations différentielles ordinaires que pour celles aux dérivées partielles.

\begin{example}
	Considérons l'équation différentielle ordinaire
	\begin{equation}
		y'-y=4.
	\end{equation}
	L'opérateur dont nous parlons est par exemple
	\begin{equation}
		\begin{aligned}
			D\colon & C^{\infty}(\eR)\to  C^{\infty}(\eR) \\
			y       & \mapsto y'-y .
		\end{aligned}
	\end{equation}
	Nous devons résoudre \( Dy=4\) où «\( 4\)»  est l'élément fonction constante égale à \( 4\) dans \(  C^{\infty}(\eR)\). L'ensemble \( \ker(D)\) sont les éléments \( y\in C^{\infty}(\eR)\) tels que \( y'=y\) :
	\begin{equation}
		\ker(D)=\{ t\mapsto K e^{t}\tq K\in \eR \}.
	\end{equation}
	Nous devons trouver un élément quelconque \( y_P\) de \( D^{-1}(4)\). Facile : \( y_P(t)=-4\).

	Au final,
	\begin{equation}
		D^{-1}(4)=\{ t\mapsto K e^{t}-4\tq K\in \eR \}.
	\end{equation}
\end{example}

Dans cet exemple nous avons pris \( V=W= C^{\infty}(\eR)\). Mais souvent nous sommes amenés à considérer des espaces plus subtils, parce qu'il existe simplement pas de solutions dans \(  C^{\infty}\), ou alors parce que beaucoup de solutions n'y sont pas.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Que faire avec \texorpdfstring{\( f(z)dz=g(t)dt\)}{fzdz} ?}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\label{SecFairedzdt}

Dans de nombreux exercices d'équations différentielles, nous tombons sur \( u'=f(t)\), et nous faisons formellement
\begin{equation}
	\begin{aligned}[]
		\frac{ du }{ dt } & =f(t) & \Rightarrow &  & du=f(t)dt,
	\end{aligned}
\end{equation}
et ensuite, il y a la formule un peu magique
\begin{equation}
	u-u_0=\int_{t_0}^tf(t)dt.
\end{equation}
Voyons ce qu'il en est. Tout d'abord, il faut comprendre ce que signifie la formule
\begin{equation}        \label{EqDiffAstufzdz}
	f(z)dz=g(t)dt.
\end{equation}
Il s'agit d'une égalité entre deux formes différentielles sur \( \eR\) où \( z\) est une fonction de \( t\).  Étant donné que \( z\) est une fonction de \( t\), il faut voir \( dz\) comme la différentielle de cette fonction. La différentielle d'une fonction à une variable est donné par la dérivée :
\begin{equation}
	dz_t=z'(t)dt
\end{equation}
Écrire l'équation \eqref{EqDiffAstufzdz} pour chaque \( t\) revient donc à écrire
\begin{equation}
	f\big( z(t) \big)z'(t)dt=g(t)dt
\end{equation}
Cela est une égalité entre deux formes différentielles. Nous avons donc égalité entre les intégrales des formes sur un chemin. Prenons un chemin tout simple de \( t_0\) vers \( t\) :
\begin{equation}
	\int_{t_0}^tf\big( z(t) \big)z'(t)dt=\int_{t_0}^tg(t)dt.
\end{equation}
Dans le premier membre, nous faisons un changement de variable \( \xi=z(t)\), \( d\xi=z'(t)dt\), et nous obtenons
\begin{equation}        \label{EqIntDiffAstuztz}
	\int_{z_0}^{z(t)}f(\xi)d\xi=\int_{t_0}^tg(t)dt.
\end{equation}
où nous avons remplacé la constante \( z(t_0)\) par \( z_0\) dans la borne d'intégration.  Si \( F\) est une primitive de \( f\) et \( G\) une primitive de \( g\), nous avons
\begin{equation}
	F(z)-F(z_0)=G(t)-G(t_0).
\end{equation}
Si aucun problème de Cauchy n'est donné, les constantes \( F(z_0)\) et \( G(t_0)\) sont mises en une seule et nous écrivons la solution
\begin{equation}
	F\big( z(t) \big)=G(t)+C,
\end{equation}
qui est une équation implicite pour \( z(t)\).

Nous trouvons assez souvent le cas simple
\begin{equation}    \label{EqAstfzdzdt}
	f(z)dz=dt.
\end{equation}
En remplaçant \( g(t)=1\) dans \eqref{EqIntDiffAstuztz}, nous trouvons la fameuse
\begin{equation}        \label{Eqttzint}
	t-t_0=\int_{z_0}^zf(z)dz,
\end{equation}
dans laquelle il y a un abus de notation terrible entre le \( z\) de la borne (que les étudiants oublient souvent) et la variable d'intégration \( z\) !!

Le passage de \eqref{EqAstfzdzdt} à \eqref{Eqttzint} sera très souvent utilisé dans le cours de mécanique par exemple.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Équations linéaires du premier ordre}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Une \defe{équation différentielle linéaire}{equation@équation!différentielle!linéaire} est une équation de la forme
\begin{equation}
	y'+u(t)y=v(t).
\end{equation}

\begin{example}     \label{EXooVVLGooPWaHUI}
	Tant qu'il n'y a pas de second membre, c'est facile. Prenons l'exemple suivant :
	\begin{equation}
		y'+2ty=0.
	\end{equation}
	Nous mettons tous les \( t\) d'un côté et tous les \( y\) et \( y'\) de l'autre :
	\begin{equation}
		\frac{ y' }{ y }=-2t,
	\end{equation}
	et puis on intègre sans oublier la constante d'intégration :
	\begin{equation}
		\ln(y)=-t^2+C,
	\end{equation}
	et donc \( y(t)=K e^{-t^2}\).
\end{example}

\begin{example}

	Lorsqu'il y a un second membre, il y a une astuce. Prenons par exemple
	\begin{equation}		\label{EqDiffExLin}
		y'+2ty=4t.
	\end{equation}
	L'astuce est de commencer par résoudre l'équation sans le second membre (l'équation homogène associée). Nous notons \( y_H\) la solution. Ici, la réponse est
	\begin{equation}
		y_H(t)=K e^{-t^2}.
	\end{equation}
	Ensuite le truc est d'essayer de trouver la solution de l'équation \eqref{EqDiffExLin} sous la forme
	\begin{equation}		\label{EqEssaiLin}
		y(t)=K(t) e^{-t^2}.
	\end{equation}
	L'idée est de prendre la même que la solution de l'équation homogène (sans second membre), mais en disant que \( K\) est une fonction. Afin de trouver la fonction \( K\) qui donne la solution, il suffit de remettre l'essai \eqref{EqEssaiLin} dans l'équation \eqref{EqDiffExLin} :
	\begin{equation}
		\underbrace{K' e^{-t^2}-2tK e^{-t^2}}_{y'(t)}+\underbrace{2tK e^{-t^2}}_{2ty(t)}=4t
	\end{equation}
	Les deux termes avec \( K\) se simplifient et il reste
	\begin{equation}
		K'(t)=4t e^{t^2},
	\end{equation}
	ce qui signifie \( K(t)=2 e^{t^2+C}\). Nous avons donc déterminé la fonction qui fait fonctionner l'essai, et la solution à l'équation est
	\begin{equation}
		y(t)=\big( 2 e^{t^2}+C \big) e^{-t^2}=2+C e^{-t^2}.
	\end{equation}
\end{example}

La technique pour résoudre cette équation est de commencer par résoudre l'équation homogène associée. Si \( U(t)\) est une primitive de \( u(t)\), nous avons
\begin{equation}
	\begin{aligned}[]
		y'_H(t)+u(t)y_H(t)   & =0                        \\
		\frac{ y'_H }{ y_H } & =-u(t)                    \\
		\ln(y_H)             & =-U(t)+C                  \\
		y_H(t)               & = e^{-U(t)+C}=K e^{-U(t)}
	\end{aligned}
\end{equation}
où \( K= e^{C}\).

Cela fournit la solution générale de l'équation homogène. Il existe un truc génial qui permet d'en tirer la solution générale du système non homogène. Lorsque nous avons trouvé \( y_H(t)=K e^{-U(t)}\), le symbole \( K\) désigne une constante. La méthode de \defe{variation des constantes}{variation des constantes} consiste à essayer la solution
\begin{equation}		\label{EqEssayVarSctr}
	y(t)=K(t) e^{-U(t)},
\end{equation}
c'est-à-dire à dire que la constante est en réalité une fonction. Afin de trouver quelle fonction \( K(t)\) fait en sorte que l'essai \eqref{EqEssayVarSctr} soit une solution, nous la remplaçons dans l'équation de départ \( y'+uy=v\). Maintenant,
\begin{equation}
	y'(t)=K'(t) e^{-U(t)}-K(t)u(t) e^{-U(t)}.
\end{equation}
En remettant dans l'équation,
\begin{equation}
	y'+uy=K' e^{-U}-Ku e^{-U}+uK e^{-U}=K' e^{-U}=v.
\end{equation}
Notez que les termes en \( K\) se sont miraculeusement simplifiés. Cela est directement dû au fait que \(  e^{-U}\) est solution de l'équation homogène. Nous restons avec l'équation
\begin{equation}
	K'=\frac{ v }{  e^{-U} }
\end{equation}
pour \( K(t)\). La solution générale du problème non homogène est donc finalement donnée par
\begin{equation}
	y(t)=\big( W(t)+C \big) e^{-U(t)}
\end{equation}
si \( W(t)\) est une primitive de \( v(t)e^{U(t)}\).

Tout ceci est un peu heuristique. Nous faisons maintenant quelques théorèmes pour préciser dans quels cas ça fonctionne.

\begin{proposition}[\cite{BIBooKNNSooMIoyOg}]	\label{PROPooFECJooPiqZHR}
	Soit un intervalle \( I\). Soient une application continue \(a \colon I\to \eR  \) et une primitive\footnote{Toute fonction continue sur un intervalle a une primitive, \ref{ThoEXXyooCLwgQg}.} \(A \colon I\to \eR  \).

	Alors l'ensemble des solutions de \( y'+ay=0\) est
	\begin{equation}
		S=\{ x\mapsto \lambda e^{-A(x)} \}_{\lambda\in \eR}.
	\end{equation}
\end{proposition}

\begin{proof}
	En deux parties.
	\begin{subproof}
		\spitem[Les éléments de \( S\) sont des solutions]
		%-----------------------------------------------------------
		Soit \( \lambda\in \eR\), et posons \( y(x)=\lambda e^{-A(x)}\). Dérivons pour le plaisir, en remarquant que \( e^{A(x)}\) est une composée de fonctions \( (\exp\circ A)(x)\) et en nous souvenant de la dérivée de l'exponentielle donnée (par définition) par le théorème \ref{ThoKRYAooAcnTut}. Nous avons
		\begin{equation}
			y'(x)=\lambda\big( -A'(x) \big)e^{-A(x)}=-\lambda a(x)e^{-A(x)}.
		\end{equation}
		Nous avons donc
		\begin{equation}
			y'(x)+a(x)y(x)=-\lambda a(x)e^{-A(x)}+a(x)\lambda e^{-A(x)}=0.
		\end{equation}

		\spitem[Toute solution est dans \( S\)]
		%-----------------------------------------------------------
		Soit une solution \( y\) de \( y'+ay=0.\). Nous posons \( z(x)=y(x)e^{A(x)}\), et nous montrons que \( z'=0\) :
		\begin{subequations}
			\begin{align}
				z'(x) & =y'(x)e^{A(x)}+y(x)A'(x)e^{A(x)}    \\
				      & =e^{A(x)}\big( y'(x)+y(x)a(x) \big) \\
				      & =0
			\end{align}
		\end{subequations}
		La proposition \ref{PROPooKZPZooWjIsWg}\ref{ITEMooYCDQooFvFyEH} nous indique que \( z\) est constante : il existe \( \lambda\in \eR\) tel que \( \lambda=y(x)e^{A(x)}\). Avec ça, nous avons\footnote{Notez l'utilisation de \ref{PROPooVADRooLCLOzP}\ref{ITEMooSCJBooNVJZah}.}
		\begin{equation}
			y(x)=\lambda e^{-A(x)}.
		\end{equation}
	\end{subproof}
\end{proof}

\begin{proposition}[\cite{BIBooGTNUooUYDzIH}]     \label{PROPooZCXQooPQpkdQ}
	Soit un intervalle \( I\). Soient des applications continues \(a,b \colon I\to \eR  \). Nous considérons une primitive \( A\) de \( a\) et une primitive \( W\) de \( e^{A(x)}b(x)\).

	Alors l'ensemble des solutions de \( y'+ay=b\) est
	\begin{equation}
		S=\{ x\mapsto e^{-A(x)}\big( W(x)+C \big) \}_{C\in \eR}
	\end{equation}
\end{proposition}

\begin{proof}
	Je vous laisse le soin de vérifier que tous les éléments de \( S\) sont bien des solutions. Dérivez, et ça ira très bien. Pendant ce temps, je m'occupe des choses sérieuses.

	Nous commençons par poser
	\begin{equation}		\label{EQooXYPGooCFTukc}
		\lambda(x)=y(x)e^{A(x)},
	\end{equation}
	et nous dérivons : \( \lambda'(x)=e^{A(x)}b(x)\). Donc \( \lambda\) est une primitive de \( e^{A(x)}b(x)\). Comme nous avons dit que \( W\) est une primitive, il existe \( C\in \eR\) tel que \( \lambda(x)=W(x)+C\) (corolaire \ref{CorZeroCst}). En remettant ça dans \eqref{EQooXYPGooCFTukc}, nous trouvons le résultat annoncé.
\end{proof}

\begin{proposition}[\cite{BIBooGTNUooUYDzIH}]	\label{PROPooEXEQooUUOizH}
	Soient un intervalle \( I\), et deux fonctions continues \(a,b \colon I\to \eR  \). Soient \( x_0\in I\) et \( y_0\in \eR\). Le problème de Cauchy
	\begin{subequations}
		\begin{numcases}{}
			y'+ay=b\\
			y(x_0)=y_0
		\end{numcases}
	\end{subequations}
	admet une unique solution.
\end{proposition}

\begin{proof}
	En vertu de la proposition \ref{PROPooZCXQooPQpkdQ}, nous essayons sous la forme
	\begin{equation}		\label{EQooGKKDooIsmjTR}
		y(x)=\big( W(x)+C \big)e^{-A(x)}
	\end{equation}
	où \( A\) est une primitive de \( a\) et \( W\) est une primitive de \( e^{A(x)}b(x)\). Nous fixons \( C\) de telle sorte à avoir \( y(x_0)=x_0\). Il s'agit seulement de résoudre
	\begin{equation}
		\big( W(x_0)+C \big)e^{-A(x)}=y_0
	\end{equation}
	pour \( C\). La solution est vite trouvée :
	\begin{equation}		\label{EQooYITWooKlYHti}
		C=y_0e^{A(x)}-W(x_0).
	\end{equation}

	Nous avons prouvé l'unicité : si une solution existe, elle est forcément de la forme \eqref{EQooGKKDooIsmjTR} avec \( C\) donné par \eqref{EQooYITWooKlYHti}.

	Pour l'existence, il suffit de dériver et vérifier.
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Pourquoi la variation des constantes fonctionne toujours ?}
%---------------------------------------------------------------------------------------------------------------------------

Prenons une équation non homogène
\begin{equation}        \label{EqAstNNHomo}
	z'(t)=f(t)z(t)+g(t),
\end{equation}
et supposons avoir une solution de l'homogène associée sous la forme \( z_H(t)=Ch(t)\). Le coup de la variation des constates consiste à essayer une solution pour l'équation non homogène sous la forme\footnote{Je ne sais plus qui a eu l'idée de changer le nom de la constante de \( C\) vers \( K\) au moment de la transformer en fonction, mais c'est une bonne idée.}
\begin{equation}
	z(t)=K(t)h(t).
\end{equation}
Nous injectons cette solution dans l'équation de départ en utilisant le fait que \( z'(t)=K'(t)h(t)+K(t)h'(t)\) :
\begin{equation}
	K'(t)h(t)+K(t)h'(t)=f(t)K(t)h(t)+g(t).
\end{equation}
Le terme \( K(t)h'(t)\) se récrit en utilisant la propriété de définition de \( h\), c'est-à-dire que \( h'(t)=f(t)h(t)\). Nous voyons que les termes ne contenant pas de \( K'\) se simplifient; il reste
\begin{equation}
	K'h=g.
\end{equation}
Cette équation a comme solution
\begin{equation}
	K=\int \frac{ f }{ h }+C.
\end{equation}
J'insiste sur la constante d'intégration ! En réalité, celles et ceux qui auront compris l'équation \eqref{Eqttzint} sauront que \( K\) est donné par
\begin{equation}
	K(t)=\int_{\xi_0}^{t}\frac{ f(\xi) }{ g(\xi) }d\xi
\end{equation}
où \( \xi_0\) joue le rôle de la constante d'intégration.

Quoi qu'il en soit, la solution générale de l'équation non homogène est
\begin{equation}        \label{EqSolVarCosntCool}
	z(t)=K(t)h(t)=\left( \int\frac{ g }{ h }+C \right)h.
\end{equation}
Cette solution comprend deux termes : \( Ch\) qui est solution de l'homogène, et \( \left( \int \frac{ g }{ h } \right)h\) qui est une particulière de l'équation non homogène.

Quelques conclusions :

\begin{enumerate}
	\item
	      Si vous avez encore du \( K\) (et pas que du \( K'\)) dans votre équation qui donne \( K\), c'est que vous n'êtes pas dans le cadre d'une équation de type \eqref{EqAstNNHomo}. Le plus souvent, c'est que vous avez fait une faute de calcul quelque part.

	\item
	      La méthode des variations des constantes n'est pas en contradiction avec le principe de « SGEH+SPENH ». En effet, la SGEP et la SPENH sont toutes deux dans la solution \eqref{EqSolVarCosntCool}.

	\item
	      La variation des constantes peut être vue comme une façon cool de trouver une solution particulière de l'équation non homogène.

	\item
	      La simplification ne se fait que après avoir remplacé \( Kh'\) par \( Kfh\), c'est-à-dire après avoir utilisé le fait que \( z_H\) est solution de l'homogène. Sinon, la simplification n'est pas du tout évidente à priori. Il se peut même que, visuellement, les termes \( Kh'\) et \( Kfh\) ne se ressemblent pas du tout. Un exemple de cela arrivera par exemple dans l'exemple~\ref{ExYCPtxgZ}, pour arriver à l'équation \eqref{EDEqFracII107exoVVprb}.

\end{enumerate}


%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Équations à variables séparées}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\label{Secvarsep}

\begin{definition}	\label{DEFooZHNTooWISQeX}
	Une \defe{équation à variables séparées}{equation@équation!différentielle!variables séparées} est une équation  de la forme
	\begin{equation}		\label{EqDiffSeparee}
		y'(t)=u(t)f\big( y(t) \big)=u(t)(f\circ y)(t).
	\end{equation}
	où \( u\colon I\to \eR\) et \( f\colon J\to \eR\) sont deux fonctions continues données.
\end{definition}

Les propositions~\ref{ProJLykrK} et~\ref{PropOkmXmC} résolvent ce type d'équation, mais avant de voir cela, nous allons donner quelques indications «pratiques».

%---------------------------------------------------------------------------------------------------------------------------
\subsection{La méthode rapide}
%---------------------------------------------------------------------------------------------------------------------------

On peut évidemment mettre tous les \( y\) et \( y'\) d'un côté :
\begin{equation}
	\frac{ y' }{ f(y) }=u(x).
\end{equation}
Une fois que cela est fait, on écrit \( y'=\frac{ dy }{ dx }\), et on envoie le \( dx\) du côté des \( x\) :
\begin{equation}
	\frac{ dy }{ f(y) }=u(x)dx.
\end{equation}
Maintenant il suffit de prendre l'intégrale des deux côtés : comme la position des \( dx\) et \( dy\) l'indiquent, il faut intégrer par rapport à \( y\) d'un côté et par rapport à \( dx\) de l'autre côté.

L'intégrale à gauche est facile : c'est \( \ln(y)\). À droite, par contre, ça dépend tout à fait de \( u\).

%---------------------------------------------------------------------------------------------------------------------------
\subsection{La méthode plus propre}
%---------------------------------------------------------------------------------------------------------------------------

\begin{equation}
	y'(t)=u(t)f\big( y(t) \big).
\end{equation}
Nous considérons \( U\), une primitive de \( u\) sur \( I\) et \( G\), une primitive de \( 1/f\) sur \( J\).  Si \( I'\subseteq I\) et \( y\colon I'\to J\), alors \( y\) est solution de \eqref{EqDiffSeparee} si et seulement si il existe une constante \( C\) telle que
\begin{equation}		\label{EqSolSepThe}
	G\big( y(t) \big)=U(t)+C.
\end{equation}
La recherche des solutions de l'équation différentielle se ramène donc à la recherche de primitives et de solutions d'une équation algébrique (il faut isoler \( y(t)\) dans \eqref{EqSolSepThe}). Réciproquement toute solution régulière de cette dernière relation est solution de l'équation différentielle.

Remarque : lorsque nous cherchons \( U\) et \( G\), nous ne cherchons que \emph{une} primitive. Il ne faut pas considérer des constantes d'intégration à ce niveau.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Les théorèmes}
%---------------------------------------------------------------------------------------------------------------------------

\begin{proposition}     \label{ProJLykrK}
	Soient des intervalles \( I\) et \( J\) de \( \eR\). Nous considérons des fonctions continues \( u\colon I\to \eR\) et \( f\colon J\to \eR\), et nous supposons que \( f\) ne s'annule pas sur \( J\). Soit \( U\), une primitive de \( u\) sur \( I\), et \( G\), une primitive de \( 1/f\) sur \( J\).

	Si \( I'\) est un intervalle, une application \( y\colon I'\to J\) est une solution de
	\begin{equation}		\label{EQooJVCQooGoVPVA}
		y'(t)=u(t)f\big( y(t) \big)
	\end{equation}
	si et seulement si il existe \( C\in \eR\) telle que
	\begin{equation}		\label{EqSoluceEqDiffSep}
		G\big( y(t) \big)=U(t)+C.
	\end{equation}
\end{proposition}


\begin{proof}
	Il s'agit d'utiliser la proposition \ref{PROPooDONLooWthqRR} pour dériver la fonction composée \( G\circ y\). La dérivée de \( G\big( y(t) \big)\) est
	\begin{equation}		\label{EQooDVWQooPQZyUM}
		(G\circ y)'(t)=G'\big( y(t) \big)y'(t)=\frac{ y'(t) }{ f\big( y(t) \big) }.
	\end{equation}

	\begin{subproof}
		\spitem[\( \Rightarrow\)]
		%-----------------------------------------------------------
		Soit \( y\) une solution de \( y'(t)=u(t)f\big( y(t) \big)\). Alors \( y\) vérifie
		\begin{equation}
			\frac{ y'(t) }{ f\big( y(t) \big) }=u(t).
		\end{equation}
		Nous avons vu dans \eqref{EQooDVWQooPQZyUM} qu'une primitive du membre de gauche est \( G\circ y\). Une primitive du membre de droite est \( U\). Le corolaire \ref{CorZeroCst} dit qu'il existe une constante \( C\) telle que \( G\circ y=u+C\).

		\spitem[\( \Leftarrow\)]
		%-----------------------------------------------------------
		Il suffit de dériver des deux côtés.
	\end{subproof}
\end{proof}


Cette proposition dit que toutes les solutions qui ne s'annulent jamais sur un intervalle ont la forme \( G\big( y(t) \big)=U(t)+C\) et peuvent donc être trouvées en calculant des primitives.

La formule \eqref{EqSoluceEqDiffSep} peut être obtenue de la façon heuristique suivante, en écrivant \( y'=dy/dt\), et en passant le \( dt\) à droite. Nous trouvons successivement
\begin{equation}
	\begin{aligned}[]
		y'                      & =u(t)f(y)    \\
		dy                      & =u(t)f(y)dt  \\
		\frac{ dy }{ f(y) }     & =u(t)dt      \\
		\int\frac{ dy }{ f(y) } & =\int u(t)dt \\
		G(y)                    & =U(t)+C.
	\end{aligned}
\end{equation}


\begin{proposition}     \label{PROPooIGWTooULXrKI}
	Soient \( 0<r<R\) ainsi que \( \alpha\in \eR\). Une fonction \( y\colon \mathopen] r , R \mathclose[\to \eR\) est une solution de
	\begin{equation}        \label{EQooBQCTooTtShNw}
		y'(x)=\frac{ \alpha }{ x }y(x),
	\end{equation}
	si et seulement si il existe \( K >0\) tel que
	\begin{equation}
		y(x)=Kx^{\alpha}.
	\end{equation}
\end{proposition}

\begin{proof}
	En deux parties.
	\begin{subproof}
		\spitem[\( \Rightarrow\)]
		Vu que le logarithme est une primitive de la fonction inverse (proposition \ref{PROPooPDJLooXphpEM}), nous pouvons utiliser la proposition \ref{ProJLykrK} avec les fonctions \( U(x)=\alpha\ln(x)\) et \( G(t)=\ln(t)\). Si \( y\) est une solution de \eqref{EQooBQCTooTtShNw}, alors il existe \( C\in \eR\) tel que
		\begin{equation}
			\ln\big( y(x) \big)=\alpha\ln(x)+C
		\end{equation}
		pour tout \( x\in\mathopen] r , R \mathclose[\). En prenant l'exponentielle des deux côtés, et en utilisant le fait que \( \alpha\ln(x)=\ln(x^{\alpha})\),
		\begin{equation}
			y(x)= e^{C} e^{\ln(x^{\alpha})}
		\end{equation}
		En posant \( K=e^C\), nous avons un \( K>0\) tel que \( y(x)=Kx^{\alpha}\).
		\spitem[\( \Leftarrow\)]
		Il suffit de dériver en utilisant la proposition \ref{PROPooKIASooGngEDh}. Pas de soucis de domaine parce que nous ne considérons que \( x\in \mathopen] r , R \mathclose[\).
	\end{subproof}
\end{proof}

\begin{proposition}[Unicité\cite{MonCerveau,BIBooARJKooLuqoxW}] \label{PropOkmXmC}
	Soient des intervalles \( I\) et \( J\) dans \( \eR\). Nous considérons
	\begin{enumerate}
		\item
		      Une application continue \(u \colon I\to \eR  \),
		\item
		      Une application continue \(f \colon J\to \eR  \) ne s'annulant pas.
		\item
		      \( t_0\in I\) et \( y_0\in J\).
		\item
		      La primitive \( U\) de \( u\) telle que \( U(t_0)=0\).
		\item
		      Une primitive \( G\) de \( 1/f\).
	\end{enumerate}
	Alors
	\begin{enumerate}
		\item
		      L'application \(G \colon J\to \eR  \) est injective.
		\item
		      Si \(y \colon I'\to J  \) est une solution de
		      \begin{subequations}		\label{SUBEQooAQXMooEnniZW}
			      \begin{numcases}{}
				      y'(t)=u(t)f\big( y(t) \big)		\label{EQooJIACooFbjdHb}\\
				      y(t_0)=y_0
			      \end{numcases}
		      \end{subequations}
	\end{enumerate}
	où \( I'\) est un intervalle de \( I\) contenant \( t_0\), alors
	\begin{equation}
		y(t)=G^{-1}\big( U(t)+G(y_0) \big).
	\end{equation}
\end{proposition}


\begin{proof}
	L'application \( G\) vérifie \( G'=1/f\) pour une certaine constante \( C\). Vu que \( f\) ne s'annule pas, elle est de signe constante et donc \( G'\) est soit partout strictement croissante, soit partout strictement décroissante (proposition \ref{PropGFkZMwD}). L'application \( G\) est donc injective et inversible.

	Soit une solution \(y \colon I\to J  \) de \eqref{SUBEQooAQXMooEnniZW}. Juste pour le plaisir nous dérivons l'application \( G\circ y\).
	\begin{subequations}
		\begin{align}
			(G\circ y)'(t) & =G'\big( y(t) \big)y'(t)                                                                   \\
			               & =\frac{ y'(t) }{ f\big( y(t) \big) }                                                       \\
			               & =\frac{ u(t)f\big( y(t) \big) }{ f\big( y(t) \big) } & \text{eq. \eqref{EQooJIACooFbjdHb}} \\
			               & = u(t)                                               & \text{pcq. }  f\neq 0               \\
			               & =U'(t).
		\end{align}
	\end{subequations}
	Vu que \( (G\circ y)'=U'\), il existe un nombre \( C\in \eR\) tel que \( (G\circ y)(t)=U(t)+C\), et donc tel que
	\begin{equation}		\label{EQooNCTIooYgGObD}
		y(t)=G^{-1}\big( U(t)+C \big).
	\end{equation}
	Nous savons de plus que \( y\) vérifie \( y(t_0)=y_0\). En calculant \eqref{EQooNCTIooYgGObD} en \( t_0\) et en tenant compte de \( U(t_0)=0\) nous trouvons \( y_0=G^{-1}(C)\) et donc \( C=G(y_0)\). Nous avons montré que si \( y\) est une solution du problème \eqref{SUBEQooAQXMooEnniZW}, alors
	\begin{equation}
		y(t)=G^{-1}\big( U(t)+G(y_0) \big).
	\end{equation}
\end{proof}


\begin{example} \label{ExYCPtxgZ}
	Résoudre l'équation différentielle
	\begin{equation}
		y-\cos(t)y'=\cos(t)\big(1-\sin(t)\big)y^2.
	\end{equation}

	La fonction \( y=0\) est solution. En posant \( z=1/y\), nous trouvons l'équation
	\begin{equation}		\label{EDEqII107EqpourZ}
		z+\cos(t)z'=\cos(t)\big(1-\sin(t)\big)
	\end{equation}
	à laquelle \( z\) doit satisfaire. L'équation homogène est
	\begin{equation}
		z_H'=-\frac{ z_H }{ \cos(t) }.
	\end{equation}
	Ceci est une équation à variables séparées que nous résolvons en suivant les méthodes données plus haut : nous posons
	\begin{equation}		\label{EqEDufUGII107}
		\begin{aligned}[]
			u(t) & =\frac{1}{ \cos(t) },                                                                               \\
			f(z) & =-z,                                                                                                \\
			U(t) & =\ln\left[ \tan\left( \frac{ \pi }{ 4 }+\frac{ t }{ 2 } \right) \right] & \text{(voir formulaire)}, \\
			G(z) & =\ln\left( \frac{1}{ z } \right).
		\end{aligned}
	\end{equation}
	La solution \( z_H\) est donnée par l'équation
	\begin{equation}
		\ln\left( \frac{1}{ z } \right)=\ln\left[ K\tan\left( \frac{ \pi }{ 4 }+\frac{ t }{ 2 } \right) \right],
	\end{equation}
	c'est-à-dire
	\begin{equation}
		z_H(t)=\frac{ K }{ \tan\left( \frac{ \pi }{ 4 }+\frac{ t }{ 2 } \right) }.
	\end{equation}
	Nous appliquons maintenant la méthode de variation des constantes sur cette solution afin de trouver la solution générale de l'équation \eqref{EDEqII107EqpourZ}. En utilisant la règle de Leibniz, \( z'=K'z_H+Kz'_H\), nous trouvons
	\begin{equation}
		\frac{ K }{ \tan\left( \frac{ \pi }{ 4 }+\frac{ t }{ 2 } \right) }+\cos(t)\left( \frac{ K' }{  \tan\left( \frac{ \pi }{ 4 }+\frac{ t }{ 2 } \right) }-\frac{ K }{ 2\sin^2 \left( \frac{ \pi }{ 4 }+\frac{ t }{ 2 } \right)  } \right)=\cos(t)\big( 1-\sin(t) \big).
	\end{equation}
	Malgré leurs apparences, les deux termes en \( K\) se simplifient. En effet, en vertu de l'équation \( z_H'=\frac{ -z_H }{ \cos(t) }\), nous avons
	\begin{equation}
		\frac{ -K }{ 2\sin^2\left( \frac{ \pi }{ 4 }+\frac{ t }{ 2 } \right)}=\frac{ -K }{ \cos(t)\tan\left( \frac{ \pi }{ 4 }+\frac{ t }{ 2 } \right) }.
	\end{equation}
	Le travail de voir quel est le lien entre \( \sin^2\left( \frac{ \pi }{ 4 }+\frac{ t }{ 2 } \right)\), \( \tan\left( \frac{ \pi }{ 4 }+\frac{ t }{ 2 } \right)\) et \( \cos(t)\) est en réalité fait dans votre formulaire au moment où vous l'avez utilisé pour intégrer \( u\) pour obtenir le \( U(t)\) de \eqref{EqEDufUGII107}.

	Après cette simplification durement méritée, nous trouvons l'équation suivante pour \( K(t)\) :
	\begin{equation}		\label{EDEqFracII107exoVVprb}
		\frac{ K' }{ \tan\left( \frac{ \pi }{ 4 }+\frac{ t }{ 2 } \right) }=1-\sin(t).
	\end{equation}
	Résoudre cela revient à trouver la primitive de
	\begin{equation}
		\big( 1-\sin(t) \big) \tan\left( \frac{ \pi }{ 4 }+\frac{ t }{ 2 } \right),
	\end{equation}
	ce qui est relativement compliqué. La réponse est
	\begin{equation}
		\begin{aligned}[]
			K(t) & =\ln \left(\sin \left({{2\,x+\pi}\over{4}}\right)+1\right)+\ln  \left(\sin \left({{2\,x+\pi}\over{4}}\right)-1\right) \\
			     & \quad+2\,\ln \sec  \left({{2\,x+\pi}\over{4}}\right)+2\,\sin ^2\left({{2\,x+\pi}\over{4 }}\right)
		\end{aligned}
	\end{equation}
	Nous pouvons un peu simplifier en utilisant le fait que \( \ln(a+b)+\ln(a-b)=\ln(a^2-b^2)\) :
	\begin{equation}
		\begin{aligned}[]
			K(t)	=\ln\left(-\cos^2 \left({{2\,x+\pi}\over{4}}\right)\right)
			+2\,\ln \sec  \left({{2\,x+\pi}\over{4}}\right)+2\,\sin ^2\left({{2\,x+\pi}\over{4 }}\right).
		\end{aligned}
	\end{equation}
	Il me semble toutefois qu'il faudrait prendre des valeurs absolues pour les logarithmes.

\end{example}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Équations linéaires d'ordre supérieur}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Équations et systèmes linéaires à coefficients constants}
%---------------------------------------------------------------------------------------------------------------------------
\label{SUBSECooMXLVooALNtge}


Nous regardons l'équation
\begin{equation}	\label{EqLinConstantRappels}
	y^{(n)} + a_1 y^{(n-1)} + \cdots + a_{n-1} y^\prime + a_n y = v(t)
\end{equation}
où les coefficients \( a_k\) sont maintenant des constantes. Il faut commencer par résoudre le polynôme caractéristique
\begin{equation}
	r^n+a_1 r^{n-1}+\cdots +a_n=0.
\end{equation}
Si \( \lambda_1,\ldots,\lambda_k\) sont les solutions avec multiplicité \( \mu_1,\ldots,\mu_k\), alors le \defe{système fondamental}{système!fondamental} de solutions linéairement indépendantes est l'ensemble suivant de solutions à l'équation homogène :
\begin{equation}
	\begin{aligned}[]
		e^{\lambda_1 t},t e^{\lambda_1 t}, & \ldots,t^{\mu_1-1} e^{\lambda_1  t}  \\
		                                   & \vdots                               \\
		e^{\lambda_k t},t e^{\lambda_k t}, & \ldots,t^{\mu_k-1} e^{\lambda_k  t}.
	\end{aligned}
\end{equation}
Nous notons \( y_i\) ces solutions. La solution générale de l'équation homogène est donc donnée par
\begin{equation}
	y_H=\sum_i c_i y_i.
\end{equation}
Afin de trouver la solution générale de l'équation non homogène, nous appliquons la méthode de variation des constantes, en imposant les \( n-1\) conditions
\begin{equation}		\label{EqVarCstSubtil}
	\sum_{i=1}^n c'_i(t)y_i^{(l)}(t)=0
\end{equation}
avec \( l=0,\ldots,n-2\). Ces conditions plus l'équation de départ \eqref{EqLinConstantRappels} forment un système de \( n\) équations différentielles pour les \( n\) fonctions inconnues \( c_i(t)\).

Cette condition peut paraitre mystérieuse. Il est cependant encore possible de travailler sans poser la condition \eqref{EqVarCstSubtil} en suivant la recette, en calculant des wronskiens\footnote{Définition \ref{DEFooISLFooPUcCIK}.}. Des exemples sont donnés dans les exercices sur le second ordre.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Si les coefficients ne sont pas constants ?}
%---------------------------------------------------------------------------------------------------------------------------

Une équation différentielle linéaire d'ordre \( n\) sur \( I\) est une équation de la forme
\begin{equation}	\label{EqLinRappels}
	y^{(n)} + u_1(t) y^{(n-1)} + \cdots + u_{n-1}(t) y^\prime + u_n(t) y = v(t)
\end{equation}
où \( v\) et \( u_k\) sont des fonctions continues fixées de \( I\) vers \( \eR\).

Pour résoudre cette équation, il faut commencer par résoudre l'équation homogène correspondante (c'est-à-dire celle que l'on obtient en posant \( v(t)=0\)). Ensuite, nous trouvons la solution de l'équation \eqref{EqLinRappels} en appliquant la méthode de la \defe{variation des constantes}{variation des constantes}.

Donnons un exemple du pourquoi la méthode de variations des constantes est efficace. Soit l'équation
\begin{equation}		\label{EqDiffExempleVarCst}
	u'+f(t)u=g(t),
\end{equation}
et disons que \( u_H\) est une solution de l'équation homogène. La méthode de variations des constantes consiste à poser \( u(t)=K(t)u_H(t)\), et donc \( u'(t)=K'u_H+Ku_H'\). En remettant dans l'équation de départ,
\begin{equation}
	K'u_H+Ku_H'+fKu_H=g.
\end{equation}
La somme \( Ku_H'+fKu_H\) est nulle, par définition de \( u_H\). Par conséquent, il ne reste que
\begin{equation}
	K'=\frac{ g(t) }{ u_H }.
\end{equation}
Lorsqu'on utilise la méthode de variation des constantes, nous trouvons toujours une simplification « miraculeuse ».

Dans l'immédiat, nous ne considérons que le cas où les \( u_i\) sont des constantes. Le cas où les \( u_i\) deviennent des fonctions de \( t\) sera vu plus tard.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Système d'équations linéaires}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%---------------------------------------------------------------------------------------------------------------------------
\subsection{La magie de l'exponentielle\ldots}
%---------------------------------------------------------------------------------------------------------------------------
\label{SUBSECooMDKIooKaaKlZ}

Prenons l'équation différentielle très simple
\begin{equation}
	y'=ay.
\end{equation}
La solution est \( y(t)=A e^{at}\). Et si on a la donnée de Cauchy \( y(t_0)=y_0\), alors
\begin{equation}		\label{EqytexposimpleProp}
	y(t)=A e^{at} e^{-at_0} e^{at_0}= e^{a(t-t_0)}y(t_0).
\end{equation}
Donc on a le facteur multiplicatif \(  e^{a(t-t_0)}\) qui sert à faire passer de \( y(0)\) à \( y(t)\). C'est un peu un opérateur d'évolution. Ce qui fait la magie  de l'exponentielle, c'est son développement en série
\begin{equation}		\label{EqDevExpoMag}
	e^x=1+x+\frac{ x^2 }{ 2 }+\frac{ x^3 }{ 3! }+\frac{ x^4 }{ 4! }+\ldots
\end{equation}
qui est tel que chaque terme est la dérivée du terme suivant.

Maintenant, si on a un système
\begin{equation}
	\bar y'=A\bar y,
\end{equation}
il n'est pas du tout étonnant d'avoir comme solution \( \bar y(t)= e^{At}\) où l'exponentielle de la matrice est définie exactement par la série \eqref{EqDevExpoMag}. C'est un peu longuet, mais dans le cours, c'est effectivement ce qui est prouvé. La matrice résolvante \( R(t,t_0)\colon \bar y_0\to \bar y(t;t_0,y_0)\) est donnée par
\begin{equation}
	R(t,t_0)= e^{(t-t_0)A},
\end{equation}
exactement comme dans l'équation \eqref{EqytexposimpleProp}.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{\ldots{} mais la difficulté}
%---------------------------------------------------------------------------------------------------------------------------

Maintenant, il est suffisant de calculer des exponentielles de matrices pour résoudre des systèmes. Hélas, il est en général très difficile de calculer des exponentielles. Tu peux essayer de prouver les deux suivantes :
\begin{equation}
	\begin{aligned}[]
		A=\begin{pmatrix}
			  0  & a \\
			  -a & 0
		  \end{pmatrix} & \leadsto  e^{A}=\begin{pmatrix}
			                                  \cos(a)  & \sin(a) \\
			                                  -\sin(a) & \cos(a)
		                                  \end{pmatrix}  \\
		S=\begin{pmatrix}
			  0 & a \\
			  a & 0
		  \end{pmatrix} & \leadsto  e^{S}=\begin{pmatrix}
			                                  \cosh(a) & \sinh(a) \\
			                                  \sinh(a) & \cosh(a)
		                                  \end{pmatrix}.
	\end{aligned}
\end{equation}
La première, tu vas la revoir si tu fais de la géométrie différentielle ou de la mécanique quantique : l'algèbre de Lie du groupe des matrices orthogonales de déterminant \( 1\) est l'algèbre des matrices antisymétriques.

La seconde se retrouve en relativité parce que \( e^S\) est la matrice qui préserve \( x^2-y^2\), tout comme \( e^A\) préserve \( x^2+y^2\). Quelques mots sur l'uutilisation des fonctions hyperboliques en relativité dans~\ref{SUBSUBSECooZVHLooYwuhAj}.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{La recette}
%---------------------------------------------------------------------------------------------------------------------------

Afin d'éviter de devoir calculer explicitement des exponentielles de matrices, nous faisons appel à toutes sortes de trucs, dont la forme de Jordan. Le résultat final est la méthode suivante. Soit le système homogène
\begin{equation}
	\bar y'=A\bar y.
\end{equation}

\let\oldTheEnumi\theenumi
\renewcommand{\theenumi}{\arabic{enumi}.}
\begin{enumerate}

	\item
	      D'abord, nous calculons les valeurs propres de \( A\).

	\item
	      Ensuite les vecteurs propres.

	\item\label{ItemRapSystDc}
	      Une bonne valeur propre, c'est une valeur propre dont l'espace propre a une dimension égale à sa multiplicité. C'est-à-dire que si \( \lambda\) est de multiplicité \( m\), alors on a, dans les bons cas,  \( m\) vecteur propres linéairement indépendants.

	      Dans ce cas, si \( v_1,\ldots,v_m\) sont les vecteurs, alors on a les solutions linéairement indépendantes suivantes :
	      \begin{equation}
		      \begin{pmatrix}
			      \vdots \\
			      v_1    \\
			      \vdots
		      \end{pmatrix} e^{\lambda t},\ldots,
		      \begin{pmatrix}
			      \vdots \\
			      v_m    \\
			      \vdots
		      \end{pmatrix} e^{\lambda t}.
	      \end{equation}
	      Pour chaque bonne valeur propre, ça nous fait un tel paquet de solutions linéairement indépendantes.

	\item
	      Si \( \lambda\) n'est pas une bonne valeur propre, alors les choses se compliquent. Mettons que \( \lambda\) ait \( k\) vecteurs propres en moins que sa multiplicité. Dans ce cas, il faut chercher des solutions sous la forme
	      \begin{equation}		\label{EqEqRapAsTestPolk}
		      \begin{pmatrix}
			      a^{(k)}_1t^k+\cdots+a_1^{(0)} \\
			      \vdots                        \\
			      a^{(k)}_nt^k+\cdots+a_n^{(0)}
		      \end{pmatrix} e^{\lambda t}.
	      \end{equation}
	      C'est-à-dire qu'on prend comme coefficient de \(  e^{\lambda t}\), un vecteur de polynômes de degré \( k\). Il faut mettre cela dans l'équation de départ pour voir quelles sont les contraintes sur les constantes \( a_i^{(j)}\) introduites.

	\item\label{ItemRapSystDe}
	      Nous avons un cas particulier du cas précédent. Si \( \lambda\) est une valeur propre de multiplicité \( m\) qui n'a que un seul vecteur propre \( v\), alors il faut chercher des polynômes de degré \( m-1\), et on peut directement fixer le coefficient de \( t^{m-1}\), ce sera l'unique vecteur propre :
	      \begin{equation}
		      \left[
		      \begin{pmatrix}
			      \vdots \\
			      v      \\
			      \vdots
		      \end{pmatrix}+
		      \begin{pmatrix}
			      a_1^{(m-2)} \\
			      \vdots      \\
			      a_n^{(m-2)}
		      \end{pmatrix}t^{m-2}+\ldots
		      \right] e^{\lambda t}.
	      \end{equation}
	      Cela économise quelques calculs par rapport à poser brutalement \eqref{EqEqRapAsTestPolk}.

\end{enumerate}
\let\theenumi\oldTheEnumi

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Système d'équations linéaires avec matrice constante}
%---------------------------------------------------------------------------------------------------------------------------

Nous considérons l'équation différentielle
\begin{equation}    \label{EqOOsXZJ}
	y'(t)=Ay(t)
\end{equation}
pour la fonction \( y\colon \eR\to \eR^n\) et \( A\) est une matrice ne dépendant pas de \( t\). Nous supposons que \( A\) est diagonalisable pour les vecteurs propres \( v_i\) et les valeurs propres \( \lambda_i\) correspondantes.

La matrice
\begin{equation}
	R(t)=\big[  e^{\lambda_1t}v_1\, \ldots  e^{\lambda_nt}v_n \big]
\end{equation}
est la \defe{matrice résolvante}{résolvante} du système. Alors la solution du système \eqref{EqOOsXZJ} pour la condition initiale \( y(0)=y_0\) est
\begin{equation}
	y(t)=R(t)y_0.
\end{equation}
En effet
\begin{equation}
	AR(t)=\left[  A\begin{pmatrix}
			\uparrow          \\
			e^{\lambda_1t}v_1 \\
			\downarrow
		\end{pmatrix}\,\ldots\,A\begin{pmatrix}
			\uparrow          \\
			e^{\lambda_nt}v_n \\
			\downarrow
		\end{pmatrix}\right]=R'(t).
\end{equation}
Par conséquent \( y'(t)=R'(t)y_0=AR(t)y_0=Ay(t)\).

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Système d'équations linéaires avec matrice non constante}
%---------------------------------------------------------------------------------------------------------------------------

\begin{theorem}[\cite{WNxwuWc}]     \label{ThoNYEXqxO}
	Soient \( I\) un intervalle de \( \eR\) et \( M\colon \eR\to \aL(\eR^n,\eR^n)\) une fonction. Si les composantes \( M_{ij}\) sont des fonctions continues sur \( I\) alors :
	\begin{enumerate}
		\item
		      pour tout \( t_0\in I\) et pour tout \( y_0\in R^n\) le système
		      \begin{equation}    \label{EqKYDrMgu}
			      y'(t)=M(t)y(t)
		      \end{equation}
		      admet une unique solution maximale définie sur \( I\) telle que \( y(t_0)=y_0\);
		\item
		      l'ensemble des solutions de l'équation \eqref{EqKYDrMgu} sur \( I\) est un espace vectoriel de dimension~\( n\).
	\end{enumerate}
\end{theorem}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Réduction de l'ordre}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\label{SecWGdleRM}

Afin de diminuer l'ordre d'une équation dans laquelle le paramètre n'apparaît pas, il y a deux changements de variables très utiles. Le premier, le plus simple, est simplement de poser \( z(t)=y'(t)\), ce qui donne
\begin{equation}
	z'(t)=y''(t).
\end{equation}
Le second, \emph{qui n'est pas le même}, est \( z\big( y(t) \big)=y'(t)\), qui entraîne
\begin{equation}
	y''(t)=z'\big( y(t) \big)y'(t)=z'\big( y(t) \big)z\big( y(t) \big).
\end{equation}
Dans ce second cas, il faut également changer de variable, et utiliser \( y(t)\) comme variable au lieu de \( t\).


Si ça ne marche pas, il faut suivre la procédure ci-après.

Nous supposons avoir une équation différentielle d'ordre \( p\) dans laquelle \( y^{(p)}\) est isolée des autres dérivées :
\begin{equation}    \label{EqHDeVQgn}
	y^{(p)}(t)=f\big( t,y(t),y'(t),\ldots, y^{(p-1)}(t) \big)
\end{equation}
où \( f\) est une fonction \( f\colon \eR\times \eR^p\to \eR\), et la fonction cherchée est \( y\colon \eR\to \eR\).

La méthode proposée ici consiste à transformer cette équation d'ordre \( p\) en un système d'équations d'ordre \( 1\). Pour cela nous posons
\begin{equation}
	\begin{aligned}
		F\colon \eR\times \eR^p & \to \eR^p                   \\
		(t,x)                   & \mapsto \begin{pmatrix}
			                                  x_2    \\
			                                  \vdots \\
			                                  x_p    \\
			                                  f(t,x_1,\ldots, x_p)
		                                  \end{pmatrix}.
	\end{aligned}
\end{equation}

Nous considérons alors l'équation différentielle
\begin{equation}    \label{EqDVFdMNi}
	Y'(t)=F\big( t,Y(t) \big).
\end{equation}
pour \( Y\colon \eR\to  \eR^p\). La fonction \( y=Y_1\) résout l'équation \eqref{EqHDeVQgn} si et seulement si la fonction \( Y\) résout l'équation \eqref{EqDVFdMNi}.

De plus si l'équation \eqref{EqHDeVQgn} est donnée avec les conditions initiales \( y^{(k)}=a_k\) (\( k=0,\ldots, p-1\)) alors l'équation \eqref{EqDVFdMNi} vient avec les conditions initiales
\begin{equation}
	Y(t_0)=\begin{pmatrix}
		a_0    \\
		\vdots \\
		a_{p-1}
	\end{pmatrix},
\end{equation}
c'est-à-dire \( Y(t_0)=A_0\) avec \( A_0\in \eR^p\).

Le théorème de Cauchy-Lipschitz~\ref{ThokUUlgU} nous donne existence et unicité locale de la solution au système~\ref{EqDVFdMNi}. Lorsque le système est linéaire, c'est-à-dire sous la forme \( Y'(t)=M(t)Y(t)\), alors il y a mieux : le théorème~\ref{ThoNYEXqxO}.

\begin{example}     \label{EXooSHMMooHVfsMB}
	Nous considérons l'équation différentielle
	\begin{subequations}
		\begin{numcases}{}
			-u''(t)-u(t)=1\\
			u(0)=a_0\in \eR\\
			u'(0)=a_1\in \eR,
		\end{numcases}
	\end{subequations}
	et nous voulons montrer que ce système accepte une unique solution. Vu que l'équation différentielle se présente sous la forme \( u''=f(t,u)\) avec \( f(t,u)=-1-u\) nous posons
	\begin{equation}
		\begin{aligned}
			F\colon \eR\times \eR^2 & \to \eR^2              \\
			(t,x)                   & \mapsto \begin{pmatrix}
				                                  x_2 \\
				                                  -1-x_1
			                                  \end{pmatrix},
		\end{aligned}
	\end{equation}
	et nous considérons l'équation différentielle
	\begin{equation}
		Y'=F(t,Y)
	\end{equation}
	pour la fonction \( Y\colon \eR\to \eR^2\). La fonction \( F\) est lipschitzienne (et même globalement) par rapport à \( Y \). En effet,
	\begin{equation}
		\| F(x)-F(y) \|^2=(x_2-y_2)^2+(x_1-y_1)^2=\| x-y \|^2.
	\end{equation}
	Le théorème de Cauchy-Lipschitz ~\ref{ThokUUlgU} s'applique et en posant \( Y_0=(a_0,a_1)\), il existe une unique solution à l'équation \( Y'=F(t,Y)\) vérifiant \( Y(0)=Y_0\). Nous notons \( t\mapsto Y(t)\) cette solution.

	En quoi cela nous aide ? Nous posons \( u(t)=Y_1(t)\). Alors
	\begin{equation}
		u'(t)=Y_1'(t)=F_1'(t,Y)=Y_2(t).
	\end{equation}
	En dérivant encore,
	\begin{equation}
		u''(t)=Y_2'(t)=F_2'(t,Y)=-1-Y_1(t)=-1-u(t),
	\end{equation}
	ce qu'il fallait. La fonction \( t\mapsto Y_1(t)\) est solution de notre équation de départ. Quid des conditions initiales ? Vu que \( u=Y_1\) et \( u'=Y_2\) nous avons\footnote{Dans les équations suivantes, il faut faire attention aux notations : \( Y_0\) est le vecteur \( Y_0\), tandis que \( Y_1\) est la première composante de la fonction \( Y\).}
	\begin{equation}
		u(0)=Y_1(0)=(Y_0)_1=a_0
	\end{equation}
	et
	\begin{equation}
		u'(0)=(Y_0)_2=a_1.
	\end{equation}
	Toutes les prescriptions sont respectées.

	Si vous voulez vraiment résoudre cette équation, il faudra plus de travail. D'abord résoudre l'équation homogène associée, c'est-à-dire l'équation caractéristique \( r^2+1=0\), ce qui va donner
	\begin{equation}
		u_H(t)=A e^{it}+B  e^{-it},
	\end{equation}
	et ensuite faire le coup de la variation des constantes pour déterminer la solution générale du problème non homogène.
\end{example}

\begin{example}     \label{EXooJNOMooYqUwTZ}
	Nous reprenons l'équation différentielle
	\begin{equation}        \label{EQooGUYPooOUStii}
		-u''(t)-u(t)=1.
	\end{equation}
	Nous avons déjà vu dans l'exemple~\ref{EXooSHMMooHVfsMB} que cette équation avait une solution unique pour toute condition initiale. Cette fois nous voulons étudier les solutions lorsque nous imposons les conditions aux limites \( u(0)=u(\pi)=0\). Nous allons voir qu'il n'y a pas de telles solutions.

	Pour ce faire, soit une solution \( u\). D'abord \( u''\) existant, la fonction \( u\) est de classe au moins \( C^1\). Mais \( u''=-1-u\), donc \( u''\) est également \( C^1\), ce qui donne la régularité \( C^3\) pour \( u\). En continuant ainsi nous trouvons que \( u\) est de classe \(   C^{\infty}\).

	Le truc est de considérer la fonction \( v(t)=\sin(t)\) qui vérifie l'équation différentielle
	\begin{subequations}
		\begin{numcases}{}
			-v''-v=0\\
			v(0)=0\\
			v'(0)=1.
		\end{numcases}
	\end{subequations}
	Nous calculons le produit scalaire sur \( L^2\big( \mathopen] 0 , \pi \mathclose[ \big)\) de \eqref{EQooGUYPooOUStii} avec \( v\):
	\begin{equation}        \label{EQooQWGEooFbsVzq}
		\langle u'', v\rangle +\langle u, v\rangle =-\langle v, 1\rangle .
	\end{equation}
	Le calcul de \( \langle v, 1\rangle \) est simplement l'intégrale de \( \sin(t)\) pour \( t\) allant de \( 0\) à \( \pi\), c'est-à-dire \( \langle v, 1\rangle =2\). Vu que \( u\) et \( v\) sont toutes deux des fonctions qui s'annulent en \( 0\) et en \( \pi\) nous pouvons faire des intégrations par partie les yeux fermés et exprimer \( \langle u'', v\rangle \) sans dérivées sur \( u\) :
	\begin{equation}
		\langle u'', v\rangle =-\langle u', v'\rangle =\langle u, v''\rangle =-\langle u, v\rangle
	\end{equation}
	où la dernière égalité n'est autre que le fait que \( v=\sin\), donc \( v''=-v\). Le membre de gauche de \eqref{EQooQWGEooFbsVzq} vaut donc zéro alors que celui de droite vaut \( -2\).

	Nous concluons que le problème aux limites posé n'admet pas de solutions.
\end{example}
