% This is part of Mes notes de mathématique
% Copyright (c) 2012-2013, 2019, 2022- 2023
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Processus de Poisson}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\label{SecHxbtzQ}

\begin{definition}[processus de comptage]
	Un \defe{processus de comptage}{processus de comptage} est une famille de variables aléatoires \( \{ N_t\colon \Omega\to \eR \}_{t\in \eR^+}\) telles que
	\begin{enumerate}
		\item
		      \( N_0(\omega)=0\) pour tout \( \omega\in \Omega\).
		\item
		      Pour tout \( t\in \eR^+\) et pour tout \( \omega\in \Omega\), \( N_t(\omega)\in \eN\).
		\item
		      Pour chaque \( \omega\in \Omega\), la fonction \( t\mapsto N_t(\omega)\) est croissante.
	\end{enumerate}
\end{definition}

\begin{definition}[processus de Poisson\cite{BIBooMECWooHQJweh}]        \label{DEFooWDXDooRGCtXL}
	Un \defe{processus de Poisson}{processus de Poisson} d'intensité \( \lambda\) est un processus de comptage \( (N_t)_{t\in \eR^+}\) tel que
	\begin{enumerate}
		\item
		      Pour tout choix de \( 0\leq t_1<\ldots < t_m\), les variables aléatoires \( N_{t_i}-N_{t_{i-1}}\) sont indépendantes\footnote{Ceci demande en particulier que l'ensemble \( \Omega\) soit assez grand pour contenir une infinité non dénombrable de variables aléatoires indépendantes.}.
		\item
		      Pour tout \( (s,t)\in \eR^2\), la variable aléatoire \( N_{s+t}-N_s\) suit une loi de Poisson\footnote{Définition \ref{DEFooUWKHooUFKlcr}.} de paramètre \( \lambda t\).
	\end{enumerate}
\end{definition}

\begin{proposition}[\cite{BIBooMECWooHQJweh}]   \label{PROPooGMBBooCIkVCB}
	Soit un processus de Poisson \( (N_t)\). Pour tout \( t\geq 0\) nous avons
	\begin{equation}
		\lim_{h\to 0^+} P\big( N_{t+h}-N_t\geq 1 \big)=0.
	\end{equation}
\end{proposition}

\begin{lemma}[\cite{BIBooORZFooWKgLCH}]     \label{LEMooLNIZooDWUvRN}
	Si les variables aléatoires \( X_1,\ldots, X_n\) sont indépendantes et identiquement distribuées de densité \( f\), alors le vecteur \( (X_1,\ldots, X_n)\) est à densité et sa densité est
	\begin{equation}
		g(x_1,\ldots, x_n)=n!\prod_{i=1}^nf(x_i)\mtu_{\{ x_1<\ldots<x_n \}}.
	\end{equation}
\end{lemma}

\begin{lemma}[\cite{MonCerveau}]        \label{LEMooXTVNooSBnnAd}
	Soit un processus de Poisson \(  \{ N_t\colon \Omega\to \eN \}_{t\in \eR^+}  \) d'intensité \( \lambda\). Pour chaque \( n\in \eN\) nous posons
	\begin{equation}
		\begin{aligned}
			T_n\colon \Omega & \to \eR                                         \\
			\omega           & \mapsto \inf\{ t\geq 0\tq N_t(\omega)\geq n \}.
		\end{aligned}
	\end{equation}
	Soit \( h>0\).
	\begin{enumerate}
		\item   \label{ITEMooXVSQooSQmIUv}
		      Il existe une partie de mesure nulle\quext{Cette subtilité est manquante dans \cite{BIBooPSSIooEliTXx,BIBooHQDOooIrIVoO,BIBooGKIYooYLIyyf}. Plus généralement, je ne l'ai vue nulle part. Si vous savez démontrer que les événements \( T_n\leq h\) et \( N_h\geq n\) sont égaux, dites-le moi.} \( Z\in \Omega\) telle que \( \{ T_n\leq h \}\subset \{ N_h\geq n \}\cup Z\).
		\item       \label{ITEMooIPKCooIfjUzS}
		      Nous avons \( \{ N_h\geq n \}\subset \{ T_n\leq h \}\).
		\item
		      Au final,
		      \begin{equation}
			      P(T_n\leq h)=P(N_h\geq n).
		      \end{equation}
	\end{enumerate}
\end{lemma}

\begin{proof}
	En plusieurs parties
	\begin{subproof}
		\spitem[\( \{ T_n\leq h \}\subset \{ N_n\geq n \}\cup Z\)]
		% -------------------------------------------------------------------------------------------- 
		Soit \( \omega\in\{ T_n\leq h \}\). Cela signifie que
		\begin{equation}
			\inf\{ t\geq 0\tq N_t(\omega)\geq n \}\leq h.
		\end{equation}
		Si \( T_n(\omega)<h\), alors \( N_h(\omega)\geq n\), et le point est démontré.

		Nous prouvons maintenant que \(  Z=\{ T_n=h \}\cap \{ N_h\leq n \}\) est de mesure nulle. Soient \( \omega\in Z\) ainsi que \( \epsilon>0\). Vu que \( T_n(\omega)=h\), nous avons \( N_{h+\epsilon}(\omega)\geq n\). Donc, pour \( \omega\in Z\) nous avons
		\begin{equation}
			N_{h+\epsilon}(\omega)-N_h(\omega)\geq 1.
		\end{equation}
		En posant \( Z_{\epsilon}=\{ N_{h+\epsilon}-N_h\geq 1 \}\), nous avons donc \( Z\subset Z_{\epsilon}\) pour tout \( \epsilon\). Nous avons alors, pour tout \( \epsilon\), que \( P(Z)\leq P(Z_{\epsilon})\). Mais la proposition \ref{PROPooGMBBooCIkVCB} nous indique que \( \lim_{\epsilon\to 0}P(Z_{\epsilon})=0\). Donc \( P(Z)=0\).
		\spitem[\( \{ N_h\geq n \}\subset \{ T_n\leq h \}   \)]
		% -------------------------------------------------------------------------------------------- 
		Soit \( \omega\in \Omega\) satisfaisant \( N_h(\omega)\geq n\). C'est direct parce que si \( N_h(\omega)\geq n\), alors
		\begin{equation}
			T_n(\omega)=\inf\{ y\geq 0\tq N_t(\omega)\geq n \}\leq h.
		\end{equation}
		\spitem[Les probabilités]
		% -------------------------------------------------------------------------------------------- 
		Le point \ref{ITEMooXVSQooSQmIUv} donne
		\begin{equation}
			P(T_n\leq h)\leq P(N_h\geq n)+P(Z)=P(N_h\geq n),
		\end{equation}
		le point \ref{ITEMooIPKCooIfjUzS} donne \( P(N_h\leq n)\leq P(T_n\leq h)\). Au final, nous avons l'égalité des probabilités.
	\end{subproof}
\end{proof}

\begin{lemma}[\cite{BIBooGKIYooYLIyyf}]     \label{LEMooJHMTooQWvOaI}
	Soient \( \lambda>0\) et \( t>0\). Nous posons
	\begin{equation}
		I_n=\int_0^t\lambda e^{-\lambda x}\frac{ (\lambda x)^{n-1} }{ (n-1)! }dx.
	\end{equation}
	Alors
	\begin{equation}
		I_{n+1}=I_n- e^{-\lambda t}\frac{ (\lambda t)^n }{ n! }.
	\end{equation}
\end{lemma}

\begin{proof}
	Nous intégrons \( I_{n+1}\) par partie en posant \( u(x)=x^n\) et \( v'(x)=\lambda e^{-\lambda x}\); \( u'(x)=nx^{n-1}\), \( v(x)=- e^{-\lambda x}\). Cela donne
	\begin{subequations}
		\begin{align}
			I_{n+1} & =\frac{ \lambda^n }{ n! }\int_0^tv'(x)u(x)dx                                                                              \\
			        & =\frac{ \lambda^n }{ n! }\left[ -x^n e^{-\lambda x} \right]_0^t+\frac{ \lambda^n }{ n! }\int_0^tnx^{n-1} e^{-\lambda x}dx \\
			        & =-\frac{ (\lambda t)^n }{ n! } e^{-\lambda t}+I_n
		\end{align}
	\end{subequations}
\end{proof}

\begin{lemma}[\cite{MonCerveau}]
	Soit un processus de Poisson \(  \{ N_t\colon \Omega\to \eN \}_{t\in \eR^+}  \) d'intensité \( \lambda\). Pour chaque \( n\in \eN\) nous posons
	\begin{equation}
		\begin{aligned}
			T_n\colon \Omega & \to \eR                                         \\
			\omega           & \mapsto \inf\{ t\geq 0\tq N_t(\omega)\geq n \}.
		\end{aligned}
	\end{equation}
	Soit \( t\geq 0\). Pour tout \( n\) nous avons
	\begin{equation}    \label{EQooRHQLooVxFfjV}
		P(T_n\leq t)=\int_0^t\lambda  e^{-\lambda x}\frac{ (\lambda x)^{n-1} }{ (n-1)! }dx.
	\end{equation}
\end{lemma}

\begin{proof}
	Nous y allons par récurrence sur \( n\). D'abord pour \( n=0\) nous savons que \( T_0=0\), donc
	\begin{equation}        \label{EQooNCMMooHnvIpQ}
		P(N_n=0)=P(T_0\leq t)-P(T_1\leq t).
	\end{equation}
	Nous savons que \( N_{s+t}-N_s\) suit une loi de Poisson de paramètre \( \lambda t\). En particulier avec \( s=0\), nous voyons que \( N_t\) suit une loi de Poisson de paramètre \( \lambda t\). Donc \( P(N_t=0)= e^{-\lambda t}\) (définition \ref{DEFooUWKHooUFKlcr}).

	L'équation \ref{EQooNCMMooHnvIpQ} donne donc \(  e^{-\lambda t}=1-P(T_1\leq t)\). Par ailleurs, pour \( n=1\), l'intégrale \eqref{EQooRHQLooVxFfjV} est facile à calculer et donne bien \( 1- e^{-\lambda t}\).

	Pour la récurrence, en reprenant la notation du lemme \ref{LEMooJHMTooQWvOaI}, nous supposons que \( P(T_n\leq t)=I_n\), et nous prouvons que \( P(T_{n+1}\leq t)=I_{n+1}\). Pour cela nous repartons de
	\begin{equation}
		P(N_t=n)=P(T_n\leq t)-P(T_{n+1}\leq t),
	\end{equation}
	et nous substituons \( P(N_t=n)= e^{-\lambda t}(\lambda t)^n/n!\) ainsi que \( P(T_n\leq t)=I_n\). Il reste
	\begin{equation}
		P(T_{n+1}\leq t)=I_n- e^{-\lambda t}\frac{ (\lambda t)^n }{ n! }.
	\end{equation}
	Et le lemme \ref{LEMooJHMTooQWvOaI} nous indique que le tout est égal à \( I_{n+1}\).
\end{proof}

Voici un théorème donnant des propriétés d'un processus de Poisson. Une réciproque partielle est donnée dans la proposition \ref{PropGMntiy}.
\begin{theorem}[\cite{BIBooRYROooNrCDGy,BIBooMECWooHQJweh, MonCerveau}]     \label{THOooYRIMooSREVEO}
	Soit un processus de Poisson \(  \{ N_t\colon \Omega\to \eN \}_{t\in \eR^+}  \) d'intensité \( \lambda\). Pour chaque \( n\in \eN\) nous posons
	\begin{equation}
		\begin{aligned}
			T_n\colon \Omega & \to \eR                                         \\
			\omega           & \mapsto \inf\{ t\geq 0\tq N_t(\omega)\geq n \}.
		\end{aligned}
	\end{equation}
	et \( S_k=T_k-T_{k-1}\).

	%TODOooINVAooKSCVwr Il faut encore prouver les points ITEMooSLWOooRjYhBA, ITEMooGBIXooSjXpsx, ITEMooUTTWooOUhkZh, ITEMooDXZFooXkklhG

	Alors
	\begin{enumerate}
		\item       \label{ITEMooSLWOooRjYhBA}
		      \( T_n\) est une variable aléatoire.
		\item   \label{ITEMooHGXTooOdonXa}
		      Pour tout \( n\), la variable aléatoire \( (T_1,\ldots, T_n)\) a pour densité la fonction
		      \begin{equation}
			      \begin{aligned}
				      g\colon \eR^n     & \to \eR                                                                \\
				      (x_1,\ldots, x_n) & \mapsto \mtu_{0\leq x_1\leq \ldots\leq x_n}\lambda^n e^{-\lambda x_n}.
			      \end{aligned}
		      \end{equation}
		\item       \label{ITEMooGBIXooSjXpsx}
		      Les variables aléatoires \( S_i\) sont à densité.
		\item       \label{ITEMooUTTWooOUhkZh}
		      La variable aléatoire \( (S_1,\ldots, S_n)\) est à densité.
		\item       \label{ITEMooUZGFooAbCvvG}
		      \( (S_n)\) est une suite de variables aléatoires indépendantes et identiquement distribuées de loi exponentielle\footnote{Définition \ref{DEFooTSFNooULWNHY}.} \( \dE(\lambda)\).
		\item   \label{ITEMooDXZFooXkklhG}
		      La variable aléatoire \( T_n\) suit la loi de densité
		      \begin{equation}
			      \begin{aligned}
				      f_n\colon \eR & \to \eR                                                                                 \\
				      s             & \mapsto \begin{cases}
					                              \frac{ \lambda }{ (n-1)! } e^{-\lambda s}(\lambda s)^{n-1} & \text{si } s\geq 0 \\
					                              0                                                          & \text{sinon. }
				                              \end{cases} \\
			      \end{aligned}
		      \end{equation}
	\end{enumerate}
\end{theorem}

\begin{proof}
	En plusieurs parties.
	\begin{center}
		Pour \ref{ITEMooSLWOooRjYhBA}
	\end{center}
	% -------------------------------------------------------------------
	\begin{center}
		Pour \ref{ITEMooHGXTooOdonXa}
	\end{center}
	Soient des nombres \( a_i\) et \( b_i\) tels que
	\begin{equation}
		0<a_1<b_1<a_2<\ldots<a_n<b_n.
	\end{equation}
	Pour éviter les petits effets de bord, nous supposons que \( n>2\). Nous considérons les événements
	\begin{equation}
		A_n=\bigcap_{i=1}^n\{ T_i\in\mathopen] a_i , b_i \mathclose] \}
	\end{equation}
	et
	\begin{equation}
		B_n=\bigcap_{i=1}^{n-1}\{ N_{b_i}-N_{a_i}=1 \}\cap\bigcap_{i=1}^{n-1}\{ N_{a_{i+1}}-N_{b_i}=0 \}\cap\{ N_{b_n}-N_{a_n}\geq 1 \}\cap\{ N_{a_1}=0 \},
	\end{equation}
	et nous allons prouver qu'il existe des parties \( Y\) et \( Z\) de \( \Omega\) telles que\quext{Je suis impressionné à quel point cette subtilité est absente de \cite{BIBooMECWooHQJweh}. Soit il y a un truc macroscopique qui m'échappe, soit il y a un gros trou dans les livres sur lesquels est basé \cite{BIBooMECWooHQJweh}, soit il y a quelque chose que je ne comprends pas.}
	\begin{subequations}
		\begin{numcases}{}
			A_n\subset B_n\cup Y\\
			B_n\subset A_n\cup Z\\
			P(Y)=P(Z)=0.
		\end{numcases}
	\end{subequations}
	Courage.

	\begin{subproof}
		\spitem[Quelques valeurs au bord dans \( A_n\)]
		% -------------------------------------------------------------------------------------------- 
		Soit \( \omega\in A_n\).
		\begin{subproof}
			\spitem[Si \( i<n\)]
			Nous montrons que si \( i<n\), alors
			\begin{subequations}        \label{SYSooCWKCooLtrVhn}
				\begin{numcases}{}
					N_{a_i}(\omega)=i-1\\
					N_{b_i}(\omega)\in\{ i-1, i \}.
				\end{numcases}
			\end{subequations}
			Pour cela, rien de tel qu'une récurrence. D'abord
			\begin{equation}
				T_1(\omega)=\inf\{ t\geq 0\tq N_t(\omega)\geq 1 \}\in \mathopen] a_1 , b_1 \mathclose].
			\end{equation}
			Donc \( T_1(\omega)>a_1\) et nous déduisons que \( N_{a_1}(\omega)=0\). De la même manière\footnote{Nous utilisons le fait que \( n>2\) pour être sûr; mais je crois que ce n'est pas nécessaire.},
			\begin{equation}
				T_2(\omega)=\inf\{ t\geq 0\tq N_t(\omega)\geq 2 \}\in \mathopen] a_2 , b_2 \mathclose].
			\end{equation}
			En particulier \( T_2(\omega)>a_2>b_1\) et nous avons \( N_{b_1}(\omega)<2\). Donc \( N_{b_1}\in\{ 0,1 \}\).

			Soit \( i<n-1\), et supposons que \eqref{SYSooCWKCooLtrVhn} soit valide. Nous avons \( T_i(\omega)\leq b_i\), et donc \( N_{b_i+h}(\omega)\geq i\) pour tout \( h>0\). En particulier \( N_{a_{i+1}}(\omega)\geq i\). Mais \( T_{i+1}(\omega)>a_{i+1}\). Donc \( N_{a_{i+1}}(\omega)<i+1\). Nous en déduisons que \( N_{a_{i+1}}(\omega)=i\).


			Comme \( i+1<n\) nous pouvons encore écrire
			\begin{equation}
				T_{i+2}(\omega)>a_{i+2}>b_{i+1},
			\end{equation}
			donc \( N_{b_{i+1}}(\omega)<i+2\). Vu que \( N_{b_{i+1}}(\omega)\geq N_{a_{i+1}}(\omega)=i\), nous avons \( N_{b_{i+1}}(\omega)\in \{ i,i+1 \}\).
			\spitem[Pour \( i=n\)]
			% -------------------------------------------------------------------------------------------- 
			De la même manière, nous avons \( N_{a_n}<n\), et \( T_{n-1}(\omega)<a_n\). Nous en déduisons \( N_{a_n}(\omega)\geq n-1\) et donc \( N_{a_n}=n-1\).

			Nous avons aussi \( N_{b_n}(\omega)\geq n-1\) et, vu que \( T_n(\omega)\in \mathopen] a_n , b_n \mathclose]\), nous avons \( N_{b_n+h}(\omega)\geq n\) pour tout \( h>0\).
		\end{subproof}
		\spitem[Une partie de mesure nulle]
		% -------------------------------------------------------------------------------------------- 
		Pour \( i=1,\ldots, n\), nous posons \( Z_i=\{ N_{b_i}=i-1 \}\). Ensuite nous définissons \( Z=\bigcup_{i=1}^nZ_i\). Nous démontrons que \( P(Z\cap A_n)=0\). Si \( \omega\in Z\cap A_n\), alors \( N_{b_i}(\omega)=i-1\) et \( N_{b_i+h}(\omega)\geq i\) pour tout \( h>0\). Donc
		\begin{equation}
			Z_i\cap A_n\subset\{ N_{b_i+h}-N_{b_i}\geq 1 \}.
		\end{equation}
		Donc
		\begin{equation}
			P(Z_i\cap A_n)\leq P\big( \{ N_{b_i+h}-N_{b_i}\geq 1 \} \big).
		\end{equation}
		En prenant la limite \( h\to 0^+\), la proposition \ref{PROPooGMBBooCIkVCB} fait que
		\begin{equation}
			P(Z_i\cap A_n)=0.
		\end{equation}
		Nous en déduisons que \( P(Z\cap A_n)=0\).

		\spitem[\( A_n\subset B_n\cup Z\)]
		% --------------------------------------------------------------------------------------------
		Soit \( \omega\in A_n\). Nous devons montrer que si \( \omega\notin Z\), alors \( \omega\in B_n\), c'est à dire
		\begin{enumerate}
			\item
			      $ N_{b_i}(\omega)-N_{a_i}(\omega)=1 $ pour \( i=1,\ldots, n-1\),
			\item
			      $N_{a_{i+1}}(\omega)-N_{b_i}(\omega)=0$ pour \( i=1,\ldots, n-1\),
			\item

			      $N_{b_n}(\omega)-N_{a_n}(\omega)\geq 1$
			\item
			      $N_{a_1}(\omega)=0$
		\end{enumerate}

		Si \( i\leq n-1\), alors \( N_{a_i}(\omega)=i-1\) et \( N_{b_i}(\omega)\in \{ i-1,i \}\). Mais si \( \omega\) n'est pas dans \( Z\), alors \( N_{b_i}(\omega)=i\). Dans ce cas, nous avons bien \( \omega\in\{ N_{b_i}-N_{a_i}=1 \}\).

		De même si \( \omega\) est dans \( A_n\) mais pas dans \( Z\), il vérifie \( N_{a_{i+1}}(\omega)=i= N_{b_i}(\omega)=i\).

		Pour \( i=n\), nous avons \( N_{a_n}(\omega)=n-1\) et \( N_{b_n}(\omega)\geq n-1\). Et encore une fois, si \( \omega\) n'est pas dans \( Z\), alors \( N_{a_n}(\omega)-N_{b_n}(\omega)\geq 1\).

		Enfin pour \( \omega\in A_n\), nous avons \( T_1(\omega)=\inf\{ t\geq 0\tq N_t(\omega)\geq 1 \}>a_1\). Donc \( N_{a_1}(\omega)=0\).

		Nous avons fini de prouver que \( A_n\subset B_n\cup Z\).
		\spitem[\( P(A_n)\leq P(B_n)\)]
		% -------------------------------------------------------------------------------------------- 
		En utilisant le lemme \ref{LemPMprYuC}\ref{ITEMooLEGKooWnYmlf}, et \ref{ITEMooABPYooFQEzqE}, nous avons
		\begin{equation}        \label{EQooGLVAooGGSZYn}
			P(A_n)\leq P(B_n\cup Z)\leq P(B_n)+P(Z)=P(B_n).
		\end{equation}
		\spitem[Quelques valeurs au bord pour \( B_n\)]
		% -------------------------------------------------------------------------------------------- 
		Soit \( \omega\in B_n\). Nous avons \( N_{a_1}(\omega)=0\). Donc
		\begin{equation}
			T_1(\omega)=\inf\{  t\geq 0\tq N_t(\omega)\geq 1 \}\geq a_1.
		\end{equation}
		De même nous prouvons les valeurs suivantes. Pour \( i<n\) nous avons :
		\begin{subequations}
			\begin{numcases}{}
				N_{a_i}(\omega)=i-1\\
				N_{b_i}(\omega)=i
			\end{numcases}
		\end{subequations}
		et pour \( i=n\) nous avons
		\begin{subequations}
			\begin{numcases}{}
				N_{a_n}(\omega)=n-1\\
				N_{b_n}(\omega)\geq n.
			\end{numcases}
		\end{subequations}
		Nous avons donc l'appartenance
		\begin{equation}        \label{EQooVYVJooHEshGE}
			T_i(\omega)\in\mathopen[ a_i , b_i \mathclose]
		\end{equation}
		pour tout \( i\leq n\).

		Cela n'est pas suffisant pour dire que \( \omega\in A_n\) parce que la possibilité \( T_i(\omega)=a_i\) n'est pas exclue.
		\spitem[Une partie de mesure nulle]
		% -------------------------------------------------------------------------------------------- 
		Nous posons \( Y_i=\{ \omega\in \Omega\tq T_i(\omega)=a_i \}\), et nous prouvons que \( P(Y_i\cap B_n)=0\). Pour \( \omega\in Y_i\cap B_n\) nous avons \( N_{a_i}(\omega)=i-1\) et \( N_{a_i+h}(\omega)=i\) pour tout \( h>0\). Donc pour tout \( h>0\) nous avons
		\begin{equation}
			Y_i\cap B_n\subset\{ N_{a_i+h}-N_{a_i}\geq 1 \},
		\end{equation}
		et donc
		\begin{equation}
			P(Y_i\cap B_n)\leq P\big( N_{a_{i+h}}-N_{a_i}\geq 1 \big).
		\end{equation}
		En utilisant à nouveau le lemme \ref{PROPooGMBBooCIkVCB}, nous trouvons \( P(Y_i\cap B_n)=0\).

		Nous posons \( Y=\bigcup_{i=1}^nY_i\).
		\spitem[\( P(B_n)\leq P(A_n)\)]
		% -------------------------------------------------------------------------------------------- 
		Si \( \omega\in B_n\), nous avons \eqref{EQooVYVJooHEshGE} : \( T_i(\omega)\in \mathopen[ a_i , b_i \mathclose]\). Par définition de \( Y\), si \( \omega\in B_n\setminus Y\) nous avons
		\begin{equation}
			T_i(\omega)\in \mathopen] a_i , b_i \mathclose].
		\end{equation}
		Autrement dit, \( B_n\setminus Y\subset A_n\) et donc \( B_n\subset A_n\cup Y\). Nous en déduisons que
		\begin{equation}    \label{EQooWQZPooPBjPsG}
			P(B_n)\leq P(A_n\cup Y)\leq P(A_n)+P(Y)=P(A_n).
		\end{equation}
		\spitem[\( P(A_n)=P(B_n)\)]
		% -------------------------------------------------------------------------------------------- 
		En mettant ensemble \eqref{EQooGLVAooGGSZYn} et \eqref{EQooWQZPooPBjPsG} nous avons
		\begin{equation}
			P(A_n)=P(B_n).
		\end{equation}
	\end{subproof}
	Calculons la probabilité de \( B_n\). Vu que \( N_0=0\), l'événement \( N_{a_i}=0\) peut être écrit \( N_{a_i}-N_0=0\). Donc \( B_n\) peut être écrit comme intersection d'incréments indépendants. Nous pouvons donc écrire \( P(A_n)\) comme un produit :
	\begin{equation}
		P(A_n)=\prod_{i=1}^{n-1}P(N_{b_i}-N_{a_i}=1)\times\prod_{i=1}^{n-1}P(N_{a_{i+1}}-N_{b_i}=0)\times P(N_{b_n}-N_{a_n}\geq 1)\times P(N_{a_1}=0).
	\end{equation}
	En posant \( l_i=b_i-a_i\) et \( \delta_i=a_{i+1}-b_i\) et en utilisant la formule \eqref{EQooLGLUooLXohWe} pour
	\begin{equation}
		P(N_{s+t}-N_s=k)= e^{-\lambda t}\frac{ (\lambda t)^k }{ k! },
	\end{equation}
	nous trouvons
	\begin{equation}
		P(A_n)=\prod_{i=1}^{n-1}(\lambda l_i) e^{-\lambda l_i}\times \prod_{i=1}^{n-1} e^{-\lambda \delta_i}\times  e^{-\lambda a_1}(1- e^{-\lambda l_n}).
	\end{equation}
	Note : pour le dernier nous avons posé \( X=N_{b_n}-N_{a_n}\) qui suit une loi exponentielle de paramètre \( \lambda l_n\) et nous avons dit $P(X\geq 1)=1-P(X=0)=1- e^{\lambda l_n}$. Remarquez que \( l_i+\delta_i=a_{i+1}-a_i\); en regroupant les exponentielles, nous avons une somme téléscopique; au final
	\begin{equation}
		P(A_n)=\lambda^{n-1} e^{-\lambda a_n}(1- e^{-\lambda l_n})\prod_{i=1}^{n-1}(l_i).
	\end{equation}

	Pour le plaisir d'ajouter des notations, nous posons \( I_n=\mathopen] a_1 , b_1 \mathclose]\times \ldots\times\mathopen] a_n , b_n \mathclose]\). Cela permet d'écrire
	\begin{equation}
		A_n=\{ (T_1,\ldots,T_n)\in I_n \}
	\end{equation}
	et nous incite à calculer \( \int_{I_n}g\). Pour alléger le calcul suivant, notez que
	\begin{equation}	\label{EQooFXPWooRDBkUE}
		\int_a^be^{-\lambda t}dt=\left[  -\frac{1}{ \lambda}e^{-\lambda t}  \right]_a^b=\frac{1}{ \lambda}e^{-\lambda a}\big( 1-e^{-\lambda(b-a)} \big).
	\end{equation}
	Ensuite nous calculons pour de vrai :
	\begin{subequations}
		\begin{align}
			\int_{I_n}g(x_1,\ldots, x_n) & =\int_{a_1}^{b_1}\ldots\int_{a_n}^{b_n}\mtu_{x_1\leq \ldots\leq x_n}\lambda^n e^{-\lambda x_n}\,dx_1\ldots dx_n                                                 \\
			                             & =\int_{a_1}^{b_1}\ldots\int_{a_n}^{b_n}\lambda^n e^{-\lambda x_n}\,dx_1\ldots dx_n                              & \text{cf. justif.}\label{SUBEQooPMLZooJhEjds} \\
			                             & =\big( \prod_{i=1}^{n-1}l_i \big)\int_{a_n}^{b_n}\lambda^ne^{-\lambda x_n}dx_n                                                                                  \\
			                             & =\big( \prod_{i=1}^{n-1}l_i \big)\lambda^n\frac{1}{ \lambda}e^{-\lambda a_n}\big(1- e^{-\lambda(b_a-a_n)} \big) & \text{eq. \eqref{EQooFXPWooRDBkUE}}           \\
			                             & =\big( \prod_{i=1}^{n-1}l_i \big)\lambda^{n-1}e^{-\lambda a_n}\big(1- e^{-\lambda l_n} \big)                                                                    \\
			                             & =P(A_n)                                                                                                                                                         \\
			                             & =P\big( (T_1,\ldots, T_n)\in I_n \big).
		\end{align}
	\end{subequations}
	Justifications:
	\begin{itemize}
		\item Pour \eqref{SUBEQooPMLZooJhEjds}. Vu que nous avons choisi \( a_1<b_1<\ldots<a_n<b_n\), nous avons toujours \( \mtu_{0\leq x_1\leq\ldots\leq x_n}=1\). La fonction à intégrer ne dépend pas de \( x_1,\ldots,x_{n-1}\).
		      Les intégrales sur \( x_1,\ldots, x_{n-1}\) sont immédiates, et nous avons
	\end{itemize}
	Nous savons que les \( T_i\) sont à valeurs dans \( \eR^+\). Donc sur les pavés \( N\) contenant des coordonnées négatives, nous avons \( P\big( (T_1,\ldots, T_n)\in N \big)=0 \). Heureusement nous avons aussi \( \int_Ng(x)dx=0\).

	En prenant tous les pavés \( I_n\) ainsi que tous ceux avec des coordonnées négatives, nous engendrons les boréliens. Le lemme \ref{LEMooIVIWooUUVStW} conclut que la fonction \( g\) proposée est une densité pour \( (T_1,\ldots, T_n)\).

	% -----------------------------------------------------------------------------------

	\begin{center}
		Pour \ref{ITEMooGBIXooSjXpsx}
	\end{center}
	% -----------------------------------------------------------------------------------

	\begin{center}
		Pour \ref{ITEMooUTTWooOUhkZh}
	\end{center}

	% -----------------------------------------------------------------------------------


	\begin{center}
		Pour \ref{ITEMooUZGFooAbCvvG}
	\end{center}
	\begin{subproof}
		\spitem[Densité pour \( (S_1,\ldots, S_n)\)]
		% -------------------------------------------------------------------------------------------- 


		Le point \ref{ITEMooUTTWooOUhkZh} nous indique que \( (S_1,\ldots, S_n)\) est à densité. Nous notons \( h\colon \eR^n\to \eR\) sa densité. Soit une application borélienne \( f\colon \eR^n\to \eR\). En posant
		\begin{equation}
			\begin{aligned}
				m\colon \eR^n     & \to \eR^n                                   \\
				(t_1,\ldots, t_n) & \mapsto (t_1, t_2-t_1,\ldots, t_n-t_{n-1}),
			\end{aligned}
		\end{equation}
		nous avons
		\begin{subequations}
			\begin{align}
				E\big( f(S_1,\ldots, S_n) \big) & =E\big( f(T_1,T_2-T_1,\ldots, T_n-T_{n-1}) \big)                                       \\
				                                & =E\big( (f\circ m)(T_1,\ldots, T_n) \big)                                              \\
				                                & =\int_{\eR^n}(f\circ m)(x)g(x)dx       \label{SUBEQooGLXSooMcZeSr}                     \\
				                                & =\int_{\eR^n}(f\circ m\circ \phi)(x)(g\circ \phi)(x)dx     \label{SUBEQooFRNHooGtSNph} \\
				                                & =\int_{\eR^n}f(x)(g\circ \phi)(x)dx        \label{SUBEQooETUFooIYIOOO}                 \\
			\end{align}
		\end{subequations}
		Justifications.
		\begin{itemize}
			\item Pour \eqref{SUBEQooGLXSooMcZeSr}, c'est le lemme \ref{LEMooYVJAooXUkRTh}\ref{ITEMooKZHAooKQQmno}.
			\item Pour \eqref{SUBEQooFRNHooGtSNph}, nous effectuons le changement de variables\footnote{Formule \eqref{EQooLYAWooTArAZR}.} pour la bijection linéaire
			      \begin{equation}
				      \begin{aligned}
					      \phi\colon \eR^n  & \to \eR^n              \\
					      (t_1,\ldots, t_n) & \mapsto \begin{pmatrix}
						                                  t_1     \\
						                                  t_1+t_2 \\
						                                  \vdots  \\
						                                  t_1+\ldots +t_n
					                                  \end{pmatrix}.
				      \end{aligned}
			      \end{equation}
			      Notons que \( \phi\) est de déterminant \( 1\) : c'est une matrice triangulaire avec des \( 1\) sur la diagonale.
			\item Pour \eqref{SUBEQooETUFooIYIOOO}. Parce que \( (m\circ \phi)(x)=x\) dans \( \eR^n\).
		\end{itemize}
		Bref, pour toute application borélienne \( f\colon \eR^n\to \eR\), nous avons
		\begin{equation}
			E\big( f(S_1,\ldots, S_n) \big)=\int_{\eR^n}f(x)(g\circ \phi)(x)dx.
		\end{equation}
		Le lemme \ref{LEMooAVTFooIQRvop} nous indique que \( g\circ \phi\) est une densité pour \( (S_1,\ldots, S_n)\). Plus explicitement, la densité de \( (S_1,\ldots, S_n)\) est
		\begin{equation}
			\begin{aligned}
				h\colon \eR^n & \to \eR                                                           \\
				x             & \mapsto \mtu_{\eR^n_+}(x)\lambda^n e^{-\lambda(x_1+\ldots +x_n)}.
			\end{aligned}
		\end{equation}
		\spitem[Densités marginales]
		% -------------------------------------------------------------------------------------------- 
		La proposition \ref{PROPooNYNUooTCJgpl} nous assure que les variables aléatoires \( S_i\) sont à densité et que pour trouver les densités, il suffit d'intégrer. La densité de \( S_i\) est
		\begin{equation}
			h_i(t)=\int_{\eR^{n-1}}\mtu_{\eR^n_+}(x_1,\ldots, t,\ldots, x_n) e^{-\lambda x_1-\ldots -\lambda t-\ldots -\lambda x_n}
		\end{equation}
		Les différentes intégrales sont indépendantes et valent
		\begin{subequations}
			\begin{align}
				\int_{\eR}\mtu_{\mathopen[ 0 , \infty \mathclose[}(u) e^{-\lambda u}du & =\left[ -\frac{1}{ \lambda } e^{-\lambda u} \right]_{0}^{\infty} \\
				                                                                       & =-\frac{1}{ \lambda }(0-1)                                       \\
				                                                                       & =\frac{1}{ \lambda }.
			\end{align}
		\end{subequations}
		Au final, nous avons
		\begin{equation}        \label{EQooBZNBooHGeaQx}
			h_i(u)=\mtu_{\mathopen[ 0 , \infty \mathclose[}(u)\lambda  e^{-\lambda u}.
		\end{equation}
		\spitem[Conclusions]
		% -------------------------------------------------------------------------------------------- 
		Nous voyons que \eqref{EQooBZNBooHGeaQx} est la densité d'une loi exponentielle (définition \ref{DEFooTSFNooULWNHY}). La proposition \ref{PROPooVUTLooDPdhxK}\ref{ITEMooUQEFooAAFXJY} nous dit que les \( S_i\) sont indépendantes.
	\end{subproof}

	% -----------------------------------------------------------------------------------

	\begin{center}
		Pour \ref{ITEMooDXZFooXkklhG}
	\end{center}


\end{proof}

\begin{definition}      \label{DEFooWXHEooEHQUJU}
	% TODOooTVZAooXnKdlW Il faut supprimer cette définition et voir les endroits qui l'utilisent pour adapter à DEFooWDXDooRGCtXL
	Une famille de variables aléatoires \( (N_t)_{t\geq 0}\) est un \defe{processus de Poisson}{processus!Poisson}\index{Poisson!processus} d'intensité \( \lambda\) si il existe une suite de variables aléatoires indépendantes et identiquement distribuées \( (T_k)_{k\in \eN}\) de loi exponentielle\footnote{Définition \ref{DEFooTSFNooULWNHY}.} \( \dE(\lambda)\) telles que
	\begin{equation}
		N_t=\sup\{ n\geq 0\tq \sum_{k=1}^nT_k\leq t \}.
	\end{equation}
	Plus explicitement, un processus de Poisson sur espace probabilisé \( (\Omega,\tribA,P)\) est une famille de variables aléatoires \( N_t\colon \Omega\to \eN\) telles que qu'il existe des variables aléatoires \( T_k\colon \Omega\to \eR\) vérifiant
	\begin{equation}
		N_t(\omega)=\sup\{ n\geq 0\tq \sum_{k=1}^nT_k(\omega)\leq t \}
	\end{equation}
	pour tout \( \omega\in\Omega\).
\end{definition}
Si nous posons \( S_n=\sum_{k=1}^nT_k\), alors nous avons une expression plus pratique pour \( N_t\) :
\begin{equation}
	N_t=\sum_{n=1}^{\infty}\mtu_{\{ S_n\leq t \}}.
\end{equation}
Nous avons par la proposition~\ref{PropGMntiy} vu que \( N_t\sim\dP(\lambda t)\).


Pour chaque \( \omega\in \Omega\), la fonction \( t\mapsto N_t(\omega)\) est une fonction (pas du tout strictement) croissante à valeurs dans \( \eN\). Cette fonction part de \( 0\) et fait un saut de taille \( 1\) après des intervalles de temps \( T_1(\omega)\), \( T_2(\omega)\), etc. Elle est continue à droite.

Nous avons les égalités d'événements suivantes qui sont pratiques :
\begin{subequations}
	\begin{align}
		\{ s<S_n\leq t \}=\{ N_t\geq n>N_s \} \\
		\{ N_t=n \}=\{ S_n\leq t\leq S_{n+1} \}.
	\end{align}
\end{subequations}

\begin{theorem}     \label{THOooVDMCooVycibj}
	Les variables aléatoires \( (N_t)_{t\geq 0}\) forment un processus de Poisson d'intensité \( \lambda\) si et seulement si elles vérifient les trois propriétés suivantes.
	\begin{description}
		\item[Accroissements indépendants] Pour tout choix \( 0<t_0<t_1<\ldots t_n\), les variables aléatoires \( N_{t_{i+1}}-N_{t_i}\) sont indépendantes.
		\item[Accroissements stationnaires] Si \( 0<s<t\) et \( h>0\) alors
			\begin{equation}
				N_{t+h}-N_{s+h}\stackrel{\mL}{=}N_t-N_s,
			\end{equation}
			c'est-à-dire que les accroissements décalés suivent les mêmes lois.
		\item[Poisson] Pour tout \( t\) nous avons \( N_t\) suit une loi de Poisson\footnote{Définition \ref{DEFooUWKHooUFKlcr}.} : \( N_t\sim\dP(\lambda t)\).
	\end{description}
\end{theorem}
Une conséquence des accroissements stationnaires est que \( N_t-N_s\stackrel{\mL}{=}N_{t-s}-N_0=N_{t-s}\) parce que \( N_0=0\).

\begin{proposition}
	Si \( (N_t)\) est un processus de Poisson d'intensité \( \lambda\), alors
	\begin{equation}
		\lim_{t\to \infty} N_t=+\infty
	\end{equation}
	presque surement. De plus
	\begin{equation}        \label{EqvaVYAs}
		\lim_{t\to \infty} \frac{ N_t }{ t }=\lambda
	\end{equation}
	presque surement.
\end{proposition}
La relation \eqref{EqvaVYAs} est appelée \defe{loi des grands nombres}{loi!des grands nombres!processus de Poisson}.

\begin{proof}
	Par définition nous savons que
	\begin{equation}
		N_t=\sup\{ n\geq 0\tq S_n\leq t \}.
	\end{equation}
	Évidemment la fonction \( t\mapsto N_t\) est croissante, donc la limite
	\begin{equation}
		\lim_{t\to \infty} N_t(\omega)
	\end{equation}
	existe dans \( \mathopen[ 0 , \infty \mathclose]\). Nous pouvons nous restreindre à \( t\in \eN\) et considérer \( L(\omega)=\lim_{n\to \infty} N_n(\omega)\). Par somme télescopique avec \( N_0=0\),
	\begin{equation}    \label{EqfRpnfF}
		\frac{ N_n }{ n }=\frac{ \sum_{k=1}^n(N_k-N_{k-1}) }{ n }.
	\end{equation}
	Étant donné que le processus est de Poisson, les variables aléatoires \( (N_k-N_{k-1})_{k=1,\ldots, n}\) sont indépendantes et suivent toutes la loi de \( N_1-N_0\), c'est-à-dire la loi de \( N_1\). Encore par le fait que \( N_t\) soit de Poisson nous savons que \( N_1\sim\dP(\lambda)\). La loi des grands nombres (\ref{ThoefQyKZ}) appliquée aux variables aléatoires \( N_k-N_{k-1}\) nous dit que
	\begin{equation}
		\frac{ N_n }{ n }\stackrel{p.s.}{\longrightarrow}E(N_1)=\lambda>0.
	\end{equation}
	Du coup \( N_n\to \infty\) et \( L(\omega)=\infty\).

	Nous démontrons maintenant la loi des grands nombres pour les processus de Poisson. Étant donné que pour les entiers \( N_n/n\to \lambda\), pour les réels, si la limite existe, ça ne peut pas être autre chose. Si nous notons \( \bar t\) la partie entière de \( t\in \eR^+\),
	\begin{equation}
		\frac{ N_t }{ t }=\frac{ N_t-N_{\bar t} }{ t }+\frac{ N_{\bar t} }{ t }.
	\end{equation}
	Le second terme est relativement simple à traiter :
	\begin{equation}
		\frac{ N_{\bar t} }{ t }=\underbrace{\frac{ N_{\bar t} }{ \bar t }}_{\to \lambda}\cdot\underbrace{\frac{ \bar t }{ t }}_{\to 1}.
	\end{equation}
	où nous avons utilisé le premier point, \( \bar t\) étant entier. Pour le premier terme nous savons que \( t\mapsto N_t\) est croissante et donc que
	\begin{equation}
		\frac{ N_t-N_{\bar t} }{ t }\leq \frac{ N_{\bar t+1}-N_{\bar t}}{ t }=\frac{ N_{\bar t+1}-N_{\bar t} }{ \bar t+1 }\frac{ \bar t+1 }{ t }.
	\end{equation}
	Le second facteur tend vers \( 1\) lorsque \( t\to \infty\). Le premier s'écrit
	\begin{equation}    \label{eqtPgPpJ}
		\frac{ N_n-N_{n-1} }{ n }
	\end{equation}
	et tend vers zéro en tant que terme général de la série \eqref{EqfRpnfF} qui converge.
\end{proof}

\begin{proposition}
	La variable aléatoire \( N_t/t\) est un estimateur sans biais de \( \lambda\). De plus il converge vers \( \lambda\) en moyenne quadratique.
\end{proposition}

\begin{proof}
	Vu que \( N_t/t\to\lambda\) presque surement, la variable aléatoire \( N_t/t\) est un estimateur de \( \lambda\). Le fait qu'il soit sans biais a été fait dans l'exemple~\ref{ExytNlTq}.

	D'autre part nous avons (voir théorème~\ref{ThojDZjuj})
	\begin{equation}
		\Var\left( \frac{ N_t }{ t } \right)=\frac{1}{ t^2 }\Var(N_t)=\frac{ \lambda }{ t }.
	\end{equation}
	En appliquant la formule \( \Var(X)=E(X^2)-E(X)^2\) à \( X=N_t/t\) nous trouvons
	\begin{equation}
		E\left( \frac{ N_t^2 }{ t^2 } \right)=\frac{ \lambda }{ t }+\lambda^2.
	\end{equation}
	Cela montre que \( \frac{ N_t }{ t }\stackrel{L^2}{\longrightarrow}\lambda\).
\end{proof}

Pour le théorème central limite d'un processus de Poisson, nous visons un résultat du style de
\begin{equation}
	\frac{ \frac{1}{ n }\sum_iX_i-mn }{ \sigma\sqrt{n} }\stackrel{\hL}{\longrightarrow}\dN(0,1).
\end{equation}
Nous écrivons le théorème central limite pour le nombre de sauts que le processus de Poisson a connu en un temps \( t\). Le rôle de la moyenne empirique est joué par \( N_t\). Nous considérons avoir fait \emph{une seule expérience} qui a duré un temps \( t\). Donc le rôle de \( n\) est joué par \( 1\) (et non \( t\) comme on pourrait le croire). Pour le reste, le nombre de succès en un temps \( t\) d'une variable aléatoire exponentielle de paramètre \( \lambda\) est une variable aléatoire de Poisson de paramètre \( \lambda t\), en vertu de ce qui est raconté au point~\ref{subsecPoissonetexpo}. C'est cela qui motive l'énoncé suivant.

\begin{theorem}[Théorème central limite pour les processus de Poisson]\index{théorème!central limite!processus de Poisson}  \label{ThoCSuLLo}
	Si \( (N_t)_{t>0}\) est un processus de Poisson de paramètre \( \lambda\), alors nous avons
	\begin{equation}
		\frac{ N_t-\lambda t }{ \sqrt{\lambda t} }\stackrel{\hL}{\longrightarrow}\dN(0,1).
	\end{equation}
\end{theorem}

\begin{remark}
	Avant de nous lancer dans la démonstration, remarquons que si nous nous limitons à \( t\in \eN\), alors nous avons
	\begin{equation}
		\frac{ N_n-\lambda n }{ \sqrt{\lambda n} }=\frac{ \sum_{k=1}^n(N_k-N_{k-1})-\lambda n }{ \sqrt{\lambda n} }
	\end{equation}
	or par définition nous avons les égalités de lois
	\begin{equation}
		N_k-N_{k-1}\sim N_1\sim \dP(\lambda),
	\end{equation}
	donc
	\begin{equation}
		\frac{ S_n-\lambda n }{ \sqrt{\lambda n} }=\frac{ \frac{1}{ n }S_n-\lambda }{ \frac{ \sqrt{\lambda n} }{ n } }=\frac{ \frac{1}{ n }S_n-\lambda }{ \sqrt{\lambda}/\sqrt{n} },
	\end{equation}
	ce qui est exactement le théorème central limite pour une suite de lois de Poisson\footnote{Au fait près que nous devrions encore montrer que \( S_n\) est de carré intégrable.}.
\end{remark}

\begin{proof}
	Nous écrivons \( \bar t\) la partie entière de \( \bar t\) et nous décomposons :
	\begin{equation}
		\frac{ N_t-\lambda t }{ \sqrt{\lambda t} }=\underbrace{\frac{ N_t-N_{\bar t} }{ \sqrt{\lambda t} }}_A+\underbrace{\frac{ N_{\bar t}-\lambda \bar t }{ \sqrt{\lambda t} }}_B+\underbrace{\frac{ \lambda \bar t-\lambda t }{ \sqrt{\lambda t} }}_C.
	\end{equation}
	En ce qui concerne le terme \( B\), nous avons
	\begin{equation}
		B=\sqrt{\frac{ \bar t }{ t }}\frac{ N_{\bar t}-\lambda \bar t }{ \sqrt{\lambda \bar t} }\to\dN(0,1).
	\end{equation}
	Notons que nous utilisons le fait que si \( a_n\to 1\) (en tant que suite de nombres) et si \( X_n\to\dN(0,1)\) (limite en loi), alors \( a_nX_n\to \dN(0,1)\) en loi.

	Le terme \( C\) est également facile parce que \( \lambda \bar t-\lambda t\) est majoré en norme par \( \lambda\). Du coup
	\begin{equation}
		-\frac{ \lambda }{ \sqrt{\lambda t} }\leq C\leq \frac{ \lambda }{ \sqrt{\lambda t} }.
	\end{equation}
	Donc \( \lim_{t\to \infty} C=0\).

	Reste à travailler sur \( A\). Vu que \( t\mapsto N_t\) est croissante, la différence \( N_t-N_{\bar t}\) est positive. Soit \( \eta>0\), nous avons
	\begin{equation}
		P(| A |>\eta)=P(N_t-N_{\bar t}>\sqrt{\lambda t}\eta)\leq P\big( N_{\bar t+1}-N_{\bar t}\geq \sqrt{\lambda t}\eta \big)=P(N_1\geq \eta\sqrt{\lambda t})
	\end{equation}
	parce que nous savons que \( N_{\bar t+1}-N_{\bar t}\sim N_1\sim\dP(\lambda)\). En vertu des propriétés de la loi de Poisson,
	\begin{equation}
		\lim_{t\to \infty}P(N_1\geq \eta\sqrt{\lambda t})=0.
	\end{equation}
	En effet si \( Z\) est une variable aléatoire de Poisson de paramètre \( \lambda\) nous avons
	\begin{equation}
		P(Z>l)=\sum_{k=l}^{\infty}P(Z=k)= e^{-\lambda}\sum_{k=l}^{\infty}\frac{ \lambda^k }{ k! }.
	\end{equation}
	Nous reconnaissons la queue de série de \(  e^{\lambda}\), qui tend donc vers zéro lorsque \( l\to \infty\). Nous avons donc prouvé que
	\begin{equation}
		\lim_{t\to \infty} P\big( | A |>\eta \big)=0,
	\end{equation}
	c'est-à-dire la convergence en probabilité de \( A\) vers zéro.

	Nous avons montré que
	\begin{subequations}
		\begin{align}
			B+C & \stackrel{\hL}{\longrightarrow} U\sim\dN(0,1) \\
			A\stackrel{P}{\longrightarrow}0.
		\end{align}
	\end{subequations}
	Le lemme de Slutsky (\ref{LemgXDlhs}) nous avons une convergence du couple
	\begin{equation}
		(A,B+C)\stackrel{\hL}{\longrightarrow}(0,U).
	\end{equation}
	Utilisant le corolaire~\ref{CorINgTPH}, nous trouvons la convergence en loi
	\begin{equation}
		A+(B+C)\stackrel{\hL}{\longrightarrow}0+U,
	\end{equation}
	ce qu'il fallait.
\end{proof}

\begin{proposition}     \label{PROPooWAVPooHDVsER}
	Si \( N_t\) est un processus de Poisson\footnote{Définition \ref{DEFooWXHEooEHQUJU}.}, alors les variables aléatoires \( X_n=N_n\) avec \( n\in \eN\) forment une chaine de Markov\footnote{Définition \ref{DEFooGDPFooWsvfRv}.}.
\end{proposition}
J'espère qu'un jour une preuve arrivera ici : \url{https://math.stackexchange.com/q/4563414}

\section{Quelques trucs sur la simulation}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Le théorème ergodique dit que
\begin{equation}
	\pi(x)=\lim_{N\to \infty} \frac{1}{ N }\sum_{k=1}^N\mtu_{X_k=x}.
\end{equation}
C'est avec cela qu'on calcule \( \pi(x)\) à partir d'une simulation de chaine de Markov.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Le théorème central limite pour Markov}
%---------------------------------------------------------------------------------------------------------------------------

\begin{theorem}[Version allégée]        \label{THOooBCKQooCkoUEV}
	Si \( (X_n)\) est irréductible et positive récurrente, alors pour toute fonction \( f\),
	\begin{equation}
		\frac{1}{ \sqrt{N} }\left[ \sum_{k=1}^N-N\int fd\pi \right]\stackrel{\hL}{\longrightarrow}\dN(0,\sigma^2)
	\end{equation}
	où \( \sigma^2\) dépend de la fonction \( f\) et de la chaine de Markov.

	Ici, \( \int fd\pi=\sum_{x\in E}f(x)\pi(x)\).
\end{theorem}

Nous allons simuler la variable aléatoire
\begin{equation}
	Z=\frac{1}{ \sqrt{N} }\left[ \sum f(X_k)-N\sum_{x\in E} f(x)\pi(x) \right]
\end{equation}
et puis on va mettre sa réalisation dans un histogramme. Dans le cas où on prend \( f(i)=\mtu_{i=i_0}\), il y a de la simplification dans l'intégrale qui devient
\begin{equation}
	Z=\frac{1}{ \sqrt{N} }\left[ \sum_{i=1}^N\mtu_{X_k=i_0}-N\pi(i_0) \right].
\end{equation}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Feuille 5}
%---------------------------------------------------------------------------------------------------------------------------

On pose
\begin{equation}
	D_n=\sqrt{n}\sup_{x\in\eR}| F_n(x)-F(x) |.
\end{equation}
On en génère un millier de fois \( D_n\), on note \( D_n^{(k)}\) ces réalisations, et on regarde ce que vaut
\begin{equation}
	\frac{1}{ 1000 }\sum_{k=1}^{1000}\mtu_{D_n^{(k)\geq c}}.
\end{equation}
Cela nous donne une approximation de
\begin{equation}
	P\big( \sqrt{n}\sup_{x\in\eR}| F_n(x)-F(x) |\geq c \big).
\end{equation}

Note que chacun des \( D_n^{(k)}\) demande de créer un nouveau vecteur \( Y_i\) de lois qu'on veut regarder. Par exemple de loi exponentielle.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Feuille 6}
%---------------------------------------------------------------------------------------------------------------------------

Pour créer une fonction qui renvoie \( i\) avec probabilité \( p_i\) pour \( i=1,2,3\), on peut faire
\begin{equation}
	U\sim\dU[0,1]
\end{equation}
et puis on a
\begin{subequations}
	\begin{align}
		P(U<p_0)         & =p_0  \\
		P(p_0<U<p_0+p_1) & =p_1  \\
		P(p_0+p_1<U<p_2) & =p_2.
	\end{align}
\end{subequations}
Une façon de faire une loi uniforme \( [0,1]\) est de faire \info{rand}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Feuille 7}
%---------------------------------------------------------------------------------------------------------------------------

L'échantillon est \( (Y_1,\ldots, Y_n) \) et nous écrivons le vecteur
\begin{equation}
	Y=X\beta+\epsilon
\end{equation}
où \( Y\sim\dN(X\beta,\sigma^2\id)\) et \( \epsilon\sim\dN(0,\sigma^2\id)\). Nous utilisons le principe de maximum de vraisemblance. Soit \( (y_1,\ldots, y_n)\) un échantillon et
\begin{equation}
	P_{\theta}(y_1,\ldots, y_n)=\prod_i\frac{1}{ \sigma\sqrt{2\pi }}\exp\left[ -\frac{ 1 }{2}\left( \frac{ y_i-X_i^t\beta }{ \sigma } \right)^2 \right].
\end{equation}
L'astuce est de faire que \( y_i-X_i^t\beta\) est la \( i\)ième composante du vecteur \( Y-X\beta\) et donc la somme qui est dans l'exponentielle devient la norme de \( Y-X\beta\) :
\begin{equation}
	f_{\theta}(y_1,\ldots, y_n)=\left( \frac{1}{ \sigma\sqrt{2\pi} } \right)^n\exp\left[ -\frac{ 1 }{2}\| Y-X\beta \|^2 \right].
\end{equation}
On passe au logarithme et on dérive par rapport à \( \sigma^2\). Attention : la variable est \( \sigma^2\), donc la dérivée de \( \sigma^2\) est \( 1\) et non \( 2\sigma\). Bref, on trouve
\begin{equation}
	\sigma^2=\frac{1}{ 2n }\| U+X\beta \|.
\end{equation}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Simuler des lois conditionnelles}
%---------------------------------------------------------------------------------------------------------------------------

Nous voulons générer des couples \( (X,Y)\) tels que \( Y\) prend les valeurs \( 0\) ou \( 1\) et tels que
\begin{subequations}
	\begin{numcases}{}
		P(X|Y=0)\sim\dE(\lambda_0)\\
		P(X|Y=1)\sim\dE(\lambda_1).
	\end{numcases}
\end{subequations}
Le plus simple est de générer une liste
\begin{subequations}
	\begin{align}
		(X_1,0) &  & (X_4,1) \\
		(X_2,0) &  & (X_5,1) \\
		(X_3,0) &  & (X_6,1)
	\end{align}
\end{subequations}
avec \( X_1,X_2,X_3\sim\dE(\lambda_0)\) et \( X_4,X_5,X_6\sim\dE(\lambda_1)\).

Avec cette méthode cependant la liste est triée et en plus on a autant de \( 1\) que de \( 0\). On peut faire un peu plus technologique pour corriger cela. Pour créer un couple, on commence par \( Y\sim\dB(p)\) et puis suivant que \( Y=0\) ou \( y=1\), on génère \( X\sim\dE(\lambda_0)\) ou \( X\sim\dE(\lambda_1)\).
