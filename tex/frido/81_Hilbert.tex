% This is part of Mes notes de mathématique
% Copyright (c) 2011-2017
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Espaces de Hilbert}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{definition}  \label{DefVKuyYpQ}
    Un \defe{espace de Banach}{espace!Banach}\index{Banach!espace} est un espace vectoriel normé complet pour la topologie de la norme. 
\end{definition}

\begin{definition}  \label{DefORuBdBN}
    Un espace vectoriel muni d'un produit scalaire est une espace \defe{préhilbertien}{préhilbertien}. Si il est complet\footnote{Définition \ref{DEFooVQDBooNxprFU}.} pour la norme induite par le produit scalaire alors il est de \defe{Hilbert}{Hilbert}.

    Dans les deux cas nous considérons la topologie métrique dérivant du produit scalaire.
\end{definition}

Dans les cas de dimension finie, les espaces vectoriels normés sont automatiquement complets par la proposition \ref{PROPooGJDTooXOoYfw}.

La différence entre un espace de Hilbert et un espace de Banach est que dans le cas d'un espace de Hilbert, nous demandons que la norme dérive d'un produit scalaire.

\begin{proposition}     \label{PropTdupIG}
    Si \( \hH\) est un espace de Hilbert réel, alors
    \begin{equation}
        \| x+y \|^2=\| x \|^2+\| y \|^2+2\langle x, y\rangle .
    \end{equation}
    Si \( \hH\) est un espace de Hilbert complexe alors
    \begin{equation}        \label{EqrbBlkK}
        \| x+y \|^2=\| x \|^2+\| y \|^2+2\real\langle x, y\rangle .
    \end{equation}
    Dans les deux cas nous avons l'inégalité de Cauchy-Schwarz\index{inégalité!Cauchy-Schwarz}\index{Cauchy-Schwarz} :
    \begin{equation}
        | \langle x, y\rangle  |\leq \| x \|\| y \|.
    \end{equation}
\end{proposition}

Dans un espace vectoriel de dimension infinie, tous les opérateurs linéaires ne sont pas continus.

\begin{example}
    Soit un espace vectoriel \( V\) engendré par la base \( \{ e_k \}_{k\in \eN}\) et l'application linéaire \( T\colon V\to V\) donnée par
    \begin{equation}
        Te_k=ke_k.
    \end{equation}
    Nous allons montrer que l'image inverse de la boule unité ouverte \( \mO\) n'est pas ouverte. En effet si \( (\epsilon_k)\) est une suite de réels strictement positifs tendant vers zéro, les vecteurs
    \begin{equation}
        a_k=\left( \frac{1}{ k }+\epsilon_k \right)e_k
    \end{equation}
    sont hors de \( T^{-1}\mO\) parce que
    \begin{equation}
        Ta_k=(1+k\epsilon_k)e_k.
    \end{equation}
    Mais la suite \( (a_k)\) converge vers \( 0\) qui fait partie de \( T^{-1}\mO\). Donc le complémentaire de \( T^{-1}\mO\) n'est pas fermé, ce qui prouve que \( T^{-1}\mO\) n'est pas ouvert.
\end{example}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Sous-espace vectoriel fermé ???}
%---------------------------------------------------------------------------------------------------------------------------

Nous verrons que beaucoup de résultats demandent un sous-espace vectoriel \emph{fermé}. Une question légitime est : est-ce qu'il existe des sous-espaces vectoriels qui ne soient pas fermés ? En dimension finie, tous les sous-espaces vectoriels sont fermés, mais cela n'est pas vrai en dimension infinie.

Soit en effet une partie libre infinie \( A=\{ v_i \}_{i\in \eN}\) dans un espace de Hilbert \( \hH\). L'ensemble $\Span(A)$ des combinaisons linéaires d'éléments de \( A\) est un sous-espace vectoriel de \( \hH\), mais il n'est pas fermé.

En effet, supposons pour simplifier les notations que \( \| v_i \|=1\) pour tout \( i\). Alors nous considérons la combinaison
\begin{equation}
    a=\sum_{k=1}^{\infty}\alpha_kv_k
\end{equation}
où les \( \alpha_k\) sont suffisamment décroissants pour assurer les convergences\footnote{Par exemple \( \alpha_k=1/k^2\) si les \( v_k\) sont orthonormaux.}. Le vecteur \( a\) n'est pas dans \( \Span(A)\), mais la suite \( a_n=\sum_{k=1}^{n}\alpha_kv_k\) est dans \( \Span(A)\) et converge vers \( a\) : \( a_n\stackrel{\hH}{\longrightarrow}a\). En effet,
\begin{equation}
    \| a_n-a \|=\| \sum_{k=n+1}^{\infty}\alpha_kv_k \|\leq \sum_{k=n+1}^{\infty}| \alpha_k | \stackrel{n\to\infty}{\longrightarrow}0.
\end{equation}
Vous voulez des détails sur la dernière limite ? Vu que la somme \( \sum_k| \alpha_k |\) converge, la suite des sommes de queues de suites\footnote{On se comprend hein.} converge vers zéro :
\begin{equation}
    \lim_{n\to \infty} \sum_{k=n+1}^{\infty}| \alpha_k |=0.
\end{equation}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Théorème de la projection}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{theorem}[Projection sur partie fermée convexe\cite{ProbCOndutetz,JDULLqS}]\index{théorème!projection!partie fermée convexe} \label{ThoProjOrthuzcYkz}
    Soit \( \hH\) un espace de Hilbert, \( x\in \hH\), et \( C\) un sous ensemble fermé convexe de \( \hH\).
    \begin{enumerate}
        \item
            Les deux conditions suivantes sur \( y\in \hH\) sont équivalentes:
    \begin{enumerate}
        \item   \label{ETsfYCSItemi}
            \( \| x-y \|=\inf\{ \| x-z \|\tq z\in C \}\),
        \item\label{ETsfYCSItemii}
            pour tout \( z\in C\), \( \real\langle x-y, z-y\rangle \leq 0\).
    \end{enumerate}
\item
    Il existe un unique \( y\in \hH\), noté \( y=\pr_C(x)\) vérifiant ces conditions.
    \end{enumerate}
\end{theorem}

\begin{proof}
    Nous commençons par prouver l'existence et l'unicité d'un élément dans \( C\) vérifiant la première condition. Ensuite nous verrons l'équivalence. 
    
    Nous nommons \( d\) l'infimum en question de la première condition.
    \begin{description}
        \item[Existence] 
    Soit \( (y_n)\) une suite dans \( C\) telle que 
    \begin{equation}
        \lim_{n\to \infty} \| x-y_n \|=\inf\{ \| x-y \|\tq z\in C \}=d.
    \end{equation}
    Nous allons montrer que cette suite peut être choisie de Cauchy. Elle convergera donc dans \( \hH\) parce que ce dernier est complet. Mais \( C\) étant supposé fermé dans \( \hH\), la limite appartiendra à \( C\). Soient \( r,s\in \eN\). D'abord nous avons
    \begin{subequations}
        \begin{align}
            \| y_r-y_s \|^2&=\langle y_r-y_s+x-x, y_r-y_s+x-x\rangle \\
            &=\| y_r-x \|^2+\| y_s-x \|^2-2\langle y_r-x, y_s-x\rangle .
        \end{align}
    \end{subequations}
    Ensuite,
    \begin{subequations}
        \begin{align}
            4\left\| \frac{ y_r+y_s }{2}-x \right\|^2&=\langle y_r+y_s-2x, y_r-y_s-2x\rangle \\
            &=\| y_r-x \|^2+\| y_s-x \|^2+2\langle y_r-x, y_s-x\rangle .
        \end{align}
    \end{subequations}
    Si nous égalisons les valeurs de \( 2\langle y_r-x, y_s-x\rangle \) nous trouvons
    \begin{equation}    \label{EqiqCyUa}
        \| y_r-y_s \|^2=-4\left\| \frac{ y_r+y_s }{2}-x \right\|^2+2\| y_r-x \|^2+2\| y_s-x \|^2.
    \end{equation}
    La distance infimum étant \( d\), nous pouvons choisir \( y_n\) de telle façon à avoir 
    \begin{equation}
        \| y_n-x \|\leq d+\frac{1}{ n }.
    \end{equation}
    D'autre part étant donné que \( C\) est convexe, \( (y_r+y_s)/2\) est dans \( C\) et nous avons
    \begin{equation}
        \left\| \frac{ y_r+y_s }{2}-x \right\| \leq d.
    \end{equation}
    En mettant ces majorations dans \eqref{EqiqCyUa} nous trouvons
    \begin{equation}
        \| y_r-y_s \|^2\leq -4d+2\left( d+\frac{1}{ r } \right)+2\left( d+\frac{1}{ s } \right)=\frac{1}{ r }+\frac{1}{ s }.
    \end{equation}
    La suite \( (y_n)\) est donc de Cauchy et la limite est un élément de \( C\). Prouvons que cet élément \( y\) réalise l'infimum. Pour cela nous avons les inégalités
    \begin{equation}
        d\leq \| x-y \|\leq\| x-y_n \|+\| y_n-y \|.
    \end{equation}
    En prenant le limite \( n\to\infty\) nous trouvons
    \begin{equation}
        d\leq \| x-y \|\leq d.
    \end{equation}
    
        \item[Unicité]

            Même preuve que pour le théorème en dimension finie \ref{ThoWKwosrH}.

        \item[\ref{ETsfYCSItemi}\( \Rightarrow\) \ref{ETsfYCSItemii}]
                
            Même preuve que pour le théorème en dimension finie \ref{ThoWKwosrH}.
        \item[\ref{ETsfYCSItemii}\( \Rightarrow\) \ref{ETsfYCSItemi}]

            Même preuve que pour le théorème en dimension finie \ref{ThoWKwosrH}.

    \end{description}
\end{proof}

\begin{proposition}     \label{PropAXJpCe}
    Soit \( C\) une partie convexe et fermée de l'espace de Hilbert \( \hH\). Alors pour tout \( x_1,x_2\in\hH\) nous avons
    \begin{equation}
        \| \pr_C(x_1)-\pr_C(x_2) \|\leq \| x_1-x_2 \|.
    \end{equation}
    En particulier la projection est une application continue.
\end{proposition}

\begin{proof}
    Nous posons \( y_1=\pr_C(x_1)\) et \( y_2=\pr_C(x_2)\). Par la partie \ref{ETsfYCSItemii} du théorème \ref{ThoProjOrthuzcYkz}, nous avons, pour tout \( z,z'\in C\) les inégalités
    \begin{subequations}
        \begin{align}
            \real\langle x_1-y_1, z-y_1\rangle \leq 0\\
            \real\langle x_2-y_2, z'-y_2\rangle \leq 0.
        \end{align}
    \end{subequations}
    En prenant \( z=y_2\) et \( z'=y_1\) et en sommant nous trouvons
    \begin{equation}
        \real\langle (x_1-y_1)+(y_2-x_2), y_2-y_1\rangle \leq 0.
    \end{equation}
    Nous pouvons maintenant calculer
    \begin{equation}
        \begin{aligned}[]
            \| y_1-y_2 \|^2&=\real\| y_1-y_2 \|\\
            &=\real\langle y_1-y_2, (y_1-x_1)+x_1-x_2+(x_2-y_2)\rangle \\
            &=\real\langle y_1-y_2, x_1-x_2\rangle +\real\langle y_2-y_1, (x_1-y_1)+(y_2-x_2)\rangle \\
            &\leq\langle y_1-y_2, x_1-x_2\rangle \\
            &\leq\big\| \langle y_1-y_2, x_1-x_2\rangle  \big\|\\
            &=\leq \| y_1-y_2 \|\| x_1-x_2 \|.
        \end{aligned}
    \end{equation}
    En simplifiant par \( \| y_1-y_2 \|\)\footnote{Si c'est nul, alors la preuve est évidente.} nous trouvons le résultat
    \begin{equation}
        \| y_1-y_2 \|\leq \| x_1-x_2 \|.
    \end{equation}
\end{proof}

\begin{theorem}[Projection orthogonale]\index{projection!orthogonale}      \label{ThoMXwOjb}
    Soit \( \hH\) un espace de Hilbert et \( K\), un sous-espace vectoriel fermé non réduit à \( \{ 0 \}\) et \( x\in\hH\). L'élément \( y=\pr_K(x)\) est l'unique élément de \( K\) tel que
    \begin{equation}
        x-y\in K^{\perp}.
    \end{equation}
    De plus l'application \( x\mapsto\pr_K(x)\) est linéaire, continue et de norme \( 1\).
\end{theorem}
\index{théorème!projection!cas vectoriel}

    L'élément \( y\) ainsi définit est la \defe{projection orthogonale}{projection!orthogonale} de \( x\) sur \( K\) et sera noté \( \pr_K(f)\).\nomenclature[Y]{\( \pr_K(x)\)}{projection orthogonale de \( x\) sur \( y\)}

\begin{proof}

    La continuité de la projection est donné par la proposition \ref{PropAXJpCe}.

            Soit \( z\) un élément de \( K\) tel que \( \langle z-x, a\rangle =0\) pour tout \( a\in K\). Nous avons
            \begin{subequations}
                \begin{align}
                    \| x-a \|^2&=\| z-x \|^2+\| a-z \|^2+2\underbrace{\langle z-x, a-z\rangle}_{=0}\\
                    &\geq \| z-x \|^2.
                \end{align}
            \end{subequations}
            Le produit scalaire est nul parce que \( a-z\in K\). La distance \( \| z-x \|\) est donc bien la plus petite distance entre \( x\) et les éléments de \( K\).

            Dans l'autre sens, nous supposons que \( y\in K\) minimise la distance à \( x\) dans \( K\). Par hypothèse pour tout \( a\) et pour tout \( \lambda\in \eR\), la différence
            \begin{equation}
                \| (y+\lambda a)-x \|^2-\| y-x \|^2
            \end{equation}
            est positive. En développant les produits scalaires nous trouvons la conditions suivante
            \begin{equation}
                \lambda^2\| a \|^2+2\lambda\langle a, y-x\rangle \geq 0
            \end{equation}
            qui doit être vraie pour tout \( \lambda\in\eR\). En tant que polynôme du second degré en \( \lambda\), cela n'aura pas deux racines réelles distinctes uniquement si \( \langle a, y-x\rangle =0\).
    
            Nous montrons maintenant la linéarité de la projection orthogonale. Soient \( x_1,x_2\in\hH\). L'élément \( y=\pr_Kx_1+\pr_Kx_2\) satisfait à la condition d'orthogonalité : pour tout \( z\in K\),
    \begin{equation}
        \langle x_1+x_2-\pr_Kx_1-\pr_Kx_2, z\rangle =\langle x_1-\pr_Kx_1, z\rangle +\langle x_2-\pr_Kx_2, z\rangle =0.
    \end{equation}
    Étant donné que \( K\) est un sous-espace vectoriel, la condition de minimalité est automatiquement vérifiée (seconde partie du théorème \ref{ThoProjOrthuzcYkz}).

    En ce qui concerne la norme opérateur de \( \pr_K\), la décomposition de \( x\in\hH\) en composantes dans \( K\) et \( K^{\perp}\) est
    \begin{equation}
        x=x+(x-\pr_Kx).
    \end{equation}
    Étant deux parties orthogonales nous avons
    \begin{equation}
        \| \pr_Kx \|^2=\| x \|^2-\| x-\pr_Kx \|^2.
    \end{equation}
    En prenant \( \| x \|=1\) nous trouvons \( \| \pr_Kx \|^2\leq 1\) et par conséquent \( \| \pr_K \|\leq 1\). Mais d'autre part en prenant \( x\in K\) nous avons automatiquement \( \| \pr_K \|\geq 1\).
\end{proof}

\begin{proposition}
    Soit \( \hH=L^2(\Omega,\tribA,\mu)\), \( \tribF\) une sous tribu de \( \tribA\) et \( K\) l'ensemble de fonctions \( \tribF\)-mesurables dans \( L^2(\Omega,\tribA,\mu)\). Si \( f\in L^2(\Omega,\tribA,\mu)\) est positive, alors \( \pr_Kf\) est positive (presque partout).
\end{proposition}

\begin{proof}
    L'ensemble \( A=\{ \pr_Kf<0 \}\) est dans \( \tribF\). En effet 
    \begin{equation}
        A=(\pr_Kf)^{-1}\big( \mathopen] -\infty , 0 \mathclose[\big)
    \end{equation}
    alors que, par construction, \( \pr_Kf\) est \( \tribF\)-mesurable. La fonction indicatrice \( \mtu_A\) est alors \( \tribF\)-mesurable (c'est à dire \( 1_A\in K\)) et nous avons
    \begin{equation}
        0\leq\int_{\Omega}f\mtu_A=\int_{\Omega}\pr_Kf\mtu_A\leq 0.
    \end{equation}
    Étant donné que nous avons supposé \( f\geq 0\) nous avons alors \( \mu(A)=0\). D'où le fait que \( \pr_Kf\) est presque partout positive.
\end{proof}


%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Systèmes orthogonaux et bases}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Dans cette partie nous noterons \( \eK\) le corps de base de l'espace \( \hH\). Seuls deux cas sont envisagés : \( \eK=\eC\) ou \( \eK=\eR\).

Pour chaque \( x\in\hH\) nous considérons l'application
\begin{equation}        \label{EQooMWZAooZUFKOs}
    \begin{aligned}
        \Phi_x\colon \hH&\to \eK \\
        y&\mapsto \langle x, y\rangle . 
    \end{aligned}
\end{equation}
Ce sont des applications continues.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Orthogonal d'une partie}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}  \label{DEFooXUXQooMmDnhW}
    Soit une partie \( A\) de l'espace de Hilbert \( \hH\). L'\defe{orthogonal}{orthogonal} de \( A\) est l'ensemble
    \begin{equation}
        A^{\perp}=\{ v\in\hH\tq \langle v, x\rangle =0\forall x\in A \}.
    \end{equation}
    \nomenclature[Y]{\( A^{\perp}\)}{orthogonal d'une partie.}
\end{definition}

\begin{proposition}     \label{PropdpaMpH}
    Si \( \hH\) est une préhilbert et si \( A\subset \hH\), alors l'ensemble \( A^{\perp}\) est un sous-espace fermé de \( \hH\).
\end{proposition}

\begin{proof}
    L'application \( \Phi_x\) définie en \eqref{EQooMWZAooZUFKOs} est continue pour chaque \( x\in\hH\) et par conséquent l'ensemble \( \ker\Phi_x=\Phi_x^{-1}(\{ 0 \})\) est fermé. L'ensemble
    \begin{equation}
        A^{\perp}=\bigcap_{x\in A}\ker\Phi_x
    \end{equation}
    est donc fermé.    
\end{proof}

\begin{proposition}[\wikipedia{fr}{Supplémentaire_topologique}{wikipédia}]     \label{PropKZDqTR}
    Soit \( V\) un espace vectoriel normé et une décomposition en somme directe \( V=F\oplus G\). Alors les trois conditions suivantes sont équivalentes.
    \begin{enumerate}
        \item
            L'isomorphisme naturel \( F\times G\to v\) est un homéomorphisme.
        \item
            \( F\) et \( G\) sont fermés et la restriction à \( G\) de la projection \( V\to V/F\) est un homéomorphisme.
        \item
            \( F\) et \( G\) sont fermés et la projection de \( E\) sur \( F\) est continue.
    \end{enumerate}
\end{proposition}
Lorsqu'une décomposition en somme directe vérifie la proposition \ref{PropKZDqTR}, nous disons que la décomposition est \defe{topologique}{topologique!somme directe}.

\begin{theorem}     \label{ThowZyaiz}
    Soit \( \hH\) un espace de Hilbert et \( F\) un sous-espace fermé de \( \hH\). Alors
    \begin{enumerate}
        \item
            Nous avons la décomposition
            \begin{equation}        \label{EqxXIvrG}
                \hH=F\oplus F^{\perp}.
            \end{equation}
        \item       \label{ItemThowZyaizii}
            La projection sur \( F\) par rapport à la somme directe \eqref{EqxXIvrG} est la projection \( \pr_F\) du théorème de projection.
        \item
            La décomposition \eqref{EqxXIvrG} est topologique.
    \end{enumerate}
\end{theorem}

\begin{proposition}
    Si \( F\) est un sous-espace de l'espace de Hilbert \( \hH\) alors on a \( F^{\perp\perp}=\bar F\).
\end{proposition}

\begin{proof}
    Nous savons par la proposition \ref{PropdpaMpH} que \( F^{\perp}\) est fermé, par conséquent le théorème \ref{ThowZyaiz} donne la somme directe
    \begin{equation}
        \hH=F^{\perp}\oplus F^{\perp\perp}.
    \end{equation}
    Mais \( \bar F\) étant également fermé nous avons la somme directe
    \begin{equation}
        \hH=\bar F\oplus(\bar F)^{\perp}.
    \end{equation}
    Montrons que \( (\bar F)^{\perp}=F^{\perp}\). En effet si \( x\in F^{\perp}\) et si \( y\in \bar F\), alors il existe une suite \( y_n\) dans \( F\) qui converge vers \( y\). Pour chaque \( n\) nous avons \( \langle x, y_n\rangle =0\) et dons \( \langle x, y\rangle =0\) par continuité du produit scalaire.

    Nous avons donc
    \begin{equation}
        \hH=F^{\perp}\oplus F^{\perp\perp}=\bar F\oplus F^{\perp}.
    \end{equation}
    Mais \( \bar F\subset F^{\perp\perp}\) (prendre une suite). Les espaces \( \bar F\) et \( F^{\perp\perp}\) étant tous deux des supplémentaires de \( F^{\perp}\), nous déduisons qu'ils doivent être égaux.
\end{proof}

\begin{proposition}     \label{PropqiWonByiBmc}
    Soit \( \hH\) un espace de Hilbert et \( F\) un sous-espace vectoriel de \( \hH\). Alors \( F\) est dense si et seulement si \( F^{\perp}=\{ 0 \}\).
\end{proposition}

\begin{proof}
    Nous savons que
    \begin{equation}
        \hH=F^{\perp}\oplus \bar F.
    \end{equation}
    Donc nous avons \( H=\bar F\) si et seulement si \( F^{\perp}=\{ 0 \}\).
\end{proof}
Pour vérifier si un sous-espace vectoriel d'un espace de Hilbert est dense, il suffit donc de montrer que son orthogonal est réduit à zéro.

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Dual, théorème de représentation de Riesz}
%---------------------------------------------------------------------------------------------------------------------------

\begin{lemma}       \label{LemjYVcHE}
    L'application  \( \Phi\colon \hH\to \aL(\hH,\eK)\) donnée par \( y\mapsto\Phi_y\) est une isométrie : nous avons \( \| \Phi_y \|=\| y \|\). De plus pour chaque \( y\), l'application \( \Phi_y\) est continue.
\end{lemma}

\begin{proof}
    En utilisant la définition de la norme opérateur et l'inégalité de Cauchy-Schwarz,
    \begin{equation}
        \| \Phi_y \|=\sup_{\| x \| =1}\| \Phi_y(x) \|=\sup| \langle x, y\rangle  |\leq\sup\| x \|\| y \|=\| y \|.
    \end{equation}
    Par conséquent \( \| \Phi_y \|\leq\| y \|\). Mais d'autre part le fait que \( \Phi_y(y)=\| y \|^2\) montre que \( \| \Phi_y \|\geq \| y \|\).

    En ce qui concerne la continuité de \( \Phi_y\), elle est garantie par le fait que c'est une application linéaire bornée via la proposition \ref{PROPooQZYVooYJVlBd}.
\end{proof}

\begin{definition}
    Le \defe{dual}{dual!d'un espace de Hilbert} de l'espace de Hilbert \( \hH\) est l'ensemble\nomenclature[Y]{\( \hH'\)}{dual}
    \begin{equation}
        \hH'=\{ f\colon \hH\to \eK\text{ linéaire et continue} \}.
    \end{equation}
\end{definition}
Notons que dans le contexte des espaces de Hilbert nous demandons la continuité des éléments du dual parce qu'elle n'est pas automatique par la linéarité dans les cas de dimension infinie. En principe nous devrions préciser dual \emph{topologique}, mais nous ne le ferons pas systématiquement lorsque le contexte parle clairement de topologie (ce qui est le cas lorsqu'on parle d'espaces de Hilbert). De temps en temps le dual \emph{algébrique} d'un espace est noté \( E^*\); dans ce cas la continuité n'est pas demandée.

\begin{theorem}[Théorème de représentation de Riesz]        \label{ThoQgTovL}
    L'application
    \begin{equation}
        \begin{aligned}
            \Phi\colon \hH&\to \hH' \\
            y&\mapsto \Phi_y 
        \end{aligned}
    \end{equation}
    est une bijection isométrique.
\end{theorem}
\index{théorème!de représentation de Riesz}
\index{rang!utilisation}

\begin{proof}
    Nous savons du lemme \ref{LemjYVcHE} que \(\Phi\) est une isométrique. Nous devons seulement montrer que \( \Phi\) est surjective. Soit \( f\in \hH'\). Par continuité nous savons que \( F=\ker(f)\) est fermé, donc
    \begin{equation}
        \hH=\ker(f)\oplus(\ker f)^{\perp}
    \end{equation}
    par le théorème \ref{ThowZyaiz}. Nous considérons une base de \( H\) adaptée à cette décomposition, c'est à dire
    \begin{itemize}
        \item \( (u_s)_{s\in S}\) une base de \( \ker f\),
        \item
            \( (v_t)_{t\in T}\) une base de \( (\ker f)^{\perp}\).
    \end{itemize}
    Il se fait que \( T\) se réduit à un seul élément parce que si \( v\in (\ker f)^{\perp}\), alors \(  f(v)\neq 0\), et par conséquent \( \{  f(v) \}\) est déjà une base de \( \Image f=\eK\). Le théorème du rang (théorème \ref{ThoGkkffA}) assure alors que
    \begin{equation}
        \{ v \}\cup\{ u_s \}_{s\in S}
    \end{equation}
    est une base de \( \hH\) avec \( v\in(\ker f)^{\perp}\) et \( u_s\in \ker f\). Nous choisissons \( v\) pour avoir \( \| v \|=1\).

    Nous pouvons maintenant prouver l'existence de \( y\) tel que \(  f_y= f\). En effet si nous posons \( y=\overline{  f(v) }v\) nous avons \(  f_y= f\), en effet
    \begin{subequations}
        \begin{align}
             f_y(v)=\langle v, y\rangle = f(v)\langle v, v\rangle = f(v)\\
             f_y(u_s)=\langle u_s, y\rangle =0.
        \end{align}
    \end{subequations}
    Par conséquent \(  f_y\) et \(  f\) coïncident sur une base de \( \hH\).

    En ce qui concerne l'unicité, d'abord si \(  f_y= f\) alors nous devons avoir \( y\in(\ker f)^{\perp}\) et par conséquent \( y=\lambda v\) pour un certain \( \lambda\in \eK\). Nous avons alors
    \begin{equation}
         f_y(v)=\bar\lambda\langle v, v\rangle =\bar\lambda.
    \end{equation}
    Pour que cela soit égal à \(  f(v)\), nous fixons \( \lambda=\overline{  f(v) }\).
    
\end{proof}
Notons que nous avons réellement utilisé le théorème du rang pour l'unicité. Si nous ne demandions pas l'unicité, alors nous n'avions pas besoin du fait que \( \dim(\ker f)^{\perp}=1\), et nous aurons donc pu parler de formes plus générales à valeurs dans \( \eK^n\).

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Séparabilité}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}      \label{DEFooSFOJooGICSbT}
    Un espace topologique est \defe{séparable}{séparable} s'il possède une partie dénombrable dense.
\end{definition}

\begin{definition}[\cite{HPJdGNV}]      \label{DEFooQVPHooJaSWyF}
    Si \( E\) est un espace vectoriel normé nous disons que \( \Delta\) est une partie \defe{totale}{totale}\index{partie!totale} de \( E\) si \( \Span(\Delta)\) est dense dans \( E\). Attention : nous rappelons que \( \Span(\Delta)\) est l'ensemble des combinaisons linéaires \emph{finies} d'éléments de \( \Delta\).
\end{definition}

\begin{proposition}     \label{PROPooZMWHooVwvNBY}
    Un espace vectoriel normé est séparable si et seulement s'il possède une partie totale dénombrable.
\end{proposition}

\begin{proof}
    Si \( \Delta\) est une partie dénombrable de \( E\), alors le \( \eQ\)-espace vectoriel \( \Span_{\eQ}\Delta\) est dénombrable, et sa fermeture est la même que celle de \( \Span_{\eK}\Delta\).
\end{proof}

\begin{definition}
    Une famille \( (u_i)_{i\in I}\) d'éléments de \( \hH\) indicée par un ensemble quelconque \( I\) est un \defe{système orthonormé}{orthonormé!système}
    \index{système!orthonormé} si
    \begin{enumerate}
        \item
            \( \| u_i \|=1\) pour tout \( i\in I\),
        \item
            \( u_i\perp u_j\) pour tout \( i\neq j\).
    \end{enumerate}
\end{definition}
Notons que si \( (u_n)_{n\in \eN}\) est un système orthonormé dénombrable alors en utilisant les formules de la proposition \ref{PropTdupIG}, nous avons
\begin{equation}    \label{EqCLQbMy}
    \big\| \sum_{k=1}^n\xi_ku_k \big\|^2=\sum_{k=1}^n| \xi_k |^2.
\end{equation}

% TODO : cohérence. Je devrais poser e_n(t)=exp(int), puis aussi faire attention aux conventions pour les intervalles non 2pi.
% Ceci est à vérifier un peu partout où on parle de série de Fourier.
\begin{example}
    Dans l'ensemble \( L^2(a,b)\) avec \( b-a=L\) l'ensemble des fonctions
    \begin{equation}        \label{EqxNXguH}
        e_n(t)=\frac{1}{ \sqrt{b-a} }\exp(\frac{ 2\pi }{ L }int)
    \end{equation}
    avec \( n\in \eZ\) forme un système orthonormé. En effet
    \begin{equation}
        \langle e_n, e_n\rangle =\frac{1}{ b-a }\int_a^b\exp(\frac{ 2\pi }{ L }int)\exp(-\frac{ 2\pi }{ L }int)=1
    \end{equation}
    et
    \begin{equation}
        \langle e_n, e_m\rangle =\frac{1}{ b-a }\int_a^b e^{\frac{ 2\pi }{ L }(n-m)t}dt=0.
    \end{equation}
    Dans cette intégrale nous utilisons le fait que \( b=a+(b-a)\) pour simplifier les expressions en cours de calcul.

    La famille \eqref{EqxNXguH} est le \defe{système trigonométrique}{système!trigonométrique} de \( L^2(a,b)\). On en parle aussi dans \cite{KuttlerTopInAl}.
\end{example}

\begin{proposition}     \label{PROPooMOQRooCPFnPC}
    Une partie orthonormée est libre.
\end{proposition}

\begin{proof}
    Soit \( (u_i)_{i\in I}\) une famille orthonormée de \( \hH\) et une combinaison linéaire \emph{finie} nulle :
    \begin{equation}
        \sum_{k=1}^{n}a_ku_k=0.
    \end{equation}
    Nous développons la somme en utilisant les formules de la proposition \ref{PropTdupIG} :
    \begin{equation}
        0=\| \sum_ka_ku_k \|^2=\sum_k| a_k |^2\| u_k \|^2+2\sum_{k<l}\langle a_ku_k, a_lu_l\rangle .
    \end{equation}
    La famille étant orthonormée, les choses se simplifient en
    \begin{equation}
        \sum_k| a_k |^2=0,
    \end{equation}
    ce qui signifie que \( a_k=0\) pour tout \( k\).
\end{proof}

Avant de continuer nous devons définir comment nous calculons des sommes sur des ensembles quelconques. Si \( I\) est un ensemble et si pour chaque \( i\in I\) nous avons un nombre réel positif \( a_i\), alors nous définissons
\begin{equation}
    \sum_{i\in I}a_i=\sup_{\substack{J\subset I\\\text{ } J\text{ fini }}}\sum_{j\in J} a_j.
\end{equation}
Cela est discuté dans la section \ref{SECooHHDXooUgLhHR}.

\begin{proposition}[Inégalités de Bessel]    \label{PropHKqVHj}
    Soit \( \hH\) un préhilbert. Si \( (u_i)_{i\in I}\) est un système orthonormé et si \( x\in \hH\), alors
    \begin{equation}        \label{EQooWCYZooOPzGaw}
        \sum_{i\in I}\big| \langle x, u_i\rangle  \big|^2\leq \| x \|^2.
    \end{equation}
\end{proposition}
\index{Bessel!inégalité}
\index{inégalité!Bessel}

\begin{proof}
    Les éléments de la somme étant des réels positifs, la notion de somme à utiliser est celle de la définition \ref{DefHYgkkA}.

    Posons \( c_i(x)=\langle x, u_i\rangle \). Pour toute partie finie \( J\subset I\) nous avons
    \begin{equation}
        0\leq \big\| x-\sum_{j\in J}c_j(x)u_j \big\|^2=\| x \|^2-2\real\sum_{j}\langle x, c_j(x)u_j\rangle +\sum_j| c_j(x) |^2.
    \end{equation}
    Mais en tenant compte du fait que 
    \begin{equation}
        \langle x, c_j(x)u_j\rangle =\overline{  c_j(x)}\langle x, u_j\rangle =| c_j(x) |^2,
    \end{equation}
    nous restons avec
    \begin{equation}    \label{EqvwXWEA}
        \| x-\sum_{j\in J}c_j(x)u_j \|=\| x \|^2-\sum_{j\in J}| c_j(x) |^2.
    \end{equation}
    Finalement,
    \begin{equation}
        \sum_{j\in J}| c_j(x) |^2\leq \| x \|^2.
    \end{equation}
    Ayant cette inégalité pour toute partie finie de \( I\), nous l'avons encore pour le supremum.
\end{proof}

\begin{proposition}     \label{PROPooWTOZooYZdlml}
    Soit \( \hH\) un préhilbert et une famille orthonormé \( (u_i)_{i\in I} \). Si 
    \begin{equation}        \label{EqitrzXi}
        x=\sum_{i\in I}\xi_iu_i
    \end{equation}
    alors \( \xi_i=\langle x, u_i\rangle \).
\end{proposition}

\begin{proof}
    Nous appliquons l'application \( \Phi_{u_k}\) du théorème de représentation de Riesz\footnote{Théorème \ref{ThoQgTovL}.} à l'équation \eqref{EqitrzXi}.

    Si \( I\) est dénombrable, alors permuter \( \Phi_{u_k}\) avec la somme consiste à invoquer la continuité, et permuter la limite des sommes partielles avec \( \Phi_{u_k}\) (l'application \( \Phi_{u_k}\) est continue parce qu'isométrique).

    Sinon, il faut utiliser la proposition \ref{PROPooWLEDooJogXpQ}. Il faut donc montrer que la famille \( \Phi_{u_k}\big( \xi_iu_i \big)\) est sommable. Cela est fort vrai parce que cette famille ne contient en réalité qu'en seul élément non nul, celui avec \( i=k\), qui vaut \( \xi_k\). Au final nous avons :
    \begin{equation}
        \langle x, u_k\rangle =\sum_{i\in I}\Phi_{u_k}(\xi_iu_i)=\xi_k.
    \end{equation}
\end{proof}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Base hilbertienne}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}      \label{DEFooADQXooFoIhTG}
    Une \defe{base orthonormée}{base!espace préhilbertien} est une famille dénombrable orthonormé et totale\footnote{Définition \ref{DEFooQVPHooJaSWyF}}. Cela sera souvent aussi appelé une \defe{base hilbertienne}{base!hilbertienne}.
\end{definition}

\begin{normaltext}
    Cette définition demande quelque remarques.

    \begin{enumerate}
        \item
            La notion de base hilbertienne pas la même notion de base qu'en algèbre. En effet pour avoir une base algébrique d'un espace vectoriel, nous demandons que les éléments soient des combinaisons linéaires \emph{finies} des éléments de la base, tandis qu'ici en demandant que la partie soit totale nous demandons simplement que les combinaisons linéaires finies soient denses.
        \item
            Nous allons voir qu'un espace de Hilbert est généré par les sommes \emph{infinies} de vecteurs d'une base hilbertienne avec des coefficients qui forment une suite dans \( \ell^2\).
        \item
            Nous ne demandons pas que la famille soit libre ? La belle affaire. Une famille orthogonale est toujours libre, proposition \ref{PROPooMOQRooCPFnPC}.
    \end{enumerate}
\end{normaltext}

\begin{lemma}[\cite{ooTANJooWqWHPb}]       \label{LEMooHWOBooQJKdTD}
    Si \( \mE\) est une base hilbertienne\footnote{Définition \ref{DEFooADQXooFoIhTG}.} de l'espace de Hilbert \( \hH\) et si \( x\in \hH\) alors l'ensemble
    \begin{equation}
        \{ e\in\mE\tq \langle x, e\rangle \neq 0 \}
    \end{equation}
    est au plus dénombrable.
\end{lemma}

\begin{proof}
    Notons qu'ici, \( \hH\) n'est pas supposé séparable. Nous savons par l'inégalité de Bessel \eqref{EQooWCYZooOPzGaw} que
    \begin{equation}
        \sum_{e\in\mE}| \langle x, e\rangle  |^2\leq \| x \|^2.
    \end{equation}
    Donc si \( \epsilon>0\) est donné, l'ensemble \( \{ e\in \mE\tq| \langle x, e\rangle  |>\epsilon \}\) est fini. Or
    \begin{equation}
        \{ e\in\mE\tq \langle x, e\rangle \neq 0  \}=\{ e\in\mE\tq| \langle x, e\rangle  |>0 \}=\bigcup_{n=1}^{\infty}\{ e\in\mE\tq | \langle x, e\rangle  |>\frac{1}{ n } \}.
    \end{equation}
    Bref, cet ensemble est une union dénombrable d'ensembles finis. Il est donc dénombrable.
\end{proof}

\begin{remark}
    Le lemme \ref{LEMooHWOBooQJKdTD} ne signifie pas que la base \( \mE\) doive être dénombrable. Il signifie seulement que pour chaque \( x\) séparément, seule une partie dénombrable de \( \mE\) est nécessaire.
\end{remark}

\begin{corollary}[\cite{ooTANJooWqWHPb}]       \label{CORooFROTooNupAQs}
    Si un espace de Hilbert possède une base hilbertienne dénombrable, alors toutes ses bases hilbertiennes sont dénombrables.
\end{corollary}

\begin{proof}
    Soient \( \mE\) et \( \mF\) des bases hilbertiennes de l'espace de Hilbert \( \hH\), en supposant que \( \mE\) soit dénombrable. Pour chaque \( f\in \mF\) nous avons \( \langle f, e\rangle \neq 0\) pour au moins un \( e\in\mE\), sinon en vertu de la décomposition \eqref{EqitrzXi} de \( f\) dans la base \( \mE\), nous aurions \( f=0\). Nous avons donc
    \begin{equation}    \label{EQooKRTFooNABXnH}
        \mF\subset\bigcup_{e\in \mE}\{ f\in\mF\tq \langle f, e\rangle \neq 0 \},
    \end{equation}
    alors que le lemme \ref{LEMooHWOBooQJKdTD} indique que chacun des ensembles de l'union est au plus dénombrable. La partie \( \mF\) est donc une union dénombrable d'ensemble dénombrables. Elle est dénombrable.
\end{proof}

\begin{remark}
    En travaillant un peu plus sur la notion de cardinalité, le corollaire \ref{CORooFROTooNupAQs} indique que toutes les bases hilbertiennes ont même cardinalité. En effet en laissant tomber l'hypothèse de dénombrabilité sur \( \mE\), l'inclusion \eqref{EQooKRTFooNABXnH} donne que \( \mF\) est une union de \( \Card(\mE)\) ensembles dénombrables et est alors de cardinalité \( \Card(\mE)\).
\end{remark}

\begin{definition}      \label{DEFooRFATooDRKWoJ}
    Une partie orthonormale \( B\) est \defe{maximale}{maximale!partie orthonormale} si le seul \( x\in \hH\) vérifiant \( \langle x, b\rangle =0\) pour tout \( b\in B\) est \( x=0\).
\end{definition}

\begin{lemma}[\cite{MonCerveau,ooLJORooJwbHlx}]\label{LEMooXIECooCAQeJN}
    Tout espace de Hilbert possède une partie orthonormale maximale.
\end{lemma}

\begin{proof}
    Soit \( \hH\) un espace de Hilbert et \( \mO\), l'ensemble de parties orthonormales de \( \hH\), ordonné\footnote{Définition \ref{DefooFLYOooRaGYRk}.} par l'inclusion. Cet ensemble est inductif. En effet soit une partie totalement ordonnée \( \{ A_i \}_{i\in I}\) de \( \mO\) : chaque \( A_i\) est une partie orthonormale de \( \hH\), et de plus pour \( i,j\in I\) nous avons soit \( A_i\subset A_j\) soit \( A_j\subset A_i\). Nous pouvons considérer
    \begin{equation}
        A=\bigcup_{i\in I}A_i.
    \end{equation}
    Cela est encore une partie orthonormé de \( \hH\) parce que si \( x,y\in A\), alors il existe \( i,j\in I\) tels que \( x\in A_i\) et \( y\in A_j\). Vu que \( \{ A_i \}_{i\in I}\) est totalement ordonné nous supposons pour fixer les idées que \( A_i\subset A_j\). Alors \(x \) et \( y\) sont dans \( A_j\) qui est une partie orthonormée; nous en déduisons que \( \langle x, y\rangle =0\) et donc que \( A\) est une partie orthonormée. C'est à dire : \( A\in \mO\). Par ailleurs, \( A\) est un majorant de \( \{ A_i \}_{i\in I}\) pour l'inclusion parce que \( A_i\subset A\) pour tout \( i\).

    Nous avons prouvé que \( \mO\) est un ensemble inductif. Le lemme de Zorn \ref{LemUEGjJBc} nous dit alors que \( \mO\) possède un maximum. Ce maximum est une partie orthonormale inclue dans aucune autre partie orthonormale. C'est à dire que ce maximum est une partie orthonormale maximale au sens de la définition \ref{DEFooRFATooDRKWoJ}.
\end{proof}

\begin{proposition}[\cite{ooLJORooJwbHlx}]      \label{PROPooENTIooIplRAS}
    Si un espace de Hilbert possède une partie orthonormale maximale dénombrable, alors toutes les parties orthonormales sont dénombrables (ou finies).
\end{proposition}

\begin{proof}
    Soit \( B\) une partie orthonormale maximale, et \( A\) une partie orthonormale. Pour chaque \( b\in B\) nous notons
    \begin{equation}
        A(b)=\{ a\in A\tq \langle a, b\rangle \neq 0 \}\cup\{ 0 \}.
    \end{equation}
    Un élément de \( A\) qui ne serait dans aucun des \( A(b)\) serait perpendiculaire à tous les éléments de \( B\), et serait donc l'élément nul. Mais l'élément nul est dans tous les \( A(b)\); donc nous avons
    \begin{equation}
        A\subset\bigcup_{b\in B}A(b).
    \end{equation}
    Or par l'inégalité de Bessel, l'ensemble \( A(b)\) est dénombrable. Par conséquent \( A\) est inclus dans une union dénombrable d'ensembles dénombrables; \( A\) est dénombrable.
\end{proof}

Le fait que tout espace de Hilbert possède une base hilbertienne est vrai. Nous allons démontrer ce résultat d'abord pour les espaces séparables et ensuite, indépendamment, en général. Si vous vous la sentez de maîtriser la proposition \ref{PROPooLDXFooRaxBsI}, vous pouvez sauter la \ref{PROPooDRFBooWTcunC}.
\begin{proposition}     \label{PROPooDRFBooWTcunC}
    Tout espace de Hilbert séparable possède une bases hilbertienne.
\end{proposition}

\begin{proof}
    Vu que nous supposons avoir un espace de Hilbert séparable, il possède une partie totale dénombrable par la proposition \ref{PROPooZMWHooVwvNBY}. Soit  \( (v_n)_{n\in \eN}\) une telle partie. Quitte à supprimer les \( v_i\) qui sont combinaisons linéaires des précédents, nous pouvons supposer que cette partie est libre. Nous considérons l'espace vectoriel
    \begin{equation}
        F_n=\Span\{ v_1,\ldots, v_n \}.
    \end{equation}
    Sur \( F_n\) nous pouvons appliquer un procédé de Gram-Schmidt pour construire une base orthonormée \( \{ u_1,\ldots, u_n \}\) de \( F_n\) au sens usuel. En considérant \( F_{n+1}\) et en recommençant, les vecteurs \( u_1,\ldots, u_n\) ne changent pas, mais nous obtenons un vecteur \( u_{n+1}\).

    Nous construisons ainsi une suite \( (u_n)\) qui est alors orthonormée au sens des espaces de Hilbert. Nous devons encore prouver qu'il s'agit d'un ensemble total. Cela est simplement dû au fait que tout élément de \( \Span\{ v_n \}\) est contenu dans \( \Span\{ u_n \}\) parce que \( \Span\) ne considère que des combinaisons linéaires finies.
\end{proof}

\begin{proposition}[\cite{ooLJORooJwbHlx}]      \label{PROPooLDXFooRaxBsI}
    À propos de parties orthonormales maximales.
    \begin{enumerate}
        \item
            Une partie d'un espace de Hilbert est orthonormale maximale si et seulement si elle est une base hilbertienne.
        \item       \label{ITEMooZFENooQnSlrv}
            Tout espace de Hilbert possède une base hilbertienne.
    \end{enumerate}
\end{proposition}

\begin{proof}
    Soit une partie orthonormale maximale \( B\) et la fermeture de son espace engendré : \( F=\overline{ \Span(B) }\). Pour que \( B\) soit une base, nous devons démontrer que \( F=\hH\). Pour cela nous considérons \( x\in \hH\) et nous utilisons le théorème de projection orthogonale \ref{ThoMXwOjb} pour mentionner le fait que 
    \begin{equation}
        x-\pr_F(x)\perp F
    \end{equation}
    Cela dit que \( x-\pr_F(x)\) est un vecteur orthogonal en particulier à tous les éléments de \( B\); par maximalité nous avons \( x-\pr_F(x)=0\), c'est à dire \( x=\pr_F(x)\) ou encore \( x\in F\). Cela prouve que \( F=\hH\).

    Note : pour être pointilleux, nous aurions dû travailler non avec \( x-\pr_F(x)\), mais avec le vecteur normalisé à \( 1\).

    En ce qui concerne le second point, nous invoquons le lemme \ref{LEMooXIECooCAQeJN} pour dire que tout espace de Hilbert possède une partie orthonormale maximale. Ensuite la première partie de cette proposition nous dit que cette dernière est une base hilbertienne.
\end{proof}

Voici un petit résumé de ce que nous avons vu en termes de dénombrabilité et séparabilité.
\begin{theorem}     \label{THOooMKNFooVrCNGA}
    Pour un espace de Hilbert, les choses suivantes sont équivalentes.
    \begin{enumerate}
        \item       \label{ITEMooSJKVooFIIbwg}
            L'espace est séparable\footnote{Définition \ref{DEFooSFOJooGICSbT}.}.
        \item       \label{ITEMooQIZLooYdtYqF}
            L'espace possède au moins une base hilbertienne\footnote{Définition \ref{DEFooADQXooFoIhTG}.} dénombrable.
        \item       \label{ITEMooHYSXooOubwUy}
            Toutes les bases hilbertiennes sont dénombrables.
        \item       \label{ITEMooMZICooNBAVum}
            Toute partie libre est dénombrable.
    \end{enumerate}
\end{theorem}

\begin{proof}
    Plein de résultats à citer \ldots
    \begin{subproof}
        \item[\ref{ITEMooSJKVooFIIbwg} implique \ref{ITEMooQIZLooYdtYqF}]

            est la proposition \ref{PROPooDRFBooWTcunC}.

    \item[\ref{ITEMooQIZLooYdtYqF} implique \ref{ITEMooHYSXooOubwUy}]
         
        est la proposition \ref{CORooFROTooNupAQs}.


    \item[\ref{ITEMooHYSXooOubwUy} implique \ref{ITEMooMZICooNBAVum}]

        Le procédé de Gram-Schmidt met en bijection une partie libre avec une partie orthonormale (qui engendre le même espace, mais c'est une autre affaire). Or lorsque l'espace de Hilbert possède une base dénombrable, toutes les parties orthonormales sont dénombrables par la proposition \ref{PROPooENTIooIplRAS}.

    \item[\ref{ITEMooMZICooNBAVum} implique \ref{ITEMooSJKVooFIIbwg}]
        Tout espace de Hilbert possède des bases hilbertiennes par la proposition \ref{PROPooLDXFooRaxBsI}\ref{ITEMooZFENooQnSlrv}. Une telle base est forcément une partie libre parce que toute famille orthonormale est libre (proposition \ref{PROPooMOQRooCPFnPC}), et donc dénombrable par hypothèse. À ce point nous avons montré que notre espace de Hilbert possédait une base hilbertienne dénombrable. Cela implique qu'il est séparable par la proposition \ref{PROPooZMWHooVwvNBY}.
        \end{subproof}
\end{proof}

\begin{remark}  \label{RemfdJcQF}
    À mon avis il doit exister un théorème de complétion de base hilbertienne disant que si on a une famille orthonormée, alors elle se prolonge en base. Utilisant cela, nous trouvons une nouvelle démonstration de la proposition \ref{PropHKqVHj} en disant que la somme sur la «partie de base» est plus petite que la somme sur la «base complète».
\end{remark}

\begin{normaltext}
    Vu que nous n'avons l'intention de ne travailler qu'avec des espaces de Hilbert séparables et que toutes leurs bases sont dénombrables, nous n'allons travailler qu'avec des bases dénombrables, et donc des systèmes orthonormés dénombrables. Nous allons conventionnellement les indicer par \( \eN\).
\end{normaltext}

La proposition suivante explique que la notion de projection est compatible avec la décomposition d'un vecteur dans un système orthonormé.
\begin{proposition}
    Soit \( (u_k)_{k\geq 1}\) un système orthonormé d'un préhilbert \( \hH\). Soient 
    \begin{equation}
        x=\sum_{k=1}^{\infty}\xi_ku_k
    \end{equation}
    et
    \begin{equation}
        F=\Span\{ u_1,\ldots, u_n \}.
    \end{equation}
    Alors 
    \begin{equation}
        \pr_F(x)=\sum_{k=1}^n\xi_ku_k.
    \end{equation}
\end{proposition}

\begin{proof}
    Nous allons dans un premier temps montrer que 
    \begin{equation}
        y=x-\sum_{k=1}^n\xi_ku_k
    \end{equation}
    est dans \( F^{\perp}\). Pour cela nous calculons
    \begin{equation}
        \langle x-\sum_{k=1}^n\xi_ku_k,u_j, \rangle =\langle \sum_{k=n+1}^{\infty}\xi_ku_k, u_j\rangle =0
    \end{equation}
    où nous avons utilisé la continuité du produit scalaire pour permuter la somme (infinie) et le produit. Étant donné que \( y\in F^{\perp}\) nous avons \( \pr_Fy=0\) par le point \ref{ItemThowZyaizii} du théorème \ref{ThowZyaiz}.

    D'autre part \( \pr_Fy\) peut être calculé selon
    \begin{equation}
        \pr_Fy=\pr_Fx-\sum_{k=1}^n\xi_k\pr_Fu_k
    \end{equation}
    tandis que \( \pr_Fu_k=u_k\) lorsque \( 1\leq k\leq n\). Par conséquent l'annulation de \( \pr_Fy\) donne
    \begin{equation}
        \pr_Fx=\sum_{k=1}^n\xi_ku_k,
    \end{equation}
    donc le résultat.
\end{proof}

\begin{theorem}[Meilleur approximation] \label{ThooRArDp}
    Soit \( \{ u_i \}_{i\in I}\) une famille orthonormé de l'espace de Hilbert \( \hH\). Alors pour tout \( x\in \hH\) et pour tout \( J\) fini dans \( I\) et pour toute famille de nombres complexes  \( (a_j)_{j\in J}\) nous avons
    \begin{equation}
        \| \sum_{j\in J}\langle x, u_j\rangle u_j-x \|\leq \| \sum_{j\in J}a_ju_j-x \|.
    \end{equation}
\end{theorem}
Ce théorème exprime le fait que les nombres \( \langle x, u_i\rangle \) sont les meilleurs coefficients à mettre devant les \( u_i\) pour approximer \( x\).

\begin{corollary}
    Soit \( \{ u_i \}_{i\in I}\) une famille orthonormé de \( \hH\). Pour tout \( x\in \hH\) et pour toutes parties finies \( J,K\) de \( I\) avec \( J\subset K\) nous avons
    \begin{equation}
        \| \sum_{j\in K}\langle x, u_j\rangle u_j-x \|\leq \| \sum_{j\in J}\langle x, u_j\rangle u_j-x \|.
    \end{equation}
\end{corollary}
Ce corollaire exprime le fait que plus on prend de termes de la forme \( \langle , u_i\rangle u_i\), mieux c'est.

\begin{proposition}     \label{PropzaKXHq}
    Soit \( \hH\) un espace de Hilbert et \( (u_n)\) un système orthonormé dans \( \hH\). Si \( (\xi_n)_{n\in \eN}\) est une suite dans \( \ell^2\) alors la série 
    \begin{equation}
        \sum_{n=1}^{\infty}\xi_nu_n
    \end{equation}
    converge dans \( \hH\).

    Autrement dit l'application
    \begin{equation}
        \begin{aligned}
            S\colon \hH&\to \ell^2 \\
            x&\mapsto \big( \langle x, u_n\rangle  \big)_{n\geq 1} 
        \end{aligned}
    \end{equation}
    est surjective.
\end{proposition}

\begin{proof}
    Nous allons montrer que la série \( \sum_{n=1}^{\infty}\xi_nu_n\) est de Cauchy, c'est à dire que la limite
    \begin{equation}
        \lim_{n\to \infty} \big\| \sum_{k=n}^{n+p}\xi_ku_k \big\|=0
    \end{equation}
    est uniforme en \( p\). Cela est un corollaire de la formule \eqref{EqCLQbMy} parce que
    \begin{equation}
        \big\| \sum_{k=n}^{n+p}\xi_ku_k \big\|^2=\sum_{k=n}^{n+p}| x_k |^2.
    \end{equation}
    Mais si \( (\xi_n)\) est dans \( \ell^2\), pour tout \( \epsilon\), il existe \( N\) tel que si \( n>N\) alors le membre de droite est inférieur à \( \epsilon\) indépendamment de \( p\).
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Décomposition dans une base hilbertienne}
%---------------------------------------------------------------------------------------------------------------------------

Étant donné une base hilbertienne de \( \hH\), nous notons
\begin{equation}
    c_k(x)=\langle x, u_k\rangle .
\end{equation}
Dans le théorème suivant (et d'ailleurs partout), les sommes sur \( I\) sont prises au sens de la définition \ref{DefIkoheE}.


\begin{theorem}[Décomposition dans une base orthogonale]     \label{ThoyAjoqP}
    Soit \( \hH\) un espace de Hilbert séparable \( \{ u_i \}_{i\in I}\) une base orthonormée (\( I\) est un ensemble dénombrable quelconque). 

    \begin{enumerate}
        \item \label{ItemQGwoIxi}
            Pour tout \( x\in \hH\) nous avons
            \begin{equation}        \label{EqPUPTXJ}
                x=\sum_{i\in I}\langle x, u_i\rangle u_i
            \end{equation}
            où la somme est prise au sens de la définition \ref{DefIkoheE}. En particulier, la somme converge de façon commutative.

        \item

            Si \( \{ e_i \}_{i\in I}\) est une famille orthonormée qui satisfait la décomposition \eqref{EqPUPTXJ} pour tout \( x\in \hH\) alors \( \{ e_i \}\) est une base hilbertienne.
        \item
            Nous avons l'identité de \defe{Plancherel}{Plancherel}
            \begin{equation}
                \| x \|^2=\sum_{i\in I}| \langle x, u_i\rangle  |^2.
            \end{equation}
            Le point \ref{ItemQGwoIx} nous indiquera que cette égalité est en fait suffisante pour dire que nous avons une base.
        \item
            Nous avons l'identité de \defe{Parseval}{Parseval}
            \begin{equation}    \label{EqHZxjtKt}
                \langle x, y\rangle =\sum_{i\in I}\langle x, u_i\rangle \overline{ \langle y, u_i\rangle  }.
            \end{equation}
        \item   \label{ItemQGwoIx}
            Si \( \{ e_i \}\) est une famille de vecteurs unitaires vérifiant l'identité de Plancherel, alors c'est une base hilbertienne.
        \item
            Si \( \{ u_i \}_{i\in I}\) est une base hilbertienne, la suite \( n\mapsto| \langle x, e_n\rangle  |\) appartient à \( \ell^2(I)\).
    \end{enumerate}
\end{theorem}

\begin{proof}
    \begin{enumerate}
        \item
            Étant donné que le système \( \{ u_i \}_{i\in I}\) est total, nous pouvons considérer une suite de combinaisons linéaires finies des \( u_i\) qui converge vers \( x\). Nous écrivons
            \begin{equation}
                x_n=\sum_{x\in J_n}a_{n,k}u_j
            \end{equation}
            et \( x_n\to x\) dans \( \hH\). Les ensembles \( J_n\) sont des sous-ensembles finis de \( I\). Nous pouvons les choisir de telle sorte que \( J_n\subset J_{n+1}\) et \( \bigcup_{n\in \eN}J_n=I\). Ce choix correspond à éventuellement prendre \( a_{n,j}=0\) pour toutes les valeurs de \( j\) «en trop».

            Soit \( \epsilon>0\) et \( N\) tel que \( \| x_n-x \|<\epsilon\) pour tout \( n\geq N\). Nous allons montrer que pour tout \( J\) fini tel que \( J_N\subset J\) nous avons \( \| \sum_{j\in J}\langle x, u_j\rangle u_j-x \|<\epsilon\). Étant donné que
            \begin{equation}
                \sum_{j\in J_N}\langle x, u_j\rangle u_j=\sum_{j\in J}a_ju_j
            \end{equation}
            avec
            \begin{equation}
                a_j=\begin{cases}
                    \langle x, u_j\rangle     &   \text{si } j\in J_N\\
                    0    &    \text{sinon},
                \end{cases}
            \end{equation}
            le théorème de meilleure approximation \ref{ThooRArDp} nous enseigne que
            \begin{equation}
                \| \sum_{j\in J}\langle x, u_j\rangle u_j-x \|\leq\| \sum_{j\in J_N}\langle x, u_j\rangle u_j-x \|<\epsilon
            \end{equation}
            par conséquent la somme \( \sum_{i\in I}\langle x, u_i\rangle u_i\) converge vers \( x\) au sens général, et en particulier commutativement.

    Les sommes étant commutatives (en particulier \( x=\sum_{i\in I}\langle x, u_i\rangle u_i\)), et les bases hilbertiennes étant dénombrables, nous ne perdons aucune généralité en ne considérant que des bases indexées par \( \eN\).

        \item
            Nous devons montrer que l'ensemble des combinaisons linéaires finies est dense dans \( \hH\). Par hypothèse, pour tout \( \epsilon\), il existe un ensemble fini \( J\) tel que
            \begin{equation}
                \| \sum_{j\in J}\langle x, u_j\rangle u_j-x \|<\epsilon.
            \end{equation}
            Cela prouve la densité dont nous avions besoin.
        \item
            La norme étant une fonction continue, elle commute avec les sommes infinies, de telle sorte que l'égalité de Plancherel donne
            \begin{equation}
                \| x \|^2=\| \sum_{i\in I}\langle x, u_i\rangle u_i \|^2.
            \end{equation}
            Le système des \( u_i\) étant orthonormé,
            \begin{equation}
                \| x \|^2=\| \sum_{i\in I}\langle x, u_i\rangle u_i \|^2=\sum_{i\in I}| \langle x, u_i\rangle  |^2.
            \end{equation}
        \item
            Au tour de \wikipedia{fr}{Perceval}{Parseval}. Nous commençons par prouver que la somme du membre de droite converge. En utilisant l'inégalité \( | zz' |\leq | z |^2+| z' |^2\) (valable pour \( z,z'\in \eC\)) et Plancherel, nous avons
            \begin{equation}
                \begin{aligned}[]
                    \sum_{i\in I}| \langle x, u_i\rangle \overline{ \langle y, u_i\rangle  } |&\leq\sum_{i\in I}| \langle x, u_i\rangle  |^2+| \langle y, u_i\rangle  |^2\\
                    &\leq \| x \|^2+\| y \|^2.
                \end{aligned}
            \end{equation}
            Nous en déduisons que la famille \( \langle x, u_i\rangle \overline{ \langle y, u_i\rangle  }\) est (commutativement) sommable en utilisant la proposition \ref{PropMpBStL}. Par ailleurs nous savons que
            \begin{subequations}
                \begin{align}
                    x=\sum_{i\in I}c_i(x)u_i\\
                    y=\sum_{i\in I}c_i(y)u_i,
                \end{align}
            \end{subequations}
           et le produit scalaire étant une forme bilinéaire continue,
           \begin{subequations}
               \begin{align}
                   \langle x, y\rangle &=\sum_{i\in I}\sum_{j\in I}\langle c_i(x)u_i, \overline{ c_j(y)u_j }\rangle \\
                   &=\sum_{i\in I}\sum_{j\in J}c_i(x)\overline{ c_j(y) }\delta_{ij}\\
                   &=\sum_{i\in I}c_i(x)\overline{ c_j(y) }.
               \end{align}
           \end{subequations}
       \item
            Nous utilisons l'égalité de Plancherel avec \( x=u_j\) :
            \begin{equation}
                \| u_j \|^2=\| u_j \|+\sum_{i\in I\setminus\{ j \}}| \langle u_j, u_i\rangle  |^2.
            \end{equation}
            Par conséquent \( \langle u_j, u_i\rangle =0\) dès que \( i\neq j\). Cela prouve que le système \( \{ u_i \}_{i\in I}\) est orthonormé.

            Nous devons encore prouver que le système est total. Pour cela nous repartons de l'équation \eqref{EqvwXWEA} que nous avions déduites dans la démonstration de l'inégalité de Bessel :
    \begin{equation}
        \| x-\sum_{j\in J}c_j(x)u_j \|=\| x \|^2-\sum_{j\in J}| c_j(x) |^2.
    \end{equation}
    Par hypothèse le membre de droite peut être rendu aussi petit que l'on veut en prenant \( J\) grand (mais fini) dans \( I\). Le membre de gauche indique alors que le système \( \{ u_i \}_{i\in I}\) est total.

\item
    L'identité de Plancherel signifie entre autres que si \( x\in \hH\) alors \( \sum_{i\in I}| \langle x, u_i\rangle  |^2\) converge. Du coup la suite \( (\langle x, u_i\rangle )_{i\in I}\) est dans \( \ell^2(I)\).
    \end{enumerate}
\end{proof}

    
\begin{remark}
    Nous avons décidé d'indexer les bases hilbertiennes par \( \eN\); cela est légitime parce que les sommes sont commutatives. Il ne faut cependant pas perdre de vue qu'en pratique l'ensemble naturel avec lequel on indexe une base est parfois \( \eZ\). Un tel cas est donné par la base trigonométrique de \( L^2\). Indexer cette dernière par \( \eN\) plutôt que par \( \eZ\) serait une contorsion inutile.
\end{remark}

\begin{remark}
    L'égalité de Parseval est la raison pour laquelle les physiciens écrivent souvent
    \begin{equation}
        \id=\sum_{n=1}^{\infty}|u_n\rangle\langle u_n|
    \end{equation}
    dans les livres de mécanique quantique par exemple. Dans certains, nous lisons même 
    \begin{equation}
        \int_{-\infty}^{+\infty}dq|q\rangle\langle q| =\hat I.
    \end{equation}
    Notons que ces personnes travaillent avec un espace de Hilbert dont la base n'est pas dénombrable. Pour dire que la physique, ça n'utilise pas des mathématiques pour rire !
\end{remark}

% TODO : cette remarque devrait être plus haut.
\begin{remark}
    Par définition une base orthonormée est donc une partie dénombrable dont l'espace vectoriel engendré est dense. Un espace de Hilbert possédant une base orthonormée est donc séparable. C'est ce fait qui nous pousse à ne considérer que des espaces de Hilbert séparables; nous n'allons donc pas étudier ce qu'il se passerait par exemple en considérant l'espace vectoriel librement engendré par les éléments de \( \eR\).
\end{remark}

%TODO : cet exemple devrait se trouver avec le reste de L^2(0,2\pi).
\begin{example}
    L'identité de Parseval \eqref{EqHZxjtKt}, dans le cas de l'espace des fonctions continues périodiques de période \( 2\pi\) signifie qu'en posant 
    \begin{equation}
        c_n(f)=\frac{1}{ 2\pi }\int_0^{2\pi}f(s) e^{-ins},
    \end{equation}
    nous avons
    \begin{equation}    \label{EqMIuCSfz}
        \frac{1}{ 2\pi }\int_0^{2\pi}| f(s) |^2=\sum_{n=-\infty}^{\infty}| c_n(f) |^2.
    \end{equation}
\end{example}

\begin{corollary}       \label{CorQETwUdF}
    Soit \( \hH\) un espace de Hilbert et \( (u_n)\) une base orthonormée. L'application
    \begin{equation}
        \begin{aligned}
            S\colon \hH&\to \ell^2 \\
            x&\mapsto \big( \langle x, u_n\rangle  \big)_{n\in \eN} 
        \end{aligned}
    \end{equation}
    est un isomorphisme d'espaces de Hilbert.

    De plus l'isomorphisme réciproque est
    \begin{equation}
        \begin{aligned}
            S^{-1}\colon \ell^2&\to \hH \\
            (\xi_n)&\mapsto \sum_{n=1}^{\infty}\xi_nu_n. 
        \end{aligned}
    \end{equation}
\end{corollary}

\begin{proof}
    Nous devons prouver que l'application est bijective et qu'elle vérifie
    \begin{equation}
        S(x)\cdot S(y)=\langle x, y\rangle 
    \end{equation}
    où le point dénote le produit dans \( \ell^2\).

    Pour la surjectivité, si \( (\xi_n)\in \ell^2\) alors nous savons que la somme \( \sum_n\xi_nu_n\) converge par la proposition \ref{PropzaKXHq} et par conséquent \( (\xi_n)\) est l'image par \( S\) de ce vecteur de \( \hH\).

    Pour l'injectivité, si \( S(x)=S(y)\) alors
    \begin{equation}
        x=\sum_n\langle x, u_n\rangle u_n=\sum_n\langle y, u_n\rangle u_n=y
    \end{equation}
    en utilisant la décomposition \eqref{EqPUPTXJ}.

    Le fait que \( S\) soit une isométrie est contenu dans Parseval.
\end{proof}

\begin{proposition}[\cite{MonCerveau}]      \label{PROPooPVQIooPcEFSe}
    Soit un espace de Hilbert séparable \( \hH\), un sous-espace vectoriel fermé \( V\) et une base orthonormée \( \{ b_i \}_{i\in I}\) de \( \hH\). En posant \( v_i=\pr_V(b_i)\) alors
    \begin{equation}
        C=\overline{ \Span\{ b_i-v_i \} }
    \end{equation}
    est l'orthogonal de \( V\).
\end{proposition}

\begin{proof}
    Juste pour rappel, lorsque nous écrivons \( v_i=\pr_V(b_i)\), nous parlons de la projection orthogonale du théorème \ref{ThoMXwOjb}. Donc tous les vecteurs \( b_i-v_i\) sont dans \( V^{\perp}\). En passant aux limites, \( C\subset V^{\perp}\).

    Soit \( x\in V^{\perp}\) que nous décomposons dans la base \( \{ b_i \}_{i\in I}\) comme \( x=\sum_{i\in I}x_ib_i\). Posons \( c_i=b_i-v_i=b_i-\pr_V(b_i)\). Alors d'une part
    \begin{equation}
        0=\pr_V(x)=\sum_ix_i\pr_V(b_i)=\sum_ix_i(b_i-c_i).
    \end{equation}
    Nous avons utilisé la continuité de \( \pr_V\) pour permuter avec la somme. D'autre part,
    \begin{equation}
        x=\sum_ix_ib_i=\sum_ix_i(b_i-c_i+c_i)=\underbrace{\sum_ix_i(b_i-c_i)}_{=0}+\sum_ix_ic_i\in C.
    \end{equation}
    Notons que pour la dernière appartenance, il est important de prendre la fermeture pour définir \( C\).
\end{proof}

\begin{proposition}[\cite{MonCerveau,ooBBNWooHJPWci}]
    Toute partie orthonormée d'un espace de Hilbert séparable se prolonge en une base hilbertienne.
\end{proposition}

\begin{proof}
    Soit une partie orthonormée \( \{ u_i \}_{i\in I}\) de l'espace de Hilbert \( \hH\). Nous mentionnons que cette partie est libre et donc, par le théorème \ref{THOooMKNFooVrCNGA}, dénombrable\footnote{Avec un peu de mauvaise foi, vous pouvez quand même dire que cela n'implique pas que \( I\) lui-même soit dénombrable, mais vous pouvez le supposer pour fixer les idées.}.  Montrons pour commencer que la partie \( V=\overline{\Span\{ u_i \}_{i\in I}}\) est un sous-espace vectoriel fermé de \( \hH\).
    \begin{subproof}
        \item[Vectoriel] Soit \( v,w\in V\) et \( \epsilon>0\). Il existe \( a\in \Span\{ u_i \}\) tel que \( \| a-v \|<\epsilon\) et \( b\in \Span\{ u_i \}\) tel que \( \| b-w \|<\epsilon\). Dans ce cas,
            \begin{equation}
                \| v+w-(a+b) \|\leq 2\epsilon.
            \end{equation}
            Cela prouve que \( v+w\in V\). Nous procédons de même pour \( \lambda v\).
        \item[Fermé] Par construction.
    \end{subproof}

    L'orthogonal\footnote{Voir la définition \ref{DEFooXUXQooMmDnhW} et la proposition \ref{PROPooPVQIooPcEFSe}.} de \( V\) est un sous-espace vectoriel de \( \hH\), et nous pouvons donc en considérer une base hilbertienne \( C=\{ c_{\alpha} \}_{\alpha\in A}\). Nous prétendons que \( C\cup U\) est une base hilbertienne\footnote{Définition \ref{DEFooADQXooFoIhTG}.} de \( \hH\).
    \begin{subproof}
        \item[\( C\cup U\) est libre]
            Bing ! Il ne faut pas le démontrer : ça ne fait pas partie de la définition d'une base hilbertienne.
        \item[\( C\cup U\) est générateur]
            Bang ! Il ne faut pas le démontrer : ça ne fait pas partie de la définition d'une base hilbertienne.
        \item[\( C\cup U\) est orthogonal]
            Ah, voila quelque chose à démontrer. Nous devons vérifier que les produits sont nuls. Soient \( u,v\in U\) et \( a,b\in C\). Nous avons :
            \begin{itemize}
                \item \( \langle u, v\rangle =0\) par hypothèse.
                \item \( \langle u, a\rangle =0\) parce que les éléments de \( C\) sont orthogonaux à \( V\) et que \( u_i\in V\).
                \item \( \langle a, b\rangle =0\) parce que \( C\) est une base hilbertienne de \( V^{\perp}\).
            \end{itemize}

        \item[\( C\cup U\) est dénombrable]

            L'ensemble \( C\) est dénombrable parce que c'est une base hilbertienne. Quant à \( \{ u_i \}_{i\in I}\), nous avons déjà mentionné le fait qu'il doive être dénombrable. L'union deux parties dénombrables est dénombrable.

        \item[\( C\cup U\) est total]

            Nous devons prouver que \( \overline{ \Span(C\cup U) }=\hH\) parce qu'il y a bien la fermeture qui intervient dans la définition \ref{DEFooQVPHooJaSWyF}. Pour cela nous utilisons la proposition \ref{PropqiWonByiBmc}.
            Si \( x\in \hH\) alors nous avons 
           \begin{equation}
               x=\pr_V(x)+\big( x-\pr_V(x) \big)=\sum_{i\in I}x_iu_i+\sum_{\alpha\in A}x_{\alpha}c_{\alpha}
           \end{equation}
           pour des coefficients \( x_i\) et \( x_{\alpha}\). Notons que \( I\) et \( A\) sont deux ensembles différents. Aucun des \( x_{\alpha}\) n'est un des \( x_i\), ni inversement. Supposons que \( x\in \Span(C\cup U)^{\perp}\); alors
           \begin{equation}
               0=\langle x, u_j\rangle =\sum_{i\in I}x_i\underbrace{\langle u_i, u_j\rangle }_{=\delta_{ij}}+\sum_{\alpha\in A}\underbrace{\langle c_{\alpha}, u_j\rangle }_{=0}=x_j.
           \end{equation}
           Donc \( x_j=0\). En faisant de même avec \( 0=\langle x, c_{\beta}\rangle =x_{\beta}\) nous déduisons \( x=0\).

    \end{subproof}
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Digression sur les normes opérateurs}
%---------------------------------------------------------------------------------------------------------------------------
\label{subsecaeSywF}

Le théorème \ref{ThoyAjoqP} nous indique que si \( \{ u_i \}_{i\in I}\) est une base hilbertienne, alors pour tout \( x\in \hH\) nous avons
\begin{equation}
    \pr_{u_i}(x)=\langle x, u_i\rangle u_i,
\end{equation}
et donc
\begin{equation}
    \sum_{i\in I}\pr_{u_i}x=x.
\end{equation}
Nous ne pouvons cependant pas conclure que
\begin{equation}    \label{EqvKDzNl}
    \sum_{i\in I}\pr_{u_i}=\id
\end{equation}
au sens de la norme opérateur de la définition \ref{DefNFYUooBZCPTr}. En effet en prenant \( I=\eN\), l'égalité \eqref{EqvKDzNl} demanderait d'avoir
\begin{equation}
    \lim_{N\to \infty} \left\| \sum_{i=1}^N\pr_{u_i}-\id \right\|_{\infty}=0,
\end{equation}
or pour tout \( N\), le vecteur \( u_{N+1}\) réalise
\begin{equation}
    \sum_{i=1}^N\pr_{u_i}(u_{N+1})-u_{N+1}=-u_{N+1}.
\end{equation}
Par conséquent pour tout \( N\) nous avons
\begin{equation}
    \sup_{\| x \|=1}\left\| \sum_{i=1}^N\pr_{u_i}x-x \right\|\geq 1.
\end{equation}
Nous ne pouvons donc pas dire
\begin{equation}
    \sum_{n=1}^{\infty}\pr_{u_i}=\id
\end{equation}
au sens de la norme opérateur.

Nous avons cependant la convergence au sens faible.
\begin{proposition}
    Soit \( \hH\) un espace de Hilbert et \( \{ u_i \}_{i\in \eN}\) une base hilbertienne de \( \hH\). Au sens de la topologie faible sur l'espace des opérateurs nous avons
    \begin{equation}
        \sum_{i=1}^{\infty}\pr_{u_i}=\id.
    \end{equation}
\end{proposition}

\begin{proof}
    Pour chaque \( N\in \eN\) et \( x\in\hH\), en vertu de la décomposition \eqref{EqPUPTXJ} nous avons
    \begin{equation}
        \sum_{i=1}^N\pr_{u_i}(x)-x=\sim_{i=N+1}^{\infty}\langle x, u_i\rangle u_i.
    \end{equation}
    Par l'orthonormalité de la base nous avons
    \begin{equation}
        \sum_{i=N+1}^{\infty}\| \langle x, u_i\rangle u_i \|=\sum_{i=N+1}^{\infty}| \langle x, u_i\rangle  |,
    \end{equation}
    dont la limite \( N\to \infty\) est zéro étant donné que la suite \( i\mapsto| \langle x, u_i\rangle  |\) est dans \( \ell^2(\eR)\) par le théorème \ref{ThoyAjoqP}.
\end{proof}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Applications linéaires et continuité}
%---------------------------------------------------------------------------------------------------------------------------

Nous avons déjà vu dans l'exemple \ref{ExHKsIelG} que la fonction 
\begin{equation}    \label{EqCJVooJOuXdN}
    \begin{aligned}
        f\colon H&\to H \\
        e_k&\mapsto ke_k 
    \end{aligned}
\end{equation}
n'était pas continue en zéro alors qu'elle est linéaire. Nous allons maintenant voir qu'elle est un contre-exemple à la proposition \ref{Diff_totale}. Calculons les dérivées partielles :
\begin{equation}
    \frac{ \partial f }{ \partial e_j }(x)=\Dsdd{ f(x+te_j) }{t}{0}=\Dsdd{ \sum_k k(x_k+t\delta_{jk})e_k }{t}{0}=je_j.
\end{equation}
où nous avons permuté la somme et la dérivée en considérant la suite de fonctions \( f_k(t)=k(x_k+tu_k)e_k\). Donc \( \frac{ \partial f }{ \partial e_j }(x)\) existe et est continue sur un voisinage de \( x=0\) (c'est même constant). Nous savons pourtant que la fonction \( f\) n'est pas différentiable en zéro parce que non continue.

L'endroit qui coince dans la preuve de la proposition \ref{Diff_totale} est l'introduction des «contres-termes» dans l'équation \eqref{EqXHVooJeQKrB}. En effet les contre-termes à ajouter seraient
\begin{equation}
    l(x)=\Dsdd{ f\big( a+s(x-a) \big) }{t}{0}
\end{equation}
qui ici serait
\begin{equation}
    l\big( \sum_kx_ke_k \big)=\Dsdd{ f\big( s\sum_kx_ke_k \big) }{t}{0}=\sum_kx_ke_k,
\end{equation}
dont la convergence est plus que douteuse.

Notons que les dérivées directionnelles n'existent pas toutes, loin s'en faut : si \( u\in H\) nous avons
\begin{equation}        \label{EQooWNLOooJNRUMQ}
    \frac{ \partial f }{ \partial u }(x)=\Dsdd{ f(x+tu) }{t}{0}=\Dsdd{ \sum_k k(x_k+tu_k)e_k }{t}{0}=\sum_k ku_ke_k
\end{equation}
La convergence de la dernière somme n'est pas garantie pour tout \( u\).

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Théorème de Kochen-Specker}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Le théorème suivant est \wikipedia{fr}{Variable_cachée}{central en mécanique quantique}. La démonstration provient de \cite{BainKochen} et de \wikipedia{en}{Kochen-Specker_theorem}{Wikipédia}. Nous allons démontrer complètement le théorème seulement pour les espaces de Hilbert de dimension plus grande ou égale à \( 4\).

\begin{theorem}[Kochen-Specker\cite{BainKochen}]
    Soit \( \hH\) un espace de Hilbert de dimension plus grande ou égale à \( 3\). Une fonction \( v\) sur l'ensemble des opérateurs de \( \hH\) ne peut pas satisfaire aux conditions suivantes :
    \begin{enumerate}
        \item
            Si \( A\) et \( B\) sont compatibles, alors \( v(A+B)=v(A)+v(B)\),
        \item
            Si \( A\) et \( B\) sont compatibles, alors \( v(AB)=v(A)v(B)\).
    \end{enumerate}
    Ici nous disons que deux opérateurs sont \defe{compatibles}{opérateurs!compatibles} lorsqu'ils possèdent une base hilbertienne commune de vecteurs propres.
\end{theorem}

\begin{proof}
    Soit \( \{ u_n \}_{n\in \eN}\) une base hilbertienne de \( \hH\). Nous notons \( \pr_i\) l'opérateur de projection sur l'espace (fermé) engendré par \( u_i\). Ce sont des opérateurs compatibles deux à deux parce que la base \( \{ u_n \}_{n\in \eN}\) est une base commune de vecteurs propres\footnote{Pour les besoins de la physique, nous remarquons que ces opérateurs sont des opérateurs hermitiens qui commutent, mais ça ne joue pas ici.}.

    D'abord nous devons avoir \( v(\mtu)=1\). En effet pour tout opérateur \( A\), nous avons
    \begin{equation}
        v(A)=v(A\mtu)=v(A)v(\mtu).
    \end{equation}
    Pour peu que \( v(A)\neq 0\), cela nous fait \( v(\mtu)=1\).

    En vertu du théorème \ref{ThoyAjoqP}, un vecteur \( x\in\hH\) se décompose en \( x=\sum_n\langle x, u_n\rangle u_n\), et nous avons
    \begin{equation}    \label{EqFFuXvq}
        \pr_ix=\langle x, u_i\rangle u_i.
    \end{equation}
    En effet le théorème de la projection orthogonale \ref{ThoMXwOjb} nous enseigne que \( \pr_ix\) serait l'unique vecteur de la forme \( \lambda u_i\) tel que \( \lambda u_i-x\perp u_i\). Il est facile de vérifier que le vecteur proposé par \eqref{EqFFuXvq} vérifie cette propriété.

    Une conséquence est que
    \begin{equation}
        \left( \sum_{i=0}^{\infty}\pr_i \right)(x)=x.
    \end{equation}
    Par conséquent, par hypothèse du théorème nous devons avoir
    \begin{equation}    \label{EqUeZHJH}
        \sum_iv(\pr_i)=v(\mtu)=1.
    \end{equation}
    Étant donné que les projections sont idempotentes,
    \begin{equation}
        v(\pr_i)=v(\pr_i^2)=v(\pr_i)^2
    \end{equation}
    et donc \( v(\pr_i)\) doit valoir zéro ou un. Mais la relation \eqref{EqUeZHJH} donne une forte contrainte sur le choix de \( 0\) et de \( 1\). En effet, parmi les \( v(\pr_i)\), un et un seul doit valoir \( 1\), les autres doivent valoir \( 0\).

    Refaisant le raisonnement pour une autre base orthonormale hilbertienne, nous trouvons que les valeurs de \( v\) sur les opérateurs de projection sur les différentes directions doivent être choisies de telle façon que tout choix de base hilbertienne orthogonale contienne exactement un \( 1\) et les reste de zéros.

    Nous voudrions maintenant insister sur un point. Le problème de déterminer de façon cohérente les valeurs \( 0\) ou \( 1\) pour tous les \( v(\pr_i)\) revient à attacher \( 0\) ou \( 1\) à tous les \emph{rayons} de \( \hH\) de façon que toute base orthogonale de \( \hH\) contienne exactement un \( 1\). Un rayon est une direction, c'est à dire une classe d'équivalence \( x\sim \lambda x\). Si nous décidons de nommer «blanc»  les rayons attachés à la valeur \( 0\) et «noirs»  ceux attachés à la valeur \( 1\), le problème se réduit à colorer la boule unité de façon compatible.

    Soit \( \{ u_i \}_{i\in \eN}\) une base orthogonale de \( \hH\) numérotée de telle sorte que \( v(u_0)=1\) et \( v(u_k)=0\) pour \( k\neq 0\). Nous allons maintenant nous particulariser au cas de dimension supérieure ou égale à \( 4\). Si \( R\) est une rotation dans le plan \( \Span\{ u_0,u_1,u_2,u_3 \}\), alors l'ensemble
    \begin{equation}
        \{ Ru_0,Ru_1,Ru_2,Ru_3,u_k \}_{k\geq 3}
    \end{equation}
    est encore une base orthogonale de \( \hH\) et nous avons encore \( v(u_k)=0\) pour \( k\geq 4\). Par conséquent un et un seul des vecteurs \( Ru_0\), \( Ru_1\), \( Ru_2\) ou \( Ru_3\) est colorié en noir; les trois autres étant blancs. Le problème est maintenant complètement réduit à la dimension \( 4\). Note : pour réduire à la dimension \( 3\), on procède de même, mais pour conclure, il faut travailler plus.

    Nous allons construire \( 9\) base orthogonales de \( \eR^4\) à partir de \( 18\) vecteurs, chacun arrivant dans exactement deux des bases. Ils sont donnés dans le tableau suivant\ :


    \begin{tabular}{c|c|c|c|c|c|c|c|c}
    $\begin{matrix}
        0    &   1    \\ 
        0    &   0    
    \end{matrix}$
    &
    $\begin{matrix}
        0    &   0    \\ 
        1    &   0
    \end{matrix}$
    &
    $\begin{matrix}
        0    &   0    \\ 
        0    &   1    
    \end{matrix}$
    &
    $\begin{matrix}
        1    &   1    \\ 
        1    &   1    
    \end{matrix}$
    &
    $\begin{matrix}
        1    &   -1    \\ 
        1    &   -1    
    \end{matrix}$
    &
    $\begin{matrix}
        1    &   -1    \\ 
        -1    &   1    
    \end{matrix}$
    &
    $\begin{matrix}
        -1    &   1    \\ 
        1    &   1    
    \end{matrix}$
    &
    $\begin{matrix}
        1    &   1    \\ 
        -1    &   1    
    \end{matrix}$
    &
    $\begin{matrix}
        1    &   1    \\ 
        1    &   -1    
    \end{matrix}$\\
    \hline      
$\begin{matrix}
        0    &   0    \\ 
        0    &   1    
    \end{matrix}$
    &
    $\begin{matrix}
        0    &   1    \\ 
        0    &   0    
    \end{matrix}$
    &
    $\begin{matrix}
        0    &   0    \\ 
        1    &   0    
    \end{matrix}$
    &
    $\begin{matrix}
        1    &   -1    \\ 
        1    &   -1    
    \end{matrix}$
    &
    $\begin{matrix}
        1    &   -1    \\ 
        -1    &   1
    \end{matrix}$
    &
    $\begin{matrix}
        1    &   1    \\ 
        1    &   1
    \end{matrix}$
    &
    $\begin{matrix}
          1  &   1    \\ 
        1    &   -1    
    \end{matrix}$
    &
    $\begin{matrix}
        -1    &   1    \\ 
        1    &   1    
    \end{matrix}$
    &
    $\begin{matrix}
        1    &   1    \\ 
        -1    &   1    
    \end{matrix}$\\
    \hline     
$\begin{matrix}
        1    &   0    \\ 
        1    &   0    
    \end{matrix}$
    &
    $\begin{matrix}
        1    &   0    \\ 
        0    &   1    
    \end{matrix}$
    &
    $\begin{matrix}
        1    &   1    \\ 
         0   &   0    
    \end{matrix}$
    &
    $\begin{matrix}
        1    &   0    \\ 
        -1    &   0    
    \end{matrix}$
    &
    $\begin{matrix}
        1    &   1    \\ 
        0    &   0    
    \end{matrix}$
    &
    $\begin{matrix}
        1    &   0    \\ 
        0    &   -1    
    \end{matrix}$
    &
    $\begin{matrix}
        1    &   0    \\ 
        0    &   1    
    \end{matrix}$
    &
    $\begin{matrix}
        1    &   0    \\ 
        1    &   0    
    \end{matrix}$
    &
    $\begin{matrix}
        1    &   -1    \\ 
        0    &   0    
    \end{matrix}$\\
    \hline     
$\begin{matrix}
        1    &   0    \\ 
        -1    &   0    
    \end{matrix}$
    &
    $\begin{matrix}
        1    &   0    \\ 
        0    &   -1    
    \end{matrix}$
    &
    $\begin{matrix}
        1    &   -1    \\ 
        0    &   0    
    \end{matrix}$
    &
    $\begin{matrix}
        0    &   1    \\ 
        0    &   -1    
    \end{matrix}$
    &
    $\begin{matrix}
        0    &   0    \\ 
        1    &   1    
    \end{matrix}$
    &
    $\begin{matrix}
        0    &   1    \\ 
       -1    &   0    
    \end{matrix}$
    &
    $\begin{matrix}
        0    &   1    \\ 
        -1    &   0    
    \end{matrix}$
    &
    $\begin{matrix}
        0    &   1    \\ 
        0    &   -1    
    \end{matrix}$
    &
    $\begin{matrix}
        0    &   0    \\ 
        1    &   1    
    \end{matrix}$\\
    \hline     
    \end{tabular}

    Chaque case de ce table représente un rayon de \( \eR^4\); il y en a \( 18\) différents, chacun écris deux fois. Une simple vérification montre que chaque colonne est un système orthogonal. La preuve du théorème de Kochen-Specker revient à montrer que nous ne pouvons pas colorier ce tableau de façon cohérente. En effet, étant donné que chaque vecteur est écrit deux fois, le tableau doit contenir un nombre pair de cases blanches et un nombre pair de cases noires.

    Par ailleurs chaque colonne étant un système orthogonal, chaque colonne contient exactement une case noire; il y a donc exactement neuf cases noires dans le tableau, ce qui est impossible.

\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Théorème de Lax-Milgram}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{definition}      \label{DEFooUNOKooCitMjL}
    Une forme bilinéaire \( a\colon V\times V\to \eR\) sur un espace vectoriel normé \( V\) est \defe{coercitive}{coercion} s'il existe \( \alpha>0\) tel que \(  a(u,u)\geq \alpha\| u \|^2 \) pour tout \( u\in V\).
\end{definition}

\begin{theorem}[Lax-Milgram\cite{ooRIEKooXIQYhE}]       \label{THOooLLUXooHyqmVL}
    Soit un espace de Hilbert réel \( V\) muni de différentes choses.
    \begin{enumerate}
        \item
            L'application linéaire \( L\colon V\to \eR\) qui est bornée sur \( V\). Nous notons \( C\) sa norme.
        \item
            La forme bilinéaire continue \( a\) sur \( V\times V\). Nous considérons \( M>0\) tel que \( | a(u,v) |\leq M\| u \|\| v \|\) pour tout \( u,v\in V\).
        \item
            La forme \( a\) est coercitive\footnote{Définition \ref{DEFooUNOKooCitMjL}.}.
    \end{enumerate}
    Alors le problème qui consiste à chercher \( u\in V\) tel que \( a(u,v)=L(v)\) pour tout \( v\in V\) admet une unique solution. De plus cette solution vérifie l'inégalité
    \begin{equation}        \label{EQooUAYSooKYyQBU}
        \| u \|\leq \frac{ M }{ \alpha }C
    \end{equation}
\end{theorem}

\begin{probleme}
    Personnellement, je ne parviens pas à montrer l'inégalité \eqref{EQooUAYSooKYyQBU}, mais seulement
    \begin{equation}
        \| u \|\leq \frac{ C }{ \alpha }.
    \end{equation}
\end{probleme}

\begin{proof}
    Avant de commencer, certaines précisions. D'abord nous nous souvenons de la proposition \ref{PROPooQZYVooYJVlBd} qui donne la continuité de \( L\). Ensuite, \( a\) est continue et linéaire en tant qu'application \( a\colon V\times V\to \eR\). Nous aurions donc envie d'écrire qu'il existe \( M>0\) tel que
    \begin{equation}
        | a(u,v) |\leq M\| (u,v) \|,
    \end{equation}
    mais la norme produit\footnote{Définition \ref{DefFAJgTCE}.} sur \( V\times V\) ne donne pas \( \| u \|\| v \|\). Le fait pour \( a\) d'être \emph{bi}linéaire donne en réalité plus que la linéarité, et la proposition \ref{PROPooQFTSooPFfbCc} nous assure l'existence du \( M\).

    \begin{subproof}
        \item[Reformulation en équation linéaire]
            La forme \( L\) est continue et donc dans le dual \( V'\); le théorème de Riesz \ref{ThoQgTovL} nous donne donc \( f\in V\) tel que
            \begin{equation}
                L(v)=\langle f, v\rangle 
            \end{equation}
            pour tout \( v\in V\). De plus si \( w\in V\) est fixé, l'application \( b_w\colon v\mapsto a(w,v)\) est linéaire et bornée parce que
            \begin{equation}
                \| b_w \|=\sup_{\| v \|=1}| b_w(v) |=\sup_{\| v \|=1}| a(w,v) |\leq M\| w \|\| v \|=M\| w \|.   
            \end{equation}
            Encore une fois, \( b_w\) étant continue et linéaire, elle est dans \( V'\) et Riesz nous fournit un élément \( A(w)\in V\) tel que
            \begin{equation}
                b_w(v)=\langle A(w), v\rangle 
            \end{equation}
            pour tout \( v\in V\). 

            Le problème variationnel \( a(u,v)=L(v)\) est équivalent à \( \langle A(u), v\rangle =\langle f, v\rangle \). L'ensemble des solution de cette dernière est égal à l'ensemble des solution de l'équation
            \begin{equation}        \label{EQooLPMPooMVuYUX}
                A(u)=f.
            \end{equation}
        \item[\( A\) est linéaire]

                Soient \( \alpha,\beta\in \eR\) et \( w,z\in V\). Nous avons pour tout \( v\in V\) :
                \begin{subequations}
                    \begin{align}
                        \langle  A(\alpha w+\beta z), v\rangle &=a(\alpha w+\beta z,v)\\
                        &=\alpha a(w,v)+\beta a(z,v)\\
                        &=\alpha\langle A(w), v\rangle +\beta\langle A(z), v\rangle \\
                        &=\langle \alpha A(w)+\beta A(z), v\rangle .
                    \end{align}
                \end{subequations}
                Étant donné que nous avons égalité pour tout \( v\in V\) nous en déduisons que \( A(\alpha w+\beta z)=\alpha A(w)+\beta A(z)\), ce qui signifie que \( A \) est linéaire.
            \item[Une autre propriété de \( A\) ]
                Nous déduisons une majoration de \( \| A(v) \|^2\) lorsque ce n'est pas nul. Pour ce faire,
                \begin{subequations}
                    \begin{align}
                        \| A(v) \|^2a&=\langle A(v), A(v)\rangle \\
                        &=a(v,A(v))\\
                        &\leq M\| v \|\| A(v) \|.
                    \end{align}
                \end{subequations}
                En simplifiant, \( \| A(v) \|\leq M\| v \|\). Et donc
                \begin{equation}        \label{EQooBQAHooAZRdAW}
                    \| A(v) \|^2\leq M^2\| v \|^2.
                \end{equation}
            \item[Une contraction]

                Nous allons choisir une valeur de \( \rho>0\) telle que l'application
                \begin{equation}
                    T\colon w\mapsto w-\rho\big( A(w)-f \big)
                \end{equation}
                soit une contraction\footnote{Définition \ref{DEFooRSLCooAsWisu}.}. Nous avons \( T(w)-T(w')=w-w'-\rho\big( A(w-w') \big)\) et donc
                \begin{subequations}
                    \begin{align}
                        \| T(w)-T(w') \|^2&=\| w-w' \|^2+\rho^2\| A(w-w') \|^2-2\rho\langle A(w-w'), w-w'\rangle \\
                        &=\| w-w' \|^2+\rho^2\| A(w-w') \|^2-2\rho a(w-w',w-w').
                    \end{align}
                \end{subequations}
                Vu que le dernier terme arrive avec un signe moins, pour majorer l'expression, il faut minorer ce terme, c'est à dire utiliser \( a(w-w',w-w")\geq \alpha\| w-w-w' \|\). Et en même temps nous utilisons \eqref{EQooBQAHooAZRdAW} pour le second terme. Au final pour pouvons factoriser \( \| w-w' \|\) et 
                \begin{equation}
                    \| T(w)-T(w') \|\leq \| w-w' \|\big( 1+\rho^2M^2-2\rho\alpha \big).
                \end{equation}
                Pout que \( T\) soit contractante, il faut \( 0<P(x)<1\) avec \( P(x)=M^2x^2-2\alpha x+1\). Le minimum de ce polynôme est obtenu en \( x=\frac{ \alpha }{ M^2 }\) (la formule du \( x_{min}=-b/2a\)) et vaut \( 1-\frac{ \alpha^2 }{ M^2 }<1\). Vu que par ailleurs \( \lim_{x\to \infty} P(x)=+\infty\), et que ce polynôme passe par au moins une valeur strictement inférieure à \( 1\), nous savons qu'il existe un \( x\) tel que \( 0<P(x)<1\). En donnant à \( \rho\) cette valeur, l'application \( T\) est une contraction.

            \item[Point fixe et conclusion]
                L'ensemble des solutions du problème \eqref{EQooLPMPooMVuYUX} est égal à l'ensemble des points fixes de \( T(v)=v-\rho\big( A(v)-f \big)\).

                L'application \( T\colon V\to V\) est contractante et \( V\) est métrique et complet. Ergo le théorème de point fixe de Picard \ref{ThoEPVkCL} s'applique et il existe un unique point fixe \( u\in V\) pour l'application \( T\). Ce point fixe est l'unique solution de notre problème initial.

            \item[La majoration]

                Nous savons que pour tout \( v\in V\), la relation \( a(u,v)=L(v)\) est vérifiée. En particulier pour \( v=u\) nous avons
                \begin{equation}
                    a(u,u)=L(u).
                \end{equation}
                D'un côté nous utilisons \( a(u,u)\geq \alpha\| u \|^2\) et de l'autre, \( L(u)\leq C\| u \|\) :
                \begin{equation}
                    \alpha\| u \|^2\leq C\| u \|
                \end{equation}
                et donc
                \begin{equation}
                    \| u \|\leq \frac{ C }{ \alpha }.
                \end{equation}
                Notons que \( L(u)\) et \( a(u,u)\) sont positifs.
    \end{subproof}
\end{proof}

\begin{theorem}[Lax-Milgram version symétrique\cite{ooRIEKooXIQYhE}]
    Nous considérons les mêmes hypothèses que celles du théorème de Lax-Milgram, c'est à dire un espace de Hilbert réel \( V\) muni de différentes choses.
    \begin{enumerate}
        \item
            L'application linéaire \( L\colon V\to \eR\) qui est bornée sur \( V\). Nous notons \( C\) sa norme.
        \item
            La forme bilinéaire continue \( a\) sur \( V\times V\). Nous considérons \( M>0\) tel que \( | a(u,v) |\leq M\| u \|\| v \|\) pour tout \( u,v\in V\).
        \item
            La forme \( a\) est coercitive.
    \end{enumerate}
    Nous supposons de plus que \( a\) est symétrique. 

    Alors un élément \( u\in V\) est tel que \( a(u,w)=l(w)\) pour tout \( w\in V\) si et seulement si elle minimise la \defe{fonctionnelle d'énergie}{fonctionnelle!énergie}
    \begin{equation}
        J(w)=\frac{ 1 }{2}a(w,w)-l(w).
    \end{equation}
\end{theorem}

\begin{proof}
    Nous séparons les deux sens.
    \begin{subproof}
        \item[\( \Rightarrow\)]
            Soit \( u\), un élément vérifiant \( a(u,w)=l(w)\) pour tout \( w\in V\). Soit aussi un élément quelconque \( w\in V\), et montrons que \( J(u+w)\geq J(u)\) (tout élément de \( V\) peut être écrit sous la forme \( u+w\)). Nous avons :
            \begin{subequations}
                \begin{align}
                    J(u+w)&=\frac{ 1 }{2}\big( a(u,u)+a(u,w)+a(w,u)+a(w,w) \big)-l(u)-l(w)\\
                    &=J(u)+\underbrace{a(u,w)-l(w)}_{=0}+\frac{ 1 }{2}a(w,w)\\
                    &=J(u)+\frac{ 1 }{2}a(w,w)
                \end{align}
            \end{subequations}
            Vu que \( a\) est coercive, le second terme est positif et nous avons
            \begin{equation}
                J(u+w)\geq J(u),
            \end{equation}
            ce qu'il fallait.

        \item[\( \Leftarrow\)]

            Soit \( u\in V\), un élément minimisant la fonctionnelle \( J\). Nous fixons \( w\in V\) et considérons la fonction \( g\colon \eR\to \eR\) définie par
            \begin{equation}
                g(\epsilon)=J(u+\epsilon w).
            \end{equation}
            En développant un peu et en regroupant les termes,
            \begin{equation}        \label{EQooHGDOooUMCRda}
                g(\epsilon)=J(u)+\epsilon\big( a(u,w)-l(w) \big)+\frac{ \epsilon^2 }{2}a(w,w).
            \end{equation}
            Cela est une fonction éminemment continue et dérivable; en réalité c'est un bête polynôme de degré deux. Vu que \( u\) minimise \( J\), pour tout \( \epsilon\neq 0\) nous avons \( g(\epsilon)\geq g(0)\) ou encore : \( \epsilon=0\) est minimum local (et même global) de \( g\). Le polynôme \eqref{EQooHGDOooUMCRda} prend son minimum en \( \epsilon=0\) si et seulement si 
            \begin{equation}
                a(u,w)-l(w)=0.
            \end{equation}
            Vous ne me croyez pas ? Faites \( g'(\epsilon)=0\) ou bien reprenez la formule du \( -b/2a\) pour le sommet d'une parabole, en tenant compte que \( a(w,w)\neq 0\). Notons qu'ici encore le fait que \( a\) soit coercive joue parce que c'est cela qui nous permet d'affirmer que la parabole a un minimum et non un maximum.

    \end{subproof}
\end{proof}

