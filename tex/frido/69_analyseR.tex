% This is part of Mes notes de mathématique
% Copyright (c) 2006-2019
%   Laurent Claessens, Carlotta Donadello
% See the file fdl-1.3.txt for copying conditions.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Suites et séries : généralités}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\label{SECooTDZNooJvjPks}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Convergence uniforme}
%---------------------------------------------------------------------------------------------------------------------------

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Critère de Cauchy uniforme}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

\begin{definition}[\cite{TrenchRealAnalisys}]
    Soient un espace (dont la nature n'est pas très importante) \( \Omega\), une partie \( A\) de \( \Omega\) et un espace normé \( V\). Lorsque \( g\) est une fonction \( g\colon \Omega\to V\), nous notons
    \begin{equation}
    \| g \|_A=\sup_{x\in A}\| g(x) \|
    \end{equation}
    C'est la norme supremum limitée à la partie \( A\).

    Nous disons qu'une suite de fonctions \( (f_n)\) définies sur un ensemble \( A\) \defe{converge uniformément sur \( A\)}{convergence!uniforme} vers la fonction \( f\) si
    \begin{equation}
        \lim_{n\to \infty} \| f_n-f \|_A=0.
    \end{equation}
\end{definition}

\begin{proposition}[Critère de Cauchy uniforme\cite{LCbyNWQ}]   \label{PropNTEynwq}
    Soit \( X\) un espace topologique et \( (Y,d)\) un espace topologique complet. La suite de fonctions \( f_n\colon X\to Y\) converge uniformément sur \( A\) si et seulement si pour tout \( \epsilon>0\) il existe \( N\in \eN\) tel que si \( k,l>N\) alors
    \begin{equation}
        d\big( f_k(x),f_l(x) \big)\leq \epsilon
    \end{equation}
    pour tout \( x\in X\).
\end{proposition}
\index{Cauchy!critère!uniforme}
\index{critère!Cauchy!uniforme}
Grosso modo, cela dit que si qu'une suite de Cauchy pour la norme uniforme est une suite uniformément convergente. Le fait que la suite converge fait partie du résultat et n'est pas une hypothèse. Ce critère sera utilisé pour montrer que \( \big( C(K),\| . \|_{\infty} \big)\) est complet, proposition~\ref{PropSYMEZGU}.

\begin{proof}
    Si \( f_n\stackrel{unif}{\longrightarrow}f\) alors le critère est satisfait; c'est dans l'autre sens que la preuve est intéressante.

    Soit donc une suite de fonctions satisfaisant au critère et montrons qu'elle converge uniformément. Pour tout \( x\in X\) la suite \( n\mapsto f_n(x)\) est de Cauchy dans l'espace complet \( Y\); nous avons donc convergence ponctuelle \( f_n\to f\). Nous devons prouver que cette convergence est uniforme. Soit \( \epsilon>0\) et \( N\in \eN\) tel que si \( k,l>N\) alors
    \begin{equation}
        d\big( f_k(x),f_l(x) \big)\leq \epsilon
    \end{equation}
    pour tout \( x\in X\). Si nous nous fixons un tel \( k\) et un \( x\in A\) nous considérons l'inégalité
    \begin{equation}
        d\big( f_k(x),f_l(x) \big)\leq \epsilon
    \end{equation}
    qui est vraie pour tout \( l\). En passant à la limite \( l\to\infty\) (limite qui commute avec la fonction distance par définition de la topologie) nous avons
    \begin{equation}
        d\big( f_k(x),f(x) \big)\leq \epsilon.
    \end{equation}
    Cette inégalité étant valable pour tout \( x\in X\), cela signifie que \( f_n\stackrel{unif}{\longrightarrow}f\).
\end{proof}

\begin{theorem}[Limite uniforme de fonctions continues]			\label{ThoUnigCvCont}
    Soit \( A\), un ensemble mesuré et \( f_n\colon A\to \eR^n\), une suite de fonctions continues convergeant uniformément vers \( f\). Si les fonctions \( f_n\) sont toutes continues en \( x_0\in A\), alors \( f\) est continue en \( x_0\).
\end{theorem}

\begin{proof}
    Soit \( \epsilon>0\). Si \( x\in A\) nous avons, pour tout \( n\), la majoration
    \begin{subequations}
        \begin{align}
            \| f(x)-f(x_0) \|&\leq \| f(x)-f_n(x) \|+\| f_n(x)-f_n(x_0) \|+\| f_n(x_0)-f(x_0) \|\\
            &\leq\| f_n(x)-f_n(x_0) \|+2\| f_n-f \|_{\infty}.
        \end{align}
    \end{subequations}
    Grâce à l'uniforme convergence, nous considérons \(N\in \eN\) tel que \( \| f_n-f \|\leq \epsilon\) pour tout \( n\geq N\). Pour de tels \( n\), nous avons
    \begin{equation}
        \| f(x)-f(x_0) \|\leq 2\epsilon+\| f_n(x)-f_n(x_0) \|.
    \end{equation}
    La continuité de \( f_n\) nous fournit un \( \delta>0\) tel que \( \| f_n(x_0)-f_n(x) \|<\epsilon\) dès que \( \| x-x_0 \|<\delta\). Pour ce \( \delta\), nous avons alors \( \| f(x)-f(x_0) \|<\epsilon\).

    Donc lorsque \( \| x-x_0 \|<\delta\) et \( n\geq N\) nous avons
    \begin{equation}
        \| f(x)-f(x_0) \|\leq 3\epsilon,
    \end{equation}
    où vous remarquerez qu'il n'y a plus de dépendance en \( n\). Cela prouve la continuité de \( f\) en \( x_0\).
\end{proof}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Complétude avec la norme uniforme}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

\begin{proposition}[Limite uniforme de fonctions continues]\label{PropCZslHBx}
    Soit \( X\) un espace topologique et \( (Y,d)\) un espace métrique. Si une suite de fonctions \( f_n\colon X\to Y\) continues converge uniformément, alors la limite est séquentiellement continue\footnote{Si \( X\) est métrique, alors c'est la continuité usuelle par la proposition~\ref{PropFnContParSuite}.}.
\end{proposition}

\begin{proof}
    Soit \( a\in X\) et prouvons que \( f\) est séquentiellement continue en \( a\). Pour cela nous considérons une suite \( x_n\to a\) dans \( X\). Nous savons que \( f(x_n)\stackrel{Y}{\longrightarrow}f(x)\). Pour tout \(k\in \eN\), tout \( n\in \eN\) et tout \( x\in X\) nous avons la majoration
    \begin{subequations}
        \begin{align}
            \big\| f(x_n)-f(x) \big\|&\leq \big\| f(x_n)-f_k(x_n) \big\|+\big\| f_k(x_n)-f_k(x) \big\|+\big\| f_k(x)-f(x) \big\|\\
            &\leq 2\| f-f_k \|_{\infty}+\big\| f_k(x_n)-f_k(x) \big\|.
        \end{align}
    \end{subequations}
    Soit \( \epsilon>0\). Si nous choisissons \( k\) suffisamment grand la premier terme est plus petit que \( \epsilon\). Et par continuité de \( f_k\), en prenant \( n\) assez grand, le dernier terme est également plus petit que \( \epsilon\).
\end{proof}

\begin{proposition} \label{PropSYMEZGU}
    Soit \( X\) un espace topologique métrique \( (Y,d)\) un espace espace métrique complet. Alors les espaces
    \begin{enumerate}
        \item
            \( \big( C^0_b(X,Y),\| . \|_{\infty} \big)\) des fonctions continues et bornées \( X\to Y\),
        \item
            \( \big( C^0_0(X,Y),\| . \|_{\infty} \big)\) des fonctions continues et s'annulant à l'infini
        \item
            \( \big( C^k_0(X,Y),\| . \|_{\infty} \big)\) des fonctions de classe \( C^k\) et s'annulant à l'infini
    \end{enumerate}
    sont complets.
\end{proposition}

\begin{proof}
    Soit \( (f_n)\) une suite de Cauchy dans \( C(X,Y)\), c'est-à-dire que pour tout \( \epsilon>0\) il existe \( N\in \eN\) tel que si \( k,l>N\) nous avons \( \| f_k-f_l \|_{\infty}\leq \epsilon\). Cette suite vérifie le critère de Cauchy uniforme~\ref{PropNTEynwq} et donc converge uniformément vers une fonction \( f\colon X\to Y\). La continuité (ou l'aspect \( C^k\)) de la fonction \( f\) découle de la convergence uniforme et de la proposition~\ref{PropCZslHBx} (c'est pour avoir l'équivalence entre la continuité séquentielle et la continuité normale que nous avons pris l'hypothèse d'espace métrique).

    Si les fonctions \( f_k\) sont bornées ou s'annulent à l'infini, la convergence uniforme implique que la limite le sera également.
\end{proof}
    Notons que si \( X\) est compact, les fonctions continues sont bornées par le théorème~\ref{ThoImCompCotComp} et nous pouvons simplement dire que \( C^0(X,Y)\) est complet, sans préciser que nous parlons des fonctions bornées.


\begin{lemma}       \label{LemdLKKnd}
    Soient un espace topologique compact \( A\) et un espace complet \( B\). L'ensemble des fonctions continues de \( A\) vers \( B\) muni de la norme uniforme est complet.

    Dit de façon courte : \( \big( C(A,B),\| . \|_{\infty} \big)\) est complet.
\end{lemma}

\begin{proof}
    Soit \( (f_k)\) une suite de Cauchy de fonctions dans \( C(A,B)\). Pour chaque \( x\in A \) nous avons
    \begin{equation}
        \| f_k(x)-f_l(x) \|_B\leq \| f_k-f_l \|_{\infty},
    \end{equation}
    de telle sorte que la suite \( (f_k(x))\) est de Cauchy dans \( B\) et converge donc vers un élément de \( B\). La suite de Cauchy \( (f_k)\) converge donc ponctuellement vers une fonction \( f\colon A\to B\). Nous devons encore voir que cette fonction est continue; ce sera l'uniformité de la norme qui donnera la continuité. En effet soit \( x_n\to x\) une suite dans \( A\) qui converge vers \( x\in A\). Pour chaque \( k\in \eN\) nous avons
    \begin{equation}
        \| f(x_n)-f(x) \|\leq \| f(x_n)-f_k(x_n) \|  +\| f_k(x_n)-f_k(x) \|+\| f_k(x)-f(x) \|.
    \end{equation}
    En prenant \( k\) et \( n\) assez grands, cette expression peut être rendue aussi petite que l'on veut; le premier et le troisième terme par convergence ponctuelle \( f_k\to f\), le second terme par continuité de \( f_k\). La suite \( f(x_n)\) est donc convergente vers \( f(x)\) et la fonction \( f\) est continue.
\end{proof}

\begin{probleme}
Il serait sans doute bon de revoir cette preuve à la lumière du critère de Cauchy uniforme~\ref{PropNTEynwq}.
\end{probleme}


\begin{normaltext}[\cite{ooXYZDooWKypYR}]
    Le théorème de Stone-Weierstrass indique que les polynômes sont denses pour la topologie uniforme dans les fonctions continues. Donc il existe des limites uniformes de fonctions \( C^{\infty}\) qui ne sont même pas dérivables. Les espaces de type \( C^p\) munis de \( \| . \|_{\infty}\) ne sont donc pas complets sans quelques hypothèses. Voir la proposition~\ref{PropSYMEZGU} et le thème~\ref{THMooOCXTooWenIJE}.
\end{normaltext}

\begin{theorem}[Théorème de Dini\cite{JIFGuct}] \label{ThoUFPLEZh}
    Soient un espace métrique complet \( D\) et une suite de fonctions \( f_n\in C(D,\eR)\) telle que
    \begin{enumerate}
        \item
            \( f_n\to g\) ponctuellement,
        \item
            \( g\in C(D,\eR)\),
        \item
            la suite \( (f_n)\) est croissante, c'est-à-dire que pour tout \( x\in D\) et pour tout \( n\geq 0\) nous avons \( f_{n+1}(x)\geq f_n(x)\).
    \end{enumerate}
    Alors la convergence est uniforme.
\end{theorem}
\index{convergence!uniforme!théorème de Dini}
\index{compacité!théorème de Dini}
\index{théorème!Dini}

\begin{proof}
    Soit \( x\in D\) et \( \epsilon>0\). Il existe \( N(x)\in \eN\) tel que
    \begin{equation}
        g(x)-\epsilon\leq f_{N(x)}\leq g(x).
    \end{equation}
    De plus \( g\) et \( f_{N(x)}\) sont des fonctions continues, donc il existe \( \eta(x)\) tel que si \( y\in B\big( x,\eta(x) \big)\) alors
    \begin{subequations}
        \begin{align}
            g(y)&\in B\big( g(x),\epsilon \big) \label{subEqXKjgKgv}\\
            f_{N(x)}(y)&\in B\big( f_{N(x)}(x),\epsilon \big)   \label{subEqHTiYZLd}.
        \end{align}
    \end{subequations}
    Si \( n\geq N(x)\) et si \( y\in B(x,\eta(x))\) alors nous avons les majorations
    \begin{equation}
            g(y)\geq f_n(y)
            \geq f_{N(x)}(y)
            \geq f_{N(x)}(x)-\epsilon
            \geq g(x)-2\epsilon
            \geq g(y)-3\epsilon.
    \end{equation}
    Justifications :
    \begin{multicols}{2}
        \begin{enumerate}
            \item
                Les deux premières inégalités sont la croissance de la suite.
            \item
                La suivante est \eqref{subEqHTiYZLd}.
            \item
                Ensuite il y a le choix de \( N(x)\).
            \item
                Et enfin il y a \eqref{subEqXKjgKgv}.
        \end{enumerate}
    \end{multicols}
    Nous retenons que si \( x\in D\) et si \( n\geq N(x)\) alors
    \begin{equation}    \label{EqJCMktdj}
        g(y)\geq f_n(y)\geq g(y)-3\epsilon
    \end{equation}
    pour tout \( y\in B(x,\eta(x))\).

    Nous utilisons maintenant la compacité de \( D\). Pour chaque \( x\in D\) nous pouvons considérer la boule ouverte \( B\big( x,\eta(x) \big)\); ces boules recouvrent \( D\). Nous en extrayons un sous-recouvrement fini, c'est-à-dire un ensemble fini d'éléments \( x_1\),\ldots, \( x_K\) tels que
    \begin{equation}
        D=\bigcup_{k=1}^K B\big(x_k,\eta(x_k)\big).
    \end{equation}
    Si à ce moment vous ne comprenez pas pourquoi c'est une égalité au lieu d'une inclusion, il faut lire l'exemple~\ref{ExKYZwYxn}. Considérons
    \begin{equation}
        n\geq N=\max\{ N(x_1),\ldots, N(x_K) \}.
    \end{equation}
    Pour tout \( y\in D\) il existe \( k\in\{ 1,\ldots, K \}\) tel que \( y\in B\big( x_k,\eta(x_k) \big)\), et vu que \( n\geq N(x_k)\) nous reprenons la majoration \eqref{EqJCMktdj} :
    \begin{equation}
        g(y)\geq f_n(y)\geq g(y)-3\epsilon.
    \end{equation}
    Pour le \( n\) choisi nous avons ces inégalités pour tout \( y\in D\), c'est-à-dire que nous avons \( \| f_n-g \|\leq 3\epsilon\) et donc la convergence uniforme.
\end{proof}

\begin{proposition}[\cite{MonCerveau}]      \label{PROPooFWVIooCzXojO}
    Soient une suite de fonctions continues \( u_i\colon \eR\to \eR\) et une fonction continue \( u\) telle que \( u_i\to u\) simplement. Alors la convergence est uniforme sur tout compact.
\end{proposition}

\begin{proof}
    Soit un compact \( K\); nous notons \( \| . \|\) la norme uniforme sur \( K\). Supposons que la limite ne soit pas uniforme, c'est-à-dire qu'il existe un \( \epsilon>0\) tel que 
    \begin{equation}
        \| u_i-u \|> 2\epsilon
    \end{equation}
    pour tout \( i\). Cela permet de considérer pour tout \( i\) un élément \( x_i\in K\) tel que\footnote{Notez l'inégalité stricte, obetenue en considérant $2\epsilon$ plus haut.}
    \begin{equation}
        \| u_i(x_i)-u(x_i) \|> \epsilon.
    \end{equation}
    Pour cela, il faut noter que \( K\) est compact et que la fonction \( x\mapsto \| u_i(x)-u(x) \|\) est continue sur \( K\). Elle est donc bornée et atteint son maximum (c'est le théorème de Weierstrass \ref{ThoWeirstrassRn}).

    La suite \( i\mapsto x_i\) est une suite dans un compact, et quitte à prendre une sous-suite, nous supposons qu'elle converge vers \( a\in K\) (ça, c'est Bolzano-Weierstrass \ref{LemMGQqgDG}).

    La convergence ponctuelle \( u_i\to u\), prise en \( a\), dit qu'il existe un \( N\) tel que \( | u_i(a)-u(a) |<\epsilon\) pour tout \( i\geq N\). Pour un tel \( i\), nous avons aussi
    \begin{equation}
        | u_i(x)-u(x) |<\epsilon
    \end{equation}
    sur un voisinage de \( a\), parce que \( u_i-u\) est continue. Mais tout voisinage de \( a\) contient un élément \( x_j\) pour lequel
    \begin{equation}
        | u_i(x_j)-u(x_j) |>\epsilon.
    \end{equation}
    Contradiction.
\end{proof}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Série de fonctions}
%---------------------------------------------------------------------------------------------------------------------------

Les séries de fonctions sont des cas particuliers de suites. 

\begin{definition}      \label{DEFooYEIUooCAgrxI}
    Si \( (f_n)\) est une suite de fonctions, nous définissons la somme des \( f_n\) de la façon suivante :
    \begin{equation}
        \sum_{n=1}^{\infty}f_n=\lim_{N\to \infty} \sum_{n=1}^{N}f_n.
    \end{equation}
    Le membre de droite est une définition de la notation introduite dans le membre de gauche.
\end{definition}
Avant de vous lancer, relisez une bonne fois les définitions de convergence absolue (définition \ref{DefVFUIXwU}) et de convergence uniforme (équation \ref{EqLNCJooVCTiIw}).

\begin{lemma}
    Soient des fonctions \( u_n\colon \Omega\to \eC\). Si il existe une suite réelle positive \( (a_n)_{n\in \eN}\) telle que
    \begin{enumerate}
        \item
            pour tout \( z\in \Omega\) et pour tout \( n\in \eN\) nous avons \( | u_n(z) |\leq a_n\) (c'est-à-dire \( a_n\geq \| u_n \|_{\infty}\)),
        \item
            la somme \( \sum_{n}a_n\) converge,
    \end{enumerate}
    alors la série de fonctions \( \sum_{n=0}^{\infty}u_n\) converge normalement\footnote{Définition~\ref{DefVBrJUxo}.}.
\end{lemma}

\begin{proof}
    Découle du lemme de comparaison~\ref{LemgHWyfG}.
\end{proof}

\begin{theorem}				\label{ThoSerCritAbel}
	Soit $\sum_{k=1}^{\infty}g_k(x)$, une série de fonctions complexes où $g_k(x)=\varphi_k(x)\psi_k(x)$. Supposons que
	\begin{enumerate}

		\item
			$\varphi_k\colon A\to \eC$ et $| \sum_{k=1}^K\varphi_k(x) |\leq M$ où $M$ est indépendant de $x$ et $K$,
		\item
			$\psi_k\colon A\to \eR$ avec $\psi_k(x)\geq 0$ et pour tout $x$ dans $A$, $\psi_{k+1}(x)\leq \psi_k(x)$, et enfin supposons que $\psi_k(x)$ converge uniformément vers $0$.

	\end{enumerate}
	Alors $\sum_{k=1}^{\infty}g_k$ est uniformément convergente.
\end{theorem}

\begin{theorem}		\label{ThoAbelSeriePuiss}
	Si la série de puissances (réelle) converge en $x=x_0+R$, alors elle converge uniformément sur $\mathopen[ x_0-R+\epsilon , x_0+R \mathclose]$ ($\epsilon>0$) vers une fonction continue.
\end{theorem}


\begin{proposition}     \label{PropUEMoNF}
    Soit \( (u_n)\) une suite de fonctions continues \( u_n\colon \Omega\subset\eC\to \eC\). Si la série \( \sum_nu_n\) converge normalement alors la somme est continue.
\end{proposition}

\begin{proof}
    Nous posons \( u(z)=\lim_{N\to \infty} \sum_{n=0}^N u_n(z)\), et nous vérifions que la fonction ainsi définie sur \( \Omega\) est continue. Soit \( z\in \Omega\). Prouvons la continuité de \( u\) au point \( z\). Pour tout \( z'\) dans un voisinage de \( z\) nous avons
    \begin{subequations}
        \begin{align}
            \big| u(z)-u(z') \big|&=\left| \sum_{n=0}^{N}u_n(z)-\sum_{n=0}^{N}u_n(z')+\sum_{n=N+1}^{\infty}u_n(z)-\sum_{n=N+1}^{\infty}u_n(z') \right| \\
            &\leq \left| \sum_{n=0}^N u_n(z)-\sum_{n=0}^Nu_n(z') \right| +\sum_{n=N+1}^{\infty}| u_n(z) |+\sum_{n=N+1}^{\infty}| u_n(z') |.
        \end{align}
    \end{subequations}
    Étant donné que les sommes partielles sont continues, en prenant \( N\) suffisamment grand, le premier terme peut être rendu arbitrairement petit. Si \( N\) est suffisamment grand, le second terme est également petit. Par contre, cet argument ne tient pas pour le troisième terme parce que nous souhaitons une majoration pour tout \( z'\) dans une boule autour de \( z\). Nous devons donc écrire
    \begin{equation}
        \sum_{n=N}^{\infty}| u_n(z) |\leq \sum_{n=N+1}^{\infty}\| u_n \|_{\infty}.
    \end{equation}
    Ce dernier est arbitrairement petit lorsque \( N\) est grand. Notons que nous avons utilisé l'hypothèse de convergence normale.
\end{proof}

La même propriété, avec la même démonstration, tient dans le cas d'espaces vectoriels normés.

\begin{proposition} \label{PropOMBbwst}
    Soient \( E\) et \( F\), deux espaces vectoriels normés, \( \Omega\) une partie ouverte de \( E\) et une suite de fonctions \( u_n\colon \Omega\to F\) convergeant normalement sur \( \Omega\), c'est-à-dire que \( \sum_n\| u_n \|_{\infty}\) converge, la norme \( \| . \|_{\infty} \) devant être comprise comme la norme supremum sur \( \Omega\). Alors la fonction \( u=\sum_nu_n\) est continue sur \( \Omega\).
\end{proposition}

\begin{proof}
    Soit \( x,x'\in \Omega\) en supposant que \( \| x-x' \|\) est petit. Soit encore \( \epsilon>0\). Nous allons montrer la continuité en \( x\). Pour cela nous savons que pour tout \( N\) l'inégalité suivante est correcte :
    \begin{equation}
        \| u(x)-u(x') \|\leq \left\|  \sum_{n=0}^Nu_n(x)-\sum_{n=0}^{N}u_n(x') \right\|+\sum_{n=N+1}^{\infty}\| u_n(x) \|+\sum_{n=N+1}^{\infty}\| u_n(x') \|.
    \end{equation}
    Les deux derniers termes sont majorés par \( \sum_{n=N+1}^{\infty}\| u_n \|_{\infty}\) qui, par hypothèse, peut être rendu aussi petit que souhaité en choisissant \( N\) assez grand. Nous choisissons donc un \( N\) tel que ces deux termes soient plus petits que \( \epsilon\). Ce \( N\) étant fixé, la fonction \( \sum_{n=0}^{N}u_n\) est continue et nous pouvons choisir \( x'\) assez proche de \( x\) pour que le premier terme soit majoré par \( \epsilon\).
\end{proof}

\begin{theorem}			\label{ThoSerUnifCont}
	Si les $g_k$ sont continues et si $\sum g_k$ converge uniformément, alors $\sum g_k$ est continue.
\end{theorem}

Le corollaire suivant permet de considérer des séries de fonctions indexées par exemple par \( \eZ\) plutôt que par \( \eN\).
\begin{corollary}
    Une famille dénombrable de fonctions continues convergeant normalement converge vers une fonction continue.
\end{corollary}

\begin{proof}
    Soit \( I\) dénombrable. Considérons une famille de fonctions continues \( (f_n)_{n\in I}\) telles que la famille \( (\| f_i \|_{\infty})_{i\in I}\) soit sommable. Le proposition~\ref{PropoWHdjw} nous permet d'utiliser une bijection entre \( I\) et \( \eN\). Le théorème~\ref{PropUEMoNF} s'applique alors.
\end{proof}

\begin{theorem}[Critère de Weierstrass]\index{critère!Weierstrass!série de fonctions}		\label{ThoCritWeierstrass}
	Soit une suite de fonctions $f_k\colon A\to \eC$ telles que $| f_k(x) |\leq M_k\in\eR$, $\forall x\in A$. Si $\sum_{k=1}^{\infty}M_k$ converge, alors $\sum_{k=1}^{\infty}f_k$ converge absolument et uniformément.
\end{theorem}

\begin{proof}
    La convergence normale est facile : l'hypothèse dit que \( \| f_k \|_{\infty}\leq M_k\), et donc que
    \begin{equation}
        \sum_{k=1}^{\infty}\| f_k \|_{\infty}\leq \sum_kM_k<\infty.
    \end{equation}

    La convergence uniforme est à peine plus subtile. Nous nommons \( F\) la fonction somme. Pour tout \( x\) et pour tout \( N\), nous avons
    \begin{subequations}
        \begin{align}
            \left\| \sum_{n=1}^Nf_n(x)-F(x) \right\|&=\| \sum_{n=N}^{\infty}f_n(x) \|\\
            &\leq\sum_{n=N}^{\infty}\| f_k(x) \|\\
            &\leq \sum_{n=N}^{\infty}\| f_n \|_{\infty}.
        \end{align}
    \end{subequations}
    La convergence normale étant assurée, la série \( \sum_{n_1}^{\infty}\| f_n \|_{\infty}\) est finie, ce qui implique que la queue de somme \( \sum_{n=N}^{\infty}\| f_n \|_{\infty}\) tend vers zéro lorsque \( N\to \infty\). Pour tout \( \epsilon\), il existe donc un \( N\) (non dépendant de \( x\)) tel que
    \begin{equation}
        \| \sum_{n=1}^Nf_n(x)-F(x) \|\leq \epsilon.
    \end{equation}
    En prenant le supremum sur \( x\in A\) nous trouvons la convergence uniforme.
\end{proof}

\begin{remark}
    Il n'y a pas de critère correspondant pour les suites. Il n'est pas vrai que si \( \lim_{n\to \infty}\| f_n \| \) existe, alors \( \lim_{n\to \infty} f_n\) existe, comme le montre l'exemple
    \begin{equation}
        f_n(x)=\begin{cases}
            1    &   \text{si } x\in\mathopen[ 0 , 1 \mathclose]\text{ et } n\text{ est pair}\\
            1    &    \text{si } x\in\mathopen[ 1 , 2 \mathclose]\text{ et } n\text{ est impair}\\
             0   &    \text{sinon.}
        \end{cases}
    \end{equation}
\end{remark}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Permuter limite et dérivée}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Pour permuter différentielle et limite, ce sera le théorème \ref{ThoLDpRmXQ}.

\begin{theorem}[\cite{TrenchRealAnalisys,ooCPZDooOqIIEz}]     \label{THOooXZQCooSRteSr}
    Soient une suite de fonctions \( f_i\colon \eR\to \eR\), une fonction \( f\colon \eR\to \eR\) et une fonction \( g\colon \eR\to \eR\) telles que
    \begin{enumerate}
        \item
            \( f_i\) est de classe \( C^1\) pour tout \( i\),
        \item
            \( f_i\to f\) simplement,
        \item
            \( f_i'\to g\) uniformément sur tout compact.
    \end{enumerate}
    Alors
    \begin{enumerate}
        \item
            \( f\) est de classe \( C^1\),
        \item
            \( f'=g\),
        \item
            \( f_i\to f\) uniformément sur tout compact.
    \end{enumerate}
\end{theorem}

\begin{proof}
  On commence par démonter la convergence uniforme sur les compacts des~$f_i$.
  Soit~$K \subseteq \eR$ un intervalle compact contenant~$x$.
  Il suffit de montrer que la suite~$(f_i)_i$ restreinte à $K$ est une suite de
  Cauchy pour la norme uniforme.  Soit~$\epsilon > 0$.
  On note~$\omega_i$ le module de continuité de~$f_i'$.
  Par le lemme~\ref{LEMooKPPSooPIncvn}, il existe~$N \geq 0$ tel que pour tout \( \delta>0\) nous ayons
  \begin{equation}\label{eq:1}
    \omega_i(\delta) \leq \omega_g(\delta) + \epsilon.
  \end{equation}
  
  Soit~$y\in K$, $n \in \eN$ et~$\alpha_n = \frac{x-y}{n+1}$.
  Pour tout~$i \geq 0$,
  \begin{equation}
    f_i(y) = f_i(x) + \sum_{k=0}^n \left( f_i(x+(k+1)\alpha_n) - f_i(x+k\alpha_n) \right),
  \end{equation}
  c'est une somme télescopique.
  Par le théorème des accroissements finis, il existe pour tout~$0\leq k\leq n$
  un réel~$u_{n,i,k} \in [k,(k+1)\alpha_n]$ tel que
  \begin{equation}
    f_i(x+(k+1)\alpha_n) - f_i(x+k\alpha_n) = \alpha_n f'_i(x+ u_{n,i,k}),
  \end{equation}
  de sorte que
  \begin{equation}
    f_i(y) = f_i(x) + \alpha_n \sum_{k=0}^n  f'_i(x+ u_{n,i,k}).
  \end{equation}
  Et pour tout~$i,j \geq 0$, on obtient
  \begin{align}
    \left| f_i(y) - f_j(y) \right| &\leq \left| f_i(x) - f_j(x) \right|
                                     + \alpha_n \sum_{k=0}^n \left| f'_i(x+ u_{n,i,k}) - f'_j(x+u_{n,j,k}) \right|.
  \end{align}
  Or
  \begin{align}
    \left| f'_i(x+ u_{n,i,k}) - f'_j(x+u_{n,j,k}) \right| &\leq  \left| f'_i(x+ u_{n,i,k}) - f'_i(x+u_{n,j,k}) \right| +  \left| f'_i(x+ u_{n,j,k}) - f'_j(x+u_{n,j,k}) \right| \\
                                                          &\leq \omega_i(\alpha_n) + \|f'_i-f'_j\|,
  \end{align}
  et il suit que pour tout~$i,j \geq N$,
  \begin{align}
    \left| f_i(y) - f_j(y) \right| & \leq  \left| f_i(x) - f_j(x) \right| + |x-y| \left(\omega_i(\alpha_n) + \|f'_i+f'_j\|_K \right)\\
    &\leq \left| f_i(x) - f_j(x) \right| + |x-y| \left(\omega_g(\alpha_n) + \epsilon + \|f'_i+f'_j\|_K \right), \label{eq:2}
  \end{align}
  où la dernière inégalité vient de~\eqref{eq:1}.
  Comme~$g$ est continue (limite uniforme de fonctions continues) sur un
  compact, elle est uniformément continue et
  $\lim_{\delta\to 0} \omega_g(\delta) = 0$.
  Donc l'inégalité~\eqref{eq:2}, avec~$n\to \infty$ devient
  \begin{equation}\label{eq:3}
  \left| f_i(y) - f_j(y) \right| \leq \left| f_i(x) - f_j(x) \right| + |x-y|
    \left(\epsilon + \|f'_i+f'_j\|_K \right).
  \end{equation}

  Comme~$K$ est borné, $\left| x-y \right|$ est borné par une quantité~$M$ ne
  dépendant que de~$K$.
  En prenant dans~\eqref{eq:3} le supremum par rapport à~$y$, on obtient
  \begin{equation}
    \|f_i-f_j\|_K \leq  \left| f_i(x) - f_j(x) \right| + |x-y|
    \left(\epsilon + \|f'_i+f'_j\|_K \right).
  \end{equation}
  
  Étant donné
  que~$\left( f_i(x) \right)_i$ est une suite de Cauchy, que~$\left( f'_i
  \right)_i$ est une suite de Cauchy pour la norme uniforme sur~$K$,
  il suit que~$(f_i|_K)_i$ est une suite de Cauchy. Donc elle converge uniformément vers une
  limite~$f|_K$.
  
  \bigskip
  Montrons maintenant que la limite~$f$ de la suite~$(f_i)_i$ est dérivable
  et que~$f'=g$.
  Soit~$y\in \eR$ et soit~$K$ un voisinage compact de~$y$. On reprend les
  notations précédentes. Pour tout~$\delta \in \eR$ suffisamment petit
  $y+\delta \in K$, et pour tout~$i \geq 0$ on a alors
  \begin{subequations}
      \begin{align}
    \Big| \frac{1}\delta \big( f(y+\delta) &- f(y) \big) - g(y) \Big|\\
    &\leq  \frac1\delta \left| f(y)-f_i(y) \right| + \frac1\delta \left| f(y+\delta) - f_i(y+\delta)  \right|
      + \left| \frac1\delta \left(f_i(y+\delta) - f_i(y)\right) - g(y) \right|\\
    &\leq \frac2\delta \|f_i - f\|_K  + \left| \frac1\delta \left(f_i(y+\delta) - f_i(y)\right) - g(y) \right|.
      \end{align}
  \end{subequations}
  Par le théorème des accroissements finis, il existe~$u\in[y-|\delta|, y+|\delta|]$ tel que
  \begin{equation}
    \frac1\delta \left(f_i(y+\delta) - f_i(y)\right) = f'_i(u).
  \end{equation}
  Il suit,
  \begin{align}
    \left| \frac{1}\delta \left( f(y+\delta) - f(y) \right) - g(y) \right| &\leq \frac2\delta \|f_i - f\|_K +
                                                                             \left| f'_i(u) - f'_i(y) \right| + \|f_i'-g\| \\
    &\leq \frac2\delta \|f_i - f\|_K + \omega_i(\delta) + \|f_i'-g\|.
  \end{align}
  En prenant~$i \to \infty$, on obtient
  \begin{equation}
    \left| \frac{1}\delta \left( f(y+\delta) - f(y) \right) - g(y) \right| \leq \omega_g(\delta).
  \end{equation}
  Or~$\lim_{\delta\to 0}\omega_g(\delta) = 0$, donc~$f$ est dérivable en~$y$
  et~$f'(y) = g(y)$.
\end{proof}

\begin{theorem}		\label{ThoSerUnifDerr}
	Soit $U\subset\eR^n$ ouvert, $f_k\colon U\to \eR$ et $f_k$ de classe $C^1$. Supposons que $f_k$ converge simplement vers $f$ et que $\partial_if_k$ converge uniformément sur tout compact  vers une fonction $g_i$ pour $i=1,\ldots,n$. Alors $f$ est de classe $C^1$ et $\partial_if=g_i$. De plus, $f_k$ converge vers $f$ uniformément.
\end{theorem}
\index{permuter!dérivée et limite}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Densité des polynômes}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Théorème de Stone-Weierstrass}
%---------------------------------------------------------------------------------------------------------------------------

Voir le thème~\ref{THEooPUIIooLDPUuq}.

Note : le lemme~\ref{LemYdYLXb} est utilisé dans la démonstration du théorème~\ref{ThoWmAzSMF}; c'est pour cela que nous l'avons isolé.

\begin{lemma}       \label{LemYdYLXb}
    Il existe une suite de polynômes sur \( \mathopen[ 0 , 1 \mathclose]\) convergeant uniformément vers la fonction racine carrée.
\end{lemma}

\begin{proof}
    Nous donnons cette suite par récurrence :
    \begin{subequations}
        \begin{align}
            P_0(t)&=0\\
            P_{n+1}(t)&=P_n(t)+\frac{ 1 }{2}\big( t-P_n(t)^2 \big).
        \end{align}
    \end{subequations}
    Nous commençons par montrer que pour tout \( t\in \mathopen[ 0 , 1 \mathclose]\), \( P_n(t)\in\mathopen[ 0 , \sqrt{t} \mathclose]\). Pour \( P_0\), c'est évident. Ensuite nous avons
    \begin{subequations}
        \begin{align}
            P_{n+1}(t)-\sqrt{t}&=P_n(t)-\sqrt{t}+\frac{ 1 }{2}(t-P_n(t)^2)\\
            &=\big( P_n(t)-\sqrt{t} \big)\left( 1-\frac{ 1 }{2}\frac{ t-P_n(t)^2 }{ P_n(t)-\sqrt{t} } \right)\\
            &=\big( P_n(t)-\sqrt{t} \big)\left( 1-\frac{ \sqrt{t}+P_n(t) }{2} \right)\\
            &\leq 0
        \end{align}
    \end{subequations}
    parce que \( \sqrt{t} \leq 1\) et \( P_n(t)\leq 1\) par hypothèse de récurrence.

    Nous savons au passage que \( P_n(t)\) est une suite réelle croissante parce que \( t-P_n(t)^2\geq t-(\sqrt{t})^2=0\). La suite \( P_n(t)\) est donc croissante et majorée par \( \sqrt{t}\); elle converge donc. Les candidats limites sont déterminés par l'équation
    \begin{equation}
        \ell=\ell+\frac{ 1 }{2}(t-\ell^2),
    \end{equation}
    dont les solutions sont \( \ell=\pm\sqrt{t}\). La suite étant positive, nous avons une convergence ponctuelle de \( P_n\) vers la racine carrée. Cette suite étant une suite croissante de fonctions continues sur un compact, convergeant ponctuellement vers une fonction continue, la convergence est uniforme par le théorème de Dini~\ref{ThoUFPLEZh}.
\end{proof}

\begin{lemma}           \label{LemUuxcqY}
    Soit \( K\), un compact de \( \eR\) et \( f_n\) une suite de fonctions sur \( K\) convergeant uniformément vers \( f\). Soit \( g\colon X\to K\) une fonction depuis un espace topologique \( K\). Alors \( f_n\circ g\) converge uniformément vers \( f\circ g\).
\end{lemma}

\begin{proof}
    En effet, pour tout \( x\in X\) nous avons
    \begin{equation}
        \| (f_n\circ g)-(f\circ g) \|_{\infty}=\sup_{x\in X} \| f_n\big( g(x) \big)-f\big( g(x) \big) \|\leq \| f_n-f \|_{\infty}.
    \end{equation}
    Par conséquent, si \( \epsilon\>0\) est donné, il suffit de choisir \( n\) de telle sorte à avoir \( \| f_n-f \|_{\infty}<\epsilon\) et nous avons \( \| (f_n\circ g)-(f\circ g) \|_{\infty}\leq \epsilon\).
\end{proof}

\begin{definition}
    Nous disons qu'une algèbre \( A\) de fonctions sur un espace \( X\) \defe{sépare les points}{sépare!les points} de \( X\) si pour tout \( x_1\neq x_2\) il existe \( g\in A\) telle que \( g(x_1)\neq g(x_2)\).
\end{definition}

Nous pouvons maintenant énoncer et démontrer une forme nettement plus générale du théorème de Stone-Weierstrass. Le théorème \ref{ThoWmAzSMF} le donne pour \( C(X,\eC)\) et le théorème \ref{THOooMDILooGPXbTW} le donne pour \( C(X,\eR)\).

\begin{theorem}[Stone-Weierstrass\cite{MGecheleSW}] \label{THOooMDILooGPXbTW}
    Soient \( X\), un espace compact et Hausdorff. Soit \( A\), une sous-algèbre de \( C(X,\eR)\) contenant une fonction constante non nulle. Alors \( A\) est dense dans \( \Big( C(X,\eR),\| . \|_{\infty}\Big)\) si et seulement si \( A\) sépare les points de \(X\).
\end{theorem}
\index{théorème!Stone-Weierstrass}

\begin{proof}
    Nous allons écrire la démonstration en plusieurs étapes (dont la première est le lemme~\ref{LemYdYLXb}). Nous commençons par la première partie, sur les réels.

    \begin{description}
        \item[Première étape] Pour tout \( x\neq y\in X\) et pour tout \( \alpha,\beta\in \eR\), il existe une fonction \( f\in A\) telle que \( f(x)=\alpha\) et \( f(y)=\beta\).

            En effet, vu que \( A\) sépare les points nous pouvons considérer une fonction \( g\in A\) telle que \( g(x)\neq g(y)\) et ensuite poser
            \begin{equation}
                f(z)=\alpha+\frac{ \alpha-\beta }{ g(y)-g(x) }\big( g(z)-g(x) \big).
            \end{equation}
            Les constantes faisant partie de \( A\), cette fonction \( f\) est encore dans \( A\).

        \item[Seconde étape] Pour tout \( n\)-uples de fonctions \( f_1,\ldots, f_n\) dans \( \bar A\), les fonctions \( \min(f_1,\ldots, f_n)\) et \( \max(f_1,\ldots, f_n)\) sont dans \( \bar A\).

            Nous le démontrons pour \( n=2\); le reste allant évidemment par récurrence. Soient \( f,g\in \bar A\). Étant donné que
            \begin{subequations}
                \begin{align}
                    \max(f,g)&=\frac{ f+g }{2}+\frac{ | f-g | }{2}\\
                    \min(f,g)&=\frac{ f+g }{2}-\frac{ | f-g | }{2},
                \end{align}
            \end{subequations}
            if suffit de montrer que si \( f\in\bar A\) alors \( | f |\in \bar A\). Si \( f\) est nulle, c'est évident; supposons que \( f\neq 0\) et posons \( M=\| f \|_{\infty}\neq 0\). Pour tout \( x\in X\) nous avons
            \begin{equation}
                \frac{ f(x)^2 }{ M^2 }\in \mathopen[ 0 , 1 \mathclose].
            \end{equation}
            Nous considérons alors la suite
            \begin{equation}
                h_n=P_n\circ\frac{ f^2 }{ M^2 }
            \end{equation}
            où \( P_n\) est une suite de polynômes convergent uniformément vers la racine carrée (voir lemme~\ref{LemYdYLXb}). Le lemme~\ref{LemUuxcqY} nous assure que \( h_n\) converge uniformément vers \( \frac{ | f | }{ M }\) dans \( C(X,\eR)\). Étant donné que \( \bar A\) est également une algèbre, \( h_n\) est dans \( \bar A\) pour tout \( n\) et la limite s'y trouve également (pour rappel, la fermeture \( \bar A\) est celle de la topologie de la convergence uniforme).

        \item[Troisième étape] Soit \( \epsilon>0\), \( f\in C(X,\eR)\) et \( x\in X\). Il existe une fonction \( g_x\in \bar A\) telle que
            \begin{subequations}
                \begin{numcases}{}
                    g_x(x)=f(x)\\
                    g_x(y)\leq f(y)+\epsilon
                \end{numcases}
            \end{subequations}
            pour tout \( y\in X\).

            Soit \( z\in X\setminus\{ x \}\) et une fonction \( h_z\) telle que \( h_z(x)=f(x)\) et \( h_z(z)=f(z)\). Une telle fonction existe par une des étapes précédentes. Étant donné que \( f\) et \( h_z\) sont continues, il existe un voisinage ouvert \( V_z\) de \( z\) sur lequel
            \begin{equation}
                h_z(y)\leq f(y)+\epsilon
            \end{equation}
            pour tout \( y\in V_z\). Nous pouvons sélectionner un nombre fini de points \( z_1,\ldots, z_n\) tels que les ouverts \( V_{z_1},\ldots, V_{z_n}\) recouvrent \( X\) (parce que \( X\) est compact, de tout recouvrement par des ouverts, nous extrayons un sous recouvrement fini.). Nous posons
            \begin{equation}
                g_x=\min(h_{z_1},\ldots, h_{z_n})\in \bar A.
            \end{equation}
            Si \( y\in X\), nous sélectionnons le \( i\) tel que \( h_{z_i}(y)\leq f(y)+\epsilon\) et nous avons
            \begin{equation}
                g_x(y)\leq h_{z_i}(y)\leq f(y)+\epsilon.
            \end{equation}

        \item[Étape \wikipedia{fr}{Final_Doom}{finale}] Soit \( \epsilon>0\) et \( f\in C(X,\eR)\). Pour chaque \( x\in X\) nous considérons une fonction \( g_x\in \bar A\) telle que
            \begin{subequations}
                \begin{numcases}{}
                    g_x(x)=f(x)\\
                    g_x(y)\leq f(y)+\epsilon
                \end{numcases}
            \end{subequations}
            pour tout \( y\in X\). Les fonctions \( f\) et \( g_x\) sont continues, donc il existe un voisinage ouvert \( W_x\) de \( x\) sur lequel
            \begin{equation}
                g_x(y)\geq f(y)-\epsilon.
            \end{equation}
            De ces \( W_x\) nous extrayons un sous recouvrement fini de \( X\) : \( W_{x_1},\ldots, W_{x_m}\) et nous posons
            \begin{equation}
                \varphi=\max(g_{x_1},\ldots, g_{x_n})\in \bar A.
            \end{equation}
            Si \( y\in X\), il existe un \( i\) tel que
            \begin{equation}
                \varphi(y)\geq g_{x_i}(y)\geq f(y)-\epsilon.
            \end{equation}
            La première inégalité est le fait que \( \varphi\) est le maximum des \( g_{x_k}\), et la seconde est le choix de \( i\). Donc pour tout \( y\in X\) nous avons
            \begin{equation}        \label{EqJMxHaF}
                f(y)-\epsilon\leq \varphi(y)\leq f(y)+\epsilon.
            \end{equation}
            La première inégalité est ce que l'on vient de faire. La seconde est le fait que pour tout \( i\) nous ayons \( g_{x_i}(y)\leq f(y)+\epsilon\); le fait que \( \varphi\) soit le maximum sur les \( i\) ne change pas l'inégalité.

            Le fait que les inégalités \eqref{EqJMxHaF} soient vraies pour tout \( y\in X\) signifie que \( \| \varphi-f \|_{\infty}\leq \epsilon\), et donc que \( f\in \Adh\big( \Adh(A) \big)=\Adh(A)\).
    \end{description}

    Tout cela prouve que \( C(X,\eR)\subset \Adh(A)\). L'inclusion inverse est le fait que \( C(X,\eR)\) est fermé pour la norme \( \| . \|_{\infty}\), étant donné qu'une limite uniforme de fonctions continues est continue.

    Nous pouvons maintenant nous tourner vers l'énoncé concernant \( C(X,\eC)\).
\end{proof}

\begin{theorem}[Stone-Weierstrass\cite{MonCerveau}] \label{ThoWmAzSMF}
    Soit \( X\), un espace compact et Hausdorff. Soit une sous-algèbre \( A\) stable par conjugaison\footnote{Pour tout \( g\in A\), nous avons \( \bar g\in A\).} \( A\) de \( C(X,\eC)\) contenant une fonction constante non nulle. Alors \( A\) est dense dans \( \Big( C(X,\eC),\| . \|_{\infty}\Big)\) si et seulement si \( A\) sépare les points de \(X\).

    Entendons-nous bien : ici \( A\) et \( C(X,\eC)\) sont des algèbres à coefficients dans \( \eC\).
\end{theorem}

\begin{proof}
    La preuve de cette version dans \( C(X,\eC)\) va bien entendu fortement reposer sur le cas dans \( C(X,\eR)\) que nous venons de prouver. Soit donc \( A\), une sous-algèbre vérifiant les hypothèses.
    \begin{subproof}
        \item[\( \real(A)\subset A\)]
            Nous prouvons que si \( f\in A\), alors \( \real(f)\in A\). En effet, vu que \( A\) est stable par conjugaison, si \( f\in A\), alors \( \bar f\in A\) et \( f+\bar f=2\real(f)\in A\).
    \end{subproof}
    Nous posons
    \begin{equation}
        A_1=\{ \real(g)\tq g\in A \}.
    \end{equation}
    \begin{subproof}
        \item[\( A_1\) est une sous-algèbre de \( A\)]
            Le fait que les élément de \( A_1\) soient dans \( A\) est déjà fait. Pour le produit, si \( g_1,h_1\in A_1\), alors il existe \( h,h\in A\) tels que \( g_1=\real(g)\) et \( h_1=\real(h)\). Nous avons
            \begin{equation}
                (g_1+ig_2)(h_1+ih_2)=g_1h_2-g_2h_2+i(g_1h_2+g_2h_1)\in A.
            \end{equation}
            La partie réelle de cela est dans \( A_1\), donc
            \begin{equation}        \label{EQooYAGUooJVpaEa}
                g_1h_2-g_2h_1\in A_1.
            \end{equation}
            Mais comme \( g_1+ig_2\in A\), nous avons aussi \( g_1-ig_2\in A \) et donc
            \begin{equation}
                (g_1-ig_2)(h_1+ih_2)=g_1h_1+g_2h_2+i(g_1h_2-g_2h_1)\in A.
            \end{equation}
            La partie réelle de cela est dans \( A_1\). Donc
            \begin{equation}
                g_1h_2+g_2h_1\in A_1.
            \end{equation}
            En comparant avec \eqref{EQooYAGUooJVpaEa}, nous avons \( g_1h_1\in A_1\).
        \item[\( A_1\) sépare les points de \( X\)]
            Soient \( x,y\in X\) ainsi que \( f\in A\) séparant les points \( x\) et \( y\), c'est-à-dire
            \begin{equation}
                f(x)\neq f(y).
            \end{equation}
            Supposons \( f_1(x)=f_2(y)\). Vu que \( f\) sépare, si ce ne sont pas les parties réelles, ce sont les parties imaginaires. C'est-à-dire que  \( f_2(x)\neq f_2(y)\). Mais d'autre part, \( if=f_2+if_1\in A\),  donc en réalité \( f_2\in A_1\) également.
    \end{subproof}
    Le partie \( A_1\) dans \( C(X,\eR)\) vérifie les hypothèses de Stone-Weierstrass réel \ref{THOooMDILooGPXbTW}, donc \( A_1\) est dense dans \( C(X,\eR)\). Le même raisonnement montre que \( A_2\) est également dense dans \( C(X,\eR)\)\quext{Il me semble même que \( A_1=A_2\) et qu'il y a un raccourcis possible dans cette preuve en exploitant ce fait. Écrivez-moi pour dire ce que vous en pensez.}

    Soit maintenant le vif de la preuve : \( f\in C(X,\eC)\) avec \( f=u+iv\), les fonctions \( u\) et \( v \) étant dans \( C(X,\eR)\). Nous avons des suites \( u_{k}\stackrel{unif}{\longrightarrow}u\) et \( v_k\stackrel{unif}{\longrightarrow}v\) pour des suites \( (u_k) \) et \( (v_k)\) dans \( C(X,\eR)\).

    Par le même genre de raisonnements que nous avons déjà fait, nous nous convainquons que \( u_k+iv_k\in A\) pour chaque \( k\). Nous avons
    \begin{equation}
        \| u_k+iv_k-u-iv \|_{\infty}\leq \| u_k-u \|_{\infty}+\| v_k-v \|_{\infty}
    \end{equation}
    En prenant \( k\) assez grand, les deux termes peuvent être rendus plus petit que \( \epsilon\).
\end{proof}

\begin{corollary}[\cite{MonCerveau}]        \label{CORooNIUJooLDrPSv}
    Soit \( B\), la boule fermée de centre \( 0\) et de rayon \( 1\) dans \( \eR^n\). La partie \( C^{\infty}(B,\eR^n)\) est dense dans \( \big( C(B,B),\| . \|_{\infty} \big)\).
\end{corollary}

\begin{proof}
    Soit \( f \in C(B,B)\) et \( \epsilon>0\). La fonction donnant la composante \( i\) est une fonction \( f_i\in C(B,\eR)\) et il existe donc, par le théorème de Stone-Weierstrass~\ref{ThoWmAzSMF}, une fonction \( g_i\in  C^{\infty}(B,\eR)\) telle que \( \| g_i-f_i \|_{\infty}\leq \epsilon\).

    La fonction \( g\) dont les composantes sont les \( g_i\) ainsi construits vérifie \( \| g-f \|_{\infty}\leq n\epsilon\).
\end{proof}

Attention toutefois que rien n'assure que les fonctions construites par le corollaire~\ref{CORooNIUJooLDrPSv} prennent leurs valeurs dans \( B\).

Le théorème suivant est un des énoncés les plus classiques de Stone-Weierstrass. Il découle évidemment du théorème général~\ref{ThoWmAzSMF} (encore qu'il faut alors bien comprendre qu'il faut traiter la fonction \( x\mapsto \sqrt{x}\) séparément). Il en existe cependant une preuve indépendante.

\begin{theorem}     \label{ThoGddfas}   
    Soit \( f\), une fonction continue de l'intervalle compact \( \mathopen[ a , b \mathclose]\) à valeurs dans \( \eR\). Alors pour tout \( \epsilon>0\), il existe un polynôme \( P\) tel que \( \| P-f \|_{\infty}<\epsilon\).

    Autrement dit, les polynômes sont denses dans \( C\mathopen[ a , b \mathclose]\) pour la norme uniforme.
\end{theorem}
\index{théorème!Stone-Weierstrass}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Primitive de fonction continue}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{proposition}[\cite{MQKDooSuEGxk}]    \label{PropQACVooBnHtRJ}
    Soit un intervalle compact \( K\) de \( \eR\) et une suite \( (f_n)\) de fonctions continues sur \( K\) telles que \( f_n\stackrel{unif}{\longrightarrow}f\). Si chacune des fonctions \( f_n\) a une primitive sur \( K\) alors \( f\) également.
\end{proposition}

\begin{proof}
    Soit \( x_0\in K\) et les primitives \( F_n\) choisies\footnote{Les fonctions \( F_n\) étant dérivables sont continues.} pour avoir \( F_n'f_n\) et \( F_n(x_0)=0\). Nous allons voir que \( (F_n)\) est une suite de Cauchy dans \( \big( K,\| . \|_{\infty} \big)\). Soient \( n,m\in \eN\) et \( x\in K\). Nous avons
    \begin{subequations}
        \begin{align}
            \| F_n-F_m \|_{\infty}&\leq \| F_n(x)-F_m(x) \|\\
            &=\| (F_n-F_m)(x) \|\\
            &\leq \| F'_n-F'_m \|_{[x,x_0]}\| x-x_0 \|
        \end{align}
    \end{subequations}
    où nous avons utilisé le théorème des accroissements finis~\ref{ThoNAKKght}. Vu que \( x\in K\) et que \( K\) est borné, \( \| x-x_0 \|\) est majoré par \( \diam(K)\) et
    \begin{subequations}
        \begin{align}
            \| F_n-F_m \|_K\leq \| f_n-f_m \|_K\diam(K).
        \end{align}
    \end{subequations}
    Vu que \( (f_n) \) est de Cauchy, si \( n\) et \( m\) sont assez grands, cela tend vers zéro. La suite \( (F_n)\) converge donc vers une certaine fonction \( F\).

    Le théorème~\ref{ThoSerUnifDerr} nous permet de permuter la limite et la dérivée pour conclure que \( F'=f\) et donc que \( f\) a une primitive sur \( K\).
\end{proof}

\begin{proposition}[\cite{MQKDooSuEGxk}]        \label{PropKKGAooDQYGKg}
    Soit un intervalle ouvert \( I\) de \( \eR\) et une fonction \( f\colon I\to \eR\) qui admet une primitive sur tout compact de \( I\). Alors \( f\) a une primitive sur \( I\).
\end{proposition}
\index{primitive!de fonction continue}

\begin{proof}
    Nous considérons une suite exhaustive\footnote{Voir le lemme~\ref{LemGDeZlOo}.} de compacts \( K_n\) pour \( I\) et \( x_0\in K_0\). Nous considérons aussi \( F_n\) la primitive de \( f\) sur \( K_n\) telle que \( F_n(x_0)=0\) (possible parce que \( x_0\in K_n\) pour tout \( n\)). Les fonctions \( F_n\) sont des restrictions les unes des autres, et nous pouvons définir
    \begin{equation}
        \begin{aligned}
            F\colon I&\to \eR \\
            x&\mapsto F_n(x)\text{ si } x\in K_n.
        \end{aligned}
    \end{equation}
    Nous avons évidemment \( F(x_0)=0\) et nous allons prouver que \( F\) est une primitive de \( f\) sur \( I\). Soit \( x\in I\) vu que \( I\) est ouvert, nous pouvons choisir \( n_0\) tel que \( x\in\Int(K_{n_0})\). Les fonctions \( F\) et \( F_{n_0}\) sont égales sur \( K_n\) et donc sur un ouvert autour de \( x\). Par conséquent \( F\) est dérivable en \( x\) et \( F'(x)=F'_{n_0}(x)=f(x)\).
\end{proof}

\begin{theorem}    \label{ThoEXXyooCLwgQg}
    Soit \( I\) un intervalle ouvert de \( \eR\). Une fonction continue sur \( I\) admet une primitive\footnote{Définition~\ref{DefXVMVooWhsfuI}.} sur \( I\).
\end{theorem}

\begin{proof}
    Sur chaque compact de \( I\), la fonction \( f\) est limite uniforme de polynômes\footnote{Si tu veux te passer de Stone-Weierstrass, tu peux prouver que toute fonction continue sur un compact est limite uniforme de fonctions affines par morceaux, par exemple. Voir \cite{MQKDooSuEGxk}.} (théorème de Stone-Weierstrass~\ref{ThoGddfas}). Donc \( f\) est primitivable sur tout compact de \( I\) (proposition~\ref{PropQACVooBnHtRJ}) et donc sur \( I\) par la proposition~\ref{PropKKGAooDQYGKg}.
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{La fonction puissance}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Si \( x\) et \( y\) sont des réels, définir \( x^y\) n'est pas une mince affaire. Pour l'instant nous savons déjà définir \( x^n\) lorsque \( x\in \eR\) et \( n\in \eN\). Voir la définition \ref{DEFooGVSFooFVLtNo} et le thème \ref{THEMEooBSBLooWcaQnR}.

Pour la suite nous notons
\begin{subequations}
    \begin{numcases}{}
        f_{\alpha}(x)=x^{\alpha}\\
        g_{a}(x)=a^x
    \end{numcases}
\end{subequations}
pour autant que ces fonctions sont définies\footnote{L'objet des pages suivantes est de déterminer pour quelles valeurs de $a$, $\alpha$ et $ x$ nous pouvons trouver des définitions raisonnables pour ces fonctions.}.

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Sur les naturels}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}      \label{DEFooKEBIooZtPkac}
    La fonction puissance définie sur \( \eN\) s'étend à \( \eZ\) de la façon suivante :
    \begin{equation}
        x^{-n}=\frac{1}{ x^n }
    \end{equation}
    pour \( n\geq 0\). Cela donne donne donc \( x^n\) pour \( x\in \eR\) et \( n\in \eZ\) a l'exception de \( x=0\) lorsque \( n<0\).
\end{definition}

Nous étudions quelques propriétés de cette fonction pour \( n>0\) fixé.

\begin{proposition}     \label{PROPooXQYFooPxoEHE}
    Soit \( n\in \eN\setminus\{ 0 \}\); nous posons \( f_n(x)=x^n\).

    Si \( n\) est pair,
    \begin{equation}
        f_n\colon \mathopen[ 0 , \infty \mathclose[\to \mathopen[ 0 , \infty \mathclose[
    \end{equation}
    est bijective.

    Si \( n\) est impair,
    \begin{equation}
        f_n\colon \eR \to \eR
    \end{equation}
    est bijective.

    Toutes les fonctions \( f_n\) sont continues sur \( \eR\).
\end{proposition}

\begin{proof}
    En plusieurs morceaux, pas spécialement dans l'ordre auquel on s'attend.
    \begin{subproof}
        \item[Continuité]

            Soit \( x\in \eR\). En vertu de~\ref{ThoLimCont} nous allons prouver que \( \lim_{\epsilon\to 0}f_n(x+\epsilon)=f_n(x)\). Pour cela nous utilisons la formule du binôme~\ref{PropBinomFExOiL} avec \( x,h>0\) :
            \begin{equation}
                f_n(x+h)=(x+h)^n=\sum_{k=0}^n{n\choose k}x^{n-k}h^k.
            \end{equation}
            Nous fixons \( x_0\in \eR\). Calcul :
            \begin{subequations}
                \begin{align}
                    | f_n(x_0+h)-f_n(x) |&=| \sum_{k=1}^n{n\choose k}x_0^{n-k}h^k |\\
                    &\leq \sum_{k=1}^n{n\choose k}| x_0 |^{n-k} |h|^k\\
                    &=h\sum_{k=1}^n{n\choose k}| x_0 |^{n-k}| h |^{k-1}\\
                    &\leq h\sum_{k=1}^n{n\choose k}| x_0 |^{n-k}.
                \end{align}
            \end{subequations}
            Justifications :
            \begin{itemize}
                \item
                   Le terme \( k=0\) est égal à \( x^n=f_n(x)\) parce que \( {n\choose 0}=1\).
               \item
                   Dans la somme nous avons majoré \( | h |\) par \( 1\), opération justifiée par le fait que nous ayons dans l'idée de faire \( h\to 0\).
            \end{itemize}
            Nous avons donc
            \begin{equation}
                \lim_{h\to 0} | f_n(x_0+h)-f_n(x) | \leq\lim_{h\to 0}  h\sum_{k=1}^n{n\choose k}| x_0 |^{n-k}=0.
            \end{equation}
            D'où la continuité de \( f_n\) en tout point \( x_0\in \eR\).

        \item[Pour \( n\) pair ou impair, bijection sur les positifs]
            Ceci sera déjà le résultat complet pour les \( n\) pairs, et a moitié du résultat pour les \( n\) impairs.
            \begin{subproof}
                \item[Stricte croissance]
                    Soit \( n\neq 0\) dans \( \eN\). Nous commençons par prouver que \( f_n\) est strictement croissante sur \( \mathopen[ 0 , \infty \mathclose[\). Nous repartons de la formule du binôme, mais cette fois, nous séparons les termes \( k=0\) et \( k=n\) des autres (si \( n=1\), il y a un peu de réécriture) en tenant compte de \( {n\choose 0}={n\choose n}=1\) :
                        \begin{equation}
                            f_n(x+h)=x^n+h^n+\sum_{k=1}^{n-1}{n\choose k}x^{n-k}h^k>x^n=f_n(x).
                        \end{equation}
                        Vous noterez que l'inégalité est stricte même si \( n=1\).

                        Vu que nous avons stricte monotonie, le théorème~\ref{ThoKBRooQKXThd}\ref{ITEMooMAWXooZXmVwA} nous dit que
                        \begin{equation}
                            f_n\colon \mathopen[ 0 , \infty \mathclose[\to f_n\big( \mathopen[ 0 , \infty \mathclose[ \big)
                        \end{equation}
                        est une bijection.
                    \item[Bijection]

                        Nous prouvons que \( f_n\big( \mathopen[ 0 , \infty \mathclose[ \big)=\mathopen[ 0 , \infty \mathclose[\). Si \( x>0\) alors \( f_n(x)>0\), cela prouve une inclusion.

                            Pour l'autre inclusion nous savons que \( f_n(x)>x\) dès que \( x>1\). Donc \( \lim_{x\to \infty} f_n(x)=\infty\). Si \( y\in \mathopen[ 0 , \infty \mathclose[\), alors il existe \( x_0\) tel que \( f_n(x_0)>y\). Étant donné que \( f_n(0)=0\) et que nous avons déjà prouvé que \( f_n\) était continue (proposition~\ref{PROPooXQYFooPxoEHE}), le théorème des valeurs intermédiaires~\ref{ThoValInter} nous indique l'existence de \( x_1\in \mathopen[ 0 , x_0 \mathclose[\) tel que \( f_n(x_1)=y\).

            \end{subproof}

            Nous avons prouvé que pour tout \( n\), la fonction
            \begin{equation}        \label{EQooYWHGooJWMTUI}
                f_n\colon \mathopen[ 0 , \infty \mathclose[\to \mathopen[ 0 , \infty \mathclose[
            \end{equation}
            est une bijection.

        \item[Pour \( n\) impair]

            Nous montrons à présent que si \( n\) est impair, alors
            \begin{equation}        \label{EQooTSLJooMAAUXH}
                f_n\colon \mathopen] -\infty , 0 \mathclose]\to \mathopen] -\infty , 0 \mathclose]
            \end{equation}
            est une bijection.

            Tout se base sur le fait que si \( x>0\) alors \( f_n(-x)=-f_n(x)\). Le fait que \eqref{EQooYWHGooJWMTUI} soit injective et surjective montre alors tout de suite le fait que \eqref{EQooTSLJooMAAUXH} soit également injective et surjective.
    \end{subproof}
\end{proof}

Vous noterez que la continuité de \( f_n\) démontrée dans la proposition \ref{PROPooXQYFooPxoEHE} est indépendant de la proposition \ref{LEMooUAFBooAwiXxj} qui sera invoquée plus tard pour définir \( a^x\) lorsque \( a>0\) dans \( \eR\).

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Sur les rationnels, racines}
%---------------------------------------------------------------------------------------------------------------------------

L'existence, pour tout réel \( a\geq 0\), d'une réel \( r\) tel que \( r^2=a\) est déjà faite en la proposition \ref{PROPooUHKFooVKmpte}.

\begin{definition}[Exposant rationnels]        \label{DEFooJWQLooWkOBxQ}
    La proposition \ref{PROPooXQYFooPxoEHE} nous dit entre autres que pour tout \( n\in \eN\), la fonction
    \begin{equation}
        \begin{aligned}
            f_n\colon \mathopen[ 0 , \infty \mathclose[&\to \mathopen[ 0 , \infty \mathclose[ \\
            x&\mapsto x^n 
        \end{aligned}
    \end{equation}
    est bijective. Nous définissions alors, pour \( a\in \mathopen[ 0 , \infty \mathclose[\),
    \begin{equation}
        a^{1/n}=f_n^{-1}(a).
    \end{equation}
    Autrement dit, le nombre \( a^{1/n}\) est l'unique solution positive de
    \begin{equation}
        x^n=a.
    \end{equation}
\end{definition}

\begin{normaltext}      \label{NORMooDUNZooUNdUKg}
    Nous ne définissons pas \( a^{1/n}\) pour \( a<0\), du moins pas encore. Vu que \( f_3\) est bijective sur \( \eR\), il serait tentant de définir \( (-1)^{1/3}=f_3^{-1}(-1)=-1\).

    Cela causera un certain nombre de problèmes plus tard vu que nous aurons envie de deux choses en même temps :
    \begin{itemize}
        \item d'une part \( \ln(-1)=i\pi\),
        \item d'autre part, \( a^x= e^{x\ln(a)}\).
    \end{itemize}
    De cette façon, nous devrions avoir
    \begin{equation}
        (-1)^{1/3}= e^{i\pi /3},
    \end{equation}
    qui est un nombre complexe non réel. Voici un exemple de ce que ça donne avec Sage :
    \lstinputlisting{tex/sage/sageSnip019.sage}
\end{normaltext}

\begin{definition}[Racince]     \label{DEFooPOELooPouwtD}
    Pour \( n\in \eN\) nous définissons \( \sqrt[n]{ x }=f_n^{-1}(x)\). Lorsque \( n\) est pair, la fonction \( x\mapsto\sqrt[n]{ x }\) n'est définie que sur \( \eR^+\), et lorsque \( n\) est impair, elle est définie sur tout \( \eR\).
\end{definition}

\begin{normaltext}      \label{NORMooYPRNooWCjEgR}
    Notons que les fonctions \( x\mapsto \sqrt[3]{ x }\) et \( x\mapsto x^{1/3}\) ne sont pas les mêmes : la première est définie sur tout \( \eR\) et donne des valeurs réelles tandis que la seconde n'est (pour l'instant) définie que sur les positifs, et donnera (quand on l'aura définie par l'exponentielle) des nombres complexes sur les négatifs.

    En suivant cette convention, c'est-à-dire en réservant la notation \( \sqrt{  }\) pour l'inverse de \( f_2\), nous ne devrions pas écrire des choses comme «\( \sqrt{ -1 }=i\)», mais plutôt «\( (-1)^{1/2}=i \)». En effet, \( \sqrt{ -1 }\) n'est pas défini et ne sera jamais défini alors que \( (-1)^{1/2}\) n'est pas encore défini, mais sera défini par 
    \begin{equation}
        (-1)^{1/2}= e^{\frac{ 1 }{2}\ln(-1)}= e^{i\pi/2}=i.
    \end{equation}
\end{normaltext}

En résumé, nous avons les fonctions suivantes :
\begin{enumerate}
    \item
        \( \sqrt[n]{  }\colon \eR\to \eR\) si \( n\) est impair,
    \item
        \( \sqrt[n]{  }\colon \mathopen[ 0 , \infty \mathclose[\to \mathopen[ 0 , \infty \mathclose[ \) si \( n\) est pair,
    \item
        \( x^{1/n}\colon \mathopen[ 0 , \infty \mathclose[\to \mathopen[ 0 , \infty \mathclose[\) pour tout \( n\in \eN\).
\end{enumerate}
Cependant nous n'hésiterons pas à utiliser la notation \( \sqrt{ x }\) pour \( x^{1/2}\) même lorsque \( x\) est négatif, parce c'est une notation très pratique. Il faut garder en tête que cette façon de faire est incohérente parce qu'elle inciterait à penser que \( \sqrt[3]{-1  }= e^{i\pi/3}\) au lieu de \( \sqrt[3]{-1  }=-1\).

Pour toute la suite de cette section, nous allons considérer \( a^x\) uniquement pour \( a>0\).

\begin{definition}
    Pour \( m,n\in \eN\) nous définissons 
    \begin{equation}        \label{EQooZFOAooTsMbub}
        a^{m/n}=(a^m)^{1/n},
    \end{equation}
    ce qui définit la fonction puissance sur \( \eQ^+\). Enfin nous posons
    \begin{equation}
        a^{-q}=\frac{1}{ a^q }
    \end{equation}
    lorsque \( q\in \eQ^+\).

    Et avec tout ça, lorsque \( a>0\) nous avons défini \( a^q\) pour tout \( q\in \eQ\).
\end{definition}

Nous allons souvent noter la définition \eqref{EQooZFOAooTsMbub} sous la forme
\begin{equation}        \label{EQooZIKKooVfjkZo}
    f_{m/n}(x)^n=x^m.
\end{equation}

\begin{lemma}[\cite{MonCerveau}]        \label{LEMooIDLJooZALNaD}
    Pour \( a>0\) et \( p,q\in \eZ\) nous avons :
    \begin{equation}
        a^{p/q}=(a^p)^{1/q}=(a^{1/q})^p.
    \end{equation}
\end{lemma}

\begin{proof}
    Nous divisons la preuve en fonction de la positivité du numérateur et du dénominateur.
    \begin{subproof}
        \item[Numérateur et dénominateurs positifs]
                
            Nous commençons avec \( p,q\in \eN\). La première égalité est la définition \ref{DEFooJWQLooWkOBxQ}. Pour la seconde, la définition de \( (a^p)^{1/q}\) est d'être le \( x>0\) tel que
            \begin{equation}
                x^q=a^p.
            \end{equation}
            La définition de \( a^{1/q}\) est d'être le \( y>0\) tel que
            \begin{equation}
                y^q=a.
            \end{equation}
            Ce \( y\) vérifie donc aussi \( y^{pq}=a^p\) et donc \( (y^p)^q=a^p\). Autrement dit, \( y^p=x\), c'est-à-dire exactement
            \begin{equation}
                (a^{1/q})^p=(a^p)^{1/q}.
            \end{equation}
            Le lemme est prouvé dans le cas où \( p,q\in \eN\).

        \item[Numérateur et dénominateur négatifs]

            Si \( p\) et \( q\) sont tous les deux négatifs, nous remarquons que \( p/q=(-p)/(-q)\) et nous sommes dans le même cas qu'avant.

        \item[Numérateur négatif, dénominateur positif]

            Pour simplifier les notations nous supposons toujours \( p,q\in \eN\) mais nous considérons \( a^{(-p)/q}\). Nous avons d'une part :
            \begin{equation}
                a^{(-p)/q}=a^{-(p/q)}=\frac{1}{ a^{p/q} }=\frac{1}{ (a^{1/q})^p }=(a^{1/q})^{-p}.   
            \end{equation}
            Dans ce calcul, nous avons utilisé au dénominateur le résultat dans le cas positif. 

            Et d'autre part nous avons :
            \begin{equation}
                (a^{-p})^{1/q}=\left( \left( \frac{1}{ a } \right)^p \right)^{1/q}=\left( \left( \frac{1}{ a } \right)^{1/q} \right)^p=\left( \frac{1}{ a^{1/q} } \right)^p=\frac{1}{ (a^{1/q})^p }=(a^{1/q})^{-p}
            \end{equation}
            où nous avons utilisé le résultat avec \( 1/a\) en guise de \( a\).

        \item[Numérateur positif, dénominateur négatif]

            Nous traitons maintenant \( a^{p/(-q)}\). Nous avons d'une part
            \begin{equation}
                a^{p/(-q)}=a^{-(p/q)}=\frac{1}{ a^{p/q} }=\frac{1}{ (a^p)^{1/q} }=(a^p)^{-(1/q)}=(a^p)^{1/(-q)}.
            \end{equation}
            Et d'autre part :
            \begin{equation}
                a^{p/(-q)}=\frac{1}{ a^{p/q} }=\frac{1}{ (a^{1/q})^p }=\left( \frac{1}{ a^{1/q} } \right)^p=\left( a^{-(1/q)} \right)^p=(a^{1/(-q)})^p.
            \end{equation}
    \end{subproof}
\end{proof}

Le lemme suivant montre que la définition sur \( \eQ^-\) est cohérente avec celle sur \( \eQ^+\), au sens où finalement nous retrouvons que \( a^{m/n}\) vérifie \( x^n=a^m \) quel que soient les signes de \( m\) et \( n\).
\begin{lemma}[\cite{MonCerveau}]
    Le nombre \( y=a^{-m/n}\) vérifie l'équation \( y^{-n}=a^m\)
\end{lemma}

\begin{proof}
    Nous posons \( x=a^{m/n}\), c'est-à-dire \( x^n=a^m\). Nous avons, par définition \( y=a^{-m/n}=\frac{1}{ x }\). Alors
    \begin{equation}
        y^{-n}=\frac{1}{ \left( \frac{1}{ x } \right)^n }=x^n=a^m,
    \end{equation}
    donc c'est bon.
\end{proof}

\begin{lemma}[\cite{MonCerveau}]        \label{LEMooJYGUooHhLASp}
    Pour \( a>0\) et \( q,q'\in \eQ\) nous avons
    \begin{equation}
        a^qa^{q'}=a^{q+q'}.
    \end{equation}
\end{lemma}

\begin{proof}
    Nous mettons \( q\) et \( q'\) au même dénominateur. Soient \( q=s/c\) et \( q'=r/c\) avec \( s,r\in \eZ\) et \( c\in \eN\). En utilisant les égalités du lemme \ref{LEMooIDLJooZALNaD} nous trouvons
    \begin{equation}
        a^{s/c}a^{r/c}=(a^{1/c})^s(a^{1/c})^r=(a^{1/c})^{s+r}=a^{(s+r)/c}=a^{q+q'}.
    \end{equation}
\end{proof}

\begin{lemma}[\cite{MonCerveau}]        \label{LEMooXJXUooLoiTMo}
    La fonction puissance prend les valeurs suivantes.
    \begin{enumerate}
        \item
            Si \( a=1\) alors \( a^q=1\) pour tout \( q\in \eQ\).
        \item       \label{ITEMooKZCGooKskUQx}
            Si \( a>1\) alors 
            \begin{itemize}
                \item \( a^q>1\) si \( q>0\)
                \item \( a^q<1\) si \( q<0\)
                \item \( a^0=1\).
            \end{itemize}
        \item
            Si \( a<1\) alors 
            \begin{itemize}
                \item \( a^q<1\) si \( q>0\)
                \item \( a^q>1\) si \( q<0\)
                \item \( a^0=1\).
            \end{itemize}
    \end{enumerate}
\end{lemma}

\begin{proof}
    Si \( a=1\) alors \( a^k=1\) pour tout \( k\in \eN\). Ensuite, pour \( m,n\in \eN\), \( a^{n/m}\) est solution de \( x^m=a^n=1\), donc \( x=1\). En ce qui concerne les puissances négatives, \( 1/1=1\).

    Si \( a>1\) alors \( a^k>1\) pour tout \( k\in \eN\). De plus pour \( q>0\) nous avons \( q=m/n\) avec \( m,n\in \eN\). Alors \( a^{m/n}\) est solution de \( x^m=a^n>1\). Or pour \( x\leq 1\) nous avons \( x^m\leq 1\), donc la solution à \( x^m=a^n\) vérifie forcément \( x>1\).

    Toujours avec \( a>1\), si \( q<0\) nous posons \( q=-q'\) avec \( q'>0\). Alors
    \begin{equation}
        a^q=q^{-q'}=\frac{1}{ a^{q'} }.
    \end{equation}
    Mais \( a^{q'}>1\), donc l'inverse est inférieur à \( 1\).

    En ce qui concerne les cas \( a<1\), ils sont obtenus en posant \( b=1/a\) et en calculant
    \begin{equation}
        a^q=\left( \frac{1}{ b } \right)^q=\frac{1}{ b^q }=b^{-q}.
    \end{equation}
\end{proof}

\begin{proposition}[\cite{MonCerveau}]\label{PROPooVXKBooQPPjMn}
    Si \( a>1\) et si \( M>0\), il existe \( n\in \eN\) tel que \( a^n>M\).
\end{proposition}

\begin{proof}
    Soit \( a=1+h\). Alors en utilisant la formule du binôme, 
    \begin{equation}
        a^n=(1+h)^n=\sum_{k=0}^n{n\choose k}h^{n-k}.
    \end{equation}
    Tous les termes de la somme sont strictement positifs. Prenons le terme \( k=n-1\). Il vaut
    \begin{equation}
        {n\choose n-1}h=nh.
    \end{equation}
    Donc \( a^n\geq nh\), donc oui, cela peut être rendu arbitrairement grand avec \( n\) sans toucher à \( a\).
\end{proof}

\begin{proposition}[\cite{MonCerveau}]      \label{PROPooGCBZooTcyGtO}
    Pour \( a>0\) nous considérons la fonction
    \begin{equation}
        \begin{aligned}
            g_a\colon \eQ&\to \eR \\
            q&\mapsto a^q.
        \end{aligned}
    \end{equation}
    \begin{enumerate}
        \item
            Si \( a\in \mathopen] 0 , 1 \mathclose[\) alors \( g_a\) est décroissante et
            \begin{subequations}
                \begin{align}
                    \lim_{q\to \infty} g_a(q)=0,&& \lim_{q\to -\infty} g_a(q)=\infty.
                \end{align}
           \end{subequations}
         \item
            Si \( a>1\)  alors \( g_a\) est croissante et
            \begin{subequations}
                \begin{align}
                    \lim_{q\to \infty} g_a(q)=\infty,&& \lim_{q\to -\infty} g_a(q)=0.
                \end{align}
           \end{subequations}
    \end{enumerate}
\end{proposition}

\begin{proof}
    Nous prouvons le cas \( a>1\). L'autre cas s'en déduit en posant \( b=1/a\). Pour la croissance, soient \( q\in \eQ\) et \( r>0\) dans \( \eQ\). En utilisant le lemme \ref{LEMooJYGUooHhLASp}, nous avons
    \begin{equation}
        a^{q+r}=a^qa^r>a^q
    \end{equation}
    parce que \( a^r>1\) par le lemme \ref{LEMooXJXUooLoiTMo}. 

    En ce qui concerne la limite \( q\to \infty\), la fonction \( g_a\) est croissante et non bornée par la proposition \ref{PROPooVXKBooQPPjMn}. Donc sa limite est \( \infty\).

    Pour la limite \( q\to -\infty\), nous avons
    \begin{equation}
        \lim_{q\to -\infty} a^q=\lim_{q\to \infty} a^{-q}=\lim_{q\to \infty} \frac{1}{ a^q }=0.
    \end{equation}
\end{proof}

\begin{proposition}[\cite{MonCerveau}]      \label{PROPooIIDGooTRtlUD}
    Soit \( a>0\). Nous avons
    \begin{equation}
        \lim_{x\to 0} a^x=1.
    \end{equation}
    Notons que dans cette limite, \( x\in \eQ\) parce que nous n'avons même pas encore défini \( a^x\) lorsque \( x\) est irrationnel.
\end{proposition}

\begin{proof}
    Nous notons, comme à l'accoutumée, \( g_a(x)=a^x\). Soit une suite \( x_k\to 0\) (avec \( x_k\neq 0\) pour tout \( k\)). En définissant \( y_k\) par \( x_k=1/y_k\) nous savons que \( a^{1/y_k}\) est la solution de \( x^{y_k}=a\).

    Nous posons \( t_k=a^{x_k}\) et notre but est de prouver que \( t_k\to 1\). Pour tout \( k\) nous avons la relation
    \begin{equation}
        t_k^{y_k}=a.
    \end{equation}
    Soit \( s>1\). Il existe un \( M>0\) tel que \( y_k>M\) implique \( s^{y_k}>a\) (proposition \ref{PROPooVXKBooQPPjMn}). Donc dès que \( y_k>M\) nous avons \( t_k<s\).

    De la même manière, si \( r<1\), il existe un \( R>0\) tel que \( y_k>R\) implique \( r^{y_k}<a\). Donc dès que \( y_k>R\) nous avons \( t_k>r\).

    Soit donc un voisinage \( \mathopen] r , s \mathclose[\) de \( 1\) (avec \( r<1\) et \( s>1\)). Nous avons les nombres \( M\) et \( R\) correspondant et nous posons \( L=\max\{ M,R \}\). Soit \( K\) tel que \( k>K\) implique \( y_k>L\). Alors pour \( k>K\) nous avons aussi \( t_k<s\) et \( t_k>r\), c'est-à-dire \( t_k\in \mathopen] r , s \mathclose[\).

        Cela prouve que \( t_k\to 1\).

        Donc pour toute suite \( x_k\to 0\) nous avons \( g_a(x_k)\to 1\). Par le critère séquentiel de la limite (proposition \ref{PROPooJYOOooZWocoq}) nous avons \( \lim_{x\to 0} g_a(x)=1\).
\end{proof}

\begin{lemma}       \label{LEMooKDBPooLQwxMD}
    Soit \( a>0\). La fonction
    \begin{equation}
        \begin{aligned}
            g_a\colon \eQ&\to \eR \\
            x&\mapsto a^x 
        \end{aligned}
    \end{equation}
    est continue.
\end{lemma}

\begin{proof}
    Soient \( x\in \eQ\) et une suite \( x_k\to 0\) (toujours dans \( \eQ\)) et utilisons le lemme \ref{LEMooJYGUooHhLASp} :
    \begin{equation}
        a^{x+x_k}=a^xa^{x_k}.
    \end{equation}
    Cela est, dans \( \eR\), le produit entre une constante (\( a^x\)) et une suite. La limite est donc le produit de cette constante et la limite de la suite (si elle existe). Par la proposition \ref{PROPooIIDGooTRtlUD} nous avons la limite \( a^{x_k}\to 1\), et donc
    \begin{equation}
        \lim_{k\to \infty} a^{x+x_k}=a^x,
    \end{equation}
    ce qui prouve la continuité (caractérisation séquentielle, proposition \ref{PropFnContParSuite}) de \( g_a\).
\end{proof}

\begin{propositionDef}[Fonction puissance\cite{MonCerveau}]  \label{DEFooOJMKooJgcCtq}
    Si \( a>0\) et \( x\in \eR\), la fonction
    \begin{equation}
        \begin{aligned}
            g_a\colon \eQ&\to \eR \\
            x&\mapsto a^x. 
        \end{aligned}
    \end{equation}
    est continue par le lemme \ref{LEMooKDBPooLQwxMD}. Si \( x\in \eR\) nous définissons
    \begin{equation}
        a^x=\tilde g_a(x)
    \end{equation}
    où \( \tilde g_a\) est l'extension de \( g_a\) donnée par le lemme \ref{LEMooUAFBooAwiXxj}.

    Nous allons la noter \( g_a\) également, et écrire \( a^x\) la valeur de \( g_a\) même lorsque \( x\) n'est pas un rationnel.
\end{propositionDef}

\begin{proposition}[\cite{MonCerveau}]      \label{PROPooVADRooLCLOzP}
    Quelque propriétés de la fonction puissance. 
    \begin{enumerate}
        \item       \label{ITEMooQHYRooJIewyp}
            Pour \( a>0\), la fonction \( g_a\colon x\mapsto a^x\) est continue sur \( \eR\).
        \item       \label{ITEMooIZBLooSGtWIp}
            Pour \( a>1\), la fonction \( g_a\colon x\mapsto a^x\) est croissante.
        \item       \label{ITEMooSCJBooNVJZah}
            Pour \( a>0\) et \( x,y\in \eR\) nous avons
            \begin{equation}        \label{EQooEWIHooDRAQGR}
                a^xa^y=a^{x+y}.
            \end{equation}
            En particulier, 
            \begin{equation}
                a^{-x}=\frac{1}{ a^x }.
            \end{equation}
    \end{enumerate}
\end{proposition}

\begin{proof}
    La continuité de \( x\mapsto a^x\) est par construction. Le point \ref{ITEMooQHYRooJIewyp} est fait.

    Pour le point \ref{ITEMooIZBLooSGtWIp}, lorsque \( a>1\), la fonction \( f_a\colon \eQ\to \eR\) est croissante (proposition \ref{PROPooGCBZooTcyGtO}). Donc par la proposition \ref{PROPooTNIAooNAJDzL}, la fonction \( x\mapsto a^x\) est croissante sur \( \eR\).

    Et enfin pour le point \ref{ITEMooSCJBooNVJZah}, il faut faire un peu plus attention. Soient des suites \( x_i\to x\) et \( y_i\to y\) dans \( \eQ\). Calculons :
    \begin{subequations}        \label{SUBEQSooMPNLooPoyjwJ}
        \begin{align}
            a^xa^y&=(\lim_ia^{x_i})a^y      \label{SUBEQooOCIOooZcewMo} \\
            &=\lim_i\big( a^{x_i}a^y \big)   \label{SUBEQooEKQXooPLqzcG}\\
            &=\lim_i\big( \lim_ka^{x_i}a^{y_k} \big)    \label{SUBEQooZEXDooRytDvS}\\
            &=\lim_i\big( \lim_k a^{x_i+y_k} \big)     \label{SUBEQooSYNBooIQZJzl}\\
            &=\lim_ia^{x_i+y}                           \label{SUBEQooKHKCooGwaPDQ}\\
            &=a^{x+y}.                                  \label{SUBEQooMZBFooSoSgKU}
        \end{align}
    \end{subequations}
    Justifications :
    \begin{itemize}
        \item Pour \ref{SUBEQooOCIOooZcewMo}. Définition de \( a^x\) lorsque \( x\in \eR\).
        \item Pour \ref{SUBEQooEKQXooPLqzcG}. Nous entrons le nombre \( a^y\) dans la limite. Entrer un facteur dans une limite convergente dans \( \eR\) est un acte anodin.
        \item Pour \ref{SUBEQooZEXDooRytDvS}. Définition de \( a^y\), et renter le nombre réel \( a^{x_i}\) dans la limite sur \( k\).
        \item Pour \ref{SUBEQooSYNBooIQZJzl}. Utilisation du lemme \ref{LEMooJYGUooHhLASp}, valable pour \( x_i,y_k\in \eQ\).
        \item Pour \ref{SUBEQooKHKCooGwaPDQ}. Pour \( i\) fixé, la suite \( k\mapsto x_i+x_k\) est une suite de rationnels qui converge vers le réel \( x_i+y\). Par définition \ref{DEFooOJMKooJgcCtq} de la fonction puissance nous avons alors \( \lim_ka^{x_i+y_k}=a^{x_i+y}\).
        \item Pour \ref{SUBEQooMZBFooSoSgKU}. La suite de réels \( i\mapsto x_i+y\) converge dans \( \eR\) vers le réel \( x+y\). Par la continuité de \( t\mapsto a^t\) (ça fait partie du lemme \ref{LEMooUAFBooAwiXxj} définissant la fonction puissance sur \( \eR\)) nous avons \( \lim_ia^{x_i+y}=a^{x+y}\).
    \end{itemize}

    Vous remarquerez que les limites sur \( k\) et sur \( i\) ne s'enlèvent pas tout à fait avec la même justification. Nous aurions pu invoquer la continuité sur \( \eR\) de \( t\mapsto a^t\) pour les deux limites. Mais cette continuité, dans le cas d'une suite purement constituée de rationnels, est la définition de la prolongation vers \( \eR\).
\end{proof}

\begin{lemma}       \label{LEMooIPLLooCgpCIn}
    Soient \( a,b>0\). Si \( 1<x<y\) alors
    \begin{equation}
        a-b<ay-bx.
    \end{equation}
\end{lemma}

\begin{proof}
    Nous posons \( y=x+s\) avec \( s>0\). Alors
    \begin{equation}
        ay-bx=a(x+s)-bx=(a-b)x+as>(a-b)x>a-b
    \end{equation}
    parce que \( as>0\) et \( x>1\).
\end{proof}

\begin{proposition}[\cite{MonCerveau}]      \label{PROPooJXHFooCDwxCS}
    Pour \( q>0\) dans \( \eQ\), la fonction
    \begin{equation}
        \begin{aligned}
            f_{q}\colon \eQ^+&\to \eR \\
                x&\mapsto x^{q} 
        \end{aligned}
    \end{equation}
    est strictement croissante.
\end{proposition}

\begin{proof}
    Division selon la généralité de \(q\).
    \begin{subproof}
        \item[Si \( q\) est entier positif]
            Soit \( q=n\in \eN\). Si \( s>0\) alors l'inégalité \( (x+s)^n>x^n\) découle du binôme de Newton de la proposition \ref{PropBinomFExOiL}.
        \item[Si \( q\) est rationnel]
            Soient un rationnel \( q=m/n\) et un nombre strictement positif \( s\). Nous avons, par la définition \ref{DEFooJWQLooWkOBxQ} sous la forme \eqref{EQooZIKKooVfjkZo} :
            \begin{equation}
                f_{m/n}(x+s)^n=(x+s)^m>x^m=f_{m/n}(x)^n.
            \end{equation}
            Nous avons utilisé la stricte croissance de \( x\mapsto x^m\). Cela donne
            \begin{equation}
                f_{m/n}(x+s)^n>f_{m/n}(x)^n.
            \end{equation}
            En utilisant encore la stricte croissance de \( x\mapsto x^n\), nous avons le résultat.
    \end{subproof}
\end{proof}

\begin{corollary}       \label{CORooYWNNooLwKmiD}
    Soient \( 1<b<a\) dans \( \eR\) et des rationnels strictement positifs \( p<q\). Alors
    \begin{equation}
        a^p-b^p<a^q-b^q
    \end{equation}
\end{corollary}

\begin{proof}
    Nous notons \( q=p+r\) avec \( r>0\) dans \( \eQ\). Par la proposition \ref{PROPooJXHFooCDwxCS},
    \begin{equation}
        a^r>b^r.
    \end{equation}
    Cela nous permet d'utilise le lemme \ref{LEMooIPLLooCgpCIn} pour écrire
    \begin{equation}
        a^p-b^p<a^pa^r-b^pb^r=a^q-b^q.
    \end{equation}
\end{proof}

\begin{proposition}[\cite{MonCerveau}]      \label{PROPooKWRGooMTbRdU}
    Soient \( a,b>0\) et \( \alpha\in \eR\). Nous avons :
    \begin{equation}
        a^{\alpha}b^{\alpha}=(ab)^{\alpha}.
    \end{equation}
\end{proposition}

\begin{proof}
    Nous supposons que c'est bon pour \( \alpha\in \eN\) et \( \alpha\in \eZ\). Pour les autres, nous donnons plus de détails.
    \begin{subproof}
        \item[\( \eQ^+\)]
            Soit \( q=m/n\) avec \( m,n\in \eN\). Si \( a^{m/n}=x\) et \( b^{m/n}=y\), alors
            \begin{subequations}
                \begin{align}
                    x^n&=a^m    \label{EQooGNMAooQJMNsL}\\
                    y^n&=b^m
                \end{align}
            \end{subequations}
            par \eqref{EQooZIKKooVfjkZo}. Nous multiplions \eqref{EQooGNMAooQJMNsL} par \( y^n\) à gauche et par \( b^m\) à droite : \( x^ny^n=a^mb^m\). En tenant compte du résultat pour \( \eN\), nous avons
            \begin{equation}
                (xy)^n=(ab)^m,
            \end{equation}
            ce qui signifie que le nombre \( xy\) est \( (ab)^{m/n}\).
        \item[Pour \( \eQ^-\)]
            Soit \( q\in \eQ^+ \), nous avons le calcul
            \begin{equation}
                a^{-q}b^{-q}=\frac{1}{ a^qb^q }=\frac{1}{ (ab)^q }=(ab)^{-q}.
            \end{equation}
        \item[Pour \( \eR\)]
            Soit une suite de rationnels \( \alpha_i\to \alpha\). Nous avons
            \begin{equation}
                a^{\alpha}b^{\alpha}=\big( \lim_ia^{\alpha_i} \big)\big( \lim_j b^{\alpha_j} \big)=\lim_i\big( a^{\alpha_i}b^{\alpha_i}\big)=\lim_i(ab)^{\alpha_i}=(ab)^{\alpha}.
            \end{equation}
            Justifications :
            \begin{itemize}
                \item la proposition \ref{PROPooIQOAooJPMoDD} pour le produit des limites,
                \item le résultat dans \( \eQ\) que nous venons de prouver,
                \item la définition de \( (ab)^{\alpha}\) comme limite de \( (ab)^{\alpha_i}\).
            \end{itemize}
    \end{subproof}
\end{proof}
    
Pour rappel, la proposition suivantes, dans le cas de \( \alpha\in \eQ^+\) est la proposition \ref{PROPooJXHFooCDwxCS}.
\begin{proposition}[\cite{MonCerveau}]      \label{PROPooRXLNooWkPGsO}
    Pour \( \alpha>0\), la fonction
    \begin{equation}
        \begin{aligned}
            f_{\alpha}\colon\mathopen] 0 , \infty \mathclose[&\to \eR \\
                x&\mapsto x^{\alpha} 
        \end{aligned}
    \end{equation}
    est strictement croissante.

    Aussi, la fonction
    \begin{equation}
        \begin{aligned}
        f_{\alpha}\colon  \mathopen] -\infty , 0 \mathclose[  &\to \eR \\
                x&\mapsto x^{\alpha} 
        \end{aligned}
    \end{equation}
    est strictement décroissante.
\end{proposition}

\begin{proof}
    Nous rappellons que le cas \( \alpha\in \eQ^+\) est déjà traité par la proposition \ref{PROPooJXHFooCDwxCS}. Soient \( x\in \mathopen] 0 , \infty \mathclose[\) et \( s>0\). Nous allons montrer que \( f_{\alpha}(x+s)-f_{\alpha}(x)>0\). Pour cela nous décomposons en plusieurs cas.
    \begin{subproof}
        \item[\( x>1\)]
            Par la proposition \ref{PROPooFGBOooHiZqbs}, nous considérons une suite strictement croissante de rationnels strictement positifs \( \alpha_i\to \alpha\). Pour tout \( i\) nous avons \( \alpha_i>\alpha_0\).

            En utilisant la stricte croissance de \( f_{\alpha_0}\) et le lemme \ref{LEMooXJXUooLoiTMo}\ref{ITEMooKZCGooKskUQx}, nous avons les inégalités \( 1<x^{\alpha_0}<(x+s)^{\alpha_0}\), et en particulier
            \begin{equation}
                0<(x+s)^{\alpha_0}-x^{\alpha_0}.
            \end{equation}
            De plus nous avons \( 1<x<x+s\) et \( \alpha_0<\alpha_i\) pour tout \( i\). Donc le corollaire \ref{CORooYWNNooLwKmiD} s'applique et nous avons, pour tout \( i\) :
            \begin{equation}
                0<(x+s)^{\alpha_0}-x^{\alpha_0}<(x+s)^{\alpha_i}-x^{\alpha_i}.
            \end{equation}
            C'est le moment de passer à la limite \( i\to \infty\). La seconde inégalité devient non stricte, mais la première reste :
            \begin{equation}
                0<(x+s)^{\alpha_0}-x^{\alpha_0}\leq(x+s)^{\alpha}-x^{\alpha}.
            \end{equation}
            Nous avons donc bien la stricte croissance de \( f_{\alpha}\) sur \( \mathopen] 1 , \infty \mathclose[\).
        \item[\( x\leq 1\)]
            Nous choisissons encore \( \alpha_i\to \alpha\) strictement croissante dans \( \eQ\). Pour chaque \( i\), nous avons encore
            \begin{equation}
                (x+s)^{\alpha_i}-x^{\alpha_i}>0.
            \end{equation}
            Le passage à la limite change l'inégalité stricte en inégalité large, et ne permet donc pas de conclure immédiatement. Nous devons donc ruser. Soit \( k\in \eN\) tel que \( k(x+s)>1\) et \( kx>1\) (existence parce que \( \eR\) est archimédien, proposition \ref{ThoooKJTTooCaxEny}). Nous avons :
            \begin{equation}
                \big( k(x+s) \big)^{\alpha}-(kx)^{\alpha}>0
            \end{equation}
            par la partie «\( x>1\)» que nous venons de prouver. Grâce à la proposition \ref{PROPooKWRGooMTbRdU} nous pouvons factoriser \( k^{\alpha}\) :
            \begin{equation}
                0<\big( k(x+s) \big)^{\alpha}-(kx)^{\alpha}=k^{\alpha}\big( (x+s)^{\alpha}-x^{\alpha} \big).
            \end{equation}
            Vu que \( k^{\alpha}>0\), cela implique \( (x+s)^{\alpha}-x^{\alpha}>0\), ce qu'il fallait.
    \end{subproof}
Nous avons fini de prouver que la fonction \( f_{\alpha}\) était strictement croissante sur \( \mathopen] 0 , \infty \mathclose[\). En ce qui concerne la fonction \( f_{\alpha}\) sur \( \mathopen] -\infty , 0 \mathclose[\), nous avons, pour \( x>0\) que
    \begin{equation}
        f_{\alpha}(-x)=\frac{1}{ f_{\alpha}(x) },
    \end{equation}
    et donc stricte décroissance.
\end{proof}

Nous prouvons à présent que \( f_{\alpha}\) est localement injective; nous en avons besoin pour prouver la continuité. Or cette continuité est nécessaire à prouver que \( f_{\alpha}\) est localement bijective. Donc nous ne pouvons pas énoncer la bijectivité ici. Ce sera la proposition \ref{PROPooEXGKooCqzLor}.

\begin{proposition}     \label{PROPooHKTKooCUEBjh}
    Soient \( \alpha\in \eR\) et \( x\in \eR\setminus\{ 0 \}\). Il existe un voisinage \( V\) de \( x\) sur lequel
    \begin{equation}
            f_{\alpha}\colon V \to f_{\alpha}(V) 
    \end{equation}
    est injective.
\end{proposition}

\begin{proof}
Soit \( x>0 \); nous considérons un voisinage \( V\) de \( x\) inclu à \( \mathopen] 0 , \infty \mathclose[\). Soit \( y\in V\); pour fixer les idées nous supposons \( y<x\). Par la stricte croissance de \( f_{\alpha}\) sur \( \mathopen] 0 , \infty \mathclose[\) (proposition \ref{PROPooRXLNooWkPGsO}), nous avons \( f_{\alpha}(y)<f_{\alpha}(x)\) et en particulier \( f_{\alpha}(x)\neq f_{\alpha}(y)\).

Le cas \( x<0\) se traite de façon analogue, avec la stricte décroissance de \( f_{\alpha}\) sur \( \mathopen] -\infty , 0 \mathclose[\).
\end{proof}
Notons que les voisinages sur lesquels \( f_{\alpha}\) est injective sont assez grands. Ils peuvent être toute une demi-droite, si l'on veut.

\begin{lemma}   \label{LEMooQTNKooLVEytN}
    Soient \( \alpha>0\), une suite de rationnels strictement décroissante \( \alpha_i\to \alpha\) ainsi que les fonctions
    \begin{equation}
        \begin{aligned}
        f_{\alpha_i}\colon \mathopen] 1 , \infty \mathclose[&\to \eR \\
            x&\mapsto x^{\alpha_i}. 
        \end{aligned}
    \end{equation}
    La famille \( \{ f_{\alpha_i} \}_{i\in \eN}\) est équicontinue\footnote{Définition \ref{DEFooSGMVooASNbxo}.}.
\end{lemma}

\begin{proof}
    Soient \( x>1\), et \( \alpha>0\). Nous allons montrer que \( \{ f_{\alpha_i} \}\) est équicontinue en \( x\). Soit \( s\) tel que \( 1<x<x+s\); le corollaire \ref{CORooYWNNooLwKmiD} nous enseigne que 
    \begin{equation}
        (x+s)^p-x^p<(x+s)^q-x^q
    \end{equation}
    dès que \( p<q\). En particulier, \( f_p\) étant croissante par la proposition \ref{PROPooRXLNooWkPGsO},
    \begin{equation}
        0<(x+s)^{\alpha_i}-x^{\alpha_i}<(x+s)^{\alpha_0}-x^{\alpha_0}.
    \end{equation}
    Soit \( \epsilon>0\) et \( \delta\) tel que \( s<\delta\) implique \( | (x+s)^{\alpha_0}-x^{\alpha_0} |<\epsilon\). Alors nous avons aussi, pour de tels \( \sigma\) et \( s\) :
    \begin{equation}
        |(x+s)^{\alpha_i}-x^{\alpha_i}|<|(x+s)^{\alpha_0}-x^{\alpha_0}|<\epsilon.
    \end{equation}
    En procédant de même\ pour \( s<0\), nous trouvons bien que
    \begin{equation}
        | y^{\alpha_i}-x^{\alpha_i} |\leq \epsilon
    \end{equation}
    pour tout \( y\in B(x,\delta)\).

    Cela signifie que \( \{ f_i \}\) est équicontinue.
\end{proof}


\begin{proposition}[\cite{MonCerveau}]      \label{PROPooUQNZooSSHLqr}
    Soit \( \alpha>0\) dans \( \eR\). La fonction
    \begin{equation}
        \begin{aligned}
            f_{\alpha}\colon \eR&\to \eR \\
            x&\mapsto x^{\alpha} 
        \end{aligned}
    \end{equation}
    est continue (sauf pour \( x=0\) si \( \alpha<0\)).
\end{proposition}

\begin{proof}
    Nous allons subdiviser quelque cas.
    \begin{subproof}
        \item[Pour \( \alpha\in \eN\)]
            Nous supposons que ce cas va bien.
        \item[Pour \( \alpha\in \eQ^+\)]
            Soit \( q=m/n\) avec \( m,n\in \eN\). Soit aussi \( \epsilon>0\). Nous avons :
            \begin{subequations}
                \begin{align}
                    f_{m/n}(x)^n&=x^m\\
                    f_{m/n}(x+\epsilon)^n&=(x+\epsilon)^m.      \label{SUBEQooGNCSooWAeRcL}
                \end{align}
            \end{subequations}
            L'équation \eqref{SUBEQooGNCSooWAeRcL} s'écrit aussi bien sous la forme
            \begin{equation}
                f_n\big( f_{m/n}(x+\epsilon) \big)=(x+\epsilon)^m.
            \end{equation}
            En prenant la limite,
            \begin{equation}
                \lim_{\epsilon\to 0}\big[ f_n\big( f_{m/n}(x+\epsilon) \big) \big]=x^m=f_{m/n}(x)^n.
            \end{equation}
            Vu que \( f_n\) est continue, nous pouvons la permuter avec la limite dans le membre de gauche tout en écrivant \( f_{m/n}(x)^n=f_n\big( f_{m/n}(x) \big)\) dans le membre de droite :
            \begin{equation}
                f_n\big[ \lim_{\epsilon\to 0}f_{m/n}(x+\epsilon) \big]=f_n\big( f_{m/n}(x) \big).
            \end{equation}
            La fonction \( f_n\) étant injective dans un voisinage autour de \( x\) (proposition \ref{PROPooHKTKooCUEBjh}),
            \begin{equation}
                \lim_{\epsilon\to 0}f_{m/n}(x+\epsilon)=f_{m/n}(x),
            \end{equation}
            ce qui est la continuité de \( f_{m/n}\) en \( x\).

        \item[Pour \( \alpha\in \eR^+\)]

        Nous prouvons séparément le cas \( x<1\) et le cas \( x\geq 1\). Commençons par \( x\in \mathopen] 1 , \infty \mathclose[\).

            Soit une suite \( \alpha_i\to \alpha\) strictement décroissante dans \( \eQ^+\). Le lemme \ref{LEMooQTNKooLVEytN} nous dit que l'ensemble de fonctions  \( \{ f_{\alpha_i}\colon \mathopen] 1 , \infty \mathclose[\to \eR \}_{i\in \eN}\) est équicontinu. La convergence simple \( f_{\alpha_i}\to f_{\alpha}\) étant par définition, la proposition \ref{PROPooICNNooAMjcut} nous dit que la fonction \( f_{\alpha}\colon \mathopen] 1 , \infty \mathclose[\to \eR\) est continue.

            Soit maintenant \( x\in \mathopen] 0 , 1 \mathclose]\). Il existe \( k\in \eN\) tel que \( kx>1\), \( k(x/2)>1\) et \( k^{\alpha}>1\) (si vous pensez bien, seule la première condition est utile).

            Nous considérons \( \epsilon\) tel que \( x+\epsilon>x/2\); de toutes façons nous comptions faire \( \epsilon\to 0\). Nous avons :
            \begin{equation}
                \big| (x+\epsilon)^{\alpha}-x^{\alpha} \big|\leq k^{\alpha}\big| (x+\epsilon)^{\alpha}-x^{\alpha} \big|=\big| [k(x+\epsilon)]^{\alpha}-(kx)^{\alpha} \big|.
            \end{equation}
            Nous prenons le \( \delta\) qui correspond à \( \epsilon\) en \( kx\) dans la continuité de \( f_{\alpha}\) déjà démontée pour \( kx>1\). Alors si \( \epsilon<\delta\) nous avons
            \begin{equation}
                \big| (x+\epsilon)^{\alpha}-x^{\alpha} \big|\leq\epsilon.
            \end{equation}
        \item[Pour \( \alpha\in \eR^{-}\)]

            Si \( \alpha>0\), la fonction \( f_{-\alpha}\) est donnée par
            \begin{equation}
                f_{-\alpha}(x)=\frac{1}{  f_{\alpha}(x) }
            \end{equation}
            et est donc continue (sauf en \( x=0\) où elle n'existe pas).
    \end{subproof}
\end{proof}

\begin{proposition}     \label{PROPooEXGKooCqzLor}
    Soit \( \alpha>0\). La fonction
    \begin{equation}
        \begin{aligned}
            f_{\alpha}\colon \mathopen[ 0 , \infty \mathclose[&\to \mathopen[ 0 , \infty \mathclose[ \\
                x&\mapsto x^{\alpha} 
        \end{aligned}
    \end{equation}
    est bijective.
\end{proposition}

\begin{proposition}[\cite{MonCerveau}]     \label{PROPooDWZKooNwXsdV}
    Soient \( a>0\) ainsi que \( x,y\in \eR\). Alors
    \begin{equation}
        (a^x)^y=(a^y)^x=a^{xy}.
    \end{equation}
\end{proposition}

\begin{proof}
    Nous découpons en fonction de la nature de \( x\) et \( y\). 

    \begin{subproof}
        \item[\( x\) rationnel, \( y\) naturel]
            Si \( q\in \eQ\) et \( n\in \eN\) alors la formule
            \begin{equation}
                (a^q)^n=a^{nq}
            \end{equation}
            découle seulement d'une récurrence sur la formule \ref{EQooEWIHooDRAQGR}.

        \item[ \( x,y\in \eQ\)]
            Soient \( y=m/n\) avec \( n\in \eZ\), \( m\in \eN\) et \( q\in \eQ\). Nous avons, en utilisant la partie déjà démontrée et le lemme \ref{LEMooIDLJooZALNaD},
            \begin{equation}
                (a^q)^{p}=(a)^{m/n}=\big( (a^q)^m \big)^{1/n}=(a^{mq})^{1/n}=a^{mq/n}=a^{pq}.
            \end{equation}
        \item[\( x,y\) irrationnels]

            Soient des suites des rationnels \( x_i\to x\) et \( y_i\to y\). En utilisant les définitions,
            \begin{equation}        \label{EQooXITUooHYNSPU}
                (a^x)^y=\lim_i(a^x)^{y_i}=\lim_i\big( \lim_j a^{x_j} \big)^{y_i}.
            \end{equation}
            Fixons un \(i\) pour commencer. Nous avons, par la continuité de \( f_{y_i}\) (proposition \ref{PROPooUQNZooSSHLqr})
            \begin{equation}
                \big( \lim_ja^{x_j} \big)^{y_i}=f_{y_i}\big( \lim_ja^{x_j} \big)=\lim_j\big( f_{y_i}(a^{x_j}) \big)=\lim_ja^{x_jy_i}.
            \end{equation}
            Nous avons utilisé le résultats déjà démontré dans le cas des rationnels. La suite \( j\mapsto x_jy_i\) est une suite dans \( \eQ\) qui converge vers le réel \( xy_i\), donc la limite sur \( j\) redonne la fonction puissance :
            \begin{equation}        \label{EQooWORSooFoRBod}
                \big( \lim_ja^{x_j} \big)^{y_i}=\lim_ja^{x_jy_i}=a^{xy_i}.
            \end{equation}
            Le résultat découle maintenant de la prise de limite dans \eqref{EQooXITUooHYNSPU} qui revient à prendre la limite \( i\to \infty\) de l'expression dans \eqref{EQooWORSooFoRBod} :
            \begin{equation}
                (a^x)^y=\lim_i\big( \lim_j a^{x_j} \big)^{y_i}=\lim_ia^{xy_i}=a^{xy}.
            \end{equation}
    \end{subproof}
\end{proof}

Le lemme suivant montre en gros que \( x^y\) croît plus rapidement en \( y\) qu'en \( x\). 
\begin{lemma}       \label{LemLJOSooEiNtTs}
     Pour tout \( \alpha>0\) et \( a<1\) nous avons la limite
     \begin{equation}
         \lim_{n\to \infty} n^{\alpha}a^n=0
     \end{equation}
\end{lemma}

\begin{proof}
    Soit \( k\in \eN\) plus grand que \( \alpha\).
    Soit la suite numérique \( s_n=n^ka^n\). Tous ses termes sont positifs et
    \begin{equation}
        \frac{ s_n }{ s_{n+1} }=\left( \frac{ n }{ n+1 } \right)^k\frac{1}{ a }.
    \end{equation}
    Étant donné que \( n/n+1\to 1\) et que \( a<1\), il existe un certain rang à partir duquel la suite \( (s_n)\) est décroissante. Deux conclusions :
    \begin{itemize}
        \item Elle est majorée par une constante \( M\).
        \item Elle est convergente par le lemme~\ref{LemSuiteCrBorncv}.
    \end{itemize}
    Soit \( l\) tel que \( ka^l<1\) et \( n>l\) alors
    \begin{equation}
        s_{n+l}=(n+l)^ka^{n+l}\leq kn^ka^na^l=ka^ls_n\leq ka^lM.
    \end{equation}
    La majoration est due au fait que dans \( (n+l)^k\) nous avons \( k\) termes tous plus petits que \( n^k\). De la même façon,
    \begin{equation}
        s_{2n+2l}\leq ka^{2l}s_{2n}\leq ka^{2l}M.
    \end{equation}
    En posant \( \varphi(i)=in+il\) nous avons
    \begin{equation}
        s_{\varphi(i)}\leq ka^iM,
    \end{equation}
    qui est une sous-suite convergente vers \( 0\). Or si une suite est convergente (ce qui est le cas de \( (s_n)\)), toutes les sous-suites convergent vers la même limite. Nous en concluons que \( s_n\to 0\).
\end{proof}

\begin{normaltext}
    Une conséquence est que si vous voulez choisir un mot de passe fort, la longueur du mot est plus importante que la taille de l'alphabet choisit : il est plus efficace de choisir une combinaison longue qu'une combinaisons mélangeant des lettres, chiffres et symboles spéciaux.
    
    Exemple : si vous choisissez un mot de passe contenant majuscules, minuscules, chiffres et symboles spéciaux complètement mélangés (ne mentez pas, vous ne le faites pas), mais que vous ne le choisissez que de taille \( 6\), vous avez \( 72^6\) possibilités (en supposant un jeu de 10 symboles spéciaux).

    Eh bien, en seulement \( 8\) lettres minuscules, vous avez plus de possibilités : \( 26^8>72^6\).

    De nombreux sites font l'erreur de considérer que
    \begin{itemize}
        \item « ggzxzheaiynshunxuydajkwyohgqxz » est un mot de passe faible,
        \item «azerty.2019A» est un mot de passe fort.
    \end{itemize}
    Il n'en est rien. Le premier est considérablement meilleur que le second, même si le second, très superficiellement, mélange les lettres majuscules, minuscules, chiffres et symboles spéciaux.

    Voila voila. La prochaine fois qu'un site vous refusera un mot de passe de 30 lettres minuscules mélangées, vous saurez pourquoi il n'y a rien qui marche en informatique, et en particulier pourquoi la sécurité générale de nos systèmes d'informations est désastreuse.
\end{normaltext}


%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Dérivation de la fonction puissance (première)}
%---------------------------------------------------------------------------------------------------------------------------

Nous n'allons pas complètement résoudre la question de la dérivation de la fonction \( x\mapsto a^x\); il faudrait des logarithmes, et nous ne les avons pas encore défini. Le logarithme sera introduit comme fonction inverse de l'exponentielle en \ref{DEFooELGOooGiZQjt}.

\begin{proposition}[\cite{BIBooXUZHooOHWxiF}]       \label{PROPooMXCDooBffXbl}
    Soit la fonction puissance
    \begin{equation}
        \begin{aligned}
            g_a\colon \eR&\to \eR \\
            x&\mapsto a^x.
        \end{aligned}
    \end{equation}
    \begin{enumerate}
        \item
            La fonction \( g_a\) est dérivable.
        \item
            La dérivée vérifie l'équation
            \begin{equation}        \label{EQooNIUJooPqDnax}
                g_a'(x)=g_a'(0)g_a(x).
            \end{equation}
    \end{enumerate}
\end{proposition}

\begin{proof}
    La fonction \( g_a\) est continue par \ref{PROPooVADRooLCLOzP}\ref{ITEMooQHYRooJIewyp}. La proposition \ref{ThoEXXyooCLwgQg} nous dit donc que la fonction \( g_a\) admet une primitive sur \( \eR\). Nous notons \( F\) une telle primitive.

    Soit \( x\in \eR\). En posant \( F_x(t)=F(x+t)\), nous avons une primitive de \( t\mapsto a^xa^t\). En effet
    \begin{equation}
        F_x'(t)=F'(x+t)\Dsdd{ x+t }{t}{0}=a^{a+t}=a^xa^t.
    \end{equation}
    Par ailleurs la fonction \( t\mapsto a^xF(t)\) est également une primitive de \( t\mapsto a^xa^t\). Donc il existe un nombre \( C(x)\) tel que
    \begin{equation}
        F_x(t)=F(x+t)=a^xF(t)+C(x).
    \end{equation}
    
    Le nombre \( F(1)-F(0)\) est un nombre sans histoires. Nous avons :
    \begin{subequations}        \label{SUBALIGNooVARJooIcPEHN}
        \begin{align}
            g_a(x)\big( F(1)-F(0) \big)&=g_a(x)F(1)-g_a(x)F(0)\\
            &=F_x(1)-C(x)-F_x(0)+C(x)\\
            &=F_x(1)-F_x(0)\\
            &=F(1+x)-F(x).
        \end{align}
    \end{subequations}
    La fonction \( F\) étant dérivable, nous en déduisons que \( g_a\) est dérivable.

    Vu que nous n'avons aucune idée de la forme de \( F\), nous ne pouvons pas tirer beaucoup d'informations d'une dérivation des membres de gauche et de droite de \eqref{SUBALIGNooVARJooIcPEHN}.

    En ce qui concerne la formule, nous écrivons la fameuse équation fonctionnelle\footnote{Pour rappel, proposition \ref{PROPooVADRooLCLOzP}\ref{ITEMooSCJBooNVJZah}.}
    \begin{equation}
        g_a(x+y)=g_a(x)g_a(y)
    \end{equation}
    Nous fixons \( x\) et dérivons par rapport à \( y\) en \( y=y_0\) :
    \begin{equation}
        g_a'(x+y_0)=g_a(x)g_a'(y_0).
    \end{equation}
    En posant \( y_0=0\) nous trouvons le résultat demandé.
\end{proof}

\begin{normaltext}
    La démonstration donnée dans \cite{BIBooXUZHooOHWxiF} s'assure d'abord de l'existence d'une intégrale (lemme \ref{LEMooWKSWooPptdEm}), pose ensuite  \( A=\int_0^1g_a(t)dt\) et fait le calcul suivant :
    \begin{equation}
        Ag_a(x)=\int_{0}^1g_a(x)g_a(t)dt=\int_{0}^1g_a(x+t)dt=\int_x^{x+1}g_a(t)dt.
    \end{equation}
    Vu que le membre de droite est une fonction dérivable de \( x\), nous concluons que \( g_a\) est dérivable. Cela demande donc toute la théorie de l'intégration pour prouver la \emph{dérivabilité} d'une fonction.

    La démonstration donnée ici est à peine mieux. Elle utilise l'existence d'une primitive et donc tout le théorème de Stone-Weierstrass \ref{ThoGddfas}.

    Dans les deux cas, je trouve que la situation n'est pas fameuse. Si vous êtes capable de montrer l'existence de la limite
    \begin{equation}
        \lim_{\epsilon\to 0}\frac{ a^{\epsilon}-1 }{ \epsilon }
    \end{equation}
    sans recourir à autre chose que des astuces sur les limites, je suis preneur. Ou, au contraire, si vous avez un argument pour dire que c'est impossible, dites-le moi également. Écrivez-moi.
\end{normaltext}



Nous posons une définition
\begin{definition}      \label{DEFooPJKMooOfZzgy}
    Soit \( a>0\). Nous nommons l'\defe{équation fonctionnelle}{équation fonctionnelle} l'équation
    \begin{subequations}        \label{EQooULHBooByFVec}
        \begin{numcases}{}
            f(x+y)=f(x)f(y)\\
            f(1)=a
        \end{numcases}
    \end{subequations}
    pour la fonction inconnue \( f\colon \eR\to \eR\).
\end{definition}



\begin{definition}      \label{DEFooXMQTooSbZzqJ}
    Soit \( a>0\). Nous nommons l'\defe{équation exponentielle}{équation exponentielle} l'équation
    \begin{subequations}        \label{EQooGDBYooUoAFPW}
        \begin{numcases}{}
            y'=y\\
            y(1)=a
        \end{numcases}
    \end{subequations}
    pour la fonction inconnue \( y\colon \eR\to \eR\).
\end{definition}

\begin{proposition}[Unicité de l'exponentielle] \label{PropDJQSooYIwwhy}
    Si elle existe, la solution au problème
    \begin{subequations}
        \begin{numcases}{}
            y'=y\\
            y(0)=1
        \end{numcases}
    \end{subequations}
    est unique.
\end{proposition}
\index{exponentielle!unicité}

\begin{proof}
    Soient \( y\) et \( g\) deux solutions et considérions la fonction \( h(x)=g(x)y(-x)\). Un calcul immédiat donne
    \begin{equation}
        h'(x)=0
    \end{equation}
    et donc \( h\) est constante. Vu que \( h(0)=1\) nous avons \( g(x)y(-x)=1\) pour tout \( x\), c'est-à-dire
    \begin{equation}
        g(x)=\frac{1}{ y(-x) }=y(x).
    \end{equation}
\end{proof}

\begin{normaltext}
    Nous savons qu'il existe une unique solution de l'équation exponentielle avec \( a=1\). Avec la relation
    \begin{equation}
        g_a'(x)=g_a(x)g_a'(0),
    \end{equation}
    de la proposition \ref{PROPooMXCDooBffXbl}, nous n'en sommes pas loin. Il faut encore savoir si il existe un \( a>0\) tel que \( g_a'(0)=1\). Notre culture générale nous dit qu'un tel réel existe et est la fameuse constante \( e\).

    Nous nous attelons maintenant à la tâche de montrer l'existence de la chose.
\end{normaltext}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Équation fonctionnelle}
%---------------------------------------------------------------------------------------------------------------------------

Il n'est un secret pour personne (proposition \ref{PROPooVADRooLCLOzP}\ref{ITEMooSCJBooNVJZah}) que la fonction
\begin{equation}
    \begin{aligned}
        g_a\colon \eR&\to \eR \\
        x&\mapsto a^x 
    \end{aligned}
\end{equation}
vérifie l'équation fonctionnelle \eqref{EQooULHBooByFVec}. Nous pouvons nous demander à quel point cette propriété caractérise la fonction puissance.


\begin{proposition}[\cite{BIBooXUZHooOHWxiF}]       \label{PROPooJDPEooYTDVtU}
    Encore plusieurs résultats sur la fonction \( g_a\) avec \( a>0\).
    \begin{enumerate}
        \item       \label{ITEMooZJUEooVoqKul}
            La fonction \( g_a\) vérifie l'équation fonctionnelle.
        \item       \label{ITEMooCSQXooUDyiMq}
            La dérivée vérifie \( g_a'(0)\neq 0\).
        \item       \label{ITEMooCKIHooNuDwrk}
            Pour tout \( a\), en posant \( \alpha=1/g'_a(0)\) nous avons
            \begin{equation}
                g_{a^{\alpha}}'(0)=1.
            \end{equation}
        \item       \label{ITEMooQQFRooWtlViJ}
            Il existe un unique \( e>0\) tel que 
            \begin{equation}
                g_e'=g_e.
            \end{equation}
        \item       \label{ITEMooERTLooWLjlnZ}
            Pour la valeur de \( e\) donnée en \ref{ITEMooQQFRooWtlViJ}, la fonction \( g_e\) vérifie l'équation exponentielle \eqref{EQooGDBYooUoAFPW} 
            \begin{subequations}
                \begin{numcases}{}
                    g_e'=g_e\\
                    g_e(1)=e.
                \end{numcases}
            \end{subequations}
    \end{enumerate}
\end{proposition}

\begin{proof}
    Un point à la fois.
    \begin{subproof}
        \item[Pour \ref{ITEMooZJUEooVoqKul}]
            Le fait que \( g_a\) vérifie l'équation fonctionnelle est la proposition \ref{PROPooVADRooLCLOzP}\ref{ITEMooSCJBooNVJZah}.

        \item[Pour \ref{ITEMooCSQXooUDyiMq}]

            La formule \eqref{EQooNIUJooPqDnax} de la proposition \ref{PROPooMXCDooBffXbl} nous assure que
            \begin{equation}        \label{EQooSCDJooTvnjEp}
                g_a'(x)=g_a(x)g_a'(0).
            \end{equation}
            Donc \( g_a'(0)=0\) impliquerait que \( g_a=0\), ce qui n'est pas le cas.

        \item[Pour \ref{ITEMooCKIHooNuDwrk}]
            Par ailleurs la proposition \ref{PROPooDWZKooNwXsdV} nous permet d'écrire
            \begin{equation}
                g_a(\alpha x)=g_{a^{\alpha}}(x).
            \end{equation}
            En dérivant des deux côtés,
            \begin{equation}        \label{EQooIHCDooGSEGNm}
                \alpha g_a'(\alpha x)=g'_{a^{\alpha}}(x).
            \end{equation}
            En posant donc \( \alpha=g'_a(0)\) et en évaluant \eqref{EQooIHCDooGSEGNm} en \( x=0\) nous trouvons le résultat.

        \item[Pour \ref{ITEMooQQFRooWtlViJ}, existence]

            Pour les valeurs de \( \alpha\) données par le point \ref{ITEMooCKIHooNuDwrk}, nous avons \( g'_{a^{\alpha}}(0)=1\), et l'équation \eqref{EQooSCDJooTvnjEp} nous donne alors
            \begin{equation}
                g_{a^{\alpha}}(x)=g_{a^{\alpha}}(x).
            \end{equation}
            Comme de plus \( g_{a^{\alpha}}(0)=1\), cette fonction vérifie bien l'équation exponentielle.
        \item[Pour \ref{ITEMooQQFRooWtlViJ}, unicité]

            Si \( a\) et \( b\) font en sorte que \( g_a'=g_a\) et \( g_b'=g_b\), alors nous avons aussi \( g_a'(0)=g_b'(0)=1\) à cause de \eqref{EQooSCDJooTvnjEp}. Donc \( g_a\) et \( g_b\) vérifient l'équation de la proposition \ref{PropDJQSooYIwwhy} dont la solution est unique. Donc \( g_a=g_b\).

            Pour tout \( x\) nous avons \( g_a(x)=g_b(x)\). En particulier pour \( x=1\) nous avons \( a=b\).
    \end{subproof}
\end{proof}

\begin{proposition}[\cite{BIBooXUZHooOHWxiF}]    \label{PROPooGBUPooWtWaFI}
    Soit \( a>0\). Nous considérons l'équation fonctionnelle \ref{DEFooPJKMooOfZzgy} et l'équation exponentielle \ref{DEFooXMQTooSbZzqJ} pour une fonction \( f\colon \eR\to \eR\).
    \begin{enumerate}
        \item       \label{ITEMooYHAVooWzJqBj}
            Si \( f\) vérifie l'équation fonctionnelle, alors
            \begin{equation}
                f(q)=a^q
            \end{equation}
            pour tout \( q\in \eQ\).
        \item       \label{ITEMooQHOMooNVzSxn}
            Si \( f\) vérifie l'équation fonctionnelle et est monotone, alors \( f=g_a\).
        \item       \label{ITEMooCNXOooZcrxeB}
            Si \( f\) vérifie l'équation fonctionnelle et est continue, alors \( f=g_a\).
    \end{enumerate}
\end{proposition}

\begin{proof}
    En beaucoup de parties. Nous commençons par prouver \ref{ITEMooYHAVooWzJqBj}. Nous supposons que \( f\colon \eR\to \eR\) est une fonction vérifiant l'équation fonctionnelle\footnote{Bien que ce ne soit pas strictement nécessaire ici, nous rappelons qu'une telle fonction existe par la proposition \ref{PROPooJDPEooYTDVtU}.}.
    \begin{subproof}
        \item[\( f(x)\geq 0\)]
            Quel que soit \( x\in \eR\) nous avons
            \begin{equation}
                f(x)=f(\frac{ x }{2}+\frac{ x }{2})=f(\frac{ x }{2})^2\geq 0.
            \end{equation}
            Vous noterez que cet argument ne fonctionne pas si \( f\) est à valeurs dans \( \eC\) au lieu de \( \eR\).
        \item[Pour \( n\in \eN\)]
            Soit \( n\in \eN\). Je vous laisse rédiger la récurrence correctement, mais l'idée est que \( f(1)=a\) et ensuite que
            \begin{equation}
                f(n+1)=f(n)f(1)=f(1)^nf(1)=f(1)^{n+1}.
            \end{equation}
        \item[Pour \( m\in \eZ\)]
            Nous avons d'une part que \( f(-m+m)=f(0)=1\), mais d'autre part que \( f(-m+m)=f(-m)f(m)\). Donc \( 1=f(-m)f(m)\); et nous concluons que
            \begin{equation}
                f(-m)=\frac{1}{ f(m) }.
            \end{equation}
        \item[Pour \( q=1/n\)]
            Nous savons que \( f(1)=a\), mais \( 1=\frac{1}{ n }+\ldots\frac{1}{ n }\) (avec \( n\) termes), donc
            \begin{equation}
                a=f(\frac{1}{ n }+\ldots \frac{1}{ n })=f(\frac{1}{ n })^n.
            \end{equation}
            Cela implique que \( f(\frac{1}{ n })^n=a\). La proposition \ref{PROPooXQYFooPxoEHE} indique qu'il existe un unique \( x>0\) tel que \( x^n=a\). Vu que nous savons déjà que \( f\) est partout positive\footnote{C'est ici que l'hypothèse de fonction à valeurs dans \( \eR\) est cruciale. Pour \( f\colon \eR\to \eC\) ceci ne fonctionne pas, et de loin.}, cette contrainte fixe \( f(1/n)\) et la définition \ref{DEFooJWQLooWkOBxQ} nous permet d'écrire
            \begin{equation}
                f(\frac{1}{ n })=a^{1/n}.
            \end{equation}
        \item[Pour \( q\in \eQ\)]
            Nous posons \( q=m/n\). Le nombre \( q\) peut être écrit sous la forme \( \frac{ m }{ n }=\frac{1}{ n }+\ldots +\frac{1}{ n }\) avec \( m\) termes. Donc
            \begin{equation}
                f(\frac{ m }{ n })=f(\frac{1}{ n }+\ldots \frac{1}{ n })=f(\frac{1}{ n })^{m}=(a^{1/n})^m=a^{m/n}
            \end{equation}
            où nous avons utilisé le lemme \ref{LEMooIDLJooZALNaD}.
    \end{subproof}
    La preuve de \ref{ITEMooYHAVooWzJqBj} est terminée.

    \begin{subproof}
        \item[Démonstration de \ref{ITEMooQHOMooNVzSxn}]
            Nous faisons maintenant la preuve de \ref{ITEMooQHOMooNVzSxn}. Nous supposons que \( f\) vérifie l'équation fonctionnelle et qu'elle est monotone. Pour fixer les idées, nous supposons qu'elle est monotone croissante\footnote{Si \( f\) est monotone décroissante, soit vous adaptez la preuve, soit vous essayez de voir si on ne peut pas recycler le cas croissant en l'appliquant à \( -f\).}.
        
            Nous considérons les parties\footnote{Il du meilleur gout de citer le lemme \ref{LemooHLHTooTyCZYL} pour dire qu'ils sont non vides.}
            \begin{subequations}
                \begin{align}
                    A=\{ q\in \eQ\tq q<x \}\\
                    B=\{ q\in \eQ\tq q>x \}.
                \end{align}
            \end{subequations}
            Vu que \( f\) est croissante, nous avons \( f(x)\geq f(q)\) pour tout \( q\in A\) et \( f(x)\leq f(q)\) pour tout \( q\in B\). En passant au supremum et à l'infimum,
            \begin{equation}
                \sup_{q\in A}f(q)\leq f(x)\leq \inf_{q\in B}f(q).
            \end{equation}
            Mais il existe dans \( A\) une suite strictement croissante convergente \( q_i\) vers \( x\) (parce que \( x=\sup(A)\)), donc
            \begin{equation}
                a^x=\lim_ia^{q_i}
            \end{equation}
            par la définition \ref{DEFooOJMKooJgcCtq}. Et de même, il existe une suite \( r_i\) décroissante dans \( B\) telle que \( x=\lim r_i\). Cette suite donne aussi
            \begin{equation}
                a^x=\lim_i a^{r_i}.
            \end{equation}
            Nous avons donc l'encadrement
            \begin{equation}
                a^x\leq f(x)\leq a^x,
            \end{equation}
            qui implique que \( f(x)=a^x\).

        \item[Démonstration de \ref{ITEMooCNXOooZcrxeB}]

            Nous ne supposons plus que \( f\) est monotone. Au lieu de cela nous supposons qu'elle est continue. Nous avons déjà vu en \ref{ITEMooYHAVooWzJqBj} que \( f=g_a\) sur \( \eQ\). Mais par hypothèse \( f\) est continue et par la proposition \ref{PROPooVADRooLCLOzP}, \( g_a\) est continue. La proposition \ref{PROPooXWHYooFiVYfi} conclu que \( f=g_a\) sur \( \eR\).
    \end{subproof}
\end{proof}

\begin{proposition}[\cite{BIBooXUZHooOHWxiF}]
    Si \( y\) vérifie l'équation exponentielle, alors elle est continue, monotone et vérifie l'équation fonctionnelle.
\end{proposition}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Dérivation de la fonction puissance (seconde)}
%---------------------------------------------------------------------------------------------------------------------------

La proposition suivante donne la dérivée de \( x\mapsto x^q\) pour tout \( q\in \eQ\). La formule donnée est encore valable pour \( x\mapsto x^{\alpha}\) pour tout \( \alpha\in \eR\), mais elle demandera plus de théorie pour être démontrée, voir la proposition \ref{PROPooKIASooGngEDh}.
\begin{proposition}[\cite{MonCerveau}]     \label{PROPooSGLGooIgzque}
    Pour tout \( \alpha\in \eQ\), si \( f_{\alpha}(x)=x^{\alpha}\) alors
    \begin{equation}
        f'_{\alpha}(x)=\alpha x^{\alpha-1}.
    \end{equation}
    En particulier, \( f_{\alpha}\) est de classe \(  C^{\infty}\) sur \( \eR\setminus\{ 0 \}\).
\end{proposition}

\begin{proof}
    Petit à petit.
    \begin{subproof}
        \item[Naturel]
            Nous prouvons que \( (x^n)'=nx^{n-1}\) par récurrence en utilisant la règle de Leibnitz de la propositon  \ref{PROPooOUZOooEcYKxn}\ref{ITEMooMQERooBCqnvS}.

            D'abord pour \( n=1\) nous avons \( f_1(x)=x\) et donc
            \begin{equation}
                f_1'(x)=\lim_{\epsilon\to 0}\frac{ (x+\epsilon)-x }{ \epsilon }=1.
            \end{equation}
            Supposons que \( f_k'(x)=kx^{k-1}\) pour un certain \( k\in \eN\). Nous prouvons que \( f_{k+1}'(x)=(k+1)x^{k}\).  Nous avons
            \begin{equation}
                x^{k+1}=xx^k.
            \end{equation}
            En utilisant la règle de Leibnitz et l'hypothèse de récurrence,
            \begin{equation}
                    \big( x^{k+1} \big)'=(x)'x^k+x\big( x^k \big)'
                    =x^k+x\big( kx^{k-1} \big)
                    =x^k+kx^k
                    =(k+1)x^k,
            \end{equation}
            ce qu'il fallait démontrer.

        \item[Rationnel positif]
            Soit donc \( \alpha=p/q\) avec \( p,q\in \eN\). Le lemme \ref{LEMooIDLJooZALNaD} nous permet d'écrire \( f_{p/q}(x)=x^{p/q}=(x^p)^{1/q}\). Cela donne
            \begin{equation}
                f_{p/q}(x)^q=x^p.
            \end{equation}
            Nous dérivons cette relation par rapport à \( x\) en utilisant à la fois la règle pour les entiers et la règle des fonctions composées\footnote{Proposition \ref{PROPooOUZOooEcYKxn}\ref{ITEMooLYZCooVUPTyh}.} :
            \begin{equation}
                qf_{p/q}'(x)^{q-1}f'_{p/q}(x)=px^{p-1}.
            \end{equation}
            En isolant \( f_{p/q}'(x)\) dans cette expression et en utilisant le fait que \( \frac{ x^a }{ x^b }=x^{a-b}\), nous trouvons le résultat.

        \item[Rationnels négatifs]

            Soit \( \alpha=-p/q\) avec \( p,q\in \eN\). Nous avons \( x^{-p/q}=\frac{1}{ f_{p/q}(x) }\). En utilisant la proposition \ref{PROPooOUZOooEcYKxn}\ref{ITEMooMUNQooLiKffz} et le point déjà prouvé sur les rationnels positifs,
            \begin{equation}
                f'_{p/q}=-\frac{ f'_{-p/q} }{ f_{p/q}^2 }=-\frac{ (-p/q)x^{-p/q-1} }{ x^{-2p/q} }=(p/q)x^{p/q-1}.
            \end{equation}
            Notez l'utilisation de la proposition \ref{PROPooDWZKooNwXsdV} au dénominateur.

        \item[Irrationnel]

            Ah ah ! On vous a bien eu. Les irrationnels, c'est pour la proposition \ref{PROPooKIASooGngEDh}.
    \end{subproof}
    En ce qui concerne le fait que la fonction \( f_{\alpha}\) est de classe \(  C^{\infty}\) sur \( \eR\setminus\{ 0 \}\), c'est simplement une récurrence. Attention : si le rationnel \( \alpha\) est négatif, \( f_{\alpha}(0)\) n'est pas défini. Mais, lorsque \( \alpha\) est positif non entier, à partir d'un certain ordre, les dérivées font intervenir \( x^{\beta}\) avec \( \beta<0\). D'où la restriction à \( \eR\setminus\{ 0 \}\) du domaine sur lequel \( f_{\alpha}\) est de classe \(  C^{\infty}\).

    Si \( \alpha\) est positif entier, alors \( f_{\alpha}\) est de classe \(  C^{\infty}\) sur tout \( \eR\) parce que toutes les dérivées sont nulles à partir d'un certain ordre.
\end{proof}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Hölder}
%---------------------------------------------------------------------------------------------------------------------------

Notre étude de la fonction puissance permet de démontrer quelque inégalités de Hölder. Voir le thème \ref{THEMEooUJVXooZdlmHj}.

\begin{theorem}[\cite{BIBooWAUMooIUnSOs}]       \label{THOooPPDPooJxTYIy}
    Si \( 1\leq p <  \infty\), alors pour tout \( x\in \eR^n\) nous avons
    \begin{equation}
        \| x \|_{\infty}\leq \| x \|_p\leq n^{1/p}\| x \|_{\infty}.
    \end{equation}
\end{theorem}

\begin{proof}
    Vu que la fonction \( t\mapsto | t |^p\) est croissante pour les \( t \) positifs\footnote{Parce que \( p\geq 1\) et la proposition \ref{PROPooRXLNooWkPGsO}.}, pour chaque \( i\) nous avons
    \begin{equation}
        | x_i |\leq \left( \sum_k| x_k |^p \right)^{1/p}=\| x \|_p.
    \end{equation}
    Cela montre que
    \begin{equation}
        \| x \|_{\infty}=\max\{ | x_i | \}\leq \| x \|_p.
    \end{equation}
    
    D'autre part, pour chaque \( i\) nous avons \( | x_i |\leq \| x \|_{\infty}\), donc
    \begin{equation}
        \| x \|_p\leq \big( n\| x \|_{\infty} \big)^{1/p}=n^{1/p}\| x \|_{\infty}.
    \end{equation}
\end{proof}

Le corollaire suivant donne une façon de majorer une norme \( \ell^p\) par une norme \( \ell^q\) moyennant un facteur. Notons cependant que l'inégalité de Hölder de la proposition \ref{PROPooQZTNooGACMlQ} est plus précise. Ce corollaire est suffisant pour prouver l'équivalence des normes \( \ell^p\).
\begin{corollary}       \label{CORooEZGHooACHOiB}
    Soient \( p\geq 1\) et \( q\leq \infty\). Pour tout \( x\in \eR^n\) nous avons
    \begin{equation}
        \| x \|_p\leq n^{1/p} \| x \|_q.
    \end{equation}
\end{corollary}

\begin{proof}
    Il suffit d'utiliser les deux inégalités du théorème \ref{THOooPPDPooJxTYIy}. D'abord la seconde avec \( p\), et ensuite la première avec \( q\).
\end{proof}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Vers les complexes}
%---------------------------------------------------------------------------------------------------------------------------

Nous avons déjà vu la proposition \ref{PROPooJDPEooYTDVtU} qui dit essentiellement que si une fonction continue \( f\colon \eR\to \eR\) vérifie \( f(x+y)=f(x)f(y)\), alors \( f(x)=a^x\). Comme indiqué durant la preuve, cette proposition (et en particulier sa preuve) ne fonctionne pas pour les fonctions à valeurs complexes. L'endroit où cela coinçait est que la contrainte
\begin{equation}
    f(\frac{1}{ n })^n=a
\end{equation}
n'implique pas grand chose lorsque \( f\) est à valeurs complexes.

Nous allons maintenant attaquer ce problème.


\begin{lemma}       \label{LEMooDEGEooXheixp}
    Soit \( \alpha\in \eC\). Si elle existe, la solution au problème
    \begin{subequations}
        \begin{numcases}{}
            y'=\alpha y\\
            y(0)=1
        \end{numcases}
    \end{subequations}
    pour \( y\colon \eR\to S^1\) est unique.
\end{lemma}

\begin{proof}
    Soient deux solutions \( y_1\) et \( y_2\). Nous posons \( h(x)=y_1(x)y_2(-x)\). Une dérivation donne
    \begin{equation}
        h'(x)=y_1'(x)y_2(-x)-y_1(x)y'_2(-x).
    \end{equation}
    En y substituant \( y'_1(x)=\alpha y_1(x)\) et \( y'_2(-x)=\alpha y_2(x)\) nous trouvons \( h'(x)=0\). Donc \( h\) est constante et nous avons
    \begin{equation}        \label{EQooTWBQooBLLKSt}
        y_1(x)y_2(-x)=1
    \end{equation}
    pour tout \( x\).

    Notons que cette identité est encore valable avec \( y_1=y_2\). Nous avons en particulier \( y_1(x)y_1(-x)=1\) et \( y_2(x)y_2(-x)=1\), et nous notons au passage que \( y_1(x)\) et \( y_2(x)\) ne s'annulent pas.

    En substituant dans \eqref{EQooTWBQooBLLKSt} la valeur \( y_2(-x)=\frac{1}{ y_2(x) }\) nous trouvons
    \begin{equation}
        \frac{ y_1(x) }{ y_2(x) }=1,
    \end{equation}
    ce qui signifie \( y_1(x)=y_2(x)\).
\end{proof}

Dans la proposition suivante, \( S^1\) désigne l'ensemble des nombres complexes de norme \( 1\), dont une paramétrisation est donnée dans la proposition \ref{PROPooZEFEooEKMOPT} :
\begin{equation}
    S^1=\{  e^{ix}\tq x\in \eR \}=\{  e^{ix}\tq x\in \mathopen[ 0 , 2\pi \mathclose[ \}.
\end{equation}

\begin{proposition}[\cite{MonCerveau}]      \label{PROPooVJLYooOzfWCd}
    Soit une fonction continue \( f\colon \eR\to S^1\) vérifiant
    \begin{equation}        \label{EQooHANKooHirpTL}
        f(x+y)=f(x)f(y).
    \end{equation}
    Alors
    \begin{enumerate}
        \item
            \( f\) est dérivable,
        \item
            \( f\) satisfait au système
            \begin{subequations}
                \begin{numcases}{}
                    f'(x)=f'(0)f(x)\\
                    f(0)=1,
                \end{numcases}
            \end{subequations}
        \item
            il existe \( m\in \eR\) tel que \( f(x)= e^{imx}\).
    \end{enumerate}
\end{proposition}

\begin{proof}
    Pour chaque \( m\in \eR\), la fonction
    \begin{equation}
        g_m(x)= e^{imx}
    \end{equation}
    vérifie évidemment toutes les conditions. Le but de cette démonstration est de montrer que les conditions imposées à \( f\) la déterminent de façon univoque (à part ce \( m\)).

    La condition \eqref{EQooHANKooHirpTL} nous dit que \( f(0)=1\). Soit une primitive \( F\) de \( f\). Il existe \( s>0\) tel que \( F(s)>F(0)\) parce que \( F'=f\) et \( f(0)=1\).

    Soit \( a\in \eR\). La fonction \( G_a\) donnée par \( G_a(x)=F(x+a)\) est une primitive de \( x\mapsto f(x)f(a)\). Donc \( G_a(x)=f(a)F(x)\). Cela dit nous avons
    \begin{equation}
        f(x)\big( F(s)-F(0) \big)=f(x)F(s)-f(x)F(0)=G_1(x)-G_0(x).
    \end{equation}
    Le membre de droite est évidemment dérivable, et \( F(s)-F(0)\neq 0\). Donc \( f\) est dérivable.

    Nous dérivons maintenant la relation \( f(x+y)=f(x)f(y)\) par rapport à \( y\) en \( y=0\). Cela donne
    \begin{equation}
        f'(x)=f'(0)f(x).
    \end{equation}
    Donc il existe \( \alpha\in \eC\) tel que \( f'(x)=\alpha f(x)\). 

    Jusqu'ici nous avons prouvé qu'il existe \( \alpha\in \eC\) tel que
    \begin{subequations}
        \begin{numcases}{}
            f'(x)=\alpha f(x)\\
            f(0)=1.
        \end{numcases}
    \end{subequations}
    Or le lemme \ref{LEMooDEGEooXheixp} donne l'unicité de la solution à ce système, et il ne faut pas chercher loin : la solution est
    \begin{equation}
        f(x)= e^{\alpha x}.
    \end{equation}
    
    Pour avoir \( f(x)\in S^1\), nous devons de plus imposer que \( \alpha\) soit imaginaire pur. Donc, en posant \( \alpha=im\), nous avons \( m\in \eR\) tel que \( f(x)= e^{imx}\).
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Polynômes de Taylor}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\label{AppSecTaylorR}

\begin{definition}
    Soit une fonction \( f\colon \eR\to \eR\). Si il existe, nous définissons le \( n\)\ieme\ \defe{polynôme de Taylor}{polynôme de Taylor} de $f$ au point \( a\in \eR\) par
    \begin{equation}
        P_n(x)=\sum_{k=0}^n\frac{ f^{(k)}(a) }{ k! }(x-a)^k.
    \end{equation}
    Et la \defe{série de Taylor}{série de Taylor} de \( f\) est la limite :
    \begin{equation}
        T(x)=\sum_{k=0}^{\infty}\frac{ f^{(k)}(a) }{ k! }(x-a)^k
    \end{equation}
    dans la mesure où la somme converge.
\end{definition}

Tant que \( f\) est \( n\) fois dérivable, le polynôme \( P_n\) existe et vérifie \( P_n(a)=f(a)\). Nous ne pouvons rien en dire de plus pour l'instant. En particulier, si \( f\) est de classe \(  C^{\infty}\) il ne faudrait pas croire que
\begin{equation}
    \lim_{n\to \infty} P_n(x)=f(x)
\end{equation}
pour tout \( x\) dans un voisinage de \( a\). Autrement dit, même si toutes les dérivées de \( f\) existent, la série entière \( T\) n'est pas garantie de
\begin{itemize}
    \item 
        un rayon de convergence\footnote{Définition \ref{DefZWKOZOl}.} plus grand que zéro,
    \item
        et même avec un grand rayon de convergence, que la limite soit les valeurs de \( f\).
\end{itemize}

\begin{normaltext}      \label{NORMooADIZooUmevqk}
    Il n'est pas très compliqué de construire une fonction \( f\) telles que \( f(0)=0\) et telle que \( f^{(k)}(0)=0\) pour tout \( k\), sans pour autant que \( f\) soit nulle partout (voir les fonctions plateaux \ref{subsecOSYAooXXCVjv}). Les polynômes de Taylor d'une telle fonction sont tous identiquement nuls.

    Ceci pour dire qu'en posant
    \begin{equation}
        T(x)=\sum_{n=0}^{\infty}\frac{ f^{(k)}(0) }{ k! }x^k,
    \end{equation}
    nous n'avons aucune garantie de \( T=f\), même pas sur le rayon de convergence de la série entière définissant \( P\). Et nous n'avons pas de garanties d'avoir un rayon de convergence plus grand que \( 0\).

    Notons toutefois que les polynômes étant denses pour la norme supremum parmi les fonctions continues\footnote{Théorème \ref{ThoGddfas}.}, pour tout compact, il existe une suite de polynômes qui converge uniformément uniformément \( f\). Mais ces polynômes ne sont pas spécialement ceux de Taylor.
\end{normaltext}

Le théorème de Taylor que nous démontrons à présent n'est pas un résultat que va dans le sens de \( \lim_{n\to \infty} P_n(x)=f(x)\). C'est un résultat qui dit juste que \( \lim_{x\to a} P_n(x)=f(a)\), et que la limite va d'autant plus vite que \( n\) est grand.

Le théorème de Taylor généralise le développement limité au premier ordre de la proposition \ref{PropUTenzfQ}.

\begin{normaltext}
    Lorsque le contexte n'est pas ambigu, nous notons simplement \( P_n\) le polynôme d'ordre \( n\) de \( f\) au point \( a\). De même nous notons le reste
    \begin{equation}
        R_n(x)=f(x)-P_n(x).
    \end{equation}
\end{normaltext}

\begin{proposition}[\cite{ooSZKEooLejXAh}]      \label{PROPooUYCMooQjeXpn}
    Soit une fonction \( f\) qui est \( n\) fois dérivable sur l'intervalle ouvert \( I\subset \eR\) contenant \( a\). Alors
    \begin{equation}
        \lim_{x\to a} \frac{ R_n(x) }{ (x-a)^n }=\lim_{x\to a} \frac{ f(x)-P_n(x) }{ (x-a)^n }=0
    \end{equation}
    où \( P_n\) est le \( n\)\ieme\ polynôme de Taylor de \( f\) autour de \( x=a\).
\end{proposition}

\begin{proof}
    Pour tout \( k=0,\ldots, n\) nous avons \( f^{(k)}(a)=P_n^{(k)}(a)\) et donc
    \begin{equation}
        R_n^{(k)}(a)=0
    \end{equation}
    pour \( k=0,\ldots, n\). En posant d'autre par \( s(x)=(x-a)^n\) nous avons \( s^{(k)}(a)=0\) pour tout \( k=0,\ldots, n-1\). Par conséquent la règle de l'Hospital de la proposition \ref{PROPooBZHTooHmyGsy} s'applique au quotient \( R_n(x)/s(x)^n\). En l'utilisant \( n\) fois,
    \begin{equation}
        \lim_{x\to a} \frac{ R_n(x) }{ s(x) }=\lim_{x\to a} \frac{ R^{(k)}(x) }{ k!(x-a)^0 }=\frac{ 0 }{ k! }=0.
    \end{equation}
\end{proof}

Nous démontrons à présent que le polynôme de Taylor est le seul à avoir la propriété de la proposition \ref{PROPooUYCMooQjeXpn}.
\begin{proposition}[\cite{ooSZKEooLejXAh}]
    Soit \( f\), une fonction \( n\) fois dérivable sur l'intervalle \( I\subset \eR\) contenant \( 0\). Soit un polynôme \( Q\) de degré \( n\) (ou moins) tel que
    \begin{equation}    \label{EQooXPTIooOZqBaD}
        \lim_{x\to a} \frac{ f(x)-Q(x) }{ (x-a)^n  }=0.
    \end{equation}
    Alors \( Q\) est le polynôme de Taylor de degré \( n\) pour \( f\) en \( a\) ci-après simplement noté \( P_n\).
\end{proposition}

\begin{proof}
    D'après la proposition \ref{PROPooUYCMooQjeXpn}, la fonction \( f-P_n\) vérifie la même limite que \( f-Q\). DOnc \( P_n-Q\) vérifie également la limite
    \begin{equation}        \label{EQooYBHHooEgZxtk}
        \lim_{x\to 0} \frac{ (P_n-Q)(x) }{ x^n }=0.
    \end{equation}
    Nous notons \( P_n(x)=\sum_{k=0}^na_kx^k\) et \( Q(x)=\sum_{k=0}^nb_kx^k\). La relation \eqref{EQooYBHHooEgZxtk} donne en particulier 
    \begin{equation}
        \lim_{x\to 0} (P_n-Q)(x)=0
    \end{equation}
    qui donne \( a_0-b_0=0\). Nous continuons par récurrence en supposant que \( a_i=b_i\) pour \( i=0,\ldots, k\). Alors
    \begin{equation}
        0=\lim_{x\to 0} \frac{ (P_n-Q)(x) }{ x^{k+1} }=\lim_{x\to 0} \sum_{l=k+1}^n(a_l-b_l)x^{l-(k+1)}.
    \end{equation}
    Le seul terme non nul à droite est celui vérifiant \( l-(k+1)=0\). Et ce terme donne l'équation
    \begin{equation}
        a_{k+1}-b_{k+1}=0,
    \end{equation}
    c'est-à-dire \( a_{k+1}=b_{k+1}\). La récurrence continue ainsi jusqu'à \( k=n\), et nous pouvons conclure que \( Q=P_n\).
\end{proof}
L'intérêt de cette proposition est que si l'on trouve, par n'importe quel moyen, un polynôme \( Q\) vérifiant la condition \eqref{EQooXPTIooOZqBaD}, alors nous savons que c'est le polynôme de Taylor.

\begin{theorem}[Théorème de Taylor\cite{TrenchRealAnalisys,ooCNZAooJEcgHZ}]		\label{ThoTaylor}
Soit $I\subset$ un intervalle non vide et non réduit à un point de $\eR$ ainsi que $a\in I$. Soit une fonction $f\colon I\to \eR$ telle que $f^{(n)}(a)$ existe. Alors il existe une fonction $\alpha$ définie sur $I$ et à valeurs dans $\eR$ vérifiant les deux conditions suivantes :
\begin{subequations}		\label{SubEqsDevTauil}
	\begin{align}
		f(x)&= \sum_{k=0}^n\frac{ f^{(k)}(a) }{ k! }(x-a)^k +\alpha(x)(x-a)^{n},	\\	\label{subeqfTepseqb}
		\lim_{t\to a}\alpha(t)&=0
	\end{align}
\end{subequations}
pour tout \( x\in I\). Ici $f^{(k)}$ dénote la $k$-ième dérivée de $f$ (en particulier, $f^{(0)}=f$, $f^{(1)}=f'$).\nomenclature{$f^{(n)}$}{La $n$-ième dérivée de la fonction $f$}
\end{theorem}

\begin{proof}
    Si \( R_n(x)=f(x)-P_n(x)\), il suffit de poser
    \begin{equation}
        \alpha(x)=R_n(x)(x-a)^n
    \end{equation}
    et d'utiliser la proposition \ref{PROPooUYCMooQjeXpn}.
\end{proof}

\begin{remark}
    Quelque remarques.
    \begin{enumerate}
        \item
            La formule \eqref{subeqfTepseqb} est une égalité, et non une approximation. Ce qui serait une approximation serait de récrire la formule dans le terme contenant $\alpha$.
        \item
            Nous avons l'égalité \eqref{subeqfTepseqb} uniquement sur \( I\). Pour les \( x\) hors de \( I\), le polynôme existe évidemment, mais nous n'avons pas spécialement de fonction \( \alpha\), et d'ailleurs la fonction \( f\) n'est pas spécialement définie.
    \end{enumerate}
\end{remark}

\begin{normaltext}
    Les conditions \eqref{SubEqsDevTauil} sont souvent aussi énoncées sous la forme qu'il existe une fonction \( \alpha\) telle que
    \begin{subequations}    \label{SUBEQooPYABooKpDgdu}
        \begin{numcases}{}
            \lim_{t\to 0} \frac{ \alpha(t) }{ t^n }=0\\
            f(a+h)=f(a)+hf'(a)+\frac{ h^2 }{2}f''(a)+\cdots+ \frac{ h^n }{ n! }f^{(n)}(a)+\alpha(h).
        \end{numcases}
    \end{subequations}
\end{normaltext}

Le théorème suivant donne une expression pas tout à fait explicite, mais pas mal quand même pour le reste de Taylor.
\begin{theorem}     \label{THOooSIGRooJTLvlV}
Soient un intervalle ouvert \( I\subset \eR\) ainsi que \( a\in I\). Soit encore une fonction de classe \( C^{k+1}\) sur $I$. Pour tout \( x\in I\), il existe un \( c\in \mathopen] a , x \mathclose[\) tel que l'égalité
    \begin{equation}        \label{EQooQFMFooBVpGzy}
        f(x)=\sum_{k=0}^n\frac{ f^{(k)}(a) }{k!}(x-a)^k+\frac{ f^{(n+1)}(c) }{ (n+1)! }(x-a)^{n+1}
    \end{equation}
    soit vérifiée.
\end{theorem}

\begin{proof}
    Pour les besoins de la preuve, nous allons démontrer la formule \eqref{EQooQFMFooBVpGzy} pour un \( b\in I\) au lieu de \( x\). C'est juste que nous allons écrire \( b\) au lieu de \( x\) parce que nous aurons besoin de la notation \( x\) dans le courant de la preuve.

    Nous posons
    \begin{equation}
        R(x)=f(x)-P_n(x)=f(x)-\sum_{k=0}^n\frac{ f^{(k)}(a) }{ k! }(x-a)^k.
    \end{equation}
    Cela vérifie \( R(a)=f(a)-f(a)=0\) et même
    \begin{equation}
        R^{(j)}(a)=0
    \end{equation}
    pour tout \( j=1,\ldots, n\). Nous posons encore
    \begin{equation}
        F(x)=R(x)-\frac{ R(b) }{ (b-a)^{n+1} }(x-a)^{n+1}.
    \end{equation}
    Nous avons \( F^{(j)}(a)=0\) pour tout \( j=0,\ldots, n\) ainsi que
    \begin{equation}
        F(b)=R(b)-\frac{ R(b) }{ (b-a)^{n+1} }(b-a)^{n+1}=0.
    \end{equation}
    et aussi
    \begin{equation}
        F(a)=R(a)-0=0.
    \end{equation}
Bref, la fonction \( F\) vérifie les conditions de la généralisation \ref{PROPooCPCAooJjOZNy} du lemme de Rolle. Il existe donc \( c\in\mathopen] a , b \mathclose[\) tel que \( F^{(n+1)}(c)=0\). Mais vu que \( P_n^{(n+1)}(x)=0\), nous avons \( R^{(n+1)}(x)=f^{(n+1)}(x)\), de telle sorte que
    \begin{equation}
        f^{(n+1)}(c)=\frac{ R(b)(n+1)! }{ (b-a)^{n+1} }.
    \end{equation}
    En injectant cela dans la définition de \( F\)
    \begin{equation}
        F(x)=R(x)-\frac{ f^{(n+1)}(c) }{ (n+1)! }(x-a)^{n+1}.
    \end{equation}
    En évaluant en \( x=b\), et en nous souvenant que \( F(b)=0\), nous trouvons
    \begin{equation}
        0=R(b)-\frac{ f^{(n+1)}(c) }{ (n+1)! }(b-a)^{n+1}
    \end{equation}
    qui est ce que nous voulions prouver.
\end{proof}

Voici un énoncé pour les fonctions à plusieurs variables.
\begin{theorem}[\cite{ooLZSZooIOILHY}]      \label{THOooTDFRooEkChgi}
    Si \( f\colon E\to \eR\) est une application \( n\) fois différentiable en \( a\in E\) alors il existe une fonction \( \epsilon\colon \eR\to \eR\) telle que
    \begin{subequations}
        \begin{numcases}{}
            f(a+h)=f(a)+df_a(h)+\frac{ 1 }{2}(d^2f)_a(h,h)+\ldots +\\
            \qquad+\ldots+\frac{1}{ n! }(d^nf)_a(h,\ldots, h)+\| h \|^n\epsilon(\| h \|)\\
            \lim_{t\to 0} \epsilon(t)=0.
        \end{numcases}
    \end{subequations}
\end{theorem}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Fonctions «petit o» }
%---------------------------------------------------------------------------------------------------------------------------

Nous voulons formaliser l'idée d'une fonction qui tend vers zéro « plus vite » qu'une autre. Nous disons que $f\in o\big(\varphi(x)\big)$ si
\begin{equation}
    \lim_{x\to 0} \frac{ f(x) }{ \varphi(x) }=0.
\end{equation}
En particulier, nous disons que $f\in o(x)$ lorsque $\lim_{x\to 0} f(x)/x=0$.


En termes de notations, nous définissons l'ensemble $o(x)$\nomenclature{$o(x)$}{fonction tendant rapidement vers zéro} l'ensemble des fonctions $f$ telles que
\begin{equation}
	\lim_{x\to 0} \frac{ f(x) }{ x }=0.
\end{equation}
Plus généralement si $g$ est une fonction telle que $\lim_{x\to 0} g(x)=0$, nous disons $f\in o(g)$ si
\begin{equation}
	\lim_{x\to 0} \frac{ f(x) }{ g(x) }=0.
\end{equation}
De façon intuitive, l'ensemble $o(g)$ est l'ensemble des fonctions qui tendent vers zéro «plus vite» que $g$.

Nous pouvons donner un énoncé alternatif au théorème~\ref{ThoTaylor} en définissant $h(x)=\epsilon(x+a)x^n$. Cette fonction est définie exprès pour avoir
\begin{equation}
	h(x-a)=\epsilon(x)(x-a)^n,
\end{equation}
et donc
\begin{equation}
	\lim_{x\to 0} \frac{ h(x) }{ x^n }=\lim_{x\to 0} \epsilon(x-a)=\lim_{x\to a}\epsilon(x)=0.
\end{equation}
Donc $h\in o(x^n)$.

Le théorème dit donc qu'il existe une fonction $\alpha\in o(x^n)$ telle que
\begin{equation}
	f(x)=T^a_{f,n}(x)+\alpha(x-a).
\end{equation}
pour tout $x\in I$.

\begin{remark}
    À titre personnel, l'auteur de ces lignes déconseille d'utiliser cette notation qui est un peu casse-figure pour qui ne la maîtrise pas bien.
\end{remark}

\begin{example}
    Le développement en série du cosinus sera traité dans la proposition \ref{PROPooNPYXooTuwAHP}.
\end{example}

\begin{proposition}[Ordre deux sur \( \eR^n\)\cite{MonCerveau}]         \label{PROPooTOXIooMMlghF}
    Soit un ouvert \( \Omega\) de \( \eR^n\) et \( a\in \Omega\) ainsi qu'une fonction \( f\colon \Omega\to \eR\) de classe \( C^2\). Alors il existe une fonction \( \alpha\colon \eR^n\to \eR\) telle que
    \begin{subequations}
        \begin{numcases}{}
            f(a+h)=f(a)+df_a(h)+\frac{ 1 }{2}(d^2f)_a(h,h)+\| h \|^2\alpha(h)\\
            \lim_{h\to 0} \alpha(h)=0.
        \end{numcases}
    \end{subequations}
    Ici, la notation \( (d^2f)_a(h,h)\) réfère à ce qui est expliqué en~\ref{NORMooZAOEooGqjpLH}.
\end{proposition}

\begin{proof}
    Dans la suite nous considérons \( t\) et \( h\) tels que toutes les expressions suivantes aient un sens, c'est-à-dire que tous les trucs comme \( a+th\) restent dans \( \Omega\). Pour \( h\in \eR^n\) nous nommons \( e_h\) le vecteur unitaire dans la direction de \( h\), c'est-à-dire \( e_h=h/\| h \|\) et nous posons
    \begin{equation}
        k_h(t)=f(a+te_h).
    \end{equation}
    et nous lui appliquons Taylor~\ref{ThoTaylor} à l'ordre deux : il existe une fonction \( \beta_h\) telle que
    \begin{equation}        \label{EQooETDFooAmiRcV}
        k_h(x)=k_h(0)+xk_h'(0)+\frac{ x^2 }{2}k''_h(0)+x^2\beta_h(x).
    \end{equation}
    avec \( \lim_{x\to 0} \beta_h(x)=0\).

    En ce qui concerne les dérivées de \( k_h\) nous avons
    \begin{equation}
        k'_h(0)=df_a(e_h)
    \end{equation}
    et
    \begin{equation}
        k_h''(0)=(d^2f)_{a}(e_h,e_h).
    \end{equation}
    Il est maintenant temps d'écrire \( f(a+h)=k(\| h \|)\) et de substituer les dérivées de \( k\) par les différentielles de \( f\) dans \eqref{EQooETDFooAmiRcV} :
    \begin{equation}        \label{EQooUSUGooYPscxV}
            f(a+h)=k(\| h \|)=f(a)+df_a(h)+\frac{ 1 }{2}(d^2f)_a(h,h)+\| h^2 \|\beta_{h}(\| h \|).
    \end{equation}
    Il reste à voir que la fonction \( \alpha\colon h\mapsto \beta_h(\| h \|)\) tend vers zéro pour \( h\to 0\). En prenant la limite \( h\to 0\) dans \eqref{EQooUSUGooYPscxV}, il est manifeste que la limite du membre de gauche existe et vaut \( f(a)\). Donc la limite du membre de droite doit exister et valoir également \( f(a)\). Nous en déduisons que la limite de
    \begin{equation}
        df_a(h)+\frac{ 1 }{2}(d^2f)_a(h,h)+\| h \|^2\beta_h(\| h \|)
    \end{equation}
    existe et vaut zéro. La limite des deux premiers termes existe et vaut zéro, donc la limite du troisième existe et vaut zéro :
    \begin{equation}
        \lim_{h\to 0} \| h \|^2\beta_h(\| h \|)=0.
    \end{equation}
\end{proof}

\begin{proposition}     \label{PROPooWWMYooPOmSds}
Soit un ouvert \( \Omega\) de \( \eR^n\) et une fonction \( f\colon \Omega\to \eR\) de classe \( C^1\) et deux fois différentiable sur \( \mathopen] x , x+h \mathclose[\). Alors il existe \( \theta\in \mathopen] 0 , 1 \mathclose[\) tel que
    \begin{equation}
        f(x+h)=f(x)+df_x(h)+\frac{ 1 }{2}(d^2f)_{x+\theta h}(h,h).
    \end{equation}
\end{proposition}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Autres formulations}
%---------------------------------------------------------------------------------------------------------------------------

\begin{example}		\label{ExempleUtlDev}
	Une des façons les plus courantes d'utiliser les formules \eqref{SubEqsDevTauil} est de développer $f(a+t)$ pour des petits $t$ en posant $x=a+t$ dans la formule :
	\begin{equation}	\label{EqDevfautouraeps}
		f(a+t)=f(a)+f'(a)t+f''(a)\frac{ t^2 }{ 2 }+\epsilon(a+t)t^2
	\end{equation}
	avec $\lim_{t\to 0} \epsilon(a+t)=0$. Ici, la fonction $T$ dont on parle dans le théorème est $T_{f,2}^a(a+t)=f(a)+f'(a)t+f''(a)\frac{ t^2 }{2}$.

	Lorsque $x$ et $y$ sont deux nombres «proches\footnote{par exemple dans une limite $(x,y)\to(h,h)$.}», nous pouvons développer $f(y)$ autour de $f(x)$ :
	\begin{equation}		\label{Eqfydevfx}
		f(y)=f(x)+f'(x)(y-x)+f''(x)\frac{ (y-x)^2 }{ 2 }+\epsilon(y-x)(y-x)^2,
	\end{equation}
	et donc écrire
	\begin{equation}
		f(x)-f(y)=-f'(x)(y-x)-f''(x)\frac{ (y-x)^2 }{ 2 }-\epsilon(y-x)(y-x)^2.
	\end{equation}
	De cette manière nous obtenons une formule qui ne contient plus que $y$ dans la différence $y-x$.
\end{example}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Formule et reste}
%---------------------------------------------------------------------------------------------------------------------------

\begin{proposition}     \label{PropDevTaylorPol}
    Soient $f\colon I\subset\eR\to \eR$ et $a\in\Int(I)$. Soit un entier $k\geq 1$. Si $f$ est $k$ fois dérivable en $a$, alors il existe un et un seul polynôme $P$ de degré $\leq k$ tel que
    \begin{equation}
        f(x)-P(x-a)\in o\big( | x-a |^k \big)
    \end{equation}
    lorsque $x\to a$, $x\neq a$. Ce polynôme  est donné par
    \begin{equation}
        P(h)=f(a)+f'(a)h+\frac{ f''(a) }{ 2! }h^2+\cdots+\frac{ f^{(k)}(a) }{ k! }h^k.
    \end{equation}
    Notons encore deux façons alternatives d'écrire le résultat. Si \( f\in C^k\) il existe une fonction \( \alpha\) telle que \( \lim_{t\to 0} \alpha(t)=0\) et
    \begin{equation}
        f(x)=\sum_{n=0}^k\frac{ f^{(n)}(a) }{ n! }(x-a)^n+(x-a)^n\alpha(x-a).
    \end{equation}
    Si \( f\in C^{k+1}\) alors
    \begin{equation}        \label{EquQtpoN}
        f(x)=\sum_{n=0}^k\frac{ f^{(n)}(a) }{ n! }(x-a)^n+(x-a)^{n+1}\xi(x-a)
    \end{equation}
    où \( \xi\) est une fonction telle que \( \xi(t)\) tend vers une constante lorsque \( t\to 0\).
\end{proposition}

La proposition suivant donne une intéressante façon de trouver le reste d'un développement de Taylor.
\begin{proposition}     \label{PropResteTaylorc}
Soient $I$, un intervalle dans $\eR$ et $f\colon I\to \eR$ une fonction de classe $C^k$ sur $I$ telle que $f^{(k+1)}$ existe sur $I$. Soient $a\in\Int(I)$ et $x\in I$. Alors il existe $c\in\mathopen] x , a \mathclose[$ tel que
\begin{equation}
    f(x)=\sum_{k=0}^n\frac{ f^{(k)}(a) }{ k! }(x-a)^k+\frac{ f^{(n+1)}(c) }{ (n+1)! }(x-a)^{n+1}.
\end{equation}
\end{proposition}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Reste intégral}
%---------------------------------------------------------------------------------------------------------------------------

Comme son nom l'indique, le «reste intégral» demande de savoir les intégrales. La formule du reste intégral sera donc pour après la définition des intégrales, proposition~\ref{PropAXaSClx}.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Développement limité autour de zéro}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Dans cette sections nous supposons toujours que les fonctions sont définies sur un intervalle ouvert de $\eR$, $I$, contenant \( 0\).

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Généralités}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}
    Soit \( f\colon I\to 0\) une fonction définie sur un ouvert \( I\) autour de zéro. Nous disons que \( f\) admet un \defe{développement limité}{développement!limité!en zéro} autour de \( 0\) à l'ordre \( n\) s'il existe une fonction \( \alpha\colon I\to \eR\) telle que
    \begin{subequations}
        \begin{numcases}{}
            f(x)=P_n(x)+x^n\alpha(x)\\
            \lim_{x\to 0} \alpha(x)=0
        \end{numcases}
    \end{subequations}
    où \( P(x)=a_0+a_1x+\cdots +a_nx^n\) est une polynôme de degré \( n\). Le polynôme \( P_n\) est appelé la \defe{partie régulière}{partie!régulière} du développement.
\end{definition}
La fonction \( \alpha\) est appelé le \defe{reste}{reste!d'un développement limité} du développement et sera parfois noté \( \alpha_f\). Lorsque \( P\) est la partie régulière d'un développement limité de \( f\) nous notons parfois \( f\sim P\).

\begin{proposition}[Troncature]
    Si \( f\) admet un développement limité d'ordre \( n\) alors il admet également un développement limité d'ordre \( n'\) pour tout \( n'<n\). Ce dernier s'obtient en tronquant le polynôme d'ordre \( n\) à l'ordre \( n'\).
\end{proposition}

\begin{proposition}[Unicité]
    Si \( f\) admet une développement limité alors ce dernier est unique : il existe un unique polynôme \( P_n\) d'ordre \( n\) et une unique fonction \( \alpha\) vérifiant simultanément les deux conditions
    \begin{subequations}
        \begin{numcases}{}
            f(x)=P_n(x)+x^n\alpha(x),\\
            \lim_{x\to 0} \alpha(x)=0.
        \end{numcases}
    \end{subequations}
\end{proposition}

\begin{example} \label{ExTHGooCBcnAy}
    En ce qui concerne les séries géométriques de raison \( x\) nous savons les formules
    \begin{equation}
        1+x+x^2+\cdots +x^n=\frac{ 1-x^{n+1} }{ 1-x }
    \end{equation}
    et
    \begin{equation}
        1+x+x^2+x^3+\cdots=\frac{ 1 }{ 1-x }
    \end{equation}
    pour tout \( x\in\mathopen] -\infty , 1 \mathclose[\). Comparant les deux, il est naturel d'essayer de prendre \( 1+x+x^2+\cdots +x^n\) comme développement limité de la fonction \( f(x)=\frac{1}{ 1-x }\). Pour voir si cela fonctionne, il faut vérifier si «le reste» est bien de la forme \( x^n\alpha(x)\) avec \( \lim_{x\to 0} \alpha(x)=0\).

    Le reste en question est donné par
    \begin{equation}
        \frac{1}{ 1-x }-1-x-x^2-\ldots-x^n=\frac{1}{ 1-x }-\frac{ 1-x^{n+1} }{ 1-x }=\frac{ x^{n+1} }{ 1-x }=x^n\frac{ x }{ 1-x }.
    \end{equation}
    En posant \( \alpha(x)=\frac{ x }{ 1-x }\) nous avons donc bien
    \begin{equation}
        f(x)=\frac{1}{ 1-x }=1+x+x^2+\cdots +x^n+x^n\frac{ x }{ 1-x }
    \end{equation}
    et \( \lim_{x\to 0} \frac{ x }{ 1-x }=0\). Cela est le développement limité de \( f\) à l'ordre \( n\) autour de \( 0\).
\end{example}

La formule des accroissements finis est un cas particulier de développement fini. Supposons que \( f\) soit dérivable en \( 0\). En effet nous pouvons facilement trouver la fonction \( \alpha\) qui convient. Sachant que \( f(0)+xf'(0)\) donne l'approximation affine de \( f\) autour de \( 0\), nous cherchons \( \alpha\) en écrivant
\begin{equation}
    f(x)=f(0)+xf'(0)+x\alpha(x).
\end{equation}
Cela nous pousse à définir
\begin{equation}    \label{EqDCFooKozKrt}
    \alpha(x)=\frac{ f(x)-f(0) }{ x }-f'(0).
\end{equation}
Notons que cette fonction n'est pas définie en \( x=0\), mais cela n'a pas d'importance : seule la limite \( \lim_{x\to 0} \alpha(x)\) nous intéresse. Par définition de la dérivée,
\begin{equation}
    \lim_{x\to 0} \alpha(x)=\lim_{x\to 0} \frac{ f(x)-f(0) }{ x }-f'(0)=0.
\end{equation}

En conclusion si \( f\) est dérivable, son développement limité à l'ordre \(  1\) est donné par
\begin{equation}
    f(x)=f(0)+xf'(0)+x\alpha(x)
\end{equation}
où \( \alpha(x)\) est donnée par la formule \eqref{EqDCFooKozKrt}.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Formule de Taylor-Young}
%---------------------------------------------------------------------------------------------------------------------------

Plus généralement nous avons la proposition suivante qui donne le développement limité de toute fonction dérivable \( n\) fois.

\begin{proposition}[Formule de Taylor-Young]    \label{PropVDGooCexFwy}
    Soit \( f\) une fonction \( n\) fois dérivable sur un intervalle \( I\) contenant \( 0\). Alors il existe une fonction \( \alpha\colon I\to \eR\) telle que
    \begin{equation}        \label{EQooBKZDooTqYyIB}
        f(x)=f(0)+f'(0)x+\frac{ f''(0) }{ 2 }x^2+\frac{ f^{(3)}(0) }{ 3! }x^3+\cdots +\frac{ f^{(n)}(0) }{ n! }x^n+x^n\alpha(x)
    \end{equation}
    et
    \begin{equation}
        \lim_{x\to 0} \alpha(x)=0.
    \end{equation}
\end{proposition}

Cette proposition nous permet de calculer facilement des développements limités tant que nous sommes capables de calculer les dérivées successives de la fonction à développer. Dans l'exemple \ref{ExTHGooCBcnAy} nous avons dû utiliser des astuces et des formules pour déterminer le développement limité de \( \frac{1}{ 1-x }\). Au contraire la formule \eqref{EQooBKZDooTqYyIB} nous permet de trouver le polynôme en appliquant mécaniquement une formule simple.

\begin{example}
    Utilisation de la formule \eqref{EQooBKZDooTqYyIB} pour déterminer le développement limité de la fonction
    \begin{equation}
        f(x)=\frac{1}{ 1-x }.
    \end{equation}
    Il faut calculer les dérivées successives de \( f\) :
    \begin{subequations}
        \begin{align}
            f(x)&=\frac{1}{ 1-x }\\
            f'(x)&=\frac{ 1 }{ (1-x)^2 }\\
            f''(x)&=\frac{ 2 }{ (1-x)^3 }
        \end{align}
    \end{subequations}
    Avec ces résultats, nous devinons que
    \begin{equation}
        f^{(n)}(x)=\frac{ n! }{ (1-x)^{n+1} }.
    \end{equation}
    Pour en être sûr nous le prouvons par récurrence. La dérivée de \(\frac{ n! }{ (1-x)^{n+1} } \) est donnée par
    \begin{equation}
        \frac{ n!(n+1)(1-x)^n }{ (1-x)^{2n+2} }=\frac{(n+1)! }{ (1-x)^{n+2} }.
    \end{equation}
    Évaluées en \( x=0\), les dérivées successives de \( f\) sont \( f(0)=0\), \( f'(0)=1\), \( f''(0)=2\),\ldots,\( f^{(n)}(0)=n!\). Utilisant la formule \eqref{EQooBKZDooTqYyIB} nous avons
    \begin{equation}
        f(x)=1+x+x^2+\cdots +x^n+x^n\alpha(x),
    \end{equation}
    conformément à ce que nous avions déjà trouvé.
\end{example}

\begin{example}     \label{EXooFLBJooYfuRsG}
    Soient \( r\in \eQ\) et la fonction donnée par
    \begin{equation}
        f(x)=(1+x)^r.
    \end{equation}
    Nous notons \( I\) le domaine de cette fonction : c'est \( \eR\) si \( r>0\) ou \( \mathopen[ -1 , \infty \mathclose]\) si \( r<0\). Si par contre \( r=0\), la fonction est constante et le domaine est \( I=\eR\).

    En ce qui concerne les dérivées\footnote{Nous utilisons la proposition \ref{PROPooSGLGooIgzque}.} : \( f'(x)=r(1+x)^{r-1}\) et plus généralement
    \begin{equation}
        f^{(k)}(x)=r(r-1)\ldots (r-k+1)(1+x)^{r-k}
    \end{equation}
    si \( k>0\). Pour \( k=0\) nous avons \( f^{(k)}(0)=1\). Le développement de Taylor-Young est alors
    \begin{equation}
      (1+x)^r=1+\sum_{k=1}^n\frac{r(r-1)\ldots (r-k+1)}{ k! }x^k+x^n\alpha(x).
    \end{equation}
    
    Notons que que si \( r\) est un entier, pour \( k=r\), le produit au numérateur s'annule et le développement s'arrête. 
    
    Dans le développement de \( (1+x)^{r}\), nous reconnaissons la formule de \( \binom{ k }{r}\), sauf que nous ne pouvons pas l'écrire avec cette notation lorsque \( r\) n'est pas entier.
\end{example}
Cet exemple fonctionnera encore avec \( r\in \eR\) au lieu de \( r\in \eQ\), mais il faudra la proposition \ref{PROPooKUULooKSEULJ} pour la dérivée

\begin{remark}
  Pour alléger la notation et ne pas écrire \(\ldots +x^n\alpha(x)\) nous pouvons aussi écrire
    \begin{equation}
         f(x)\sim 1+x+x^2+\cdots +x^n,
    \end{equation}
    mais il est interdit d'écrire
    \begin{equation}
         f(x)= 1+x+x^2+\cdots +x^n
    \end{equation}
    en mettant un signe d'égalité entre une fonction et son développement limité\footnote{Il faut cependant être très prudents avec la notation abrégée. Elle pourrait nous faire oublier des informations importantes, voir les développements des fonctions trigonométriques pour un exemple.}.
\end{remark}

Notons cependant que la proposition~\ref{PropVDGooCexFwy} ne donne pas de moyen simple de trouver la fonction \( \alpha\). Si la fonction $f$ est très régulière dans l'intervalle $I$ on a le résultat suivant.

\begin{proposition}[Reste dans la forme de Lagrange]
    Si la fonction $f$ est dérivable $n+1$ fois dans $I$ alors il existe $\bar x$ dans l'intervalle \( \mathopen[ 0 , x \mathclose]\) tel que
  \begin{equation}
    f(x) = P_n(x) + \frac{1}{(n+1)!} f^{n+1}(\bar x) x^{n+1}.
  \end{equation}
\end{proposition}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Règles de calcul}
%---------------------------------------------------------------------------------------------------------------------------

    Les règles suivantes permettent de calculer les développements limités des fonctions qu'on peut écrire comme combinaison de fonctions dont nous savons déjà le développement.

    Il est toujours possible de calculer le développement limité d'une fonction par la formule de Taylor-Young (proposition \ref{PropVDGooCexFwy}). Les règles suivantes peuvent nous economiser de l'effort et du temps.

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Linéarité des développements limités}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

L'opération qui consiste à prendre le développement limité d'une fonction est une opération linéaire : connaissant les développements limités de \( f\) et de \( g\), il suffit de les sommer pour obtenir celui de \( f+g\). De m\^eme, si $\lambda$ est une constante, le développement limité de $\lambda f$ est le développement limité de $f$ fois $\lambda$.
\begin{proposition}
Soient $\lambda$ et $\mu$ dans $\eR$.  Si \( f\) et \( g\) sont deux fonctions acceptant des développements limités d'ordre \( n\)
    \begin{subequations}    \label{EqJPPooCHihNn}
        \begin{align}
            f(x)&=P(x)+x^n\alpha_f(x)\\
            g(x)&=Q(x)+x^n\beta(x)
        \end{align}
    \end{subequations}
    avec \( \lim_{x\to 0} \alpha(x)=\lim_{x\to 0} \beta(x)=0\), alors la fonction \( \lambda f+\mu g\) admet le développement limité
    \begin{equation}    \label{EqCJFooVpyCtz}
        (f+g)(x)=(\lambda P+\mu Q)(x)+(\lambda \alpha+\mu\beta)(x).
    \end{equation}
\end{proposition}
\begin{remark}
  La forme explicite du reste ne nous interesse pas. Dans la pratique on écrira toujours $(f+g)(x)=(P+Q)(x)+\alpha(x)$, où on appelle $\alpha$ une fonction apportune telle que $\lim_{x\to 0} \alpha(x)=0$.
\end{remark}
\begin{proof}
    Vu les définitions \eqref{EqJPPooCHihNn} des polynômes \( P\), \( Q\) et des restes \( \alpha\) et \( \beta\), l'égalité \eqref{EqCJFooVpyCtz} est une conséquence de la linéarité de la dérivation et de la proposition~\ref{PropVDGooCexFwy}

    De plus \( P+Q\) est un polynôme de degré \( n\) dès que \( P\) et \( Q\) sont des polynômes de degré \( n\), et
    \begin{equation}
        \lim_{x\to 0} (\lambda \alpha+\mu\beta)(x)=\lim_{x\to 0} \lambda\alpha(x)+\lim_{x\to 0} \mu\beta(x)=0.
    \end{equation}
    Par conséquent \(\lambda \alpha+\mu\beta\) est la fonction de reste de \( \lambda f+\mu g\).
\end{proof}

\begin{example} \label{ExKPBooJmdFvY}
    Calculer le développement de la fonction
    \begin{equation}
        f(x)=3\sqrt[3]{1+x}+ e^{-2x}.
    \end{equation}
    Le développement de \( \sqrt[3]{1+x}\) est donné par la formule de l'exemple \ref{EXooFLBJooYfuRsG} avec \( \alpha=\frac{1}{ 3 }\). Nous avons donc dans un premier temps
    \begin{subequations}
        \begin{align}
            \sqrt[3]{1+x}&=1+\frac{ 1 }{ 3 }x+\frac{ \frac{1}{ 3 }\left( \frac{1}{ 3 }-1 \right) }{ 2 }x^2+\frac{ \frac{1}{ 3 }\left( \frac{1}{ 3 }-1 \right)\left( \frac{1}{ 3 }-2 \right) }{ 6 }x^3+x^3\alpha(x)\\
            &=1+\frac{1}{ 3 }x-\frac{1}{ 9 }x^2+\frac{ 5 }{ 81 }x^3+x^3\alpha(x).
        \end{align}
    \end{subequations}
    Nous avons alors
    \begin{subequations}
        \begin{align}
            3\sqrt[3]{1+x}+ e^{-2x}&=3\Big[  1+\frac{1}{ 3 }x-\frac{1}{ 9 }x^2+\frac{ 5 }{ 81 }x^3+x^3\alpha(x)\Big]+1-2x+2x^2-\frac{ 4 }{ 3 }x^3+x^3\beta(x)\\
            &=4-x+\frac{ 5 }{ 3 }x^2-\frac{ 31 }{ 27 }x^3+x^3\big( \alpha(x)+\beta(x) \big).
        \end{align}
    \end{subequations}

\end{example}

La condition \( \lim_{x\to 0} \alpha(x)=0\) signifie que l'approximation qui consiste à remplacer \( f(x) \) par le polynôme n'est pas une trop mauvaise approximation lorsque \( x\) est petit. Cela ne signifie rien de plus. En particulier si \( x\) est grand, l'approximation polynomiale peut-être (et est souvent) très mauvaise.

À ce propos, notez qu'un polynôme tend toujours vers \( \pm\infty\) lorsque \( x\) est grand. Une approximation polynomiale d'une fonction bornée est donc toujours (très) mauvaise pour les grandes valeurs de \( x\).

À titre d'exemple nous avons tracé sur la figure~\ref{LabelFigWUYooCISzeB} la fonction
\begin{equation}
    f(x)=3\sqrt[3]{x+1}+ e^{-2x}
\end{equation}
et ses développements limités d'ordre \( 1\) à \( 3\). Il est particulièrement visible que l'approximation est assez bonne pour la partie gauche du graphe sur laquelle la fonction est bien croissante, alors qu'elle est franchement mauvaise sur la droite où le graphe ressemble plutôt à une constante\footnote{Pouvez-vous cependant dire que vaut \( \lim_{x\to \infty} f(x)\) ?}.

\newcommand{\CaptionFigWUYooCISzeB}{Les développements limités d'ordre de plus en plus grand de la fonction de l'exemple~\ref{ExKPBooJmdFvY}. La fonction est en bleu et les «approximations» sont en rouge.}
\input{auto/pictures_tex/Fig_WUYooCISzeB.pstricks}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Développement limité d'un quotient}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

\begin{proposition}     \label{PROPooMANAooXhuanS}
    Si \( P_f\) est le polynôme du développement limité de \( f\) à l'ordre \( n\) et \( P_g\) celui de \( g\), alors nous obtenons le développement limité de \( f/g\) à l'ordre \( n\) en effectuant la division selon les puissances croissantes de \( P_f\) par \( P_g\).
\end{proposition}
Attention : il s'agit bien de faire une division selon les puissances croissantes, et non une divisions euclidienne. La division euclidienne de \( A\) par \( B\) consiste à écrire \( A=BQ+R\) avec le reste \( R\) de degré le plus \emph{petit} possible. Ici nous voulons avoir un reste de degré le plus \emph{grand} possible.

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Développement limité d'une fonction composée}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////


\begin{proposition}
    Soient \( f\) et \( g\) des fonctions admettant des développements limités d'ordre $n$ au voisinage de $0$. Nous supposons que \( \lim_{x\to 0} g(x)=0\). Alors la composée \( f\big( g(x) \big)\) admet un développement limité d'ordre $n$ au voisinage de $0$ qui s'obtient en substituant le développement de \( g\) à chaque <<\(x \)>> du développement de \( f\), et en supprimant tous les termes de degré plus élevé que $n$.
\end{proposition}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Développement ailleurs qu'à l'origine}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Il est intéressant de développer une fonction au voisinage de zéro lorsque nous nous intéressons à son comportement pour les \( x\) pas très grands. Il est toutefois souvent souhaitable de savoir le comportement d'une fonction au voisinage d'autres valeurs que zéro.

Pour développer la fonction \( f\) autour de \( x_0\), nous considérons la fonction \( h\mapsto f(x_0+h)\) que nous développons autour de zéro (pour \( h\)). L'objectif est de trouver une polynôme \( P\) et une fonction \( \alpha\) tels que
\begin{subequations}
    \begin{numcases}{}
        f(x)=P(x)+(x-x_0)^n\alpha(x)\\
        \lim_{x\to x_0} \alpha(x)=0.
    \end{numcases}
\end{subequations}
En pratique, le développement limité à l'ordre $n$ d'une fonction autour d'un point $x_0$ quelconque à l'intérieur de son domaine prend la forme suivante, qui généralise la formule de Taylor-Young vue dans la proposition~\ref{PropVDGooCexFwy}
\begin{proposition}[Formule de Taylor-Young, cas général]
    Soit \( f\) une fonction \( n\) fois dérivable sur un intervalle \( I\) contenant \(x_0\). Alors il existe une fonction \( \alpha\colon I\to \eR\) telle que
    \begin{equation}    \label{EqTJRooUbsyzJ}
      \begin{aligned}
        f(x)=f(x_0)+&f'(x_0)(x-x_0)+\frac{ f''(x_0) }{ 2 }(x-x_0)^2+\\
        &+\frac{ f^{(3)}(x_0) }{ 3! }(x-x_0)^3+\cdots +\frac{ f^{(n)}(x_0) }{ n! }(x-x_0)^n+(x-x_0)^n\alpha(x-x_0)
      \end{aligned}
    \end{equation}
    et
    \begin{equation}
        \lim_{t\to 0} \alpha(t)=0.
    \end{equation}
\end{proposition}



%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Application au calcul de limites}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Lors d'un calcul de limite, développer une partie d'une expression peut être utile.

\begin{example}
    À calculer :
    \begin{equation}
        \lim_{x\to 0} \frac{ \ln(1+x) }{ x }.
    \end{equation}
    Cela est une indétermination de type \( \frac{ 0 }{ 0 }\). Le développement limité du numérateur nous donne une fonction \( \alpha(x)\) telle que \( \lim_{x\to 0} \alpha(x)=0\) et
    \begin{equation}
        \frac{ \ln(1+x) }{ x }=\frac{ x-\frac{ x^2 }{2}+x^2\alpha(x) }{ x }=1-\frac{ x }{ 2 }+x\alpha(x).
    \end{equation}
    Sur le membre de droite la limite est facile à calculer :
    \begin{equation}
        \lim_{x\to 0} \frac{ \ln(1+x) }{ x }=\lim_{x\to 0} \Big( 1-\frac{ x }{ 2 }+x\alpha(x) \Big) =1.
    \end{equation}
\end{example}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Développement au voisinage de l'infini}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Il est souvent utile de connaitre le comportement d'une fonction pour les grandes valeurs de \( x\) et de déterminer ses asymptotes éventuelles. La technique que nous allons utiliser consiste à poser \( x=\frac{1}{ h }\) et de développer la fonction ``auxiliaire'' $g(h) = f(1/h)$ autour de \( h=0\). La limite avec \( h\to 0^+\) donnera le comportement pour \( x\to \infty\) et la limite \( h\to 0^-\) donnera le comportement pour \( x\to -\infty\).

Dans le cas d'une développement autour de \( \pm\infty\) nous ne parlons plus de développement \emph{limité} mais de \defe{développement asymptotique}{développement!asymptotique}.

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{La fonction puissance : remarques pour la suite}
%---------------------------------------------------------------------------------------------------------------------------

Il y a encore de nombreuses choses à dire sur la fonction puissance. Pour savoir lesquelles, voir le thème \ref{THEMEooBSBLooWcaQnR}.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Fonctions réelles de deux variables réelles}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Une \textbf{fonction réelle de 2 variables réelles} est une fonction $f : A \subset \eR^2 \to \eR : (x,y) \mapsto z = f(x,y)$.

Le \textbf{graphe de $f$}, noté $\Graphe f$, est un sous-ensemble de $\eR^3$:\[\Graphe f = \{(x,y,z) \in \eR^3 \mid (x,y) \in A \text{ et } z = f(x,y)\}\]

Les \textbf{courbes de niveau} de la fonction $f$ sont obtenues en posant $f(x,y)=\lambda$.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Limites de fonctions à deux variables}
%---------------------------------------------------------------------------------------------------------------------------

Ici nous n'allons pas entrer dans tous les détails, mais simplement mentionner les quelques techniques les plus courantes.

\begin{theorem}		\label{ThoLimiteCompose}
	Soient deux fonctions $f\colon \eR^n\to \eR^p$ et $g\colon \eR^p\to \eR^q$. Si $a$ est un point adhérent au domaine de $g\circ f$ et si
	\begin{equation}
		\begin{aligned}[]
			\lim_{x\to a}f(x)&=b\\
			\lim_{y\to b}g(y)&=c,
		\end{aligned}
	\end{equation}
	alors
	\begin{equation}
		\lim_{x\to a}(g\circ f)(x)=c.
	\end{equation}
\end{theorem}

Les techniques usuelles sont
\begin{enumerate}

	\item
		La règle de l'étau. Cette technique demande un peu plus d'imagination parce qu'il faut penser à un «truc» différent pour chaque exercice. En revanche, la justification est facile : il y a un théorème qui dit que ça marche.

	\item
		Lorsqu'on applique la règle de l'étau, penser à
		\begin{equation}
			| x |=\sqrt{x^2}\leq\sqrt{x^2+y^2}.
		\end{equation}
		Cela permet de majorer le numérateur. Attention : ce genre de majoration fonctionne seulement au numérateur : agrandir le dénominateur ferait diminuer la fraction.

	\item
		Il n'est pas vrai que
		\begin{equation}
			| x |=\sqrt{x^2}\leq\sqrt{x^4}\leq\sqrt{x^4+2y^4}.
		\end{equation}
		En effet, si $x$ est petit, alors $x^2>x^4$, et non le contraire.

\end{enumerate}

Une technique très efficace pour les limites $(x,y)\to (0,0)$ est le passage aux coordonnées polaires. Il s'agit de poser
\begin{subequations}
	\begin{numcases}{}
		x=r\cos(\theta)\\
		y=r\sin(\theta)
	\end{numcases}
\end{subequations}
et puis de faire la limite $r\to 0$.

Si la limite obtenue {\bf ne dépend pas de $\theta$}, alors c'est la limite cherchée. Voici quelque exemples.

\begin{example}
	Calculer les limites suivantes :
	\begin{enumerate}

		\item
			$\lim_{(x,y)\to(0,0)}\frac{ x-y }{ x+y }$
		\item
			$\lim_{(x,y)\to(0,0)}\frac{ (xy)^2 }{ (x+y)^2+(x-y)^2 }$
		\item
			$\lim_{(x,y)\to(0,0)}\frac{ xy^3 }{ x^2+y^2 }$
		\item
			$\lim_{(x,y)\to(0,0)}\frac{ x\sin(y) }{ \sqrt{x^2+y^2} }$
	\end{enumerate}
    
    Tentez de les faire par vous-même avant de regarder la solution qui suit.
	\begin{enumerate}
		\item
			Ici la méthode des chemins pour est particulièrement éclairante. Regardons d'abord la fonction sur la droite $x=y$. Nous avons
			\begin{equation}
				f(x,y)=\frac{ x-x }{ 2x }=0.
			\end{equation}
			Donc la fonction est nulle sur toute la ligne.

			Si nous regardons maintenant la ligne verticale $x=0$, nous avons
			\begin{equation}
				f(0,y)=\frac{ -y }{ y }=-1,
			\end{equation}
			donc la fonction vaut $-1$ sur toute la ligne verticale.
       %TODO : refaire la figure
%Regardez la figure \ref{LabelFigExoHuitUnINGE}

		\item

		\item
			Regardons la technique des coordonnées polaires. Nous remplaçons $x$ par $r\cos(\theta)$ et $y$ par $r\sin(\theta)$ :
			\begin{equation}
				f(r,\theta)=\frac{ r^4\cos(\theta)\sin^3(\theta) }{ r^2 }=r^2\cos(\theta)\sin^3(\theta).
			\end{equation}
			Cette fonction tend vers zéro quand $r\to 0$. Nous avons donc 
			\begin{equation}
				\lim_{(x,y)\to(0,0)}f(x,y)=0.
			\end{equation}

			Pour cet exercice nous pouvons aussi utiliser la règle de l'étau en écrivant d'abord
			\begin{equation}
				0\leq | f(x,y) |\leq\frac{ | x | |y^3 | }{ | x^2+y^2 | }.
			\end{equation}
			Mais on a $| x |\leq\sqrt{x^2+y^2}$, $| y |\leq\sqrt{x^2+y^2}$ et $| x^2+y^2 |=\big( \sqrt{x^2+y^2} \big)^2$, donc
			\begin{equation}
				0\leq| f(x,y) |\leq \frac{ \sqrt{x^2+y^2}\big( \sqrt{x^2+y^2} \big)^3 }{ \big( \sqrt{x^2+y^2} \big)^2 }=\big( \sqrt{x^2+y^2} \big)^2\to 0.
			\end{equation}

		\item
			En passant aux polaires, nous avons
			\begin{equation}
				f(r,\theta)=\frac{ r\cos\theta\sin\big( r\sin\theta \big) }{ r }=\cos(\theta)\sin\big( r\sin\theta \big).
			\end{equation}
			La limite de cette dernière fonction lorsque $r\to 0$ vaut zéro.

			Une autre façon de procéder consiste à multiplier et diviser par $y$ de telle façon à faire apparaitre $\sin(y)/y$ dont nous connaissons la limite :
			\begin{equation}
				f(x,y)=\frac{ \sin(y) }{ y }\cdot\frac{ xy }{ \sqrt{x^2+y^2} }.
			\end{equation}
			La limite du premier facteur est $1$, tandis que le second peut être traité de façon classique en prenant la valeur absolue et en majorant $| x |$ par $\sqrt{x^2+y^2}$.
			
	\end{enumerate}

	%\newcommand{\CaptionFigExoHuitUnINGE}{Sur toute la ligne rouge, la fonction vaut zéro, tandis que sur la ligne bleue elle vaut $-1$. Au point $(0,0)$, les deux sont inconciliables. Donc la limite n'existe pas.}
	%\input{auto/pictures_tex/Fig_ExoHuitUnINGE.pstricks}

\end{example}


%---------------------------------------------------------------------------------------------------------------------------
\subsection{Dérivées partielles}
%---------------------------------------------------------------------------------------------------------------------------

La \defe{dérivée partielle}{dérivée!partielle} par rapport à $x$ au point $(x,y)$ est notée
\begin{equation}
	\frac{\partial f}{\partial x}(x,y)
\end{equation}
et se calcule en dérivant $f$ par rapport  à $x$ en considérant que $y$ est constante.

De la même manière, la dérivée partielle par rapport à $y$ au point $(x,y)$ est notée
\begin{equation}
	\frac{\partial f}{\partial y}(x,y)
\end{equation}
et se calcule en dérivant $f$ par rapport  à $y$ en considérant que $x$ est constante.

Pour les dérivées partielles secondes,
\begin{itemize}
\item $f''_{xx} (x,y) = (f'_x)'_x = \frac{\partial^2 f}{\partial x^2}(x,y) = \frac{\partial}{\partial x}(\frac{\partial f}{\partial x})$.
\item $f''_{yy} (x,y) = (f'_y)'_y = \frac{\partial^2 f}{\partial y^2}(x,y) = \frac{\partial}{\partial y}(\frac{\partial f}{\partial y})$.
\item $f''_{xy} (x,y) = (f'_x)'_y  = (f'_y)'_x = f''_{yx} (x,y) \text{ ou } \frac{\partial^2 f}{\partial x \partial y}(x,y) = \frac{\partial}{\partial x}(\frac{\partial f}{\partial y})  = \frac{\partial}{\partial y}(\frac{\partial f}{\partial x}) =\frac{\partial^2 f}{\partial y \partial x}(x,y)$.
\end{itemize}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Différentielle et accroissement}
%---------------------------------------------------------------------------------------------------------------------------

La \defe{différentielle totale}{différentielle!totale} de $f$ au point $(a,b)$ est donnée, quand elle existe (!), par la formule
\begin{equation}
	df(a,b) = \frac{\partial f}{\partial x}(a,b)dx + \frac{\partial f}{\partial y}(a,b) dy.
\end{equation}

De la même façon que la formule des accroissements finis disait que $f(x+a)\simeq f(x)+af'(x)$, en deux dimensions nous avons que l'\defe{accroissement}{accroissement} approximatif de $f$ au point $(a,b)$ pour des accroissements $\Delta x$ et $\Delta y$ est
\begin{equation}
	f(x+\Delta x,y+\Delta y)=f(x,y)+\Delta x\frac{ \partial f }{ \partial x }(x,y)+\Delta y\frac{ \partial f }{ \partial y }(x,y).
\end{equation}

%TODO : pour l'index, l'expression régulière suivante aide :
% grep "defe{[A-Za-z ]*}{[A-Z]" *.tex
Le \defe{plan tangent}{plan!tangent} au graphe de $f$ au point $\big(a,b,f(a,b)\big)$ est
\begin{equation}
	T_{(a,b)}(x,y) = f(a,b) + \frac{\partial f}{\partial x}(a,b) (x-a) + \frac{\partial f}{\partial y}(a,b) (y-b)
\end{equation}
essayez d'écrire l'équation de la droite tangente au graphe de $f(x)$ au point $x=a$ en terme de la dérivée de $f$, et comparez votre résultat à cette formule.

Un des principaux théorèmes pour tester la différentiabilité d'une fonction est le suivant.

\begin{theorem}		\label{ThoProuverDiffable}
	Soit une fonction $f\colon \eR^m\to \eR^p$. Si les dérivées partielles existent dans un voisinage de $a$ et donc continues en $a$, alors $f$ est différentiable en $a$.
\end{theorem}
Le plus souvent, nous prouvons qu'une fonction est différentiable en calculant les dérivées partielles et en montrant qu'elles sont continues.

\textbf{Dérivation implicite:} Soit $F(x,f(x)) = 0$ la représentation implicite d'une fonction $y=f(x)$ alors \[y' = f'(x) = - \frac{F'_x}{F'_y}.\]


%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Les fonctions à valeurs vectorielles}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Jusqu'à présent nous avons vu des fonctions de plusieurs variables qui prenaient leurs valeurs dans $\eR$. Nous allons maintenant voir ce qu'il se passe lorsque les fonctions prennent leurs valeurs dans $\eR^3$.

Une fonction d'une variable est dite \defe{à valeurs vectorielles}{fonction!valeurs vectorielles} lorsque
\begin{equation}
    \begin{aligned}
        f\colon I\subset \eR&\to \eR^3 \\
        f(x)&=\begin{pmatrix}
            f_1(x)    \\
            f_2(x)    \\
            f_3(x)
        \end{pmatrix}.
    \end{aligned}
\end{equation}
Les fonctions $f_i\colon \eR\to \eR$ sont les \defe{composantes}{composante} de $f$. Ce que nous avons raconté à propos des dérivées passe facilement :
\begin{equation}
    \frac{ f(a+\epsilon)-f(a) }{ \epsilon }=
    \begin{pmatrix}
        \frac{ f_1(a+\epsilon)-f_1(a) }{ \epsilon }    \\
        \frac{ f_2(a+\epsilon)-f_2(a) }{ \epsilon }    \\
        \frac{ f_3(a+\epsilon)-f_3(a) }{ \epsilon }
    \end{pmatrix}.
\end{equation}
En particulier dès que les fonctions $f_i$ sont dérivables, nous avons
\begin{equation}
    f'(a)=\begin{pmatrix}
        f_1'(a)    \\
        f_2'(a)    \\
        f_3'(a)
    \end{pmatrix}
\end{equation}
comme dérivée de la fonction. Cette dérivée est un vecteur.

\begin{example}
    Si
    \begin{equation}
        f\colon x\in\eR\mapsto \begin{pmatrix}
            x^2 e^{x}    \\
            \cos(x^2)    \\
            x^3+x
        \end{pmatrix},
    \end{equation}
    alors
    \begin{equation}
        f'(x)=\begin{pmatrix}
            2xe^x+x^2e^x    \\
            -2x\sin(x^2)    \\
            3x^2+1
        \end{pmatrix}.
    \end{equation}
\end{example}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Fonctions vectorielles de plusieurs variables}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Ce sont les fonctions de la forme
\begin{equation}
    \begin{aligned}
        f\colon \eR^3&\to \eR^3 \\
        \begin{pmatrix}
            x    \\
            y    \\
            z
        \end{pmatrix}&\mapsto \begin{pmatrix}
            f_1(x,y,z)\\
            f_2(x,y,z)\\
            f_3(x,y,z)
        \end{pmatrix}.
    \end{aligned}
\end{equation}

En ce qui concerne les dérivées, tout se passe comme avant. Si les dérivées partielles des composantes $f_i$ existent au point $a\in\eR^3$, alors
\begin{equation}
    \begin{aligned}[]
        \frac{ \partial f }{ \partial x }(a)&=\begin{pmatrix}
            \partial_xf_1(a)    \\
            \partial_xf_2(a)    \\
            \partial_xf_3(a)    \\
        \end{pmatrix},&
        \frac{ \partial f }{ \partial y }(a)&=\begin{pmatrix}
            \partial_yf_1(a)    \\
            \partial_yf_2(a)    \\
            \partial_yf_3(a)    \\
        \end{pmatrix},&
        \frac{ \partial f }{ \partial z }(a)&=\begin{pmatrix}
            \partial_zf_1(a)    \\
            \partial_zf_2(a)    \\
            \partial_zf_3(a)    \\
        \end{pmatrix}.
    \end{aligned}
\end{equation}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Limites à plusieurs variables}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{proposition}	\label{PropLimParcompos}
	Soit $f\colon D\subset\eR^m\to \eR^n$. Nous avons
	\begin{equation}
		\lim_{x\to a} f(x)=\ell
	\end{equation}
	si et seulement si
	\begin{equation}
		\lim_{x\to a} f_i(x)=\ell_i
	\end{equation}
	pour tout $i\in\{ 1,\ldots,n \}$ où $f_i(x)$ dénote la $i$-ème composante de $f(x)$ et $\ell_i$ la $i$-ème composante de $\ell\in\eR^n$.
\end{proposition}
Cette proposition revient à dire que la convergence d'une fonction est équivalente à la convergence de chacune de ses composantes.

\begin{proof}
	L'élément clef de la preuve est le fait que pour tout vecteur $u\in\eR^p$, nous ayons l'inégalité
	\begin{equation}	\label{Equilequnorme}
		| u_i |\leq\sqrt{\sum_{k=1}^p| u_k |^2}=\| u \|.
	\end{equation}
	La norme (dans $\eR^p$) d'un vecteur est plus grande ou égale à la valeur absolue de chacune de ses composantes.

	Supposons que nous ayons une fonction dont chacune des composantes a une limite en $a$ : $\lim_{x\to a} f_i(x)=\ell_i$. Montrons que dans ce cas la fonction $f$ tend vers $\ell$. Si nous considérons $\varepsilon>0$, par définition de la limite de chacune des fonctions $f_i$, il  existent des $\delta_i$ tels que
	\begin{equation}
		\| x-a \|_{\eR^m}<\delta_i\Rightarrow | f_i(x)-\ell_i |<\varepsilon.
	\end{equation}
	Notez que la norme à gauche est une norme dans $\eR^m$ et que celle à droite est une simple valeur absolue dans $\eR$. Considérons $\delta=\min\{ \delta_i \}_{i=1,\ldots n}$. Si $\| x-a \|<\delta$, alors
	\begin{equation}
		\| f(x)-\ell \|=\sqrt{\sum_{i=1}^n| f_i(x)-\ell_i |^2}<\sqrt{\sum_{i=1}^n\varepsilon^2}=\sqrt{n\varepsilon^2}=\sqrt{n}\varepsilon.
	\end{equation}
	Nous voyons qu'en choisissant les $\delta_i$ tels que $| f_i(x)-\ell_i |<\varepsilon$, nous trouvons $\| f(x)-\ell \|<\sqrt{n}\varepsilon$. Afin d'obtenir $\| f(x)-\ell \|<\varepsilon$, nous choisissons donc les $\delta_i$ de telle manière a avoir $| f_i(x)-\ell_i |<\varepsilon/\sqrt{n}$.

	Nous avons donc prouvé que la limite composante par composante impliquait la limite de la fonction. Nous devons encore prouver le sens inverse.

	Supposons donc que $\lim_{x\to a} f(x)=\ell$, et prouvons que nous ayons $\lim_{x\to a} f_i(x)=\ell_i$ pour chaque $i$. Soit $\varepsilon>0$ et $\delta>0$ tel que $\| x-a \|<\delta$ implique $\| f(x)-\ell \|<\varepsilon$. Avec ces choix, nous avons
	\begin{equation}
		| f_i(x)-\ell_i |\leq\| f(x)-\ell \|<\varepsilon
	\end{equation}
	où nous avons utilisé la majoration \eqref{Equilequnorme} avec $f(x)-\ell$ en guise de $u$.
\end{proof}

De même, pour la continuité nous avons la proposition suivante :
\begin{proposition}
	Soit une fonction $f\colon D\subset\eR^m\to \eR^n$ et $a\in D$. La fonction $f$ est continue en $a$ si et seulement si chacune de ses composantes l'est, c'est-à-dire si et seulement si chacune des fonctions $f_i\colon D\to \eR$ est continue en $a$.
\end{proposition}
Essayez de prouver cette proposition directement par la définition de la continuité, en suivant pas à pas la démonstration de la proposition~\ref{PropLimParcompos}.

\begin{proposition}		\label{Propfaposfxposcont}
	Soit $f\colon \eR^m\to \eR$ et $a$, un point du domaine de $f$ telle que $f(a)>0$. Alors il existe un rayon $r$ tel que $f(x)>0$ pour tout $x$ dans $B(a,r)$.
\end{proposition}
Cette proposition signifie que si la fonction est strictement positive en un point, alors elle restera strictement positive en tous les points «pas trop loin».

\begin{proof}
	Prenons $\varepsilon=f(a)/2$ dans la définition de la continuité. Il existe donc un rayon $\delta$ tel que pour tout $x$ dans $B(a,\delta)$,
	\begin{equation}
		| f(x)-f(a) |\leq \frac{ f(a) }{2},
	\end{equation}
	en d'autres termes, $f(x)\in B\big( f(a),\frac{ f(a) }{ 2 } \big)$. évidemment aucun nombre négatif ne fait partie de cette dernière boule lorsque $f(a)$ est strictement positif.
\end{proof}

\begin{corollary}		\label{CorfneqzOuvert}
	Si $f\colon \eR^m\to \eR$ est une fonction continue, alors l'ensemble
	\begin{equation}
		A=\{ x\in\eR^m\tqs f(x)\neq 0 \}
	\end{equation}
	est ouvert.
\end{corollary}

\begin{proof}
	Soit $x\in A$. Si $x>0$ (le cas $x<0$ est laissé en exercice), alors il existe une boule autour de $x$ sur laquelle $f$ reste strictement positive (proposition~\ref{Propfaposfxposcont}). Cette boule est donc contenue dans $A$. Étant donné qu'autour de chaque point de $A$ nous pouvons trouver une boule contenue dans $A$, ce dernier est ouvert.
\end{proof}

\begin{example} \label{ExBNOQEWe}
    Soit  $GL_n(\eR)$ l'ensemble des matrices $n \times n$ inversibles.   Nous allons montrer que $GL_n(\eR)$ est un ouvert de $ \eR^{n^2}$. L'identification entre les vecteurs et les matrices consiste simplement à «déplier» la matrice pour en faire un vecteur. Par exemple, en dimension deux,
	\begin{equation}
		\begin{pmatrix}
			1	&	2	\\
			3	&	4
		\end{pmatrix}\mapsto
		\begin{pmatrix}
			1	\\
			2	\\
			3	\\
			4
		\end{pmatrix}\in\eR^4.
	\end{equation}
	En dimension $3$,
	\begin{equation}
		\begin{aligned}[]
			\begin{pmatrix}
				1	&	2	&	3	\\
				4	&	5	&	6	\\
				7	&	8	&	9
			\end{pmatrix}
			\mapsto
			\begin{pmatrix}
				1	\\
				2	\\
				3	\\
				4	\\
				5	\\
				6	\\
				7	\\
				8	\\
				9
			\end{pmatrix}\in\eR^9.
		\end{aligned}
	\end{equation}

	Une matrice est inversible si et seulement si son déterminant est non nul. Or le déterminant est un polynôme en les composantes de la matrice. En dimension deux, nous avons
	\begin{equation}
		\det\begin{pmatrix}
			a	&	b	\\
			c	&	d
		\end{pmatrix}=ad-bc,
	\end{equation}
	mais en écriture «dépliée», nous pouvons aussi bien écrire
	\begin{equation}
		\det\begin{pmatrix}
			a	\\
			b	\\
			c	\\
			d
		\end{pmatrix}=ad-bc.
	\end{equation}
	En dimension $3$, le déterminant est donc un polynôme des $9$ variables qui apparaissent dans le vecteur «déplié». En général, dans $\eR^{n^2}$, nous considérons donc le polynôme $\det\colon \eR^{n^2}\to \eR$ qui à un vecteur $X\in\eR^{n^2}$ fait correspondre le déterminant de la matrice obtenue en «repliant» le vecteur $X$.

	Donc dans $\eR^{n^2}$, l'ensemble des matrices inversibles est donné par l'ensemble des vecteurs sur lesquels le polynôme $\det$ ne s'annule pas, c'est-à-dire
	\begin{equation}
		\{ X\in\eR^{n^2}\tqs \det(X)\neq 0 \}.
	\end{equation}
	Mais le déterminant est un polynôme, et donc une fonction continue. Cet ensemble est par conséquence ouvert par le corollaire~\ref{CorfneqzOuvert}.
\end{example}



La proposition suivante montre que la limite peut «passer à travers» les fonctions continues.
\begin{proposition}[limite de fonction composée]		\label{PropLimCompose}
	Soit $f\colon \eR^n\to \eR^q$ et $g\colon \eR^m\to \eR^n$ telles que
	\begin{subequations}
		\begin{align}
			\lim_{x\to a} g(x)&= p		\label{EqLimCompHypa}\\
			\lim_{y\to p} f(y)&= q		\label{EqLimCompHypb}
		\end{align}
	\end{subequations}
	Alors nous avons $\lim_{x\to a} (f\circ g)(x)=q$.
\end{proposition}

\begin{proof}
	Comme presque toute preuve à propos de limite ou de continuité, nous commençons par choisir $\varepsilon>0$. Nous devons montrer qu'il existe un $\delta$ tel que $\| x-a \|\leq \delta$ implique $\| f\big( g(x) \big)-q \|\leq \varepsilon$.

	La limite \eqref{EqLimCompHypb} impose l'existence d'un $\tilde\delta$ tel que $\| y-p \|\leq\tilde\delta$ implique $\| f(y)-q \|\leq\varepsilon$, tandis que la limite \eqref{EqLimCompHypa} donne un $\delta$ tel que $\| x-a \|\leq\delta$ implique $\| g(x)-p \|\leq\tilde\delta$ (nous avons pris $\tilde\delta$ en guise de $\varepsilon$ dans la définition de la limite pour $g$).

	Avec ces choix, si $\| x-a \|\leq \delta$, alors $\| g(x)-p \|\leq\tilde\delta$, et par conséquent,
	\begin{equation}
		\| f\big( g(x) \big)-q \|\leq\varepsilon,
	\end{equation}
	ce que nous voulions.
\end{proof}

De façon pragmatique, la proposition~\ref{PropLimCompose} nous fournit une formule pour les limites de fonctions composée :
\begin{equation}		\label{Eqlimfgvomp}
	\lim_{x\to a} (f\circ g)(x)=\lim_{y\to \lim_{x\to a} g(x)}f(y)
\end{equation}
lorsque $f$ est continue.

\begin{remark}
	La formule \eqref{Eqlimfgvomp} ne peut pas être utilisée à l'envers. Il existe des cas où $\lim_{x\to a} (g\circ f)(x)=q$, et $\lim_{x\to a} f(x)=p$ sans pour autant avoir $\lim_{y\to q} g(y)=q$. Par exemple
	\begin{subequations}
		\begin{align}
			g(x)&=\begin{cases}
				2	&	\text{si }x\geq0\\
				0	&	 \text{si }x<0\\
			\end{cases}\\
			f(x)&=| x |.
		\end{align}
	\end{subequations}
	Nous avons $(g\circ f)(x)=2$ pour tout $x$, ainsi que $\lim_{x\to 0} f(x)=0$, mais la limite $\lim_{y\to 0} g(y)$ n'existe pas.
\end{remark}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Champs de vecteurs}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Un champ de vecteur est une fonction $f\colon \eR^3\to \eR^3$. Géométriquement, il s'agit simplement de mettre un vecteur en chaque point de l'espace. Cela arrive très souvent en physique.

\begin{example}
    Si un fluide (eau, gaz) coule dans un tube, en tout point le point a une vitesse, qui sera un vecteur généralement dirigé le long du tube.
\end{example}

\begin{example}
    La force d'attraction de la Terre sur une masse $m$ située au point $r=(x,y,z)$ est donnée par
    \begin{equation}
        F(r)=-G\frac{ Mmr }{ \| r \|^3 }.
    \end{equation}
    Dans cette expression, tant $r$ que $F(r)$ sont des vecteurs. Nous l'avons représenté sur la figure~\ref{LabelFigSQNPooPTrLRQ}. % From file SQNPooPTrLRQ
\newcommand{\CaptionFigSQNPooPTrLRQ}{Le champ de gravitation de la Terre.}
\input{auto/pictures_tex/Fig_SQNPooPTrLRQ.pstricks}

    L'application
    \begin{equation}
        \begin{aligned}
            F\colon \eR^3&\to \eR^3 \\
            r&\mapsto F(r)
        \end{aligned}
    \end{equation}
    est le champ gravitationnel de la Terre.

\end{example}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Matrice jacobienne}
%---------------------------------------------------------------------------------------------------------------------------

La \defe{matrice jacobienne}{jacobien} de la fonction $f\colon \eR^3\to \eR^3$ au point $a\in\eR^3$ est la matrice dont les colonnes sont les vecteurs $\frac{ \partial f }{ \partial x }(a)$, $\frac{ \partial f }{ \partial y }(a)$ et $\frac{ \partial f }{ \partial z }(a)$, c'est-à-dire
\begin{equation}
    J_f(a)=\begin{pmatrix}
        \frac{ \partial f_1 }{ \partial x }(a)   &   \frac{ \partial f_1 }{ \partial y }(a)    &   \frac{ \partial f_1 }{ \partial z }(a)    \\
        \frac{ \partial f_2 }{ \partial x }(a)   &   \frac{ \partial f_2 }{ \partial y }(a)    &   \frac{ \partial f_2 }{ \partial z }(a)    \\
        \frac{ \partial f_3 }{ \partial x }(a)   &   \frac{ \partial f_3 }{ \partial y }(a)    &   \frac{ \partial f_3 }{ \partial z }(a)
    \end{pmatrix}.
\end{equation}

\begin{example}
    Si
    \begin{equation}
        f(x,y,z)=\begin{pmatrix}
            xy e^{z}    \\
            x^2+\cos(yz)    \\
            xyz
        \end{pmatrix},
    \end{equation}
    alors
    \begin{equation}
        J_f(x,y,z)=\begin{pmatrix}
            ye^z    &   xe^z    &   xye^z    \\
            2x    &   -z\sin(yz)    &   -y\sin(yz)    \\
            yz    &   xz    &   xy
        \end{pmatrix}.
    \end{equation}
\end{example}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Divergence, rotationnel et l'opérateur nabla}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Nous avons déjà vu le gradient d'une fonction $f\colon \eR^3\to \eR$
\begin{equation}        \label{EqDefNablaf}
    \nabla f(x,y,z)=\begin{pmatrix}
        \partial_xf(x,y,z)    \\
        \partial_yf(x,y,z)    \\
        \partial_zf(x,y,z)
    \end{pmatrix}
\end{equation}
Afin de définir la divergence et le rotationnel, nous introduisons $\nabla$ sous une forme un peu plus abstraite comme le «vecteur»
\begin{equation}
    \nabla=\begin{pmatrix}
        \partial_x    \\
        \partial_y    \\
        \partial_z
    \end{pmatrix}.
\end{equation}
Vue comme ça, la formule \eqref{EqDefNablaf} est claire.

Si $F$ est un champ de vecteurs, nous introduisons la \defe{divergence}{divergence} de $F$ par
\begin{equation}
    \nabla\cdot F=\frac{ \partial F_x }{ \partial x }+\frac{ \partial F_y }{ \partial y }+\frac{ \partial F_z }{ \partial z }.
\end{equation}
Cela est une fonction. Et nous introduisons le rotationnel du champ de vecteur $F$ par
\begin{equation}
    \begin{aligned}[]
        \nabla\times F&=\begin{vmatrix}
              e_x  &   e_y    &   e_z    \\
            \partial_x    &   \partial_y    &   \partial_z    \\
            F_x    &   F_y    &   F_z
        \end{vmatrix}\\
        &=
        \left( \frac{ \partial F_z }{ \partial y }-\frac{ \partial F_y }{ \partial z } \right)e_x
        -\left( \frac{ \partial F_z }{ \partial x }-\frac{ \partial F_x }{ \partial z } \right)e_y
        +\left( \frac{ \partial F_y }{ \partial x }-\frac{ \partial F_x }{ \partial y } \right)e_z.
    \end{aligned}
\end{equation}
Cela est un champ de vecteur. En utilisant le symbole complètement antisymétrique \( \epsilon_{ijk}\), le rotationnel d'un champ de vecteur peut s'écrire
\begin{equation}
    \nabla\times F=\sum_{ijk}\epsilon_{ijk}\partial_i F_j e_k.
\end{equation}

Le gradient, la divergence et le rotationnel consistent à appliquer simplement à $\nabla$ est trois produits qu'on peut effectuer sur un vecteur:
\begin{enumerate}
    \item
        Le produit d'un vecteur par un scalaire multiplie chacune des composantes :
        \begin{equation}
            \begin{pmatrix}
                \partial_x    \\
                \partial_y    \\
                \partial_z
            \end{pmatrix}f
            =\begin{pmatrix}
                \partial_xf    \\
                \partial_yf    \\
                \partial_zf
            \end{pmatrix}.
        \end{equation}
    \item
        Le produit scalaire d'un vecteur avec un autre vecteur donne lieu à la divergence :
        \begin{equation}
            \begin{pmatrix}
                \partial_x    \\
                \partial_y    \\
                \partial_z
            \end{pmatrix}\cdot
            \begin{pmatrix}
                F_x    \\
                F_y    \\
                F_z
            \end{pmatrix}=
            \frac{ \partial F_x }{ \partial x }+\frac{ \partial F_y }{ \partial y }+\frac{ \partial F_z }{ \partial z }.
        \end{equation}
    \item
        Le produit vectoriel de deux vecteurs :
        \begin{equation}
            \begin{pmatrix}
                \partial_x    \\
                \partial_y    \\
                \partial_z
            \end{pmatrix}\times\begin{pmatrix}
                F_x    \\
                F_y    \\
                F_z
            \end{pmatrix}=
            \begin{vmatrix}
                e_x    &   e_y    &   e_z    \\
                \partial_x    &   \partial_y    &   \partial_z    \\
                F_x    &   F_y    &   F_z
            \end{vmatrix}.
        \end{equation}
\end{enumerate}
Ces trois opérations joueront un rôle central en électromagnétisme dans les équations de Maxwell.

\begin{example}
    Soit $F(x,y,z)=x e_x+xy e_y+e_z$, c'est-à-dire
    \begin{equation}
        F(x,y,z)=\begin{pmatrix}
            x    \\
            xy    \\
            1
        \end{pmatrix}.
    \end{equation}
    Son rotationnel est donné par
    \begin{equation}
        \nabla\times F=\begin{vmatrix}
            e_x    &   e_y    &   e_z    \\
            \frac{ \partial  }{ \partial x }    &   \frac{ \partial  }{ \partial y }    &   \frac{ \partial  }{ \partial y }    \\
            x    &   xy    &   1
        \end{vmatrix}=
        (0-0)e_x-(0-0)e_y+(y-0)e_z=ye_z=\begin{pmatrix}
            0    \\
            0    \\
            y
        \end{pmatrix}.
    \end{equation}
\end{example}

Afin d'étudier comment se comporte la composition de ces opérateurs, nous aurons besoin de ce lemme que nous n'énoncerons pas précisément.
\begin{lemma}       \label{LemPermDerrxyz}
    Si $f\colon \eR^3\to \eR$ est une fonction de classe $C^2$, alors on peut permuter l'ordre des dérivées:
    \begin{equation}
        \begin{aligned}[]
            \frac{ \partial  }{ \partial x }\left( \frac{ \partial f }{ \partial y } \right)&=\frac{ \partial  }{ \partial y }\left( \frac{ \partial f }{ \partial x } \right)\\
            \frac{ \partial  }{ \partial x }\left( \frac{ \partial f }{ \partial z } \right)&=\frac{ \partial  }{ \partial z }\left( \frac{ \partial f }{ \partial x } \right)\\
            \frac{ \partial  }{ \partial z }\left( \frac{ \partial f }{ \partial y } \right)&=\frac{ \partial  }{ \partial y }\left( \frac{ \partial f }{ \partial z } \right)
        \end{aligned}
    \end{equation}
\end{lemma}
La fonction
\begin{equation}
    (x,y,z)\mapsto\frac{ \partial  }{ \partial x }\left( \frac{ \partial f }{ \partial y } \right)(x,y,z)
\end{equation}
sera notée
\begin{equation}
    \frac{ \partial^2f }{ \partial x\partial y }.
\end{equation}

Il y a deux propriétés importantes :
\begin{theorem}
    Soit $f\colon \eR^3\to \eR$ une fonction de classe $C^2$. Alors
    \begin{equation}
        \nabla\times(\nabla f)=0.
    \end{equation}
    Si $F\colon \eR^3\to \eR^3$ est un champ de vecteurs de classe $C^2$, alors
    \begin{equation}
        \nabla\cdot(\nabla\times F)=0.
    \end{equation}
\end{theorem}

\begin{proof}
    Ce sont seulement deux calculs qui manipulent les définitions. Pour le premier, la divergence de $f$ est le champ de vecteurs
    \begin{equation}
        \nabla f=\frac{ \partial f }{ \partial x }e_x+\frac{ \partial f }{ \partial y }e_y+\frac{ \partial f }{ \partial z }e_z.
    \end{equation}
    En mettant ce champ dans la définition du rotationnel,
    \begin{equation}
        \begin{aligned}[]
            \nabla\times(\nabla f)=\begin{vmatrix}
                 e_x   &   e_y    &   e_z    \\
                 \frac{ \partial  }{ \partial x }    &   \frac{ \partial  }{ \partial y }    &   \frac{ \partial  }{ \partial z }    \\
                 \frac{ \partial f }{ \partial x }    &   \frac{ \partial f }{ \partial y }    &   \frac{ \partial f }{ \partial z }
            \end{vmatrix}
            &=\left[ \frac{ \partial  }{ \partial y }\left( \frac{ \partial f }{ \partial z } \right)-\frac{ \partial  }{ \partial z }\left( \frac{ \partial f }{ \partial y } \right) \right]e_x\\
            &\quad-\left[ \frac{ \partial  }{ \partial x }\left( \frac{ \partial f }{ \partial z } \right)-\frac{ \partial  }{ \partial z }\left( \frac{ \partial f }{ \partial x } \right) \right]e_y\\
            &\quad+\left[ \frac{ \partial  }{ \partial x }\left( \frac{ \partial f }{ \partial y } \right)-\frac{ \partial  }{ \partial y }\left( \frac{ \partial f }{ \partial x } \right) \right]e_z.
        \end{aligned}
    \end{equation}
    En utilisant le lemme~\ref{LemPermDerrxyz}, chacun des termes fait zéro.

    La seconde propriété se démontre en utilisant le même type de calcul.
\end{proof}

\begin{remark}
    Il n'y a pas de propriétés du même style pour la combinaison $\nabla\times(\nabla\cdot F)$ pour le rotationnel de la divergence. En effet la divergence d'un champ de vecteur est une fonction, et il n'y a pas de rotationnel pour une fonction.
\end{remark}

\notbool{isBook}
{
\begin{center}
            \includegraphics[width=10cm]{pictures_bitmap/501-curling-with-gradients.png}\\
        \url{http://spikedmath.com/501.html}{Spiked math}, \href{http://creativecommons.org/licenses/by-nc-sa/2.5/ca/}{licence Creative Commons by-nc 2.5}.
\end{center}
}{}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section[Interprétation de la divergence]{Interprétation géométrique et physique de la divergence}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

En physique, on dit qu'un champ de vecteurs à divergence nulle est \defe{incompressible}{incompressible!champ de vecteur}. Nous allons essayer de comprendre pourquoi. Lorsqu'un fluide incompressible se déplace, il faut qu'en chaque point il y ait autant de fluide qui rentre que de fluide qui sort. Nous allons voir sur quelques exemples que la divergence d'un champ de vecteurs est le «bilan de masse» d'un fluide qui se déplace selon le champ de vecteurs.

Si en un point la divergence est positive, cela signifie qu'il y a une perte de masse et si la divergence est négative, cela signifie qu'il y a une accumulation de masse.

Prenons par exemple un fluide qui se déplace selon le champ de vitesse montré à figure~\ref{LabelFigBEHTooWsdrys}. % From file BEHTooWsdrys
\newcommand{\CaptionFigBEHTooWsdrys}{Le champ de vecteurs $F(x,y)=\frac{1}{ x }(1,0)$.}
\input{auto/pictures_tex/Fig_BEHTooWsdrys.pstricks}

Étant donné que la vitesse diminue lorsque $x$ avance, il y a une accumulation de fluide. Regardez en effet la quantité de fluide qui rentre dans le rectangle par rapport à la quantité de fluide qui en sort. Ce champ de vecteurs a pour équation :
\begin{equation}
    F(x,y)=\frac{1}{ x }\begin{pmatrix}
        1    \\
        0
    \end{pmatrix}=\begin{pmatrix}
        1/x    \\
        0
    \end{pmatrix}.
\end{equation}
Sa divergence vaut donc
\begin{equation}
    (\nabla\cdot F)(x,y)=\frac{ \partial F_x }{ \partial x }(x,y)+\underbrace{\frac{ \partial F_y }{ \partial y }(x,y)}_{=0}=-\frac{1}{ x^2 }.
\end{equation}
Cette divergence étant négative, il y a bien accumulation de fluide en tout point, et d'autant plus que $x$ est petit.

\begin{example}     \label{ExamDivFrot}

    Prenons le champ de vecteurs tournant
    \begin{equation}
        F(x,y)=\frac{1}{ \sqrt{x^2+y^2} }\begin{pmatrix}
            y    \\
            -x
        \end{pmatrix}
    \end{equation}
    représenté à la figure~\ref{LabelFigYQVHooYsGLHQ}. Cela est un vecteur qui est constamment perpendiculaire au rayon.


\newcommand{\CaptionFigYQVHooYsGLHQ}{Le champ de vecteurs $F(x,y)=(y,-x)$.}
\input{auto/pictures_tex/Fig_YQVHooYsGLHQ.pstricks}

    Un fluide dont la vitesse serait donné par ce champ de vecteur se contente de tourner. Intuitivement il ne devrait pas y avoir de divergence parce qu'il n'y a aucune accumulation de fluide. En effet,
    \begin{equation}
        \nabla\cdot F(x,y)=\frac{ -2xy }{ (x^2+y^2)^2 }+\frac{ 2xy }{ (x^2+y^2)^2 }=0.
    \end{equation}
\end{example}

\begin{example}
    Prenons le cas du champ de force de gravitation :
    \begin{equation}
        F(x,y,z)=\frac{1}{ (x^2+y^2+z^2)^{3/2} }\begin{pmatrix}
            x    \\
            y   \\
            z
        \end{pmatrix}.
    \end{equation}
    Nous pouvons rapidement remarquer que $\nabla\cdot F=0$. Est-ce que cela peut se comprendre sur le dessin de la figure~\ref{LabelFigZGUDooEsqCWQ} ? % From file ZGUDooEsqCWQ
\newcommand{\CaptionFigZGUDooEsqCWQ}{Le champ de vecteur de la gravité. Nous avons tracé, sur les deux cercles la même densité de vecteurs, c'est-à-dire le même nombre de vecteurs par unité de surface.}
\input{auto/pictures_tex/Fig_ZGUDooEsqCWQ.pstricks}

    Essayons de voir combien de fluide entre dans la zone bleue et combien en sort. D'abord, il est certain que les vecteurs qui sortent sont plus courts que ceux qui rentrent, ce qui voudrait dire qu'il y a plus de fluide qui rentre. Mais on voit également que le \emph{nombre} de vecteurs qui sortent est plus grand parce que la seconde sphère est plus grande et qu'il y a un vecteur en chaque point de la sphère.

    Intuitivement nous pouvons dire que la quantité qui rentre dans la sphère de rayon $r_1$ donnée par la taille des vecteurs entrants multiplié par la surface de la sphère, c'est-à-dire
    \begin{equation}        \label{EqQpinormeVecto}
        4\pi r_1^2\| F(x,y,z) \|,
    \end{equation}
    mais $\| F(x,y,z) \|=\frac{1}{ r_1^2 }$, donc la quantité de fluide entrant est $4\pi$. La quantité de fluide sortant sera la même.

    Cela explique deux choses
    \begin{enumerate}
        \item
            Pourquoi les forces de gravitation et électromagnétiques sont en $1/r^2$; c'est parce que nous vivons dans un monde avec trois dimensions d'espace. En étudiant très précisément le champ de gravitation, certains physiciens espèrent trouver des déviations expérimentales par rapport à la règle du \( 1/r^2\); cela \emph{pourrait} être un signe que l'espace contient des dimensions supplémentaires.
        \item
            Pourquoi il y a un $4\pi$ comme coefficient dans beaucoup d'équations en électromagnétisme; en particulier dans certaines anciennes unités de flux.
    \end{enumerate}

\end{example}

\begin{remark}
    Nous allons voir plus loin comment s'assurer que l'équation \eqref{EqQpinormeVecto} représente bien la «quantité de fluide» qui rentre dans la zone délimitée
\end{remark}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Quelques formules de Leibnitz}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

La divergence étant une combinaison de dérivées, il n'est pas tellement étonnant que la divergence de produits donne lieux à des formules en deux termes. Si $f$ est une fonction et si $F$ et $G$ sont des champs de vecteurs, nous avons la proposition suivante.

\begin{proposition}     \label{PROPooDMWEooNaJBCM}
    Si \( F\) et \( G\) sont des champs de vecteurs dont toutes les dérivées partielles existent, alors    
    \begin{enumerate}
        \item
            $\nabla\cdot(fF)f\nabla\cdot F+F\cdot\nabla f$
        \item
            $\nabla\cdot(F\times G)=G\cdot\nabla\times F-F\cdot\nabla\times G$
        \item       \label{ITEMooFDJIooKTnvKj}
            $\nabla\times(fF)=f\nabla\times F+\nabla f\times F$.
    \end{enumerate}
\end{proposition}

