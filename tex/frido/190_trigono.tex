% This is part of (everything) I know in mathematics
% Copyright (c) 2011-2017, 2019
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Isométries de l'espace euclidien}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Nous considérons l'espace affine euclidien \( A=\affE_n(\eR)\) modelé sur \( \eR^n\) avec sa métrique usuelle. Un premier grand résultat sera le théorème~\ref{ThoDsFErq} qui dira que les isométries de cet espace sont des applications linéaires.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Structure du groupe  \texorpdfstring{\( \Isom(\eR^n)\)}{Isom(Rn)} }
%---------------------------------------------------------------------------------------------------------------------------

Si vous ne voulez pas savoir ce qu'est un produit semi-direct de groupes, vous pouvez lire seulement le point~\ref{ITEMooLLUIooIGsknv} du théorème suivant, et passer directement à la remarque~\ref{REMooLUEZooIwvTqu}.
\begin{theorem}     \label{THOooQJSRooMrqQct}
    Un peu de structure sur \( \Isom(\eR^n)\).
    \begin{enumerate}
        \item       \label{ITEMooLLUIooIGsknv}
            L'application
            \begin{equation}
                \begin{aligned}
                    \psi\colon T(n)\times \gO(n)&\to \Isom(\eR^n) \\
                    (v,\Lambda)&\mapsto \tau_v\circ\Lambda
                \end{aligned}
            \end{equation}
            est une bijection. Ici,  \( T(n)\) est le groupe des translations de \( \eR^n\).
        \item
            Un couple \( (v,\Lambda)\in T(n)\times\SO(n)\) agit sur \( x\in \eR^n\) par
            \begin{equation}
                (v,\Lambda)x=\Lambda x+v
            \end{equation}
            au sens où \( \psi(v,\Lambda)x=\Lambda x+v\).
        \item       \label{ITEMooEWSIooNKzRxB}
            En tant que groupes,
            \begin{equation}
                \Isom(\eR^n)\simeq T(n)\times_{\rho}\gO(n)
            \end{equation}
            où \( \rho\) représente l'action adjointe de \( \gO(n)\) sur \( T(n)\) et \( \times_{\rho}\) dénotes le produit semi-direct de la définition~\ref{DEFooKWEHooISNQzi}.
    \end{enumerate}
\end{theorem}

\begin{proof}
    Point par point.
    \begin{enumerate}
        \item
            Prouvons que l'application proposée est injective et surjective. Notons aussi que ce point ne parle pas de structure de groupe, mais seulement d'une bijection en tant qu'ensembles.
            \begin{subproof}
                \item[Injection]
                    Si \( \psi(v,\Lambda)=\psi(w,\Lambda')\) alors en appliquant sur \( x=0\) nous avons tout de suite \( v=w\). Et ensuite \( \Lambda=\Lambda'\) est immédiat.
                \item[Surjection]
                    Une isométrie \( g\in\Isom(\eR^n)\) est une application \( g\colon \eR^n\to \eR^n\) telle que \( d(x,y)=d\big( g(x),g(y) \big)\). Dans le cas de \( \eR^n\) cela se traduit par
                    \begin{equation}
                        \| x-y \|=\big\| g(x)-g(y) \big\|,
                    \end{equation}
                    Vu que \( x\mapsto\| x \|\) est une forme quadratique, elle tombe sous le coup du théorème~\ref{ThoDsFErq}, ce qui nous permet de dire que \( g\) est affine. Or par définition une application est affine lorsqu'elle est la composée d'une translation et d'une application linéaire.

                    Donc \( g=\tau_v\circ \Lambda\) pour une certaine application linéaire isométrique \( \Lambda\colon \eR^n\to \eR^n\). L'application \( \Lambda\) est donc dans \( \gO(n)\) par la proposition \ref{PropKBCXooOuEZcS}\ref{ITEMooOWMBooHUatNb}.
            \end{subproof}
        \item
            C'est seulement le fait que \( (\tau_v\circ\Lambda)x=\tau_v\big( \Lambda x \big)=\Lambda(x)+v\).
        \item
            Nous allons étudier l'application
            \begin{equation}
                \psi\colon T(n)\times_{\rho}O(n)\to \Isom(\eR^n).
            \end{equation}
            \begin{subproof}
            \item[Le produit semi-direct est bien définit]
                Il faut montrer que
                \begin{equation}
                    \begin{aligned}
                        \rho\colon O(n)&\to \Aut\big( T(n) \big) \\
                        \Lambda&\mapsto \AD(\Lambda)
                    \end{aligned}
                \end{equation}
                est correcte.

                D'abord pour \( \Lambda\in O(n)\), nous avons bien \( \rho_{\Lambda}(\tau_v)\in T(n)\) parce qu'en appliquant à \( x\in \eR^n\),
                    \begin{equation}
                        (\Lambda\tau_v\Lambda^{-1})(x)=\Lambda\big( \tau_v(\Lambda^{-1} x) \big)=\Lambda\big( \Lambda^{-1}x+v \big)=x+\Lambda(v)=\tau_{\Lambda(v)}(x).
                    \end{equation}
                    Donc \( \rho_{\Lambda}(\tau_v)=\tau_{\Lambda(v)}\).

                    De plus, \( \rho_{\Lambda}\in\Aut\big( T(n) \big)\) parce que
                    \begin{equation}
                        \rho_{\Lambda}\big( \tau_v\circ \tau_w \big)=\rho_{\Lambda}(\tau_v)\circ\rho_{\Lambda}(\tau_v),
                    \end{equation}
                    comme on peut aisément vérifier que les deux membres sont égaux à \( \tau_{\Lambda(v+w)}\).
                \item[\( \psi\) est une bijection]
                    Cela est déjà vérifié.
                \item[\( \psi\) est un homomorphisme]
                    Nous avons d'une part
                    \begin{equation}
                        \psi\big( (v,g)(w,h) \big)=\psi\big( v\rho_g(w),gh \big)=\tau_v\circ g\circ\tau_w\circ g^{-1}\circ g\circ h=\tau_v\circ g\circ\tau_w\circ h.
                    \end{equation}
                    Et d'autre part,
                    \begin{equation}
                        \psi(v,g)\circ\psi(w,h)=\tau_v\circ g\circ \tau_w\circ h,
                    \end{equation}
                    ce qui est la même chose.
            \end{subproof}
    \end{enumerate}
\end{proof}

\begin{remark}      \label{REMooLUEZooIwvTqu}
    Notons au passage la loi de groupe sur les couples qui est donnée, pour tout \( v,v'\in \eR^n\), \( \Lambda,\Lambda'\in\SO(n)\), par
    \begin{equation}    \label{EqDiHcut}
            (v,\Lambda)\cdot(v',\Lambda')=(\Lambda v'+v,\Lambda\Lambda')
    \end{equation}
    comme le montre le calcul suivant :
    \begin{subequations}
        \begin{align}
            (v,\Lambda)\cdot(v',\Lambda')x&=(v,\Lambda)(\Lambda'x+v')\\
            &=\Lambda\Lambda'x+\Lambda v'+v\\
            &=(\Lambda v'+v,\Lambda\Lambda')x.
        \end{align}
    \end{subequations}
\end{remark}

\begin{proposition}[\cite{ooZYLAooXwWjLa}]      \label{PROPooDHYWooXxEXvl}
    Soient \( n\geq 1\) et \( R\) un élément de \( \gO(n)\) de déterminant \( -1\) tels que \( R^2=\id\). En posant \( C_2=\{ \id,R \}\) nous avons
    \begin{equation}
        \gO(n)=\SO(n)\times_{\rho} C_2
    \end{equation}
\end{proposition}

\begin{proof}
    Notons qu'un élément \( R\) comme décrit dans l'énoncé existe. Par exemple il y a l'application  \( (x_1,\ldots, x_n)\mapsto (-x_1,x_2,\ldots, x_n)\). 

    Cela étant dit, nous allons montrer que
    \begin{equation}
        \begin{aligned}
            \psi\colon \SO(n)\times C_2&\to \gO(n) \\
            (A,h)&\mapsto Ah.
        \end{aligned}
    \end{equation}
    est un isomorphisme.
    \begin{subproof}
        \item[Injectif]
            Soient \( A,B\in \SO(n)\) et \( h,k\in C_2\) tels que \( \psi(A,h)=\psi(B,k)\), c'est-à-dire tels que \( Ah=Bk\). Vu que \( \det(A)=\det(B)=1\) nous avons \( \det(h)=\det(k)\). Mais comme \( C_2\) contient un élément de déterminant \( 1\) et un élément de déterminant \( -1\), nous avons \( h=k\). De là \( A=B\).
        \item[Surjectif]
            Soit \( X\in\gO(n)\). Si \( \det(X)=1\) alors \( X\in \SO(n)\) et \( X=\psi(X,\mtu)\). Si par contre \( \det(X)=-1\) alors \( XR\in\SO(n)\) parce que \( \det(XR)=1\) et nous avons
            \begin{equation}
                \psi(XR,R)=XR^2=X.
            \end{equation}
        \item[Homomorphisme]
            Nous avons
            \begin{equation}
                \psi\Big( (A,h)(B,k) \Big)=\psi\big( A\rho_h(B),hk \big)=A(hBh^{-1})hk=AhBk,
            \end{equation}
            tandis que
            \begin{equation}
                \psi(A,h)\psi(B,k)=AhBk,
            \end{equation}
            qui est la même chose.
    \end{subproof}
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Isométries dans $\eR^n$}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{definition}
    Un \defe{hyperplan}{hyperplan} de \( \eR^n\) est un sous-espace affine de dimension \( n-1\).
\end{definition}

\begin{lemmaDef}
    Si un hyperplan \( H\) de \( \eR^n\) est donné, et si \( x\in \eR^n\), il existe un unique point \( y\in \eR^n\) tel que
    \begin{enumerate}
        \item
            \( x-y\perp H\),
        \item
            Le segment \( [x,y]\) coupe \( H\) en son milieu.
    \end{enumerate}
    La \defe{réflexion}{réflexion!par rapport à un hyperplan} \( \sigma_H\) est l'application $\sigma_H\colon \eR^n\to \eR^n $ qui à \( x\) fait correspondre ce \( y\).
\end{lemmaDef}

\begin{proof}
    Il faut vérifier que les conditions données définissent effectivement un unique point de \( \eR^n\). Soit \( H_0\) le sous-espace vectoriel parallèle à \( H\) et une base orthonormée \( \{ e_1,\ldots, e_{n-1} \}\) de \( H_0\). Nous complétons cela en une base orthonormée de \( \eR^n\) avec un vecteur \( e_n\). Si \( H=H_0+v\), quitte à décomposer \( v\) en une partie parallèle et une partie perpendiculaire à \( H\), nous avons
    \begin{equation}
        H=H_0+\lambda e_n
    \end{equation}
    pour un certain \( \lambda\).

    Une droite passant par \( x\) et perpendiculaire à \( H\) est de la forme \( t\mapsto x+te_n\). Si \( x=\sum_{i=1}^{n}x_ie_i\) alors l'unique point de cette droit à être dans \( H\) est le point tel que \(   x_ne_n+te_n=\lambda e_n   \), c'est-à-dire \( t=-x_n\). L'unique point \( y\) sur cette droite à être tel que \( [x,y ]\) coupe \( H\) en son milieu est celui qui correspond à \( t=-2x_n\).
\end{proof}

Notons au passage que cette preuve donne une formule pour \( \sigma_H\) :
\begin{equation}        \label{EQooRTWLooLPsUpY}
    \sigma_H(x)=\sum_{i=1}^{n-1}x_ie_i-x_ne_n.
\end{equation}
Il s'agit donc de changer le signe de la composante perpendiculaire à \( H\).

\begin{lemma}       \label{LEMooWYVRooQmWqvM}
    Dans cette même base si \( H_0\) est l'hyperplan parallèle à \( H\) et passant par l'origine, nous écrivons \( H=H_0+\lambda e_n\) pour un certain \( \lambda\). Alors
    \begin{equation}
        \sigma_H=\sigma_{H_0}+2\lambda e_n.
    \end{equation}
\end{lemma}

\begin{proof}
    Un élément \( x\in \eR^n\) peut être décomposé dans la base adéquate en \( x=x_H+x_ne_n\). Nous savons de la formule \eqref{EQooRTWLooLPsUpY} que
    \begin{equation}
        \sigma_H(x)=x_H-x_ne_n.
    \end{equation}
    Mais vu que \( \sigma_{H_0}(x_H)=x_H-2\lambda e_n\) nous avons
    \begin{equation}
            \sigma_{H_0}(x)+2\lambda e_n=\sigma_{H_0}(x_H+x_ne_n)+2\lambda e_N=x_H-2\lambda e_n-x_ne_n+2\lambda e_n=x_H-x_ne_n.
    \end{equation}
\end{proof}

Le lemme suivant est une généralisation du fait que tous les points de la médiatrice d'un segment sont à égale distance des deux extrémités du segment (très utile lorsqu'on étudie les triangles isocèles).
\begin{lemma}[\cite{ooZYLAooXwWjLa}]        \label{LEMooDPLYooJKZxiM}
    Soient deux points distincts \( x_0,y_0\in \eR^n\) l'ensemble \( H\subset \eR^n\) donné par
    \begin{equation}
        H=\{ x\in \eR^n\tq d(x,x_0)=d(x,y_0) \}.
    \end{equation}
    Alors \( H\) est l'hyperplan orthogonal au vecteur \( v=y_0-x_0\) et \( H\) passe par le milieu du segment \( [x_0,y_0] \).
\end{lemma}

\begin{proof}
    Nous savons que
    \begin{equation}
        d(x,x_0)^2=\langle x-x_0, x-x_0\rangle =\| x \|^2+\| x_0 \|^2-2\langle x, x_0\rangle,
    \end{equation}
    ou encore
    \begin{equation}
        \| x_0 \|^2-\| y_0 \|^2=2\langle x, x_0-y_0\rangle .
    \end{equation}
    En posant \( v=y_0-x_0\) et en considérant la forme linéaire
    \begin{equation}
        \begin{aligned}
            \beta\colon \eR^n&\to \eR \\
            x&\mapsto \langle x, v\rangle ,
        \end{aligned}
    \end{equation}
    Nous avons \( x\in H\) si et seulement si \( \beta(x)=\frac{ 1 }{2}\big( \| y_0 \|^2-\| x_0 \|^2 \big)=\lambda\). En d'autres termes, \( H=\beta^{-1}(\lambda)\). Par la proposition~\ref{PROPooAKJBooMkmsiV} la partie \( H\) est un sous-espace affine. C'est même un translaté de \( \ker(\beta)\), et comme \( \ker(\beta)\) est l'espace vectoriel des vecteurs perpendiculaires à \( v\), nous avons \( \dim(H)=\dim\big( \ker(\beta) \big)=n-1\).

    Le fait que \( H\) contienne le milieu du segment \( [x_0,y_0]\) est par définition.
\end{proof}

Pour le lemme suivant, et pour que la récurrence se passe bien nous disons que l'ensemble vide est un espace vectoriel de dimension \( -1\).
\begin{lemma}[\cite{ooYVHDooLeexeT}]       \label{LEMooJCDRooGAmlwp}
    Soit un espace euclidien \( E\) de dimension \( n\).
    \begin{enumerate}
        \item       \label{ITEMooFYEDooIJZBjP}
            Si \( f\) est une isométrie de \( E\) satisfaisant
            \begin{equation}
                \dim\big( \Fix(f) \big)=n-k
            \end{equation}
            alors \( f\) peut être écrit comme composition de \( k\) réflexions hyperplanes.
        \item       \label{ITEMooJTZVooWvyfDD}
            Une isométrie de \( E\) peut être écrite sous la forme de \( \rang(f-\id)\) réflexions, mais pas moins.
        \item       \label{ITEMooUCZWooSbyPwt}
            Toute isométrie de \( \eR^n\) peut être écrite comme composition de \( n+1\) réflexions.
    \end{enumerate}
\end{lemma}

\begin{proof}
    Les deux parties importantes à démontrer sont les points \ref{ITEMooFYEDooIJZBjP} et la partie «pas moins» de \ref{ITEMooJTZVooWvyfDD}. Le reste sont des reformulations.
        \begin{subproof}
        \item[Pour \ref{ITEMooFYEDooIJZBjP}]

    Nous faisons une récurrence sur \( k\geq 0\).

    Pour l'initialisation, si \( k=0\) alors \( \dim\big( \Fix(f) \big)=n\), c'est-à-dire que \( f\) fixe tout \( \eR^n\), autant dire que \( f\) est l'identité, une composition de zéro réflexions.

    Pour la récurrence, nous supposons que le lemme est démontré jusqu'à \( k\geq 0\). Soit donc \( f\in\Isom(\eR^n)\) tel que
    \begin{equation}
        \dim\big( \Fix(f) \big)=n-(k+1).
    \end{equation}
    Vu que \( k\geq 0\), la dimension de \( \Fix(f)\) est strictement plus petite que \( n\), donc il existe un \( x_0\in \eR^n\) tel que \( f(x_0)\neq x_0\). Nous posons
    \begin{equation}
        H=\{ x\in E\tq d(x,x_0)=d\big( x,f(x_0) \big)  \}.
    \end{equation}
    Par le lemme~\ref{LEMooDPLYooJKZxiM}, ce \( H\) est l'hyperplan orthogonal à \( v=f(x_0)-x_0\) et passant par le milieu du segment \( [x_0,f(x_0)]\).

    Nous posons \( g=\sigma_H\circ f\). Vu que \( g(x_0)=\sigma_H(f(x_0))=x_0\), ce \( x_0\) est un point fixe de \( g\). Le fait que \( \sigma_H\big( f(x_0) \big)=x_0\) est vraiment la définition de l'hyperplan \( H\).

    Nous avons donc
    \begin{equation}
        x_0\in\Fix(g)\setminus\Fix(f).
    \end{equation}
    Mais nous prouvons de plus que \( \Fix(f)\subset\Fix(g)\). En effet si \( y\in Fix(f)\) alors \( y\in H\) parce que
    \begin{equation}
        d(y,x_0)=d\big( f(y),f(x_0) \big)=d\big( y, f(x_0) \big).
    \end{equation}
    Vu que \( y\in H\) nous avons \( y\in \Fix(g)\) parce que
    \begin{equation}
        g(y)=\sigma_H\big( f(y) \big)=\sigma_H(y)=y.
    \end{equation}
    Tout cela pour dire que l'ensemble \( \Fix(g)\) est \emph{strictement} plus grand que \( \Fix(f)\). Et comme ce sont des espaces affines nous pouvons parler de dimension :
    \begin{equation}
        \dim\big( \Fix(g) \big)>\dim\big( \Fix(f) \big).
    \end{equation}
    Par hypothèse de récurrence, l'application \(  g\) peut être écrite comme composition de \( k\) réflexions. Donc l'application
    \begin{equation}
        f=\sigma_H\circ g
    \end{equation}
    est une composition de \( k+1\) réflexions.
        \item[Pour \ref{ITEMooJTZVooWvyfDD}, existence]

            Ce point est une reformulation du point \ref{ITEMooFYEDooIJZBjP}. Le fait est que \( \Fix(f)=\ker(f-\id)\) parce que \( x\in\Fix(f)\) si et seulement si \( f(x)=x\) si et seulement si \( (f-\id)x=0\). Nous utilisons le théorème du rang \ref{ThoGkkffA} à l'endomorphisme \( f-\id\) :
            \begin{equation}
                \dim\big( \Fix(f) \big)=\dim\big( \ker(f-\id) \big)=\dim(E)-\rang(f-\id).
            \end{equation}
            En remplaçant par les valeurs :
            \begin{equation}
                n-k=n-\rang(f-\id).
            \end{equation}
            Or le point \ref{ITEMooFYEDooIJZBjP} donnait \( f\) comme composée de \( n-k\) réflexions. Donc \( f\) est composée de \( \rang(f-\id)\) réflexions.
        \item[Pour \ref{ITEMooJTZVooWvyfDD}, «pas moins»]

            Supposons que \( f=\sigma_1\circ\ldots \circ \sigma_r\) où \( \sigma_i\) est la réflexion de l'hyperplan \( H_i\). Nous devons prouver que \( r\geq \rang(f-\id)\). Nous avons
            \begin{equation}
                \bigcap_{i=1}^rH_i\subset \ker(f-\id).
            \end{equation}
            D'autre part, la proposition \ref{PROPooRCLNooJpIMMl} nous donne \( \dim\bigcap_iH_i\geq n-r\). Donc
            \begin{equation}
                n-r\leq \dim\big( \bigcap_{i=1}^r \big)\leq\dim\big( \ker(f-\id) \big)=n-\rang(f-\id).
            \end{equation}
            Donc \( n-r\leq n-\rang(f-\id)\) ou encore
            \begin{equation}
                r\geq \rang(f-\id).
            \end{equation}

        \item[Pour \ref{ITEMooUCZWooSbyPwt}]
    La première partie de ce théorème n'est rien d'autre que le lemme~\ref{LEMooJCDRooGAmlwp} parce que le pire cas est celui où le fixateur de \( f\) est réduit à l'ensemble vide, et dans ce cas l'application \( f\) est une composition de \( n+1\) réflexions.
        \end{subproof}
\end{proof}

\begin{proposition}     \label{PROPooUSKEooUbNVfs}
    Un élément de \( \SO(3)\) qui fixe deux vecteurs linéairement indépendants est l'identité.
\end{proposition}

\begin{proof}
    Soit un élément \( A\in \SO(3)\) et deux vecteurs linéairement indépendants \( v_1,v_3\in \eR^3\) tels que \( Av_1=v_1\) et \( Av_2=v_2\). Vu que \( v_1\) et \( v_2\) sont linéairement indépendants, le théorème de la base incomplète \ref{ThonmnWKs} nous permet de considérer \( v_3\in \eR^3\) tel que \( \{ v_1,v_2,v_3 \}\) soit une base. Dans cette base, la matrice de \( A\) est de la forme
    \begin{equation}
        A=\begin{pmatrix}
            1    &   0    &   a    \\
            0    &   1    &   b    \\
            0    &   0    &   c
        \end{pmatrix}.
    \end{equation}
    Le déterminant de cette matrice est \( c\). Or \( \det(A)=1\) parce qu'elle est dans \( \SO(3)\). Donc \( c=1\). Le fait que \( A\) soit orthogonale implique que la troisième colonne doit être un vecteur de norme \( 1\). Donc \( a=b=0\).

    Donc \( A=\id\).
\end{proof}

\begin{corollary}       \label{CORooJCURooSRzSFb}
    Tout élément de \( \SO(3)\) peut être écrit comme composée de deux réflexions.
\end{corollary}

\begin{proof}
    Un élément de \( \SO(3)\) est une isométrie de \( \eR^3\) parce que si \( A\in\SO(3)\) alors\footnote{Opérateur orthogonal, définition \ref{DEFooYKCSooURQDoS}.}
    \begin{equation}
        \langle Ax, Ay\rangle =\langle A^*Ax, y\rangle =\langle x, y\rangle .
    \end{equation}
    Donc si le rang de \( A\) est \( k\), alors \( A\) est la composée de \( 3-k\) réflexions par le lemme \ref{LEMooJCDRooGAmlwp}.

    Si \( A=\id\), c'est bon parce que l'identité est la composée de deux réflexions égales. Nous supposons que \( A\) n'est pas l'identité.

    Comme discuté dans l'exemple \ref{EXooIPLOooSNfiWg}, l'opérateur \( A\) possède trois valeurs propres dans \( \eC\) dont une réelle, et deux complexes conjuguées. Nous les notons \( \lambda\in \eR\) et \( \alpha,\bar \alpha\in \eC\). Le déterminant de \( A\), qui vaut \( 1\), est le produit de ces trois valeurs propres, c'est-à-dire \( \lambda| \alpha |^2\). En particulier \( \lambda>0\).

    Si \( v\) est un vecteur propre correspondant à la valeur propre \( \lambda\), nous avons \(  \| v \|= \| Av \|=| \lambda |\| v \|\) parce que \( A\) est une isométrie. Donc \( \lambda=\pm 1\).

    Au final, \( \lambda=1\). Cela signifie que \( A\) laisse au moins un vecteur invariant. Vu que \( A\) n'est pas l'identité, la proposition \ref{PROPooUSKEooUbNVfs} nous indique qu'il n'y a pas d'autres vecteurs de \( \eR^3\) à être fixé par \( A\). Donc \( \dim\big( \Fix(A) \big)=1\) et le lemme \ref{LEMooJCDRooGAmlwp}\ref{ITEMooFYEDooIJZBjP} nous s'écrit avec \( n=3\), \( k=2\) et implique que \( A\) est la composée de deux réflexions.
\end{proof}

\begin{lemma}       \label{LEMooMCVKooKzmlAg}
    Soit un hyperplan \( H\) et un vecteur \( v\) de \( \eR^n\). Nous avons
    \begin{equation}
        \tau_v\circ \sigma_H\circ\tau_v^{-1}=\sigma_{\tau_v(H)}.
    \end{equation}
\end{lemma}

\begin{proof}
    Pour ce faire nous considérons une base adaptée. Les vecteurs \( \{ e_1,\ldots, e_{n-1} \}\) forment une base orthonormée de \( H_0\) et \( e_n\) complète en une base orthonormée de \( \eR^n\). Soit \( H_0\) l'hyperplan parallèle à \( H\) et passant par l'origine; nous avons, pour un certain \( \lambda\in \eR\),
    \begin{equation}
        H=H_0+\lambda e_n
    \end{equation}
    D'un autre côté, le vecteur \( v\) peut être décomposé en \( v=v_1+v_2\) où \( v_1\perp H\) et \( v_2\parallel H\). Alors
    \begin{equation}
        \tau_v(H)=H+v=H+v_2=H_0+\lambda e_n+v_2.
    \end{equation}
    Nous pouvons maintenant utiliser le lemme~\ref{LEMooWYVRooQmWqvM} pour exprimer la transformation \( \sigma_{\tau_v(H)}\) :
    \begin{equation}        \label{EQooNYKFooXprXav}
        \sigma_{\tau_v(H)}(x)=\sigma_{H_0}(x)+ 2\lambda e_n+2v_2
    \end{equation}

    Mais d'autre part,
    \begin{equation}
        (\tau_v\circ \sigma_H\circ\tau_{v}^{-1})(x)=v+\sigma_H(x-v)=v+\sigma_{H_0}(x-v)+2\lambda e_n.
    \end{equation}
    Vue la décomposition de \( v=v_1+v_2\) nous avons \( \sigma_{H_0}(v)=-v_1+v_2\) et donc
    \begin{equation}        \label{EQooGOHEooALPRFB}
        (\tau_v\circ \sigma_H\circ\tau_{v}^{-1})(x)= v+  \sigma_{H_0}(x)+v_1-v_2+2\lambda e_n=\sigma_{H_0}+2v_1+2\lambda e_n.
    \end{equation}
    Les expressions \eqref{EQooNYKFooXprXav} et \eqref{EQooGOHEooALPRFB} coïncident, d'où l'égalité recherchée.
\end{proof}

\begin{theorem}[\cite{ooZYLAooXwWjLa}]      \label{THOooWBIYooCtWoSq}
    Une isométrie de \( (\eR^n,d)\) préserve l'orientation si et seulement si est elle composition d'un nombre pair de réflexions.
\end{theorem}

\begin{proof}
    Nous définissons
    \begin{equation}
        \begin{aligned}
            \epsilon\colon \Isom(\eR^n)&\to \{ \pm 1 \} \\
            \tau_v\circ \alpha&\mapsto \det(\alpha)
        \end{aligned}
    \end{equation}
    où nous nous référons à la décomposition unique d'un élément de \( \Isom(\eR^n)\) sous la forme \( \tau_v\circ \alpha\) avec \( \alpha\in O(n)\) donnée par le théorème~\ref{THOooQJSRooMrqQct}\ref{ITEMooEWSIooNKzRxB}.

    Le noyau de \( \epsilon\) est alors la partie
    \begin{equation}
        \ker(\epsilon)=\eR^n\times_{\AD}\SO(n).
    \end{equation}
    Une isométrie \( f\) préserve l'orientation si et seulement si \( \epsilon(f)=1\). Vu que toutes les isométries sont des compositions de réflexions (première partie), il nous suffit de montrer que \( \epsilon(\epsilon_H)=-1\) pour qu'une isométrie préserve l'orientation si et seulement si elle est composition d'un nombre pair de réflexions.

    Nous commençons par prouver que pour tout vecteur \( v\), \( \epsilon\big( \sigma_H \big)=\epsilon\big( \sigma_{\tau_v(H)} \big)\). Pour cela nous utilisons le lemme~\ref{LEMooMCVKooKzmlAg} et le fait que \( \epsilon\) est un homomorphisme :
    \begin{equation}
        \epsilon(\sigma_{\tau_v(H)})=\epsilon(\tau_v)\epsilon(\sigma_H)\epsilon(\tau_v^{-1})=\epsilon(\sigma_H)
    \end{equation}
    parce que la partie linéaire d'une translation est l'identité (et donc \( \epsilon(\tau_v)=1\) pour tout \( v\)).

    Nous avons donc \( \epsilon(\sigma_H)=\epsilon(\sigma_{H_0})\). En ce qui concerne \( \sigma_{H_0}\), dans la base adaptée la matrice est
    \begin{equation}
        \sigma_{H_0}=\begin{pmatrix}
             1   &       &       &       \\
                &   \ddots    &       &       \\
                &       &   1    &       \\
                &       &       &   -1
         \end{pmatrix},
    \end{equation}
    dont le déterminant est \( -1\).
\end{proof}

Pour en savoir plus sur le groupe des isométries, il faut lire le théorème de Cartan-Dieudonné dans \cite{JGAdTA}.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Groupes finis d'isométries}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{definition}      \label{DEFooCUYLooAlbtzv}
    Si \( X\) est une partie finie de \( \eR^n\), le \defe{barycentre}{barycentre!cas vectoriel} de \( X\) est le point
    \begin{equation}
        B_X=\frac{1}{ | X | }\sum_{x\in X}x
    \end{equation}
    où \( | X |\) est le cardinal de \( X\).
\end{definition}
Cela est à mettre en relation avec la définition dans le cadre affine~\ref{LemtEwnSH}.

\begin{lemma}[\cite{ooZYLAooXwWjLa}]        \label{LEMooSEZYooYceLIb}
    Les applications affines de \( \eR^n\) préservent le barycentre\footnote{Définition \ref{DEFooCUYLooAlbtzv}.} des parties finies.
\end{lemma}

\begin{proof}
    Soit une partie finie \( X\) de \( \eR^n\) et une application affine \( f\in\Aff(\eR^n)\). Nous devons prouver que
    \begin{equation}
        f(B_X)=B_{f(X)}.
    \end{equation}

    Nous savons que toute application affine est une composée de translation et d'une application linéaire : \( f=\tau_v\circ g\) avec \( v\in \eR^n\) et \( g\in \GL(n,\eR)\). Nous vérifions le résultat séparément pour \( \tau_v\) et pour \( g\).

    D'une part,
    \begin{equation}
        B_{\tau_v(X)}=\frac{1}{ | \tau_v(X) | }\sum_{y\in \tau_v(X)}y=\frac{1}{ | X | }\sum_{x\in X}(x+v)=B_x+\frac{1}{ | X | }\sum_{x\in X}v=B_x+v=\tau_v(B_X).
    \end{equation}
    Nous avons utilisé le fait que \( X\) et \( \tau_v(X)\) possèdent le même nombre d'éléments, ainsi que le fait d'avoir une somme de \( | X |\) termes tous égaux à \( v\).

    D'autre part,
    \begin{equation}
        B_{g(X)}=\frac{1}{ | X | }\sum_{x\in X}g(x)=g\big( \frac{1}{ |X | }\sum_{x\in X}x \big)=g(B_X)
    \end{equation}
    où nous avons utilisé la linéarité de \( g\) dans tous ses retranchements.
\end{proof}

\begin{proposition}     \label{PROPooLAEBooWdcBoe}
    Points fixes d'un sous-groupe.
    \begin{enumerate}
        \item
            Soit \( H\) un sous-groupe finie des isométries de \( (\eR^n,d)\). Alors il existe \( v\in \eR^n\) tel que \( f(v)=v\) pour tout \( f\in H\).
        \item
            Si \( H\) est un sous-groupe de \( \Isom(\eR^n,d)\) n'acceptant pas de points fixes, alors il est infini.
    \end{enumerate}
\end{proposition}

\begin{proof}
    Le groupe \( H\) agit sur \( \eR^n\), et si \( x\in \eR^n\) nous pouvons considérer son orbite 
    \begin{equation}
        Hx=\{f(x)\tq f\in H\},
    \end{equation}
    qui est une partie finie de \( \eR^n\). Considérons son barycentre $v=B_{Hx}$. Soit \( f\in H\). Alors  
    \begin{subequations}
        \begin{align}
            f(v)&=f(B_{Hx})\\
            &=B_{f(Hx)}     \label{SUBEQooOQBZooYlIbgN}\\
            &=B_{Hx}        \label{SUBEQooXWEGooSoezYg}\\
            &=v,
        \end{align}
    \end{subequations}
    Justifications:
    \begin{itemize}
        \item Pour \eqref{SUBEQooOQBZooYlIbgN}, c'est le lemme \ref{LEMooSEZYooYceLIb}.
        \item Pour \eqref{SUBEQooXWEGooSoezYg}, c'est le fait que, \( f\in H\) étant donné, l'application \( g\mapsto fg\) est une bijection de \( H\), donc
            \begin{equation}
                f(Hx)=\{(fg)(x)\tq h\in H\}=\{g(x)\tq g\in H\}=Hx.
            \end{equation}
    \end{itemize}
    Bref, \( v\) est fixé par \( H\).

    La seconde affirmation n'est rien d'autre que la contraposée de la première.
\end{proof}

\begin{proposition}     \label{PROPooEUFIooDUIYzi}
    À propos de groupes finis d'isométries.
    \begin{enumerate}
        \item
            Tout sous-groupe fini de \( \Isom(\eR^n)\) est isomorphe à un sous-groupe fini de \( \gO(n)\).
        \item
            Tout sous-groupe fini de \( \Isom^+(\eR^n)\) est isomorphe à un sous-groupe fini de \( \SO(n)\).
    \end{enumerate}
\end{proposition}

\begin{proof}
    Soit \( H\) un sous-groupe fini de \( \Isom(\eR^n)\) et \( v\in \eR^n\) un élément fixé par \( H\) (comme garantit par la proposition~\ref{PROPooLAEBooWdcBoe}). Nous posons
    \begin{equation}
        \begin{aligned}
            \phi\colon H&\to \Isom(\eR^n) \\
            f&\mapsto \tau_v^{-1}\circ f\circ \tau_v.
        \end{aligned}
    \end{equation}

    \begin{subproof}
        \item[\( \phi\) est un homomorphisme]
            Les opération du type \( \phi=\AD(\tau_v)\) sont toujours des homomorphismes.
        \item[\( \phi\) consiste à extraire la partie linéaire]
            Si \( f=\tau_w\circ g\) alors
            \begin{subequations}
                \begin{align}
                    \phi(f)(x)&=(\tau_{-v}\circ\tau_w\circ g\circ\tau_v)(x)\\
                    &=\tau_{w-v}(   g(x)+g(v)  )\\
                    &=g(x)+g(v)-v+w
                \end{align}
            \end{subequations}
            Mais \( g(v)+w=f(v)\) et nous savons que \( f(v)=v\). Donc il ne reste que \( \phi(f)(x)=g(x)\).
        \item[\( \phi\) est injective]
            Si \( f=\tau_w\circ g\) vérifie \( \phi(f)=\id\), il faut en particulier que \( g=\id\). Mais \( H\) est fini et ne peut donc pas contenir de translations non triviales. Donc \( w=0\) et \( f=\id\).
    \end{subproof}
    Donc \( \phi\) est une injection à valeur dans les transformations linéaires de \( \Isom(\eR^n)\). Autrement dit, \( \phi\) est un isomorphisme entre \( H\) et son image, laquelle image est dans \( \gO(n)\).

    En ce qui concerne la seconde partie, si \( f\in\Isom^+(\eR^n)\), alors \( \phi(f)\) y est aussi, tout en étant linéaire. Donc \( \phi(f)\in \SO(n)\).
\end{proof}

L'extraction de la partie linéaire est injective ? Certe c'est prouvé, mais on peut se demander ce qu'il se passe si \( H\) contient deux éléments qui ont la même partie linéaire. Cela n'est pas possible parce si \( f_1=\tau_{w_1}\circ g\) et \( f_2=\tau_{w_2}\circ g\) sont dans \( H\) alors \( f_1f_2^{-1}=\tau_{w_1+w_2}\) est également dans \( H\), ce qui n'est pas possible si \( H\) est fini.
 
%---------------------------------------------------------------------------------------------------------------------------
\subsection{Groupe diédral}
%---------------------------------------------------------------------------------------------------------------------------
\label{subsecHibJId}

\begin{proposition}     \label{PROPooUPPTooZBFvPg}
    Les racines de l'unité dans \( \eC\), c'est-à-dire la partie
    \begin{equation}
        \{  e^{2ik\pi/n},k=0,\ldots, n-1 \},
    \end{equation}
    forment un polynôme régulier.
\end{proposition}
% TODOooVDNMooJFwymI : prouver que les racines de l'unité forment un polygone régulier, PROPooUPPTooZBFvPg

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Définition et générateurs : vue géométrique}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

\begin{definition}  \label{DEFooIWZGooAinSOh}
    Le \defe{groupe diédral}{groupe!diédral} \( D_n\)\nomenclature[R]{\( D_n\)}{groupe diédral} (\( n\geq 3\)) est le groupe des isométries de \( (\eC,d)\) laissant invariant l'ensemble
    \begin{equation}
        \{  e^{2ik\pi/n},k=0,\ldots, n-1 \}
    \end{equation}
    des racines de l'unité.
\end{definition}
\index{groupe!agissant sur un ensemble!diédral}
\index{groupe!en géométrie}
\index{groupe!fini!diédral}
\index{groupe!permutation!diédral}

\begin{normaltext}
    La proposition \ref{PROPooUPPTooZBFvPg} nous permet de dire que le groupe diédral est le groupe des isométries de \( \eR^2\) laissant invariant un polygone régulier à \( n\) côtés.
    C'est un peu pour cela que nous n'avons défini \( D_n\) que pour \( n\geq 3\); et un peu aussi pour une raison technique qui arrivera dans la preuve du lemme \ref{LEMooCUVPooMZKnzo}.
\end{normaltext}

\begin{lemma}       \label{LEMooCUVPooMZKnzo}
    Nous avons
    \begin{equation}
        D_n\subset O(2,\eR).
    \end{equation}
\end{lemma}

\begin{proof}
    Si \( f\in D_n\), alors \( f( e^{2ik\pi/n}) \) doit être l'un des \(  e^{2ik'\pi/n}\), et vu que \( f\) conserve les longueurs dans \( \eC\), nous devons avoir
    \begin{equation}
        1=d(0, e^{2ik\pi/n})=d\big( f(0), e^{2ik'\pi/n} \big).
    \end{equation}
    Donc \( f(0)\) est à l'intersection de tous les cercles de rayon \( 1\) centrés en les \(  e^{2ik\pi/n}\), ce qui montre que \( f(0)=0\) (dès que \( n\geq 3\)). Par conséquent notre étude du groupe diédral ne doit prendre en compte que les isométries vectorielles de \( \eR^2\). En d'autres termes
    \begin{equation}
        D_n\subset O(2,\eR).
    \end{equation}
\end{proof}

\begin{proposition}[\cite{tzHydF}]
    Le groupe \( D_n\) contient un sous-groupe cyclique d'ordre \( 2\) et un sous-groupe cyclique d'ordre \( n\).
\end{proposition}

\begin{proof}
    Nous notons \( s\) la conjugaison complexe\footnote{C'est une réflexion; la réflexion d'axe \( \eR\) dans \( \eC\).}. C'est un élément d'ordre \( 2\) qui est dans \( D_n\) parce que
    \begin{equation}    \label{EqSUshknP}
        s\big(  e^{2ki\pi/n} \big)= e^{2(n-k)i\pi/n}.
    \end{equation}

    De la même façon, la rotations d'angle \(2\pi/n\), que l'on note \( r\), agit sur les racines de l'unité et engendre un le groupe d'ordre \( n\) des rotations d'angle \(2 k\pi/n\).
\end{proof}

\begin{proposition}[\cite{tzHydF}]
    Si \( s\) est la conjugaison complexe et \( r\) la rotation d'angle \( 2\pi/n\), alors \( (sr)^2=\id\).
\end{proposition}

\begin{proof}
    Si \( z^n=1\), alors
    \begin{equation}
        (srsr)z=srs e^{2 i\pi/n}z=sr\big( e^{-2\pi i/n\bar z}\big)=s\bar z=z.
    \end{equation}
\end{proof}

\begin{proposition}[\cite{tzHydF}] \label{PropLDIPoZ}
    Nous notons \( s\) la conjugaison complexe et \( r\) la rotation d'angle \( 2\pi/n\).
    \begin{enumerate}
        \item
            Le groupe diédral \( D_n\) est engendré par \( s\) et \( r\). 
        \item       \label{ITEMooOEBHooULRmZk}
            Tous les éléments de \( D_n\) s'écrivent sous la forme \( r^m\) ou \( s\circ r^m\).
    \end{enumerate}
\end{proposition}
\index{groupe!diédral!générateurs (preuve)}
\index{racine!de l'unité}
\index{géométrie!avec nombres complexes}
\index{géométrie!avec des groupes}
\index{isométrie!de l'espace euclidien \( \eR^2\)}

\begin{proof}
    Nous considérons les points \( A_0=1\) et \( A_k= e^{2ki\pi/n}\) avec \( k\in\{ 1,\ldots, n-1 \}\). Par convention, \( A_n=A_0\). L'action des éléments \( s\) et \( r\) sur ces points est
    \begin{subequations}
        \begin{align}
            r(A_k)&=A_{k+1}\\
            s(A_k)&=A_{n-k}.
        \end{align}
    \end{subequations}
    Cette dernière est l'équation \eqref{EqSUshknP}.

    Soit \( f\in D_n\). Étant donné que c'est une isométrie de \( \eR^2\) avec un point fixe (le point \( 0\)), \( f\) est soit une rotation soit une réflexion.
    %TODO : il faut démontrer ce point et mettre un lien vers ici.

    Supposons pour commencer que un des \( A_k\) est fixé par \( f\). Dans ce cas \( f\) a deux points fixes : \( O\) et \( A_k\) et est donc la réflexion d'axe \( (OA_k)\). Dans ce cas, nous avons \( f=s\circ r^{n-2k}\). En effet
    \begin{equation}
        s\circ r^{n-2k}(A_k)=s(A_{k+n-2k})=s(A_{n-k})=A_k.
    \end{equation}
    Donc \( O\) et \( A_k\) sont deux points fixes de l'isométrie \( f\); donc \( f\) est bien la réflexion sur le bon axe.

    Nous passons à présent au cas où \( f\) ne fixe aucun des \( A_k\).
    \begin{enumerate}
        \item
            Supposons que \( f\) soit une rotation. Si \( f(A_k)=A_m\), alors l'angle de la rotation est
            \begin{equation}
                \frac{ 2(m-k)\pi }{ n },
            \end{equation}
            et donc \( f=r^{m-k}\), qui est de la forme demandée.
        \item
            Supposons à présent que \( f\) soit une réflexion d'axe \( \Delta\). Cette fois, \( \Delta\) ne passe par aucun des points \( A_k\), par contre \( \Delta\) passe par \( 0\). Nous commençons par montrer que \( \Delta\) doit être la médiatrice d'un des côtés \( [A_p,A_{p+1}]\) du polygone. Vu que \( \Delta\) passe par \( O\) et n'est aucune des droites \( (OA_k)\), cette droite passe par l'intérieur d'un des triangles \( OA_pA_{p+1}\) et intersecte donc le côté correspondant.

            Notre tâche est de montrer que \( \Delta\) coupe \( [A_p,A_{p+1}]\) en son milieu. Dans ce cas, \( \Delta\) sera automatiquement perpendiculaire parce que le triangle \( OA_pA_{p+1}\) est isocèle en \( O\). Nommons \( l\) la longueur des côtés du polygone, \( P=\Delta\cap[A_p,A_{p+1}]\), \( x=d(A_p,P)\) et \( \delta=d(A_p,\Delta)\). Vu que \( f\) est la symétrie d'axe \( \Delta\), nous avons aussi \( d\big( f(A_p),\Delta \big)=\delta\) et \( d\big( A_p,f(A_p) \big)=2\delta\). D'autre part, par la définition de la distance, \( \delta<x\). Si \( x<\frac{ l }{2}\), alors \( \delta<\frac{ \delta }{2}\) et donc \( d\big( A_p,f(A_p) \big)<l\). Or cela est impossible parce que le polygone ne possède aucun sommet à distance plus courte que \( l\) de \( A_p\).

            De la même manière si \( x>\frac{ l }{2}\), nous raisonnons avec \( A_{p+1}\) pour obtenir une contradiction. Nous en concluons que la seule possibilité est \( x=\frac{ l }{2}\), et donc \( f(A_p)=A_{p+1}\). Montrons alors que \( f=s\circ r^{n-2p-1}\). Il faut montrer que c'est une réflexion qui envoie \( A_p\) sur \( A_{p+1}\). D'abord c'est une réflexion parce que
            \begin{equation}
                \det(sr^{n-2p-1})=\det(s)\det(r^{n-2p-1})=-1
            \end{equation}
            parce que \( \det(s)=-1\) alors que \( \det(r^k)=1\) parce que \( r\) est une rotation dans \( \SO(2)\). Ensuite nous avons
            \begin{equation}
                s\circ r^{n-2p-1}(A_p)=s(A_{p+n-2p-1})=s(A_{n-p-1})=A_{n-(n-p-1)}=A_{p+1}.
            \end{equation}

            Donc \( s\circ r^{n-2p-1}\) est bien une réflexion qui envoie \( A_p\) sur \( A_{p+1}\).

    \end{enumerate}
\end{proof}

\begin{corollary}   \label{CorWYITsWW}
La liste des éléments de \( D_n\) est
\begin{equation}
    D_n=\{ 1,r,\ldots, r^{n-1},s,sr,\ldots, sr^{n-1} \}
\end{equation}
et \( | D_n |=2n\).
\end{corollary}

\begin{proof}
    Nous savons par la proposition~\ref{PropLDIPoZ} que tous les élément de \( D_n\) s'écrivent sous la forme \( r^k\) ou \( sr^k\). Vu que \( r\) est d'ordre \( n\), il ne faut considérer que \( k\in\{ 1,\ldots, n-1 \}\). Les éléments \( 1\), \( r\),\ldots, \( r^{n-1}\) sont tous différents, et sont (pour des raisons de déterminant) tous différents des \( sr^k\). Les isométries \( sr^k\) sont toutes différentes entre elles pour essentiellement la même raison :
    \begin{equation}
        sr^k(A_p)=s(A_{p+k})=A_{n-p+k}
    \end{equation}
    donc si \( k\neq k'\), \( sr^k(A_p)\neq sr^{k'}(A_p)\). La liste des éléments de \( D_n\) est donc
    \begin{equation}
        D_n=\{ 1,r,\ldots, r^{n-1},s,sr,\ldots, sr^{n-1} \}
    \end{equation}
    et donc \( | D_n |=2n\).
\end{proof}

\begin{example}     \label{EXooHNYYooUDsKnm}
    Nous considérons le carré \( ABCD\) dans \( \eR^2\) et nous cherchons les isométries de \( \eR^2\) qui laissent le carré invariant. Nous nommons les points comme sur la figure~\ref{LabelFigIsomCarre}. La symétrie d'axe vertical est nommée \( s\) et la rotation de \( 90\) degrés est notée \( r\).
    \newcommand{\CaptionFigIsomCarre}{Le carré dont nous étudions le groupe diédral.}
    \input{auto/pictures_tex/Fig_IsomCarre.pstricks}

    Il est facile de vérifier que toutes les symétries axiales peuvent être écrites sous la forme \( r^is\). De plus le groupe engendré par \( s\) agit sur le groupe engendré par \( r\) parce que
    \begin{equation}
        (srs^{-1})(A,B,C,D)=sr(B,A,D,C)=s(A,D,C,B)=(B,C,D,A),
    \end{equation}
    c'est-à-dire \( srs^{-1}=r^{-1}\). Nous sommes alors dans le cadre du corolaire~\ref{CoroGohOZ} et nous pouvons écrire que
    \begin{equation}
        D_4=\gr(r)\times_{\sigma}\gr(s).
    \end{equation}
\end{example}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Table de multiplication}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

La proposition \ref{PropLDIPoZ} nous indique que tous les éléments de \( D_n\) s'écrivent sous la forme \( s^{\epsilon}\circ r^m\) avec \( \epsilon\in\{ 0,1 \}\). Nous allons maintenant écrire la table de multiplication pour de telles transformations de \( \eC\).

\begin{lemma}       \label{LEMooBNJFooAbhsUa}
    Si \( R\) est une rotation autour de \( 0\) (dans \( \eC\)), et si \( s\) est la conjugaison complexe, alors
    \begin{equation}
        rs=sr^{-1}
    \end{equation}
\end{lemma}

\begin{proof}
    Il s'agit seulement d'un calcul en écrivant \( R\) comme la multiplication par \(  e^{i\alpha}\). Nous avons
    \begin{equation}
        (Rs)z= e^{i\alpha}\bar z=s\big(  e^{-i\alpha}z \big)=sR^{-1}z.
    \end{equation}
\end{proof}

\begin{proposition}     \label{PROPooPYDLooLgiUjk}
    Si \( \epsilon_1,\epsilon_2\in\{ 0,1 \}\) et si \( k,l\in \eZ\) nous avons
    \begin{equation}
        (s^{\epsilon_1}r^k)(s^{\epsilon_2}r^l)=s^{\epsilon_1+\epsilon_2}r^{l+(-1)^{\epsilon_1}k}.
    \end{equation}
\end{proposition}

\begin{proof}
    Si \( \epsilon_2=1\) alors nous utilisons le lemme \ref{LEMooBNJFooAbhsUa} pour trouver
    \begin{equation}
        (s^{\epsilon_1}r^k)(s^{\epsilon_2}r^l)=s^{\epsilon_1}(r^ks^{\epsilon_2})r^l=s^{\epsilon_1}s^{\epsilon_2}r^{-k}r^l.
    \end{equation}
    La proposition est déjà prouvée dans ce cas.

    Passons à \( \epsilon_2=0\). Dans ce cas nous avons
    \begin{equation}
        (s^{\epsilon_1}r^k)(s^{\epsilon_2}r^l)=s^{\epsilon_1}r^{k+l},
    \end{equation}
    et c'est bon.
\end{proof}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Générateurs : vue abstraite}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

\begin{normaltext}      \label{NORMooCCUEooRRENed}
    Nous allons montrer que \( D_n\) peut être décrit de façon abstraite en ne parlant que de ses générateurs. Nous considérons un groupe \( G\) engendré par des éléments \( a\) et \( b\) tels que
    \begin{enumerate}
        \item
            \( a\) est d'ordre \( 2\),
        \item
            \( b\) est d'ordre \( n\) avec \( n\geq 3\),
        \item
            \( abab=e\).
    \end{enumerate}
    Nous allons prouver que ce groupe doit avoir la même liste d'éléments que celle du corolaire~\ref{CorWYITsWW}.
\end{normaltext}

\begin{proposition}[\cite{tzHydF}]
    Le groupe \( G\) n'est pas abélien.
\end{proposition}

\begin{proof}
    Nous savons que \( abab=e\), donc \( abab^{-1}=b^{-2}\), mais \( b^{-2}\neq e\) parce que \( b\) est d'ordre \( n>2\). Donc \( abab^{-1}\neq e\). En manipulant un peu :
    \begin{equation}
        e\neq abab^{-1}=(ab)(ba^{-1})^{-1}=(ab)(ba)^{-1}
    \end{equation}
    parce que \( a^{-1}=a\). Donc \( ab\neq ba\).
\end{proof}

\begin{lemma}[\cite{tzHydF}]        \label{LemKKXdqdL}
    Pour tout \( k\) entre \( 1\) et \( n-1\) nous avons
    \begin{equation}
        \AD(a)b^k=ab^ka^{-1}=ab^ka=b^{-k}.
    \end{equation}
\end{lemma}

\begin{proof}
    Nous faisons la démonstration par récurrence. D'abord pour \( k=1\), nous devons avoir \( aba=b^{-1}\), ce qui est correct parce que par construction de \( G\) nous avons \( abab=e\). Ensuite nous supposons que le lemme tient pour \( k\) et nous regardons ce qu'il se passe avec \( k+1\) :
    \begin{equation}
            ab^{k+1}ba=ab^kba=\underbrace{ab^ka}_{b^{-k}}\underbrace{aba}_{b^{-1}}=b^{-k}b^{-1}=b^{-(k+1)}.
    \end{equation}
\end{proof}

\begin{proposition}     \label{PROPooVQARooWuKHMZ}
    L'élément \( a\) n'est pas une puissance de \( b\).
\end{proposition}

\begin{proof}
    Supposons le contraire : \( a=b^k\). Dans ce cas nous aurions
    \begin{equation}
        e=(ab)(ab)=b^{k+1}b^{k+1}=b^{2k+2}=b^{2k}b^2=a^2b^2=b^2,
    \end{equation}
    ce qui signifierait que \( b\) est d'ordre \( 2\), ce qui est exclu par construction.
\end{proof}

\begin{proposition}[\cite{tzHydF}]      \label{PROPooEPVGooQjHRJp}
    La liste des éléments de \( G\) est donnée par
    \begin{equation}
        G=\{ 1,b,\cdots,b^{n-1},a,ab,\ldots, ab^{n-1} \}=\{ a^{\epsilon}b^k\}_{\substack{\epsilon=0,1\\k=0,\ldots, n-1}}
    \end{equation}
    Les éléments de ces listes sont distincts.
\end{proposition}

\begin{proof}
    Étant donné que \( a\) n'est pas une puissance de \( b\), les éléments \( 1\), \( a\), \( b\),\ldots, \( b^{n-1}\) sont distincts. De plus si \( k\) et \( m=k+p\) sont deux éléments distincts de \( \{ 1,\ldots, n-1 \}\), nous avons \( ab^k\neq ab^m\) parce que si \( ab^k=ab^{k+p}\), alors \( a=ab^p\) avec \( p<n\), ce qui est impossible. Pour la même raison, \( ab^k\neq e\), et \( ab^k\neq b^m\).

    Au final les éléments \( 1,a,b,\ldots, b^{n-1},ab,\ldots, ab^{n-1}\) sont tous différents. Nous devons encore voir qu'il n'y en a pas d'autres.

    Par définition le groupe \( G\) est engendré par \( a\) et \( b\), donc tout élément \( x\in G\) s'écrit $x=a^{m_1}b^{k_1}\ldots a^{m_r}b^{k_r}$ pour un certain \( r\) et avec pour tout \( i\), \( k_i\in\{ 1,\ldots, n-1 \}\) (sauf \( k_r\) qui peut être égal à zéro) et \( m_i=1\), sauf \( m_1\) qui peut être égal à zéro. Donc
    \begin{equation}
        x=a^mb^{k_1}ab^{k_2}a\ldots b^{k_{r-1}}ab^{k_r}
    \end{equation}
    où \( m\) et \( k_r\) peuvent éventuellement être zéro. En utilisant le lemme~\ref{LemKKXdqdL} sous la forme \( b^{k_i}a=ab^{-k_i}\), quitte à changer les valeurs des exposants, nous pouvons passer tous les \( a \) à gauche et tous les \( b\) à droite pour finir sous la forme \( x=a^kb^m\).

    Donc non, il n'existe pas d'autres éléments dans \( G\) que ceux déjà listés.
\end{proof}

\begin{lemma}[\cite{MonCerveau}]        \label{LemooNFRIooPWuikH}
    Tout élément de \( G\) s'écrit de façon unique sous la forme \( a^{\epsilon}b^k\) ou \( b^ka^{\epsilon}\) avec \( \epsilon=0,1\) et \( k=0,\ldots, n-1\).
\end{lemma}

\begin{proof}
    Nous commençons par la forme \( a^{\epsilon}b^k\). L'existence est la proposition~\ref{PROPooEPVGooQjHRJp}. Pour l'unicité nous supposons \( a^{\epsilon}b^k=a^{\sigma}b^l\) et nous décomposons en \( 4\).
    \begin{subproof}
        \item[\( \epsilon=0\), \( \sigma=0\)]
            Alors \( b^k=b^l\). Mais \( b\) étant d'ordre \( n\) et \( k,l\) étant égaux au maximum à \( n-1\), cette égalité implique \( k=l\).
        \item[\( \epsilon=0\), \( \sigma=1\)]
            Alors \( b^k=ab^l\), ce qui donne \( a=b^{k-l}\), ce qui est interdit par la proposition~\ref{PROPooVQARooWuKHMZ}.
        \item[\( \epsilon=1\), \( \sigma=0\)]
            Même problème.
        \item[\( \epsilon=1\), \( \sigma=1\)]
            Encore une fois \( b^k=b^l\) implique \( k=l\).
    \end{subproof}
    En ce qui concerne la forme \( b^ka^{\epsilon}\), l'existence est à montrer. Soit l'élément \( g=a^{\epsilon}b^k\) et cherchons à le mettre sous la forme \( b^la^{\sigma}\). Si \( \epsilon=0\) c'est évident. Sinon \( \epsilon=1\) et nous avons par le lemme~\ref{LemKKXdqdL}
    \begin{equation}
        ab^k=b^{-k}a^{-1}=b^{-k}b^na=b^{-k}a.
    \end{equation}
    En ce qui concerne l'unicité, nous refaisons \( 4\) cas pour \( b^ka^{\epsilon}=b^la^{\sigma}\) comme précédemment et ils se traitement exactement comme précédemment.
\end{proof}

\begin{theorem}     \label{THOooYITHooTNTBuG}
    Les groupes \( G\) et \( D_n\) sont isomorphes.
\end{theorem}

\begin{proof}
        Nous utilisons l'application
    \begin{equation}
        \begin{aligned}
            \psi\colon G&\to D_n \\
            a^kb^m&\mapsto s^kr^m.
        \end{aligned}
    \end{equation}
    C'est évidemment bien défini et bijectif, mais c'est également un homomorphisme parce que si nous calculons \( \psi\) sur un produit, nous devons comparer
    \begin{equation}        \label{EqBULPilp}
        \psi\big( a^{k_1}b^{m_1}a^{k_2}b^{m_2} \big)
    \end{equation}
    avec
    \begin{equation}        \label{EqIVEIphI}
        \psi\big( a^{k_1}b^{m_1}\big)\psi\big(a^{k_2}b^{m_2} \big)= s^{k_1}r^{m_1}s^{k_2}r^{m_2}.
    \end{equation}
    Vu que \( D_n\) et \( G\) ont les mêmes propriétés qui permettent de permuter \( a\) et \( b\) ou \( s\) et \( r\), l'expression à l'intérieur du \( \psi\) dans \eqref{EqBULPilp} se simplifie en \( a^kb^m\) avec les même \( k\) et \( n\) que l'expression à droite dans \eqref{EqIVEIphI} ne se simplifie en \( s^kr^m\).
\end{proof}

\begin{corollary}
    Toutes les propriétés démontrées pour \( G\) sont vraies pour \( D_n\). En particulier, avec quelques redites :
    \begin{enumerate}
        \item
            Le groupe \( D_n\) peut être défini comme étant le groupe engendré par un élément \( s\) d'ordre \( 2\) et un élément \( r\) d'ordre \( n-1\) assujettis à la relation \( srsr=e\).
        \item
            Le groupe \( D_n\) n'est pas abélien.
        \item
            Pour tout \( k\in\{ 1,\ldots, n-1 \}\) nous avons \( sr^ks=r^{-k}\).
        \item
            L'élément \( s\) ne peut pas être obtenu comme une puissance de \( r\).
        \item
            La liste des éléments de \( D_n\) est
            \begin{equation}
                D_n=\{ 1,r,\ldots, r^{n-1},s,sr,\ldots, sr^{n-1} \}
            \end{equation}
        \item
            Le groupe diédral \( D_n\) est d'ordre \( 2n\).
    \end{enumerate}
\end{corollary}

\begin{proposition}
    En posant \( C_n=\{ r^k \}_{k=0,\ldots, n-1}\) et \( C_2=\{ a^{\epsilon} \}_{\epsilon=0,1}\), nous pouvons exprimer \( D_n\) comme le produit semi-direct
    \begin{equation}
        D_n=C_n\times_{\rho}C_2
    \end{equation}
    où \( \rho\) désigne l'action adjointe.
\end{proposition}

\begin{proof}
    L'isomorphisme est :
    \begin{equation}
        \begin{aligned}
            \psi\colon C_n\times_{\rho}C_2&\to D_n \\
            (b^k,a^{\epsilon})&\mapsto b^ka^{\epsilon}.
        \end{aligned}
    \end{equation}
    \begin{subproof}
        \item[Action adjointe]
            L'application \( \rho_{a^{\epsilon}}=\AD(a^{\epsilon})\) est toujours un homomorphisme. Vu que \( a^{\epsilon}\) est soit \( e\) soit \( a\), nous allons nous restreindre à \( a\) et oublier l'exposant \( \epsilon\). Il faut montrer que\( \AD(a)\in\Aut(C_n)\). En utilisant le lemme~\ref{LemKKXdqdL},
            \begin{equation}
                \AD(a)b^k=ab^ka^{-1}=b^{-k}=b^{n-k}.
            \end{equation}
            L'application \( \AD(a)\colon C_n\to C_n\) est donc bijective et homomorphique. Ergo isomorphisme.
        \item[Injectif]
            Si \( \psi(b^k,a^{\epsilon})=\psi(b^l,a^{\sigma})\), alors par unicité du lemme~\ref{LemooNFRIooPWuikH} nous avons \( k=l\) et \( \epsilon=\sigma\).
        \item[Surjectif]
            Par la partie «existence»  du lemme~\ref{LemooNFRIooPWuikH}.
        \item[Homomorphisme]
            Lorqu'on prend deux sous-groupes d'un même groupe (ici le groupe des isométrique de \( \eR^2\)), et que l'on tente de faire un produit demi-direct en utilisant l'action adjointe, nous avons toujours un homomorphisme. Dans notre cas, le calcul est :
            \begin{equation}
                \psi\big( (b^k,a^{\epsilon})(b^l,a^{\sigma}) \big)=b^k\rho_{a^{\epsilon}}(b^l)a^{\epsilon+\sigma}=b^ka^{\epsilon}b^la^{-\epsilon}a^{\epsilon+\sigma}=b^ka^{\epsilon}b^la^{\sigma}=\psi(b^k,a^{\epsilon})\psi(b^l,a^{\sigma}).
            \end{equation}
    \end{subproof}
\end{proof}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Classes de conjugaison}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\label{subsubsecZQnBcgo}

Pour les classes de conjugaison du groupe diédral nous suivons \cite{HRIMAJJ}.

D'abord pour des raisons de déterminants\footnote{Vous notez qu'ici nous utilisons un argument qui utilise la définition de \( D_n\) comme isométries de \( \eR^2\). Si nous avions voulu à tout prix nous limiter à la définition «abstraite» en termes de générateurs, il aurait fallu trouver autre chose.}, les classes des éléments de la forme \( r^k\) et de la forme \( sr^k\) ne se mélangent pas. Nous notons \( C(x)\) la classe de conjugaison de \( x\), et \( y\cdot x=yxy^{-1}\).

Les relations que nous allons utiliser sont
\begin{subequations}
    \begin{align}
        sr^ks=r^{-k}\\
        rs=sr^{-1}=sr^{n-1}.
    \end{align}
\end{subequations}

La classe de conjugaison qui ne rate jamais est bien entendu \( C(1)={1}\). Nous commençons les vraies festivités \( C(r^{m})\). D'abord \( r^k\cdot r^m=r^m\), ensuite
\begin{equation}
    (sr^k)\cdot r^m=sr^kr^mr^{-k}s^{-1}=sr^ms^{-1}=r^{-m}.
\end{equation}
Donc
\begin{equation}    \label{EqVFfFxgi}
    C(r^m)=\{ r^m,r^{-m} \}.
\end{equation}
À ce niveau il faut faire deux remarques. D'abord si \( m>\frac{ n }{2}\), alors \( C(r^m)\) est la classe de \( C^{n-m}\) avec \( n-m<\frac{ n }{2}\). Donc les classes que nous avons trouvées sont uniquement à lister avec \( m<\frac{ n }{2}\). Ensuite si \( m=\frac{ n }{2}\) alors \( r^m=r^{-m}\) et la classe est un singleton. Cela n'arrive que si \( n\) est pair.

Nous passons ensuite à \( C(s)\). Nous avons
\begin{equation}
    r^k\cdot s=r^ksr^{-k}=ssr^ksr^{-k}=sr^{-k}r^{-k}=sr^{n-2k},
\end{equation}
et
\begin{equation}
    (sr^k)\cdot s=\underbrace{sr^ks}_{r^{-k}}r^{-k}s^{-1}=r^{-2k}s=r^{n-2k}s=sr^{(n-1)(n-2k)}=sr^{n^2-2kn-n+2k}=sr^{2k}.
\end{equation}
donc
\begin{equation}
    C(s)=\{ sr^{n-2k},sr^{2k} \}_{k=0,\ldots, n-1}.
\end{equation}
Ici aussi l'écriture n'est pas optimale : peut-être que pour certains \( k\) il y a des doublons. Nous reportons l'écriture exacte à la discussion plus bas qui distinguera \( n\) pair de \( n\) impair. Notons juste que si \( n\) est pair, l'élément \( sr\) n'est pas dans la classe \( C(s)\).

Nous en faisons donc à présent le calcul en gardant en tête le fait qu'il n'a de sens que si \( n\) est pair. D'abord
\begin{equation}
    s\cdot (sr)=ssrs=rs=sr^{n-1}.
\end{equation}
Ensuite
\begin{equation}
    (sr^k)\cdot (sr)=sr^ksrr^{-k}s=r^{-2k+1}s=sr^{2k-1}.
\end{equation}
Avec \( k=\frac{ n }{2}\), cela rend \( s\cdot (sr)\), donc pas besoin de le recopier. Nous avons
\begin{equation}
    C(sr)=\{ sr^{2k-1} \}_{k=1,\ldots, n-1}.
\end{equation}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Le compte pour $ n$ pair}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\label{SubsubsecROVmHuM}

Si \( n\) est pair, nous avons les classes
\begin{subequations}
    \begin{align}
        C(1)&=\{ 1 \}       &&& 1\text{ élément}\\
        C(r^m)&=\{ r^m,r^{m-1} \}&\text{ pour }&0<m<\frac{ n }{2}   & \frac{ n }{2}-1\text{ fois } 2\text{ éléments}\\
        C(r^{n/2})&=\{ r^{n/2} \}   &&&  1\text{ élément}\\
        C(s)&=\{ sr^{2k} \}_{k=0,\ldots, \frac{ n }{2}-1} &&&  \frac{ n }{2}\text{ éléments}\\
        C(sr)&=\{ sr^{2k+1} \}_{k=0,\ldots, \frac{ n }{2}-1} &&&  \frac{ n }{2}\text{ éléments}.
    \end{align}
\end{subequations}
Au total nous avons bien listé \( 2n\) éléments comme il se doit, dans \(  \frac{ n }{2}+3\) classes différentes.

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Le compte pour $ n$ impair}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\label{GJIzDEP}

Si \( n\) est impair, nous avons les classes
\begin{subequations}
    \begin{align}
        C(1)&=\{ 1 \}       &&& 1\text{ élément}\\
        C(r^m)&=\{ r^m,r^{m-1} \}&\text{ pour }&0<m<\frac{ n-1 }{2}   & \frac{ n-1 }{2}\text{ fois } 2\text{ éléments}\\
        C(s)&=\{ sr^k \}_{k=0,\ldots, n-1} &&&  n\text{ éléments}
    \end{align}
\end{subequations}
Au total nous avons bien listé \( 2n\) éléments comme il se doit, dans \(  \frac{ n+3 }{2}\) classes différentes.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Applications : du dénombrement}
%---------------------------------------------------------------------------------------------------------------------------

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Le jeu de la roulette}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\label{pTqJLY}
\index{groupe!fini}
\index{groupe!de permutations}
\index{groupe!et géométrie}
\index{combinatoire}
\index{dénombrement}

Soit une roulette à \( n\) secteurs que nous voulons colorier en \( q\) couleurs\cite{HEBOFl}. Nous voulons savoir le nombre de possibilités à rotations près. Soit d'abord \( E\) l'ensemble des coloriages possibles sans contraintes; il y a naturellement \( q^n\) possibilités. Sur l'ensemble \( E\), le groupe cyclique \( G\) des rotations d'angle \( 2\pi/n\) agit. Deux coloriages étant identiques si ils sont reliés par une rotation, la réponse à notre problème est donné par le nombre d'orbites de l'action de \( G\) sur \( E\) qui sera donnée par la formule du théorème de Burnside~\ref{THOooEFDMooDfosOw}.

Nous devons calculer \( \Card\big( \Fix(g) \big)\) pour tout \( g\in G\). Soit \( g\), un élément d'ordre \( d\) dans \( G\). Si \( g\) agit sur la roulette, chaque secteur a une orbite contenant \( d\) éléments. Autrement dit, \( g\) divise la roulette en \( n/d\) secteurs. Un élément de \( E\) appartenant à \( \Fix(g)\) doit colorier ces \( n/d\) secteurs de façon uniforme; il y a \( q^{n/d}\) possibilités.

Il reste à déterminer le nombre d'éléments d'ordre \( d\) dans \( G\). Un élément de \( G\) est donné par un nombre complexe de la forme \(  e^{2ik\pi/n}\). Les éléments d'ordre \( d\) sont les racines primitives\footnote{Une racine non primitive \( 8\)ième de l'unité est par exemple \( i\). Certes \( i^8=1\), mais \( i^4=1\) aussi. Le nombre \( i\) est d'ordre \( 4\).} \( d\)ièmes de l'unité. Nous savons que --par définition-- il y a \( \varphi(d)\) telles racines primitives de l'unité. Bref il y a \( \varphi(d)\) éléments d'ordre \( d\) dans \( G\).

La formule de Burnside nous donne maintenant le nombre d'orbites :
\begin{equation}
    \frac{1}{ n }\sum_{d|n}\varphi(d)q^{n/d}.
\end{equation}
Cela est le nombre de coloriage possibles de la roulette à \( n\) secteurs avec \( q\) couleurs.

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{L'affaire du collier}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\label{siOQlG}

Nous avons maintenant des perles de \( q\) couleurs différentes et nous voulons en faire un collier à \( n\) perles. Cette fois non seulement les rotations donnent des colliers équivalents, mais en outre les symétries axiales (il est possible de retourner un collier, mais pas une roulette). Le groupe agissant sur \( E\) est maintenant le groupe diédral\footnote{Définition~\ref{DEFooIWZGooAinSOh}.}\index{diédral}\index{groupe!diédral} \( D_n\) conservant un polygone a \( n\) sommets.

Nous devons séparer le cas \( n\) impair du cas \( n\) pair.

Si \( n\) est impair, alors les axes de symétries passent par un sommet par le milieu du côté opposé. Le groupe \( D_n\) contient \( n\) symétries axiales. Nous avons donc maintenant
\begin{equation}
    | G |=2n.
\end{equation}
Nous écrivons la formule de Burnside
\begin{equation}
    \Card(\Omega)=\frac{1}{ 2n }\sum_{g\in G}\Card\big( \Fix(g) \big).
\end{equation}
Si \( g\) est une rotation, le travail est déjà fait. Si \( g\) est une symétrie, nous avons le choix de la couleur du sommet par lequel passe l'axe et le choix de la couleur des \( (n-1)/2\) paires de sommets. Cela fait
\begin{equation}
    qq^{(n-1)/2}=q^{\frac{ n+1 }{2}}
\end{equation}
possibilités. Nous avons donc
\begin{equation}
    \Card(\Omega)=\frac{1}{ 2n }\left( \sum_{d|n}q^{n/d}\varphi(d)+nq^{\frac{ n+1 }{2}} \right).
\end{equation}

Si \( n\) est pair, le choses se compliquent un tout petit peu. En plus de symétries axiales passant par un sommet et le milieu du côté opposé, il y a les axes passant par deux sommets opposés. Pour colorier un collier en tenant compte d'une telle symétrie, nous pouvons choisir la couleur des deux perles par lesquelles passe l'axe ainsi que la couleur des \( (n-2)/2\) paires de perles. Cela fait en tout
\begin{equation}
    q^2q^{\frac{ n-2 }{2}}=q^{\frac{ n+2 }{2}}.
\end{equation}
Le groupe \( G\) contient \( n/2\) tels axes.

Notons que cette fois \( G\) ne contient plus que \( n/2\) symétries passant par un sommet et un côté. L'ordre de $G$ est donc encore \( 2n\). La formule de Burnside donne
\begin{equation}
    \Card(\Omega)=\frac{1}{ 2n }\left( \sum_{d\divides n}\varphi(d)q^{n/d}+\frac{ n }{2}q^{(n+2)/2}+\frac{ n }{2}q^{n/2} \right).
\end{equation}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Points fixés par une affinité}
%---------------------------------------------------------------------------------------------------------------------------

\begin{lemma}[\cite{JGAdTA}]        \label{LEMooGUEGooTUXRsQ}
    Si \( n\geq 3\), alors toute droite est intersection de deux plans non isotropes.
\end{lemma}

\begin{proposition}[\cite{ooZYLAooXwWjLa}]      \label{PROPooVEEUooJQmmkN}
    Si une isométrie de \( \eR^n\) fixe un ensemble \( F\) de points, alors elle fixe l'espace affine engendrée par \( F\).
\end{proposition}

\begin{proof}
    Soit \( f\in \Isom(\eR^n)\) fixant \( F\). Par le théorème~\ref{ThoDsFErq}, c'est une application affine et l'ensemble \( \Fix(f)\) des points fixés par \( f\) est un sous-espace affine de \( \eR^n\), grâce à la proposition~\ref{PROPooYRCJooIcmUVI}.

    Donc \( \Fix(f)\) est un espace affine contenant \( F\). Vu que l'espace affine engendré par \( F\) est l'intersection de tous les espaces affines contenant \( F\), il est en particulier contenu dans \( \Fix(f)\).
\end{proof}

\begin{corollary}       \label{CORooZHZZooDgTzsW}
    Si \( f\) et \( g\) sont des isométries de \( \eR^n\) qui coïncident sur \( F\), alors elles coïncident sur l'espace affine engendré par \( F\).
\end{corollary}

\begin{proof}
    Nous considérons \( h=g^{-1}\circ f\) qui est une isométrie de \( \eR^n\) fixant \( F\). Elle fixe donc, par la proposition~\ref{PROPooVEEUooJQmmkN}, l'espace affine engendré par $F$. Or tout point fixé par \( h\) est un point sur lequel \( g\) et \( f\) coïncident.
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Classification des isométries dans \( \eR^2\)}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Réflexions}
%---------------------------------------------------------------------------------------------------------------------------

Soit un espace vectoriel \( E\) de dimension \( 2\) muni d'un produit scalaire\footnote{Définition~\ref{DefVJIeTFj}.}. Cela pourrait très bien être \( \eR^2\), mais nous allons nous efforcer de l'appeler \( E\) pour rester un peu général.

\begin{lemmaDef}[Caractérisation des réflexions]        \label{DEFooLJKDooUaamen}
    Soit une droite \( \ell\) de \( \eR^2\). Il existe une unique application \( f\colon \eR^2\to \eR^2\) telle que
    \begin{enumerate}
        \item
            \( f(x)=x\) pour tout \( x\in \ell\).
        \item
            \( f\) échange les côtés de \( \ell\).
        \item
            \( f\) laisse invariants les droites perpendiculaires à \( \ell\) et les cercles dont le centre est sur \( \ell\).
    \end{enumerate}
    Cette application est la \defe{réflexion}{réflexion!dans \( \eR^2\)} d'axe \( \ell\).
\end{lemmaDef}

\begin{proof}
    Soit \( x\) hors de \( \ell\) et \( p\) la droite perpendiculaire à \( \ell\) et passant par \( x\). Nous avons \( f(x)\in p\). En nommant \( P\) l'intersection entre \( \ell\) et \( p\), nous considérons le cercle \( S(P,\| Px \|)\) qui est un cercle dont le centre est sur \( \ell\). Il contient \( x\) et donc \( f(x)\in S(P,\| Px \|)\).

    Donc \( f(x)\in p\cap S(P,\| Px \|)\). L'intersection entre un cercle et une droite contient de façon générique deux points. L'un est \( x\), mais \( f(x)=x\) n'est pas possible parce que \( x\) est hors de \( \ell\) et \( f\) doit inverser les côtés de \( \ell\). Donc \( f(x)\) est l'autre.

    Cela prouve l'unicité. En ce qui concerne l'existence, il suffit de noter que la réflexion \( \sigma_{\ell}\) satisfait les contraintes.
\end{proof}

\begin{lemma}       \label{LEMooZSDRooUkNYer}
    Soit une droite \( \ell\) est \( A\in E\). Alors
    \begin{equation}        \label{EQooVUQDooKuwszl}
        \sigma_{\ell}(A)=2\pr_{\ell}(A)-A
    \end{equation}
    où \( \pr_{\ell}\) est l'opération de projection orthogonale sur la droite \( \ell\).
\end{lemma}

\begin{proof}
    Nous posons \( f(X)=2\pr_{\ell}(X)-X\) et nous allons montrer que \( f=\sigma_{\ell}\) en vérifiant les conditions de la définition~\ref{DEFooLJKDooUaamen}.
    % Il faut laisser le saut de ligne ici.
    Nous nous gardons bien de faire un raisonnement du type «nous allons montrer que \( f\) et \( \sigma_{\ell}\) coïncident sur deux points, et sont donc égales par le corolaire~\ref{CORooZHZZooDgTzsW}» parce que nous ne savons pas encore que \( \sigma_{\ell}\) est une application affine, ni même que c'est une isométrie.

    Si \( X\in\ell\) alors \( \pr_{\ell}(X)=X\) et nous avons \( f(X)=2X-X=X\). Donc \( \ell\) est conservée.

    En ce qui concerne les deux côtés de \( \ell\), il existe une application linéaire \( s\colon E\to \eR\) et une constante \( c\in \eR\) telles qu'en posant \( \ell(X)=s(X)+c\), la droite \( \ell\) soit le lieux des points \( X\) tels que \( \ell(X)=0\). Un côté de la droite est \( \ell<0\) et l'autre côté est \( \ell>0\). Nous avons :
    \begin{subequations}
        \begin{align}
            \ell\big( f(A) \big)&=\ell\big( 2\pr_{\ell}(A)-A \big)\\
            &=s(2\pr_{\ell}(A)-A)+c\\
            &=2s\big( \pr_{\ell}(A) \big)-s(A)+c\\
            &=s\big( \pr_{\ell}(A) \big)-s(A)\\
            &=-c-s(A)\\
            &=-\ell(A)
        \end{align}
    \end{subequations}
    où nous avons utilisé le fait que, \( \pr_{\ell}(A)\) étant sur \( \ell\), \( s\big( \pr_{\ell}(A) \big)+c=0\). Nous avons donc \( \ell\big( f(A) \big)=-\ell(A)\), ce qui indique que \( A\) et \( f(A)\) sont de part et d'autre de \( \ell\).

    Si \( d\) est une droite perpendiculaire à \( \ell\) et si \( A\in d\) alors \( f(A)=2\pr_{\ell}(A)-A=  \big( \pr_{\ell}(A)-A \big)+A\in d  \) parce que \( \pr_{\ell}(A)\in d\) du fait que \( d\) soit précisément perpendiculaire à \( \ell\). Nous avons aussi utilisé le fait que si \( A,B,C\in d\) alors \( (B-A)+C\in d\); pensez que \( B-A\) est un vecteur directeur et que \( C\) est un point de \( d\).

    Enfin soit \( K\in\ell\) et un cercle \( S(K,r)\) centré en \( K\). Soit \( A\in S(K,r)\); nous devons vérifier que \( f(A)=S(K,r)\). Le segment \( [A,f(A)]\) est par définition perpendiculaire à \( \ell\). Soit \( M\), le milieu, qui est sur la droite \( \ell\). Les triangles \( AMK\) et \( f(A)MK\) sont rectangles en \( M\), et \( \| AM \|=\| Mf(A) \|\). Le théorème de Pythagore donne \( \| AK \|=\| f(A)K \|\). Donc le cercle centré en \( K\) est donc préservé par \( f\).

    Nous en déduisons que \( f=\sigma_{\ell}\).
\end{proof}

\begin{proposition}[\cite{ooIIMKooJpdFyk}]      \label{PROPooFSVEooWmJsnv}
    Une réflexion est une isométrie de \( (E,d)\) où \( d(A,B)=\| A-B \|\).
\end{proposition}

\begin{proof}
    Soient \( A,B\in E\); il faut vérifier que \( \| A-B \|=\| \sigma_{\ell}(A)-\sigma_{\ell}(B) \|\). Pour cela nous écrivons
    \begin{equation}
        B-A=\underbrace{B-\pr_{\ell}(B)}_{=a}+\underbrace{\pr_{\ell}(B)-\pr_{\ell}(A)}_{=b}+\underbrace{\pr_{\ell}(A)-A}_{=c}.
    \end{equation}
    Vu que \( b\perp a\) et \( b\perp c\) nous avons
    \begin{equation}
        \| B-A \|=\langle B-A, B-A\rangle =\| a \|^2+2\langle a, c\rangle +\| b \|^2+\| c \|^2.
    \end{equation}
    Nous pouvons faire le même jeu avec \( \sigma_{\ell}(B)-\sigma_{\ell}(A)\) en tenant compte du fait que \( \pr_{\ell}\big( \sigma_{\ell}(X) \big)=\pr_{\ell}(X)\) et que
    \begin{equation}
        \sigma_{\ell}(A)-\pr_{\ell}(A)=2\pr_{\ell}(A)-A-\pr_{\ell}(A)=-\big( A-\pr_{\ell}(A) \big).
    \end{equation}
    Là nous avons utilisé le lemme~\ref{LEMooZSDRooUkNYer}. Ce que nous trouvons est que
    \begin{equation}
        \sigma_{\ell}(B)-\sigma_{\ell}(A)=-a+b-c,
    \end{equation}
    et donc encore une fois
    \begin{equation}
        \| \sigma_{\ell}(B)-\sigma_{\ell}(A) \|=\| a \|^2-2\langle a, c\rangle +\| b \|^2+\| c \|^2.
    \end{equation}
\end{proof}

\begin{remark}
    Il faut bien comprendre que si l'axe de la réflexion ne passe par par \( 0\) (le zéro de l'espace vectoriel normé \( (E,\| . \|)\)), la réflexion n'est pas une isométrie de \( (E,\| . \|)\) au sens où nous n'avons pas \( \| \sigma_{\ell}(x) \|=\| x \|\).
\end{remark}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Segment, plan médiateur et équidistance}
%---------------------------------------------------------------------------------------------------------------------------

\begin{lemma}   \label{LEMooSZZWooPDHnGl}
    Un point \( M\) est sur la médiatrice du segment \( [A,B]\) si et seulement si \( \| M-A \|=\| M-B \|\).
\end{lemma}

\begin{lemma}       \label{LEMooVBVUooOTFFXT}
    Soient \( A\) et \( B\) de points de \( \eR^3\). Alors le plan médiateur du segment \( [A,B]\) est le lieu des points de \( \eR^3\) à être équidistants de \( A\) et \( B\).
\end{lemma}

\begin{proof}
    Nous nommons \( \sigma\) ce plan.

    Soit \( X\) un point équidistant de \( A\) et \( B\). Alors dans le plan \( (A,B,X)\), le triangle \( ABX\) est isocèle en \( X\), et la hauteur issue de \( X\) coupe perpendiculairement \( [A,B]\) en son milieu. Cela prouve que \( X\) est dans le plan médiateur du segment \( [A,B]\) (lemme~\ref{LEMooSZZWooPDHnGl}).

    Mettons au contraire que \( X\) est dans le plan médiateur de \( [A,B]\). Nous avons \( (X,M)\perp (A,B)\). Donc le triangle \( A,B,X\) est isocèle en \( X\) et donc \( X\) est équidistant de \( A\) et \( B\).
\end{proof}

\begin{lemma}       \label{LEMooTCIEooXdyuHu}
    Si \( A'\) est l'image de \( A\) par \( \sigma_{\ell}\) alors \( \ell\) est la médiatrice du segment \( [A,A']\).
\end{lemma}

\begin{proof}
    Soit \( M\in\ell\). Nous avons
    \begin{equation}
        \| A-M \|^2=\| \pr_{\ell}(A)-A \|^2+\| \pr_{\ell}(A)-M \|^2
    \end{equation}
    parce que \( A-\pr_{ell}(A)\perp M-\pr_{\ell}(A)\). Par ailleurs, vu que \( \sigma_{\ell}(A)=2\pr_{\ell}(A)-A\) et que \( \pr_{\ell}(A)=\pr_{\ell}(A')\),
    \begin{equation}
        \| \pr_{\ell}(A)-A \|=\| \pr_{\ell}(A')-A' \|.
    \end{equation}
    Nous avons donc
    \begin{equation}
        \| \sigma_{\ell}(A)-M \|^2=\| A-M \|^2,
    \end{equation}
    ce qui prouve que \( M\) est sur la médiatrice de \( [A',A]\) par le lemme~\ref{LEMooSZZWooPDHnGl}.
\end{proof}

\begin{normaltext}
    Si \( l\) est une droite dans \( \eR^2\), nous avons la réflexion \( \sigma_l\in\Isom(\eR^2)\) d'axe \( l\). Cela est une isométrie et donc une application affine par le théorème~\ref{ThoDsFErq}. Le lemme suivant détermine comment la réflexion \( \sigma_{\ell}\) se décompose en une translation et une application linéaire.
\end{normaltext}

\begin{lemma}   \label{LEMooVOJLooCFgdNG}
    Soit une droite \( \ell\). Alors
    \begin{equation}
        \sigma_{\ell}=\tau_{2w}\circ\sigma_{\ell_0}
    \end{equation}
    où \( \ell_0\) est la droite parallèle à \( \ell\) passant par l'origine, et \( w\) est le vecteur perpendiculaire à \( \ell\) tel que \( \ell_0=\ell+w\).
\end{lemma}

\begin{proof}
    Il faut trouver trois points non alignés sur lesquels les deux applications coïncident; cela suffira par le corolaire~\ref{CORooZHZZooDgTzsW}.

    Pour tous les points de \( \ell_0\), l'égalité fonctionne parce que si \( x\in\ell_0\),
    \begin{equation}
        \sigma_{\ell}(x)=x+2w,
    \end{equation}
    tandis que
    \begin{equation}
        \sigma_{\ell_0}(x)+2w=x+2w
    \end{equation}
    du fait que \( \sigma_{\ell_0}(x)=x\).

    Si \( x\in\ell\), alors
    \begin{equation}
        \sigma_{\ell}(x)=x
    \end{equation}
    tandis que
    \begin{equation}
        \sigma_{\ell_0}(x)+2w=x-2w+2w=x.
    \end{equation}
    Donc les applications affines \( \sigma_{\ell}\) et \( x\mapsto \sigma_{\ell_0}(x)+2w\) coïncident sur \( \ell\) et \( \ell_0\). Elles coïncident donc partout.
\end{proof}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Translations et réflexions}
%---------------------------------------------------------------------------------------------------------------------------

\begin{lemma}       \label{LEMooMKTXooYKZcdQ}
    Si \( A\in \eR^2\), si \( \ell\) est une droite de \( \eR^2\), alors nous avons
    \begin{equation}
        \pr_{\tau_A(\ell)}=\tau_A\circ \pr_{\ell}\circ\tau_A^{-1}.
    \end{equation}
\end{lemma}

\begin{proof}
    Soit \( x\in \eR^2\). Soit \( v\) unitaire dans la direction\footnote{Cela signifie qu'il existe \( a\in \eR^2\) tel que \( \ell=a+\eR v\).} de \( \ell\). La condition \( q=\pr_{\ell}(x)\) est le système
    \begin{subequations}
        \begin{numcases}{}
            q\in \ell\\
            (q-x)\cdot v=0.
        \end{numcases}
    \end{subequations}
    Nous voulons prouver que \( \tau_A(q)=\pr_{\tau_A(\ell)}\big( \tau_A(x) \big)\), c'est-à-dire que
    \begin{subequations}
        \begin{numcases}{}
            \tau_A(q)\in \tau_A(\ell)\\
            \big( \tau_A(q)-\tau_A(x) \big)\cdot v=0.
        \end{numcases}
    \end{subequations}
    Nous avons utilisé le fait que $v$ est un vecteur unitaire dans la direction de \( \tau_A(\ell)\) aussi bien que de \( \ell\).

    Vu que \( q\in \ell\), bien entendu que \( \tau_A(q)\in \tau_A(\ell)\). D'autre part, \( \tau_A(q)-\tau_A(x)=q-x\), donc
    \begin{equation}
            \big( \tau_A(q)-\tau_A(x) \big)\cdot v=(q-x)\cdot v=0.
    \end{equation}
\end{proof}

\begin{lemma}       \label{LEMooSMMMooAqsHWb}
    Si \( \ell\) est une droite de \( \eR^2\), si \( A\in \eR^2\), alors
    \begin{equation}
        \sigma_{\tau_A(\ell)}=\tau_A\sigma_{\ell}\tau_A^{-1}.
    \end{equation}
\end{lemma}

\begin{proof}
    Il s'agit d'un calcul mettant en scène les lemmes \ref{LEMooZSDRooUkNYer} et \ref{LEMooMKTXooYKZcdQ} :
    \begin{subequations}
        \begin{align}
            \big( \sigma_{\tau_A(\ell)}\tau_A \big)(x)&=2\pr_{\tau_A(\ell)}\big( \tau_A(x) \big)\\
            &=2\tau_A\big( \pr_{\ell}(x) \big)-\tau_A(x)\\
            &=2\pr_{\ell}(x)+2A-x-A\\
            &=2\pr_{\ell}(x)-x+A\\
            &=\tau_A\big( \sigma_{\ell}(x) \big).
        \end{align}
    \end{subequations}
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Rotations}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}[Rotation en dimension \( 2\)]        \label{DEFooFUBYooHGXphm}
    Une \defe{rotation}{rotation!en dimension \( 2\)} d'un espace euclidien de dimension \( 2\) est une composée de deux réflexions d'axes non parallèles. L'identité est une rotation.
\end{definition}

\begin{normaltext}
    Quelques remarques à propos de cette définition.
    \begin{enumerate}
        \item
            Attention : nous ne parlons pas encore de rotations «vectorielles» : ici le centre de la rotation (que nous n'avons pas encore défini) peut ne pas être \( 0\).
        \item
            Dans la même veine : plus tard, lorsque nous saurons que les rotations sont des isométries de \( (E,d)\) où \( d(X,Y)=\| X-Y \|\), nous allons en réalité beaucoup plus souvent parler de rotations centrées en l'origine qu'en un point quelconque. C'est pourquoi à partir de~\ref{NORMooOUDJooRfbDEX} nous dirons le plus souvent «rotation»  pour «rotation centrée en \( 0\)». D'où les énoncés comme «les rotations sont les matrice orthogonales» (corolaire~\ref{CORooVYUJooDbkIFY}), qui \emph{stricto senus} de la définition~\ref{DEFooFUBYooHGXphm} sont faux.
        \item
            Une rotation est composée de deux réflexions d'axes non parallèles. Il est cependant trop tôt pour décréter que l'intersection de ces axes est le centre de la rotation. Rien ne dit en effet pour l'instant que deux décompositions différentes de la même rotation, avec des axes différents donnent le même point d'intersection.
        \item
            Pourquoi ajouter l'identité  ? Pour avoir un groupe. Dans le cas vectoriel, il est suffisant de demander d'être une composée de deux réflexions, parce que toutes les réflexions vectorielles ont des axes qui s'intersectent en \( 0\). Le cas des axes parallèles est seulement le cas des axes confondus et revient à l'identité.

            Si nous voulons avoir un groupe même pour les rotations centrées ailleurs qu'en zéro, nous devons ajouter «à la main» l'identité.
    \end{enumerate}

    Toutes ces remarques se résument par : «tout devient compliqué du fait que nous voulons considérer également les rotations centrées ailleurs qu'en zéro». En se contentent du cas vectoriel, de nombreuses choses sont plus simples.
\end{normaltext}

\begin{corollary}       \label{CORooNKKIooPGOUJl}
    Si \( A\neq B\) dans \( E\) alors il existe une unique réflexion envoyant \( A\) sur \( B\).
\end{corollary}

\begin{proof}
    En ce qui concerne l'existence, la réflexion dont l'axe est la médiatrice de \( [A,B]\) fait l'affaire. En ce qui concerne l'unicité, le lemme~\ref{LEMooTCIEooXdyuHu} nous dit que si \( A\) est envoyé sur \( B\), l'axe est forcément la médiatrice de \( [A,B]\).
\end{proof}

\begin{lemmaDef}[\cite{ooYPVPooYGSlNU}]        \label{LEMooIJELooLWqBfE}
    Soit une rotation \( r=\sigma_1\circ\sigma_2\) différente de l'identité. 
    \begin{enumerate}
        \item
            Elle admet un unique point fixe.
        \item
            Ce point fixe est l'intersection des axes \( \ell_1\cap\ell_2\).
    \end{enumerate}

    Le \defe{centre}{centre!d'une rotation} d'une rotation (autre que l'identité) est cet unique point fixe.
\end{lemmaDef}

\begin{proof}
    Nous nommons \( O=\ell_1\cap\ell_2\). Soit \( A\in E\), et supposons que \( r(A)=A\). Nous avons \( \sigma_1\circ r=s_2\) et donc
    \begin{equation}
        \sigma_1(A)=(\sigma_1\circ r)(A)=s_2(A).
    \end{equation}
    On pose \( B=\sigma_1(A)\). Alors \( \sigma_1\) et \( \sigma_2\) envoient tout deux \( A\) sur \( B\).

    Si \( A=B\) alors \( A\) est fixé par \( \sigma_1\) et donc appartient à \( \ell_1\). Même chose pour \( A\) est fixé par \( \sigma_2\) et donc \( A\in\ell_2\). Cela donne \( A=B=O\), et donc le point fixé par \( r\) est \( O\).

    Si \( A\neq B\) alors il existe une unique réflexion envoyant \( A\) sur \( B\) (corolaire~\ref{CORooNKKIooPGOUJl}). L'unicité signifie que \( \sigma_1=\sigma_2\). Dans ce cas, \( r=\sigma_1\circ\sigma_2=\id\).
\end{proof}

\begin{normaltext}      \label{NORMooDPBOooKkRuTn}
    La rotation \( \sigma_1\circ\sigma_2\) laisse évidemment fixé le point \( \ell_1\cap \ell_2\). Si \( \sigma_1\circ\sigma_2=\sigma_a\circ\sigma_b\) alors rien n'oblige les axes de \( \sigma_1\) et \( \sigma_2\) d'être identiques à ceux que \( \sigma_a\) et \( \sigma_b\). Mais l'intersection \( \ell_1\cap\ell_2\) doit être la même que l'intersection \( \ell_a\cap \ell_b\) parce que c'est l'unique point fixé par la composée. Cela nous permet de poser les définitions suivante.
\end{normaltext}


\begin{lemma}       \label{LEMooTZNWooTVOklu}
    Les rotation sont des isométries pour la distance : \( \| X-Y \|=\| r(X)-r(Y) \|\).
\end{lemma}

\begin{proof}
    Si \( r=\sigma_1\circ\sigma_2\), en utilisant le fait que \( \sigma_1\) et \( \sigma_2\) sont des isométries de \( (E,d)\) (\ref{PROPooFSVEooWmJsnv}) nous avons :
    \begin{equation}
        d(X,Y)=d\big( \sigma_2(X),\sigma_2(Y) \big)=d\big( \sigma_1\sigma_2(X),\sigma_1\sigma_2(Y) \big)=d\big( r(X),r(Y) \big).
    \end{equation}
\end{proof}

Ce lemme nous dit qu'une rotation de centre \( O\) vérifie \( \| OX \|=\| Or(X) \|\) pour tout \( X\).

\begin{proposition}[\cite{ooYPVPooYGSlNU}]      \label{PROPooNXJKooEDOczh}
    Soient \( A,B,O\in E\) tels que \( \| AO \|=\| BO \|\neq 0\). Alors il existe une unique rotation \( r\) centrée en \( O\) telle que \( r(A)=B\).
\end{proposition}

\begin{probleme}
    Attention : la preuve qui suit contient de nombreuses galipettes et improvisations personnelles. Relisez-la attentivement avant de la prendre pour argent comptant.

    La difficulté tient essentiellement à ce que cette preuve traite de façon vectorielle (tous les points sont des éléments de \( E\)) un énoncé qui est essentiellement affine : tous les points doivent être vus comme vecteurs partant de \( O\).

    Si vous comparez la preuve donnée ici avec celle de \cite{ooYPVPooYGSlNU}, vous remarquerez que dans ce dernier, seule la partie «\( A\) et \( O\) son alignés» est présente. C'est parce que lui, il se met directement dans le cas vectoriel et \( O=0\). Il a donc une preuve un tout petit peu moins générale, mais au moins ses isométries sont linéaires et non affines.
\end{probleme}

\begin{proof}
    Existence et unicité séparément.
    \begin{subproof}
        \item[Existence]
            Si \( A=B\), l'identité fait l'affaire. Sinon, \( \| A-O \|=\| B-O \|\) implique que la médiatrice de \( [A,B]\) contient \( O\). Soit \( \sigma_m\) la réflexion selon cette médiatrice. La rotation \( \sigma_m\circ\sigma_{(AO)}\) convient.

        \item[Unicité]

            Soit \( r\) une rotation de centre \( O\) et telle que \( r(A)=B\). Si \( A=B\) alors \( r=\id\) parce qu'une rotation autre que l'identité ne fixe que son centre par le lemme~\ref{LEMooIJELooLWqBfE}. Nous supposons que \( A\neq B\).

            Nous posons \( g=\sigma_m\circ r\). Alors \( g(A)=\sigma_m(B)=A\) parce que \( \sigma_m(B)=A\) et \( r(A)=B\). Cela signifie que \( g\) est une isométrie qui fixe \( A\).

            \begin{subproof}
                \item[Si \( A\) et \( O\) ne sont pas alignés]

                    Attention : ici \( O\) est un point de \( E\), pas le zéro de l'espace vectoriel \( E\). Lorsqu'on dit que \( A\) et \( O\) ne sont pas alignés, nous parlons bien d'alignement avec le zéro de \( E\).

                    Nous avons \( g(A)=A\) et \( g(O)=O\). Donc \( g\) coïncide avec \( \sigma_{(AO)}\) en deux points non alignés, c'est-à-dire en deux points pour lesquels l'espace engendré est tout \( E\). Nous en déduisons que \( g=\sigma_{(AO)}\).

                \item[Si \( A\) et \( O\) sont alignés]


            Soit maintenant un point \( C\) tel que \( A-O\perp C-O\) et
            \begin{equation}
                \| OC \|=\| OA \|=\| OB \|.
            \end{equation}
            Vu que \( g\) est une isométrie pour la distance sur \( E\), pas pour la norme, nous ne pouvons pas écrire \( g(C-O)\perp g(A-O)\) à partir de \( C-O\perp A-O\). Nous décomposons \( g(X)=s(X)+G\) où \( s\) est linéaire sur \( E\). Il est vite vu que \( s\) est une isométrie de \( (E,\| . \|)\) :
            \begin{equation}
                \| X-Y \|=\| g(X)-g(Y) \|=\| s(X)+G-s(y)-G \|=\| s(X)-s(Y) \|=\| s(X-Y) \|
            \end{equation}
            pour tout \( X,Y\in E\). Nous avons de plus \( g(A)=A\) et \( g(O)=O\), ce qui donne \( O=s(O)+G\) et \( A=s(A)+G\). En égalisant les valeurs de \( G\) nous avons
            \begin{equation}        \label{EQooPEWGooABHUvu}
                O-s(O)=A-s(A).
            \end{equation}
            Vu que \( s\) est une isométrie (une vraie) nous avons
            \begin{equation}
                s(A-O)\perp s(C-O),
            \end{equation}
            mais \( s(A-O)=s(A)-s(O)=A-O\) par \eqref{EQooPEWGooABHUvu}. Donc
            \begin{equation}
                A-O\perp s(C-O).
            \end{equation}
            Nous en concluons que \( s(C-O)=\pm (C-O)\). Parce que les vecteurs \( \pm(C-O)\) sont les deux seuls de norme \( \| AO \| =\| CO \|\) à être perpendiculaire à \( A-O\). Rappel : la définition de \( C\) et le fait que nous soyons en dimension \( 2\).

            Est-il possible d'avoir \( s(C-O)=C-O\) ? Cela donnerait
            \begin{subequations}
                \begin{align}
                    g(A-O)&=s(A)-s(O)+G=s(A)-O+O-s(O)+G=A-O+G\\
                    g(C-O)&=C-O+G,
                \end{align}
            \end{subequations}
            ce qui signifierait que \( g\) et \( \tau_G\) coïncideraient sur les points \( A-O\) et \( C-O\), et donc seraient égaux par le corolaire~\ref{CORooZHZZooDgTzsW}. Cela est cependant impossible parce que \( g\) fixe au moins les points \( A\) et \( O\) alors que la translation ne fixe aucun point. Nous en déduisons \( s(C-O)=-(C-O)\).

            Nous avons aussi, parce que \( (AO)\) est une droite passant par l'origine que
            \begin{equation}
                \sigma_{(AO)}(A-O)=A-O
            \end{equation}
            et parce que \( C-O\) est perpendiculaire à cette droite :
            \begin{equation}
                \sigma_{(AO)}(C-O)=-(C-O).
            \end{equation}
            Nous avons donc quand même que \( g\) et \( \sigma_{(AO)}\) coïncident sur deux points non alignés : \( A-O\) et \( C-O\).

            \end{subproof}

            Dans tous le cas, \( g=\sigma_{(AO)}\). Nous avons donc
            \begin{equation}
                \sigma_{(OA)}=\sigma_m\circ r,
            \end{equation}
            et donc \( r\) est fixé à
            \begin{equation}
                r=\sigma_m\circ\sigma_{(OA)}.
            \end{equation}
    \end{subproof}
\end{proof}

\begin{normaltext}
    Anticipons un peu et faisons semblant de déjà connaitre les matrices et les fonctions trigonométriques. La proposition~\ref{PROPooNXJKooEDOczh} nous dit qu'il existe une seule rotation amenant \( A\) sur \( B\). Vous pourriez objecter que le point \( (1,0)\) peut être amené sur \( (0,-1)\) soit par la rotation d'angle \( 3\pi/2\), soit par celle d'angle \( -\pi/2\). Il n'en est rien parce que ces deux rotations sont les mêmes ! Pensez-y. En tant qu'application \( \eR^2\to \eR^2\), la rotation \( R_{3\pi/2}\) est égale à \( R_{-\pi/2}\).
\end{normaltext}

Une rotation donnée peut être écrite de beaucoup de façons comme composée de deux réflexions. En fait d'autant de façons qu'il y a de réflexions.
\begin{proposition}[\cite{ooYPVPooYGSlNU}]      \label{PROPooKAZEooLTHWKe}
    Soit une rotation \( r\) de \( E\) centrée en \( O\). Pour toute réflexion \( \sigma_{\ell}\) telle que le centre de \( r\) soit sur \( \ell\), il existe une réflexion \( \sigma_1\) tells que \( r=\sigma_1\circ\sigma_{\ell}\). Il existe aussi une réflexion \( \sigma_2\) telle que \( r=\sigma_{\ell}\circ s_2\).
\end{proposition}

\begin{proof}
    Si \( r=\id\) c'est bon avec \( s_1=s_2=\sigma_{\ell}\). Sinon nous considérons \( A\neq O\) sur \( \ell\), et \( B=r(A)\). Nous savons que \( B\neq A\) parce que \( O\) est le seul point de \( E\) fixé par \( r\) (proposition~\ref{LEMooIJELooLWqBfE}). Il existe une réflexion (unique) \( \sigma_1\) faisant \( \sigma_1(A)=B\), et c'est le réflexion dont l'axe est la médiatrice de \( [A,B]\). Le point \( O\) est sur cette médiatrice parce que les rotations sont des isométries de \( (E,d)\) (lemme~\ref{LEMooTZNWooTVOklu}).

    La rotation \( \sigma_1\circ \sigma_{\ell}\) vérifie
    \begin{equation}
        (\sigma_1\circ\sigma_{\ell})(A)=\sigma_1(A)=B.
    \end{equation}
    Or \( \| OA \|=\| OB \|\), donc il y a unicité de la rotation centrée en \( O\) portant \( A\) sur \( B\) (proposition~\ref{PROPooNXJKooEDOczh}); nous avons donc \( r=\sigma_1\circ\sigma_{\ell}\).

    En ce qui concerne \( r=\sigma_{\ell}\circ\sigma_2\), il faut appliquer ce que nous venons de faire à la rotation \( r^{-1}\): il existe \( \sigma_2\) tel que \( r^{-1}=\sigma_2\circ\sigma_{\ell}\), ce qui donne
    \begin{equation}
        r=\sigma_{\ell}\circ\sigma_2.
    \end{equation}
\end{proof}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Rotation d'un angle donné}
%---------------------------------------------------------------------------------------------------------------------------

\begin{lemmaDef}        \label{DEFooADTDooKIZbrw}
    Soit \( \theta\in \eR\). Nous considérons l'application linéaire \( R_0(\theta)\colon \eR^2\to \eR^2\) dont la matrice dans la base canonique est
    \begin{equation}
        \begin{pmatrix}
            \cos(\theta)    &   -\sin(\theta)    \\ 
            \sin(\theta)    &   \cos(\theta)    
        \end{pmatrix}.
    \end{equation}
    \begin{enumerate}
        \item       \label{ITEMooIEKJooZfsAui}
    Nous avons
    \begin{equation}        \label{EQooEVCTooBpTDDq}
        R_0(\theta)=\sigma_{\ell}\circ s
    \end{equation}
    où \( s\) est la réflexion d'axe horizontal et \( \ell\) est la droite
    \begin{equation}
        \ell=\eR\begin{pmatrix}
            \cos(\theta/2)    \\ 
            \sin(\theta/2)    
        \end{pmatrix}.
    \end{equation}
\item       \label{ITEMooBEYOooMHRRYk}
    L'application \( R_0(\theta)\) est une rotation autour de \( (0,0)\).
\item     \label{ITEMooEQPAooQcsYfj}
          Si \( A\in \eR^2\), alors l'application
          \begin{equation}
              R_A(\theta)=\tau_A\circ R_0(\theta)\circ \tau_A^{-1}
          \end{equation}
            est une rotation autour de \( A\) nommée \defe{rotation d'angle \( \theta\)}{rotation d'angle \( \theta\)}.       
    \end{enumerate}
\end{lemmaDef}

\begin{proof}
    Nous allons prouver l'égalité \eqref{EQooEVCTooBpTDDq} en calculant les deux membres sur les vecteurs \( \begin{pmatrix}
        1    \\ 
        0    
    \end{pmatrix}\) et \( \begin{pmatrix}
        1    \\ 
        0    
    \end{pmatrix}\) qui forment une base.

    \begin{subproof}
        \item[Pour \( p=(1,0)\)]
            D'abord la chose facile\footnote{Ici comme partout dans le Frido nous ne faisons aucune différence entre \( (a,b)\) et \( \begin{pmatrix}
            a    \\ 
        b    
    \end{pmatrix}\); ce sont seulement deux façons différentes d'écrire le même élément de \( \eR^2\). Nous ne faisons pas du semblant de croire que l'un ou l'autre serait un «covecteur» suivant que l'on tourne notre page dans un sens ou un autre.} : \( s(1,0)=(1,0)\).

    Pour calculer \( \sigma_{\ell}(1,0)\), nous utilisons le lemme \ref{LEMooZSDRooUkNYer}; nous commençons par chercher la projection orthogonale \( q\) de \( p=(1,0)\) sur \( \ell\). Nous posons
    \begin{equation}        \label{EQooUFMWooWhwcHR}
            q=\lambda\begin{pmatrix}
                \cos(\theta/2)    \\ 
                \sin(\theta/2)    
            \end{pmatrix}
        \end{equation}
        et nous cherchons \( \lambda\) satisfaisant \( q\cdot(q-p)=0\). Un peu de calculs passant par \eqref{EQooNYCZooApyyRd} nous donne
        \begin{equation}
            q\cdot (q-p)=\lambda\big( \lambda-\cos(\theta/2) \big).
        \end{equation}
        Les deux solutions sont \( \lambda=0\) et \( \lambda=\cos(\theta/2)\). Mais la solution \( \lambda=0\) revient à dire que la droite \( \ell\) est verticale, c'est-à-dire \( \cos(\theta/2)=0\). Donc la solution est toujours donnée par
        \begin{equation}
            \lambda=\cos(\theta/2).
        \end{equation}
        Nous introduisons cette valeur dans \eqref{EQooUFMWooWhwcHR} pour fixer \( q\), et nous utilisons la formule du lemme \ref{LEMooZSDRooUkNYer} :
        \begin{equation}
            \sigma_{\ell}\begin{pmatrix}
                1    \\ 
                0    
            \end{pmatrix}=2q-p=\begin{pmatrix}
                2\cos^2(\theta/2)-1    \\ 
                2\cos(\theta/2)\sin(\theta/2)    
            \end{pmatrix}
            =\begin{pmatrix}
                \cos(\theta)    \\ 
                \sin(\theta)    
            \end{pmatrix}.
        \end{equation}
        Nous avons utilisé le formules trigonométrique de duplication d'angle (corolaire \ref{CORooQZDQooWjMXTF}).
    \item[Pour \( p=(0,1)\)]
        Cette fois \( s(p)=(0,-1)\) et l'équation pour déterminer \( \lambda\) est
        \begin{equation}
            0=q\cdot(q-p)=\begin{pmatrix}
                \lambda\cos(\theta/2)    \\ 
                \lambda\sin(\theta/2)    
            \end{pmatrix}\cdot\begin{pmatrix}
                \lambda\cos(\theta/2)    \\ 
                \lambda\sin(\theta/2)-1    
            \end{pmatrix}.
        \end{equation}
        Nous trouvons \( \lambda\big( \lambda+\sin(\theta/2) \big)=0\). Le cas \( \lambda=0\) signifie que la droite \( \ell\) est horizontale et donc que \( \sin(\theta/2)=0\). Donc la solution est dans tous les cas
        \begin{equation}
            \lambda=-\sin(\theta/2).
        \end{equation}
        Nous trouvons
        \begin{equation}
            \sigma_{\ell}\begin{pmatrix}
                0    \\ 
                -1    
            \end{pmatrix}=2q-p=\begin{pmatrix}
                -\sin(\theta)    \\ 
                \cos(\theta)    
            \end{pmatrix}.
        \end{equation}
    \end{subproof}
    Le calcul de \( \sigma_{\ell}\circ s\) étant fait sur une base, il est facile de reconstituer la matrice
    \begin{equation}
        \begin{pmatrix}
            \cos(\theta)    &   -\sin(\theta)    \\ 
            \sin(\theta)    &   \cos(\theta)    
        \end{pmatrix}.
    \end{equation}
    Cette matrice étant celle, par définition, de \( R_0(\theta)\), nous avons montré que \( R_0(\theta)\) était bien une rotation. Nous avons prouvé les points \ref{ITEMooIEKJooZfsAui} et \ref{ITEMooBEYOooMHRRYk}.

    Nous passons maintenant au point \ref{ITEMooEQPAooQcsYfj}. Il est facile de voir que \( A\) est un point fixe de \( R_{A}(\theta)\) parce que \( \tau_A^{-1}(A)=(0,0)\).

    Nommons \( \ell'\) la droite horizontale \( \eR(1,0)\). Nous avons, par le point précédent \( R_0(\theta)=\sigma_{\ell}\circ \sigma_{\ell'}\). En introduisant astucieusement \( \tau_A^{-1}\tau_A\) dans l'expression définissant \( R_A(\theta)\), nous avons
    \begin{equation}
        R_A(\theta)=\tau_A\sigma_{\ell}\sigma_{\ell'}\tau_A^{-1}=\underbrace{\tau_A\sigma_{\ell}\tau_A^{-1}}_{=\sigma_{\tau_A(\ell)}}\underbrace{\tau_A\sigma_{\ell'}\tau_A^{-1}}_{\sigma_{\tau_A(\ell')}}=\sigma_{\tau_A(\ell)}\sigma_{\tau_A(\ell')}.
    \end{equation}
    Nous avons utilisé le lemme \ref{LEMooSMMMooAqsHWb}.

    Nous voyons que \( R_A(\theta)\) est une composée de deux réflexions se coupant en \( A\). C'est donc une rotation centrée en \( A\).


\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Rotations vectorielles}
%---------------------------------------------------------------------------------------------------------------------------

L'expression «rotation vectorielle» signifie rotation centrée en zéro. Elles sont «vectorielles» parce qu'elles sont linéaires comme nous le voyons à présent.

\begin{proposition}     \label{PROPooTFNSooFjiWHG}
    Quelques résultats à propos de rotations.
    \begin{enumerate}
        \item       \label{ITEMooONJOooRgycsQ}
    Toutes les rotations de \( \eR^2\) centrées en \( 0\) sont de la forme \( R_0(\theta)\) pour un \( \theta\in \eR\).
\item
    Les rotations de \( \eR^2\) centrées en \( 0\) sont des applications linéaires.
        \item       \label{ITEMooSIHZooBEJhdu}
            Si \( r\) est une rotation dans \( \eR^2\), il existe \( A\in \eR^2\) et \( \theta\in \eR\)
            \begin{equation}
                r=\tau_A\circ R_0(\theta)\circ \tau_A^{-1}.
            \end{equation}
    \end{enumerate}
\end{proposition}

\begin{proof}
    Soit \( r\) une rotation centrée en \( (0,0)\). La proposition \ref{PROPooKAZEooLTHWKe}, il existe une droite \( \ell\) passant par \( (0,0)\) telle que telle que \( r=\sigma_{\ell}\circ s\) où \( s\) est la réflexion d'axe horizontal : \( s(x,y)=(x,-y)\).

    Soit un vecteur unitaire \( v\in \ell\). Vu que \( v\in S^1\), la proposition \ref{PROPooKSGXooOqGyZj} nous donne \( t\in \mathopen[ 0 ,2\pi  \mathclose[\) tel que
        \begin{equation}
            v=\begin{pmatrix}
                \cos(t)    \\ 
                \sin(t)    
            \end{pmatrix}.
        \end{equation}
        En posant \( \theta=2 t\) nous avons
        \begin{equation}
            \ell=\eR\begin{pmatrix}
                \cos(\theta/2)    \\ 
                \sin(\theta/2)    
            \end{pmatrix},
        \end{equation}
        et donc \( r=R_0(\theta)\) qui est l'application linéaire définie en \ref{DEFooADTDooKIZbrw}.

    Et enfin nous voyons le point \ref{ITEMooSIHZooBEJhdu}. Soit \( A\) l'unique point fixe de la rotation \( r\). Cette dernière s'écrit alors \( r=\sigma_{\ell_1}\circ\sigma_{\ell_2}\) où \( \ell_1\) et \( \ell_2\) sont des droites telles que \( \ell_1\cap\ell_2=\{ A \}\).

    En utilisant le lemme \ref{LEMooSMMMooAqsHWb}, nous avons \( \sigma_{\ell_i}=\tau_A\circ \sigma_{\tau_A^{-1}(\ell_i)}\circ \tau_A^{-1}\). En substituant cela et en nous rendant compte que \( \tau_A^{-1}\tau_A=\id\) nous avons
    \begin{equation}
        r=\sigma_{\ell_1}\circ\sigma_{\ell_2}=\tau_A r_0\tau_1^{-1}
    \end{equation}
    où \( r_0\) est la rotation \( \sigma_{\tau_A^{-1}(\ell_1)}\circ \sigma_{\tau_A^{-1}}(\ell_2)\). Cette dernière est une rotation autour de \( (0,0)\) parce que \( \tau_A^{-1}(\ell_1)\cap \tau_A^{-1}(\ell_2)=\{ 0 \}\). Elle est donc, par le point \ref{ITEMooONJOooRgycsQ}, de la forme \( R_0(\theta)\) pour une certaine valeur de \( \theta\).

\end{proof}

\begin{proposition}[\cite{ooYPVPooYGSlNU}]      \label{PROPooWMESooNJMdxf}
    Les rotations basées en \( O\) forment un groupe abélien.
\end{proposition}

\begin{proof}
    L'identité est une rotation par définition. En ce qui concerne l'inverse, si \( r=\sigma_1\sigma_2\) alors \( r^{-1}=\sigma_2\sigma_1\). Nous commençons maintenant les choses pas tout à fait évidentes.
    \begin{subproof}
        \item[Composition]
            Soient des rotations \( r,r'\) centrées en \( O\). Soit également une réflexion \( \sigma\) dont l'axe contient \( O\). Alors la proposition~\ref{PROPooKAZEooLTHWKe} nous donne l'existence de \( \sigma_1\) et \( \sigma_2\) tels que \( r=\sigma_1\sigma\) et \( r'=\sigma\sigma_2\). Avec ça, la composition donne
            \begin{equation}
                rr'=\sigma_1\sigma\sigma\sigma_2=\sigma_1\sigma_2,
            \end{equation}
            qui est encore une rotation.
        \item[Commutativité]
            Soient deux rotations \( r\) et \( r'\) ainsi que des décompositions \( r=\sigma_1\sigma\), \( r'=\sigma\sigma_2\). Nous avons
            \begin{subequations}
                \begin{align}
                    rr'&=\sigma_1\sigma_2\\
                    r'r&=\sigma\sigma_2\sigma_2\sigma.
                \end{align}
            \end{subequations}
            Vu que \( t=\sigma_2\sigma_1\) est une rotation nous pouvons encore appliquer la proposition~\ref{PROPooKAZEooLTHWKe} pour avoir \( t=\sigma_2\sigma_1=\sigma\sigma_3\). Avec ça,
            \begin{equation}
                r'r=\sigma\sigma\sigma_3\sigma=\sigma_3\sigma.
            \end{equation}
            Mais aussi \( rr'=\sigma_1\sigma_2=t^{-1}=\sigma_3\sigma\). Nous avons donc bien \( rr'=r'r\), et le groupe est commutatif.
    \end{subproof}
\end{proof}

\begin{normaltext}      \label{NORMooOUDJooRfbDEX}
    Jusqu'à présent nous avons parlé de rotations «affines». Parmi elles, les rotations centrées en \( 0\) (zéro, l'origine de \( E\) comme espace vectoriel) sont de particulière importance. Ce sont des applications linéaires, et même des isométries. Dans la suite, nous allons souvent dire simplement «rotation» pour dire «rotation centrée en \( 0\)».

    Vu que nous allons maintenant prendre un point de vue plus vectoriel, nous allons noter les points de \( E\) avec des lettres comme \( x\), \( y\), \( u\), \( v\) et plus avec des majuscules, comme quand on avait un point de vue afin. En même temps, nous allons noter les applications \( E\to E \) par des lettres comme \( A\) et ne plus écrire les parenthèses. Bref, nous écrivons \( Au\) au lieu de \( r(A)\).
\end{normaltext}

\begin{lemma}       \label{LEMooSYZYooWDFScw}
    En dimension \( 2\), les réflexions vectorielles (c'est-à-dire dont l'axe passe par \( 0\)) ont un déterminant \( -1\).
\end{lemma}

\begin{proof}
    Soit une réflexion d'axe \( \ell\). Prenons une base orthonormale de \( E\) constituée de \( e_1\) sur \( \ell\) et de \( e_2\perp \ell\). Alors \( \sigma_{\ell}(e_1)=e_1\) et \( \sigma_{\ell}(e_2)=-e_2\). La formule du déterminant donne
    \begin{equation}
        \det(\sigma_{\ell})=e_1^*\big( \sigma_{\ell}(e_1) \big)e_1^*\big( \sigma_{\ell}(e_2) \big)-e_2^*\big( \sigma_{\ell}(e_1) \big)e_1^*\big( \sigma_{\ell}(e_2) \big)=1\times (-1)-0\times 0=-1.
    \end{equation}
    Nous utilisons de façon cruciale le fait que le calcul du déterminant ne dépende pas de la base choisie, lemme~\ref{LEMooQTRVooAKzucd}.
\end{proof}

\begin{proposition}     \label{PROPooTUJWooAjtEnQ}
    Les rotations\footnote{Centrées en \( 0\), nous ne le répéterons pas !} sont
    \begin{enumerate}
        \item
            des applications linéaires orthogonales au sens de la définition~\ref{DEFooYKCSooURQDoS},
        \item
             des applications de déterminant \( 1\),
    \end{enumerate}
\end{proposition}

\begin{proof}
    Le fait qu'elles soient linéaires est la proposition \ref{PROPooTFNSooFjiWHG}.

    Nous avons, pour tout \( u\in E\) l'égalité de la norme \( \| u \|\) et \( \| Au \|\) par le lemme~\ref{LEMooTZNWooTVOklu} appliqué à \( Y=0\). En termes de produits scalaires nous avons alors \( \langle Au, Au\rangle =\langle u, u\rangle \), et donc
    \begin{equation}
        \langle A^*Au, u\rangle =\| u \|^2.
    \end{equation}
    En particulier si \( \{ e_i \}_{i=1,\ldots, n}\) est une base orthonormée de \( E\) nous avons
    \begin{equation}
        (A^*Ae_i)_i=\| e_i \|^2=1,
    \end{equation}
    ce qui donne \( \| A^*Ae_i \|\geq 1\), avec égalité si et seulement si \( A^*Ae_i=e_i\). Ici nous avons utilisé le fait que \( \langle x, e_i\rangle =x_i\), et le fait que pour tout \( i\) nous ayons \( \| x \|\geq | x_i |\), avec égalité seulement si \( x\) est un multiple de \( e_i\).

    Par ailleurs l'inégalité de Cauchy-Schwarz~\ref{ThoAYfEHG} nous donne
    \begin{equation}
        \| u \|^2=| \langle A^*Au, u\rangle  | \leq \| A^*Au \|\| u \|
    \end{equation}
    et donc
    \begin{equation}
        \| u \|\leq \| A^*Au \|.
    \end{equation}
    Encore une fois, en appliquant cela à \( u=e_i\) nous trouvons \( 1\leq \| A^*Ae_i \|\). Vu que nous avions déjà l'inégalité dans l'autre sens, \( \| A^*Ae_i \|=1\). Et le cas d'égalité est uniquement possible avec \( A^*Ae_i=e_i\).

    Donc pour tout \( i\) de la base nous avons \( A^*Ae_i=e_i\). Nous avons donc \( A^*A=\id\) et l'application \( A\) est orthogonale.

    En ce qui concerne le déterminant, les réflexions sont de déterminant \( -1\) par le lemme~\ref{LEMooSYZYooWDFScw}, donc \( A=\sigma_1\circ\sigma_2\) est de déterminant \( 1\). Nous avons utilisé le fait que le déterminant était un morphisme : proposition~\ref{PropYQNMooZjlYlA}\ref{ItemUPLNooYZMRJy}.
\end{proof}

\begin{remark}
    Nous ne savons pas encore que les rotations forment tout le groupe \( \SO(2)\) des endomorphismes orthogonaux de déterminant \( 1\). Il faudra attendre le corolaire~\ref{CORooVYUJooDbkIFY} pour le savoir.
\end{remark}

\begin{lemma}       \label{LEMooMIJXooCjiQqP}
    L'application \( -\id\) est une rotation de \( \eR^2\).
\end{lemma}

\begin{proof}
    Soit une base orthonormée \( \{ e_1,e_2 \}\) de \( E\) et la rotation \( r=\sigma_1\sigma_2\) où \( \sigma_i\) est la réflexion le long de l'axe \( \ell_i=\{ te_i \}_{t\in \eR}\). Faut-il vous prouver que \( r=-\id\) ? La réflexion \( \sigma_2\) retourne la composante \( y\) d'un vecteur écrit dans la base \( \{ e_1,e_2 \}\) sans toucher à la composante \( x\). La réflexion \( \sigma_1\) fait le contraire.
\end{proof}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Matrice des transformations orthogonales}
%---------------------------------------------------------------------------------------------------------------------------

Nous donnons maintenant une forme générale (trigonométrique) pour les matrices de \( \SO(2)\). Nous ne pouvons cependant pas invoquer les lemmes \ref{LEMooAJMAooXPSKtS} ou \ref{LEMooHRESooQTrpMz} pour prétendre avoir une matrice des rotations, parce que nous n'avons pas encore prouvé que les rotations étaient des transformations orthogonales. Ce sera pour la proposition \ref{PROPooOTIVooZpvLnb}.

\begin{lemma}       \label{LEMooAJMAooXPSKtS}
    Si \( A\in \gO(2)\) alors il existe un unique \( \theta\in\mathopen[ 0 , 2\pi \mathclose[\) et un unique \( \epsilon=\pm 1\) tels que
    \begin{equation}
        A=\begin{pmatrix}
            \cos(\theta)    &   -\epsilon\sin(\theta)    \\
            \sin(\theta)    &   \epsilon\cos(\theta)
        \end{pmatrix}
    \end{equation}
\end{lemma}

\begin{proof}
    Soit une matrice \( A=\begin{pmatrix}
        a    &   b    \\
        c    &   d
    \end{pmatrix}\) et imposons qu'elle soit dans \( \gO(2)\). Le fait que \( A\) soit orthogonale impose
    \begin{equation}
        \begin{pmatrix}
            a    &   c    \\
            b    &   d
        \end{pmatrix}\begin{pmatrix}
            a    &   b    \\
            c    &   d
        \end{pmatrix}=\begin{pmatrix}
            a^2+c^2    &   ab+cd    \\
            ab+cd    &   b^2+d^2
        \end{pmatrix}=\begin{pmatrix}
            1    &   0    \\
            0    &   1
        \end{pmatrix}.
    \end{equation}
    Nous avons alors le système
    \begin{subequations}
        \begin{numcases}{}
            a^2+b^2=1\\
            b^2+d^2=1\\
            ab+cd=0
        \end{numcases}
    \end{subequations}
    La proposition~\ref{PROPooKSGXooOqGyZj} nous permet de déduire qu'il existe un unique \( \theta\in\mathopen[ 0 , 2\pi \mathclose[\) tel que \( a=\cos(\theta)\), \( c=\sin(\theta)\), ainsi que plusieurs \( \alpha\in \eR\) tel que \( b=\cos(\alpha)\), \( d=\sin(\alpha)\).

        Note : si nous voulons \( \alpha\in\mathopen[ 0 , 2\pi \mathclose[\), alors il y a unicité. Ici nous ne nous attachons pas à cette contrainte; nous savons qu'il en existe plusieurs, et nous allons en fixer un en fonction de \( \theta\). Le \( \alpha\) ainsi fixé ne sera peut-être pas dans \( \mathopen[ 0 , 2\pi \mathclose[\), mais ce ne sera pas grave.

        Les angles \( \theta\) et \( \alpha\) sont alors liés par la contrainte
        \begin{equation}
            \cos(\theta)\cos(\alpha)+\sin(\theta)\sin(\alpha)=0.
        \end{equation}
        Utilisant l'identité \eqref{EQooCVZAooQfocya} cela signifie que \( \cos(\theta-\alpha)=0\). Donc
        \begin{equation}
            \alpha\in\{ \theta+\frac{ \pi }{2}+k\pi \}_{k\in \eZ}.
        \end{equation}
        Si \( k\) est pair, ça donne
        \begin{subequations}
            \begin{align}
                \cos(\alpha)=-\sin(\theta)\\
                \sin(\alpha)=\cos(\theta)
            \end{align}
        \end{subequations}
        et alors
        \begin{equation}        \label{EQooNAMKooKACIfd}
            A=\begin{pmatrix}
                \cos(\theta)    &   -\sin(\theta)    \\
                \sin(\theta)    &   \cos(\theta)
            \end{pmatrix}.
        \end{equation}
        Si au contraire \( k\) est impair, alors
        \begin{subequations}
            \begin{align}
                \cos(\alpha)=\sin(\theta)\\
                \sin(\alpha)=-\cos(\theta),
            \end{align}
        \end{subequations}
        et
        \begin{equation}        \label{EQooJMYFooGgAiMJ}
            A=\begin{pmatrix}
                \cos(\theta)    &   \sin(\theta)    \\
                \sin(\theta)    &   -\cos(\theta)
            \end{pmatrix}.
        \end{equation}

        Nous avons démontré qu'une matrice de \( \gO(2)\) était forcément d'une des deux formes \eqref{EQooNAMKooKACIfd} ou \eqref{EQooJMYFooGgAiMJ}. Il est maintenant facile de vérifier que ces deux matrices sont effectivement dans \( \gO(2)\).
\end{proof}

\begin{lemma}       \label{LEMooHRESooQTrpMz}
    Tout élément de \( \SO(2)\) s'écrit (dans la base canonique) de façon unique sous la forme
    \begin{equation}
        \begin{pmatrix}
            \cos(\theta)    &   -\sin(\theta)    \\
            \sin(\theta)    &   \cos(\theta)
        \end{pmatrix}
    \end{equation}
    avec \( \theta\in\mathopen[ 0 , 2\pi \mathclose[\).
\end{lemma}

\begin{proof}
    Vu que \( \SO(2)\) est la partie de \( \gO(2)\) constitué des matrices de déterminant \( 1\), nous pouvons reprendre la forme donnée par le lemme~\ref{LEMooAJMAooXPSKtS} et fixer \( \epsilon\) par la contrainte sur le déterminant.

    Nous avons, en utilisant la relation du lemme~\ref{LEMooAEFPooGSgOkF},
    \begin{equation}
        \det\begin{pmatrix}
            \cos(\theta)    &   -\epsilon\sin(\theta)    \\
            \sin(\theta)    &   \epsilon\cos(\theta)
        \end{pmatrix}=\epsilon,
    \end{equation}
    et donc il faut et suffit de fixer \( \epsilon=1\).
\end{proof}



\begin{corollary}[\cite{MonCerveau}]        \label{CORooGGVUooLQYGET}
    Nous avons une bijection
    \begin{equation}
        \begin{aligned}
            \psi\colon \SO(2)&\to \mathopen[ 0 , 2\pi \mathclose[ \\
        \begin{pmatrix}
            \cos(\theta)    &   -\sin(\theta)    \\
            \sin(\theta)    &   \cos(\theta)
        \end{pmatrix}
              &\mapsto \theta,
        \end{aligned}
    \end{equation}
    et un isomorphisme de groupe
    \begin{equation}
        \begin{aligned}
            \varphi\colon \SO(2)&\to \gU(1)=\{  e^{i\theta} \}_{\theta\in \eR} \\
        \begin{pmatrix}
            \cos(\theta)    &   -\sin(\theta)    \\
            \sin(\theta)    &   \cos(\theta)
        \end{pmatrix}
        &\mapsto  e^{i\theta}.
        \end{aligned}
    \end{equation}
\end{corollary}

\begin{proof}
    La première assertion est une paraphrase du lemme~\ref{LEMooHRESooQTrpMz}. Pour la seconde, il faut vérifier que c'est bien un morphisme et une bijection.

    Pour le morphisme, ce sont les formules d'addition d'angle du lemme~\ref{LEMooJAWBooJGfZIL} qui jouent. En ce qui concerne la bijection\ldots

    \begin{subproof}
        \item[Surjection]
            Vu que \(  e^{i\theta+2ki\pi}= e^{i\theta}\), tout élément de \( \gU(1)\) est exponentielle de \( i\theta\) pour un \( \theta\in\mathopen[ 0 , 2\pi \mathclose[\).
        \item[Injection]
            Nous avons \( \varphi(A)=\varphi(B)\) lorsque les formes matricielles de \( A\) et \( B\) sous forme trigonométrique sont avec des angles différents d'un multiple de \( 2\pi\). Vu que les fonctions trigonométriques sont périodiques, nous avons \( A=B\) parce que leurs matrices sont égales.
    \end{subproof}
\end{proof}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Rotations, \( \SO(2)\) et matrice de rotation}
%---------------------------------------------------------------------------------------------------------------------------

\begin{corollary}[\cite{MonCerveau}] \label{CORooVYUJooDbkIFY}
    Le groupe des rotations centrées en \( (0,0)\) est le groupe \( \SO(2)\).
\end{corollary}

\begin{proof}

    Nous devons prouver deux choses : 
    \begin{itemize}
        \item Toutes les rotations sont des éléments de \( \SO(2)\).
        \item Tous les éléments de \( \SO(2)\) sont des rotations.
    \end{itemize}

    La proposition \ref{PROPooTFNSooFjiWHG} nous indique que toute rotation de \( \eR^2\) centrée en \( (0,0)\) est de la forme \( R_0(\theta)\), c'est-à-dire a une matrice de la forme
    \begin{equation}        \label{EQooSJNBooMPIRZS}
        \begin{pmatrix}
            \cos(\theta)    &   -\sin(\theta)    \\
            \sin(\theta)    &   \cos(\theta)
        \end{pmatrix}.
    \end{equation}
    Donc toute rotation est dans \( \SO(2)\).

    D'autre part, le lemme \ref{LEMooHRESooQTrpMz} indique que tout élément de \( \SO(2)\) a, dans la base canonique, une matrice de la forme \eqref{EQooSJNBooMPIRZS}. Le lemme \ref{DEFooADTDooKIZbrw} nous indique alors que c'est une rotation.
\end{proof}

\begin{proposition}         \label{PROPooOTIVooZpvLnb}
    Si \( r\) est une rotation de \( \eR^2\) centrée en \( (0,0)\), il existe un unique \( \theta\in\mathopen[ 0 , 2\pi \mathclose[\) tel que \( r=R_0(\theta)\).
\end{proposition}

\begin{proof}
    Soit une rotation \( r\) autour de \( (0,0)\). Le corolaire \ref{CORooVYUJooDbkIFY} nous dit qu'il existe \( \theta\in \eR\) tel que
    \begin{equation}
        r=R_0(\theta)=\begin{pmatrix}
            \cos(\theta)    &   -\sin(\theta)    \\ 
            \sin(\theta)    &   \cos(\theta)    
        \end{pmatrix}.
    \end{equation}
    Nous avons identifié l'application linéaire à sa matrice. L'élément \( \big( \cos(\theta), \sin(\theta) \big)\) est dans \( S^1\), et il existe donc, par la proposition \ref{PROPooKSGXooOqGyZj}, un unique \( t\in \mathopen[ 0 , 2\pi \mathclose[\) tel que \( \cos(t)=\sin(\theta)\) et \( \sin(t)=\sin(\theta)\). Pour ce \( t\) nous avons alors
        \begin{equation}
        r=R_0(\theta)=\begin{pmatrix}
            \cos(t)    &   -\sin(t)    \\ 
            \sin(t)    &   \cos(t)    
        \end{pmatrix}.
        \end{equation}
\end{proof}

\begin{proposition}     \label{PROPooISUCooRYJcwo}
    Nous avons la formule suivante pour la composition :
    \begin{equation}
        R_0(\alpha)\circ R_0(\beta)=R_0(\alpha+\beta).
    \end{equation}
\end{proposition}

\begin{proof}
    Par définition de \( R_0(\theta)\), dans la base canonique de \( \eR^2\), la composition se calcule avec le produit suivant, en utilisant les formules du lemme \ref{LEMooJAWBooJGfZIL} :
    \begin{subequations}
        \begin{align}
            \begin{pmatrix}
                \cos(\alpha)    &   -\sin(\alpha)    \\ 
                \sin(\alpha)    &   \cos(\alpha)    
            \end{pmatrix}&\begin{pmatrix}
                \cos(\beta)    &   -\sin(\beta)    \\ 
                \sin(\beta)    &   \cos(\beta)    
            \end{pmatrix}\\
            &=\begin{pmatrix}
                \cos(\alpha)\cos(\beta)  -\sin(\alpha)\sin(\beta)  &  -\cos(\alpha)\sin(\beta)-\sin(\alpha)\cos(\beta)     \\ 
                \sin(\alpha)\cos(\beta)+\cos(\alpha)\sin(\beta)    &   -\sin(\alpha)\sin(\beta)+\cos(\alpha)\cos(\beta)    
            \end{pmatrix}\\
            &=\begin{pmatrix}
                \cos(\alpha+\beta)    &   -\sin(\alpha+\beta)    \\ 
                \sin(\alpha+\beta)    &   \cos(\alpha+\beta)    
            \end{pmatrix}.
        \end{align}
    \end{subequations}
    Donc dans la base canonique, la matrice de \( R_0(\alpha)R_0(\beta)\) est celle de \( R_0(\alpha+\beta)\).
\end{proof}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Rotation et application affine}
%---------------------------------------------------------------------------------------------------------------------------

Nous considérons à nouveau la définition \ref{DEFooUAWZooXcMKve} d'une application affine ainsi que sa décomposition en application linéaire et translation donnée par le lemme \ref{LEMooYJCDooOGAHkF}. Nous voyons maintenant comment ces choses se mettent dans le cas d'une rotation non centrée en l'origine.

\begin{example}
    Soit \( A\in \eR^2\) ainsi qu'une rotation \( f\) autour de \( A\), c'est-à-dire une composition de deux symétries dont les axes se coupent en \( A\)\footnote{Voir la définition \ref{DEFooFUBYooHGXphm}.}. Nous allons extraire de \( f\) la partie linéaire définie en \ref{LEMooYJCDooOGAHkF}.

    Il existe des axes \( \ell_1\) et \( \ell_2\) tels que \( \ell_1\cap\ell_2=\{ A \}\) et tels que
    \begin{equation}
        f=s_{\ell_1}\circ s_{\ell_2}.
    \end{equation}
    En utilisant le lemme \ref{LEMooSMMMooAqsHWb},
    \begin{equation}
        f=t_A\circ s_{t^{-1}_A(\ell_1)}\circ t_A^{-1}\circ t_A\circ s_{t_A^{-1}(\ell_2)}\circ t_A^{-1}=t_A\circ s_{t^{-1}_A(\ell_1)}\circ s_{t_A^{-1}(\ell_2)}\circ t_A^{-1}.
    \end{equation}
    Vu que \( A\in\ell_i\), nous avons \( O=(0,0)\in t_A^{-1}(\ell_i)\). Donc les axes \( t_A^{-1}(\ell_1)\) et \( t_A^{-1}(\ell_2)\) se coupent en \( O\) et nous pouvons écrire
    \begin{equation}        %TODOooEZCRooAQsRkZ
        f=t_A\circ R\circ t_A^{-1}
    \end{equation}
    où \( R\) est une rotation centrée en \( O\); donc une application linéaire par la proposition \ref{PROPooTFNSooFjiWHG}.

    Nous avons
    \begin{subequations}
        \begin{align}
            f(x)&=(t_A\circ R\circ t_A^{-1})(x)\\
            &=(t_A\circ R)(x-A)\\
            &=t_A\big( R(x)-R(A) \big)\\
            &=R(x)+t_{R(A)+A}\\
            &=(t_{R(A)+A}\circ R)(x).
        \end{align}
    \end{subequations}
    Donc 
    \begin{equation}
        f=t_{R(A)+A}\circ R.
    \end{equation}
    Il est maintenant aisé de montrer que \( R\) est la partie linéaire de \( f\). Pour tout \( M,x\in \eR^2\) nous avons
    \begin{subequations}
        \begin{align}
            f(M+x)&=R(M+x)+R(A)+A\\
            &=R(M)+R(x)+R(A)+A\\
            &=R(x)+f(M).
        \end{align}
    \end{subequations}
    Donc ok pour la formule
    \begin{equation}
        f(M+x)=R(x)+f(M)
    \end{equation}
    et \( R\) est la partie linéaire de \( f\), voir la définition \ref{LEMooYJCDooOGAHkF}.
\end{example}

\begin{lemma}[\cite{MonCerveau}]        \label{LEMooUKEVooAEWvlM}
    Tout sous-groupe fini de \( \SO(2)\) est cyclique.
\end{lemma}

\begin{proof}
    Soit uns sous-groupe fini \(G\) de \( \SO(2)\).  Nous savons que \( \SO(2)\) est isomorphe à \( \gU(1)\) par le corolaire~\ref{CORooGGVUooLQYGET}, et en bijection avec \( \mathopen[ 0 , 2\pi \mathclose[\). Vu que \( G\) est fini, l'ensemble \( G\setminus\{ e \}\) il possède, dans \( \mathopen[ 0 , 2\pi \mathclose[\) un élément minimum non nul. Soit \( g_0\) ce minimum.

        Soit un élément \( g_1\) de \( G\) qui ne serait ni l'identité ni un multiple de \( g_0\). En particulier tous les nombres du type \( g_1-kg_0\) sont dans \( G\) (l'image de \( G\) dans \( \mathopen[ 0 , 2\pi \mathclose[\) en fait). Si \( g_1\) n'est pas un multiple de \( g_0\), il n'en reste pas moins que \( g_1=\lambda g_0\); alors en prenant pour \( k\) la partie entière de \( \lambda\), l'élément \( g_1-kg_0\) est plus petit que \( g_0\). Contradiction.
\end{proof}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Angle entre deux droites}
%---------------------------------------------------------------------------------------------------------------------------

Avant d'aborder la classification des isométries, nous devons parler de l'angle entre deux droites. Si \( \ell_1\) et \( \ell_2\) sont deux droites, alors il est bien clair deux angles peuvent prétendre être «l'angle entre \( \ell_1\) et \( \ell_2\)». De plus chacun de ces deux angles sont doubles parce que si \( \alpha\) peut prétendre être l'angle entre \( \ell_1\) et \( \ell_2\), alors \( -\alpha\) peut également prétendre.

\begin{remark}
    Nous ne parlons pas de l'angle entre \( \ell_1\) et \( \ell_2\) mais bien de l'angle \emph{de} \( \ell_1\) \emph{à} \( \ell_2\). L'ordre des droites est important.
\end{remark}

\begin{normaltext}
    Pour la suite, \( R_O(\alpha)\) est la rotation d'angle \( \alpha\) autour du point \( O\) tandis que \( R(\alpha)\) est la rotation d'angle \( \alpha\) autour de l'origine. 
\end{normaltext}

\begin{proposition}[\cite{ooGEXYooMTrOdH}]      \label{PROPooDWIMooQPkobw}
    Si \( u\) et \( v\) sont des vecteurs unitaires\footnote{De norme \( 1\).} de \( \eR^2\) alors il existe une unique rotation\footnote{Définition~\ref{DEFooFUBYooHGXphm}.} \( f\) telle que \( f(u)=v\).
\end{proposition}

\begin{proof}
    C'est la proposition~\ref{PROPooNXJKooEDOczh} appliquée à \( O=(0,0)\).
\end{proof}

\begin{remark}
    Notons l'unicité. Nous ne faisons pas de différences entre \( R_{\theta}\) et \( R_{\theta+2\pi}\) et les autres \( R_{\theta+2k\pi}\). En particulier si une rotation \( T\) est donnée, dire «\( T=R_{\theta}\)» ne définit pas un nombre \( \theta\) de façon univoque. Par contre ça définit une classe modulo \( 2\pi\), c'est-à-dire un élément \( \theta\in \eR/2\pi\).

    Nous avons déjà défini le groupe \( \SO(2)\) en la définition~\ref{DEFooJLNQooBKTYUy} et nous avons déterminé ses matrices dans \( \eR^2\) en le lemme~\ref{LEMooHRESooQTrpMz}.
\end{remark}



%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Angle orienté}
%---------------------------------------------------------------------------------------------------------------------------

La proposition~\ref{PROPooDWIMooQPkobw} donne une application
\begin{equation}
    T\colon S^1\times S^1\to \SO(2).
\end{equation}
Et nous avons une relation d'équivalence sur \( S^1\times S^1\) donnée par \( (u,v)\sim(u',v')\) si et seulement si il existe \( g\in\SO(2)\) telle que \( g(u)=u'\) et \( g(v)=v'\).

\begin{definition}[Angle orienté\cite{ooGEXYooMTrOdH}]      \label{DEFooVBKIooWlHvod}
    Les classes de \( S^1\times S^1\) pour cette relation d'équivalence sont les \defe{angles orientés de vecteurs}{angle!orienté de vecteurs}. Nous notons \( [u,v]\) la classe de \( (u,v)\).
\end{definition}

\begin{proposition}     \label{PROPooIWJQooGQJBWR}
    Nous avons \( T(u,v)=T(u',v')\) si et seulement si \( (u,v)\sim(u',v')\).
\end{proposition}

\begin{proof}
    En utilisant la commutativité du groupe \( \SO(2)\) nous avons équivalence entre les affirmations suivantes :
    \begin{itemize}
        \item \( (u,v)\sim (u',v')\)
        \item \( T(u,u')=T(v',v')\)
        \item \( T(u,u')\circ T(u',v)=T(v,v')\circ T(u',v)\)
        \item
            \( T(u,v)=T(u',v')\).
    \end{itemize}
\end{proof}

\begin{proposition}
    Nous avons une bijection
    \begin{equation}
        \begin{aligned}
            S\colon \frac{ S^1\times S^1 }{ \sim }&\to \SO(2) \\
            [u,v]&\mapsto T(u,v).
        \end{aligned}
    \end{equation}
\end{proposition}

\begin{proof}
    En plusieurs points.
    \begin{subproof}
    \item[\( S\) est bien définie]
        En effet si \( [u,v]=[z,t]\) alors \( T(u,v)=T(z,t)\).
    \item[Injectif]
        Si \( S[u,v]=S[z,t]\) alors \( T(u,v)=T(z,t)\), qui implique \( (u,v)\sim (z,t)\) par la proposition~\ref{PROPooIWJQooGQJBWR}.
    \item[Surjectif]
        Nous avons \( R_{\theta}=T(u,R_{\theta}u)\).
    \end{subproof}
\end{proof}

\begin{definition}[Somme d'angles orientés\cite{ooGEXYooMTrOdH}]
    Si \( [u,v]\) et \( [z,t]\) sont des angles orientés, nous définissons la somme par
    \begin{equation}
        [u,v]+[z,t]=S^{-1}\Big( S[u,v]\circ S[z,t] \Big).
    \end{equation}
\end{definition}

\begin{lemma}       \label{LEMooWISVooYsStJp}
    Quelques propriétés des angles plats liées à la somme.
    \begin{enumerate}
        \item
            \( (S^1\times S^1)/\sim\) est un groupe commutatif.
        \item       \label{ITEMooBKTFooWbEvIU}
            Relations de Chasles :
            \begin{equation}
                [u,v]+[v,w]=[u,w].
            \end{equation}
        \item
            \( -[u,v]=[v,u]\).
    \end{enumerate}
\end{lemma}

\begin{proof}
    Pour la relation de Chasles, ça se base sur la propriété correspondante sur \( T\) :
    \begin{subequations}
        \begin{align}
            [u,v]+[v,w]&=S^{-1}\Big( T(u,v)\circ T(v,w) \Big)\\
            &=S^{-1}\big( T(u,w) \big)\\
            &=[u,w].
        \end{align}
    \end{subequations}
    Pour l'inverse, la vérification est que
    \begin{equation}
        [u,v]+[v,u]=[u,u]=0.
    \end{equation}
\end{proof}

\begin{definition}      \label{DEFooFLGNooCZUkHY}
    La \defe{mesure}{mesure!angle entre vecteurs} de l'angle orienté \( [u,v]\) est \( [\theta]_{2\pi}\) si \( T[u,v]=R_{\theta}\).
\end{definition}
Notons dans cette définition qu'écrire \( T[u,v]=R_{\theta}\) dans \( \SO(2)\) ne définit pas \( \theta\), mais seulement sa classe modulo \( 2\pi\). C'est pour cela que la mesure de l'angle orienté n'est également définie que modulo \( 2\pi\).

Pour la suite nous allons nous intéresser à des vecteurs qui ont, dans l'idée, un point de départ et un point d'arrivée. Si \( A,B\in \eR^2\) nous notons
\begin{equation}
    \vect{ AB }=\frac{ B-A }{ \| B-A \| }.
\end{equation}
C'est le vecteur unitaire dans la direction «de \( B\) vers $A$».

\begin{theorem}[Théorème de l'angle inscrit\cite{ooRGSCooNgALYH}]       \label{THOooQDNKooTlVmmj}
    Soit un cercle \( \Gamma\) de centre \( O\) et trois points distincts \( A,B,M\in \Gamma\). Alors
    \begin{equation}
        2(\vect{ MA },\vect{ MB })\in (\vect{ OA },\vect{ OB })_{2\pi}
    \end{equation}
    où l'indice \( 2\pi\) indique la classe modulo \( 2\pi\).
\end{theorem}

\begin{proof}
    Le triangle \( MOA\) est isocèle en \( O\), donc les angles à la base sont égaux. Et de plus la somme des angles est dans \( [\pi]_{2\pi}\). Bon, entre nous, nous savons que la somme des angles est exactement \( \pi\), mais comme nous n'avons pas défini les angles autrement que modulo \( \pi\), nous ne pouvons pas dire mieux. Donc
    \begin{equation}
        2(\vect{ AB },\vect{ AO })+(\vect{ OB },\vect{ OA })\in [\pi]_{2\pi}.
    \end{equation}
    Il faut être sûr de l'orientation de tout cela. Le nombre \( (\vect{ AB },\vect{ AO })\) est l'angle qui sert à amener \( \vect{ AB }\) sur \( \vect{ AO }\). Vu que nous l'avons choisi dans le sens trigonométrique, il faut bien prendre les autres dans le sens trigonométrique et utiliser \( (\vect{ OA }, \vect{ OB })\) et non \( (\vect{ OB },\vect{ OA })\).

\begin{center}
   \input{auto/pictures_tex/Fig_YQIDooBqpAdbIM.pstricks}
\end{center}

De la même manière sur le triangle \( MOB\) nous écrivons
\begin{equation}
    2(\vect{ MB },\vect{ MO })+(\vect{ OM },\vect{ OB })\in[\pi]_{2\pi}.
\end{equation}
Nous faisons la différence entre les deux équations en remaquant que la différence de deux représentants de \( [\pi]_{2\pi}\) est un représentant de \( [0]_{2\pi}\) et en en nous souvenant que \( -(\vect{ MB },\vect{ MO })=(\vect{ MO },\vect{ MB })\) et les relations de Chasles du lemme~\ref{LEMooWISVooYsStJp}\ref{ITEMooBKTFooWbEvIU} nous avons :
\begin{equation}
    2(\vect{ MA },\vect{ MB })+(\vect{ OB },\vect{ OA })\in[0]_{2\pi}.
\end{equation}
\end{proof}

\begin{normaltext}
    Comment exprimer le fait qu'un angle orienté soit égal à \( \theta\) modulo \( \pi\) alors que les angles orientés sont des classes modulo \( 2\pi\) ? Nous ne pouvons certainement pas écrire
    \begin{equation}
        (u,v)=[\theta]_{\pi}
    \end{equation}
    parce que \( (u,v)\) est un élément de \( S^1\times S^1\) alors que \( [\theta]_{\pi}\) est un ensemble de nombres. Nous pouvons écrire
    \begin{equation}
        [u,v]\subset [\theta]_{\pi}.
    \end{equation}
    C'est cohérent parce que nous avons des deux côtés des ensembles de nombres. Les opérations permises sont l'égalité ou l'inclusion. L'égalité entre les deux ensembles n'est pas possible parce que la différence minimale ente deux éléments dans \( [u,v]\) est \( 2\pi\) alors que celle dans \( [\theta]_{\pi}\) est \( \pi\).

    Si \( u\) et \( v\) forment un angle droit, nous avons
    \begin{equation}
        [u,v]=\{ \frac{ \pi }{2}+2k\pi \}_{k\in \eZ}.
    \end{equation}
    Et cela est bien un sous-ensemble de \( [\pi/2]_{\pi}\).

    Pour exprimer que la différence entre deux angles orientés diffèrent de \( \pi\) nous devrions écrire :
    \begin{equation}
        [u,v]\subset[a,b]_{\pi}
    \end{equation}
    où le membre de droite signifie la classe modulo \( \pi\) d'un représentant de \( [a,b]\).

    Nous allons cependant nous permettre d'écrire
    \begin{equation}
        [u,v]=[a,b]_{\pi}
    \end{equation}
    voire carrément
    \begin{equation}
        (u,v)=(a,b)_{\pi}.
    \end{equation}
    Cette dernière égalité devant être comprise comme voulant dire que l'angle pour passer de \( u\) à \( v\) est soit le même que celui pour alle de \( a\) à \( b\) soit ce dernier plus \( \pi\).
\end{normaltext}

\begin{theorem}[\cite{ooRGSCooNgALYH}]      \label{THOooUDUGooTJKDpO}
    Soient \( 4\) points distincts du plan \( A,B,C,D\). Ils sont alignés ou cocycliques\footnote{C'est-à-dire sur un même cercle.} si et seulement si
    \begin{equation}
        (\vect{ CA },\vect{ CB })=(\vect{ DA },\vect{ DB })_{\pi}.
    \end{equation}
\end{theorem}

Nous allons seulement démontrer l'implication directe.
\begin{proof}
    Si les quatre points sont alignés nous avons \( [\vect{ CA },\vect{ CB }]=[0]_{2\pi}\) et \( [\vect{ DA },\vect{ DB }]=[0]_{2\pi}\). En particulier nous avons
    \begin{equation}
        [\vect{ CA },\vect{ CB }]=[\vect{ DA },\vect{ DB }]
    \end{equation}
    et a fortiori l'égalité modulo \( \pi\) au lieu de \( 2\pi\).

    Nous nous relâchons en termes de notations. Si les quatre points sont cocycliques, nous pouvons utiliser le théorème de l'angle inscrit~\ref{THOooQDNKooTlVmmj} dans les triangles \( ABC\) et \( ADB\) :
    \begin{subequations}
        \begin{align}
            2(\vect{ CA },\vect{ CB })=(\vect{ OA },\vect{ OB })_{2\pi}\\
            2(\vect{ DA },\vect{ DB })=(\vect{ OA },\vect{ OB })_{2\pi},
        \end{align}
    \end{subequations}
    ce qui donne \(  2(\vect{ CA },\vect{ CB })=2(\vect{ DA },\vect{ DB })_{2\pi}  \) et donc
    \begin{equation}
        (\vect{ CA },\vect{ CB })=(\vect{ DA },\vect{ DB })_{\pi}.
    \end{equation}

    Comme annoncé, nous ne faisons pas la preuve dans l'autre sens; elle peut être trouvée dans~\cite{ooRGSCooNgALYH}.
\end{proof}

\begin{example}     \label{EXooOXAAooZMdDfP}
    À propos de groupe engendré et de générateur\footnote{Définition \ref{DEFooWMFVooLDqVxR} et \ref{DefHFJWooFxkzCF}}. Soit \( G\) le groupe des rotations d'angle\footnote{Voir la définition \ref{DEFooFLGNooCZUkHY}.} \( k\pi/5\) (avec \( k \) entier). Ce groupe est constitué des \og{} dixièmes de tour \fg{}, puisque \( \frac{k\pi} 5 = \frac{2k\pi}{10}.\)
    
     La rotation d'angle \( 2 \pi/5\)  n'est pas génératrice parce qu'elle n'engendre que des \og{} cinquièmes de tour \fg{} : \( 4 \pi/5\), \( 6 \pi/ 5\),\( 8\pi/5\) et l'identité.
     
     Par contre, la rotation d'angle \( \pi/5\) est génératrice.
\end{example}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Angles et nombres complexes}
%---------------------------------------------------------------------------------------------------------------------------
\label{SUBSECooKNUVooUBKaWm}

Les nombres complexes peuvent être repérés par une norme et un angle, ce qui en fait un terrain propice à l'utilisation des angles orientés. Nous en ferons d'ailleurs usage dans \( \hat\eC=\eC\cup\{ \infty \}\) pour parler d'alignement, de cocyclicité et de birapport dans la proposition~\ref{PROPooSGCJooLnOLCx}.

Soient deux éléments \( z_1,z_2\in \eC\). Nous les écrivons sous la forme \( z_1=r_1 e^{i\theta_1}\) et \( z_2=r_2 e^{i\theta_2}\); remarquons que cela ne définit \( \theta_i\) qu'à \( 2\pi\) près. Nous avons
\begin{equation}
    [z_1,z_2]=[\theta_2-\theta_1]_{2\pi}.
\end{equation}

Soient maintenant \( a,b,c,d\in \eC\). Nous écrivons \( \vect{ ab }\) le vecteur unitaire dans le sens «de \( a\) vers \( b\)», c'est-à-dire un multiple positif bien choisi du nombre \( b-a\). Nous notons \( \theta_{ab}\) l'argument du nombre complexe \( b-a\), et nous avons encore
\begin{equation}
    [\vect{ ab },\vect{ cd }]=[\theta_{ab}-\theta_{cd}].
\end{equation}

Avec toutes ces notations, ce qui est bien est que les produits et quotients de nombres complexes se comportent très bien par rapport aux angles : l'argument de \( a/b\) est \( \theta_a-\theta_b\) et en particulier l'argument de
\begin{equation}
    \frac{ a-b }{ c-d }
\end{equation}
est dans la classe de l'angle orienté
\begin{equation}
    [\vect{ ba },\vect{ dc }].
\end{equation}


\begin{definition}      \label{DEFooUPUUooKAPFrh}
    Soient trois points \( A,O,B\in \eR^2\). Voici comment nous définissons l'angle \( \widehat{AOB}\); informelement c'est l'angle de la rotation qui fait aller de \( A\) vers \( B\).
    \begin{itemize}
        \item Nous nous mettons en l'origine : \( A'=A-O\) et \( B'=B-O\).
        \item Nous normalisons : \( A''=A'/\| A' \|\) et \( B''=B'/\| B' \|\).
        \item Soit \( f\), l'unique rotation telle que \( f(A'')=B''\) (proposition \ref{PROPooDWIMooQPkobw}).
        \item Soit \( \theta\) l'unique élément de \( \mathopen[ 0 , 2\pi \mathclose[\) tel que la matrice de \( f\) dans la base canonique soit
    \begin{equation}
        \begin{pmatrix}
            \cos(\theta)    &   -\sin(\theta)    \\
            \sin(\theta)    &   \cos(\theta)
        \end{pmatrix}
    \end{equation}
    par la proposition \ref{PROPooOTIVooZpvLnb}.
\item L'angle \( \widehat{AOB}\) est ce nombre.
    \end{itemize}
\end{definition}

Nous voyons que l'angle est toujours un nombre entre \( 0\) et \( 2\pi\). Par abus de notation, nous admettrons de temps en temps de parler d'angle en-dehors de cet intervalle.

\begin{lemmaDef}        \label{DEFooEGKOooRPGOAs}
    Si \( \ell_1\) et \( \ell_2\) sont deux droites de \( \eR^2\) sécantes au point \( O\) et si \( x\in\ell_1\) n'est pas \( O\), alors il existe un unique \( \alpha\in \mathopen[ 0 , \pi \mathclose[\) tel que \( R_O(\alpha)x\in \ell_2\). La valeur de \( \alpha\) ne dépend pas du choix du point \( x\in \ell_1\).

        Cet angle \( \alpha\) est l'\defe{angle}{angle!entre deux droites} de \( \ell_1\) à \( \ell_2\).
\end{lemmaDef}


\begin{proposition}[\cite{MonCerveau}]      \label{PROPooKVSHooRODGWE}
    Les angles sont invariants sous les translations. 

    Plus précisément, si \( A,B,S,v\in \eR^2\), alors
    \begin{equation}
        \reallywidehat{T_v(A)T_v(S)T_v(B)}=\reallywidehat{ASB}
    \end{equation}
    où \( T_v(X)=X+v\).
\end{proposition}

\begin{proof}
    Nous notons \( X_v=X+v\). Nous avons \( A'_v=A_v-S_v=(A+v)-(S+v)=A-S=A''\). Donc les vecteurs \( A''\) et \( B''\) à partir desquels est calculé \( \widehat{ASB}\) sont les mêmes que les vecteurs \(  A_v'' \) et \( B''_v\) qui servent à calculer \( \reallywidehat{T_v(A)T_v(S)T_v(B)}\).
\end{proof}

\begin{proposition}[\cite{MonCerveau}]      \label{PROPooYWKJooRjybUJ}
    Les angles sont invariants par rotations, c'est-à-dire que si \( A,B,S\in \eR^2\) et si \( R_{\theta}\) est une rotation, alors
    \begin{equation}
        \reallywidehat{ASB}=\reallywidehat{R_{\theta}(A)R_{\theta}(S)R_{\theta}(B)}.
    \end{equation}
\end{proposition}

\begin{proof}
    Pour être plus concis, nous écrivons \( A_{\theta}\) for \( R_{\theta}(A)\) et de même pour \( B\) et \( S\). Afin de calculer l'angle \reallywidehat{R_{\theta}(A)R_{\theta}(S)R_{\theta}(B)}, nous définissons
    \begin{subequations}
        \begin{numcases}{}
            A'_{\theta}=A_{\theta}-S_{\theta}\\
            S'_{\theta}=0\\
            B'_{\theta}=B_{\theta}-S_{\theta}.
        \end{numcases}
    \end{subequations}
    et
    \begin{subequations}
        \begin{numcases}{}
            A''_{\theta}=\frac{ A_{\theta}-S_{\theta} }{ \| A_{\theta}-S_{\theta} \| }\\
            B''_{\theta}=\frac{ B_{\theta}-S_{\theta} }{ \| B_{\theta}-S_{\theta} \| }.
        \end{numcases}
    \end{subequations}
    Par définition, l'angle est le \( \alpha\) tel que \( R_{\alpha}(A_{\theta}'')=B''_{\theta}\). Nous devons prouver que le même \( \alpha\) vérifie \( R_{\alpha}(A'')=B''\).

    Le fait que \( R_{\theta}\) soit une isométrie nous donne déjà
    \begin{equation}
        \| R_{\theta}(A)-R_{\theta}(B) \|=\| A-B \|.
    \end{equation}
    Ensuite, la relation de définition de \( \alpha\) s'écrit
    \begin{equation}
        \frac{ R_{\alpha}R_{\theta}(A)-R_{\alpha}R_{\theta}(S) }{ \| A_{\theta}-S_{\theta} \| }=\frac{ R_{\theta}(B)-R_{\theta}(S) }{ \| B_{\theta}-S_{\theta} \| }.
    \end{equation}
    Vu que $R_{\alpha}$ et \( R_{\theta}\) commutent, nous avons
    \begin{equation}
        R_{\theta}\frac{ R_{\alpha}(A)-R_{\alpha}(B) }{ \| A-S \| }=R_{\theta}\frac{ B-S }{ \| B-S \| },
    \end{equation}
    et comme \( R_{\theta}\) est inversible, cela donne \( R_{\alpha}(A'')=B''\).
\end{proof}

\begin{lemma}[\cite{MonCerveau}]        \label{LEMooJLHGooQIpKIE}
    Soit \( A\in \eR^2\) et une droite \( \ell_1\). Soit \( \ell_2\) une droite passant par \( A\) et intersectant \( \ell_1\) en \( O\). Alors
    \begin{equation}
        \sigma_{\ell_1}(A)=R_O(-2\alpha)A
    \end{equation}
    où \( \alpha\) est l'angle de \( \ell_1\) à \( \ell_2\).
\end{lemma}

\begin{proof}
    Nous allons utiliser des coordonnées autour de \( O\). Il existe un vecteur \( v\) tel que
    \begin{equation}
        A=O+v
    \end{equation}
    Par définition de l'angle \( \alpha\)\footnote{Définition \ref{DEFooEGKOooRPGOAs}.}, la droite \( \ell_2\) s'obtient par rotation d'angle \( \alpha\) depuis la droite \( \ell_1\). Donc le point
    \begin{equation}
        B=R_O(-\alpha)A
    \end{equation}
    est sur \( \ell_1\).

    Nous allons prouver que le point
    \begin{equation}
        D=R_O(-2\alpha)A
    \end{equation}
    est \( D=\sigma_{\ell_1}A\).

    Nous commençons par montrer que la droite \( (DA)\) est perpendiculaire à \( \ell_1\), c'est-à-dire que
    \begin{equation}
        (D-A)\cdot (B-O)=0.
    \end{equation}
    En utilisant le fait que
    \begin{equation}
        R_O(\alpha)(O+X)=O+R(\alpha)X,
    \end{equation}
    nous avons
    \begin{equation}
        D-A=R_O(-2\alpha)(O+v)-(O+v)=O+R(-2\alpha)v-O-v=R(-2\alpha)v-v
    \end{equation}
    et de la même façon,
    \begin{equation}
        B-O=R(-\alpha)v.
    \end{equation}
    Notons que tous les \( O\) se sont simplifiés et qu'il ne reste que des rotations usuelles. En utilisant le fait que \( R(\alpha)\) est une isométrie, nous pouvons alors calculer
    \begin{subequations}
        \begin{align}
            (D-A)\cdot (B-O)&=\langle R(-2\alpha)v-v, R(-\alpha)v\rangle \\
            &=\langle R(-\alpha)v-R(\alpha)v, v\rangle.
        \end{align}
    \end{subequations}
    En utilisant la matrice de rotation du lemme \ref{LEMooHRESooQTrpMz} nous trouvons
    \begin{equation}
        \big( R(-\alpha)-R(\alpha) \big)v=\begin{pmatrix}
            2\sin(\alpha)v_2    \\
            -2\sin(\alpha)v_1
        \end{pmatrix}
    \end{equation}
    et donc
    \begin{equation}
        \langle  \big( R(-\alpha)-R(\alpha) \big)v  , v\rangle =0.
    \end{equation}

    Le point \( D\) est bien sûr la droite perpendiculaire à \( \ell_1\) et passant par \( A\). Mais vu que \( D\) est obtenu à partir de \( A\) par une rotation, le point \( D\) est également sur le cercle de rayon \( \| OA \|\) et centré en \( O\). Ce cercle possède exactement deux intersections avec cette droite. Le premier est \( A\) et le second est \( \sigma_{\ell_1}(A)\). Vu que \( D\) n'est pas \( A\), nous avons \( D=\sigma_{\ell}(A)\).
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Classification}
%---------------------------------------------------------------------------------------------------------------------------

\begin{theorem}[\cite{ooZYLAooXwWjLa}]      \label{THOooRORQooTDWFdv}
    Toute isométrie du plan \( (\eR^2,d)\) est une composition d'au plus \( 3\) réflexions.
\end{theorem}

\begin{proof}
    Encore une fois nous décomposons la preuve en fonction du nombre de points fixes.
    \begin{subproof}
        \item[Si \( f\) n'a pas de points fixes]
            Soit \( x\in \eR^2\). Nous considérons le segment \( [f,f(x)]\) et nous nommons \( l\) sa médiatrice. Par construction, \( f(x)=\sigma_l(x)\). Nous posons \( g=\sigma_l\circ f\), et nous avons
            \begin{equation}
                g(x)=x.
            \end{equation}
            Donc nous avons \( f=\sigma_l\circ g\) avec \( x\in\Fix(g)\).
        \item[Si \( f\) a un unique point fixe]
            Soit \( x\) cet unique point fixe. Soit \( y\neq x\) et \( l\) la médiatrice de \( [y,f(y)]\). En posant \( g=\sigma_l\circ f\) nous avons
            \begin{equation}
                g(y)=y
            \end{equation}
            et \( g(x)=x\) parce que
            \begin{equation}
                d\big( x,f(y) \big)=d\big( f(x),f(y) \big)=d(x,y),
            \end{equation}
            ce qui donne que \( x\) est à égale distance de \( y\) et de \( f(y)\), c'est-à-dire que \( x\in l\) et par conséquent \( g(x)=(\sigma_l\circ f)(x)=\sigma_l(x)=x\).

            Donc \( g\) fixe \( x\) et \( y\) et donc toute la droite \( (xy)\).
        \item[Si \( f\) fixe une droite]
            Soit \( l\) une droite fixée par \( f\), et soient \( x,y\in l\) et \( z\notin l\) (avec \( x\neq y\)). Le fait que \( x\) et \( y\) soient des points fixes de \( f\) implique
            \begin{subequations}
                \begin{numcases}{}
                    d\big( x,f(z) \big)=d(x,z)\\
                    d\big( y,f(z) \big)=d(y,z)
                \end{numcases}
            \end{subequations}
            ce qui signifie que \( f(z)\) est sur l'intersection des deux cercles\footnote{L'intersection existe pare que \( d(x,z)+d(y,z)>d(x,y)\).} \( S\big( x,d(x,z) \big)\) et \( S\big( y, d(y,z) \big)\), et comme ce sont deux cercles centrés sur la droite \( l\), les intersections sont liées par \( \sigma_l\). Autrement dit, les intersections sont \( z\) et \( \sigma_l(z)\).

            Si \( f(z)=z\) alors \( f\) fixe trois points non alignés et fixe dont \( \eR^2\), c'est-à-dire \( f=\id\).

            Si par contre \( f(z)=\sigma_l(z)\) alors les isométries \( f\) et \( \sigma_l\) coïncident sur trois points et coïncident donc partout par le corolaire~\ref{CORooZHZZooDgTzsW} : \( f=\sigma_l\).
        \item[Conclusion]

            Nous avons montré que si \( \Fix(f)\) a dimension \( m\), alors il existe une droite pour laquelle \( f=\sigma_l\circ g\) avec \( \dim\big( \Fix(g) \big)>m\). Donc il faux au maximum trois pas pour avoir \( \dim\big( \Fix(g) \big)=2\) c'est-à-dire pour avoir \( g=\id\).
    \end{subproof}
\end{proof}

\begin{definition}      \label{DEFooJEOYooNwYtuQ}
    Une \defe{réflexion glissée}{réflexion!glissée} est une transformation du plan de la forme \( \tau_v\circ\sigma_{\ell}\) où le vecteur \( v\) est parallèle à la droite \( \ell\).
\end{definition}

\begin{theorem}[\cite{ooZYLAooXwWjLa}]      \label{THOooVRNOooAgaVRN}
    Les isométries du plan \( (\eR^2,d)\) sont exactement
    \begin{enumerate}
        \item
            l'identité (composée de \( 0\) réflexions),
        \item
            les réflexions,
        \item
            les translations (composées de \( 2\) translations d'axes parallèles),
        \item
            les rotations (composées de \( 2\) réflexions d'axes non parallèles),
        \item
            les réflexions glissées (composées de \( 3\) réflexions)
    \end{enumerate}
\end{theorem}

\begin{proof}
    Nous savons déjà que \( f\in \Isom(\eR^2)\) est une composée de \( 0\), \( 1\), \( 2\) ou \( 3\) réflexions.
    \begin{subproof}
        \item[Zéro réflexions]
            Alors c'est l'identité. Ce n'est pas très profond.
        \item[Une réflexion]
            Alors \( f\) est une réflexion. Toujours pas très profond.
        \item[Deux réflexions]
            Soit \( f=\sigma_{\ell_1}\circ\sigma_{\ell_2}\). Maintenant ça s'approfondit un bon coup.

            Nous supposons d'abord que \( \ell_1\parallel\ell_2\). Dans ce cas nous allons prouver que \( f=\tau_{2v}\) où \( v\) est le vecteur perpendiculaire à \(  \ell_1 \) tel que \( \ell_1+v=\ell_2\). Nous allons utiliser le lemme~\ref{LEMooVOJLooCFgdNG} pour montrer que \( \sigma_{\ell_1}\circ\sigma_{\ell_2}=\tau_{2v}\). Nous avons
            \begin{subequations}
                \begin{align}
                    \ell_1=\ell_0+w\\
                    \ell_2=\ell_0+w+v
                \end{align}
            \end{subequations}
            où \( w\) est un vecteur perpendiculaire à \( \ell_1\) et \( \ell_0\) est la droite passant par l'origine et parallèle à \( \ell_1\) et \( \ell_2\). Avec cela,
            \begin{subequations}
                \begin{align}
                    (\sigma_{\ell_1}\circ\sigma_{\ell_2})(x)&=\sigma_{\ell_1}\big( \sigma_{\ell_0}(x)+2w \big)\\
                    &=\sigma_{\ell_0}\big( \sigma_{\ell_0}(x)+2w \big)+2(v+w)\\
                    &=x+\underbrace{\sigma_{\ell_0}(2w)}_{-2w}+2v+2w\\
                    &=x+2v.
                \end{align}
            \end{subequations}
            Donc si \( f\) est composée de deux réflexions d'axes parallèles, alors \( f\) est une translation.

            Toujours dans le cas où \( f\) est composée de deux réflexions, nous supposons que \( f=\sigma_{\ell_2}\circ\sigma_{\ell_1}\) avec \( \ell_1\) et \( \ell_2\) non parallèles. Nous notons \( O\) le point d'intersection, et nous allons voir que \( f=R_O(2\alpha)\) où \( \alpha\) est l'angle de \( \ell_1\) à \( \ell_2\) donné par le lemme~\ref{DEFooEGKOooRPGOAs}.

            Soit \( x\in \ell_1\). Alors
            \begin{equation}
                f(x)=\sigma_{\ell_2}(x),
            \end{equation}
            et le lemme~\ref{LEMooJLHGooQIpKIE} nous donne un moyen de calculer \( \sigma_{\ell_2}(x)\) parce que \( \ell_1\) est une droite passant par \( x\) et coupant \( \ell_1\) au point \( O\). Le lemme dit que \( \sigma_{\ell_2}(x)=R_O(2\alpha)\). Remarque : c'est bien \( 2\alpha\) et non \( -2\alpha\) parce qu'il s'agit de l'angle de \( \ell_2\) à \( \ell_2\); il y a inversion des numéros entre ici et l'énoncé du lemme.

            Nous avons donc bien \( f(x)=R_O(2\alpha)x\) pour \( x\in \ell_1\).

            Si \( y\in\ell_2\) alors
            \begin{equation}
                f(y)=\sigma_{\ell_2}\big( R_O(-2\alpha)y \big)
            \end{equation}
            Nous posons \( z=\sigma_{\ell_1}(y)=R_O(-2\alpha)y\). Soit la droite \( \ell_3\) passant par \( O\) et \( z\). Vu que \( R_O(2\alpha)z=y\in \ell_2\), l'angle de \( \ell_3\) à \( \ell_2\) est \( 2\alpha\). Par conséquent
            \begin{equation}
                \sigma_{\ell_2}(z)=R_O\big( -2\times (-2\alpha) \big)z=R_O(4\alpha)z=R_O(4\alpha)R_O(-2\alpha)y=R_O(2\alpha)y.
            \end{equation}

            Donc les transformations \( f\) et \( R_O(2\alpha)\) coïncident pour tous les points des droites \( \ell_1\) et \( \ell_2\), qui ne sont pas parallèles. Cela prouve que \( f=R_{O}(2\alpha)\).

        \item[Trois réflexions]
            Nous écrivons \( f=\sigma_{\ell_3}\circ\sigma_{\ell_2}\circ\sigma_{\ell_1}\). Nous allons transformer cela progressivement en une symétrie glissée en passant par plusieurs étapes :
            \begin{enumerate}
                \item       \label{ITEMooHVYCooPhFMiv}
                    \( f=\sigma_{\ell}\circ\tau_v\),
                \item       \label{ITEMooUKGLooFlCcjt}
                    \( f=\tau_v\circ\sigma_{\ell}\),
                \item       \label{ITEMooWUCWooZSjofe}
                    \( f=\tau_v\circ\sigma_{\ell} \) avec \( v\parallel\ell\).
            \end{enumerate}
            À chacune de ces étapes, \( v\) et \( \ell\) vont changer. La dernière est une réflexion glissée.

            Nous commençons par supposer \( \ell_2\parallel\ell_3\). Dans ce cas, \( \sigma_{\ell_3}\circ\sigma_{\ell_2}\) est une translation, comme nous l'avons déjà vu. Alors \( f= \tau_v\circ\sigma_{\ell_1}\) et nous sommes déjà dans le cas~\ref{ITEMooUKGLooFlCcjt}.

            Nous supposons que \( \ell_2\) n'est pas parallèle à \( \ell_3\). Dans ce cas, si \( O=\ell_2\cap\ell_3\) nous avons
            \begin{equation}
                \sigma_{\ell_3}\circ\sigma_{\ell_2}=R_O(2\alpha)
            \end{equation}
            où \( \alpha\) est l'angle de \( \ell_2\) à \( \ell_3\). En réalité tant que l'angle de \( \ell'_3\) à \( \ell'_2\) est \( \alpha\) nous avons
            \begin{equation}
                \sigma_{\ell'_3}\circ\sigma_{\ell'_2}= \sigma_{\ell_3}\circ\sigma_{\ell_2}=R_O(2\alpha).
            \end{equation}
            Nous choisissons \( \ell'_2\) parallèle à \( \ell_1\), de telle sorte à ce que \( \sigma_{\ell'_2}\circ\sigma_{\ell_1}\) soit une translation. Alors nous avons
            \begin{equation}
                f=\sigma_{\ell_3}\circ\sigma_{\ell_2}\circ\sigma_{\ell_1}=\sigma_{\ell_3}\circ\sigma_{\ell'_2}\circ\sigma_{\ell'_1}=\sigma_{\ell_3}\circ\tau_v.
            \end{equation}
            où \( v\) est le vecteur de la translation en question.

            Nous avons donc prouvé que toute composition de trois réflexions peut être écrite soit sous la forme~\ref{ITEMooHVYCooPhFMiv} soit sous la forme~\ref{ITEMooUKGLooFlCcjt}.

            Nous prouvons à présent que toute transformation de la forme~\ref{ITEMooHVYCooPhFMiv} peut être écrite sous la forme~\ref{ITEMooUKGLooFlCcjt}. Plus précisément nous allons prouver que si \( \ell\) est une droite, \( v\) un vecteur et \( \ell_0\) la droite parallèle à \( \ell\) passant par l'origine, alors
            \begin{equation}
                \sigma_{\ell}\circ\tau_v=\tau_{\sigma_{\ell_0}(v)}\circ\sigma_l
            \end{equation}
            D'abord nous savons que \( \sigma_{\ell}(x)=\sigma_{\ell_0}(x)+2w\) où \( w\) est le vecteur tel que \( \ell=\ell_0+w\). Ensuite c'est un simple calcul utilisant le fait que \( \sigma_{\ell_0}\) est linéaire :
            \begin{equation}
                (\sigma_{\ell}\circ\tau_v)(x)=\sigma_l(x+v)=\sigma_{\ell_0}(x)+\sigma_{\ell_0}(v)+2w,
            \end{equation}
            et
            \begin{equation}
                (\tau_{\sigma_{\ell_0}(v)}\circ\sigma_{\ell})(x)=\sigma_{\ell_0}(v)+\sigma_{\ell}(x)=\sigma_{\ell_0}(v)+\sigma_{\ell_0}(x)+2w.
            \end{equation}
            L'égalité est faite.

            Nous montrons maintenant que toute transformation de la forme~\ref{ITEMooUKGLooFlCcjt} peut être mise sous la forme~\ref{ITEMooWUCWooZSjofe}. Soit donc \( f=\tau_v\circ\sigma_{\ell}\) où \( v\) et \( \ell\) ne sont pas spécialement parallèles.

            Pour cela nous décomposons \( v=v_1+v_2\) avec \( v_1\perp \ell\) et \( v_2\parallel\ell\) et nous posons \( \ell'=\ell+\frac{ 1 }{2}v_1\). Nous montrons que
            \begin{itemize}
                \item \( \tau_v\circ\sigma_{\ell}=\tau_{v_2}\circ\sigma_{\ell'}\)
                \item \( v_2\parallel \ell'\).
            \end{itemize}
            Pour le deuxième point, \( v_2\parallel\ell\) et bien entendu \( \ell'\parallel\ell\). Donc \( v_2\parallel\ell'\).

            Soit \( \ell_0\) la droite parallèle à \(  \ell\) et \( \ell'\) et passant par l'origine. Soit aussi le vecteur \( w\) tel que \( \ell=\ell_0+w\). Alors nous avons
            \begin{subequations}
                \begin{numcases}{}
                    \sigma_{\ell}=\sigma_{\ell_0}+2w\\
                    \sigma_{\ell'}=\sigma_{\ell_0}+2w+v_1
                \end{numcases}
            \end{subequations}
            Nous avons
            \begin{equation}
                (\tau_v\circ\sigma_{\ell})(x)=v+\sigma_{\ell_0}(x)+2w
            \end{equation}
            et
            \begin{subequations}
                \begin{align}
                    (\tau_{v_2}\circ\sigma_{\ell'})(x)&=v_2+\sigma_{\ell_0}(x)+2w+v_1\\
                    &=\sigma_{\ell_0}(x)+v+2w
                \end{align}
            \end{subequations}
            où dans la dernière ligne, nous avons regroupé \( v_1+v_2=v\). Et voilà.
    \end{subproof}
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Classification des isométries de \( \eR\)}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}
    Soit \( x\in \eR\); nous notons \( \sigma_x\) la \defe{réflexion}{réflexion}\nomenclature[R]{\( \sigma_x\)}{réflexion par rapport à \( x\)} par rapport à \( x\), c'est-à-dire
    \begin{equation}
        \sigma_x(y)=2x-y.
    \end{equation}
\end{definition}

\begin{theorem}[\cite{ooZYLAooXwWjLa}]
    Toute isométrie de \( \eR\) est composée d'au plus \( 2\) réflexions. Plus précisément toute isométrie de \( \eR\) est dans une des trois catégories suivantes :
    \begin{itemize}
        \item l'identité (\( 0\) réflexions),
        \item les réflexions,
        \item les translations (\( 2\) réflexions)
    \end{itemize}
\end{theorem}

\begin{proof}
    Nous divisions la preuve en fonction du nombre de points fixés par l'isométrie \( f\in\Isom(\eR)\).
    \begin{subproof}
        \item[\( f\) fixe deux points distincts]
            Alors elle fixe l'espace affine engendrée par ces deux points par la proposition~\ref{PROPooVEEUooJQmmkN}. Donc \( f\) fixe tout \( \eR\) et est l'identité.
        \item[\( f\) fixe un unique point]
            Soit \( x\) l'unique point fixé par \( f\) et considérons \( y\neq x\). Vu que \( x=f(x)\) et que \( f\) est une isométrie,
            \begin{equation}
                d\big( x,f(y) \big)=d\big( f(x),f(y) \big)=d(x,y).
            \end{equation}
            Donc \( f(y)\) est à égale distance de \( x\) que \( y\). Autrement dit, \( f(y)\) est soit \( y\) soit \( \sigma_x(y)\). Mais comme \( x\) est unique point fixe, \( f(y)=\sigma_x(y)\). Ce raisonnement étant valable pour tout \( y\neq x  \) nous avons \( f=\sigma_x\).
        \item[\( f\) n'a pas de points fixes]
            Soient \( x\in \eR\) et \( y=\frac{ x+f(x) }{ 2 }\). Nous posons \( g=\sigma_y\circ f\). Alors \( x\) est un point fixe de \( g\) parce que
            \begin{equation}
                g(x)=\sigma_y\big( f(x) \big)=2y-f(x)=x.
            \end{equation}
            Donc soit \( g\) est l'identité soit \( g\) est une réflexion (par les points précédents). La possibilité \( g=\id\) est exclue parce que cela ferait \( f=\sigma_y\) alors que \( f\) n'a pas de points fixes. Donc \( g\) est une réflexion; et comme \( x\) est un point fixe de \( g\) nous avons \( g=\sigma_x\). Au final
            \begin{equation}
                f=\sigma_y\circ\sigma_x.
            \end{equation}
            Montrons que cela implique que \( f\) est une translation :
            \begin{equation}
                \sigma_y\sigma_x(z)=\sigma_y(2x-z)=2y-2x+z=z+2(y-x).
            \end{equation}
            Donc \( \sigma_y\circ\sigma_x\) est la translation de vecteur \( 2(y-x)\).
    \end{subproof}
\end{proof}


%---------------------------------------------------------------------------------------------------------------------------
\subsection{Isométries du tétraèdre régulier}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}
    Un polyèdre \defe{régulier}{régulier!polyèdre} est un polyèdre dont les faces sont des polygones réguliers identiques dont tous les sommets joignent le même nombre d'arrêtes.
\end{definition}

\begin{definition}
    Le \defe{tétraèdre}{tétraèdre} est une pyramide à base triangulaire dont toutes les faces sont des triangles équilatéraux.
\end{definition}

\begin{proposition}[Isométries affines du tétraèdre régulier]       \label{PROPooVNLKooOjQzCj}
    Soient \( T\) un tétraèdre régulier et \( \Iso(T)\) son groupe d'isométries affines (définition~\ref{DEFooZGKBooGgjkgs}). Alors
    \begin{equation}
        \Iso(T)\simeq S_4
    \end{equation}
    où \( S_4\) est le groupe des permutations de quatre objets.
\end{proposition}

\begin{proof}
    Commençons par prouver qu'une isométrie préserve les sommets : l'image d'un sommet est un sommet. Pour cela nous considérons \( g\in \Iso(T)\) et nous supposons que l'image d'un sommet \( x\) soit à l'intérieur d'une arrête. Soient \( g(y)\) et \( g(z)\) deux points distincts de cette arrête situés à égale distance de \( g(x)\). Cela est possible parce que \( g\) est une bijection de \( \eR^3\). Aussi : \( y\neq z\). Mais une application affine préserve l'alignement (vous ne le croyez pas  ? regardez la forme donnée par le lemme \eqref{LEMooZZAIooOMiayy}), donc \( x\), \( y\) et \( z\) foment un triangle isocèle en \( x\) de points alignés et appartenant à \( T\). Cela est impossible si \( x\) est un sommet.

    Donc l'image d'un sommet est un sommet. Si nous numérotons les sommets \( x_1\),\ldots, \( x_4\), nous obtenons un morphisme de groupe \( \varphi\colon \Isom(T) \to S_4\) qui envoie \( g\) sur la permutation qui envoie \( 1\) sur le numéro du sommet \( g(x_1)\), \( 2\) sur le numéro du sommet \( g(x_2)\), etc.

    \begin{subproof}
    \item[Le morphisme \( \varphi\) est injectif]
        Supposons \( \varphi(g_1)=\varphi(g_2)\). Alors \( g_1^{-1}\circ g_2\) est une isométrie de \( (\eR^3,d)\) qui fixe les quatre sommets. Une application affine \( \eR^4\to\eR^3\) fixant \( 4\) point est l'identité par le lemme~\ref{LEMooDUMVooFtfFOe}. Donc \( g_1^{-1}g_2=\id\), ce qui prouve que \( g_1=g_2\). Vous noterez que nous utilisons l'unicité de l'inverse dans un groupe.

    \item[\( \varphi\) est surjectif]

        Nous savons que \( S_4\) est engendré par les transpositions (proposition~\ref{PropPWIJbu}). Or les transpositions sont dans l'image de \( \varphi\). En effet, notons les sommets de notre tétraèdre par \( A\), \( B\), \( D\) et \( D\) et considérons la transposition \( A\leftrightarrow B\). Elle est l'image par \( \varphi\) de la réflexion selon le plan \( \sigma\), médiateur du segment \( [A,B]\). Pour nous assurer de cela, nous devons nous assurer que \( C\) et \( D\) appartiennent à \( \sigma\). Cela est le contenu du lemme~\ref{LEMooVBVUooOTFFXT}.

    \item[Conclusion]

        L'application \( \varphi\) est un morphisme bijectif, c'est-à-dire un isomorphisme.

    \end{subproof}
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Représentation de \( S_4\) via les isométries du tétraèdre}
%---------------------------------------------------------------------------------------------------------------------------
\label{SUBSECooVEASooDUbsBh}


\begin{normaltext}
    Lorsque le tétraèdre a son barycentre en l'origine de \( \eR^3\), l'isomorphisme \( \varphi\colon \Iso(T)\to S_4\) donne une représentation de dimension \( 3\) de \( S_4\). Nous avons calculé les caractères de \( S_4\) en la section \ref{SecUMIgTmO} sans avoir besoin de savoir que l'une des représentations de dimension \( 3\) est cella que nous venons de trouver via le groupe des isométries du tétraèdre. Nous allons cependant également y calculer les caractères de la représentation \( \varphi\), pour le sport.
\end{normaltext}

Une des représentations trouvées (la représentation \( \rho_s\)) peut être vue comme le groupe \( \Iso(T)\) des isométries affine du tétraèdre grâce à la proposition \ref{PROPooVNLKooOjQzCj} qui donne un isomorphisme de groupe \( S_4\simeq \Iso(T)\) lorsque \( T\) est un tétraèdre régulier de \( \eR^3\).

Si le barycentre de \( T\) est situé à l'origine de \( \eR^3\), alors les éléments de \( \Iso(T)\) sont des applications linéaires parce que
\begin{itemize}
    \item les affinités laissent invariantes les barycentres (proposition~\ref{PROPooGSPZooRnVgiU}),
    \item les affinités qui laissent l'origine invariante sont linéaires (corolaire~\ref{CORooATCNooUwEPNI}).
\end{itemize}
Nous allons à présent calculer la trace de cette représentation, en utilisant le fait que nous la connaissions explicitement. Nous savons que les caractères sont constants sur les classes de conjugaison; nous allons donc écrire une matrice par classe de conjugaison (qui sont données dans l'exemple~\ref{EXooQAXRooBsPURs}).

Pour tout cela nous allons considérer un tétraèdre dont le centre (isobary) est en \( (0,0,0)\) et une base de \( \eR^3\) formée de trois sommets \( e_1\), \( e_2\) et \( e_3\). Vu que l'isobarycentre des quatre sommes est en \( (0,0,0)\), le quatrième somme est forcément le point de coordonnées \( e_4(-1,-1,-1)\), de telle sorte que \( e_1+e_2+e_3+e_4=0\).

\begin{description}
    \item[Les transpositions]

        Quelle isométrie de $\eR^3$ permute deux sommets du tétraèdre sans bouger les autres ? Pour permuter les sommets \( e_1\) et \( e_2\) en laissant \( e_3\) et \( e_4\), c'est le symétrie par rapport au plan médiateur de \( [e_1,e_2]\). Ce plan passe par les sommets \( e_3\) et \( e_4\), parce que le tétraèdre étant régulier, les points \( e_3\) \( e_4\) sont équidistants de \( e_1\) et \( e_2\). Le lemme~\ref{LEMooVBVUooOTFFXT} dit qu'alors ces points dont partie du plan médiateur.

        Dans notre base, la matrice de la transposition précédemment nommée \( (12)\) est
        \begin{equation}
            \begin{pmatrix}
                0    &   1    &   0    \\
                1    &   0    &   0    \\
                0    &   0    &   1
            \end{pmatrix},
        \end{equation}
        dont la trace est \( 1\). Donc \( \chi_s(12)=1\).

    \item[Les bitranspositions]

        La bitransposition \( (12)(34)\) est le produit des transpositions selon les plans médiateur de \( [e_1,e_2]\) et \( [e_3,e_4]\). Ces deux plans sont perpendiculaires, et l'intersection est la droite qui passe par les milieux. Cette droite est perpendiculaire aux deux segments en même temps. La matrice est :
        \begin{equation}
            \begin{pmatrix}
                0    &    1   &   -1    \\
                1    &   0    &   -1    \\
                0    &   0    &   -1
            \end{pmatrix}
        \end{equation}
        parce que \( e_1\mapsto e_2\), \( e_2\mapsto e_1\) et \( e_3\mapsto e_4\). Pour rappel, la matrice est formée des images des vecteurs de base. Cela donne
        \begin{equation}
            \chi_s\big( (12)(34) \big)=-1.
        \end{equation}

    \item[Les \( 3\)-cycles]

        La symétrie qui permute cycliquement les points \( e_1\), \( e_2\) et \( e_3\) est la rotation d'angle\footnote{Angle d'une rotation, définition \ref{DEFooADTDooKIZbrw}.} \( 2\pi/3\) dans le plan formé par les extrémités de ces trois vecteurs. Heureusement, la trace est invariante par changement de base; donc nous pouvons calculer la trace d'une rotation d'angle \( 2\pi/3\) dans n'importe quelle base. Par exemple :
        \begin{equation}
            \chi_s\big( (12)(34) \big)=\tr\begin{pmatrix}
                1    &   0    &   0    \\
                0    &   \cos(2\pi/3)    &   \sin(2\pi/3)    \\
                0    &   -\sin(2\pi/3)    &   \cos(2\pi/3)
            \end{pmatrix}=1+2\cos(2\pi/3)=0.
        \end{equation}

        Notons que, sans cette interprétation géométrique, nous y arrivons aussi facilement : dans notre base le \( 3\)-cycle est \( e_1\mapsto e_2\mapsto e_3\mapsto e_1\), donc la matrice est :
        \begin{equation}
            \begin{pmatrix}
                0    &   0    &   1    \\
                1    &   0    &   0    \\
                0    &   1    &   0
            \end{pmatrix},
        \end{equation}
        dont la trace est manifestement nulle : \( \chi_s\big( (123) \big)=0\).

    \item[Le \( 4\)-cycle]

        Il fait \( e_1\mapsto e_2\mapsto e_3\mapsto e_4\mapsto e_1\), dont la matrice est
        \begin{equation}        \label{EQooONDUooYlduup}
            \begin{pmatrix}
                0    &   0    &   -1    \\
                1    &   0    &   -1    \\
                0    &   1    &   -1
            \end{pmatrix},
        \end{equation}
        et la trace est \( \chi_s\big( (1,2,3,4) \big)=-1\).
\end{description}
Nous avons retrouvé les caractères de la représentation \( \rho_s\), et nous pouvons vérifier qu'elle est irréductible.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Transformations de Lorentz}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Nous considérons dans cette section un nombre réel \( c>0\) ainsi que l'espace \( \eR^2\) muni du produit pseudo-scalaire\footnote{Définition \ref{DEFooLPBGooXLxubc}.} donné par la matrice
\begin{equation}
    \eta=\begin{pmatrix}
        c^2    &   0    \\ 
        0    &   -1    
    \end{pmatrix}.
\end{equation}
Et pour faire plus vrai, nous notons \( (x_0,x_1)\) les coordonnées sur \( \eR^2\). Ainsi
\begin{equation}
    x\cdot y=c^2x_0y_0-x_1y_1.
\end{equation}
Nous insistons sur le fait que cela n'est pas un produit scalaire.

\begin{lemma}[\cite{MonCerveau}]        \label{LEMooPZPZooVAdPVj}
    Soit \( c>0\). L'application
    \begin{equation}
        \begin{aligned}
        \varphi\colon \mathopen] -c , c \mathclose[&\to \eR \\
            v&\mapsto \frac{ -v/c }{ \sqrt{ 1-\frac{ v^2 }{ c^2 } } } 
        \end{aligned}
    \end{equation}
    est une bijection.
\end{lemma}

\begin{proof}
    Nous commençons par mentionner le fait que \( \varphi\) est continue du fait que le dénominateur ne s'annule pas. Une petite étude fonction montre que
    \begin{equation}
        \lim_{v\to -c} \varphi(v)=\infty,
    \end{equation}
    et
    \begin{equation}
        \lim_{v\to c} \varphi(v)=-\infty,
    \end{equation}
    et
    \begin{equation}
        \varphi'(v)=-\frac{1}{ c\sqrt{ 1-\frac{ v^2 }{ c^2 } } }-\frac{ v^2/c^3 }{ \left( 1-\frac{ v^2 }{ c^2 } \right)^{3/2} }<0.
    \end{equation}
    Tout cela fait que \( \varphi\) est bijective (entre autres par le théorème des valeurs intermédiaires \ref{ThoValInter} et la théorème dérivée et croissance \ref{PropGFkZMwD}).
\end{proof}

\begin{lemma}       \label{LEMooUZFKooSIjery}
    La forme bilinéaire
    \begin{equation}
        \begin{aligned}
            b\colon \eR^2\times \eR^2&\to \eR \\
            x,y&\mapsto x\cdot y
        \end{aligned}
    \end{equation}
    est non dégénérée\footnote{Définition \ref{DEFooNUBFooLfCqaK}.}.
\end{lemma}

\begin{proof}
    Soit \( (x_0,x_1)\in \eR^2\) tel que
    \begin{equation}
        b\big( (x_0,x_1), (y_0,y_1) \big)=0
    \end{equation}
    pour tout \( (y_0,y_1)\in \eR^2\). Nous avons
    \begin{equation}
        c^2x_0y_0-x_1y_1=0.
    \end{equation}
    En écrivant cela avec \( (y_0,y_1)=(1,0)\) puis \( (0,1)\) nous obtenons immédiatement que \( (x_0,x_1)=(0,0)\).
\end{proof}

\begin{theorem}     \label{THOooYHDWooWxVovH}
    Soit une bijection\quext{À mon avis, il y a moyen d'affaiblir cette hypothèse. Écrivez-moi si vous avez une idée.} \( f\colon \eR^2\to \eR^2\) telle que 
    \begin{equation}
        f(x)\cdot f(y)=x\cdot y
    \end{equation}
    pour tout \( x,y\in \eR^2\). Alors :
    \begin{enumerate}
        \item
            \( f\) est linéaire.
        \item
            Il existe un unique choix de \( (x,\sigma_1,\sigma_2)\in \eR\times \{ \pm1 \}\times \{ \pm1 \}\) tel que la matrice de \( f\) ait la forme
            \begin{equation}
                f=\begin{pmatrix}
                    \sigma_1\cosh(\xi)    &   \frac{ \sigma_1\sigma_2 }{ c }\sinh(\xi)    \\ 
                    c\sinh(\xi)    &   \sigma_2\cosh(\xi)    
                \end{pmatrix}.
            \end{equation}
        \item
        Il existe un unique \( v\in\mathopen] -c , c \mathclose[\) tel que la matrice de \( f\) ait la forme
            \begin{equation}
                f=\begin{pmatrix}
                    \frac{ \sigma_1 }{ \sqrt{ 1-\frac{ v^2 }{ c^2 } } }    &   -\frac{ \sigma_1\sigma_2 }{ c^2 }\frac{ v }{ \sqrt{ 1-\frac{ v^2 }{ c^2 } } }    \\ 
                    \frac{ -v }{ \sqrt{ 1-\frac{ v^2 }{ c^2 } } }    &   \frac{ \sigma_2 }{ \sqrt{ 1-\frac{ v^2 }{ c^2 } } }    
                \end{pmatrix}.
            \end{equation}
    \end{enumerate}
\end{theorem}

\begin{proof}
    Vu que notre produit pseudo-scalaire est non dégénéré (lemme \ref{LEMooUZFKooSIjery}), le fait que \( f\) soit linéaire est la proposition \ref{ThoDsFErq}. Nous posons 
    \begin{equation}
         A=\begin{pmatrix}
            \alpha    &   \beta    \\ 
            \gamma    &   \delta    
        \end{pmatrix}
    \end{equation}
    et, conformément à la proposition \ref{PROPooSYQMooEnZFdp} nous imposons \( A^t\eta A=\eta\). Après un petit produit matriciel nous obtenons :
    \begin{equation}
        \begin{pmatrix}
            c^2\alpha^2-\gamma^2    &   c^2\alpha\beta-\gamma\delta    \\ 
            c^2\alpha\beta-\gamma\delta    &   c^2\beta^2-\delta^2    
        \end{pmatrix}=\begin{pmatrix}
            c^2    &   0    \\ 
            0    &   -1    
        \end{pmatrix}.
    \end{equation}
    Voila quatre équations à résoudre pour les quatre inconnues \( \alpha, \beta,\gamma, \delta\). Déjà les équations des termes anti-diagonaux sont les mêmes. Nous recopions le reste :
    \begin{subequations}
        \begin{numcases}{}
            c^2\alpha^2-\gamma^2=c^2            \label{SUBEQooXZUGooITKZnH}\\
            c^2\alpha\beta-\gamma\delta=0       \label{SUBEQooDWQRooBeDaPw}\\
            c^2\beta^2-\delta^2=1.              \label{SUBEQooJAFLooGxmbaO}
        \end{numcases}
    \end{subequations}
    C'est le moment d'utiliser la proposition \ref{PROPooWEHGooOBqSHY}. La relation \eqref{SUBEQooXZUGooITKZnH} donne
    \begin{equation}
        \alpha^2-\left( \frac{ \gamma }{ c } \right)^2=1,
    \end{equation}
    ce qui implique l'existence d'un unique\footnote{Par \ref{}.} \( \xi_1\in \eR\) et \( \sigma_1\in \{ \pm 1 \}\) tels que
    \begin{subequations}        \label{SUBEQSooQUSIooRZRYSW}
        \begin{align}
            \gamma&=c\sinh(\xi_1)\\
            \alpha&=\sigma_1\cosh(\xi_1).
        \end{align}
    \end{subequations}
    La relation \eqref{SUBEQooJAFLooGxmbaO} implique quant à elle l'existence de \( \xi_2\in \eR\) et \( \sigma_2\in\{ \pm 1 \}\) tels que
    \begin{subequations}        \label{SUBEQSooLFHCooXVetmK}
        \begin{align}
            \delta&=\sigma_2\cosh(\xi_2)\\
            \beta&=\frac{1}{ c }\sinh(\xi_2).
        \end{align}
    \end{subequations}
    
    Nous substituons maintenant toutes les valeurs \eqref{SUBEQSooQUSIooRZRYSW} et \eqref{SUBEQSooLFHCooXVetmK} dans \eqref{SUBEQooDWQRooBeDaPw}. Cela donne
    \begin{equation}        \label{EQooHTMSooVYzJUS}
        \sigma_1\cosh(\xi_1)\sinh(\xi_2)=\sinh(\xi_1)\cosh(\xi_2).
    \end{equation}
    Nous mettons cette relation au carré et nous substituons \( \cosh(\xi_1)^2=1+\sinh^2(\xi_1)\). Ce que nous trouvons est
    \begin{equation}
        \sinh(\xi_1)^2=\sinh(\xi_2)^2,
    \end{equation}
    qui implique que \( \xi_1=\pm\xi_2\). Nous posons donc \( \xi_2=\sigma_3\xi_1\) pour un certain \( \sigma_3\in \{ \pm 1 \}\). Cela nous permet d'alléger la notation et d'écrire \( \xi\) au lieu de \( \xi_1\).
    
    Nous remettons la valeur \( \xi=\xi_1=\sigma_3\xi_2\) dans l'équation \eqref{EQooHTMSooVYzJUS} en tenant compte du fait que \( \sinh\) est impaire et \( \cosh\) est paire :
    \begin{equation}
        \sigma_1\sigma_3\cosh(\xi)\sinh(\xi)=\sigma_2\sinh(\xi)\cosh(\xi).
    \end{equation}
    Et cela nous enseigne que \( \sigma_3=\sigma_1\sigma_2\).

    Jusqu'à présent nous avons prouvé qu'il existe un unique \( \xi\in \eR\) et \( \sigma_1,\sigma_2\in \{ \pm 1 \}\) tels que
    \begin{equation}        \label{EQooYZIVooCTdmSh}
        A=\begin{pmatrix}
            \sigma_1\cosh(\xi)    &   \frac{ \sigma_1\sigma_2 }{ c }\sinh(\xi)    \\ 
            c\sinh(\xi)    &   \sigma_2\cosh(\xi)    
        \end{pmatrix}.
    \end{equation}
    
Nous utilisons à présent la bijection du lemme \ref{LEMooPZPZooVAdPVj}. Il existe un unique \( v\in \mathopen] -v , v \mathclose[\) tel que \( \sinh(\xi)=\varphi(v)\). En utilisant \( \cosh(\xi)^2=1+\varphi(v)^2\), nous trouvons
    \begin{equation}
        \cosh(\xi)^2=\frac{1}{ 1-\frac{ v^2 }{ c^2 } }.
    \end{equation}
    Mais comme le cosinus hyperbolique est toujours strictement positif, nous pouvons prendre la racine carrée des deux côtés :
    \begin{equation}
        \cosh(\xi)=\frac{1}{ \sqrt{ 1-\frac{ v^2 }{ c^2 } } }.
    \end{equation}
    En substituant dans \eqref{EQooYZIVooCTdmSh}, nous trouvons le résultat annoncé.
\end{proof}


%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Sous-groupe fini d'isométries du plan}
%---------------------------------------------------------------------------------------------------------------------------

\begin{theorem}[\cite{BIBooULRWooPsjtBE}]       \label{THOooKDMUooUxQqbB}
    Soit un groupe fini \( G\) d'isométries de \( (\eR^2,d)\) contenant \( n \) éléments.
    \begin{enumerate}
        \item       \label{ITEMooYEONooCOMpeb}
            Il existe un point \( C\in \eR^2\) fixé par tous les éléments de \( G\).
        \item       \label{ITEMooGELWooFFAqkc}
            Si \( G\) ne contient pas de réflexions, alors il est cyclique\footnote{Définition \ref{DefHFJWooFxkzCF}.} et engendré par la rotation d'angle \( 2\pi/n\) autour de \( C\).
        \item       \label{ITEMooDHKEooFpCfmX}
            Si \( G\) contient au moins une réflexion, et si \( C\) est un point fixe de \( G\), alors
            \begin{enumerate}
                \item       \label{ITEMooGQZTooJIPPLtyf}
                    toutes les réflexions ont un axe qui passe par \( C\),
                \item       \label{ITEMooKPQRooLquSiQ}
                    \( n\) est pair,
                \item       \label{ITEMooCHSWooHpDGHf}
                    Si \( \sigma\) est une réflexion dans \( G\), alors nous avons $G=\gr\big(\sigma,R_C(4\pi/n)\big)$ où \( R_C(\theta)  \) est la rotation d'angle \( \theta\) autour de \( C\),
                \item       \label{ITEMooROUYooRghvMv}
                    \( G\) est isomorphe au groupe diédral \( D_{n/2}\).
            \end{enumerate}
    \end{enumerate}
\end{theorem}

\begin{proof}
    Soit un groupe fini \( G\) constitué d'isométries de \( (\eR^2,d)\). Nous prouvons le théorème point par point.
    \begin{subproof}
        \item[Pour \ref{ITEMooYEONooCOMpeb}]
            C'est la proposition \ref{PROPooLAEBooWdcBoe}.
        \item[Questions de réflexions]
            Le théorème \ref{THOooRORQooTDWFdv} nous dit que les éléments de \( G\) sont des compositions d'au maximum \( 3\) réflexions. 
        \item[Exclure trois réflexions]
            Il n'est pas possible que \( G\) contienne un élément composé de trois réflexions. En effet, les composées de trois réflexions, par le théorème \ref{THOooVRNOooAgaVRN} sont des réflexions glissées\footnote{Définition \ref{DEFooJEOYooNwYtuQ}.}, c'est-à-dire des transformations de la forme \( g=\tau_v\circ \sigma_{\ell}\) où \( v\) est un vecteur parallèle à la droite \( \ell\). Si \( x\in \ell\), alors
            \begin{equation}
                g(x)=\tau_v(x)=x+v,
            \end{equation}
            de telle sorte que \( g^k(x)=x+kv\), qui signifie que tous les \( g^k\) sont différents. Le groupe \( G\) ne peut pas être fini si il contient une réflexion glissée.

        \item[\( G^+\) et \( G^-\)]
            Pour la même raison que celle qui exclu les réflexions glissées, \( G\) ne peut pas contenir de translations. Le théorème \ref{THOooVRNOooAgaVRN} nous donne la liste des possibilités. Après exclusion des translations et des réflexions glissées, il reste :
            \begin{itemize}
                \item l'identité
                \item les rotations,
                \item les réflexions.
            \end{itemize}
            Nous notons \( G^+\) la partie de \( G\) contenant l'identité et les rotations et \( G^-\) celle contenant les réflexions. Notons que \( G^+\) n'est pas vide parce qu'il contient au moins l'identité, tandis que \( G^-\) peut être vide, mais n'est certainement pas un groupe.
        \item[Même nombre d'éléments]
            Nous prouvons à présent que si \( G^-\) est non vide, alors il a le même nombre d'éléments que \( G\). Un élément de \( G^-\) est une réflexion. Soit \( \sigma\in G^-\). Nous prouvons que
            \begin{equation}        \label{EQooWRVVooBQCtPg}
                \begin{aligned}
                    \varphi\colon G^+&\to G^- \\
                    f&\mapsto \sigma\circ f 
                \end{aligned}
            \end{equation}
            est une bijection.

            \begin{subproof}
                \item[Surjective]
                    Soit \( s\in G^-\). Posons \( f=\sigma^{-1}\circ s\). Vu que \( \sigma^{-1}\) et \( s\) sont des réflexions, \( f\) est une rotation. Donc \( f\in G^+\) et \( \varphi(f)=s\).
                \item[Injective]
                    La condition \( \varphi(f)=\varphi(g)\) dit que \( \sigma\circ f=\sigma\circ g\). En composant par \( \sigma^{-1}\) nous obtenons \( f=g\).
            \end{subproof}
        \item[\( G=\gr\big(R_C(2\pi /p)\big)\)]
            Nous nommons \( p\) le nombre d'éléments de \( G^+\). Si \( G^-\) est vide, \( p=n\), et sinon \( p=n/2\). Dans les deux cas, \( G^+\) est un groupe de rotations à \( p\) éléments. 

            Le groupe \( G^+\) contient seulement des rotations; or le centre d'une rotation est l'unique point fixe. Donc tous les éléments de \( G^+\) sont des rotations autour de \( C\).
            
            Le corolaire \ref{CorpZItFX} au théorème de théorème de Lagrange nous indique que tous les éléments de \( G^+\) vérifient \( g^p=\id\). Seules les rotations d'angle \( 2k\pi/p\) autour de \( C\) satisfont la condition \( g^p=\id\). Or il n'y a que \( p\) telles rotations. Donc elles sont toutes dans \( G^+\). Nous en déduisons que
            \begin{equation}        \label{EQooUWTVooEMqkVH}
                G^+=\gr\big( R_C(2\pi/p) \big).
            \end{equation}
        \item[Pour \ref{ITEMooGELWooFFAqkc}]
            Dans le cas où \( G\) ne contient pas de réflexions, \( G^-\) est vide et \( G\) contient \( n\) éléments. La relation \eqref{EQooUWTVooEMqkVH} devient
            \begin{equation}
                G=G^+=\gr\big( R_C(2\pi/n) \big).
            \end{equation}
        \item[Pour \ref{ITEMooDHKEooFpCfmX}]
            Nous supposons maintenant que \( G\) contienne au moins une réflexion. De la sorte \( G^-\neq \emptyset\).
            \begin{subproof}
            \item[Pour \ref{ITEMooGQZTooJIPPLtyf}]
                Les seuls points fixes d'une réflexions sont ceux de l'axe. Donc \( C\) soit être sur tous les axes des réflexions contenues dans \( G^-\).

                Notons au passage que deux réflexions d'axes qui se coupent forment une rotation. Donc \( G^-\) ne forme pas un groupe, mais même pas en rêve.
            \item[Pour \ref{ITEMooKPQRooLquSiQ}]
                Vu que l'union \( G=G^+\cup G^-\) est disjointe et que \( G^+\) et $G^-$ ont le même nombre d'éléments par la bijection \ref{EQooWRVVooBQCtPg}, si \( G^-\) est non vide, \( G\) possède un nombre pair d'éléments.
            \item[Pour \ref{ITEMooCHSWooHpDGHf}]
                Si \( \sigma\in G\) est une réflexion, nous savons que \( G^+\) possède \( p=n/2\) éléments et que
                \begin{equation}
                    G^+=\{  R_C(2k\pi/p)  \}=\{  R_C(4k\pi/n) \}_{k=1,\ldots, n/2}.
                \end{equation}
                L'élément \( \sigma\in G^- \) étant fixé, la bijection \eqref{EQooWRVVooBQCtPg} nous indique que tous les éléments de \( G^-\) sont de la forme \( \sigma\circ f\) avec \( f\in G^+\). Donc
                \begin{equation}
                    G^{-}\subset \gr\big( \sigma, R_C(4\pi/n)  \big).
                \end{equation}
                Nous avons aussi
                \begin{equation}
                    G^+\subset \gr\big( \sigma,  R_C(4\pi/n)  \big).
                \end{equation}
                Et comme \( \sigma\) et \(  R_C(4\pi/n)  \) sont dans \( G\) nous avons \( \gr\big( \sigma ,  R_C(4\pi/n)  \big)\subset G\). Tout cela pour dire que 
                \begin{equation}
                    G=\gr\big( \sigma,  R_C(4\pi/n) \big).
                \end{equation}

            \item[\( R\sigma = \sigma R^{-1}\)]

                Nous restons dans le cas où \( G^-\) n'est pas vide. Nous considérons \( R\), la rotation d'angle \( \theta\) autour de \( C\). Si \( R_0\) est la rotation d'angle \( \theta\) autour de \( (0,0)\), nous avons
                \begin{equation}
                    R=\tau_C\circ R_0\circ \tau_C^{-1},
                \end{equation}
                et si \( \sigma_0\) est la symétrie d'axe parallèle à l'axe de \( \sigma\), mais passant par \( (0,0)\) nous avons : 
                \begin{equation}
                    \sigma=\tau_C\circ\sigma_0\circ\tau_C^{-1}.
                \end{equation}
                Si \( v\) est le vecteur directeur de la réflexion \( \sigma_0\), nous considérons enfin \( \alpha\), la rotation qui fait \( \alpha(v)=(1,0)\). Nous avons alors
                \begin{equation}
                    \sigma_0=\alpha^{-1}\circ s\circ \alpha
                \end{equation}
                où \( s\) est la symétrie autour de l'axe horizontal. En n'ayant pas peur d'identifier \( \eR^2\) à \( \eC\), l'applicaiton \( s\) est la conjugaison complexe. Avec tout ça nous avons
                \begin{equation}
                    R\sigma=\tau_CR_0\tau_C^{-1}\tau_C\sigma_0\tau_C^{-1}=\tau_CR_0\alpha^{-1}s\alpha\tau_C^{-1}=\tau_C\alpha^{-1}R_0s\alpha\tau_C^{-1}
                \end{equation}
                où nous avons utilisé le fait que les rotations autour de \( (0,0)\) forment un groupe abélien pour commuter \( \alpha^{-1}\) avec \( R_0\). Nous utilisaons à présent le lemme \ref{LEMooBNJFooAbhsUa} pour commuter \( R\) avec \( s\) :
                \begin{subequations}
                    \begin{align}
                        R\sigma&=\tau_X\alpha^{-1}sR_0^{-1}\alpha\tau_C^{-1}\\
                        &=\tau_C\underbrace{\alpha^{-1}s\alpha}_{\sigma_0} R_0^{-1}\tau_C^{-1}\\
                        &=\tau_C\sigma_0\tau_C^{-1}\tau_CR_0^{-1}\tau_C^{-1}\\
                        &=\sigma R^{-1}.
                    \end{align}
                \end{subequations}
                Nous avons utilisé le fat que \( \tau_CR_0^{-1}\tau_C^{-1}=R^{-1}\) comme on peut s'en convaincre en calculant le produit.

            \item[Table de multiplication]
                
                Nous considérons une réflexion \( \sigma\in G\). Les éléments de \( G^+ \) sont des rotations autour de \( C\) et ceux de \( G^-\) de la forme \( \sigma R\) où \( R\) est une rotation autour de \( C\). Pour savoir la table de multiplication de \( G\), nous devons écrire
                \begin{equation}
                    (\sigma^{\epsilon_1}R^k)(\sigma^{\epsilon_2}R^l)=\sigma^{\epsilon}R^m
                \end{equation}
                où \( \epsilon_1,\epsilon_2\in \{ 0,1 \}\), \( R\) est la rotation d'angle \( 4\pi/n\) autour de \( C\) et \( \alpha\) et \( m\) sont des constantes à exprimer en fonction de \( \epsilon_1\), \( \epsilon_2\), \( k\) et \( l\).

                Tous les éléments de \( G\) pouvant être écrits soit sous la forme \( R^m\) soit sous la forme \( \sigma R^m\), nous avons les possibilités suivantes :
                \begin{enumerate}
                    \item
                        \( R^mR^l=R^{m+l}\)
                    \item
                        \( (R^m)(\sigma R^l)=\sigma R^{-m}R^l=\sigma R^{l-m}\)
                    \item
                        \( (\sigma R^m)R^l=\sigma R^{m+l}\)
                    \item
                        \( (\sigma R^m)(\sigma R^l)=\sigma\sigma R^{l-m}=R^{l-m}\).
                \end{enumerate}
            \item[Pour \ref{ITEMooROUYooRghvMv}]
                Récoltons quelque faits.
                \begin{itemize}
                    \item 
                        Nous venons de prouver que \( R\sigma=\sigma R^{-1}\).
                    \item
                        Tout élément de \( G\) peut s'écrire soit sous la forme \( R^m\) soit sous la forme \( \sigma R^m\) suivant que l'élément soit dans \( G^+\) ou \( G^-\).
                    \item
                        Tout élément du groupe diédral \( D_n\) s'écrit soit sous la forme \( r^m\) soit sous la forme \( sr^m\) (proposition \ref{PropLDIPoZ}\ref{ITEMooOEBHooULRmZk}).
                \end{itemize}
                L'application \( \varphi\colon G\to D_n\) suivante est donc une bijection :
                \begin{subequations}
                    \begin{numcases}{}
                        \varphi(R^m)=r^m\\
                        \varphi(\sigma R^m)=sr^m.
                    \end{numcases}
                \end{subequations}
                Il nous reste à prouver que c'est un morphisme. Cela se fait en utilisant la table de multiplication du groupe diédral donnée dans la proposition \ref{PROPooPYDLooLgiUjk} et celle du groupe \( G\) que nous venons de faire.
            \end{subproof}
    \end{subproof}
\end{proof}

\begin{definition}[Groupe de symétrie d'une partie de \( \eR^n\)\cite{ooZYLAooXwWjLa}]
    Si \( Y\) est une partie de \( \eR^n\), nous définissons le \defe{groupe des symétries}{groupe!des symétries} de \( Y\) par
    \begin{equation}
        \Sym(Y)=\{ f\in\Isom(\eR^n)\tq f(Y)=Y \}.
    \end{equation}
    Nous définissons aussi le groupe des symétries propres de \( Y\) par
    \begin{equation}
        \Sym^+(Y)=\{ f\in\Isom^+(\eR^n)\tq f(Y)=Y \}.
    \end{equation}
\end{definition}

\begin{theorem}[\cite{ooZYLAooXwWjLa}]      \label{THOooAYZVooPmCiWI}
    Soit \( Y\subset \eR^2\) tel que le groupe \( \Sym^+(Y)\) soit fini d'ordre \( n\). Alors c'est un groupe cyclique d'ordre \( n\).

    Si \( \Sym^+(Y)\) est fini, alors \( \Sym(Y)\) est soit cyclique\footnote{Définition \ref{DefHFJWooFxkzCF}.} d'ordre \( n\) soit isomorphe au groupe diédral\footnote{Définition \ref{DEFooIWZGooAinSOh}.} d'ordre \( 2n\).
\end{theorem}

\begin{proof}
    Nous savons déjà par la proposition~\ref{PROPooEUFIooDUIYzi} que \( \Sym^+(Y)\) est isomorphe à un sous-groupe \( H^+\) d'ordre \( n\) de \( \SO(2)\). Vérifions que ce groupe est cyclique. Si \( n=1\), c'est évident. Si \( n\geq 2\) alors nous savons que \( H^+\) est constitué de rotations d'angles dans \( \mathopen[ 0 , 2\pi \mathclose[\) et vu que c'est un ensemble fini, il possède une rotation d'angle minimal (à part zéro). Notons \( \alpha_0\) cet angle.

        Nous montrons que \( H^+\) est engendré par la rotation d'angle \( \alpha_0\). Soit une rotation d'angle \( \alpha\). Étant donné que \( \alpha_0<\alpha\) nous pouvons effectuer la division euclidienne\footnote{Théorème~\ref{ThoDivisEuclide}.} de \( \alpha\) par \( \alpha_0\) et obtenir
        \begin{equation}
            \alpha=k\alpha_0+\beta
        \end{equation}
        avec \( \beta<\alpha_0\). Mézalors \( R(\beta)=R(\alpha)R(\alpha_0)^{-k}\) est également un élément du groupe. Cela contredit la minimalité dès que \( \beta\neq 0\). Avoir \( \beta=0\) revient à dire que \( \alpha\) est un multiple de \( \alpha_0\), ce qui signifie que le groupe \( H^+\) est cyclique engendré par \( \alpha_0\).

        Notons au passage que nous avons automatiquement \( \alpha_0=\frac{ 2\pi }{ n }\) parce qu'il faut \( R(\alpha_0)^n=\id\). Nous avons prouvé que \( \Sym^+(Y) \) est cyclique d'ordre \( n\).

        Nous étudions maintenant le groupe \( \Sym(Y)\). Par la proposition~\ref{PROPooEUFIooDUIYzi} nous avons un homomorphisme injectif
        \begin{equation}
            \phi\colon \Sym(Y)\to \gO(2),
        \end{equation}
        et en posant \( H=\phi\big( \Sym(Y) \big)\) nous avons un isomorphisme de groupes \( \phi\colon \Sym(Y)\to H\). Nous savons aussi que ce \( \phi\) se restreint en
        \begin{equation}
            \phi\colon   \Sym^+(Y) \to H^+\subset\SO(2)
        \end{equation}
        où \( H^+=\phi\big( \Sym^+(Y) \big)=H\cap\SO(2)\). Le groupe \( H^+\) est cyclique et est engendré par la rotation \( R(2\pi/n)\).

        Supposons un instant que \( H\subset \SO(2)\). Alors nous avons \( H=H^+\) et \( \phi\) est un isomorphisme entre \( \Sym(Y)\) et le groupe cyclique engendré par \( R(2\pi/n)\).

        Nous supposons à présent que \( H\) n'est pas un sous-ensemble de \( \SO(2)\). Quelles sont les isométries de \( \eR^2\) qui ne sont pas de déterminant \( 1\) ? Il faut regarder dans le théorème~\ref{THOooVRNOooAgaVRN} quelles sont les isométries contenant un nombre impair de réflexions. Ce sont les réflexions et les réflexions glissées. Or il ne peut pas y avoir de réflexions glissées dans un groupe fini parce que si \( f\) est une réflexion glissée, tous les \( f^k\) sont différents.

        Nous en déduisons que si \( H\) n'est pas inclus dans \( \SO(2)\), il contient une réflexion que nous nommons \( \sigma\). Nous allons en déduire que \( H\simeq H^+\times_{\AD}C_2\) où \( C_2=\{ \id,\sigma \}\). Si \( h\in H\) nous pouvons écrire
        \begin{equation}
            h=(h\sigma^{\epsilon})\sigma^{\epsilon}
        \end{equation}
        pour n'importe quelle valeur de \( \epsilon\), et en particulier pour \( \epsilon=\pm 1\).

        Si \( h\in \SO(2)\) alors nous écrivons \( h=h\epsilon^{0}\) et si \( h\notin\SO(2)\) nous écrivons \( h=(h\sigma)\sigma\). Vu que \( h\sigma\in\SO(2)\), cette dernière écriture est encore de la forme \( \SO(2)\times C_2\). Quoi qu'il en soit tout élément de \( H\) s'écrit comme un produit
        \begin{equation}
            H=H^+C_2.
        \end{equation}
        Cette décomposition est unique parce que si \( h_1c_1=h_2c_2\) alors \( h_2^{-1}h_1=c_2c_1^{-1}\), et comme \( h_2^{-1}h_1\in H^+\) nous avons \( c_2c_1^{-1}\in H^+\) et donc \( c_1=c_2\). Partant nous avons aussi \( h_1=h_2\). Pour avoir le produit semi-direct il faut encore montrer que \( \AD(C_2)H^+\subset H^+\). Le seul cas à vérifier est \( \AD(\sigma)H^+\subset H^+\). Vu que les éléments de \( H^+\) sont caractérisés par le fait d'avoir un déterminant positif, nous avons
        \begin{equation}
            \AD(\sigma)R(\alpha)=\sigma R(\alpha)\sigma^{-1}\in H^+.
        \end{equation}
\end{proof}

\begin{remark}
    Tout ceci est cohérent avec le théorème de Burnside~\ref{ThooJLTit} parce que le sous-groupe fini de \( \SO(n)\) engendré par la rotation \( R(2\pi/n)\) est un groupe d'exposant fini, à savoir que si \( h\) est dans ce groupe, \( h^n=\id\).
\end{remark}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Relations trigonométriques dans un triangle rectangle}
%---------------------------------------------------------------------------------------------------------------------------

Nous donnons maintenant quelques relations trigonométriques classiques dans un triangle rectangle. Le théorème de Pythagore est déjà le théorème \ref{THOooHXHWooCpcDan}; nous nous concentrons ici sur les angles.

\begin{proposition}
    Soient \( A,B,S\in \eR^2\) des points distincts et non alignés formant un triangle rectangle en \( A\) :
    \begin{equation}
        (A-S)\cdot (B-A)=0.
    \end{equation}
    En posant \( \theta=\reallywidehat{ASB}\) nous avons
    \begin{equation}
        \cos(\theta)=\frac{ \| A-S \| }{ \| B-S \| }
    \end{equation}
    et
    \begin{equation}        \label{EQooEKZEooFeNImX}
        \sin(\theta)=\pm\frac{ \| B-A \| }{ \| B-S \| }.
    \end{equation}
    
\end{proposition}

\begin{proof}
    Nous posons \( C=A-S\) et \( D=B-S\). Vu que \( C\neq 0\), il existe une rotation \( R_{\alpha}\) telle que
    \begin{subequations}
        \begin{numcases}{}
            (R_{\alpha}C)_x>0\\
            (R_{\alpha}C)_y=0.
        \end{numcases}
    \end{subequations}
    Nous posons \( X=R_{\alpha}C\) et \( Y=R_{\alpha}D\).

    Le triangle formé de \( O\), \( X\) et \( Y\) est «posé» sur l'axe des abscisses et est rectangle en \( X\), c'est-à-dire
    \begin{equation}
        X\cdot (Y-X)=0.
    \end{equation}
    De ce fait, le point \( Y\) satisfait à \( Y_x=X_x\). Et enfin, grâce aux propositions \ref{PROPooKVSHooRODGWE} et \ref{PROPooYWKJooRjybUJ} nous avons \( \widehat{ASB}=\widehat{XOY}\).

    Nous écrivons les relations qui définissent l'angle \( \widehat{XOY}\). Pour cela nous posons \( X'=X/\| X \|\) et \( Y'=Y/\| Y \|\) et nous avons
    \begin{subequations}        \label{SUBEQooVHNDooPOfbjC}
        \begin{numcases}{}
            \cos(\theta)=X'_xY'_x\\
            \sin(\theta)=X'_xY'_y.
        \end{numcases}
    \end{subequations}
    Vu que \( X=(X_x,0)\) nous avons \( X'_x=1\). De plus
    \begin{equation}
        \| Y \|=\| R_{\alpha}(D) \|=\| D \|=\| B-S \|.
    \end{equation}
    En substituant les valeurs dans \eqref{SUBEQooVHNDooPOfbjC},
    \begin{equation}
        \cos(\theta)=Y'_x=\frac{ Y_x }{ \| Y \| }=\frac{ X_x }{ \| B-S \| }=\frac{ \| C \| }{ \| B-S \| }=\frac{ \| A-S \| }{ \| B-S \| }.
    \end{equation}
    Voila déjà une chose de prouvée.

    Pour la seconde, nous avons \( \sin(\theta)=Y'_y\). Selon le signe de \( Y_y\) nous avons \( Y_y=\pm\| Y-X \|\) et donc
    \begin{equation}
        \sin(\theta)=Y'_y=\frac{ Y_y }{ \| Y \| }=\frac{ \pm\| Y-X \| }{ \| Y \| }=\pm\frac{ \| D-C \| }{ \| Y \| }=\pm\frac{ \| B-A \| }{ \| B-S \| }.
    \end{equation}
\end{proof}

Le signe sur la formule du sinus revient au fait que la définition de l'angle \( \widehat{AOB}\) est de considérer la rotation qui fait aller \( A\) vers \( B\). Donc suivant la position relative de \( A\), \( O\) et \( B\), il se peut que l'angle mesuré soit l'angle \emph{extérieur} au triangle.

La proposition suivante est parfois prise comme définition de l'angle. 
\begin{proposition}
    Soient trois points non alignés \( A,S,B\in \eR^2\). Nous avons
    \begin{equation}        \label{EQooOWULooVQntyE}
        \cos\big( \widehat{ASB} \big)=\frac{ (A-S)\cdot(B-S) }{ \| A-S \|\| B-S \| }.
    \end{equation}
\end{proposition}

\begin{proof}
    Nous posons \( C=A-S\), \( D=B-S\), \( X=C/\| C \|\) et \( Y=D/\| D \|\). Avec cela, la définition \ref{DEFooUPUUooKAPFrh} donne l'équation
    \begin{equation}
        \begin{pmatrix}
            \cos(\theta)    &   -\sin(\theta)    \\ 
            \sin(\theta)    &   \cos(\theta)    
        \end{pmatrix}\begin{pmatrix}
            X_x    \\ 
            X_u    
        \end{pmatrix}=\begin{pmatrix}
            Y_x    \\ 
            Y_y    
        \end{pmatrix}
    \end{equation}
    que nous écrivons comme le système
    \begin{subequations}
        \begin{numcases}{}
            X_c\cos(\theta)-X_y\sin(\theta)=Y_x\\
            X_y\cos(\theta)+X_x\sin(\theta)=Y_y.
        \end{numcases}
    \end{subequations}
    Nous considérons maintenant cela comme un système pour \( \big( \cos(\theta), \sin(\theta) \big)\) :
    \begin{equation}
        \begin{pmatrix}
            X_x    &   -X_y    \\ 
            X_y    &   X_x    
        \end{pmatrix}\begin{pmatrix}
            \cos(\theta)    \\ 
            \sin(\theta)    
        \end{pmatrix}=\begin{pmatrix}
            Y_x    \\ 
            Y_y    
        \end{pmatrix}.
    \end{equation}
    Le déterminant de la dernière matrice est \( X_x+X_y^2=\| X \|^2=1\) parce que \( X\) est unitaire. Cette matrice est donc inversible et son inverse est vite calculée. Nous avons
    \begin{equation}
        \begin{pmatrix}
            \cos(\theta)    \\ 
            \sin(\theta)    
        \end{pmatrix}=\begin{pmatrix}
            X_x    &   X_y    \\ 
            -X_y    &   X_x    
        \end{pmatrix}\begin{pmatrix}
            Y_x    \\ 
            Y_y    
        \end{pmatrix}.
    \end{equation}
    Cela donne ce que nous voulions :
    \begin{equation}
        \cos(\theta)=X\cdot Y=\frac{ C\cdot D }{ \| C \|\| D \| }=\frac{ (A-S)\cdot(B-S) }{ \| A-S \|\| C-S \| }.
    \end{equation}
\end{proof}

\begin{remark}
    Prendre la formule \eqref{EQooOWULooVQntyE} comme définition de l'angle $\widehat{ASB}$ est cependant trompeur parce que ça ne permet de définir les angles que sur une partie de \( \mathopen[ 0 , 2\pi \mathclose[\) sur laquelle le cosinus est injectif. Pour réellement définir tous les angles, il faut alors un peu bricoler.

    Sans vouloir être méchant, je crois que ceux qui prennent ça pour définition d'angle sont ceux qui donnent un cours sur le produit scalaire sans avoir l'intention de lier la définition d'une rotation comme composée de réflexions aux matrices de \( \SO(2)\) et aux fonctions trigonométriques.
\end{remark}
