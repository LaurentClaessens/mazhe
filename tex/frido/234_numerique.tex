% This is part of Mes notes de mathématique
% Copyright (C) 2010-2018, 2022
%   Laurent Claessens
% See the file LICENCE.txt for copying conditions.


%---------------------------------------------------------------------------------------------------------------------------
\subsection{Discrétisation en croix}
%---------------------------------------------------------------------------------------------------------------------------

Nous allons maintenant déduire une discrétisation du laplacien en discrétisant les opérations \( \partial^2_x\) et \( \partial^2_y\). Nous discrétisons \( \Omega\) en mailles carrées de côté \( h\) : \( x_k=kh\) et \( y_k=kh\). L'opération de dérivée partielle \( \partial_x\) est discrétisée par
\begin{equation}
	(D_x^+u)(x,y)=\frac{ u(x+h,y)-u(x,y) }{ h }
\end{equation}
ou
\begin{equation}
	(D_x^-u)(x,y)=\frac{ u(x,y)-u(x-h,y) }{ h }
\end{equation}
ou
\begin{equation}
	(D^0_xu)(x,y)=\frac{ u(x+h,y)-u(x-h,y) }{ 2h }
\end{equation}
où le \( h\) est sous-entendu dans les opérateurs \( D^0\), \( D^+\) et \( D^-\).

La dérivée partielle seconde \( \partial^2_xu\) peut être approximée par toutes les combinaisons imaginables, par exemple
\begin{equation}
	(D^-_xD^+_xu)(x,y)=\frac{ u(x+h,y)-2u(x,y)+u(x-h,y) }{ h^2 }.
\end{equation}
Pour évaluer la différence entre \( (\partial^2_xu)(x,y)\) et \( (D^-D^+u)(x,y)\), il est possible d'utiliser le théorème de Taylor en deux dimensions, mais nous pouvons également recycler ce qui a été fait. Nous posons \( u_y(x)=u(x,y)\) et alors \( (\partial_x^2u)(x,y)=u_y''(x)\) et le lemme~\ref{LEMooZECZooVKxOZZ}\ref{ITEMooRWUHooZJLKuL} donne, si \( u_y\) est de classe \( C^4\),
\begin{equation}
	| u_y''(x)-D^-D^+u_y(x) |\leq \frac{1}{ 12 }h^2\| u_y^{(4)} \|_{\infty}.
\end{equation}
Là, les opérateurs \( D^+\) et \( D^-\) sont ceux à une dimension. Mais nous avons \( (D^-D^+u_y)(x)=(D^-D^+u)(x,y)\) (à droite ce sont les opérateurs à deux dimensions), donc
\begin{equation}
	\big| (\partial^2_xu)(x,y)-(D^-D^+u)(x,y) \big|\leq \frac{1}{ 12 }h^2\| \partial^4_xu \|_{\infty}
\end{equation}
et nous pouvons écrire
\begin{equation}        \label{EQooCLSCooYLYJkU}
	(\partial^2_xu)(x,y)=(D^-D^+u)(x,y)+h^2R(x,y,h)
\end{equation}
où \( R\) est une fonction qui dépend de \( x\), \( y\) et \( h\), mais aussi de \( u\). Le point important est que \( R\) soit majoré par une quantité indépendante de \( h\), de telle sorte que nous ayons quelques garanties que négliger ce terme soit une bonne approximation lorsque \( h\to 0\).

Au niveau de la discrétisation, nous considérons \( x_i\) avec \( i=0,\ldots, N_x\) et \( y_j\) avec \( j=0,\ldots, N_y\). La discrétisation de \( -(\Delta u)(x,y)=f(x,y)\) donne, pour \( i=1,\ldots, N_x-1\) et \( j=1,\ldots, N_y-1\),
\begin{equation}        \label{EQooPWXBooPimUrU}
	\frac{1}{ h^2 }(-u_{i+1,j}+4u_{ij}-u_{i-1,j}-u_{i,j+1}+u_{i,j-1})=f_{ij}.
\end{equation}
Les équations avec \( i\) ou \( j\) valant \( 0\) ou \( N_x\), \( N_y\) sont les valeurs aux bords.

\begin{normaltext}
	Nous notons pour référence ultérieure la discrétisation suivante du laplacien :
	\begin{equation}    \label{EQooQQUHooNYVqta}
		(\Delta_hu)(x_i,y_j)=\frac{1}{ h^2 }\big( -4u_{i,j}+u_{i+1,j}+u_{i-1,j}+u_{i,j-1}+u_{i,j+1} \big).
	\end{equation}
	Elle vérifie
	\begin{equation}
		\Delta_hf=\Delta f+h^2\alpha(h).
	\end{equation}
	Cette discrétisation est dite «en croix» parce que les points exploités forment une croix.
\end{normaltext}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Discrétisation en carré}
%---------------------------------------------------------------------------------------------------------------------------

L'opérateur laplacien est défini par \( \Delta=\partial_x^2+\partial_y^2\), mais il existe de nombreuses autres façons de l'écrire.

\begin{lemma}
	Le laplacien est invariant par changement de coordonnées orthogonales. Plus précisément, si \( A\) est une matrice orthogonale, en posant \( u_i=\sum_kA_{ik}e_k\) nous avons
	\begin{equation}
		\sum_i\frac{ \partial^2 }{ \partial u_i^2 }f=\Delta f.
	\end{equation}
\end{lemma}

\begin{proof}
	Nous avons :
	\begin{equation}
		\frac{ \partial f }{ \partial u_i }=\sum_kA_{ik}\frac{ \partial f }{ \partial x_k },
	\end{equation}
	et donc
	\begin{equation}
		\sum_i\frac{ \partial^2f }{ \partial u_i^2 }=\sum_i\frac{ \partial  }{ \partial u_i }\left( \sum_kA_{ik}\frac{ \partial f }{ \partial x_k } \right)=\sum_{ijk}(A^t)_{ji}A_{ik}\partial^2f=\sum_{jk}(A^tA)_{jk}\partial_{jk}^2f.
	\end{equation}
	En particulier si \( A\) est une matrice orthogonale, \( (A^tA)_{jk}=\delta_{jk}\) et le résultat est prouvé.
\end{proof}

Les plus convaincus diront que \( \Delta=\nabla\cdot\nabla\) et que le produit scalaire est invariant sous changement de coordonnées orthogonales.

Nous avons déjà déduit la discrétisation \eqref{EQooQQUHooNYVqta} du laplacien :
\begin{equation}
	(\Delta_hu)(x_i,y_j)=\frac{1}{ h^2 }\big( -4u_{i,j}+u_{i+1,j}+u_{i-1,j}+u_{i,j-1}+u_{i,j+1} \big).
\end{equation}
Nous allons maintenant en déduire une par l'idée de décomposer le laplacien dans la base \( u=e_1+e_2\), \( v=e_1-e_2\). Pour cela nous introduisons les opérations (le nombre \( h\) dont dépendent ces opérateurs est sous-entendu)
\begin{subequations}
	\begin{align}
		(D^+_uf)(x,y) & =\frac{ f(x+h,y+h)-f(x,y) }{ h }  \\
		(D^+_vf)(x,y) & =\frac{ f(x+h,y-h)-f(x,y) }{ h }  \\
		(D^-_uf)(x,y) & =\frac{ f(x,y)-f(x-h,y-h) }{ h }  \\
		(D^-_vf)(x,y) & =\frac{ f(x,y)-f(x-h,y+h) }{ h }.
	\end{align}
\end{subequations}
Puisque
\begin{equation}
	\partial_u^2+\partial_v^2=2\Delta,
\end{equation}
nous discrétisons le laplacien par
\begin{equation}
	\Delta'_h=\frac{ 1 }{2}\big( D_u^-D_u^++D_v^-D_v^+ \big).
\end{equation}
Un peu de calcul donne :
\begin{subequations}   \label{EQooLHBDooSBFkho}
	\begin{align}
		(\Delta'_hf)(x,y)=\frac{1}{ 2h^2 }\Big( -4f(x,y) & +f(x+h,y+h)+f(x-h,y+h)        \\
		                                                 & +f(x+h,y-h)+f(x-h,y-h) \Big).
	\end{align}
\end{subequations}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Résolution de la discrétisation en croix}
%---------------------------------------------------------------------------------------------------------------------------

Les équations \eqref{EQooPWXBooPimUrU} forment un système d'équations linéaires à résoudre. Certaines peuvent être simplifiées parce qu'elles «touchent» le bord. Nous verrons cela un peu plus tard.

Nous allons d'abord numéroter correctement les équations de façon à ne pas avoir deux mais un seul indice. Notre fonction de numérotation sera
\begin{equation}
	\varphi(i,j)=(j-1)(N_x-1)+i
\end{equation}
avec \( i=1,\ldots, N_x-1\) et \( j=1,\ldots, N_y-1\). Cela correspond à numéroter les points de l'intérieur du quadrillage ligne par ligne de bas en haut, et de gauche à droite. Avec cela les équations \eqref{EQooPWXBooPimUrU} vont être numérotées par un seul indice \( I\) allant de \( \varphi(1,1)=1\) à \( \varphi(N_x-1,N_y-1)=(N_x-1)(N_y-1)\).

Si \( I=\varphi(i,j)\) alors nous avons vite
\begin{subequations}
	\begin{align}
		\varphi(i+1,j) & =I+1      \\
		\varphi(i,j+1) & =I+N_x-1  \\
		\varphi(i-1,j) & =I-1      \\
		\varphi(i,j-1) & =I-N_x+1.
	\end{align}
\end{subequations}
Nous posons \( U_I=u_{\varphi^{-1}(I)}\), et l'équation \eqref{EQooPWXBooPimUrU} devient
\begin{equation}
	\frac{1}{ h^2 }(-U_{I+1}+4U_I-U_{I-1}-U_{I+N_x-1}-U_{I-N_x+1})=f_I.
\end{equation}
Pour écrire la matrice représentant ce système, nous devons simplifier les équations qui doivent l'être. Par exemple avec \( I=1\), le terme \( U_{I-1}=U_0\) vaut \( u_{0,1}=f_{0,1}\). Ce n'est donc pas réellement une inconnue de notre problème.

Nous voulons mettre les équations sous la forme du système
\begin{equation}
	L_hU=F.
\end{equation}
Sur la ligne numéro \( I\) de \( L_h\), les éléments non nuls sont :
\begin{subequations}        \label{SUBEQQooSRQNooYrCNhj}
	\begin{align}
		L_{I,I}=4        \\
		L_{I,I+1}=-1     \\
		L_{I,I-1}=-1     \\
		L_{I,I+N_x-1}=-1 \\
		L_{I,I-N_x+1}=-1
	\end{align}
\end{subequations}
pour peu qu'ils existent. Par exemple pour \( I=1\), il n'y a pas d'éléments \( L_{I,I-1}\). Les indices \( I\) et \( J\) de \( L_{I,J}\) vont de \( 1\) à \( \varphi(N_x-1,N_y-1)=(N_y-1)(N_x-1)\).

Voici un dessin de notre situation :

\begin{center}
	\input{auto/pictures_tex/Fig_GMRNooCNBpIl.pstricks}
\end{center}

À chaque élément du quadrillage correspond une équation.
\begin{itemize}
	\item
	      Aux points simples sur le bord, correspondent des équations triviales parce que la fonction \(u \) y est directement donnée par les conditions aux bords.
	\item
	      Aux points étoilés entourés en traits continus correspondent des équations «incomplètes» parce que certains termes de l'équation \eqref{EQooPWXBooPimUrU} sont donnés par les conditions aux bords. Elle correspondent aussi aux lignes incomplètes de la matrice \( L_h\) où certains éléments donnés en \eqref{SUBEQQooSRQNooYrCNhj} n'existent pas.

	      Le membre de droite de ces équations est par contre enrichi de ce qui à gauche est «donné».
	\item
	      Aux points étoilés du centre entourés en traits discontinus correspondent des équations complètes.
\end{itemize}

Notons que \( f_{0,0}\) ne joue aucun rôle dans notre histoire parce que dans les équations \eqref{EQooPWXBooPimUrU}, chaque point \( (i,j)\) du maillage n'est lié qu'aux quatre points situés «à côté».


\begin{proposition} \label{PROPooWGTRooVjWhYY}
	La matrice \(L_h\) est
	\begin{enumerate}
		\item
		      irréductible et à diagonale fortement dominante\footnote{Définition~\ref{DEFooLSUTooHuXabV}. Le cas \( 1\times 1\) est discutablement à diagonale fortement dominante, il faut avouer.},
		\item       \label{ITEMooOOHPooDsvUPP}
		      une M-matrice,
		\item
		      inversible avec \( L_{h}>0\),
		\item
		      symétrique,
		\item
		      strictement définie positive.
	\end{enumerate}
\end{proposition}

\begin{proof}
	On divise la preuve.
	\begin{subproof}
		\spitem[Irréductible]
		Une matrice \( n\times n\) dont les deux premières diagonales sont entièrement composées d'éléments non nuls est toujours irréductible. En effet, la première lie l'élément \( (1,2)\) à l'élément \( (n-1,n)\) et donc permet de dire que tous les \( i<j\) sont connectés.

		La seconde diagonale lie l'élément \( (n,n-1)\) à l'élément \( (2,1)\).

		\spitem[Diagonale fortement dominante]
		En ce qui concerne la dominance de la diagonale, il faut sommer sur les lignes. Or chaque ligne contient (en valeur absolue) un \( 4\) sur la diagonale et au plus quatre éléments qui valent \( 1\). D'où
		\begin{equation}
			| L_{II} |\geq \sum_{J\neq I}| L_{IJ} |.
		\end{equation}
		La première ligne n'est jamais complète : elle contient un \( 4\) sur l'élément \( (1,1)\) et au maximum, deux \( 1\), plus à droite. Donc la matrice \( L_h\) est à diagonale fortement dominante.

		\spitem[M-matrice]

		D'après ce que nous venons de voir (proposition~\ref{PROPooWGTRooVjWhYY}), le théorème~\ref{THOooLZGSooSevggj} s'applique et \( L_h\) est une M-matrice\footnote{Notons que c'est ici que nous sommes content d'avoir posé \( -\Delta u=f\) dans le système \eqref{SYSooTANLooRgnIMp}, avec un signe négatif devant le laplacien. Sinon tous les signes auraient changé, et la matrice \( -L_h\) aurait été une M-matrice, au lieu de \( L_h\).}.

		\spitem[Inverse strictement positif]
		La proposition~\ref{PROPooZDMQooIZAbKK} nous assure qu'une M-matrice irréductible est d'inverse strictement positif. Donc \( L_h^{-1}>0\).

		\spitem[Symétrique]
		La ligne numéro \( I\) est
		\begin{equation}
			\big( \ldots ,\underbrace{-1}_{I-N_x+1},\ldots,-1,4,-1,\ldots,\underbrace{-1}_{I+N_x-1},\ldots \big)
		\end{equation}
		Prenons par exemple l'élément \( (I,I-N_x+1)\) qui vaut \( -1\). Son symétrique est l'élément \( (I-N_x+1,I)\) qui se trouve sur la ligne \( I-N_x+1\). Sur cette dernière ligne nous avons un \( -1\) sur la colonne \( I-N_x+1+N_x-1=I\). Donc l'élément \( (I-N_x+1,I)\) vaut bien \( -1\) et la matrice est symétrique.

		\spitem[Strictement définie positive]
		Vu que la matrice \( L_h\) est symétrique, irréductible à diagonale fortement dominante (proposition~\ref{PROPooWGTRooVjWhYY}), et comme ses éléments diagonaux sont strictement positifs (ils valent \( 4\)), la proposition~\ref{PROPooQBWQooBbeZLO} nous dit que \( L_h\) est strictement définie positive.
	\end{subproof}
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Consistance, convergence}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Définitions, mise en place}
%---------------------------------------------------------------------------------------------------------------------------

Soit un ouvert \( \Omega\subset \eR^n\) et un opérateur différentiel \( L\) sur \( \Omega\). Nous considérons le problème qui consiste à trouver une fonction \( u\) sur \( \Omega\) telle que
\begin{equation}
	Lu=f
\end{equation}
pour une fonction \( f\) donnée.

\begin{probleme}
	La définition suivante est une invention personnelle, n'est pas précise et mérite des commentaires de la part \randomGender{du lecteur}{de la lectrice}.
\end{probleme}
\begin{definition}[\cite{MonCerveau}]
	Un \defe{schéma numérique}{schéma numérique} de pas \( h\) pour \( Lu=f\) est la donnée de
	\begin{enumerate}
		\item
		      un nombre \( h>0\) supposé petit,
		\item
		      une quantité \( N\) de points \( x_i \) dans \( \Omega\) formant l'ensemble discret \( \Omega_h\),
		\item
		      une matrice \( L_h\) de taille \( N\times N\),
		\item
		      une solution \( u_h\colon \Omega_h\to \eR\) de l'équation \( (L_hu_h)(x_i)=f_i\) où nous avons posé \( f_i=f(x_i)\).
	\end{enumerate}
\end{definition}

\begin{normaltext}
	Évidemment pour qu'un schéma mérite le nom de schéma de pas \( h\) pour l'équation \( Lu=f\), il faut que le nombre \( h\) soit lié au choix des points \( x_i\), et que la matrice \( L_h\) soit liée à l'opérateur \( L\). La définition n'impose pas formellement de tels liens, parce qu'il y a de nombreuses façons d'approximer une équation différentielle en un système linéaire, sans compter que même l'équation \( (L_hu_h)_i=f_i\) peut se résoudre de beaucoup de façons, exactes ou approchées.

	Cela pour dire que le lien entre la solution exacte \( u\) et la solution approchée n'a rien d'évident, et va dépendre des choix faits lors de la discrétisation et lors de la résolution du système linéaire. Nous allons supposer dans un premier temps que l'équation \( L_hu_h=f\) est résolue exactement (nous avons un peu parlé de ces problèmes dans les sections~\ref{SECooQGLRooZQzzsA} et suivantes).
\end{normaltext}

\begin{definition}
	L'erreur \defe{de consistance}{erreur!de consistance} d'un schéma numérique est la fonction \( \tau_h\colon \Omega_h\to \eR\) définie par
	\begin{equation}        \label{EQooPFBBooJumDZO}
		\tau_h(x_i)=(L_hu)_i-(Lu)(x_i).
	\end{equation}
\end{definition}
Il y a un jeu de notation pas tout à fait évident dans la définition \eqref{EQooPFBBooJumDZO}. En effet, \( L_h\) est une matrice, et ne s'applique donc à priori pas immédiatement à une fonction. Ce que signifie la notation \( (L_hu)_i\) est que l'on applique la matrice \( L_h\) au vecteur \( j\mapsto u(x_j)\) et que l'on prend la composante \( i\) du résultat.

\begin{definition}
	Nous disons que le schéma est \defe{consistant}{schéma!consistant} avec l'opérateur différentiel \( L\) lorsque
	\begin{equation}        \label{EQooMPQYooCZsaAT}
		\lim_{h\to 0^+} \| \tau_h \|=0
	\end{equation}
	où la norme \( \| . \|\) est souvent la norme uniforme, c'est-à-dire \( \| \tau_h \|=\max_i\tau_h(x_i)\).
\end{definition}

Notons que le lien entre \( h\) et le choix des \( x_i\) fait partie de la définition du schéma. Sur un segment de longueur \( \ell\), lorsque \( h\) n'est pas un diviseur de \( \ell\), le schéma devrait expliquer ce que l'on fait pour que la limite \eqref{EQooMPQYooCZsaAT} ait un sens.

\begin{definition}
	Le schéma \( (\Omega_h,L_h)\) est \defe{consistant à l'ordre \( p\)}{consistance!ordre} avec l'opérateur différentiel \( L\) pour la norme \( \| . \|\) si il existe une constante \( C\) indépendante de \( h\) telle que
	\begin{equation}
		\| \tau_h \|\leq Ch^p.
	\end{equation}
\end{definition}

\begin{definition}
	L'\defe{erreur de discrétisation}{erreur!discrétisation} entre la solution \( u\) du problème \( Lu=f\) et la solution approchée \( u_h\) sur \( \Omega_h\) est la fonction
	\begin{equation}
		\begin{aligned}
			e_h\colon \Omega_h & \to \eR             \\
			x_i                & \mapsto u(x_i)-u_i.
		\end{aligned}
	\end{equation}
	où \( u_i=u_h(x_i)\) est la solution approchée.

	Le schéma discret \( (L_hu_h)(x_i)=f_i\) est \defe{convergent}{schéma discret convergent} si \( \lim_{h\to 0} \| e_h \|=0\). Si de plus, il existe une constante \( C\), et \( p>0\), tels que
	\begin{equation}
		\| e_h \|\leq Ch^p,
	\end{equation}
	alors nous disons que le schéma est convergent à l'\defe{ordre}{ordre!de convergence d'un schéma} \( p\).
\end{definition}

Si l'erreur de consistance est petite, le \emph{problème} est bien approximé par le système linéaire. Cela n'implique cependant pas que la solution trouvée soit bien approximée.

\begin{example}[Deux opérateurs différentiels proches dont les solutions sont loin]
	Soit la partie \( \Omega=\mathopen] 0 , \infty \mathclose[\), et les problèmes
	\begin{subequations}
		\begin{numcases}{}
			L_1u=u'=0\\
			u(0)=1
		\end{numcases}
	\end{subequations}
	et
	\begin{subequations}
		\begin{numcases}{}
			L_2v=v'-\epsilon v=0\\
			v(0)=1.
		\end{numcases}
	\end{subequations}
	Les solutions exactes sont \( u(x)=1\) et \( v(x)= e^{\epsilon x}\).

	En ce qui concerne les opérateurs, quelle que soit la norme utilisée, nous avons
	\begin{subequations}
		\begin{align}
			\| L_1-L_2 \| & =\sup_{\| f \|=1}\| L_1(f)-L_2(f) \| \\
			              & =\sup_{\| f \|=1}\| \epsilon f \|    \\
			              & =\epsilon.
		\end{align}
	\end{subequations}
	Donc lorsque \( \epsilon\) est petit, l'opérateur \( L_2\) approxime bien l'opérateur \( L_1\). Pour toutes les normes. Mais
	\begin{equation}
		\big| u(x)-v(x) \big|=| 1- e^{\epsilon x} |,
	\end{equation}
	donc quel que soit \( \epsilon\) nous avons \( \| u-v \|_{\infty}=\infty\). Et d'ailleurs, quelle que soit la norme raisonnable que nous mettons sur l'espace des fonctions, avoir \( \| u-v \|=\infty\) semble inévitable.

	Donc deux opérateurs différentiels proches peuvent avoir des solutions lointaines.
\end{example}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Exemple}
%---------------------------------------------------------------------------------------------------------------------------

Soit l'opérateur différentiel \( L\) donné par
\begin{equation}
	Lu=-u''+cu
\end{equation}
où \( c\) est une fonction. Nous considérons sur \( \Omega=\mathopen] 0 , 1 \mathclose[\) l'équation différentielle
\begin{equation}
	Lu=0.
\end{equation}
En ce qui concerne la discrétisation, nous définissons le maillage \( \Omega_h=\{x_i=ih\}\) avec \( i=0,\ldots, N+1\). La solution approchée discrètement sera le vecteur \( v\) qui peut être vu comme fonction \( v\colon \Omega_h\to \eR\). Les nombres \( v_0\) et \( v_{N+1}\) sont à priori donnés par les conditions aux bords. Pour les autres \( v_i\) nous avons les équations
\begin{equation}
	(L_hv)_i=-\frac{ v_{i+1}-2v_i+v_{i-1} }{ h^2 }+c(x_i)v_i.
\end{equation}
Cela est la définition de l'opérateur \( L_h\), et le vecteur \( v\) solution de \( L_hv=0\), est la solution du problème au sens de la méthode des différences finies (pour peu qu'il existe, soit unique et tout ça).

Pour calculer l'erreur de consistance, nous considérons une fonction \( u\) et nous posons \( u_i=u(x_i)\). Le vecteur \( (u_i)\) ainsi construit est approximé par \( v\) (on espère). Nous avons :
\begin{equation}
	\tau_h(x_i)=-\frac{ u_{i+1}-2u_i+u_{i-1} }{ h^2 }-c(x_i)u_i-(Lu)(x_i).
\end{equation}
Pour étudier cela nous développons \( u_{i+1}=u(x_i+h)\) et \( u_{i-1}=u(x_i-h)\) à l'ordre \( 4\) : il existe \( \alpha_i\in\mathopen[ x_i , x_i+h \mathclose]\) et \( \beta_i\in\mathopen[ x_i-h , x_i \mathclose]\) tels que
\begin{equation}
	u_{i+1}=u(x_i)+hu'(x_i)+\frac{ h^2 }{2}u''(x_i)+\frac{ h^3 }{ 3! }u^{(3)}(x_i)+\frac{ h^4 }{ 4! }u^{(4)}(\alpha_i)
\end{equation}
et
\begin{equation}
	u_{i-1}=u(x_i)-hu'(x_i)+\frac{ h^2 }{2}u''(x_i)-\frac{ h^3 }{ 3! }u^{(3)}(x_i)+\frac{ h^4 }{ 4! }u^{(4)}(\beta_i).
\end{equation}
Après simplification de plusieurs termes,
\begin{equation}
	\tau_h(x_i)=-\frac{ u_{i+1}-2u_i+u_{i-1} }{ h^2 }-c_iu_i+u''(x_i)+c_iu_i=\frac{ h^2 }{ 4! }\big( u^{(4)}(\alpha_i)+u^{(4)}(\beta_i) \big).
\end{equation}
Parler de la consistance du schéma demande d'étudier \( \lim_{h\to 0^+}\| \tau_h \| \), et pour cela, il faut préciser la norme avec laquelle nous voulons travailler. L'ordre de consistance va dépendre de la norme utilisée.

Pour la norme \(  \| . \|_{\infty}\), les nombres \( u^{(4)}(\alpha_i)\) et \( u^{(4)}(\beta_i)\) se majorent par \(  \| u^{(4)} \|_{\infty}\) et nous avons
\begin{equation}
	\| \tau_h \|_{\infty}\leq \frac{ h^2 }{ 12 }\| u^{(4)} \|_{\infty}.
\end{equation}
Nous avons consistance d'ordre \( 2\).

\begin{remark}
	La valeur de \( \| \tau_h \|_{\infty}\) dépend de la fonction \( u\) sur laquelle nous la calculons. Cependant nous avons convergence \( \| \tau_h \|_{\infty}\to 0\) pour toute fonction (de classe disons, \( C^4\)).

	La constante \( C\) pour laquelle nous avons \( \| \tau_h \|\leq Ch^2\) et donc qui nous vaut de pouvoir dire que la consistance est d'ordre \( 2\) ne dépend pas de \( h\), ni des valeurs ponctuelles de \( u\) ou de ses dérivées, mais dépend des normes de \( u\) et de ses dérivées (en l'occurrence seulement de la norme de \( u^{(4)}\).)
\end{remark}

Étudions la consistance pour la norme \( L_1\) :
\begin{equation}
	\| \tau_h \|_1=\sum_i| \tau_h(x_i) |\leq \frac{ h^2 }{ 12 }\sum_i\| u^{(4)} \|_{\infty}
\end{equation}
où nous avons majoré chacun des \( u^{(4)}(\alpha_i)\) par \( \| u^{(4)} \|_{\infty}\). Combien de termes dans la somme ? Nous avons \( h=1/(N-1)\) et donc \( N=(1+h)/h\), ce qui donne
\begin{equation}
	\| \tau_h \|_1\leq N\frac{ h^2 }{ 12 }\| u^{(4)} \|_{\infty}=(1+h)Ch.
\end{equation}
La constante \( 1+h\) se majore par n'importe quelle constante strictement plus grande que \( 1\). Nous pouvons donc la rentrer dans \( C\) et écrire
\begin{equation}
	\| \tau_h \|_1\leq Ch
\end{equation}
et donc avoir la consistance à l'ordre \( 1\).

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Consistance, stabilité et convergence}
%---------------------------------------------------------------------------------------------------------------------------

\begin{lemma}       \label{LEMooUOUMooPCoAtA}
	Soit un opérateur différentiel \( L\), soit \( u\) la solution de \( Lu=f\) et un schéma numérique \( (L_h,\Omega_h)\) pour cette équation. Nous notons \( u_h\) la solution de \( L_hu_h=f\). Alors nous avons
	\begin{equation}
		L_he_h=\tau_h
	\end{equation}

	Et si de plus \( L_h\) est inversible,
	\begin{equation}
		\| e_h \|\leq \| L_h^{-1} \|\| \tau_h \|.
	\end{equation}
\end{lemma}

\begin{proof}
	Par définition \( u_h\) est solution de \( L_hu_h=f\) en tant que fonction sur \( \Omega_h\). Nous avons donc
	\begin{equation}
		L_he_h=L_hu_h-L_hu
	\end{equation}
	où \( u\) doit être compris comme la restriction de \( u\) à \( \Omega\). En appliquant au point \( x_i\),
	\begin{equation}
		(L_he_h)(x_i)=\underbrace{(L_hu_h)(x_i)}_{=f_i}-(L_hu)(x_i),
	\end{equation}
	mais \( f_i=(Lu)(x_i)\) parce que \( u\) est solution de \( Lu=f\). Donc
	\begin{equation}
		(L_he_h)(x_i)=(Lu)(x_i)-(L_hu)(x_i)=\tau_h(x_i).
	\end{equation}

	Si la matrice \( L_h\) est inversible nous avons \( e_h=L_h^{-1}\tau_h\) et donc
	\begin{equation}
		\| e_h \|\leq \| L_h^{-1} \|\| \tau_h \|
	\end{equation}
	par le lemme~\ref{LEMooIBLEooLJczmu}.
\end{proof}

Bien entendu, en tant qu'opérateur linéaire sur un espace de dimension finie, l'opérateur \( L_h^{-1}\) est borné pour chaque \( h\). Mais si il n'y a pas une borne uniforme en \( h\), alors le lemme~\ref{LEMooUOUMooPCoAtA} dit qu'il n'y a pas d'espoir de majorer \( \| e_h \|\) de façon à passer à la limite \( \lim_{h\to 0} \| L_h^{-1} \|\).

\begin{definition}
	Un schéma numérique est \defe{stable}{stable!schéma numérique} si il existe une constante \( C>0\) indépendante de \( h\) telle que \( \| L_h^{-1} \|\leq C\).
\end{definition}

\begin{theorem}     \label{THOooEPQQooUQMcgF}
	En deux parties.
	\begin{enumerate}
		\item
		      Si un schéma discret est consistant et stable, alors il est convergent.
		\item
		      Si de plus il est consistant à l'ordre \( p\), alors il est convergent à l'ordre \( p\).
	\end{enumerate}
\end{theorem}

\begin{proof}
	Nous savons du lemme~\ref{LEMooUOUMooPCoAtA} (qui s'applique parce que l'inversibilité de \( L_h\) est dans la définition de la stabilité) que  \( \| e_h \|\leq \| L_h^{-1} \| \| \tau_h \|\) et que  \( \| L_h^{-1} \|\leq C  \). En passant à la limite\footnote{Toutes les limites \( h\to 0\) sont en réalité des limites \( h\to 0^+\), mais nous allégeons cette notation.},
	\begin{equation}
		\lim_{h\to 0} \| e_h \|\leq C\lim_{h\to 0} \| \tau_h \|=0.
	\end{equation}
	La dernière limite est le fait que le schéma soit consistant. Le schéma est donc convergent.

	Si de plus il est consistant à l'ordre \( p\), alors
	\begin{equation}
		\| e_h \|\leq C\| \tau_h \|\leq C'h^p
	\end{equation}
	Il est donc également convergent à l'ordre \( p\).
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Exemple : schéma à cinq points, laplacien en croix}
%---------------------------------------------------------------------------------------------------------------------------

Nous avions développé le schéma dont l'opérateur sur \( \Omega_h\) est (voir \eqref{EQooPWXBooPimUrU})
\begin{equation}
	(L_hu_h)(x_i,y_j)=\frac{1}{ h^2 }\big( -u_{i+1,j}-u_{i,j+1} +4u_{i,j}-u_{i-1,j}-u_{i,j-1}  \big).
\end{equation}

\begin{proposition}
	Le schéma est :
	\begin{enumerate}
		\item
		      consistant à l'ordre \( 2\),
		\item
		      stable pour la norme uniforme et
		      \begin{equation}
			      \| L_h^{-1} \|_{\infty}\leq \frac{1}{ 8 },
		      \end{equation}
		\item
		      convergent à l'ordre \( 2\) pour la norme \( \| . \|_{\infty}\).
	\end{enumerate}
\end{proposition}

\begin{proof}
	Cet opérateur avait été construit de telle sorte à avoir (voir \eqref{EQooCLSCooYLYJkU})
	\begin{equation}
		(\Delta u)(x_i,y_j)=(L_hu)(x_i,y_i)+h^2R(x,y,h)
	\end{equation}
	où \( R\) peut être majoré indépendamment de \( h\). En tant que fonctions sur \( \Omega_h\) nous avons
	\begin{equation}
		\tau_h=\Delta u-L_hu=h^2R(x,y,h),
	\end{equation}
	et donc \( \| \tau_h \|_{\infty}\leq Ch^2\), parce que le lemme~\ref{LEMooZECZooVKxOZZ}\ref{ITEMooRWUHooZJLKuL} donne aussi
	\begin{equation}
		\| R \|_{\infty}\leq C\max\{ \| \frac{ \partial^4u }{ \partial x^4 } \|_{\infty},\| \frac{ \partial^4u }{ \partial y^4 } \|_{\infty} \}.
	\end{equation}

	En ce qui concerne la stabilité nous allons utiliser le théorème~\ref{THOooWIFGooBQpddF}. Nous considérons la fonction
	\begin{equation}
		g(x,y)=-\frac{1}{ 4 }(x^2+y^2),
	\end{equation}
	qui vérifie \( -\Delta g=1\) sur le carré \( \mathopen[ 0 , 1 \mathclose]^2\). Nous considérons le vecteur \( g_h\) d'indices \( (i,j)\mapsto g_{ij}=g(x_i,y_j)\) sur lequel nous calculons \( L_h\) :
	\begin{equation}
		(L_hg_h)_{ij}=\frac{1}{ h^2 }(-g_{i+1,j}-g_{i,j+1}+4g_{ij}-g_{i-1,j}-g_{i,j-1});
	\end{equation}
	en remplaçant les \( g\) par leurs valeurs en termes de \( x_i\), \( x_{i-1}\), \( x_{i+1}\), \( y_j\), \( y_{j-1}\) et \( y_{j+1}\), et en tenant compte du fait que \( x_k=kh\) et \( y_l=lh\), nous avons :
	\begin{equation}
		(L_hg_h)_{ij}=\frac{1}{ 4 }\big( (i+1)^2-j^2+i^2+(j+1)^2-4i^2-4j^2+(i-1)^2+j^2+i^2+(j-1)^2 \big)=1.
	\end{equation}
	Donc \( L_hg_h=1\).

	Comme \( L_h\) est une M-matrice (proposition~\ref{PROPooWGTRooVjWhYY}\ref{ITEMooOOHPooDsvUPP}), le théorème~\ref{THOooWIFGooBQpddF} nous dit alors que \( L_h^{-1}\) vérifie
	\begin{equation}
		\| L_h^{-1} \|_{\infty}\leq \| g_h \|_{\infty}.
	\end{equation}
	Mais
	\begin{equation}
		\| g_h \|_{\infty}\leq \| g \|_{\infty}=g\big( \frac{ 1 }{2},\frac{ 1 }{2} \big)=\frac{1}{ 8 }.
	\end{equation}
	Notons que cela est bien une inégalité et non une égalité parce que rien n'assure que le point \( (1/2,1/2)\) soit sur le maillage; donc rien n'assure que la valeur \( g(1/2,1/2)\) ne soit parmi les valeurs du vecteur discrétisé \( g_h\).

	Notre schéma numérique est stable et consistant à l'ordre \( 2\) pour la norme \( \| . \|_{\infty}\). Le théorème~\ref{THOooEPQQooUQMcgF} dit alors que le schéma est convergent à l'ordre \( 2\) pour la même norme.
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Autres laplaciens}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Nous avons vu le laplacien en croix \eqref{EQooQQUHooNYVqta}
\begin{subequations}\label{EQooOBWUooDEWKYv}
	\begin{align}
		(\Delta_hf)(x,y)=\frac{1}{ h^2 }\big( -4f(x,y) & +f(x+h,y)+f(x-h,y)       \\
		                                               & +f(x,y+h)+f(x,y-h) \big)
	\end{align}
\end{subequations}
qui vérifie
\begin{equation}        \label{EQooQITHooZVJlVa}
	\Delta_hf=\Delta f+Kh^2,
\end{equation}
ainsi que le laplacien en carré \eqref{EQooLHBDooSBFkho}
\begin{subequations}   \label{EQooUOYVooRpAMOC}
	\begin{align}
		(\Delta'_hf)(x,y)=\frac{1}{ 2h^2 }\Big( -4f(x,y) & +f(x+h,y+h)+f(x-h,y+h)       \\
		                                                 & +f(x+h,y-h)+f(x-h,y-h) \Big)
	\end{align}
\end{subequations}
qui vérifie également \( \Delta_h'f=\Delta f+Kh^2\).

À priori toutes combinaisons de la forme
\begin{equation}
	a\Delta_h+b\Delta_h'
\end{equation}
avec \( a+b=1\) sont valable comme tentative de discrétiser le laplacien. Ce sont des schémas à \( 9\) points. Évidemment la matrice \( L_h\) correspondante va être moins creuse, mais nous pouvons espérer ajuster \( a\) et \( b\) de telle sorte à obtenir une consistance d'un ordre supérieur à \( 2\).

Nous allons développer les \( \Delta_hf\) et \( \Delta_h'f\) à l'ordre \( 4\) (reste à l'ordre \( 6\)). Quelques remarques avant de commencer.
\begin{enumerate}
	\item
	      Allez relire la proposition~\ref{PROPooQKZIooXTvkIr} et les notations qui vont avec pour comprendre les différentielles.
	\item
	      Écrivez les formules du type \eqref{EQooXRWWooMoKoOB} pour \( d^2f\) et \( d^4f\).
	\item
	      Allez relire le développement de Taylor du théorème~\ref{THOooTDFRooEkChgi}.
	\item
	      À l'ordre zéro, il n'y a rien, parce que le terme \( -4f(x,y)\) compense les quatre termes d'ordre zéro des autres termes.
	\item
	      Aux ordres impairs, il n'y a rien. En effet, prenons un nombre impair \( l\) et la formule
	      \begin{equation}
		      (d^lf)_x(h,\ldots, h)=\sum_{i_1,\ldots, i_l}h_{i_1}\ldots h_{i_l}\frac{ \partial^lf }{ \partial x_{i_1}\ldots \partial x_{i_l} }(x).
	      \end{equation}
	      Nous avons
	      \begin{equation}
		      (d^lf)_x(h,\ldots, h)+(d^lf)_x(-h,\ldots, -h)=0.
	      \end{equation}
	      Or dans les expressions \eqref{EQooUOYVooRpAMOC} et \eqref{EQooOBWUooDEWKYv}, les termes arrivent par paires opposées.
\end{enumerate}

Commençons par calculer \( h^2(\Delta_hf)(x,y)\).
\begin{description}
	\item[Ordre \( 4\)]. Le premier terme est :
	\begin{equation}
		(d^2f)_{(x,y)}\big( (h,0),(h,0) \big)=h^2(d^2f)_{(x,y)}\big( (1,0),(1,0) \big).
	\end{equation}
	La formule \eqref{EQooXRWWooMoKoOB} à peine adaptée permet de calculer ça explicitement.

	Il y a encore les termes du même type avec \( (0,1)\), \( (-1,0)\) et \( (0,-1)\).

	\item[Ordre \( 4\)]
		Cette fois, ce sont \( 4\) termes du type
		\begin{equation}
			h^4(d^4f)_{(x,y)}\big( (1,0),(1,0),(1,0),(1,0) \big)
		\end{equation}
		à calculer.
\end{description}
Cela fait beaucoup de termes à calculer. Je vous laisse vous persuader que le programme suivant en Sage nous donne les coefficients.
\lstinputlisting{tex/sage/coefs.sage}

Le résultat est, en utilisant la formule
\begin{equation}
	\partial^4_xf+2\partial_{xxyy}^4f+\partial^4_yf=\Delta\Delta f,
\end{equation}
nous avons
\begin{subequations}
	\begin{align}
		(\Delta_hf)(x,y) & =\frac{ 1 }{2}(2\partial_x^2f+2\partial_y^2f)(x,y)+\frac{1}{ 4! }2h^2(\partial^4_xf+\partial_y^4f)(x,y)+Kh^4 \\
		                 & =(\Delta f)(x,y)+\frac{1}{ 12 }h^2(\partial_x^4f+\partial_y^4f)(x,y)+Kh^4                                    \\
		                 & =\Delta f+\frac{ h^2 }{ 12 }\Delta\Delta f-\frac{ h^2 }{ 12 }2\partial^4_{xxyy}f+Kh^4                        \\
		                 & =\Delta f+\frac{ h^2 }{ 12 }\Delta\Delta f-\frac{ h^2 }{ 6 }\partial^4_{xxyy}f+Kh^4
	\end{align}
\end{subequations}
où \( K\) est une constante qui peut être majorée en termes des dérivées quatrièmes de \( f\). En particulier la plus grande des normes supremum de ces dérivées.

Le même genre de calculs donnent
\begin{equation}
	(\Delta'_hf)(x,y)=\frac{ 1 }{2}\Big[  \frac{ 1 }{2}4\Delta f+\frac{h^2}{ 4! }(4\partial_x^4f+24\partial_x^2\partial_y^2f+4\partial_y^2f)   \Big]+Kh^4.
\end{equation}
Ça donne :
\begin{equation}
	(\Delta'_hf)=\Delta f+\frac{ h^2 }{ 12 }\Delta\Delta f+\frac{ h^2 }{ 3 }\partial^4_{xxyy}f+Kh^4
\end{equation}
avec redéfinition du \( K\); nous ne le préciserons plus à chaque fois.


Nous avons donc le résultat proposé dans \cite{ooURUTooREoTyo} :
\begin{equation}
	a\Delta_hf+b\Delta_h'f=(a+b)\Delta f+(a+b)\frac{ h^2 }{ 12 }\Delta^2f+h^2\frac{1}{ 6 }(a-2b)\partial^4_{xxyy}f+Kh^4.
\end{equation}
L'idée est d'appliquer ça à une fonction \( u\) qui vérifie l'équation différentielle \( -\Delta u=f\) (attention au clash de notation pour \( f\)). Le mieux est de supprimer le terme en \( \partial_{xxyy}f\) en demandant \( a-2b=0\). Nous avons donc à résoudre le système
\begin{subequations}
	\begin{numcases}{}
		a+b=1\\
		a-2b=0.
	\end{numcases}
\end{subequations}
Qui propose une décomposition \( PLU\) pour résoudre ce système linéaire ? Quelle que soit la manière, la solution est
\begin{equation}
	\begin{aligned}[]
		a=\frac{ 2 }{ 3 }, &  & b=\frac{1}{ 3 }.
	\end{aligned}
\end{equation}
Nous allons donc étudier la discrétisation à neuf points
\begin{equation}        \label{EQooRFJVooVplhEr}
	L_h=\frac{ 2 }{ 3 }\Delta_h+\frac{1}{ 3 }\Delta'_h.
\end{equation}
En faisant quelques additions nous trouvons que l'opération
\begin{equation}        \label{EQooKBIIooDWciKl}
	\begin{aligned}[]
		(L_hu)(x_i,y_j)=\frac{1}{ 6h^2 }\Big( -20u_{ij} & +4\big( u_{i+1,j}+u_{i-1,j}+u_{i,j+1}+u_{i,j-1} \big) \\
		                                                & +u_{i+1,j+1}+u_{i-1,j+1}+u_{i+1,j-1}+u_{i-1,j-1}\Big)
	\end{aligned}
\end{equation}
vérifie
\begin{equation}        \label{EQooTLHQooXgZGef}
	L_hf=\Delta f+\frac{ h^2 }{ 12 }\Delta^2 f+Kh^4.
\end{equation}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Travail avec le laplacien à 9 points}
%---------------------------------------------------------------------------------------------------------------------------

Nous allons écrire un schéma numérique pour l'équation différentielle \( -\Delta u=f\) utilisant la discrétisation à 9 points du laplacien. Nous recopions ses propriétés fondamentales \eqref{EQooRFJVooVplhEr}, \eqref{EQooKBIIooDWciKl}, \eqref{EQooTLHQooXgZGef} :
\begin{equation}
	L_h=\frac{ 2 }{ 3 }\Delta_h+\frac{1}{ 3 }\Delta'_h,
\end{equation}
et
\begin{equation}
	\begin{aligned}[]
		(L_hu)(x_i,y_j)=\frac{1}{ 6h^2 }\Big( -20u_{ij} & +4\big( u_{i+1,j}+u_{i-1,j}+u_{i,j+1}+u_{i,j-1} \big)  \\
		                                                & +u_{i+1,j+1}+u_{i-1,j+1}+u_{i+1,j-1}+u_{i-1,j-1}\Big),
	\end{aligned}
\end{equation}
et
\begin{equation}        \label{EQooSUKTooXyWQQm}
	L_hf=\Delta f+\frac{ h^2 }{ 12 }\Delta^2 f+Kh^4.
\end{equation}

Nous appliquons \eqref{EQooSUKTooXyWQQm} à \( u\) et nous isolons \( \Delta u\) :
\begin{equation}
	\Delta u=L_hu-\frac{ h^2 }{ 12 }\Delta^2u+Kh^4=\frac{1}{ 6h^2 }T_hu+\frac{ h^2 }{ 12 }\Delta f+Kh^4
\end{equation}
où nous avons utilisé \( \Delta^2u=-\Delta f\) et avons noté
\begin{equation}
	T_hu=-20u_{ij}+4( u_{i+1,j}+u_{i-1,j}+u_{i,j+1}+u_{i,j-1} )+u_{i+1,j+1}+u_{i-1,j+1}+u_{i+1,j-1}+u_{i-1,j-1}.
\end{equation}
Nous imposons maintenant \( \Delta u=-f\) en écrivant
\begin{equation}
	\frac{1}{ 6h^2 }T_hu=-f-\frac{ h^2 }{ 12 }\Delta f+\alpha(h)h^4.
\end{equation}
Une idée est de remplacer \( \Delta f\) par son approximation en croix \eqref{EQooQITHooZVJlVa} :
\begin{equation}
	T_hu=-6h^2f-\frac{ h^4 }{ 2 }(\Delta_hf+Kh^2)+\alpha(h)h^6
\end{equation}
Avec quelques calculs nous trouvons le schéma numérique suivant :
\begin{subequations}        \label{EQooKUMVooCVrzjt}
	\begin{align}
		20u_{ij} & -4( u_{i+1,j}+u_{i-1,j}+u_{i,j+1}-u_{i,j-1} )
		-u_{i+1,j+1}-u_{i-1,j+1}-u_{i+1,j-1}-u_{i-1,j-1}                                           \\
		         & =\frac{ h^2 }{2}(8f_{ij}+f_{i+1,j}+f_{i-1,j}+f_{i,j+1}+f_{i,j-1})+\alpha(h)h^6.
	\end{align}
\end{subequations}
En oubliant le terme en \( \alpha(h)h^6\), nous obtenons un système d'équations linéaires.

\begin{probleme}
	Il me semble que ce schéma donne une convergence d'ordre \( 6\). C'est correct ?
\end{probleme}
