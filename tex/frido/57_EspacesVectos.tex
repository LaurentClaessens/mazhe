% This is part of Mes notes de mathématique
% Copyright (c) 2008-2025
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.


%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Valeur propre et vecteur propre}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Généralités}
%---------------------------------------------------------------------------------------------------------------------------

Nous savons qu'une application \emph{linéaire} \( A\colon \eR^3\to \eR^3\) est complètement définie par la donnée de son action sur les trois vecteurs de base, c'est-à-dire par la donnée de
\begin{equation}
	\begin{aligned}[]
		Ae_1, &  & Ae_2 &  & \text{et} &  & Ae_3.
	\end{aligned}
\end{equation}
La matrice d'une application \( A\) se forme en mettant simplement les vecteurs \( Ae_1\), \( Ae_2\) et \( Ae_3\) en colonne. Donc la matrice
\begin{equation}		\label{EqExempleALin}
	A=\begin{pmatrix}
		3 & 0 & 0 \\
		0 & 0 & 1 \\
		0 & 1 & 0
	\end{pmatrix}
\end{equation}
signifie que l'application linéaire \( A\) envoie le vecteur \( e_1\) sur \( \begin{pmatrix}
	3 \\
	0 \\
	0
\end{pmatrix}\), le vecteur \( e_2\) sur \( \begin{pmatrix}
	0 \\
	0 \\
	1
\end{pmatrix}\) et le vecteur \( e_3\) sur \( \begin{pmatrix}
	0 \\
	1 \\
	0
\end{pmatrix}\).
Pour savoir comment \( A\) agit sur n'importe quel vecteur, on applique la règle de produit vecteur\( \times\)matrice :
\begin{equation}
	\begin{pmatrix}
		1 & 2 & 3 \\
		4 & 5 & 6 \\
		7 & 8 & 9
	\end{pmatrix}\begin{pmatrix}
		x \\
		y \\
		z
	\end{pmatrix}=
	\begin{pmatrix}
		x+2y+3z  \\
		4x+5y+6z \\
		7x+8y+9z
	\end{pmatrix}.
\end{equation}

Une chose intéressante est de savoir quelles sont les directions invariantes de la transformation linéaire. Par exemple, on peut lire sur la matrice \eqref{EqExempleALin} que la direction \( \begin{pmatrix}
	1 \\
	0 \\
	0
\end{pmatrix}\) est invariante : elle est simplement multipliée par \( 3\). Dans cette direction, la transformation est juste une dilatation. Afin de savoir si \( v\) est un vecteur d'une direction conservée, il faut voir si il existe un nombre \( \lambda\) tel que \( Av=\lambda v\), c'est-à-dire voir si \( v\) est simplement dilaté.

L'équation \( Av=\lambda v\) se récrit \( (A-\lambda\mtu)v=0\), c'est-à-dire qu'il faut résoudre l'équation
\begin{equation}
	(A-\lambda\mtu)\begin{pmatrix}
		x \\
		y \\
		z
	\end{pmatrix}=
	\begin{pmatrix}
		0 \\
		0 \\
		0
	\end{pmatrix}.
\end{equation}
Nous savons qu'une telle équation ne peut avoir de solutions que si \( \det(A-\lambda\mtu)=0\). La première étape est donc de trouver les \( \lambda\) qui vérifient cette condition.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Dans le vif du sujet}
%---------------------------------------------------------------------------------------------------------------------------

\begin{propositionDef}      \label{DefooMMKZooVcskCc}
	Soit un \( \eK\)-espace vectoriel \( E\) et un endomorphisme \( T\colon E\to E\). Un \defe{vecteur propre}{vecteur!propre} de \( T\) est un vecteur \( v \neq 0\) tel que \( T(v)=\lambda v\) pour un certain \( \lambda\in \eK\). Dans ce cas, \( \lambda\) est la \defe{valeur propre}{valeur!propre} de \( v\).

	Soit \( \lambda\in \eK\). L'ensemble des vecteurs propres de \( T\) pour la valeur propre \( \lambda\) est un espace vectoriel nommé \defe{espace propre}{espace propre}.
\end{propositionDef}

\begin{proof}
	Soit \( \lambda\in \eK\). Soient des vecteurs propres \( v,w\) pour la valeur propre \( \lambda\). Si \( \alpha\in \eK\), en utilisant la linéarité de \( T\), nous avons
	\begin{equation}
		T(\alpha v+w)=\alpha T(v)+T(w)=\alpha\lambda v+\lambda w=\lambda(\alpha v+w),
	\end{equation}
	donc \( \alpha v+w\) est un vecteur propre de \( T\) pour la même valeur propre \( \lambda\).
\end{proof}

\begin{definition}
	L'ensemble des valeurs propres de l'endomorphisme \( T\) est son \defe{spectre}{spectre d'un endomorphisme} et est noté \( \Spec(T)\).
\end{definition}

\begin{remark}
	Le nombre zéro peut être une valeur propre; c'est le vecteur zéro qui ne peut pas être vecteur propre. La matrice nulle est une matrice diagonalisable.
\end{remark}

\begin{lemma}[\cite{BIBooAVGXooZZlEGJ}]     \label{LEMooWHWUooFFXlzT}
	Le spectre d'une matrice est égal au spectre de sa transposée : \( \Spec(T)=\Spec(T^t)\).
\end{lemma}

\begin{proof}
	Nous savons que \( T\) est inversible si et seulement si \( T^t\) l'est parce que si \( TS=\mtu\) alors \( S^tT^t=\mtu\). Nous avons équivalence entre les énoncés suivants :
	\begin{itemize}
		\item \( \lambda\) est une valeur propre de \( T\)
		\item
		      il existe \( v\) tel que \( (T-\lambda\mtu)v=0\)
		\item
		      \( T-\lambda\mtu\) n'est pas inversible
		\item
		      \( (T^t-\lambda\mtu)\) n'est pas inversible
		\item
		      il existe \( w\) tel que \( T^tw=\lambda w\).
		\item
		      \( \lambda\) est valeur propre de \( T^t\).
	\end{itemize}
\end{proof}

\begin{lemma}       \label{LemjcztYH}
	Soient un espace vectoriel \( E\), un endomorphisme \( T\in \End(E)\), ainsi que ses sous-espaces propres \( \{ E_{\lambda} \}_{\lambda\in \Spec(T)}  \)\nomenclature[A]{\( E_{\lambda}(T)\)}{Espace propre de \( T\)}. Toute somme finie de la forme
	\begin{equation}
		E_{\lambda_1}+\ldots+E_{\lambda_p}
	\end{equation}
	est directe\footnote{Définition \ref{DEFooIJDNooRUDUYF}.}.
\end{lemma}

\begin{proof}
	Nous utilisons le lemme \ref{LEMooDQMQooInVVDY}. Soient \( v_i\in E_{\lambda_i}\) un choix de vecteurs tels que
	\begin{equation}        \label{EQooROAXooFpgxxF}
		\sum_{i=1}^pv_i=0.
	\end{equation}
	Soit un entier \( j_0\) entre \( 1\) et \( p\). Nous allons montrer que \( v_{j_0}=0\). Pour cela nous remarquons d'abord que, pour tout \( i\neq j_0\),
	\begin{equation}        \label{EQooGVPYooXRPEVU}
		\prod_{k\neq j_0}(\lambda_i-\lambda_k)=0.
	\end{equation}
	Nous appliquons l'opérateur \( \prod_{k\neq j_0}(T-\lambda_k\mtu)\) à l'égalité \eqref{EQooROAXooFpgxxF} :
	\begin{subequations}
		\begin{align}
			0 & = \sum_{i=1}^p\prod_{k\neq j_0}(T-\lambda_k)v_i                                                   \\
			  & = \sum_{i=1}^p\prod_{k\neq j_0}(\lambda_i-\lambda_k)v_i       \label{SUBEQooHHGJooTvCcDb}         \\
			  & = \prod_{k\neq j_0}(\lambda_{j_0}-\lambda_k)v_{j_0}.                  \label{SUBEQooSHQYooNLVoVZ}
		\end{align}
	\end{subequations}
	Justifications.
	\begin{itemize}
		\item Pour \eqref{SUBEQooHHGJooTvCcDb}. Pour chaque \( k\) et \( i\) nous avons \( (T-\lambda_k)v_i=Tv_i-\lambda_kv_i=\lambda_iv_i-\lambda_kv_i\) parce que \( v_i\) est un vecteur propre de \( T\) pour la valeur propre \( \lambda_i\).
		\item Pour \eqref{SUBEQooSHQYooNLVoVZ}. Dans la somme, seul le terme \( i=j_0\) est non nul, à cause de \eqref{EQooGVPYooXRPEVU}.
	\end{itemize}
	Donc \( v_{j_0}=0\) parce que le produit \( \prod_{k\neq j_0}(\lambda_{j_0}-\lambda_k)\), lui, est non nul.
\end{proof}



%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Polynômes d'endomorphismes}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\label{SECooUEQVooLBrRiE}

Soit \( A\) un anneau commutatif et \( \eK\), un corps commutatif. L'injection canonique \( A\to A[X]\) se prolonge en une injection
\begin{equation}
	\eM(A)\to\eM\big( A[X] \big).
\end{equation}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Polynômes d'endomorphismes}
%---------------------------------------------------------------------------------------------------------------------------

Soit \( u\in\End(E)\) où \( E\) est un \( \eK\)-espace vectoriel. Nous considérons l'application
\begin{equation}    \label{EqOVKooeMJuv}
	\begin{aligned}
		\varphi_u\colon \eK[X] & \to \End(E)   \\
		P                      & \mapsto P(u).
	\end{aligned}
\end{equation}
L'image de \( \varphi_u\) est un sous-espace vectoriel. En effet si \( A=\varphi_u(P)\) et \( B=\varphi_u(Q)\), alors \( A+B=\varphi_u(P+Q)\) et \( \lambda A=(\lambda P)(u)\). En particulier c'est un espace fermé\footnote{Proposition \ref{CORooJHSGooUkGepQ}.}.

Soit \( u\) un endomorphisme d'un \( \eK\)-espace vectoriel \( E\) et \( P\), un polynôme. Nous disons que \( P\) est un polynôme \defe{annulateur}{polynôme!annulateur} de \( u\) si \( P(u)=0\) en tant qu'endomorphisme de \( E\).

\begin{lemma}       \label{LemQWvhYb}
	Si \( P\) et \( Q\) sont des polynômes dans \( \eK[X]\) et si \( u\) est un endomorphisme d'un \( \eK\)-espace vectoriel \( E\), nous avons
	\begin{equation}
		(PQ)(u)=P(u)\circ Q(u).
	\end{equation}
\end{lemma}

\begin{proof}
	Si \( P=\sum_i a_iX^i\) et \( Q=\sum_j b_jX^j\), alors le coefficient de \( X^k\) dans \( PQ\) est
	\begin{equation}        \label{EqCoefGPyVcv}
		\sum_la_lb_{k-l}.
	\end{equation}
	Par conséquent \( (PQ)(u)\) contient \( \sum_la_lb_{k-l}u^k\). Par ailleurs \( P(u)\circ Q(u)\) est donné par
	\begin{equation}
		\sum_ia_iu^i\left( \sum_jb_ju^j \right)(x)=\sum_{ij}a_ib_ju^{i+j}(x).
	\end{equation}
	Le coefficient du terme en \( u^k\) est bien le même que celui donné par \eqref{EqCoefGPyVcv}.
\end{proof}

\begin{theorem}[Décomposition des noyaux ou lemme des noyaux\cite{BIBooLUNZooKoIbjD}]       \label{ThoDecompNoyayzzMWod}
	Soit \( u\) un endomorphisme du \( \eK\)-espace\footnote{Le corps \( \eK\) est commutatif comme tous les corps dans le Frido.} vectoriel \( E\). Soit \( P\in\eK[X]\) un polynôme tel que \( P(u)=0\). Nous supposons que \( P\) s'écrive comme le produit \( P=P_1\ldots P_n\) de polynômes deux à deux étrangers\footnote{Définition~\ref{DefDSFooZVbNAX}.}. Alors
	\begin{enumerate}
		\item
		      Nous avons la formule
		      \begin{equation}
			      E=\ker P_1(u)\oplus\ldots\oplus\ker P_n(u).
		      \end{equation}
		\item
		      En posant \( Q_i=\prod_{j\neq i}P_j\), il existe des polynômes \( R_i\) tels que
		      \begin{equation}
			      R_1Q_1+\ldots +R_nQ_n=1.
		      \end{equation}
		\item       \label{ITEMooMOBPooPVXuXj}
		      Les projecteurs sur \( \ker\big( P_j(u) \big)\) sont donnés par
		      \begin{equation}
			      \proj_{\ker(P_i(u))}=(R_iQ_i)(u).
		      \end{equation}
	\end{enumerate}
\end{theorem}
\index{lemme!des noyaux}

\begin{proof}
	Dans ce qui suit, nous allons beaucoup utiliser le fait que \( \eK[X]\) soit commutatif (lemme \ref{LEMooWVUXooQlaepO}). Nous posons
	\begin{equation}
		Q_i=\prod_{j\neq i}P_j.
	\end{equation}
	\begin{subproof}
		\spitem[Utilisation de Bézout]

		Par le lemme~\ref{LemuALZHn} ces polynômes sont étrangers entre eux et le théorème de Bézout (théorème~\ref{ThoBezoutOuGmLB}) donne l'existence de polynômes \( R_i\) tels que
		\begin{equation}        \label{EQooMMCVooRzlXpA}
			R_1Q_1+\cdots+R_nQ_n=1.
		\end{equation}
		\spitem[Une première somme, pas directe]
		Si nous appliquons cette égalité à \( u\) et ensuite à \( x\in E\) nous trouvons
		\begin{equation}        \label{EqqVcpUy}
			\sum_{i=1}^n(R_iQ_i)(u)(x)=x,
		\end{equation}
		et en particulier si nous posons \( E_i=\Image\big(R_iQ_i(u)\big)\) nous avons
		\begin{equation}
			E=\sum_{i=1}^nE_i.
		\end{equation}
		Cette dernière somme n'est éventuellement pas une somme directe.
		\spitem[\( Q_iQ_j\) est multiple de \( P\)]
		Si \( i\neq j\), en utilisant la commutativité de \( \eK[X]\),
		\begin{equation}
			Q_iQ_j=\left(\prod_{k\neq i}P_k\right)\left(\prod_{l\neq j}P_l\right)=\Big( \prod_{\substack{k\neq i\\k\neq j}}P_k \Big)P_j\left( \prod_{l\neq j}P_l \right)=\prod_{\substack{k\neq i\\k\neq j}}P_k\prod_kP_l=S_{ij}P,
		\end{equation}
		où \( S_{ij}\) est un polynôme. Nous voyons que \( Q_iQ_j\) est multiple de \( P\).
		\spitem[Une somme directe]
		Toujours avec \( i\neq j\), en utilisant le lemme \ref{LemQWvhYb},
		\begin{equation}
			(R_iQ_i)(u)\circ (R_jQ_j)(u)=\big( R_iQ_iR_jQ_j \big)(u)=\big( R_iR_j\underbrace{Q_iQ_j}_{=S_{ij}P} \big)(u)=(R_iR_jS_{ij})(u)\circ P(u)=0
		\end{equation}
		Nous pouvons voir \( E\) comme un \( \eK\)-module et appliquer le théorème~\ref{ThoProjModpAlsUR}. Les opérateurs \( R_iQ_i(u)\) ont l'identité comme somme et sont orthogonaux, et nous avons donc la décomposition en somme directe :
		\begin{equation}        \label{EQooJPQLooOZepwZ}
			E=\bigoplus_{i=1}^nR_iQ_i(u)E.
		\end{equation}

		\spitem[\( R_iQ_i(u)E\subset \ker P_i(u)\)]		\label{SPITEMooQIPJooXleSMb}
		%-----------------------------------------------------------
		Attention : utilisation massive du lemme \ref{LemQWvhYb}. Un élément de \( R_iQ_i(u)E\) est de la forme \( (R_iQ_i)(u)x\) avec \( x\in E\). Nous appliquons l'endomorphisme \( P_i(u)\) à cet élément, et nous vérifions que nous obtenons zéro :
		\begin{subequations}
			\begin{align}
				P_i(u)\big( (R_iQ_i)(u)x \big) & =(P_iR_iQ_i)(u)x                                \\
				                               & =(R_i\underbrace{P_iQ_i}_{=P})(u)x              \\
				                               & =(R_iP)(u)x                                     \\
				                               & =\big( R_i(u)\circ \underbrace{P(u)}_{=0}\big)x \\
				                               & =0.
			\end{align}
		\end{subequations}
		Par conséquent
		\begin{equation}		\label{EQooULVHooAgKzTE}
			\Image(R_iQ_i(u))\subset \ker P_i(u).
		\end{equation}

		\spitem[Et la somme qu'il nous fallait]
		%-----------------------------------------------------------
		Le fait que la somme \eqref{EQooJPQLooOZepwZ} soit directe n'est en fait pas crucial. En effet, vu que chacun des termes est inclus dans \( \ker P_i(u)\), nous avons la somme (pas directe à priori)
		\begin{equation}		\label{EQooOEJHooPzmWbu}
			E=\sum_{i=1}^nR_iQ_i(u)E\subset\sum_{i=1}^n\ker P_i(u).
		\end{equation}
		Mais cette fois, nous prouvons qu'elle est directe en utilisant la caractérisation du lemme \ref{LEMooDQMQooInVVDY}\ref{ITEMooPLXGooCOQgen}. Supposons que, pour un certain \( k\),
		\begin{equation}
			x\in\ker P_k(u)\cap\big( \sum_{j\neq k}\ker P_j(u) \big).
		\end{equation}
		Nous allons montrer que \( x=0\).
		\begin{subproof}
			\spitem[\( Q_i(u)x=0\) si \( i\neq k\)]
			Si \( i\neq k\), nous avons
			\begin{equation}
				Q_i(u)x=\Big( \prod_{\substack{j\neq i\\j\neq k}}P_j \Big)P_k(u)x=0
			\end{equation}
			parce que \( x\in\ker P_k(u)\).
			\spitem[\( Q_k(u)x=0\)]
			Nous savons qu'il existe \( z_l\in\ker P_l(u)\) tel que \( x=\sum_{l\neq k}z_l\). Nous avons alors
			\begin{equation}
				Q_k(u)x=\Big( \prod_{j\neq k}P_j \Big)\sum_{l\neq k}z_l=\sum_{l\neq k}\Big( \prod_{j\neq k}P_j(u) \Big)z_l=0
			\end{equation}
			parce que parmi les \( P_j(u)\) (\( j\neq k\)), il y a \( P_l(u)\) qui annule \( z_l\).
			\spitem[Et finalement]
			Nous avons prouvé que \( Q_i(u)x=0\) pour tout \( i\). La formule de Bézout \eqref{EQooMMCVooRzlXpA} donne alors
			\begin{equation}
				\sum_iR_i\subset\underbrace{Q_i(u)x}_{=0}=x
			\end{equation}
			et donc \( x=0\).

			\spitem[Conclusion pour la somme directe]
			%-----------------------------------------------------------
			Nous venons de prouver que les \( \ker\big( P_i(u) \big)\) sont en somme directe. L'équation \eqref{EQooOEJHooPzmWbu} donne alors \( E\subset\bigoplus_i\ker\big( P_i(u) \big)\) et donc
			\begin{equation}
				E=\bigoplus_{i=1}^n\ker\big( P_i(u) \big).
			\end{equation}
		\end{subproof}
		\spitem[Les projecteurs]
		%-----------------------------------------------------------
		Nous avons déjà tout et pour faire bien, on va poser plein de notations. D'abord \( K_i=\ker\big( P_i(u) \big)\), et ensuite \( s_i=(R_iQ_i)(u)\). L'équation \eqref{EQooOEJHooPzmWbu} dit que
		\begin{equation}		\label{EQooAEXKooOYaRdR}
			E=\bigoplus_iK_i,
		\end{equation}
		et \eqref{EQooULVHooAgKzTE} dit que
		\begin{equation}
			s_i(E)\subset K_i,
		\end{equation}
		et aussi, par \eqref{EqqVcpUy} :
		\begin{equation}		\label{EQooQVPUooUConGX}
			\sum_is_i=\id.
		\end{equation}
		Nous devons prouver que \( s_k\) est la projection sur \( K_k\) parallèle aux autres \( K_i\) (définition \ref{DEFooYQZHooCDuhDU}). Pour cela nous vérifions les conditions du lemme \ref{LEMooCFDYooHTroSi}.

		D'abord \( s_i\) est linéaire en tant que composition et somme d'applications linéaires.

		Soit \( x\in K_i\). En posant \( y_l=s_l(x)\) et en utilisant \eqref{EQooQVPUooUConGX} :
		\begin{equation}
			y_1+\ldots+y_n=\sum_ls_l(x)=x	\in K_i.
		\end{equation}
		Vu que la somme \eqref{EQooAEXKooOYaRdR} est directe nous avons \( y_j=0\) si \( j\neq i\) et \( y_i=x\). En prenant \( i=k\) et \( i\neq k\) nous avons les deux conditions du lemme \ref{LEMooCFDYooHTroSi}.
	\end{subproof}
\end{proof}

\begin{normaltext}
	Ce résultat est utilisé pour prouver que toute représentation est décomposable en représentations irréductibles, proposition~\ref{PropHeyoAN} ainsi que pour le théorème~\ref{ThoDigLEQEXR} qui dit que si le polynôme minimal d'un endomorphisme est scindé à racine simple alors il est diagonalisable.
\end{normaltext}

\begin{corollary}   \label{CorKiSCkC}
	Soit \( E\), un \( \eK\)-espace vectoriel de dimension finie et \( f\), un endomorphisme semi-simple dont la décomposition du polynôme minimal \( \mu_f\) en facteurs irréductibles sur \( \eK[X]\) est \( \mu_f=M_1^{\alpha_1}\cdots M_r^{\alpha_r}\). Si \( F\) est un sous-espace stable par \( f\), alors
	\begin{equation}
		F=\bigoplus_{i=1}^r\ker M_i^{\alpha_i}(f)\cap F.
	\end{equation}
\end{corollary}

\begin{proof}
	Nous posons \( E_i=\ker M_i^{\alpha_i}(f)\) et \( F_i=E_i\cap F\). Les polynômes \( M_i^{\alpha_i}\) sont deux à deux étrangers et \( \mu_f(f)=0\), donc le lemme des noyaux (\ref{ThoDecompNoyayzzMWod}) s'applique et
	\begin{equation}
		E=E_1\oplus\ldots\oplus E_r.
	\end{equation}
	Nous pouvons décomposer \( x\in F\) en termes de cette somme :
	\begin{equation}     \label{EqbBbrdi}
		x=x_1+\cdots +x_r
	\end{equation}
	avec \( x_i\in E_i\). Toujours selon le lemme des noyaux, les projections sur les espaces \( E_i\) sont des polynômes en \( f\). Par conséquent \( F\) est stable sous toutes ces projections \( \pr_i\colon E\to E_i\), et en appliquant \( \pr_i\) à \eqref{EqbBbrdi}, \( \pr_i(x)=x_i\). Puisque \( x\in F\), le membre de gauche est encore dans \( F\) et \( x_i\in E_i\cap F\). Nous avons donc
	\begin{equation}
		F\subset\bigoplus_{i=1}^rF_i.
	\end{equation}
	L'inclusion inverse est immédiate parce que \( F_i\subset F\) pour chaque \( i\).
\end{proof}

\begin{lemma}   \label{LemVISooHxMdbr}
	Si \( x\) est un vecteur propre de valeur propre \( \lambda\) pour l'endomorphisme \( u\) et si \( P\) est un polynôme, alors \( x\) est vecteur propre de \( P(u)\) pour la valeur propre \( P(\lambda)\).
\end{lemma}

\begin{proof}
	C'est un simple calcul de \( P(u)x\) en ayant noté\footnote{En complète violation de ce qu'on disait dans \ref{NORMooHHIVooSfHlxv}.} \( P(X)=\sum_{k=0}^nc_kX^n\) :
	\begin{equation}
		P(u)x=\sum_{k=0}^nc_ku^k(x)=\sum_{k=0}^nc_k\lambda^kx=P(\lambda)x.
	\end{equation}
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Polynôme minimal et minimal ponctuel}
%---------------------------------------------------------------------------------------------------------------------------

Nous avons déjà vu la définition de polynôme minimal en \ref{DefCVMooFGSAgL}. Le lemme suivant permet de parler de polynôme minimal d'endomorphisme.

\begin{lemma}        \label{LEMooQJQGooRcAxmJ}
	Soit un endomorphisme \( f\colon E\to E\) d'un \( \eK\)-espace vectoriel de dimension finie. Il existe un unique polynôme annulateur unitaire de degré minimum\footnote{Degré minimum au sens où il existe peut-être d'autres polynômes annulateurs, mais ils seront de degré plus élevé.}.

	Tout endomorphisme de \( \eK\)-espace vectoriel de dimension finie possède un polynôme minimal\footnote{Définition \ref{DefCVMooFGSAgL}.}.
\end{lemma}

\begin{proof}
	Pour l'unicité, soient \( P\) et \( Q\) deux polynômes annulateurs de \( f\) de même degré minimum \( N\) et ayant tous deux \( 1\) comme coefficient de \( x^N\). Alors \( P-Q\) est de degré \( N-1\) tout en étant encore annulateur. Vu que nous avions dit que \( N\) était le degré minimum, le seul polynôme annulateur de degré \( N-1\) est le polynôme nul. Donc \( P-Q=0\).

	Pour l'existence, les endomorphismes \( \id\), \( f\), \( f^2\), \ldots ne peuvent pas être tous linéairement indépendants parce que la dimension de \( \End(E)\) est finie. Il existe donc un nombre \( N\) et des coefficients \( a_k\) tels que \( \sum_{k=0}^Na_kf^k=0\). Le polynôme \( P(X)=\sum_{k=0}^Na_kX^k\) est donc annulateur de \( f\).

	Une autre façon de le dire est que l'application linéaire \( \varphi\colon \eK[X]\to \End(E)\) donnée par \( \varphi(P)=P(f)\) est un endomorphisme d'un espace vectoriel de dimension infinie vers un espace vectoriel de dimension finie. Il ne peut donc pas être injectif et possède donc un noyau non réduit à zéro.

	L'existence d'un polynôme minimal est maintenant seulement dû au fait que, avec les notations de la définition \ref{DefCVMooFGSAgL}, l'idéal \( I_f\) n'est pas réduit à \( \{ 0 \}\).
\end{proof}

\begin{remark}
	La preuve donnée ci-dessus montre que \( \deg(\mu)\leq \dim(E)^2\). Comme conséquence du théorème de Cayley-Hamilton~\ref{ThoCalYWLbJQ} nous verrons qu'en réalité le degré du polynôme minimal est majoré par la dimension de l'espace.
\end{remark}

Dans la suite, l'endomorphisme \( f\) du \( \eK\)-espace vectoriel \( E\) de dimension \( n\) est fixé. Pour \( x\in E\) nous notons
\begin{equation}            \label{EqooOAYDooEpZELo}
	E_x=\{ P(f)x\tq P\in \eK[X] \}.
\end{equation}
Nous considérons le morphisme d'algèbres
\begin{equation}
	\begin{aligned}
		\varphi\colon \eK[X] & \to \End(E)  \\
		P                    & \mapsto P(f)
	\end{aligned}
\end{equation}
et si \( x\in E\) est donné nous considérons le morphisme de \( \eK\)-espaces vectoriels
\begin{equation}
	\begin{aligned}
		\varphi_x\colon \eK[X] & \to E          \\
		P                      & \mapsto P(f)x.
	\end{aligned}
\end{equation}
Les noyaux de ces applications sont des idéaux, entre autres par le lemme~\ref{LemQWvhYb}. Ils ont donc un unique générateur unitaire (chacun) par le théorème~\ref{ThoCCHkoU}. En termes de vocabulaire, l'ensemble
\begin{equation}
	\ker(\varphi)=\{  P\in\eK[X]\tq P(f)=0  \}
\end{equation}
est l'\defe{idéal annulateur}{polynôme!annulateur} de \( f\) et un polynôme \( P\) tel que \( P(f)=0\) est un polynôme annulateur de \( f\).

\begin{propositionDef}      \label{DEFooUICRooBGYhqQ}
	La partie \( \ker(\varphi_x)\) est un idéal de \( \eK[X]\) qui possède un unique générateur unitaire.

	Le générateur unitaire de \( \ker(\varphi_x)\) est le \defe{polynôme minimal ponctuel}{polynôme!minimal!ponctuel} de \( f\) en \( x\). Il sera noté \( \mu_{f,x}\) ou \( \mu_x\) lorsque la dépendance en \( f\) est claire dans le contexte.
\end{propositionDef}
Nous notons \( \mu\) le générateur unitaire du noyau de \( \varphi\) et \( \mu_x\) celui de \( \varphi_x\). Puisque \( \mu\in\ker(\varphi_x)\) pour tout \( x\) nous avons \( \mu_x\divides \mu\) pour tout \( x\).

\begin{example}[Pas en dimension infinie]       \label{ExooDTUJooIMqSKn}
	En dimension infinie, il n'y a pas toujours de polynôme annulateur. Si \( E\) est un espace vectoriel de dimension infinie ayant une base dénombrable \( \{ e_i \}_{i\in \eN}\) alors l'opérateur donné par \( f(e_i)=e_{i+1}\) n'a pas de polynôme annulateur. Même pas ponctuel en quel que point que ce soit.

	De même l'opérateur donné par \( g(e_1)=0\) et \( g(e_i)=e_{i-1}\) si \( i\neq 1\) n'a pas de polynôme annulateur, mais il a un polynôme annulateur ponctuel évident en \( x=e_1\). L'exemple~\ref{ExooLRHCooMYLQTU} donnera un habillage à peine subtil à cet exemple.
\end{example}

\begin{proposition}     \label{PropAnnncEcCxj}
	Si \( P\) est un polynôme tel que \( P(f)=0\), alors le polynôme minimal \( \mu_f\) divise \( P\). Autrement dit, le polynôme minimal engendre l'idéal des polynômes annulateurs.
\end{proposition}

\begin{proof}
	L'ensemble \( \ker(\varphi)=\{ Q\in \eK[X]\tq Q(f)=0 \} \) est un idéal par le lemme \ref{LemQWvhYb}. Le polynôme minimal de \( f\) est un élément de degré plus bas dans \( I\) et par conséquent \( I=(\mu_f)\) par le théorème~\ref{ThoCCHkoU}. Nous concluons que \( \mu_f\) divise tous les éléments de \( I\).
\end{proof}

La proposition suivante permet de caractériser le polynôme minimal.
\begin{proposition}[\cite{ooEPEFooQiPESf}]      \label{PROPooVUJPooMzxzjE}
	Soit une application linéaire \( f\) sur un \( \eK\)-espace vectoriel. Il existe un unique polynôme unitaire\quext{À mon avis, «unitaire» manque dans \cite{ooEPEFooQiPESf}.} \( P\in \eK[X]\) tel que
	\begin{enumerate}
		\item
		      \( P(f)=0\);
		\item
		      l'application
		      \begin{equation}        \label{EQooIBMDooVTaEhf}
			      \begin{aligned}
				      \varphi\colon \frac{ \eK[X] }{ (P) } & \to \End(E)  \\
				      \bar Q                               & \mapsto Q(f)
			      \end{aligned}
		      \end{equation}
		      est injective.
	\end{enumerate}
\end{proposition}

\begin{proof}
	En ce qui concerne l'existence, il existe le polynôme minimal de \( f\) qui satisfait les conditions. Pour l'unicité nous y travaillons maintenant.

	Supposons que l'application \eqref{EQooIBMDooVTaEhf} soit injective. Alors pour tout \( Q\in \eK[X]\) tel que \( Q(f)=0\) nous avons \( \bar Q=0\), c'est-à-dire \( Q=PR\) pour un certain \( R\in \eK[X]\). Autrement dit : \( P\) est un générateur unitaire de l'idéal annulateur de \( f\). Le théorème~\ref{ThoCCHkoU}\ref{ITEMooASHKooZqkiCH} nous dit alors que \( P=\mu\) parce que \( \mu\) est également générateur unitaire.
\end{proof}

\begin{lemma}[\cite{ooRJDSooXpVtMD}]\label{LemSYsJJj}
	Soit \( f\colon E\to E\) un endomorphisme de l'espace vectoriel \( E\). Il existe un élément \( x\in E\) tel que \( \mu_{f,x}=\mu_f\).
\end{lemma}

\begin{proof}
	Soit une décomposition en irréductibles du polynôme minimal \( \mu=P_1^{\alpha_1}\ldots P_r^{\alpha_r}\). Nous notons \( E_i=\ker\big( P_i^{\alpha_i}(f) \big)\). Les polynômes \( P_i\) sont étrangers deux à deux (un diviseur commun aurait a fortiori été un diviseur et aurait contredit l'irréductibilité). Le lemme des noyaux~\ref{ThoDecompNoyayzzMWod} nous donne la somme directe
	\begin{equation}
		E=\bigoplus_{i=1}^r\ker\big( P_i^{\alpha_i}(f) \big).
	\end{equation}
	Si \( x_i\in E_i\) alors \( \mu_{x_i}\) est une puissance de \( P_i\). En effet \( \mu_{x_i}\divides \mu\) et est donc un produit des puissances des \( P_j\). Or si \( (QP_j)(f)x_i=0\) alors \( (P_jQ)(f)x_i=0\), ce qui donne \( Q(f)x_i\in E_j\cap E_i=\{ 0 \}\) si \( j\neq i\). Donc \( \mu_{x_i}\) n'est pas de la forme \( QP_j\) pour \( j\neq i\). Nous en déduisons que \( \mu_{x_i}\) est une puissance de \( P_i\) dès que \( x_i\in E_i\). Nous choisissons \( x_i\in E_i\) tel que \( \mu_{x_i}=P_i^{\alpha_i}\).

	Nous posons enfin \( a=x_1+\cdots +x_r\); par définition du polynôme annulateur \( \mu_a\), nous avons
	\begin{equation}        \label{EqooVIGGooSfuvwB}
		0=\mu_a(f)a=\mu_a(f)x_1+\cdots +\mu_a(f)x_r.
	\end{equation}
	Mais \( \mu_a(f)x_i\in E_i\), et la somme des \( E_i\) est directe, donc l'annulation de la somme \eqref{EqooVIGGooSfuvwB} implique l'annulation de chacun des termes : \( \mu_a(f)x_i=0\) pour tout \( i\). Cela prouve que \( \mu_{x_i}\divides \mu_a\). Mais comme les \( \mu_{x_i}\) sont premiers deux à deux (parce que ce sont les \( P_i^{\alpha_i}\)), nous concluons que le produit divise encore \( \mu_a\) :
	\begin{equation}
		\prod_{i=1}^r\mu_{x_i}\divides \mu_a,
	\end{equation}
	c'est-à-dire \( \mu\divides \mu_a\). Comme nous avons aussi \( \mu_a\divides \mu\), nous déduisons \( \mu_a=\mu\).
\end{proof}

\begin{definition}[Matrices, endomorphismes et vecteurs cycliques]      \label{DEFooFEIFooNSGhQE}
	Une matrice est \defe{cyclique}{cyclique!matrice}\index{matrice!cyclique} si elle est semblable à une matrice compagnon. Un endomorphisme \( f\colon E\to E\) est \defe{cyclique}{cyclique!endomorphisme}\index{endomorphisme!cyclique} si il existe un vecteur \( x\in E\) tel que \( \{ f^k(x) \}_{k=0,\ldots, n-1} \) est une base de \( E\). Un vecteur ayant cette propriété est un \defe{vecteur cyclique}{vecteur!cyclique} pour \( f\).
\end{definition}

\begin{lemma}   \label{LemAGZNNa}
	Soit \( E\) un espace vectoriel de dimension finie et un endomorphisme cyclique\footnote{Voir la définition~\ref{DEFooFEIFooNSGhQE}.} \( f\) de \( E\). Soit un vecteur cyclique \( v\) de \( f\), alors le polynôme minimal de \( f\) est égal au polynôme minimal de \( f\) au point \( v\) : \( \mu_{f}=\mu_{f,v}\).
\end{lemma}

\begin{proof}
	Montrons que \( \mu_{f,v}\) est un polynôme annulateur de \( f\), ce qui prouvera que \( \mu_f\) divise \( \mu_{f,v}\) par la proposition~\ref{PropAnnncEcCxj}. Étant donné que \( v\) est cyclique, tout élément de \( E\) s'écrit sous la forme \( x=Q(f)v\). Prenons un polynôme \( P\) annulateur de \( f\) en \( v\) : \( P(f)v=0\). Nous montrons que \( P\) est alors un polynôme annulateur de \( f\). En effet, nous avons
	\begin{equation}
		P(f)x=\big( P(f)\circ Q(f) \big)v=\big( Q(f)\circ P(f) \big)v=0
	\end{equation}
	où nous avons utilisé le lemme~\ref{LemQWvhYb}.
\end{proof}

\begin{lemma}[\cite{ooRJDSooXpVtMD}]        \label{LEMooOWDAooWPbPda}
	Soit \( a\in E\) un vecteur cyclique pour \( f\), tel que \( \mu_a=\mu\). Alors \( E_a\) est un sous-espace stable par \( f\) pour lequel il existe un supplémentaire stable.
\end{lemma}

\begin{proof}
	Soit \( l=\deg(\mu)=\deg(\mu_a)\). L'espace \( E_a\) étant engendré par les \( f^k(a)\) nous savons que \( e_1=a\), \( e_2=f(a)\),\ldots, \( e_l=f^{l-1}(a)\) forment une base de \( E_a\). Nous pouvons la compléter en une base \( \{ e_1,\ldots, e_n \}\) de \( E\). Et nous posons\footnote{ici, comme presque partout, \( e^*_{l}\) est le dual de \( e_l\), c'est-à-dire l'application linéaire sur \( E\) donnée par \( e^*_l(e_i)=\delta_{li}\), voir la définition \ref{DEFooTMSEooZFtsqa}.}
	\begin{subequations}
		\begin{align}
			G & = \{ x\in E\tq e^*_l\big( f^k(x) \big)=0, \forall k\geq 0 \} \\
			  & = \bigcap_{k\geq 0}\ker\{ e^*_l\circ f^k \}                  \\
			  & = \bigcap_{k=0}^{l-1}\ker( e^*_l\circ f^k ).
		\end{align}
	\end{subequations}
	La dernière égalité est due au fait que \( l\) soit le degré de \( \mu\). Du coup \( f^l\) est une combinaison linéaire des \( f^i\) avec \( i\leq l-1\).

	Nous avons \( f(G)\subset G\) et de plus \( E_a\cap G=\{ 0 \}\) parce qu'un élément de \( E_a\) est une combinaison linéaire d'éléments de la forme \( f^j(a)\) (\( j\leq l\)). Après application de \( f^{l-j}\), ces éléments obtiennent une composante \( f^l(a)=e_l\). De plus \( G\) est un sous-espace vectoriel du fait que \( e^*_l\circ f^i\) est une application linéaire.

	Montrons enfin que \( \dim(G)=n-l\). Pour cela nous remarquons que \( G\) est une intersection d'hyperplans, et nous montrons que les équations définissant ces hyperplans sont linéairement indépendantes. Soit donc
	\begin{equation}        \label{EqooOHESooRtBUfc}
		\sum_{j=0}^{l-1}\lambda_j\big( e^*_l\circ f^j \big)=0
	\end{equation}
	et montrons que \( \lambda_j=0\) pour tout \( j\) est l'unique solution. Soit \( x\in E\) et appliquons l'opération \eqref{EqooOHESooRtBUfc} au vecteur \( f^i(x)\); le résultat est zéro :
	\begin{equation}
		0=\sum_{j=0}^{l-1}\lambda_j(e^*_l\circ f^i\circ f^j)=(e^*_l\circ f^i)P(u)
	\end{equation}
	où nous avons posé \( P(X)=\sum_{j=0}^{l-1}\lambda_jX^j\). Appliquons cela à \( a\) : pour tout \( i\) nous avons
	\begin{equation}
		(e^*_l\circ f^i)\big( P(f)a \big)=0.
	\end{equation}
	Mais par définition de \( E_a\), l'élément \(P(f)a \) est dans \( E_a\). Nous en déduisons que
	\begin{equation}
		P(f)a\in G\cap E_a=\{ 0 \},
	\end{equation}
	c'est-à-dire que \( P\) est un polynôme annulateur de \( a\). Mais \( P\) est de degré \( l-1\) alors que le polynôme minimal de \( a\) est de degré \( l\). Par conséquent \( P=0\) et \( \lambda_j=0\) pour tout \( j\).
\end{proof}

\begin{definition}  \label{DEFooBOHVooSOopJN}
	L'endomorphisme \( f\) d'un espace vectoriel est \defe{semi-simple}{semi-simple!endomorphisme} si tout sous-espace stable par \( f\) possède un supplémentaire stable.
\end{definition}

\begin{lemma}   \label{LemrFINYT}
	Si le polynôme minimal d'un endomorphisme est irréductible, alors cet endomorphisme est semi-simple\footnote{Définition~\ref{DEFooBOHVooSOopJN}.}.
\end{lemma}

\begin{proof}
	Soit \( f\), un endomorphisme dont le polynôme minimal est irréductible et \( F\), un sous-espace stable par \( f\). Nous devons en trouver un supplémentaire stable. Si \( F=E\), il n'y a pas de problème. Sinon nous considérons \( u_1\in E\setminus F\) et
	\begin{equation}
		E_{u_1}=\{ P(f)u_1\tq P\in \eK[X] \},
	\end{equation}
	qui est un espace stable par \( f\).

	Montrons que \( E_{u_1}\cap F=\{ 0 \}\). Pour cela nous étudions l'idéal
	\begin{equation}
		I_{u_1}=\{ P\in \eK[X]\tq P(f)u_1=0 \}.
	\end{equation}
	C'est un idéal non réduit à \( \{ 0 \}\) parce que le polynôme minimal de \( f\) par exemple est dans \( I_{u_1}\). Soit \( P_{u_1}\) un générateur unitaire de \( I_{u_1}\). Étant donné que \( \mu_f\in I_{u_1}\), nous avons \( P_{u_1}\) divise \( \mu_f\) et donc, \( P_{u_1}=\mu_f\), parce que \( \mu_f\) est irréductible par hypothèse.

	Soit \( y\in E_{u_1}\cap F\). Par définition il existe \( P\in\eK[X]\) tel que \( y=P(f)u_1\) et si \( y\neq 0\), cela signifie que \( P\notin I_{u_1}\), c'est-à-dire que \( P_{u_1} \) ne divise pas \( P\). Étant donné que \( P_{u_1}\) est irréductible cela implique que \( P_{u_1}\) et \( P\) sont premiers entre eux (ils n'ont pas d'autre \( \pgcd\) que \( 1\)).

	Nous utilisons maintenant des coefficient de Bézout (théorème~\ref{ThoBezoutOuGmLB}) \( A,B\in \eK[X]\) tels que
	\begin{equation}
		AP+BP_{u_1}=1.
	\end{equation}
	Nous appliquons cette égalité à \( f\) et puis à \( u_1\):
	\begin{equation}
		u_1=A(f)\circ \underbrace{P(f)u_1}_{=y}+B(f)\circ \underbrace{P_{u_1}(f)u_1}_{=0}=A(f)y.
	\end{equation}
	Mais \( y\in F\), donc \( A(f)y\in F\). Nous aurions donc \( u_1\in F\), ce qui est impossible par choix. Nous savons maintenant que l'espace \( E_{u_1}\oplus F\) est stable sous \( f\). Si cet espace est \( E\) alors nous arrêtons. Sinon nous reprenons le raisonnement avec \( E_{u_1}\oplus F\) en guise de \( F\) et en prenant \( u_2\in E\setminus(E_{u_1}\oplus F)\). Étant donné que \( E\) est de dimension finie, ce procédé s'arrête à un certain moment et nous aurons
	\begin{equation}
		E=F\oplus E_{u_1}\oplus\ldots\oplus E_{u_k}
	\end{equation}
	où chacun des \( E_{u_i}\) sont stables.
\end{proof}

\begin{theorem} \label{ThoFgsxCE}
	Un endomorphisme est semi-simple si et seulement si son polynôme minimal est produit de polynômes irréductibles distincts deux à deux.
\end{theorem}
\index{anneau!principal}

\begin{proof}

	Supposons que \( f\) soit semi-simple et que son polynôme minimal soit donné par \( \mu_f=M_1^{\alpha_1}\ldots M_r^{\alpha_r}\) où les \( M_i\) sont des polynômes irréductibles deux à deux distincts. Nous devons montrer que \( \alpha_i=1\) pour tout \( i\). Soit \( i\) tel que \( \alpha_i\geq 1\) et \( N\in \eK[X]\) tel que \( \mu_f=M^2N\) où l'on a noté \( M=M_i\). Nous étudions l'espace
	\begin{equation}
		F=\ker M(f)
	\end{equation}
	qui est stable par \( f\), et qui possède donc un supplémentaire \( S\) également stable par \( f\). Nous allons montrer que \( MN\) est un polynôme annulateur de \( f\).

	D'abord nous prenons \( x\in S\). Étant donné que \( F\) est le noyau de \( M(f)\),
	\begin{equation}
		M(f)\big( MN(f)x \big)=\mu_f(f)x=0,
	\end{equation}
	ce qui signifie que \( MN(f)x\in F\). Mais puisque \( S\) est stable par \( f\) nous avons aussi \( MN(f)x\in S\). Finalement \( MN(f)x\in F\cap S=\{ 0 \}\). Autrement dit, \( MN(f)\) s'annule sur \( S\).

	Prenons maintenant \( y\in F\). Nous avons
	\begin{equation}
		MN(f)=N(f)\big( M(f)y \big)=0
	\end{equation}
	parce que \( y\in F=\ker M(f)\).

	Nous avons prouvé que \( MN(f)\) s'annule partout et donc que \( MN(f)\) est un polynôme annulateur de \( f\), ce qui contredit la minimalité de \( \mu_f=M^2N\).

	Nous passons au sens inverse. Soit \( m_f=M_1\ldots M_r\) une décomposition du polynôme minimal de l'endomorphisme \( f\) en irréductibles distincts deux à deux. Soit \( F\) un sous-espace vectoriel stable par \( f\). Nous notons
	\begin{equation}
		E_i=\ker(M_i(f))
	\end{equation}
	et \( f_i=f|_{E_i}\). Par le lemme~\ref{CorKiSCkC} nous avons
	\begin{equation}
		F=\bigoplus_{i=1}^r(F\cap E_i).
	\end{equation}
	Les espaces \( E_i\) sont stables par \( f\) et étant donné que \( M_i\) est irréductible, il est le polynôme minimal de \( f_i\). En effet, \( M_i\) est annulateur de \( f_i\), ce qui montre que le polynôme minimal de \( f_i\) divise \( M_i\). Mais \( M_i\) étant irréductible, \( M_i\) est le polynôme minimal. Étant donné que \( \mu_{f_i}=M_i\), l'endomorphisme \( f_i\) est semi-simple par le lemme~\ref{LemrFINYT}.

	L'espace \( F\cap E_i\) étant stable par l'endomorphisme semi-simple \( f_i\), il possède un supplémentaire stable que nous notons \( S_i\)~:
	\begin{equation}
		E_i=S_i\oplus(F\cap E_i).
	\end{equation}
	Étant donné que sur chaque \( S_i\) nous avons \( f|_{S_i}=f_i\), l'espace \( S=S_1\oplus\ldots\oplus S_r\) est stable par \( f\). Par conséquent, nous avons
	\begin{subequations}
		\begin{align}
			E & = E_1\oplus\ldots\oplus E_r                                                          \\
			  & = \big( S_1\oplus(F\cap E_1) \big)\oplus\ldots\oplus\big( S_r\oplus(F\cap E_r) \big) \\
			  & = \big( \bigoplus_{i=1}^rS_i \big)\oplus\big( \bigoplus_{i=1}^rF\cap E_i \big)       \\
			  & = S\oplus F,
		\end{align}
	\end{subequations}
	ce qui montre que \( F\) a bien un supplémentaire stable par \( f\) et donc que \( f\) est semi-simple.
\end{proof}

\begin{example}[L'espace engendré par \( \mtu\), \( A\), \( A^2\),\ldots]
	Soit \( A\) une matrice, et
	\begin{equation}
		E=\Span\{A^k\tq k\in \eN \}.
	\end{equation}
	Nous montrons que \( \dim(E)\) est le degré du polynôme minimal de \( A\).

	D'abord l'idéal annulateur de \( A\) est engendré par le polynôme minimal\footnote{Proposition~\ref{PropAnnncEcCxj}.} que nous notons
	\( \mu=\sum_{k=0}^pa_kX^k\).
	La partie \( \{ \mtu,\ldots, A^{p-1} \}\) est libre parce qu'une combinaison linéaire nulle de ces éléments serait un polynôme annulateur en \( A\) de degré plus petit que \( p\). Donc \( \dim(E)\geq p\).

	La partie \( \{ \mtu,A,\ldots, A^p \}\) est liée à cause du polynôme minimal. Isoler \( A^p\) dans \( \mu(A)=0\) donne un polynôme \( f\) de degré \( p-1\) tel que \( A^p=f(A)\).

	Nous allons montrer à présent que la famille \( \{ \mtu,A,\ldots, A^{p-1} \}\) est génératrice (alors \( \dim(E)\leq p\)). Soit un entier \( q\geq p\) et de division euclidienne\footnote{Théorème~\ref{ThoDivisEuclide}.} \( np+r=q\) avec \( r<p\). Nous avons \( A^q=A^{np}A^r\). D'une part
	\begin{equation}
		A^{np}=(A^p)^n=f(A)^n
	\end{equation}
	est de degré \( n(p-1)\). Par conséquent
	\begin{equation}
		A^q=f(A)^nA^r
	\end{equation}
	qui est de degré \( n(p-1)+r=q-n\). Autrement dit il existe un polynôme \( g_1\) de degré \( q-n\) tel que \( A^q=g_1(A)\). Si \( q-n>p-1\) alors nous pouvons recommencer et obtenir un polynôme \( g_2\) de degré strictement inférieur à celui de \( g_1\) tel que \( A^q=g_2(A)\). Au bout du compte, il existe un polynôme \( g\) de degré au maximum \( p-1\) tel que \( A^q=g(A)\). Cela prouve que la partie \( \{ \mtu,A,\ldots, A^{p-1} \}\) est génératrice de \( E\).

	La dimension de \( E\) est donc \( p\), le degré du polynôme minimal.
\end{example}

\begin{proposition}     \label{PropooCFZDooROVlaA}
	Soit \( f\) un endomorphisme d'un espace vectoriel de dimension finie. Nous avons l'isomorphisme d'espace vectoriel
	\begin{equation}
		\eK[f]\simeq\frac{ \eK[X] }{ (\mu_f) }
	\end{equation}
	La dimension en est \( \deg(\mu_f)\).
\end{proposition}

\begin{proof}
	Notons avant de commencer que \( (\mu)\) est l'idéal engendré par \( \mu\). Les classes dont il est question dans le quotient \( \eK[X]/(\mu)\) sont
	\begin{equation}
		\bar P=\{ P+S\mu \}_{S\in \eK[X]}.
	\end{equation}
	Nous allons montrer que l'application suivante fournit l'isomorphisme :
	\begin{equation}
		\begin{aligned}
			\psi\colon \frac{ \eK[X] }{ (\mu) } & \to \eK[f]    \\
			\bar P                              & \mapsto P(f).
		\end{aligned}
	\end{equation}
	\begin{subproof}
		\spitem[\( \psi\) est bien définie]
		Si \( Q\in \bar P\) alors \( Q=P+S\mu\) pour un certain \( S\in \eK[X]\). Du coup nous avons
		\begin{equation}
			\psi(\bar Q)=P(f)+(S\mu)(f).
		\end{equation}
		Mais \( \mu(f)=0\) donc le deuxième terme est nul. Donc \( \psi(\bar P)\) est bien défini.
		\spitem[Injectif]
		Si \( \psi(\bar P)=0\) nous avons \( P(f)=0\), ce qui signifie que \( P=S\mu\) pour un polynôme \( S\). Par conséquent \( P\in (\mu)\) et donc \( \bar P=0\).
		\spitem[Surjectif]
		Soit \( P\in \eK[X]\). L'élément \( P(f) \) de \( \eK[f]\) est dans l'image de \( \psi\) parce que c'est \( \psi(\bar P)\).
	\end{subproof}
	En ce qui concerne la dimension, le corolaire~\ref{CorsLGiEN} en parle déjà : une base est donnée par les projections de \( 1,X,\ldots, X^{\deg(\mu_f)-1}\).
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Polynôme caractéristique}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}  \label{DefOWQooXbybYD}
	Soit un anneau commutatif \( A\). Si \( u\in\eM(n,A)\), nous définissons le \defe{polynôme caractéristique de \( u\)}{polynôme!caractéristique}\index{caractéristique!polynôme} :
	\begin{equation}    \label{Eqkxbdfu}
		\chi_u(X)=\det(u-X\mtu_n).
	\end{equation}
	Nous définissons de même le polynôme caractéristique d'un endomorphisme \( u\colon E\to E\).
\end{definition}

\begin{remark}
	Quelques remarques à propos du signe\quext{Attention : je crois qu'il y a des incohérences dans le Frido à propos de ce choix}.
	\begin{itemize}
		\item
		      Certains auteurs définissent le polynôme caractéristique par \( \det(X-u)\) au lieu de \( \det(u-X)\).
		\item
		      Wikipédia francophone\cite{BIBooYPTLooZlMfAG} prend la définition \( \det(X-u)\) (donc opposée de la notre). Allez lire la page de discussion.
		\item
		      Sur les wikipédias en d'autres langues, ça varie.
		\item
		      Un avantage de \( \det(u-X)\) est que \( \det(u)=\chi_u(0)\).
		\item
		      Un avantage de \( \det(X-u)\) est qu'il est unitaire.
	\end{itemize}
\end{remark}

\begin{lemma}       \label{LemooWCZMooZqyaHd}
	Soit un endomorphisme \(u \colon E\to E  \).
	\begin{enumerate}
		\item		\label{ITEMooAALOooGlQYOs}
		      Le polynôme caractéristique \( \chi_u\) a pour degré la dimension de \( E\).
		\item
		      Si la dimension de \( E\) est paire, alors le polynôme caractéristique \( \chi_u\) est unitaire.
	\end{enumerate}
	%TODOooACQDooFsOfSj. Prouver ça.
\end{lemma}

\begin{theorem}     \label{ThoNhbrUL}
	Soit \( E\) un \(\eK\)-espace vectoriel de dimension finie \( n\) et un endomorphisme \( u\in\End(E)\). Alors
	\begin{enumerate}
		\item
		      Le polynôme caractéristique divise \( (\mu_u)^n\) dans \(\eK[X]\).
		\item
		      Les polynômes caractéristiques et minimaux ont mêmes facteurs irréductibles dans \(\eK[X]\).
		\item
		      Les polynômes caractéristiques et minimaux ont mêmes racines dans \(\eK[X]\).
		\item
		      Le polynôme caractéristique est scindé si et seulement si le polynôme minimal est scindé.
	\end{enumerate}
	%TODOooZHTCooTahuKD. Prouver ça.
\end{theorem}

\begin{theorem} \label{ThoWDGooQUGSTL}
	Soit \( u\in\End(E)\) et \( \lambda\in\eK\). Les conditions suivantes sont équivalentes
	\begin{enumerate}
		\item\label{ItemeXHXhHi}
		      \( \lambda\in\Spec(u)\)
		\item\label{ItemeXHXhHii}
		      \( \chi_u(\lambda)=0\)
		\item\label{ItemeXHXhHiii}
		      \( \mu_u(\lambda)=0\).
	\end{enumerate}
\end{theorem}

\begin{proof}
	\ref{ItemeXHXhHi} \( \Leftrightarrow\)~\ref{ItemeXHXhHii}. Dire que \( \lambda\) est dans le spectre de \( u\) signifie que l'opérateur \( u-\lambda\mtu\) n'est pas inversible, ce qui est équivalent à dire que \( \det(u-\lambda\mtu)\) est nul par la proposition~\ref{PropYQNMooZjlYlA}\ref{ItemUPLNooYZMRJy} ou encore que \( \lambda\) est une racine du polynôme caractéristique de \( u\).

	\ref{ItemeXHXhHii} \( \Leftrightarrow\)~\ref{ItemeXHXhHiii}. C'est une application directe du théorème~\ref{ThoNhbrUL} qui précise que le polynôme caractéristique a les mêmes racines dans \(\eK\) que le polynôme minimal.
\end{proof}

\begin{example} \label{ExICOJcFp}
	Sur \( \eR^2\), nous considérons la matrice \( A=\begin{pmatrix}
		1 & 0 \\
		1 & 1
	\end{pmatrix}\) qui a pour polynôme caractéristique\footnote{Définition~\ref{DefOWQooXbybYD}.} le polynôme \( \chi_A=(X-1)^2\). Le nombre \( \lambda=1\) est une racine double de ce polynôme, et pourtant il n'y a qu'une seule dimension d'espace propre :
	\begin{equation}
		\begin{pmatrix}
			1 & 0 \\
			1 & 1
		\end{pmatrix}\begin{pmatrix}
			x \\
			y
		\end{pmatrix}=\begin{pmatrix}
			x \\
			y
		\end{pmatrix}
	\end{equation}
	entraine \( x=0\).

	Ici la multiplicité algébrique est différente de la multiplicité géométrique.
\end{example}

\begin{proposition}[\cite{RombaldiO}]\label{PropNrZGhT}
	Soit \( f\), un endomorphisme de \( E\) et \( x\in E\). Alors
	\begin{enumerate}
		\item
		      L'espace \( E_{f,x}\) est stable par \( f\).
		\item\label{ItemfzKOCo}
		      L'espace \( E_{f,x}\) est de dimension
		      \begin{equation}
			      p_{f,x}=\dim E_{f,x}=\deg(\mu_{f,x})
		      \end{equation}
		      où \( \mu_{f,x}\) est le générateur unitaire de \( I_{f,x}\).
		\item   \label{ItemKHNExH}
		      Le polynôme caractéristique de \( f|_{E_{f,x}}\) est \( \mu_{f,x}\).
		\item   \label{ItemHMviZw}
		      Nous avons
		      \begin{equation}
			      \chi_{f|_{E_{f,x}}}(f)x=\mu_{f,x}(f)x=0.
		      \end{equation}
	\end{enumerate}
\end{proposition}

\begin{proof}
	Le fait que \( E_{f,x}\) soit stable par \( f\) est classique. Le point~\ref{ItemHMviZw} est une application du point~\ref{ItemKHNExH}. Les deux gros morceaux sont donc les points~\ref{ItemfzKOCo} et~\ref{ItemKHNExH}.

	Étant donné que \( \mu_{f,x}\) est de degré minimal dans \( I_{f,x}\), l'ensemble
	\begin{equation}
		B=\{ f^k(x)\tq 0\leq k\leq p_{f,x}-1 \}
	\end{equation}
	est libre. En effet une combinaison nulle des vecteurs de \( B\) donnerait un polynôme en \( f\) de degré inférieur à \( p_{f,x}\) annulant \( x\). Nous écrivons
	\begin{equation}
		\mu_{f,x}(X)=X^{p_{f,x}}-\sum_{i=0}^{p_{f,x}-1}a_iX^i.
	\end{equation}
	Étant donné que \( \mu_{f,x}(f)x=0\) et que la somme du membre de droite est dans \( \Span(B)\), nous avons \( f^{p_{f,x}}(x)\in\Span(B)\). Nous prouvons par récurrence que \( f^{p_{f,x}+k}(x)\in\Span(B)\). En effet en appliquant \( f^k\) à l'égalité
	\begin{equation}
		0=f^{p_{f,x}}(x)-\sum_{i=0}^{p_{f,x}-1}a_if^i(x)
	\end{equation}
	nous trouvons
	\begin{equation}
		f^{p_{f,x}+k}(x)=\sum_{i=0}^{p_{f,x}-1}a_if^{i+k}(x),
	\end{equation}
	alors que par hypothèse de récurrence le membre de droite est dans \( \Span(B)\). L'ensemble \( B\) est alors générateur de \( E_{f,x}\) et donc une base d'icelui. Nous avons donc bien \( \dim(E_{f,x})=p_{f,x}\).

	Nous montrons maintenant que \( \mu_{f,x}\) est annulateur de \( f\) au point \( x\). Nous savons que
	\begin{equation}
		\mu_{f,x}(f)x=0.
	\end{equation}
	En y appliquant \( f^k\) et en profitant de la commutativité des polynômes sur les endomorphismes (proposition~\ref{LemQWvhYb}), nous avons
	\begin{equation}
		0=f^k\big( \mu_{f,x}(f)x \big)=\mu_{f,x}(f)f^k(x),
	\end{equation}
	de telle sorte que \( \mu_{f,x}(f)\) est nul sur \( B\) et donc est nul sur \( E_{f,x}\). Autrement dit,
	\begin{equation}
		\mu_{f,x}\big( f|_{E_{f,x}} \big)=0.
	\end{equation}
	Montrons que \( \mu_{f,x}\) est même minimal pour \( f|_{E_{f,x}}\).

	Supposons avoir \( Q\), un polynôme non nul de degré \( p_{f,x}-1\) annulant \( f|_{E_{f,x}}\). En particulier \( Q(f)x=0\). Cela signifie que \( B\) est un système lié, alors que nous avons montré que c'était un système libre. Contradiction. Nous concluons que \( \mu_{f,x}\) est le polynôme minimal de \( f|_{E_{f,x}}\).
\end{proof}

Cette histoire de densité permet de donner une démonstration alternative du théorème de Cayley-Hamilton.
\begin{theorem}[Cayley-Hamlilton]   \label{ThoCalYWLbJQ}
	Le polynôme caractéristique est un polynôme annulateur.
\end{theorem}
\index{théorème!Cayley-Hamilton}

Une démonstration plus simple via la densité des diagonalisables est donnée en théorème~\ref{ThoHZTooWDjTYI}.
\begin{proof}
	Nous devons prouver que \( \chi_f(f)x=0\) pour tout \( x\in E\). Pour cela nous nous fixons un \( x\in E\), nous considérons l'espace \( E_{f,x}\) et \( \chi_{f,x}\), le polynôme caractéristique de \( f|_{E_{f,x}}\). Étant donné que \( E_{f,x}\) est stable par \( f\), le polynôme caractéristique de \( f|_{E_{f,x}}\) divise \( \chi_f\), c'est-à-dire qu'il existe un polynôme \( Q_x\) tel que
	\begin{equation}
		\chi_f=Q_x\chi_{f,x},
	\end{equation}
	et donc aussi
	\begin{equation}
		\chi_f(f)x=Q_x(f)\big( \chi_{f,x}(f)x \big)=0
	\end{equation}
	parce que la proposition~\ref{PropNrZGhT} nous indique que \( \chi_{f,x}\) est un polynôme annulateur de \( f|_{E_{f,x}}\).
\end{proof}

\begin{corollary}
	Le degré du polynôme minimal est majoré par la dimension de l'espace.
\end{corollary}

\begin{proof}
	Le polynôme minimal divise le polynôme caractéristique parce qu'il engendre l'idéal des polynômes annulateurs par la proposition \ref{PropAnnncEcCxj}. Or le degré du polynôme caractéristique est la dimension de l'espace par le lemme~\ref{LemooWCZMooZqyaHd}.
\end{proof}

\begin{example}[Calcul de l'inverse d'un endomorphisme]
	Le théorème de Cayley-Hamilton donne un moyen de calculer l'inverse d'un endomorphisme inversible pourvu que l'on connaisse son polynôme caractéristique. En effet, supposons que
	\begin{equation}
		\chi_f(X)=\sum_{k=0}^na_kX^k.
	\end{equation}
	Nous aurons alors
	\begin{equation}
		0=\chi_f(f)=\sum_{k=0}^na_kf^k.
	\end{equation}
	Nous appliquons \( f^{-1}\) à cette dernière égalité en sachant que \( f^{-1}(0)=0\) :
	\begin{equation}
		0=a_0f^{-1}+\sum_{k=1}^na_kf^{k-1},
	\end{equation}
	et donc
	\begin{equation}
		f^{-1}=-\frac{1}{ \det(f) }\sum_{k=1}^na_kf^{k-1}
	\end{equation}
	où nous avons utilisé le fait que \( a_0=\chi_f(0)=\det(f)\).
\end{example}

\begin{proposition}\label{PropooBYZCooBmYLSc}
	Si \( (X-z)^l\) (\( l\geq 1\)) est la plus grande puissance de \( (X-z)\) dans le polynôme caractéristique d'un endomorphisme \( f\) alors
	\begin{equation}
		1\leq \dim(E_z)\leq l.
	\end{equation}
	C'est-à-dire que nous avons au moins un vecteur propre pour chaque racine du polynôme caractéristique.
\end{proposition}

\begin{proof}
	Si \( (X-z)\) divise \( \chi_f\) alors en posant \( \chi_f=(X-z)P(X)\) nous avons
	\begin{equation}
		\det(f-X\mtu)=(X-z)P(X),
	\end{equation}
	ce qui, évalué en \( X=z\), donne \( \det(f-z\mtu)=0\). L'annulation du déterminant étant équivalente à l'existence d'un noyau non trivial, nous avons \( v\neq 0\) dans \( E\) tel que \( (f-z\mtu)v=0\). Cela donne \( f(v)=zv\) et montre que \( v\) est vecteur propre de \( f\) pour la valeur propre \( z\). Et aussi que \( \dim(E_z)\geq 1\).

	Si \( \dim(E_z)=k\) alors le théorème de la base incomplète~\ref{ThonmnWKs} nous permet d'écrire une base de \( E\) dont les \( k\) premiers vecteurs forment une base de \( E_z\). Dans cette base, la matrice de \( f\) est de la forme
	\begin{equation}
		\begin{pmatrix}
			z &        &   & *      \\
			  & \ddots &   & \vdots \\
			  &        & z & *      \\
			  &        &   & *
		\end{pmatrix}
	\end{equation}
	où les étoiles représentent des blocs à priori non nuls. En tout cas, sous cette forme, il est visible que \( (X-z)^k\) divise \( \chi_f\).
\end{proof}
