% This is part of Mes notes de mathématique
% Copyright (c) 2006-2025
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Étude d'asymptote}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Lorsqu'une fonction tend vers l'infini pour \( x\to \infty\), une question qui peut venir est : à quelle vitesse tend-elle vers l'infini ?

Il est «visible» que la fonction logarithme ne tend pas très vite vers l'infini : certes
\begin{equation}
	\lim_{x\to \infty} \ln(x)=+\infty,
\end{equation}
mais par exemple \( \ln(100000)\simeq 11.5\) tandis que \(  e^{100000}\simeq 10^{43429}\). Sans contestations possibles, l'exponentielle croit plus vite que le logarithme.

Soient \( f\) et \( g\) deux fonctions dont la limite \( x\to \infty\) est \( \infty\). Si
\begin{equation}
	\lim_{x\to \infty} \frac{ f(x) }{ g(x) }=0
\end{equation}
nous disons que \( g\) tend vers \( \infty\) plus vite que \( f\); si
\begin{equation}
	\lim_{x\to \infty} \frac{ f(x) }{ g(x) }=\infty
\end{equation}
nous disons que \( f\) tend vers \( \infty\) plus vite que \( g\), et si
\begin{equation}
	\lim_{x\to \infty} \frac{ f(x) }{ g(x) }=a\in \eR
\end{equation}
avec \( a\neq 0\) alors nous disons que \( f\) tend vers l'infini à la même vitesse que \( ag(x)\).

\begin{example}
	La fonction \( x\mapsto x^2\) tend vers l'infini plus vite que la fonction \( x\mapsto \sqrt{x}\).
\end{example}

Dans cette section nous allons nous contenter de déterminer les fonctions qui tendent vers l'infini aussi vite qu'une droite oblique, que nous appellons asymptote et que nous voulons déterminer.


\begin{example}
	Déterminer les asymptotes obliques (s'ils existent) de la fonction
	\begin{equation}
		f(x)= e^{1/x}\sqrt{1+4x^2}.
	\end{equation}
	Tout d'abord nous remarquons que \( \lim_{x\to \infty} f(x)=\infty\). Nous sommes donc en présence d'une branche du graphe qui tend vers l'infini. Ensuite,
	\begin{equation}
		\lim_{x\to \infty} \frac{ f(x) }{ x }=\lim_{x\to \infty}  e^{1/x}\sqrt{\frac{1}{ x^2 }+4}=2.
	\end{equation}
	Donc le graphe de \( f\) tend vers l'infini à la même vitesse que le graphe de la fonction \( y=2x\). Nous aurons donc une asymptote oblique de coefficient directeur \( 2\). De façon imagée, nous pouvons penser que le graphe de \( f\) et celui de \( y=2x\) sont presque parallèles si \( x\) est assez grand. Afin de déterminer l'ordonnée à l'origine de l'asymptote, il nous reste à voir quelle est la «distance» entre le graphe de \( f\) et celui de \( y=2x\) :
	\begin{equation}
		\lim_{x\to \infty} f(x)-2x=\lim_{x\to \infty}  e^{1/x}\sqrt{1+4x^2}-2x.
	\end{equation}
	Cette limite a été calculée dans l'exemple~\ref{ExBCDookjljhjk} et vaut \( 2\).

	Nous concluons que le graphe de la fonction \( f\) admet l'asymptote
	\begin{equation}
		y=2x+2.
	\end{equation}
\end{example}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Développement en série}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Série génératrice d'une suite}
%---------------------------------------------------------------------------------------------------------------------------

Soit \( u_n\) une suite telle que le rayon de convergence de
\begin{equation}
	f(z)=\sum_{n=0}^{\infty}u_nz^n
\end{equation}
soit strictement positif. Alors la série \( f\) est la \defe{série génératrice}{série!génératrice d'une suite} de la suite \( (u_n)\).

Grâce au théorème~\ref{ProptzOIuG} nous pouvons la dériver terme à terme autour de \( z=0\). En utilisant la petite formule \eqref{EqSOFdwhw} nous trouvons
\begin{equation}    \label{EqNGhVCpP}
	f^{(l)}(z)=\sum_{n=l}^{\infty}u_n\frac{ n! }{ (n-l)! }z^{n-l},
\end{equation}
et donc
\begin{equation}
	u_l=\frac{ f^{(l)}(0) }{ l! }.
\end{equation}
D'où le nom de série génératrice. Cela est évidemment intéressant seulement si nous connaissons une autre forme pour \( f\) par ailleurs.

Nous en utiliserons une pour déterminer les partitions d'un nombre en parts fixes, proposition~\ref{THOooQDYWooCOiUMb}.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Développement en série et Taylor}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}  \label{DefwmRzKh}
	Soit une fonction \( f\colon \eC\to \eC\) et \( z_0\in \eC\). Nous disons que \( f\) est \defe{développable en série entière}{développable!en série entière} dans un voisinage de \( z_0\) si il existe une série \( \sum_n a_nz^n\) de rayon de convergence \( R>0\) et \( r\leq R\) tel que
	\begin{equation}
		f(z)=\sum_{n=0}^{\infty}a_n(z-z_0)^n
	\end{equation}
	pour tout \( z\in B(z_0,r)\).
\end{definition}

\begin{proposition}
	Si \( V\) est un ouvert dans \( \eC\) alors l'ensemble des fonctions \( V\to \eC\) développables en série entière forme une \( \eC\)-algèbre.
\end{proposition}

\begin{proof}
	Les séries entières passent aux sommes et aux produits en gardant des rayons de convergence non nuls.
\end{proof}

\begin{proposition} \label{ThoTGPtDj}
	Si \( f\) est développable en série entière à l'origine alors elle est \( C^{\infty}\) sur un voisinage de l'origine et le développement est celui de \defe{Taylor}{Taylor!série entière} :
	\begin{equation}
		f(x)=\sum_{n=0}^{\infty}\frac{ f^{(n)}(0) }{ n! }x^n
	\end{equation}
	pour tout \( x\) dans un voisinage de \( 0\).
\end{proposition}

\begin{proof}
	Si \( f(x)=\sum a_nx^n\), nous savons que \( f\) est \( C^1\) et que nous pouvons dériver terme à terme (au moins dans un voisinage). De plus le fait de dériver ne change pas le domaine. Par récurrence, la fonction est \( C^{\infty}\) sur le voisinage. En dérivant \( k\) fois la série \( \sum a_nx^n\) nous trouvons
	\begin{equation}
		f^{(k)}(x)=\sum_{n=k}^{\infty}n(n-1)\ldots (n-k+1)a_nx^{n-k}.
	\end{equation}
	En calculant en \( x=0\) nous trouvons
	\begin{equation}
		f^{(k)}(0)=k! a_k,
	\end{equation}
	d'où le terme général
	\begin{equation}
		a_k=\frac{ f^{(k)}(0) }{ k! }.
	\end{equation}
\end{proof}

Si \( f\) est une fonction et si la série
\begin{equation}
	T_f(x)=\sum_{n=0}^{\infty}\frac{ f^{(n)}(0) }{ n! }x^n
\end{equation}
converge, alors cette série est la \defe{série de Taylor}{série!Taylor} de \( f\).

\begin{remark}
	La série de Taylor d'une fonction n'est pas liée à sa fonction de façon aussi raide qu'on pourrait le croire. Même dans le cas d'une fonction \( C^{\infty}\) il peut arriver que \( T_f(x)\neq f(x)\).

	Il peut aussi arriver que \( f\) ne soit pas développable en série entière.
\end{remark}

\begin{example}
	Nous considérons la fonction
	\begin{equation}
		f(x)=\begin{cases}
			e^{-1/x^2} & \text{si } x\neq 0     \\
			0          & \text{si } x=0\text{.}
		\end{cases}
	\end{equation}
	Nous avons
	\begin{equation}
		f'(x)=\begin{cases}
			\frac{ 2 }{ x^3 } e^{-1/x^2} & \text{si } x\neq 0 \\
			0                            & \text{si } x=0.
		\end{cases}
	\end{equation}
	Note : pour la seconde ligne nous devons faire explicitement le calcul
	\begin{equation}
		f'(0)=\lim_{t\to 0} \frac{ f(t)-f(0) }{ t }=\lim_{t\to 0} \frac{1}{ t } e^{-1/t^2}=0.
	\end{equation}
	Plus généralement nous avons \( f^{(k)}(0)=0\), et par conséquent la série de Taylor converge (trivialement) vers la fonction identiquement nulle.

	Cette fonction n'est donc pas développable en série entière vu qu'il n'existe aucun voisinage de zéro sur lequel la série de \( f\) coïncide avec \( f\).
\end{example}

\begin{example}     \label{ExwobBAW}
	Développement de \( f(x)=\arctan(x)\). Nous savons que
	\begin{equation}
		f'(x)=\frac{1}{ 1+x^2 },
	\end{equation}
	alors que nous connaissons le développement
	\begin{equation}    \label{EqVmuaqT}
		\frac{1}{ 1-x }=\sum_{n=0}^{\infty}x^n
	\end{equation}
	pour tout \( x\in B(0,1)\). Nous avons donc successivement
	\begin{subequations}
		\begin{align}
			\frac{1}{ 1+x }     & =\sum_{n=0}(-x)^n                                      \\
			\frac{ 1 }{ 1+x^2 } & =\sum_{n=0}(-1)^nx^{2n}                                \\
			\arctan(x)          & =\sum_{n=1}^{\infty}(-1)^n\frac{ x^{2n+1} }{ 2n+1 }+C.
		\end{align}
	\end{subequations}
	Notons que dans la dernière nous avons évité d'écrire la somme depuis \( n=0\) (qui serait un terme constant) et nous avons écris explicitement «\( +C\)». Étant donné que \( \arctan(0)=0\), nous devons poser \( C=0\) et donc
	\begin{equation}
		\arctan(x)=\sum_{n=1}^{\infty}(-1)^n\frac{ x^{2n+1} }{ 2n+1 }.
	\end{equation}
\end{example}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Resommer une série}
%---------------------------------------------------------------------------------------------------------------------------

Nous avons vu comment trouver la série correspondant à une fonction donnée. Un exercice difficile consiste à trouver la fonction qui correspond à une somme donnée.

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Les sommes du type \texorpdfstring{\(  \sum_nP(n)x^n\)}{P}}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Pour calculer
\begin{equation}
	\sum_{n=0}^{\infty}P(n)x^n
\end{equation}
où \( P\) est un polynôme de degré \( m\) nous commençons par écrire
\begin{equation}
	P(n)=\alpha_0+\alpha_1(n+1)+\alpha_2(n+1)(n+2)+\cdots +\alpha_m(n+1)\ldots (n+m).
\end{equation}
Nous décomposons alors la somme en \( m\) sommes de la forme
\begin{equation}
	\sum_{n=0}^{\infty}\alpha_k\frac{ (n+k)! }{ n! }x^n=\alpha_k\left( \sum_{n=0}^{\infty}x^{n+k} \right)^{(k)}.
\end{equation}
Effectuons par exemple
\begin{equation}
	\sum_{n=0}^{\infty}x^{n+3}=\frac{1}{ 1-x }-1-x-x^2
\end{equation}
Notons que dans un usage pratique, ce terme devra être ensuite dérivé trois fois, de telle manière que les termes «correctifs» n'interviennent pas. Cette méthode ne demande donc que de calculer les dérivées successives de \( 1/(1-x)\).

\begin{example}
	Calculons la fonction
	\begin{equation}
		f(x)=\sum_{n=0}^{\infty}n^3x^n.
	\end{equation}
	D'abord nous écrivons
	\begin{equation}
		n^3=-1+7(n+1)-6(n+1)(n+2)+(n+1)(n+2)(n+3).
	\end{equation}
	Nous avons
	\begin{equation}
		\sum_{n=0}^{\infty}(n+1)x^n=\left( \sum_{n=0}^{\infty}x^{n+1} \right)'=\left( \frac{1}{ 1-x }-1 \right)'=\frac{1}{ (x-1)^2 }.
	\end{equation}
	De la même façon,
	\begin{subequations}
		\begin{align}
			\sum_n (n+1)(n+2)x^n & =\left( \sum x^{n+2} \right)''=\frac{ -2 }{ (x-1)^3 } \\
			\sum_n (n+1)(n+2)(n+3)x^n=\frac{ 6 }{ (x-1)^4 }.
		\end{align}
	\end{subequations}
	En remettant tout ensemble nous obtenons
	\begin{equation}
		\sum_{n=0}^{\infty}n^3x^n=-\frac{1}{ 1-x }+\frac{ 7 }{ (x-1)^2 }+\frac{ 12 }{ (x-1)^3 }+\frac{ 6 }{ (x-1)^4 }.
	\end{equation}

	Nous pouvons vérifier ce résultat en traçant les deux courbes et en remarquant qu'elles coïncident.
	\begin{verbatim}
----------------------------------------------------------------------
| Sage Version 4.7.1, Release Date: 2011-08-11                       |
| Type notebook() for the GUI, and license() for information.        |
----------------------------------------------------------------------
sage: n=var('n')
sage: S(x)=sum(  [ n**3*x**n for n in range(0,30)  ]   )
sage: f(x)=-1/(1-x)+7/((x-1)**2)+12/((x-1)**3)+6/( (x-1)**4  )
sage: S(0.1)
0.214906264288980
sage: f(0.1)
0.214906264288981
sage: f.plot(-0.5,0.5)+S.plot(-0.5,0.5)
\end{verbatim}

\end{example}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Les sommes du type \texorpdfstring{\(  \sum_nx^n/P(n)\)}{P}}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Si \( P(n)\) a des racines entières, nous pouvons le décomposer en fractions simples et utiliser la somme
\begin{equation}
	\sum_{n=1}^{\infty}\frac{ x^n }{ n }=-\ln(1-x).
\end{equation}
Nous avons par exemple
\begin{subequations}
	\begin{align}
		\sum_{n=0}^{\infty}\frac{x^n}{ n+1 } & =\frac{1}{ x }\sum_{n=0}\frac{ x^{n+1} }{ n+1 }                             \\
		                                     & =\frac{1}{ x }\sum_{n=1}^{\infty}\frac{ x^n }{ n }=-\frac{ \ln(1-x) }{ x }.
	\end{align}
\end{subequations}
Notez le changement de point de départ de la somme au passage.

Autre exemple :
\begin{subequations}
	\begin{align}
		\sum_{n=0}^{\infty}\frac{ x^n }{ n+3 } & =\frac{1}{ x^3 }\left( \sum_{n=1}^{\infty}\frac{ x^n }{ n }-x-\frac{ x^2 }{ 2 } \right) \\
		                                       & =-\frac{ \ln(x-1) }{ x^3 }-\frac{1}{ x^2 }-\frac{1}{ 2x }.
	\end{align}
\end{subequations}

Si le polynôme possède des racines non entières, les choses se compliquent.

\begin{example}
	Calculons
	\begin{equation}
		\sum_{n=0}^{\infty}\frac{ x^n }{ 2n+1 }.
	\end{equation}
	Si \( x\geq 0\), en posant \( t=\sqrt{x}\) nous trouvons
	\begin{equation}
		\sum_{n=0}^{\infty}\frac{ x^n }{ 2n+1 }=\frac{1}{ t }\sum_{n=0}^{\infty}\frac{ t^{2n+1} }{ 2n+1 }.
	\end{equation}
	Étudions
	\begin{equation}
		H(t)=\sum_{n=0}^{\infty}\frac{ t^{2n+1} }{ 2n+1 }.
	\end{equation}
	Nous avons
	\begin{equation}     \label{EqBuPjcM}
		H'(t)=\sum_{n=0}^{\infty}t^{2n}=\sum_{n=0}(t^2)^n=\frac{1}{ 1-t^2 }.
	\end{equation}
	Une primitive de cette fonction est
	\begin{equation}
		\frac{ 1 }{2}\ln\left| \frac{ t+1 }{ t-1 } \right|.
	\end{equation}
	En \( t=0\), cette fonction vaut \( 0\) qui est la bonne valeur. Donc nous avons bien
	\begin{equation}
		H(t)=\frac{ 1 }{2}\ln\left| \frac{ t+1 }{ t-1 } \right|.
	\end{equation}

	Notons que ce que l'équation \eqref{EqBuPjcM} nous dit est que \( H(t)\) est une primitive de \( 1/(1-t^2)\). Il faut choisir la bonne primitive en fixant une valeur.

	Nous avons donc
	\begin{equation}
		\sum_{n=0}^{\infty}\frac{ x^n }{ 2n+1 }=\frac{ 1 }{2\sqrt{x}}\ln\left| \frac{ \sqrt{x}+1 }{ \sqrt{x}-1 } \right|
	\end{equation}
	pour \( x>0\). Nous devons encore trouver ce que cela vaut pour \( x<0\).

	Nous posons successivement \( X=-x\) puis \( g(X)=f(-X)\). Ce que nous devons calculer est
	\begin{equation}
		g(t)=\frac{1}{ t }\sum_{n=0}^{\infty}\frac{ (-1)^nt^{2n+1} }{ 2n+1 }.
	\end{equation}
	Si nous posons
	\begin{equation}
		h(t)=\sum \frac{ (-1)^nt^{2n+1} }{ 2n+1 },
	\end{equation}
	alors
	\begin{equation}
		h'(t)=\sum (-1)^nt^{2n}=\sum (-t^2)^n=\frac{1}{ 1+t^2 },
	\end{equation}
	par conséquent \( h(t)=\arctan(t)\) (cela avait déjà été déduit à l'envers dans l'exemple~\ref{ExwobBAW}).

	Au final
	\begin{equation}        \label{EqIHlDjG}
		f(x)=\sum_{n=0}^{\infty}\frac{ x^n }{ 2n+1 }=\begin{cases}
			\frac{ 1 }{2\sqrt{x}}\ln\left| \frac{ \sqrt{x}+1 }{ \sqrt{x}-1 } \right| & \text{si } x>0  \\
			\frac{ \arctan(\sqrt{-x}) }{ \sqrt{-x} }                                 & \text{si } x<0  \\
			1                                                                        & \text{si } x=0.
		\end{cases}
	\end{equation}
	Notons qu'elle est continue en zéro à gauche et à droite.

\end{example}

\begin{example}
	Nous considérons l'exemple suivant :
	\begin{equation}
		f(x)=\sum_{n=0}^{\infty}\frac{ x^n }{ 3n+2 }.
	\end{equation}
	Nous posons \( t=\sqrt[3]{x}\), et nous substituons :
	\begin{equation}
		\frac{ x^n }{ 3n+2 }=\frac{ t^{3n} }{ 3n+2 }=\frac{1}{ t^2 }\frac{ t^{3n+2} }{ 3n+2 }.
	\end{equation}
	Nous devons étudier la fonction
	\begin{equation}
		g(t)=\sum_{n=0}^{\infty}\frac{ t^{3n+2} }{ 3n+2 }
	\end{equation}
	Nous avons
	\begin{equation}
		g'(t)=\sum_{n=0}t^{3n+1}=t\sum_{n=0}t^{3n}=\frac{ t }{ 1-t^3 }.
	\end{equation}
	Notons que \( g(0)=0\).
\end{example}

\begin{example}
	Calculer le nombre
	\begin{equation}        \label{EqgUyKYe}
		\sum_{n=0}^{\infty}\frac{ (-1)^n }{ 2n+1 }.
	\end{equation}
	Nous aurions envie de dire que cela est \( f(-1)\) pour la fonction \( f\) donnée en \eqref{EqIHlDjG}. Le problème est que le rayon de convergence de \( f\) étant \( 1\), rien n'est garanti quand au fait que la fonction y soit continue en \( x=-1\). En particulier nous devons justifier le fait que
	\begin{equation}
		\lim_{x\to -1} \sum_n\frac{ x^n }{ 2n+1 }=\lim_{x\to -1} \frac{1}{ \sqrt{-x} }\arctan(\sqrt{-x}).
	\end{equation}
	Ce qui nous sauve est le critère d'Abel radial (théorème~\ref{ThoLUXVjs}). En effet la série
	\begin{equation}        \label{EqAFrXRB}
		\sum\frac{ r^n }{ 2n+1 }
	\end{equation}
	étant convergente avec \( r=-1\), la série correspondante est continue sur \( \mathopen[ -1 , 0 \mathclose]\). Nous pouvons donc calculer la série \eqref{EqgUyKYe} en posant \( x=-1\) dans \eqref{EqIHlDjG} :
	\begin{equation}
		\sum_{n=0}^{\infty}\frac{ (-1)^n }{ 2n+1 }=\frac{ \pi }{ 4 }.
	\end{equation}

	Note : la série \eqref{EqAFrXRB} ne converge pas avec \( r=1\). La fonction \( f\) n'est pas continue en \( x=1\).
\end{example}

\begin{example}     \label{ExGxzLlP}
	Nous avons
	\begin{equation}
		\sum_{n=1}^{\infty}nx^{n-1}=\frac{1}{ (1-x)^2 }.
	\end{equation}
	En effet si nous désignons par \( f\) la somme à gauche, nous trouvons que \( f=g'\) avec
	\begin{equation}
		g(x)=\sum_{n=1}^{\infty}x^n.
	\end{equation}
	Nous savons par ailleurs que \( g(x)=1/(1-x)\). Par conséquent
	\begin{equation}
		f(x)=\left( \frac{1}{ 1-x } \right)'=\frac{1}{ (1-x)^2 }.
	\end{equation}
\end{example}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Sage, primitives et logarithme complexe}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

\begin{normaltext}\label{ooOPWYooDDSZWx}

	Attention : Sage pourrait nous induire en erreur si nous n'y prenions pas garde. En effet ce que vous ne savez pas mais que Sage sait, c'est que
	\begin{equation}
		\ln(-1)=i\pi.
	\end{equation}
	Par conséquent Sage se permet de donner des primitives sans valeurs absolues dans le logarithme :
	\begin{verbatim}
sage: f(x)=1/x
sage: f.integrate(x)
x |--> log(x)
\end{verbatim}
	La primitive à laquelle on s'attend d'habitude est \( \ln(| x |)\). Ici la réponse est correcte parce que si \( x\) est négatif nous avons
	\begin{equation}
		\ln(x)=\ln\big( (-1)| x | \big)=\ln(-1)+\ln(| x |).
	\end{equation}
	Cette fonction est donc décalée de la primitive usuelle seulement de la constante \( \ln(-1)\).

	Un exemple plus élaboré :
	\begin{verbatim}
sage: h(x)=1/(1-x**2)
sage: H=h.integrate(x)
sage: H
x |--> -1/2*log(x - 1) + 1/2*log(x + 1)
sage: H(0)
-1/2*I*pi
\end{verbatim}
\end{normaltext}

\begin{example}
	Encore une fois il faut faire attention en demandant la primitive à Sage :
	\begin{verbatim}
----------------------------------------------------------------------
| Sage Version 4.7.1, Release Date: 2011-08-11                       |
| Type notebook() for the GUI, and license() for information.        |
----------------------------------------------------------------------
sage: f(x)=x/(1-x**3)
sage: F=f.integrate(x)
sage: F(0)
-1/3*I*pi - 1/3*sqrt(3)*arctan(1/3*sqrt(3))
\end{verbatim}
	Cette fois la primitive proposée diffère de celle qu'on cherche de la constante complexe
	\begin{equation}
		-\frac{ \pi }{ 3 }i.
	\end{equation}
	Mais il y a pire si nous voulons tracer. Nous voudrions définir la fonction \( F_2(x)=F(x)-F(0)\). Mathématiquement c'est bien de cette fonction que nous parlons, mais :
	\begin{verbatim}
sage: F2(x)=F(x)-F(0)
sage: F2(x)
1/3*I*pi - 1/3*sqrt(3)*arctan(1/3*(2*x + 1)*sqrt(3)) +
    +1/3*sqrt(3)*arctan(1/3*sqrt(3)) - 1/3*log(x - 1) + 1/6*log(x^2 + x + 1)
sage: F2.plot(x,-0.1,0.1)
verbose 0 (4101: plot.py, generate_plot_points) 
        WARNING: When plotting, failed to evaluate function at 200 points.
verbose 0 (4101: plot.py, generate_plot_points) 
        Last error message: 'unable to simplify to float approximation'
\end{verbatim}
	Il refuse de tracer. Pourquoi ? La partie complexe de l'expression de \( F_2\) est mathématiquement nulle, mais elle est en deux parties :
	\begin{equation}
		\frac{ \pi }{ 3 }+\text{la partie imaginaire de} -\frac{1}{ 3 }\ln(x-1).
	\end{equation}
	Lorsque Sage tente de tracer, il donne à \( x\) un certain nombre de valeurs et calcule une \emph{valeur approchée} de \( \ln(x-1)\). Cette dernière ne se simplifie pas avec le nombre \emph{exact} \( \pi/3\). Sage reste donc avec une partie imaginaire qu'il ne peut pas tracer.

	Notez la nuance :
	\begin{verbatim}
sage: ln(-0.1)
-2.30258509299405 + 3.14159265358979*I
sage: ln(-1/10)
I*pi + log(1/10)
\end{verbatim}
	Du coup nous avons aussi
	\begin{verbatim}
sage: F2(-0.1)
1/3*I*pi - 1/3*sqrt(3)*arctan(0.266666666666667*sqrt(3))
    + 1/3*sqrt(3)*arctan(1/3*sqrt(3)) - 0.0474885065133152 - 1.04719755119660*I
\end{verbatim}

\end{example}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Nombres de Bell}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Ici nous montrerions bien le théorème~\ref{ThoYFAzwSg} sur les nombres de Bell parce que c'est essentiellement un résultat sur les séries entières et leurs manipulations. Hélas, il demande un tout petit peu d'équation différentielle (presque rien). Donc il est postposé jusqu'en page \pageref{ThoYFAzwSg}.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Séries entières de matrices}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\label{secEVnZXgf}

Nous nous proposons d'étudier des séries de la forme
\begin{equation}
	\sum_{k=0}^{\infty}a_kA^k
\end{equation}
où \( A\) est une matrice. L'essentiel de la théorie va rester. Nous considérons une norme algébrique (définition~\ref{DefJWRWQue}), c'est-à-dire \( \| AB \|\leq \| A \|\| B \|\).

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Rayon de convergence}
%---------------------------------------------------------------------------------------------------------------------------

La notion de rayon de convergence de cette série reste la même : c'est la définition~\ref{DefZWKOZOl} qui ne dépend que des coefficients \( a_k\) et pas du tout de ce qu'on met à côté dans la somme. Évidemment il faudra montrer que dans le cas des matrices, le nom «rayon de convergence» n'est pas usurpé.

\begin{proposition} \label{PropFIPooSSmJDQ}
	Soit \( (a_n)\) une suite dans \( \eC\) de rayon de convergence \( R\) et \( A\in \eM(n,\eR)\) une matrice vérifiant \( \| A \|<R\). Alors la série
	\begin{equation}
		\sum_{k=0}^{\infty}a_kA^k
	\end{equation}
	converge absolument, c'est-à-dire que \( \sum_k\| a_kA^k \|<\infty\).
\end{proposition}

\begin{proof}
	Nous avons les majorations
	\begin{equation}
		\| a_n A^n\|\leq | a_n |\| A^n \|\leq | a_n |\| A \|^n.
	\end{equation}
	Par hypothèse \( \| A \|<R\) et \( R\) est un supremum, donc il existe \( r\) tel que \( \| A \|<r<R\) avec \( (a_nr^n)\) borné. Nommons \( M\) un majorant de la suite \( (a_nr^n)\). Alors nous avons
	\begin{equation}
		\| a_nA^n \|\leq | a_n |r^n\frac{ \| A \|^n }{ r^n }\leq M\left( \frac{ \| A \| }{ r } \right)^n.
	\end{equation}
	La série du membre de droite converge parce que c'est une série géométrique de raison plus petite que \( 1\), proposition \ref{PROPooWOWQooWbzukS}.
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Convergence et rayon spectral}
%---------------------------------------------------------------------------------------------------------------------------

Le concept de rayon spectral permet aussi de donner des informations sur la convergence de séries de matrices. Pour rappel le rayon spectral d'une matrice est le maximum du module de ses valeurs propres (définition~\ref{DEFooEAUKooSsjqaL}). Le rayon spectral de la matrice \( A\) est noté \( \rho(A)\).

La proposition suivante sera redémontrée indépendamment dans le théorème~\ref{THOooMNLGooKETwhh}.

\begin{proposition}[\cite{fJhCTE}]      \label{PROPooDJFLooBqqEPT}
	Si \( A\in \eM(n,\eC)\) est telle que \( \rho(A)<1\), alors \( A^n\to 0\).
\end{proposition}

\begin{proof}
	Nous nous plaçons dans une base des espaces caractéristiques\footnote{Voir le théorème~\ref{ThoSpectraluRMLok}} de \( A\), c'est-à-dire que nous supposons que la matrice \( A\) a la forme
	\begin{equation}        \label{EqWMvkgLo}
		A=\begin{pmatrix}
			\lambda_1\mtu+N_1 &        &                   \\
			                  & \ddots &                   \\
			                  &        & \lambda_s\mtu+N_s
		\end{pmatrix}
	\end{equation}
	où les \( \lambda_i\) sont les valeurs propres de \( A\) et les \( N_i\) sont nilpotentes. En effet nous savons que l'espace caractéristique \( F_{\lambda_i}\) est l'espace de nilpolence de \( A-\lambda_i\mtu\). Si nous notons \( A_i\) la restriction de \( A\) à cet espace, la matrice \( N_i=A_i-\lambda_i\mtu\) est nilpotente. Du coup \( A_i=\lambda_I\mtu+N_i\) et nous avons bien la décomposition \eqref{EqWMvkgLo}.

	Nous avons donc \( A^n\to 0\) si et seulement si \( (N_i+\lambda_i\mtu)^n\to 0\) pour tout \( i\). Soit donc \( N\) nilpotente et \( \lambda<1\) (parce que nous savons que toutes les valeurs propres de \( A\) sont inférieures à un). Nous avons
	\begin{equation}
		(\lambda\mtu+N)^n=\sum_{k=0}^n\binom{ n }{ k }\lambda^{n-k}N^{k}
		=\sum_{k=0}^{r-1}\binom{ n }{ k }\lambda^{n-k}N^{k}.
	\end{equation}
	Nous voyons que le nombre de termes dans la somme ne dépend pas de \( n\). De plus pour chacun de termes, la puissance de \( N\) ne dépend pas non plus de \( n\). Le terme
	\begin{equation}
		\binom{ n }{ k }\lambda^{n-k}\leq P(n)\lambda^{n-k}
	\end{equation}
	où \( P\) est un polynôme tend vers zéro lorsque \( n\) devient grand parce que c'est un cas polynôme fois exponentielle.
\end{proof}

\begin{theorem}[Série de Von Neumann, thème~\ref{THEMEooPQKDooTAVKFH}\cite{ooETMNooSrtWet}]   \label{THOooMNLGooKETwhh}
	Soit \( A\in \eM(n,\eK)\) (\( \eK=\eR\) ou \( \eC\)). Les affirmations suivantes sont équivalentes.
	\begin{enumerate}
		\item       \label{ITEMooCGLSooZsMXSt}
		      \( \lim_{k\to \infty} A^k=0\)
		\item       \label{ITEMooYBGEooXAzVbD}
		      \( \rho(A)<1\)
		\item       \label{ITEMooEJSQooTqkBbo}
		      \( \sum_{k=0}^{\infty}A^k\) converge.
	\end{enumerate}
	Dans le cas où ces conditions sont vérifiées, nous avons aussi
	\begin{itemize}
		\item \( \mtu-A\) est inversible,
		\item
		      \(\sum_{k=0}^{\infty}A^k=(\mtu - A)^{-1}\)
	\end{itemize}
\end{theorem}

\begin{proof}
	Nous supposons qu'une norme est donnée sur \( \eK^n\) et nous considérons sur \( \eM(n,\eK)\) la topologie associée à la norme subordonnée\footnote{Si on parle de convergence d'une suite, c'est qu'il y a une topologie quelque part.}. Nous subdivisons la preuves en différentes implications.
	\begin{subproof}
		\spitem[\ref{ITEMooCGLSooZsMXSt} implique~\ref{ITEMooYBGEooXAzVbD}]
		Si \( \rho(A)\geq 1\), en combinant la proposition~\ref{PROPooWZJBooTPLSZp} avec la proposition~\ref{PROPooYPLGooWKLbPA}, nous avons
		\begin{equation}
			\| A^m \|\geq \big( \rho(A) \big)^m\geq 1
		\end{equation}

		Mais la limite \( A^k\stackrel{\eM(n,\eK)}{\longrightarrow} 0\) signifie la limite \( \| A^k \|\stackrel{\eR}{\longrightarrow}0\). Le fait que tous les éléments de la suite soient plus grand que \( 1\) empêche cette limite.
		\spitem[\ref{ITEMooYBGEooXAzVbD} implique~\ref{ITEMooCGLSooZsMXSt}]

		Vu que \( \rho(A)<1\), il existe \( \epsilon>0\) tel que \( \rho(A)+\epsilon<1\). Par le lemme~\ref{LEMooGBLJooCPvxNl} il existe une norme \( N\) sur \( \eM(n,\eK)\) telle que \( N(A)\leq \rho(A)+\epsilon<1\). Notons que cette norme \( N\) dépend de \( A\) et de \( \epsilon\).

		Avec cette norme nous avons
		\begin{equation}
			N(A^k)\leq N(A)^k\stackrel{\eR}{\longrightarrow}0.
		\end{equation}
		Cela signifie que \( A^k\stackrel{N}{\longrightarrow}0\). L'équivalence entre toutes les normes sur \( \eM(n,\eK)\) donne alors la convergence \( A^k\stackrel{\| . \|}{\longrightarrow}0\).

		Pour une preuve alternative de cette implication, voir la proposition~\ref{PROPooDJFLooBqqEPT}.

		\spitem[\ref{ITEMooEJSQooTqkBbo} implique~\ref{ITEMooCGLSooZsMXSt}]

		La convergence d'une série implique que la norme du terme général converge vers zéro par la proposition~\ref{PROPooYDFUooTGnYQg}. Nous avons donc \( \| A^k \|\to 0\), ce qui signifie \( A^k\to 0\), et donc \( \rho(A)<1\) parce que~\ref{ITEMooCGLSooZsMXSt} implique~\ref{ITEMooYBGEooXAzVbD}.

		\spitem[\( \rho(A)<1\) implique \( \mtu-A\) est inversible]

		Si \( \mu\) est une valeur propre de \( \mtu-A\) alors
		\begin{equation}
			\det\big( (\mtu-A)-\mu\mtu \big)=\det\big( A-(1-\mu)\mtu \big),
		\end{equation}
		donc \( 1-\mu\) est une valeur propre de \( A\). Donc les valeurs propres de \( \mtu-A\) sont les nombres \( 1-\lambda_i\) où les \( \lambda\i\) sont les valeurs propres de \( A\). Par hypothèse, nous avons \( \lambda_i<1\) pour tout \( i\), donc les valeurs propres de \( \mtu-A\) sont toutes non nulles. Donc \( \mtu-A\) est inversible (pas de noyau).

		\spitem[Le reste]
		Nous montrons à présent que si \( \rho(A)<1\) alors \( \sum_{k=0}^{\infty}A^k\) converge vers \(\mtu-A\). Pour cela nous savons déjà que \( \mtu-A\) est inversible. Nous posons
		\begin{equation}
			B_m=\mtu+A+\ldots +A^m,
		\end{equation}
		ce qui donne immédiatement \( AB_m=A+A^2+\ldots +A^{m+1}\). Nous avons donc
		\begin{equation}
			(\mtu-A)B_m=\mtu-A^{m+1}.
		\end{equation}
		Nous savons que \( \lim_{m\to0}A^m=0\), donc
		\begin{equation}
			(\mtu-A)\sum_{k=0}^{\infty}A^k=\lim_{k\to \infty} (\mtu-A)B_k=\lim_{k\to \infty} (\mtu-A^{k+1})=\mtu.
		\end{equation}
		Notez au passage que nous avons permuté la somme avec le produit matriciel (voir~\ref{SUBSECooOAWAooFcyUfI}).
	\end{subproof}
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Exponentielle et logarithme de matrice}
%---------------------------------------------------------------------------------------------------------------------------
\label{subsecXNcaQfZ}

La définition de l'exponentielle dans le cas des matrices est celle sur les algèbres normées non commutatives,~\ref{THOooFGTQooZPiVLO}.
\begin{proposition} \label{PropXFfOiOb}
	L'application
	\begin{equation}
		\begin{aligned}
			\exp\colon \eM(n,\eR) & \to \eM(n,\eR)                                \\
			A                     & \mapsto \sum_{k=0}^{\infty}\frac{ A^k }{ k! }
		\end{aligned}
	\end{equation}
	est une application de classe \(  C^{\infty}\). Sa différentielle en zéro est l'identité : \( (d\exp)_0=\id\).
\end{proposition}
\index{exponentielle!de matrice}

\begin{proof}
	En ce qui concerne la continuité, nous savons que le rayon de convergence de la suite \( \frac{1}{ k! }\) est infini; la proposition~\ref{PropQIIURAh} conclut.

	Pour la différentielle, c'est la proposition~\ref{PropAMBXKgV} qui nous permet d'écrire
	\begin{equation}
		d\exp_0(U)=\Dsdd{ \exp(tU) }{t}{0}=\Dsdd{ \sum_{k=0}^{\infty}\frac{ t^kU^k }{ k! } }{t}{0}=\left. \sum_{k=0}^{\infty}\frac{ kt^{k-1}U^k }{ k! }\right|_{t=0}=U
	\end{equation}
	parce que seul le terme \( k=1\) n'est pas nul.
\end{proof}

Nous avons vu par la proposition~\ref{PropKKdmnkD} que toute matrice complexe inversible a un logarithme. Nous allons maintenant parler de logarithme de matrices réelles avec une condition sur la norme. La formule ci-dessous montre explicitement que le logarithme est réel.
\begin{equation}
	\begin{aligned}
		\ln\colon \{ A\in \eM(n,\eR)\tq \| A-\mtu \| <1 \} & \to \eM(n,\eR)                                                   \\
		A                                                  & \mapsto \sum_{k=0}^{\infty}(-1)^k\frac{ (A-\mtu)^{k+1} }{ k+1 }.
	\end{aligned}
\end{equation}

\begin{lemma}   \label{LemQZIQxaB}
	Si \( \| m \|<1\) dans \( \eM(n,\eR)\), alors nous posons
	\begin{equation}    \label{EqIKgMabb}
		\ln(\mtu+m)=\sum_{k=0}^{\infty}(-1)^k\frac{ m^{k+1} }{ k+1 }.
	\end{equation}
	Cette fonction a les propriétés suivantes.
	\begin{enumerate}
		\item
		      Elle est de classe \(  C^{\infty}\).
		\item
		      Elle est un bon logarithme au sens où
		      \begin{equation}
			      e^{\ln(\mtu+m)}=\mtu+m.
		      \end{equation}
		\item
		      Elle vérifie l'approximation
		      \begin{equation}
			      \ln(1+m)=m+\sigma(m)
		      \end{equation}
		      où \( \sigma\) a la propriété que
		      \begin{equation}
			      \lim_{k\to \infty} k\sigma\left( \frac{ m }{ k } \right)=0.
		      \end{equation}
	\end{enumerate}
\end{lemma}
\index{logarithme!de matrice}
%TODO : le reste de la preuve, en particulier le point avec l'exponentielle.

\begin{proof}

	Le rayon de convergence de la suite \( a_k=\frac{ (-1)^k }{ k+1 }\) est \( 1\). Donc l'application donnée est \(  C^{\infty}\) sur \( B(0,1)\) par le théorème~\ref{PropQIIURAh}.

	D'après la formule \eqref{EqIKgMabb} nous avons
	\begin{equation}
		\sigma(m)=\sum_{l=1}^{\infty}(-1)^l\frac{ m^{l+1} }{ l+1 }.
	\end{equation}
	Nous avons alors
	\begin{equation}
		k\sigma(\frac{ m }{ k })=\sum_{l=1}^{\infty}(-1)^l\frac{ m^{l+1} }{ k^l(l+1) },
	\end{equation}
	et donc
	\begin{equation}
		\| k\sigma(\frac{ m }{ k }) \|\leq \sum_{l=1}^{\infty}\frac{ \| m \|^{l+1} }{ k^l(l+1) }\leq\frac{1}{ k }\sum_{l=1}^{\infty}\frac{ \| m \|^{l+1} }{ l+1 }\stackrel{k\to\infty}{\to} 0
	\end{equation}
	Cela prouve la dernière assertion.
\end{proof}

\begin{proposition}
	Soit \( V\) un espace vectoriel de dimension finie et \( A\in\End(V)\). Nous considérons la fonction
	\begin{equation}
		\begin{aligned}
			f\colon \eR & \to \End(V)      \\
			t           & \mapsto  e^{tA}.
		\end{aligned}
	\end{equation}
	Cette fonction vérifie
	\begin{equation}
		f'(t)=\big(  e^{tA} \big)'=A e^{tA}.
	\end{equation}
\end{proposition}

\begin{proof}
	Si nous posons \( f_k(t)=\frac{ t^kA^k }{ k! }\) alors la fonction \( f\) est la somme : \( f=\sum_{k=0}^{\infty}f_k\). Nous allons permuter la somme et la dérivation à l'aide du théorème~\ref{ThoLDpRmXQ}. Vu que
	\begin{equation}
		f'_k(t)=\frac{ kt^{k-1}A^k }{ k! },
	\end{equation}
	la suite des dérivées converge normalement sur \( \eR\), nous pouvons dériver terme à terme pour obtenir
	\begin{equation}
		\Big( \sum_{k=0}^{\infty}t^k\frac{ A^k }{ k! } \Big)'=\sum_{k=0}^{\infty}kt^{k-1}\frac{ A^k }{ k! }=\sum_{k=1}^{\infty}kt^{k-1}\frac{ A^k }{ k! }=A\sum_{k=1}^{\infty}\frac{ A^{k-1}t^{k-1} }{ (k-1)! }=A e^{tA}.
	\end{equation}
	Notez le jeu au niveau du point départ de la somme : elle passe de \( 0\) à \( 1\) parce que le terme zéro est nul, mais la simplification \( \frac{ k }{ k! }=\frac{ 1 }{ (k-1)! }\) n'a pas de sens pour \( k=0\).
\end{proof}

\begin{lemma}[\cite{DOAooAgGKTi}]   \label{LemQEARooLRXEef}
	Soit \( A\in\End(V)\) où \( V\) est un espace vectoriel réel de dimension finie. Si nous notons \( \lambda_i\) (\( i=1,\ldots, r\)) les valeurs propres distinctes de \( A\) alors il existe un polynôme \( P\in \eR[X]\) tel que
	\begin{equation}
		\|  e^{tA} \|\leq P\big( | t | \big)\sum_{i=1}^r e^{t\real(\lambda_i)}.
	\end{equation}
\end{lemma}

\begin{proof}
	Le polynôme caractéristique de \( A\) se note, d'après le corolaire~\ref{CorUNZooAZULXT} de la façon suivante :
	\begin{equation}
		\chi_A(X)=\prod_{i=1}^r(X-\lambda_i)^{m_i}
	\end{equation}
	où \( m_i\) est la multiplicité de la valeur propre \( \lambda_i\). Le lemme des noyaux~\ref{ThoDecompNoyayzzMWod} nous dit qu'en posant
	\begin{equation}
		V_i=\ker(A-\lambda_i\mtu)^{m_i}
	\end{equation}
	nous avons \( V=\bigoplus_{i=1}^rV_i\). Nous nommons \( p_i\colon V\to V\) la projection canonique de \( E\) sur \( V_i\) ainsi que \( x_i\) la composante de \( x\in V\) dans l'espace caractéristique \( V_i\) et nous posons \( A_i=p_i\circ A\). Les espaces caractéristiques sont stables par \( A\) (lemme~\ref{LemBLPooHMAoyJ}), donc \( (Ax_i)_i=Ax_i\). Par conséquent \( \sum_i A_ip_i=A\) parce que
	\begin{equation}
		\big( \sum_ip_iAp_i \big)(x)=\sum_i(Ax_i)_i=\sum_iAx_i=A\sum_ix_i=Ax.
	\end{equation}
	En ce qui concerne les puissances de \( A\) nous avons de même
	\begin{equation}
		A_i^nx_i=A_i\underbrace{A_i^{n-1}x_i}_{\in V_i}=AA_i^{n-1}x_i=A^nx_i,
	\end{equation}
	et donc
	\begin{equation}
		\sum_{i=1}^rA_i^np_i=A^n.
	\end{equation}
	En particulier,
	\begin{equation}    \label{EqPVIooGxwFBH}
		e^{tA}=\sum_i e^{tA_i}p_i.
	\end{equation}
	C'est de cette exponentielle de matrice que nous devons étudier la norme.

	La décomposition de Dunford du théorème~\ref{ThoRURcpW} est toujours un bon plan pour traiter avec les exponentielles : nous avons \( A=s+n\) avec
	\begin{equation}
		\begin{aligned}[]
			s & =\sum_k\lambda_kp_k, & n=\sum_k(A-\lambda_k\mtu)p_k.
		\end{aligned}
	\end{equation}
	Nous montrons que la décomposition de Dunford de \( p_iA\) est \( p_iA=p_is+p_in\). Nous avons
	\begin{equation}
		p_is=\sum_k\lambda_kp_ip_k=\lambda_ip_i
	\end{equation}
	qui est bien diagonalisable. De plus les espaces caractéristiques sont stables par \( n\), donc \( p_in\) est nilpotent. Enfin ils commutent :
	\begin{equation}    \label{EqNJIooDxKlxn}
		[p_is,p_in]=\lambda_i(p_in-p_inp_i).
	\end{equation}
	Vu que \( n\) préserve les espaces caractéristiques, lorsque \( v\in V_k\) avec \( k\neq i\) nous avons \( p_inp_iv=0\) et \( p_inv=0\). Mais si \( v\in V_i\) alors
	\begin{equation}
		p_inp_iv=p_inv=nv
	\end{equation}
	et \( p_inv=nv\), donc les opérateurs \( p_in\) et \( p_inp_i\) sont égaux et \eqref{EqNJIooDxKlxn} donne bien zéro. En ce qui concerne l'exponentielle de \( A_i\) nous avons
	\begin{equation}
		e^{p_iA}= e^{p_is} e^{p_in}= e^{\lambda_ip_i} \exp\big( (A-\lambda_i\mtu)p_i\big).
	\end{equation}

	Nous pouvons maintenant sérieusement nous attaquer à la norme de \(  e^{tA}\) de l'équation \eqref{EqPVIooGxwFBH}. D'abord nous avons \( \| p_i \|=1\) parce que l'opérateur \( p_i\) est l'identité sur au moins un vecteur (en fait tout ceux de l'espace caractéristique \( V_i\)). En utilisant les propriétés de la norme opérateur\footnote{Surtout le fait que ce soit une norme d'algèbre, lemme~\ref{LEMooFITMooBBBWGI}.}, nous trouvons dans un premier temps\footnote{Si les valeurs propres de \( A\) sont \( \lambda_i\), celles de \( tA\) sont \( t\lambda_i\).} :
	\begin{equation}
		\|  e^{tA} \|\leq \sum_{i=1}^r\|  e^{tA_i} \|\leq \sum_{i=1}^r|  e^{t\lambda_i} |\underbrace{\sum_{k=0}^{m_i}\frac{ | t |^k }{ k! }\| A-\lambda_i\mtu_i \|^k}_{=P_i( | t | }
	\end{equation}
	où \( \mtu_i\) est l'opérateur identité sur \( V_i\). Petit détail dans le calcul :
	\begin{equation}
		\|  e^{\lambda_ip_i} \|\leq \sum_{l=0}^{\infty}\frac{ \lambda_i^l }{ k! }\| p_i \|^l= e^{\lambda_i}.
	\end{equation}
	Notons que tous les termes de \( P_i(| t |)\) et \( P_i\big( | t | \big)\) sont positifs, de telle sorte que nous pouvons majorer en ajoutant des termes partout. À la place d'avoir \( P_i(| t |)\) comme coefficient de \( |  e^{t\lambda_i} |\) nous majorons en mettant \( \sum_{j=1}^rP_j(| t |)\) comme coefficient :
	\begin{equation}
		\|  e^{tA} \|\leq    \sum_{i=1}^r|  e^{t\lambda_i} |P_i\big( | t | \big)
		=\sum_{i=1}^r|  e^{t\lambda_i} |\sum_{j=1}^rP_j\big( | t | \big)=P\big( | t | \big)\sum_{i=1}^r e^{t\real(\lambda_i)}.
	\end{equation}
	L'arrivée de la partie réelle est une égalité usuelle pour les nombres complexes : \( |  e^{a+bi} |= e^{a}|  e^{bi} |= e^{a}\).
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Calcul effectif de l'exponentielle d'une matrice}
%---------------------------------------------------------------------------------------------------------------------------
\label{SUBSECooGAHVooBRUFub}

Nous reprenons l'exemple de \cite{MneimneReduct}. Soit \( A\) une matrice dont le polynôme minimum s'écrit
\begin{equation}
	P(X)=(X-1)^2(X-2).
\end{equation}
Par le théorème~\ref{ThoDecompNoyayzzMWod} de décomposition des noyaux nous avons
\index{théorème!décomposition des noyaux!et exponentielle de matrice}
\begin{equation}
	E=\ker(A-1)^2\oplus\ker(A-2).
\end{equation}
En suivant les notations de ce théorème nous avons \( P_1(X)=(X-1)^2\), \( P_2(X)=X-2\) et
\begin{subequations}
	\begin{align}
		Q_1(X) & =X-2      \\
		Q_2(X) & =(X-1)^2.
	\end{align}
\end{subequations}
En posant
\begin{equation}
	\begin{aligned}[]
		R_1(X) & =-X \\
		R_2(X) & =1,
	\end{aligned}
\end{equation}
nous avons une solution de Bezout :
\begin{equation}
	R_1Q_1+R_2Q_2=1.
\end{equation}
Conformément au théorème \ref{ThoDecompNoyayzzMWod}\ref{ITEMooMOBPooPVXuXj}, le projecteur \( p_i\) sur \( \ker\big( P_i(A) \big)\) est
\(  (R_iQ_i)(A)\) :
\begin{equation}
	\begin{aligned}[]
		p_1 & =\pr_{\ker(A-1)^2}=-A(A-2) \\
		p_2 & =\pr_{\ker(A-2)}=(A-1)^2
	\end{aligned}
\end{equation}
Passons maintenant au calcul de l'exponentielle\footnote{Définition~\ref{THOooFGTQooZPiVLO}. Thème~\ref{THEMEooKXSGooCsQNoY}}. Nous avons évidemment
\begin{equation}    \label{EQooVIOWooACVAoZ}
	e^A=e^Ap_1+e^Ap_2.
\end{equation}
Afin de nous adapter au projecteurs que nous avons en main, nous écrivons \( A=\mtu+(A-\mtu)\) et nous utilisons la proposition \ref{PROPooFLHPooRhLiZE}\ref{ITEMooROPJooMarenu} :
\begin{equation}
	e^{A}= e^{\mtu+(A-\mtu)}= e^{\mtu} e^{A-\mtu}=e e^{A-1}.
\end{equation}
Pour tout \( x\), nous avons \( (A-\mtu)^kp_1(x)=0\) dès que \( k\geq 2\). Donc nous avons
\begin{equation}
	e^{A}p_1(x)=e e^{A-1}p_1(x)=e\sum_k\frac{ (A-\mtu)^k }{ k! }p_1(x)=ep_1(x)+e(A-\mtu)p_1(x)=eAp_1(x).
\end{equation}
En ce qui concerne \( p_2\) nous faisons de même en partant de \(  e^{A}=  e^{2\mtu} e^{A-2\mtu}\) :
\begin{equation}
	e^{A}p_2(x)= e^{2}\sum_{k=0}^{\infty}\frac{ (A-\mtu)^k }{ k! }p_2(x)=e^2p_2(x).
\end{equation}

En recollant les morceaux avec \eqref{EQooVIOWooACVAoZ},
\begin{equation}
	e^{A}(x)=eAp_1(x)+e^2p_2(x)=-eA^2(A-2)x+e^2(A-1)^2x.
\end{equation}
Au final nous avons prouvé que
\begin{equation}
	e^{A}=-eA^2(A-2)+e^2(A-1)^2.
\end{equation}



\begin{proposition}[\cite{MonCerveau}]	\label{PROPooFXPZooKUEarD}
	Soit un espace de Banach réel \( E\). Nous considérons l'espace vectoriel \( \End(E)\) muni de la norme opérateur.
	\begin{enumerate}
		\item
		      La partie \( \GL(E)\) des opérateurs inversibles est ouverte.
		\item
		      L'opérateur d'inversion
		      \begin{equation}
			      \begin{aligned}
				      i\colon \GL(E) & \to \GL(E)     \\
				      f              & \mapsto f^{-1}
			      \end{aligned}
		      \end{equation}
		      est analytique.
	\end{enumerate}
\end{proposition}

\begin{proof}
	La partie \( \GL(E)\) est formée des opérateurs inversibles qui sont continus et dont l'inverse est continu. Or un opérateur est continu si et seulement si il est borné (proposition \ref{PROPooQZYVooYJVlBd}).

	Donc \( \GL(E)\) est une intersection de deux ouverts de \( \End(E)\) : les opérateurs linéaires continus et les opérateurs linéaires inversibles. Donc \( \GL(E)\) est ouvert.

	Vu que \( \GL(E)\) est ouvert et contenu dans \( \Omega\), une application analytique sur \( \Omega\) est analytique sur \( \GL(E)\).
\end{proof}


%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Lemme de Borel}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Fonctions plateaux, Urysohn, partition de l'unité}
%---------------------------------------------------------------------------------------------------------------------------
\label{subsecOSYAooXXCVjv}

Une fonction plateau sur \( \eR\) est donnée dans le lemme d'Urysohn \ref{LEMooECTNooKagaRU}. Sur \( \eR^n\), il y a le lemme d'Urysohn \ref{PROPooBOZIooAhKbPs}.


Vous voulez une fonction de classe \( C^{\infty}\) nulle sur un ouvert, mais qui n'est pas nulle partout ? En voici une.
\begin{lemma}       \label{LEMooFLUSooKaZRRY}
	La fonction
	\begin{equation}
		\varphi(x)=\begin{cases}
			e^{-1/x} & \text{si } x>0 \\
			0        & \text{sinon}.
		\end{cases}
	\end{equation}
	est de classe \(  C^{\infty}\).
\end{lemma}

\begin{proof}
	Pour tout polynôme \( P\) nous avons la limite\footnote{Voir la proposition \ref{PROPooKVIFooGdKpfP}\ref{ITEMooBLNOooZQNTfd}.}
	\begin{equation}
		\lim_{x\to 0^+} \frac{ e^{-1/x} }{ P(x)} =0 .
	\end{equation}
	De là, en écrivant les dérivées successives de \( \varphi\), il est facile de voir qu'elles sont continues en \( x=0\).
\end{proof}


Une variation sur le même thème est l'existence de fonctions infiniment dérivables à support compact, c'est-à-dire des fonctions dans \(  C^{\infty}_c(\eR^d)=\swD(\eR^d)\).

\begin{lemma}[\cite{MonCerveau}]        \label{LEMooLHIFooWpbauN}
	Pour tout \( n\in \eN\) nous avons
	\begin{equation}
		\lim_{x\to 1^-} \frac{   e^{-1/(1-x^2)}  }{ (1-x^2)^n }=0.
	\end{equation}
\end{lemma}

\begin{proof}
	D'abord le lemme \ref{LEMooNYFVooXjFShk} nous indique que
	\begin{equation}
		\lim_{x\to \infty} x^n e^{-x}=0.
	\end{equation}
	Nous prouvons ensuite que
	\begin{equation}
		\lim_{x\to 0^+} \frac{  e^{-1/x} }{ x^n }=0.
	\end{equation}
	Pour cela nous considérons \( \epsilon>0\). Soit \( M>0\) tel que \( x^n e^{-x}<\epsilon\) pour tout \( x>M\). Nous considérons \( \delta\) tel que  \( 0<x<\delta\) implique \( 1/x>M\).

	Pour de tels \( x\), nous avons \(  e^{-1/x}/x^n<\epsilon\).

	Nous montrons enfin que
	\begin{equation}
		\lim_{x\to 1^+} \frac{ e^{-1/(1-x^2)} }{ (1-x^2) }=0.
	\end{equation}
	Pour cela, soit \( \epsilon>0\). Soit \( \delta\) tel que \( 0<x<\delta\) implique \(  e^{-1/x}/x^n<\epsilon\). Soit \( \delta'\) tel que \( 1<x<1+\delta'\) implique \( 1-x^2<\delta\). Avec ça, nous avons
	\begin{equation}
		1<x<1+\delta'\Rightarrow \frac{  e^{-1/(1-x^2)} }{ (1-x^2)^n }<\epsilon.
	\end{equation}
\end{proof}

\begin{proposition}     \label{PROPooAHLKooMFMgFq}
	La fonction \( \xi\colon \eR^d\to \eR\) donnée par
	\begin{equation}    \label{EqOBYNEMu}
		\xi(x)=\begin{cases}
			e^{-1/(1-\| x \|^2)} & \text{si } x\in B(0,1) \\
			0                    & \text{sinon}.
		\end{cases}
	\end{equation}
	est de classe \( C^{\infty}\) et à support compact.
\end{proposition}

\begin{proof}
	Le fait que le support soit compact est le fait qu'un support est toujours fermé (c'est dans la définition) et que le support de \( \xi\) est borné, contenu dans \( B(0,1)\). Le vrai travail est de montrer que cette fonction est de classe \(  C^{\infty}\).

	Nous commençons par voir en dimension \( 1\). C'est-à-dire la fonction
	\begin{equation}
		\begin{aligned}
			f\colon \eR & \to \eR                                     \\
			x           & \mapsto \begin{cases}
				                      e^{-1/(1-x^2)} & \text{si } | x |<1 \\
				                      0              & \text{sinon }
			                      \end{cases}
		\end{aligned}
	\end{equation}
	Le lemme \ref{LEMooLHIFooWpbauN} dit que \( f\) est continue. En ce qui concerne les dérivées de \( f\), vous pouvez montrer par récurrence que
	\begin{equation}
		f^{(n)}(x)=\begin{cases}
			\frac{ P_n(x) }{ (x^2-1) }f(x) & \text{si } | x |<1 \\
			0                              & \text{sinon }
		\end{cases}
	\end{equation}
	où \( P_n\) est un polynôme. Le lemme \ref{LEMooLHIFooWpbauN} (encore lui) nous indique que \( f^{(n)}\) est continue.

	Pour que \( \xi\) soit de classe \(  C^{\infty}\), il suffit maintenant d'invoquer la proposition \ref{PROPooQUAZooGXskwF} qui dit que la norme est une application de classe \(  C^{\infty}\).
\end{proof}

\begin{corollary}       \label{CORooHHZXooXmwGmC}
	Il existe une fonction \( \xi\in\swD\big( B(0,R) \big)\) telle que \( \int_{\eR}\xi(x)dx=1\).
\end{corollary}

\begin{proof}
	Prenez la fonction de la proposition \ref{PROPooAHLKooMFMgFq}. Si \( R<1\), faites une redéfinition \( \xi_2=\xi(\lambda x)\) pour que le support soit dans \( B(0,R)\). Ensuite, si l'intégrale n'est pas \( 1\), encore une redéfinition \( \xi_3=\mu\xi_2\).
\end{proof}


\begin{lemma}[\cite{BIBooRTZNooZBNRXG}]       \label{LEMooRVSIooKcpWoK}
	Soit \( m>0\). Il existe une application \( \psi_m\in  C^{\infty}(\eR)\) vérifiant
	\begin{equation}
		\psi_m(x)=\begin{cases}
			1               & \text{si } x<0                               \\
			0               & \text{si } x>m                               \\
			\text{positive} & \text{si } x\in\mathopen[ 0 , m \mathclose].
		\end{cases}
	\end{equation}
\end{lemma}

\begin{proof}
	La proposition \ref{PROPooAHLKooMFMgFq} dit que l'application
	\begin{equation}
		\begin{aligned}
			\xi\colon \eR & \to \eR                                     \\
			x             & \mapsto \begin{cases}
				                        e^{-1/(1-x^2)} & \text{si } | x |<1 \\
				                        0              & \text{sinon }
			                        \end{cases}
		\end{aligned}
	\end{equation}
	est de classe \( C^{\infty}\) à support compact. Nous posons \( M=\int_{\eR}\xi\) et
	\begin{equation}
		\begin{aligned}
			f\colon \eR & \to \eR                                       \\
			x           & \mapsto \frac{1}{ M}\int_{-\infty}^x\xi(t)dt.
		\end{aligned}
	\end{equation}
	Notez que l'intégrale n'est en réalité qu'entre \( -1\) et \( x\) parce que \( \xi\) est nulle en-dehors de \( | x |<1\). Nous avons donc \( f(x)=0\) pour tout \( x<-1\). Vu que \( \int_{1}^a\xi\) est nulle pour tout \( a>1\), nous avons aussi \( f(x)=f(1)=1\) pour tout \( x>1\).

	L'application \( f\) est non nulle entre \( -1\) et \( 1\), vaut \( 0\) à gauche et \( 1\) à droite. Il reste à adapter pour construire \( \psi_m\). On pose
	\begin{equation}
		\psi_m(x)=1-(f\circ\mu)(x)
	\end{equation}
	où \( \mu(x)=ax+b\). Les paramètres \( a\) et \( b\) sont fixés pour avoir \( \mu(0)=-1\) et \( \mu(m)=1\). Ce n'est pas très compliqué à résoudre, et le résultat est que l'application recherchée est
	\begin{equation}
		\psi_m(x)=1-f\big( \frac{ 2 }{ m }x-1 \big).
	\end{equation}
\end{proof}



\begin{lemma}[\cite{BIBooPITOooZANjFn}]     \label{LEMooFFPVooDKGUAp}
	Soient \( a<b\) dans \( \eR\). Il existe une fonction \( f\in  C^{\infty}(\eR)\) telle que
	\begin{enumerate}
		\item
		      \( 0\leq f\leq 1\),
		\item
		      \( f=0\) sur \( \mathopen] -\infty , a \mathclose]\),
		\item
		      \( f=1\) sur \( \mathopen[ b , \infty \mathclose[\).
	\end{enumerate}
\end{lemma}

\begin{proof}
	C'est une variation sur le thème de la fonction du lemme \ref{LEMooRVSIooKcpWoK}; il s'agit de la retourner, dilater et décaler. Posez successivement \( f_1(x)=\psi_m(-x)\), \( f_2(x)=f_1\big(mx/(b-a)\big)\) et \( f_3(x)=f_2(x-a)\) et je crois que le compte est bon. La fonction \( f_3\) est celle que nous cherchons.
\end{proof}

\begin{proposition}     \label{PROPooAZJZooTYWjzb}
	Soient \( a<b<c<d\) dans \( \eR\). Il existe une fonction \( f\in C^{\infty}(\eR)\) à valeurs positives telle que
	\begin{enumerate}
		\item
		      \( f(x)=1\) si \( x\in\mathopen[ b , c \mathclose]\)
		\item
		      \( \supp(f)\subset\mathopen[ a , d \mathclose]\).
	\end{enumerate}
\end{proposition}

\begin{proof}
	Nous considérons la fonction \( \psi_m\) du lemme \ref{LEMooRVSIooKcpWoK}, et nous considérons les fonctions
	\begin{subequations}
		\begin{align}
			f_1(x) & =\psi_{d-c}(x-c)=\begin{cases}
				                          1               & \text{si } x<c                               \\
				                          0               & \text{si } x>d                               \\
				                          \text{positive} & \text{si } x\in\mathopen[ c , d \mathclose].
			                          \end{cases} \\
			f_2(x) & =\psi(b-a)(b-x)=\begin{cases}
				                         0               & \text{si } x<a                                \\
				                         1               & \text{si } x>b                                \\
				                         \text{positive} & \text{si } x\in \mathopen[ a , b \mathclose].
			                         \end{cases},
		\end{align}
	\end{subequations}
	et finalement la fonction suivante répond à la question des fonctions plateaux sur \( \eR\) :
	\begin{equation}    \label{EqIHAFooXjfcll}
		f(x)=f_1(x)f_2(x).
	\end{equation}
	\index{fonction!définie par une intégrale}
\end{proof}




Il ne faudrait pas croire pour autant que tout est toujours rose au pays des fonctions \(  C^{\infty}\) à support compact.

\begin{proposition}
	Si \( \phi\) est une fonction \(  C^{\infty}\) non nulle à support compact sur \( \eR\), alors \( \phi'/\phi\) n'est pas bornée.

	Plus présisément, nous posons \( D=\{ x\in \eR\tq \phi(x)\neq 0 \}\). Alors la fonction
	\begin{equation}
		\begin{aligned}
			f\colon D & \to \eR                  \\
			x         & \mapsto \phi'(x)/\phi(x)
		\end{aligned}
	\end{equation}
	n'est pas bornée.
\end{proposition}

\begin{proof}
	Quitte à décaller et à multiplier, nous supposons que \( \phi(0)=1\). Sinon vous considérez \( x_0\) tel que \( \phi(x_0)=y_0\neq 0\) et vous adaptez tout le reste de la démonstration à vos frais.

	Vu que \( \phi\) est continue, la partie \( Z=\{ x\geq 0\in \eR\tq \phi(x)=0 \}\) est fermée. Elle est également bornée vers le bas par \( 0\). Donc elle possède un minimum que nous nommons \( a\) :
	\begin{equation}
		a=\min\{ x\geq 0\tq \phi(x)=0 \}.
	\end{equation}
	Les valeurs de \( \phi\) qui vons nous intéresser sont :
	\begin{equation}
		\phi(x)=\begin{cases}
			>0 & \text{si } x\in\mathopen[ 0 , a \mathclose[ \\
			=0 & \text{si }x=a.
		\end{cases}
	\end{equation}
	Enfin, nous posons
	\begin{equation}
		M=\sup\{ \phi'(x)/\phi(x) \}_{x\in\mathopen[ 0 , a \mathclose[}.
	\end{equation}
	Nous supposons que \( M<\infty\)\footnote{Vous pouvez ne pas supposer cela et voir le reste de la preuve comme une démonstration que \( M=\infty\). Ici nous allons faire par l'absurde et montrer une contradiction en supposant que \( M<\infty\).}.

	Nous posons
	\begin{equation}
		\begin{aligned}
			F\colon \mathopen[ 0 , a \mathclose[ & \to \eR                                         \\
			x                                    & \mapsto \int_0^x\frac{ \phi'(t) }{ \phi(t) }dt.
		\end{aligned}
	\end{equation}
	Vu que \( \phi\) est de classe \(  C^{\infty}\) et que \( x\) est dans \( \mathopen[ 0 , a \mathclose[\) sur lequel \( \phi\) ne s'annule pas, cette intégrale n'a rien d'exceptionnel.

	Nous pouvons majorer \( F\) de la façon suivantes :
	\begin{equation}
		F(x)=\int_0^x\frac{ \phi'(t) }{ \phi(t) }dt\leq \int_0^xMdt=Mx< Ma.
	\end{equation}

	La proposition \ref{PropEZFRsMj} lie primitive et intégrale; celle de \( \phi'(x)/\phi(x)\) est \( \ln\big( \phi(x) \big)\) nous avons donc
	\begin{equation}        \label{EQooCEVKooLgXiaj}
		F(x)=\ln(\phi(x))-\ln(\phi(0))=\ln\big( \phi(x) \big).
	\end{equation}
	Mais vu que \( \lim_{x\to a} \phi(x)=0\), nous avons \( \lim_{x\to a} F(x)=\infty\), d'où la contradiction.
\end{proof}

Notez que l'expression \ref{EQooCEVKooLgXiaj} montre que \( \phi'(x)/\phi(x)\) tend vers \( -\infty\), ce qui est logique : la dérivée est négative alors que \( \phi\) reste positive. Ce que dit la proposition est qu'une fonction \(  C^{\infty}\) à support compact tend plus vite vers zéro que sa dérivée.

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Lemme de Urysohn}
%---------------------------------------------------------------------------------------------------------------------------

Le lemme d'Urysohn comprend de nombreuses variantes plus ou moins générales\footnote{Pour une version sur \( \eR^n\), voir la proposition \ref{PROPooBOZIooAhKbPs}.}. En voici une parmi les plus simples.
\begin{lemma}[Lemme d'Urysohn]      \label{LEMooECTNooKagaRU}
	Soient un ouvert \( \mU\) de \( \eR\) et un compact \( K\) inclus dans \( \mU\). Il existe une fonction \( f\colon \eR\to \mathopen[ 0 , 1 \mathclose]\) de classe  \(  C^{\infty}\) telle que
	\begin{enumerate}
		\item
		      \( f(x)=1\) pour \( x\in K\),
		\item
		      \( \supp(f)\subset \mU\).
	\end{enumerate}
\end{lemma}

\begin{proof}
	Vu que \( K\) est compact, il est borné (théorème \ref{ThoXTEooxFmdI}). Nous posons \( b=\min(K)\) et \( c=\max(K)\). En particulier \( b\) et \( c\) sont des éléments de \( K\) et donc de \( \mU\). Comme \( \mU\) est ouvert, il existe des boules centrées en \( b\) et \( c\) contenues dans \( \mU\). Soit \( r\) le rayon de telles boules :
	\begin{subequations}
		\begin{align}
			B(b,r)\subset \mU \\
			B(c,r)\subset \mU.
		\end{align}
	\end{subequations}
	Nous posons \( a=b-r\in \mU\) et \( d=c+r\in \mU\). Nous considérons à présent la fonction plateau \( f\) de la proposition \ref{PROPooAZJZooTYWjzb}. Elle est de classe \(  C^{\infty}\) et vérifie \( f(x)=1\) pour \( x\in \mathopen[ b , c \mathclose]=K\) ainsi que \( f(x)=0\) hors de \( \mathopen[ a , d \mathclose]\subset \mU\).
\end{proof}

\begin{normaltext}
	Notons que la fonction du lemme d'Urysohn \ref{LEMooECTNooKagaRU} n'épouse pas spécialement très bien la forme de \( K\). Si par exemple \( K=\mathopen[ 0 , 1 \mathclose]\cup \mathopen[ 10 , 11 \mathclose]\), la fonction \( f\) sera égale à \( 1\) au moins sur \( \mathopen[ 0 , 11 \mathclose]\).
\end{normaltext}


\begin{lemma}[\cite{MonCerveau}]		\label{LEMooGZXYooZqFzyc}
	Si une fonction \(f \colon \eR^n\to \eR  \) est intégrable, et si \( s\in \eR\) alors l'application
	\begin{equation}
		\begin{aligned}
			f_s\colon \eR^n & \to \eR                      \\
			x               & \mapsto \frac{1}{ s^n}f(x/s)
		\end{aligned}
	\end{equation}
	est intégrable et
	\begin{equation}
		\int_{\eR^n}f_s=\int_{\eR^n}f.
	\end{equation}
\end{lemma}

\begin{proof}
	Il s'agit d'appliquer le théorème \ref{THOooUMIWooZUtUSg}\ref{ITEMooEZUBooGBuDOS} au changement de variable \( \phi(x)=x/s\). Nous avons \( f_s=\frac{1}{ s^n}f\circ \phi\), et
	\begin{equation}
		(d\phi)_av=\frac{1}{ s}v,
	\end{equation}
	de telle sorte que le déterminant de \( d\phi\) soit une constante et vaille \( \det(d\phi)=1/s^n\). Enfin \( \phi\) est une bijection de \( \eR^n\). Nous avons tous les ingrédients pour faire le changement de variables :
	\begin{equation}
		\int_{\eR^n}f_s(x)dx=  \int_{\eR^n}(f\circ \phi)(x)\frac{1}{ s^n}dx=\int_{\phi(\eR^n)}f(xdx).
	\end{equation}
\end{proof}

Pour une fonction plateau sur \( \Omega\subset \eR^n\), voir le lemme d'Urysohn, proposition \ref{PROPooBOZIooAhKbPs}.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Le lemme de Borel}
%---------------------------------------------------------------------------------------------------------------------------

\begin{lemma}[Lemme de Borel\cite{KXjFWKA}] \label{LemRENlIEL}
	Soit \( (a_n)\) une suite dans \( \eR\). Il existe une fonction \( u\in C^{\infty}(\eR)\) telle que \( u^{(k)}(0)=a_k\) pour tout \( k\geq 0\).
\end{lemma}
\index{lemme!Borel}
\index{prolongement!de fonctions!lemme de Borel}
\index{dérivabilité!lemme de Borel}

\begin{proof}
	Soit \( \varphi\in C^{\infty}_c(\eR)\) une fonction telle que \( \varphi(x)=1\) si \( | x |\leq \frac{ 1 }{2}\) et telle que \( \supp(\varphi)\subset\mathopen] -1 , 1 \mathclose[\).

		Nous commençons par considérer une suite de réels strictement positifs \( (\lambda_k)\) dont nous fixerons une valeur précise plus tard, et nous posons
		\begin{equation}
			f_k(x)=\varphi(\lambda_k x)\frac{ a_k }{ k! }x^k.
		\end{equation}
		Nous allons étudier la convergence et les propriétés de \( u(x)=\sum_{k=0}^{\infty}f_k(x)\).

		Calculons (formellement) la \( m\)\ieme\ dérivée de \( f_k\) :
		\begin{subequations}
			\begin{align}
				f_k^{(m)}(x) & =\frac{ a_k }{ k! }\sum_{l=0}^{m}\binom{ m }{ l }\lambda_k^{m-l}\varphi^{(m-l)}(\lambda_kx)(x^k)^{(l)}  \\
				             & =a_k\sum_{l=0}^{m}\binom{ m }{ l }\lambda_k^{m-l}\varphi^{(m-l)}(\lambda_kx)\frac{ x^{k-l} }{ (k-l)! }.
			\end{align}
		\end{subequations}
		Notons que nous travaillons à \( m\) fixé et que nous ne nous intéressons qu'aux termes avec \( k\) assez grand; nous pouvons donc supposer \( k\geq m\). De toutes façons pour \( \sum_{k=0}^mf_k\), on a la classe \(  C^{\infty}\), et la permutation de la somme avec tout ce qu'on veut. Vu que \( \varphi\) est continue à support compact nous pouvons poser
		\begin{equation}
			M_m=\max_{0\leq j\leq m}\| \varphi^{j} \|_{\infty}=\max_{0\leq j\leq m}\max_{x\in \eR}| \varphi^{(j)}(x) |.
		\end{equation}
		Nous continuons en nous fixant un \( x\in \eR\) et un \( k\geq m\).

		Si \( | x |>\frac{1}{ \lambda_k }\), alors \( \varphi^{(m)}(\lambda_kx)=0\) parce que \( \lambda_kx\) est strictement hors du support de \( \varphi\) qui est \( \mathopen] -1 , 1 \mathclose[\). Donc pour \( | x |>\frac{1}{ \lambda_k }\).

	Si par contre \( | x |\leq\frac{1}{ \lambda_k }\), nous avons les majorations
	\begin{subequations}
		\begin{align}
			| f^{(m)}_k(x) | & \leq  |a_k|\sum_{l=0}^{m}\binom{ m }{ l }|\lambda_k|^{m-l}\underbrace{\varphi^{(m-l)}(\lambda_kx)}_{\leq M_m}\frac{ 1 }{ (k-l)! }\underbrace{| x |^{k-l}}_{\leq (1/\lambda_k)^{k-l}} \\
			                 & \leq | a_k |M_m| \lambda_k |^{m-k}\frac{1}{ (k-m)! }\sum_{l=0}^{m}\binom{ m }{ l }                                                                                                   \\
			                 & \leq \frac{ | a_k |M_m | \lambda_k |^{m-k}2^m }{ (k-m)! }                                                                                                                            \\
			                 & = \frac{ | a_k |M_m 2^m }{ (k-m)!  | \lambda_k |^{k-m} }       \label{EqQSPUaun}
		\end{align}
	\end{subequations}
	où pour faire disparaitre la somme de coefficients binomiaux, nous avons remarqué que \( \sum_{l=0}^m\binom{ m }{ l }\) est le nombre total de termes dans le développement de \( (a+b)^m\), c'est-à-dire \( 2^m\). Nous voulons, pour \( m\) fixé, étudier la convergence de la somme de cela. Notons que le \( 2^m\) n'a en particulier strictement aucune importance parce qu'on travaille à \( m\) fixé.

	Nous fixons maintenant la valeur des \( \lambda_k\) :
	\begin{equation}
		\lambda_k=\max\{ | a_k |,1 \}.
	\end{equation}
	Avec cela, en nous souvenant que nous n'étudions que les termes \( k>m\), le dénominateur de \eqref{EqQSPUaun} est réellement croissant en \( k\), donc nous avons la majoration
	\begin{equation}
		| f^{(m)}_k(x) |\leq \frac{ M_m2^m }{ (k-m)! }.
	\end{equation}
	Au final nous avons
	\begin{equation}
		\| f_k^{(m)} \|_{\infty}\leq \frac{ 2^mM_m }{ (k-m)! }.
	\end{equation}
	Et la somme de cela converge sans difficultés. Donc la série
	\begin{equation}
		u(x)=\sum_{k=0}^{\infty}f_k^{(m)}(x)
	\end{equation}
	converge normalement et donc uniformément sur \( \eR\). Nous pouvons alors permuter la somme et la dérivation par le théorème~\ref{ThoCSGaPY}. Donc
	\begin{equation}
		u^{(m)}=\sum_{k=0}^{\infty}f_k^{(m)}
	\end{equation}
	est continue. En particulier, pour évaluer en zéro, on peut faire
	\begin{equation}
		u^{(m)}(0)=\sum_{k=0}^{\infty}f_k^{(m)}(0).
	\end{equation}
	Nous avons
	\begin{equation}
		f_k(x)=\varphi(\lambda_kx)\frac{ a_k }{ k! }x^k.
	\end{equation}
	Pour calculer la dérivée en zéro, il suffit de la calculer sur un voisinage sur lequel \( \varphi(\lambda_kx)\) est la constante \( 1\); un tel voisinage existe pour tout \( k\). À ce moment le calcul est classique :
	\begin{equation}
		f_k^{(m)}(x)=\begin{cases}
			a_k & \text{si } k=m \\
			0   & \text{sinon}.
		\end{cases}
	\end{equation}
	Finalement nous avons bien
	\begin{equation}
		u^{(m)}(0)=\sum_{k=0}^{\infty}f_k^{(m)}(0)=a_k.
	\end{equation}

\end{proof}

\begin{remark}
	Pour prouver le lemme de Borel, la première chose qui passe par la tête est la fonction toute simple
	\begin{equation}
		u(x)=\sum_{k=0}^{\infty}\frac{ a_k }{ k! }x^k.
	\end{equation}
	Évidemment si on calcule les dérivées successives de cette fonction, nous trouvons les bons résultats. Le problème est la convergence.  Rien qu'en prenant \( a_k=k!k^k\), la série ne converge pour aucun \( x\) positif. L'idée de multiplier chacun de \( f_k\) par une fonction plateau sur un petit intervalle autour de zéro a plusieurs avantages. D'abord on conserve les dérivées correctes parce qu'on ne touche pas à la valeur des \( f_k\) sur un petit voisinage. Ensuite cela ne modifie pas la continuité; et enfin en multipliant par \( \varphi(\lambda_kx)\), ça calme méchamment les divergences parce que \( \lambda_kx\) passe vite au dessus de \( 1\) (et donc en dehors du support de \( \varphi\)) si \( \lambda_k\) est grand. D'où le fait qu'il soit normal que les \( \lambda_k\) soient de l'ordre des \( a_k\).
\end{remark}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Nombres de Bell}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{theorem}[Nombres de Bell\cite{KXjFWKA}]  \label{ThoYFAzwSg}
	Soient \( n\geq 1\) et \( B_n\) le nombre de partitions distinctes de l'ensemble \( \{ 1,\ldots, n \}\) avec la convention que \( B_0=0\). Alors
	\begin{enumerate}
		\item
		      La série entière
		      \begin{equation}    \label{EqYCMGBmP}
			      \sum_{n=0}^{\infty}\frac{ B_n }{ n! }x^n
		      \end{equation}
		      a un rayon de convergence \( R>0\) et sa somme est donnée par
		      \begin{equation}
			      f(x)= e^{ e^{x}-1}
		      \end{equation}
		      pour tout \( x\in\mathopen] -R , R \mathclose[\).
		\item
		      Pour tout \( k\in \eN\),
		      \begin{equation}
			      B_n=\frac{1}{ e }\sum_{k=0}^{\infty}\frac{ k^n }{ k! }.
		      \end{equation}
		\item
		      Le rayon de convergence de la série \eqref{EqYCMGBmP} est en réalité infini : \( R=\infty\).
	\end{enumerate}
\end{theorem}
\index{anneau!de séries formelles}
\index{dénombrement!partitions de \( \{ 1,\ldots, n \} \)}
\index{série!numérique}
\index{série!entière}
\index{limite!inversion}

\begin{proof}
	\begin{enumerate}
		\item
		      Soient \( n\geq 1\) et \( 0\leq k\leq n\). Nous notons \( E_k\) l'ensemble des partitions de \( \{ 1,\ldots, n+1 \}\) pour lesquelles le «paquet» contenant \( n+1\) soit de cardinal \( k+1\). Calculons le cardinal de \( E_k\).

		      Pour construire un élément de \( E_k\), il faut d'abord prendre le nombre \( n+1\) et lui adjoindre \( k\) éléments choisis dans \( \{ 1,\ldots, n \}\), ce qui donne \( n\choose k\) possibilités. Ensuite il faut trouver une partition des \( (n+1)-(k+1)=n-k\) éléments restants, ce qui fait \( B_{n-k}\) possibilités. Donc
		      \begin{equation}
			      \Card(E_k)={n\choose k}B_{n-k}.
		      \end{equation}
		      L'intérêt des ensembles \( E_k\) est que \( \{ E_0,\ldots, E_n \}\) est une partition de l'ensemble des partitions de \( \{ 1,\ldots, n+1 \}\), c'est-à-dire que \( B_{n+1}=\sum_{k=0}^n\Card(E_k)\), ce qui va nous donner une relation de récurrence pour les \( B_n\) :
		      \begin{equation}
			      B_{n+1}=\sum_{k=0}^n\Card(E_k)
			      =\sum_{k=0}^n{n\choose k}B_{n-k}
			      =\sum_{l=0}^n{n\choose n-l}B_l
			      =\sum_{l=0}^n{n\choose l}B_l.
		      \end{equation}
		      où nous avons utilisé un petit changement de variables \( l=n-k\). Afin d'étudier la convergence de la série \eqref{EqYCMGBmP}, nous allons montrer par récurrence que pour tout \( n\), \( B_n<n!\). D'abord pour \( n=0\) c'est bon : \( B_1=1\) parce que la seule partition de \( \{ 1 \}\) est \( \{ 1 \}\). Supposons que l'inégalité soit vraie pour une certaine valeur \( k\), et montrons qu'elle est vraie pour la valeur \( k+1\).
		      \begin{equation}
			      B_{k+1}=\sum_{l=0}^n{n\choose l}B_l
			      \leq \sum_{l=0}^n{n\choose l}l!
			      =\sum_{l=0}^n \frac{ n! }{ l!(n-l)! }l!=n!\sum_{l=0}^n\underbrace{\frac{ 1 }{ (n-l)! }}_{\leq 1}
			      \leq n!(n+1)
			      =(n+1)!
		      \end{equation}
		      où nous avons utilisé le coefficient binomial : \( {n\choose l}=\frac{ n! }{ l!(n-l)! }\).

		      Donc pour tout \( x\in \eR\) nous avons
		      \begin{equation}
			      0\leq \frac{ B_n }{ n! }| x^n |\leq | x |^n,
		      \end{equation}
		      et donc la série a un rayon de convergence au moins aussi grand que celui de la série géométrique, c'est-à-dire que \( 1\). Donc \( R\geq 1\). Nous nommons \( R\) ce rayon de convergence.

		\item

		      Soit \( x\in\mathopen] -R , R \mathclose[\). Pour une telle valeur de \( x\) à l'intérieur du disque de convergence, la proposition~\ref{ProptzOIuG} nous permet de dériver terme à terme la série\footnote{C'est ici qu'on utilise la convention \( B_0=0\) et ça aura une influence sur le choix de la constante \( K\) plus bas.}
			      \begin{equation}
				      f(x)=\sum_{k=0}^{\infty}\frac{ B_k }{ k! }x^k=1+\sum_{k=0}^{\infty}\frac{ B_{k+1} }{ (k+1)! }x^{k+1},
			      \end{equation}
			      pour obtenir
			      \begin{subequations}
				      \begin{align}
					      f'(x)=\sum_{k=0}^{\infty}\frac{ B_{k+1} }{ (k+1)! }(k+1)x^k & =\sum_{k=0}^{\infty}\frac{ B_{k+1} }{ k! }x^k                                                                                                               \\
					                                                                  & =\sum_{k=0}^{\infty}\left( \sum_{l=0}^k{k\choose l}B_l \right)\frac{ x^k }{ k! }=\sum_{k=0}^{\infty}\left( \sum_{l=0}^k\frac{ B_l }{ l!(l-k)! } \right)x^k.
				      \end{align}
			      \end{subequations}
			      En cette expression, nous reconnaissons un produit de Cauchy (proposition~\ref{ThokPTXYC}) avec \( a_l=\frac{ B_l }{ l! }\) et \( b_n=\frac{ 1 }{ n! }\). Vu que ce sont deux séries ayant un rayon de convergence plus grand que zéro, le produit a encore un rayon de convergence plus grand que zéro et nous pouvons prendre le produit des séries :
			      \begin{equation}
				      f'(x)=\left( \sum_{l=0}^{\infty}\frac{ B_l }{ l! }x^l \right)\left( \sum_{k=0}^{\infty}\frac{1}{ k! }x^k \right)=f(x) e^{x}.
			      \end{equation}
			      Étudions l'équation différentielle \( y'=ye^x\). D'abord par un argument en lacet de chaussure\footnote{Genre ce qui est fait pour prouver~\ref{ThoRWOZooYJOGgR}\ref{ItemYTLTooSnfhOu}.}, une solution est de classe \(  C^{\infty}\). Ensuite si une solution est non nulle, elle est de signe constant. En effet si \( y(x_0)<0\) et \( y(x_1)=0\) (on choisit \( x_1\) minimum pour cette propriété parmi les nombres plus grands que \( x_0\)) alors il existe\footnote{Théorème de Rolle~\ref{ThoRolle}.} un \( t\in\mathopen] x_0 , x_1 \mathclose[\) tel que \( y'(t)>0\), ce qui donnerait \( y(t)>0\), ce qui contredirait la minimalité de \( x_1\).

		      Nous prétendons\footnote{Ou alors on utilise le théorème~\ref{ThoNYEXqxO} avec \( M(x)=e^x\) dans les cas \( n=1\) et \( I=\mathopen] -R , R \mathclose[\).} que cette équation différentielle a un espace de solutions de dimension \( 1\). En effet, si \( y'=ye^x\) et \( g'=ge^x\) alors en posant \( \varphi=y/g\) nous obtenons tout de suite \( \varphi'=0\), ce qui signifie que \( \varphi\) est constante, ou encore que \( y\) et \( g\) sont multiples l'un de l'autre.

		      Si nous en trouvons une non nulle par n'importe quel moyen, c'est bon. Une solution étant dérivable est continue, donc l'équation \( f'=f e^{x}\) nous indique que \( f'\) est continue. Une solution non nulle va automatiquement accepter un petit voisinage sur lequel la manipulation suivante a un sens :
		      \begin{equation}
			      \frac{ f'(x) }{ f(x) }= e^{x},
		      \end{equation}
		      donc \( \ln\big( | f(x) | \big)= e^{x}+C\) et \( f(x)=K e^{ e^{x}}\) pour une certaine constante. Il est vite vérifié que cette fonction est une solution de l'équation différentielle \( y'(x)=y(x) e^{x}\) et par unicité, toutes les solutions sont de cette forme. Autrement dit, l'espace des solutions est l'espace vectoriel \( \Span\{ x\mapsto e^{e^x} \}\). Étant donné que \( f(0)=0\), nous devons choisir \( K=\frac{1}{ e }\) et donc
		      \begin{equation}
			      f(x)=\frac{1}{ e } e^{e^x}= e^{e^x-1}.
		      \end{equation}

		\item

		      Nous commençons par écrire la fonction \( f\) comme une série de puissance. La partie simple du calcul : pour \( x\in \mathopen] -R , R \mathclose[\), nous avons
		      \begin{equation}    \label{EqODjgjDN}
			      e^{e^x}=\sum_{k=0}^{\infty}\frac{ (e^x)^k }{ k! }=\sum_{k=0}^{\infty}\frac{1}{ k! }\sum_{l=0}^{\infty}\frac{ (kx)^l }{ l! }=\sum_{k=0}^{\infty}\sum_{l=0}^{\infty}\frac{k^l}{k! }\frac{ x^l }{ l! }.
		      \end{equation}
		      Notons que cela n'est pas une série de puissance en \( x\) parce qu'il y a la double somme. Nous allons inverser les sommes au moyen du théorème de Fubini sous la forme du corolaire~\ref{CorTKZKwP}. Pour cela nous considérons la fonction
		      \begin{equation}
			      \begin{aligned}
				      a\colon \eN\times \eN & \to \eR                         \\
				      (k,l)                 & \mapsto \frac{ (kx)^l }{ k!l! }
			      \end{aligned}
		      \end{equation}
		      et nous mettons la mesure de comptage\footnote{Nous passons outre les avertissements et menaces de Arnaud Girand.} sur \( \eN\) et \( \eN^2\). Nous commençons donc à vérifier l'intégrabilité variable par variable de \( | a |\) :
		      \begin{subequations}    \label{SubEqsFHsBfhk}
			      \begin{align}
				      \int_{\eN}\left( \int_{\eN}| a(k,l) |dm(l) \right)dm(k) & =\sum_{k=0}^{\infty}\frac{1}{ k! }\frac{ (k| x |)^l }{ l! } \\
				                                                              & =\sum_{k=0}^{\infty}\frac{1}{ k! } e^{k| x |}.
			      \end{align}
		      \end{subequations}
		      Nous devons montrer que cette dernière somme va bien. Pour cela nous posons \( u_k=\frac{ e^{k| x |} }{ k! }\) et nous remarquons que \( \frac{ u_{k+1} }{ u_k }\to 0\). Donc la double intégrale \eqref{SubEqsFHsBfhk} converge, ergo \( a\in L^1(\eN\times \eN)\), ce qui nous permet d'utiliser le théorème de Fubini~\ref{ThoFubinioYLtPI} pour inverser les \sout{sommes} \sout{intégrales} sommes dans l'équation \eqref{EqODjgjDN} :
		      \begin{equation}
			      \frac{1}{ e }e^{e^x}=\frac{1}{ e }\sum_{k=0}^{\infty}\sum_{l=0}^{\infty}\frac{1}{ k! }\frac{1}{ l! }(kx)^l=\sum_{l=0}\frac{1}{ e }\frac{1}{ l! }\left( \sum_{k=0}^{\infty}\frac{ k^l }{ k! } \right)x^l.
		      \end{equation}
		      Cela est un développement en série entière pour la fonction \( \frac{1}{ e } e^{e^x}\), dont nous savions déjà le développement \eqref{EqYCMGBmP}; par unicité du développement\footnote{Proposition \ref{PROPooVUEYooYemzhe}.} nous pouvons identifier les coefficients :
		      \begin{equation}
			      B_l=\frac{1}{ e }\sum_{k=0}^{\infty}\frac{ k^l }{ k! }.
		      \end{equation}
		\item
		      Le développement \eqref{EqODjgjDN} étant en réalité valable pour tout \( x\) et tous les calculs subséquents l'étant aussi, le développement
		      \begin{equation}
			      e^{e^x-1}=\sum_{n=0}^{\infty}\frac{ B_n }{ n! }x^n
		      \end{equation}
		      est en fait valable pour tout \( x\), ce qui donne à la série entière un rayon de convergence infini.
	\end{enumerate}
\end{proof}


%+++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Applications analytique entre espaces de Banach}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++


%-------------------------------------------------------
\subsection{Applications analytiques}
%----------------------------------------------------

\begin{definition}[\cite{BIBooTIAZooFwCEtZ}]	\label{DEFooAIHMooKbWsBt}
	Soient deux espaces de Banach \( E\) et \( F\). Une application \(f \colon E\to F  \) définie sur un voisinage de \( x_0\in E\) est \defe{analytique}{analytique entre espaces de Banach} en \( x_0\) si il existe un voisinage \( U\) de \( x_0\) sur lequel nous avons
	\begin{equation}		\label{EQooWATIooCCmlbT}
		f(x)=\sum_{k=0}^{\infty}\alpha_k(x-x_0)^k
	\end{equation}
	avec les conditions
	\begin{enumerate}
		\item
		      Pour chaque \( k\in \eN\), l'application \( \alpha_k\) est une forme \( k\)-multilinéaire, continue et symétrique
		\item
		      La notation \( \alpha_kx^k=\alpha_k(x,\ldots,x)\).
		\item
		      Pour chaque \( x\in U\), nous avons
		      \begin{equation}	\label{EQooQYBGooKyoNHA}
			      \sum_{k=0}^{\infty}\| \alpha_k \|\| x-x_0 \|^k<\infty
		      \end{equation}
		      où \( \| \alpha_k \|\) est la norme de \( \alpha_k\) en tant qu'application \( k\)-multilinéaire, définition \ref{DEFooTAUWooNDJJEO}.
	\end{enumerate}
\end{definition}

\begin{normaltext}
	Notez que la condition \eqref{EQooQYBGooKyoNHA} n'est pas la convergence absolue de \( \sum_n\alpha_n(x)\) qui aurait été la condition \( \sum_n\| \alpha_n(x) \|_F<\infty\) ni la convergence normale qui aurait été \( \sum_n\| \alpha_n \|<\infty\).
\end{normaltext}

\begin{proposition}[Critère d'Abel\cite{MonCerveau}]	\label{PROPooHCYXooHlUEuV}
	Soit une série entière \( \sum_{n=0}^{\infty}\alpha_k(x)\) de rayon de convergence \( R\).

	\begin{enumerate}
		\item		\label{ITEMooVAOTooELMOlK}
		      Si \( \| x \|<R\) alors
		      \begin{equation}
			      \sum_{n=0}^{\infty}\| \alpha_n \|\| x \|^n<\infty.
		      \end{equation}
		      Autrement dit : une série entière est analytique à l'intérieur de son disque de convergence.
		\item	\label{ITEMooEEVMooVeiHyY}
		      Si \( \| x \|>R\) alors
		      \begin{equation}
			      \sum_{n=0}^{\infty}\| \alpha_n \|\| x \|^n=\infty.
		      \end{equation}
		      Autrement dit : une série entière n'est pas analytique à l'extérieur de son disque de convergence.
	\end{enumerate}
\end{proposition}

\begin{proof}
	Nous considérons un \( r\in \eR\) satisfaisant \( \| x \|<r<R\), et nous considérons un majorant \( M\) pour \( \| \alpha_n \|r^n\). Nous avons alors
	\begin{equation}
		\| \alpha_n \|\| x \|^n=\| \alpha_n \|r^n\left( \frac{ \| x \| }{ r } \right)^n\leq M\left( \frac{ \| x \| }{ r } \right)^r.
	\end{equation}
	Donc la suite \( \| \alpha_n \|\| x \|\) est majorée par la suite \( M(\| x \|/r)^r\) dont la série est convergente en tant que série géométrique (proposition \ref{PROPooWOWQooWbzukS}\ref{ITEMooVZHKooNGpDkx}).

	Si \( \| x \|>R\) alors la suite \( \| \alpha_k \|\| x \|^r\) n'est pas bornée. En tant que série de termes positifs non bornés nous avons \( \sum_{n=0}^{\infty}\| \alpha_n \|\| x \|^n=\infty\).
\end{proof}

\begin{lemma}[\cite{MonCerveau}]	\label{LEMooZDPSooXxPkYs}
	Soit une application \(f \colon E\to F  \) analytique sur \( \overline{B(x_0,R)}\) s'écrivant sous la forme
	\begin{equation}
		f(x)=\sum_{k=0}^{\infty}a_k(x-x_0)
	\end{equation}
	avec \( a_k(x)=\sum_{\alpha\in\Lambda_k}a_{\alpha}x^{\alpha}\).

	Il existe \( C>0\) tel que pour tout \( \epsilon>0\) il existe \( N\in \eN\) tel que pour tout \( k\geq N\) nous ayons
	\begin{equation}
		| a_{\alpha} |<\frac{ \epsilon }{ C }R^{-k}.
	\end{equation}
\end{lemma}

\begin{proof}
	Soit \( \epsilon>0\). Nous considérons \( x\in B(x_0,R)\), en choisissant de telle sorte à avoir \( \| x-x_0 \|=R\). Nous avons donc, par définition d'une application analytique :
	\begin{equation}
		\sum_{k=0}^{\infty}\| a_k \|\| x-x_0 \|^k=\sum_{k=0}^{\infty}\| a_k \|R^k<\infty.
	\end{equation}
	Par la proposition \ref{PROPooYDFUooTGnYQg}, il existe alors \( N\) tel que si \( k\geq N\) alors \( \| a_k \|R^k<\epsilon\). Vu que \( \max_{\alpha\in\Lambda_k}| a_{\alpha} |\) est une norme (lemme \ref{LEMooORANooRLJYWw}) et que toutes les normes sont équivalentes, il existe \( C'>0\) tel que  \( C| a_{\alpha} |R^k<\epsilon\) et donc en posant \( C=1/C'\) nous avons bien
	\begin{equation}
		| a_{\alpha} |<C\epsilon R^{-k}.
	\end{equation}
\end{proof}


\begin{proposition}[\cite{MonCerveau}]	\label{PROPooMGWOooTeCDRk}
	Toute application linéaire est analytique.
\end{proposition}

\begin{proof}
	Si \(f \colon E\to F  \) est linéaire, alors \( f(x)=\sum_{n=0}^{\infty}\alpha_n(x)\) avec \( \alpha_k(x)=0\) pour \( k\neq 1\) et \( \alpha_1(x)=f(x)\).
\end{proof}

\begin{theorem}[\cite{BIBooTIAZooFwCEtZ}]	\label{THOooNBNFooMsAorH}
	Soient des espaces de Banach \( E\) et \( F\) sur \( \eC\). Soient des applications \( \alpha_n\in\aL(E,F)\). Nous supposons que \( \{ \alpha_n(x) \}\) est borné. Nous posons \( z=tx\) avec \( | t |<1\). Alors
	\begin{equation}
		\sum_{n=0}^{\infty}\alpha_n(z)
	\end{equation}
	converge absolument.
\end{theorem}

\begin{proof}
	Par hypothèse, il existe \( K\in\eR\) tel que \( \| \alpha_n(x) \|<K\) pour tout \( n\). Alors nous avons
	\begin{equation}
		\| \alpha_n(z) \|=\| \alpha_n(tz,\ldots,tz) \|=\| t^n\alpha_n(z,\ldots,z) \|\leq | t |^nK.
	\end{equation}
	Vu que \( | t |<1\), la série \( \sum_{n=0}^{\infty}K| t |^n\) converge (proposition \ref{PROPooWOWQooWbzukS}\ref{ITEMooAFAMooGuXqBm}). Donc la série \( \sum_k\| \alpha_n(z) \|\) converge par le critère de comparaison\footnote{Lemme \ref{LemgHWyfG}\ref{ITEMooBBWTooYDHnuH}.}
\end{proof}

\begin{normaltext}		\label{NORMooQDCKooXHtrHQ}
	Dans la suite, nous devons faire appel à quelques astuces de notations. Si \( \alpha\in\aL_n\), nous notons \( \alpha(x)\) pour \( \alpha(x,\ldots,x)\).

	Si \( \alpha\in \aL_{k+n}(E,F)\) est symétrique, alors nous notons \( \alpha x^n\) l'élément de \(\aL_k(E,F) \) donné par
	\begin{equation}
		(y_1,\ldots,y_k)\mapsto \alpha(x,\ldots,x,y_1,\ldots,y_n).
	\end{equation}
	Notons au passage que l'ordre n'est pas important parce que \( \alpha\) est symétrique.
\end{normaltext}


\begin{theorem}[\cite{BIBooTIAZooFwCEtZ,BIBChatGPT}]	\label{THOooHSXLooMCzTTD}
	Soient des espaces de Banach \( E\) et \( F\). Nous supposons que la série de puissance
	\begin{equation}
		\begin{aligned}
			f\colon E & \to F                                   \\
			x         & \mapsto \sum_{n=0}^{\infty}a_n(x-x_0)^n
		\end{aligned}
	\end{equation}
	ait un rayon de convergence \( r_0>0\).

	Nous posons\footnote{Voir la notation expliquée en \ref{NORMooQDCKooXHtrHQ}.}
	\begin{equation}		\label{EQooXVAIooOXGaQz}
		b_k=\sum_{n=0}^{\infty}\binom{n+k}{n}a_{n+k}(x_1-x_0)^n\in\aL_k(E,F),
	\end{equation}
	Alors :
	\begin{enumerate}
		\item		\label{ITEMooWBTAooGrKzpo}
		      \( f\) est analytique\footnote{Définition \ref{DEFooAIHMooKbWsBt}.} en tout point de \( B(x_0,r)\),
		\item		\label{ITEMooOPLBooTZZOOx}
		      Pour tout \( x\in B(x_1,r_1)\) nous avons
		      \begin{equation}
			      f(x)=\sum_{k=0}^{\infty}b_k(x-x_1)^k.
		      \end{equation}
		\item		\label{ITEMooNTPIooXpKePf}
		      La série
		      \begin{equation}
			      \sum_{k=0}^{\infty}b_k(x-x_1)^k
		      \end{equation}
		      a un rayon de convergence \( r_1\geq r_0-\| x_1-x_0 \|\).
	\end{enumerate}
\end{theorem}

\begin{proof}
	En plusieurs parties.
	\begin{subproof}
		\spitem[Pour \ref{ITEMooWBTAooGrKzpo}]
		%-----------------------------------------------------------
		C'est le critère d'Abel \ref{PROPooHCYXooHlUEuV}\ref{ITEMooVAOTooELMOlK}.
		\spitem[Pour \ref{ITEMooOPLBooTZZOOx}]
		%-----------------------------------------------------------
		Soit \( x_1\in B(x_0,r)\). Notons \( h=x_1-x_0\), de telle sorte que \( x-x_0=(x-x_1)+h\). En appliquant la multilinéarité de \( \alpha_n\), nous voyons que le binôme de Newton \ref{PropBinomFExOiL} fonctionne aussi bien :
		\begin{equation}
			\alpha_n\big( (x-x_1)+h \big)=\sum_{k=0}^n\binom{ n }{ k }\alpha_n\big( h^{n-k},(x-x_1)^k \big).
		\end{equation}
		Nous pouvons permuter les deux sommes avec le lemme \ref{LEMooKMCIooItDMRo} :
		\begin{subequations}
			\begin{align}
				f(x) & =\sum_{n=0}^{\infty}\alpha_n\big( (x-x_1)+h \big)                                                 \\
				     & =\sum_{n=0}^{\infty}\sum_{k=0}^n\binom{ n }{ k }\alpha_n\big( h^{n-k},(x-x_1)^k \big)             \\
				     & =\sum_{k=0}^{\infty}\sum_{n=k}^{\infty}\binom{ n }{ k }\alpha_n\big( h^{n-k},(x-x_1)^k \big)      \\
				     & =\sum_{k=0}^{\infty}\left( \sum_{n=k}^{\infty}\binom{ n }{ k }\alpha_n(h^{n-k}) \right)(x-x_1)^k.
			\end{align}
		\end{subequations}
		Donc en posant \( \beta_k=\sum_{n=k}^{\infty}\binom{ n }{ k }\alpha_n(h^{n-k})\) nous avons bien
		\begin{equation}
			f(x)=\sum_{k=0}^{\infty}\beta_k(x-x_1).
		\end{equation}
		La formule \eqref{EQooXVAIooOXGaQz} est maintenant juste un décalage de la somme.
		\spitem[Pour \ref{ITEMooNTPIooXpKePf}]
		%-----------------------------------------------------------
		Vu que \( B(x_1,r_1)\subset B(x_0,r_0)\), la fonction \( f\) est analytique sur \( B(x_1,r_1)\). Vu que
		\begin{equation}
			f(x)=\sum_{n=0}^{\infty}\beta_n(x-x_1),
		\end{equation}
		la partie \( B(x_1,r_1)\) soit être dans le rayon de convergence des \( \beta_k\) par le lemme d'Abel \ref{PROPooHCYXooHlUEuV}\ref{ITEMooEEVMooVeiHyY}.
	\end{subproof}
\end{proof}

\begin{lemma}[\cite{MonCerveau}]	\label{LEMooVGUFooSmJHhl}
	Si \(f \colon E\to F  \) est analytique sur \( B(a,r)\), alors
	\begin{equation}
		\begin{aligned}
			g\colon B(a+h,r) & \to F          \\
			x                & \mapsto f(x+h)
		\end{aligned}
	\end{equation}
	est analytique sur \( B(a+h)\)
	%TODOooPYCBooHIiSEw. Prouver ça.
\end{lemma}



\begin{proposition}[\cite{MonCerveau}]	\label{PROPooFEMWooDwAYyO}
	Soient un espace de Banach \( E\) ainsi que \( a\in E\). L'application
	\begin{equation}
		x\mapsto x+a
	\end{equation}
	est analytique.
	%TODOooRXHGooCxoHAr. Prouver ça.
	% Une bonne question à se poser est de voir combien de temps il y a entre ceci et l'arrivée de TODOooTNQVooMxLtUn dans ma liste.
\end{proposition}



%-------------------------------------------------------
\subsection{Opérateur d'inversion}
%----------------------------------------------------

\begin{proposition}[\cite{BIBooCAEBooLKBuqb}]	\label{PROPooSGVWooQupJxn}
	Soit un espace de Banach réel \( E\). Nous considérons l'espace vectoriel \( \End(E)\) muni de la norme opérateur.
	\begin{enumerate}
		\item
		      La partie \( \Omega\) des opérateurs inversibles\footnote{En dimension finie, \( \Omega\) est \( \GL(E)\), mais en dimension infinie, la partie \( \GL(E)\) contient seulement les opérateurs inversibles continue d'inverse continu. Voir la définition \ref{DEFooTLQUooJvknvi}.} est ouverte.
		\item
		      L'opérateur d'inversion
		      \begin{equation}
			      \begin{aligned}
				      i\colon \Omega & \to \Omega     \\
				      f              & \mapsto f^{-1}
			      \end{aligned}
		      \end{equation}
		      est analytique\footnote{Application analytique entre espaces de Banach : définition \ref{DEFooAIHMooKbWsBt}.}
	\end{enumerate}
	%TODOooHOKOooVPdSZb. Prouver ça.
\end{proposition}
Note : pour prouver ça, il faudra surement considérer une adaptation aux opérateurs du théorème \ref{THOooMNLGooKETwhh}.


%-------------------------------------------------------
\subsection{Famille sommable}
%----------------------------------------------------

\begin{probleme}
	Je suis presque certain que dans la proposition \ref{PROPooFXVEooCeiwMB}, la famille \( (a_{\alpha}x^{\alpha})\) est même absolument sommable. Mais je ne suis pas capable de le prouver. C'est peut-être prouvé au passage dans la preuve de la proposition \ref{PROPooZMXDooHLRvCd}.
\end{probleme}

\begin{proposition}[\cite{MonCerveau,BIooGNKFooTYlRlt}]	\label{PROPooFXVEooCeiwMB}
	Soit un espace de Banach \( F\) et une une application \(f \colon \eR^n\to F  \) analytique en \( x\) que nous décomposons en
	\begin{equation}
		f(x)=\sum_{k=0}^{\infty}a_k(x).
	\end{equation}
	Pour chaque \( k\in \eN\) nous posons
	\begin{equation}
		\Lambda_k=\{ \alpha\in \eN^n\tq \sum_i\alpha_i=k \},
	\end{equation}
	et \( \Lambda=\bigcup_{k=1}^{\infty}\Lambda_k\). En écrivant \( a_k\) sous la forme\footnote{Voir le lemme \ref{LEMooIEXNooPOHokX}.}
	\begin{equation}
		a_k(x)=\sum_{\alpha\in\Lambda_k}a_{\alpha}x^{\alpha},
	\end{equation}
	l'ensemble \( (a_{\alpha}x^{\alpha})_{\alpha\in\Lambda}\) est une famille sommable\footnote{Définition \ref{DefIkoheE}.} dont la somme vaut
	\begin{equation}
		S=f(x)=\sum_{k=0}^{\infty}a_k(x).
	\end{equation}
\end{proposition}

\begin{proof}
	Soit \( \epsilon>0\). Nous considérons un \( N>0\) tel que
	\begin{equation}		\label{EQooOVPIooKdvoJO}
		\| \sum_{k=p}^{\infty}a_k(x) \|<\epsilon
	\end{equation}
	pour tout \( p\geq N\). Nous supposons que \( N\) est également assez grand pour que
	\begin{equation}		\label{EQooZTKGooFeKFXO}
		\sum_{k=p}^{\infty}\| a_k \|\| x \|^k<\epsilon
	\end{equation}
	pour tout \( p\geq N\).
	Nous posons \( I_0=\bigcup_{k\leq N}\Lambda_k\) et nous considérons une partie finie \( K\) telle que \( I_0\subset K\subset\Lambda\). Nous posons
	\begin{equation}
		M=\max\{ | \alpha |\tq \alpha\in K \}.
	\end{equation}
	Notez que \( M\geq N\). Nous décomposons la somme sur \( \alpha\in K\) en
	\begin{equation}
		\sum_{\alpha\in K}a_{\alpha}x^{\alpha}=\sum_{k\leq N}\sum_{\alpha\in K\cap \Lambda_k}a_{\alpha}x^{\alpha}+\sum_{k=N+1}^{M}\sum_{\alpha\in K\cap \Lambda_k}a_{\alpha}x^{\alpha}.
	\end{equation}
	Notez que pour \( k\leq N\) nous avons \( K\cap\Lambda_k=\Lambda_k\), donc
	\begin{equation}
		\sum_{k\leq N}\sum_{\alpha\in K\cap\Lambda_k}a_{\alpha}x^{\alpha}=\sum_{k=0}^Na_k(x).
	\end{equation}
	C'est le moment d'un peu calculer :
	\begin{subequations}		\label{SUBEQSooUJGQooXuWdDr}
		\begin{align}
			\| \sum_{\alpha\in K}a_{\alpha}x^{\alpha}-S \| & =\| \sum_{k=0}^Na_k(x)+\sum_{k=N+1}^M\sum_{\alpha\in K\cap \Lambda_k}a_{\alpha}x^{\alpha}-S \|                                    \\
			                                               & =\| \sum_{k=N+1}^M\sum_{\alpha\in K\cap \Lambda_k}a_{\alpha}x^{\alpha}-\sum_{k=N+1}^{\infty}a_k(x) \|                             \\
			                                               & =\| \sum_{k=N+1}^M\sum_{\alpha\in K\cap \Lambda_k}a_{\alpha}x^{\alpha}-\sum_{k=N+1}^{M}a_k(x)-\sum_{k=M+1}^{\infty}a_k(x) \|      \\
			                                               & \leq \| \sum_{k=N+1}^M\Big( \sum_{\alpha\in K\cap\Lambda_k}a_{\alpha}x^{\alpha}-a_k(x) \Big) \|+\| \sum_{k=M+1}^{\infty}a_k(x) \| \\
			                                               & \leq \| \sum_{k=N+1}^M\sum_{\alpha\in\Lambda_k\setminus K}a_{\alpha}x^{\alpha} \|+\epsilon.
		\end{align}
	\end{subequations}
	Notez que pour majorer le second terme nous avons utilisé \( M\geq N\) et \eqref{EQooOVPIooKdvoJO}.

	Encore un calcul :
	\begin{subequations}
		\begin{align}
			\| \sum_{k=N+1}^M\sum_{\alpha\in \Lambda_k\setminus K}a_{\alpha}x^{\alpha} \| & \leq \sum_{k=N+1}^M\sum_{\alpha\in\Lambda_k}\| a_{\alpha}x^{\alpha} \|                                                                   \\
			                                                                              & \leq \sum_{k=N+1}^M\| a_k \|\big( | x_1 |+\ldots+| x_n | \big)^k       & \text{  lem. \ref{LEMooIEXNooPOHokX}\ref{ITEMooHMZUooGjtmEB}  } \\
			                                                                              & \leq \sqrt{n}\sum_{k=N+1}^M\| a_k \|\| x \|^k                          & \text{prop. \ref{PropLJEJooMOWPNi}\ref{ItemABSGooQODmLNi}}.
			\\
			                                                                              & \leq \sqrt{n}\epsilon                                                  & \text{par \eqref{EQooZTKGooFeKFXO}}.
		\end{align}
	\end{subequations}
	Avec ça nous continuons \eqref{SUBEQSooUJGQooXuWdDr} :
	\begin{equation}
		\| \sum_{\alpha\in K}a_{\alpha}x^{\alpha}-S \|\leq \epsilon(\sqrt{n}+1).
	\end{equation}
	Donc la famille \( (a_{\alpha}x^{\alpha})_{\alpha\in \Lambda}\) est sommable.
\end{proof}

\begin{lemma}[\cite{MonCerveau,BIBooNZIVooQauSDz}]	\label{LEMooYSDEooOEiXvl}
	Soit un espace de Banach \( F\) et une application \(f \colon \eR^n\to \eR  \) analytique sur \( B(0,R)\) que nous décomposons en

	\begin{equation}
		f(x)=\sum_{k=0}^{\infty}a_k(x).
	\end{equation}
	pour chaque \( x\in B(0,R)\). Pour chaque \( k\in \eN\) nous posons
	\begin{equation}
		\Lambda_k=\{ \alpha\in \eN^n\tq \sum_i\alpha_i=k \},
	\end{equation}
	et \( \Lambda=\bigcup_{k=1}^{\infty}\Lambda_k\). Nous écrivons \( a_k\) sous la forme\footnote{Voir le lemme \ref{LEMooIEXNooPOHokX}.}
	\begin{equation}
		a_k(x)=\sum_{\alpha\in\Lambda_k}a_{k,\alpha}x^{\alpha}.
	\end{equation}
	Pour \( \rho\) assez petit, l'application
	\begin{equation}
		\begin{aligned}
			v\colon \eN\times \Lambda \times B(0,r) & \to \eR                        \\
			(k,\alpha,x)                            & \mapsto a_{k,\alpha}x^{\alpha}
		\end{aligned}
	\end{equation}
	est dans \( L^1\big( \eN\times\Lambda\times B(0,\rho) \big)\).
\end{lemma}

\begin{proof}
	En plusieurs étapes.
	\begin{subproof}
		\spitem[La fonction \( u\)]
		%-----------------------------------------------------------

		Nous considérons la fonction
		\begin{equation}
			\begin{aligned}
				u\colon \eN\times \Lambda & \to \eR                          \\
				k,\alpha                  & \mapsto  a_{k,\alpha}x^{\alpha}.
			\end{aligned}
		\end{equation}
		Notez que si \( | \alpha |\neq k\) alors \( a_{k,\alpha}=0\). En utilisant la mesure de comptage sur \( \eN\) et \( \Lambda\), nous avons
		\begin{equation}
			f(x)=\int_{\eN}\left( \int_{\Lambda}u(k,\alpha)d\alpha \right)dk.
		\end{equation}

		\spitem[\( u\in L^1(\eN\times \Lambda)\)]
		%-----------------------------------------------------------
		Nous utilisons le bon vieux truc de \ref{NORMooKIRJooPvyPWQ} pour montrer que \( u\in L^1(\eN\times \Lambda)\). D'abord nous avons
		\begin{subequations}
			\begin{align}
				\int_{\Lambda}| u(k,\alpha) |d\alpha & =\sum_{\alpha\in\Lambda}\| a_{k,\alpha}x^{\alpha} \|                                                                           \\
				                                     & =\sum_{\alpha\in\Lambda}\| a_{k,\alpha}x^{\alpha} \|          & \text{pcq. \( a_{k,\alpha}=0\) si \( \alpha\not\in\Lambda_k\)} \\
				                                     & \leq\sum_{\alpha\in\Lambda_k}\| a_{k,\alpha} \|| x |^{\alpha}                                                                  \\
				                                     & \leq C^k\| a_k \|\| x \|^k                                    & \text{lem. \ref{LEMooIEXNooPOHokX}\ref{ITEMooHMZUooGjtmEB}.}
			\end{align}
		\end{subequations}
		À partir de maintenant nous nous restreignons à \( x\in B(0,R/C)\) de telle sorte à avoir \( C\| x \|<R\) et donc de pouvoir profiter de la borne \ref{EQooQYBGooKyoNHA}.

		Nous avons
		\begin{equation}		\label{EQooLCYMooGVECbX}
			\int_{\eN}\left( \int_{\Lambda}| u(k,\alpha) |d\alpha \right)dk\leq\int_{\eN}\| a_k \|\big( C\| x \| \big)^kdk=\sum_{k=0}^{\infty}\| a_k \|r^k<\infty.
		\end{equation}
		Le corolaire \ref{CorTKZKwP} implique maintenant que \( u\in L^1(\eN\times \Lambda)\).

		\spitem[La fonction \( v\)]
		%-----------------------------------------------------------
		Nous considérons \( \rho=R/C\) et nous continuons. Nous avons
		\begin{equation}
			\int_{\eN\times \Lambda}| v(x,k,\alpha) |dkd\alpha\leq \sum_{k=0}^{\infty}\| a_k \|r^k.
		\end{equation}
		Cette majoration tient pour tout \( x\in B(0,\rho)\). Nous avons donc
		\begin{equation}
			\int_{B(0,\rho)}\left( \int_{\eN\times \Lambda}| v(x,k,\alpha) |d(k\times \alpha) \right)dx<0.
		\end{equation}
		Et voilà que \( v\in L^1\big( B(0,\rho)\times (\eN\times \Lambda) \big)\).
	\end{subproof}
\end{proof}


La proposition suivante est dédiée à la petite fugue BWV 578.

\begin{proposition}[\cite{MonCerveau,BIBooNZIVooQauSDz}]	\label{PROPooZMXDooHLRvCd}
	Soit un espace de Banach \( F\) et une une application \(f \colon \eR^n\to F  \) analytique sur \( B(0,R)\) que nous décomposons en
	\begin{equation}
		f(x)=\sum_{k=0}^{\infty}a_k(x).
	\end{equation}
	pour chaque \( x\in B(0,R)\). Pour chaque \( k\in \eN\) nous posons
	\begin{equation}
		\Lambda_k=\{ \alpha\in \eN^n\tq \sum_i\alpha_i=k \},
	\end{equation}
	et \( \Lambda=\bigcup_{k=1}^{\infty}\Lambda_k\). Nous écrivons \( a_k\) sous la forme\footnote{Voir le lemme \ref{LEMooIEXNooPOHokX}.}
	\begin{equation}
		a_k(x)=\sum_{\alpha\in\Lambda_k}a_{k,\alpha}x^{\alpha},
	\end{equation}
	Nous posons
	\begin{equation}
		\Gamma_l=\{ \alpha\in\Lambda\tq \alpha_1=l \}.
	\end{equation}
	Alors il existe une boule \( B(0,r)\) sur laquelle
	\begin{equation}
		f(x)=\sum_{l=0}^{\infty}\sum_{\alpha\in\Gamma_l}a_{\alpha}x^{\alpha}.
	\end{equation}
	Si \( R=\infty\) alors \( r=\infty\) aussi.
\end{proposition}

\begin{proof}
	En plusieurs parties.
	\begin{subproof}
		\spitem[La fonction \( u\)]
		%-----------------------------------------------------------
		Nous considérons la fonction
		\begin{equation}
			\begin{aligned}
				u\colon \eN\times \Lambda & \to \eR                          \\
				k,\alpha                  & \mapsto  a_{k,\alpha}x^{\alpha}.
			\end{aligned}
		\end{equation}
		Nous avons vu dans le lemme \ref{LEMooYSDEooOEiXvl} que si on se restreint à \( x\in B(0,\rho)\) nous avons \( u\in L^1(\eN\times \Lambda)\).

		\spitem[Une partition de \( \eN\times \Lambda\)]
		%-----------------------------------------------------------
		Nous avons l'ensemble \( \Gamma_l=\{ \alpha\in \Lambda\tq \alpha_1=l \}\) et l'union disjointe \( \Lambda=\bigcup_{l=0}^{\infty}\Gamma_l\). Donc
		\begin{equation}
			\eN\times \Lambda=\bigcup_{l=0}^{\infty}\eN\times \Gamma_l.
		\end{equation}
		Par \( \sigma\)-additivité de l'intégrale, \( \int_{\eN\times \Lambda}u=\sum_l\int_{\eN\times \Gamma_l}u\). De plus la fonction \( u\) étant dans \( L^1\) nous pouvons faire l'intégrale sur \( \eN\times\Gamma_l\) en intégrant d'abord sur \( \Gamma_l\) et ensuite sur \( \eN\). Tout cela pour justifier ce calcul :
		\begin{subequations}
			\begin{align}
				f(x)=\int_{\eN\times \Lambda}u(k,\alpha)dkd\alpha & =\sum_{l=0}^{\infty}\int_{\eN\times \Gamma_l}u(k,\alpha)d(k\otimes \alpha)       \\
				                                                  & =\sum_{l=0}^{\infty}\int_{\Gamma_l}\left( \int_{\eN}u(k,\alpha)dk \right)d\alpha \\
				                                                  & =\sum_{l=0}^{\infty}\sum_{\alpha\in\Gamma_l}\sum_{k=0}^{\infty}u(k,\alpha).
			\end{align}
		\end{subequations}
		Vu que \( u(k,\alpha)\neq 0\) uniquement lorsque \( k=| \alpha |\), la somme sur \( k\) se restreint au seul terme \( k=| \alpha |\). Nous continuons donc le calcul
		\begin{subequations}
			\begin{align}
				f(x) & =\sum_{l=0}^{\infty}\sum_{\alpha\in \Gamma_l}u(| \alpha |,\alpha) \\
				     & =\sum_{l=0}^{\infty}\sum_{l\in\Gamma_l}a_{\alpha}x^{\alpha}.
			\end{align}
		\end{subequations}
	\end{subproof}
\end{proof}

%-------------------------------------------------------
\subsection{Intégrale par rapport à une des variables}
%----------------------------------------------------


\begin{proposition}[\cite{MonCerveau,BIBChatGPTDifficile}]	\label{PROPooBHKJooUZUKnc}
	Soit une application analytique\footnote{Définition \ref{DEFooAIHMooKbWsBt}.}
	\begin{equation}
		\begin{aligned}
			f\colon \eR\times \eR^m & \to \eR                                                                                        \\
			(t,\lambda)             & \mapsto \sum_{k=0}^{\infty}\sum_{\alpha\in\Lambda^{(m+1)}_{k}}a_{k,\alpha}(t,\lambda)^{\alpha}
		\end{aligned}
	\end{equation}
	que nous supposons être analytique sur un voisinage de \( (0,0)\). Nous avons :
	\begin{enumerate}
		\item		\label{ITEMooMWMSooRoXLgL}
		      L'application
		      \begin{equation}
			      \begin{aligned}
				      f\colon \eR\times \eR^m & \to \eR                         \\
				      (t,\lambda)             & \mapsto \int_0^t f(s,\lambda)ds
			      \end{aligned}
		      \end{equation}
		      est analytique sur un voisinage de \( (0,0)\).
		\item		\label{ITEMooSRHFooAjKHFg}
		      En posant
		      \begin{equation}
			      \begin{aligned}
				      \theta\colon \Lambda & \to\{ 0,1 \}                      \\
				      \alpha               & \mapsto \begin{cases}
					                                     0 & \text{si } \alpha_1=0 \\
					                                     1 & \text{sinon },
				                                     \end{cases}
			      \end{aligned}
		      \end{equation}
		      nous avons
		      \begin{equation}
			      g(t,\lambda)=\sum_{k=0}^{\infty}\sum_{\alpha\in\Lambda_k}\theta(\alpha)\frac{ a_{k-1,(\alpha_1-1,\alpha')} }{ \alpha_1+1 }(t,\lambda)^{\alpha}.
		      \end{equation}
		\item		\label{ITEMooACJMooQHkdPY}
		      Il existe \( 0<q<1\)et un polynôme \( P\) de degré \( m-1\) tel que
		      \begin{equation}
			      | b_k(t,\lambda) |\leq P(k)q^{-k}.
		      \end{equation}
	\end{enumerate}
	Le point \ref{ITEMooACJMooQHkdPY} n'est pas très utile, mais il introduit des techniques qui pourraient servir plus tard.
\end{proposition}

\begin{proof}
	Nous supposons que \( f\) est analytique sur \( \overline{B(0,R_t)}\times \overline{B(0,R_{\lambda})}\), et qu'elle se présente sous la forme\footnote{Lemme \ref{LEMooIEXNooPOHokX}.}
	\begin{equation}
		f(t,\lambda) =\sum_{k=0}^{\infty}a_k(t,\lambda)  =\sum_{k=0}^{\infty}\sum_{\alpha\in \Lambda_k}a_{k,\alpha}(t,\lambda)^{\alpha}.
	\end{equation}
	\begin{subproof}
		\spitem[Permuter somme et intégrale]
		%-----------------------------------------------------------
		Notre premier objectif est de permuter la somme et l'intégrale dans
		\begin{equation}
			g(t,\lambda)=\int_{0}^t\sum_{k=0}^{\infty}a_k(s,\lambda)ds.
		\end{equation}
		Pour cela nous utilisons la convergence dominée de Lebesgue (théorème \ref{ThoConvDomLebVdhsTf}) en fixant \( \lambda\in B(0,\rho)\) et en posant
		\begin{equation}
			f_k(t)=a_k(t,\lambda)
		\end{equation}
		et
		\begin{equation}
			h(t)=\sum_{k=0}^{\infty}| f_k(t) |.
		\end{equation}
		\begin{subproof}
			\spitem[\( h(t)<\infty\)]
			%-----------------------------------------------------------
			Nous avons \( f_k(t)=a_k(t,\lambda)\) et donc \( | f_k(t) |\leq \| a_k \|\| (t,\lambda) \|^k\). En sommant,
			\begin{equation}
				\sum_{k=0}^{\infty}| f_k(t) |\leq \sum_{k=0}^{\infty}\| a_k \|\| (t,\lambda) \|^k<\infty.
			\end{equation}
			\spitem[\( | f_k(t) |\leq | h(t) |\)]
			%-----------------------------------------------------------
			Parce que \( | h(t) |\) est la somme de plein de termes positifs, dont \( | f_k(t) |\).

			\spitem[\( h\in L^1\big( \mathopen[ 0,t\mathclose] \big)\)]
			%-----------------------------------------------------------
			Nous allons prouver que \( h\) est continue comme somme uniformément convergente de fonctions continues (théorème \ref{ThoSerUnifCont}). Pour tout \( t\in B(0,R_t)\) nous avons
			\begin{equation}
				| f_k(t) |\leq \| a_k \|\| (R_t,R_{\lambda}) \|^k.
			\end{equation}
			Donc en posant \( M_k= \| a_k \|\| (R_t,R_{\lambda}) \|^k\), nous avons \( \sum_{k=0}^{\infty}M_k<\infty\) et \( | f_k(t) |\leq M_k\) pour tout \( t\) et tout \( k\). Le critère de Weierstrass \ref{ThoCritWeierstrass} nous dit que la série converge uniformément. Donc \( h\) est continue. Donc elle est dans \( L^1\big( \mathopen[ 0,t\mathclose] \big)\) en tant que fonction continue sur un compact.
		\end{subproof}
		Nous utilisons le théorème de la convergence dominée :
		\begin{equation}
			g(t,\lambda)=\sum_{k=0}^{\infty}\int_0^ta_k(s)ds
		\end{equation}

		\spitem[Intégration et un peu de calcul]
		%-----------------------------------------------------------
		L'intégration n'est pas très compliquée à effectuer. En termes de notations, si \( \alpha\in\Lambda\) est un multiindice, nous notons \( \alpha'=(\alpha_2,\ldots,\alpha_n)\). Voici un peu de calcul :
		\begin{subequations}
			\begin{align}
				\int_0^ta_k(s)ds & =\int_0^t\sum_{\alpha\in \Lambda_k}a_{k,\alpha}(s,\lambda)^{\alpha}                              \\
				                 & =\sum_{\alpha\in\Lambda_k}\frac{ a_{k,\alpha} }{ \alpha_1+1 }(t,\lambda)^{(\alpha_1+1,\alpha')}.
			\end{align}
		\end{subequations}
		En posant
		\begin{equation}
			\begin{aligned}
				\theta\colon \Lambda & \to \{ 0,1 \}                     \\
				\alpha               & \mapsto \begin{cases}
					                               1 & \text{si } \alpha_1>0 \\
					                               0 & \text{si }\alpha_1=0,
				                               \end{cases}
			\end{aligned}
		\end{equation}
		nous avons
		\begin{equation}
			\sum_{\alpha\in \Lambda_k}\frac{ a_{k,\alpha} }{ \alpha_1+1 }(t,\lambda)^{(\alpha_1+1,\alpha')}=\sum_{\beta\in\Lambda_{k+1}}\theta(\beta)\frac{ a_{k,(\beta_1-1,\beta')} }{ \beta_1 }(t,\lambda)^{\beta}.
		\end{equation}
		Nous posons donc, pour \( k\geq 1\) :
		\begin{equation}
			b_k(t,\lambda)=\sum_{\beta\in\Lambda_k}\theta(\beta)\frac{ a_{k-1,(\beta_1-1,\beta')} }{ \beta_1 }(t,\lambda)^{\beta},
		\end{equation}
		et pour \( k=0\) nous posons \( b_0(t,\lambda)=0\) (ce qui est cohérent avec \( \theta(\beta)=0\) dans ce cas). Au final voici une belle forme pour \( g(t,\lambda)\) :
		\begin{equation}
			g(t,\lambda)=\sum_{k=0}^{\infty}b_k(t,\lambda).
		\end{equation}
		Cela prouve déjà le point \ref{ITEMooSRHFooAjKHFg}, mais nous n'avons pas encore prouvé que \( g\) est analytique.

		\spitem[Pour \ref{ITEMooMWMSooRoXLgL} : \( g\) est analytique]
		%-----------------------------------------------------------

		Nous devons prouver que \( \sum_{k=0}^{\infty}\| b_k \|\| (t,\lambda) \|^k<\infty\). Pour cela, nous allons nous souvenir que l'ensemble des applications \( k\)-multilinéaires a les normes de la définition \ref{DEFooTAUWooNDJJEO} et du lemme \ref{LEMooORANooRLJYWw}. Nous utilisons deux fois l'équivalence entre ces deux normes\footnote{Théorème \ref{ThoNormesEquiv}.} :
		\begin{subequations}
			\begin{align}
				\| b_k \| & \leq C_1\max_{\alpha\in\Lambda_k}\Big| \theta(\alpha)\frac{ a_{k-1,(\alpha_1-1,\alpha')} }{ \alpha_1+1 }  \Big| \\
				          & \leq C_1\max_{\alpha\in\Lambda_k}|  a_{k-1,(\alpha_1-1,\alpha') }|                                              \\
				          & \leq C_1C_2\| a_{k-1} \|.
			\end{align}
		\end{subequations}
		Nous avons alors
		\begin{equation}
			\| b_k \|\| (t,\lambda) \|^k  \leq C_1C_2\| a_{k-1} \|\| (t,\lambda) \|^k =C\| (t,\lambda) \|\| a_{k-1} \|\| (t,\lambda) \|^k,
		\end{equation}
		et donc
		\begin{subequations}
			\begin{align}
				\sum_{k=0}^{\infty}\| b_k \|\| (t,\lambda) \|^k & \leq C_1C_2\sum_{k=1}^{\infty}\| a_{k-1} \|\| (t,\lambda) \|^k          & \text{\( b_0=0\)} \\
				                                                & =\| (t,\lambda) \|C_1C_2\sum_{k=0}^{\infty}\| a_k \|\| (t,\lambda) \|^k                     \\
				                                                & <\infty.
			\end{align}
		\end{subequations}
	\end{subproof}

	\spitem[Prouver \ref{ITEMooACJMooQHkdPY}]
	%-----------------------------------------------------------
	Pour rappel, \( R_t\) et \( R_{\lambda}\) définissent un voisinage de \( (0,0)\) sur lequel \( f\) est analytique. Voir tout en-haut de la preuve. Nous choisissons \( (t,\lambda)\) de telle sorte que \( | t |<R_t\) et \( | \lambda |<R_{\lambda}\). Et nous considérons \( r_t,r_{\lambda}\) tels que \( | t |<r_t<R_t\) et \( | \lambda |<r_{\lambda}<R_{\lambda}\).

	Nous devons majorer la norme de
	\begin{equation}		\label{EQooJGTDooDhcKFF}
		b_k(t,\lambda)=\sum_{\alpha\in\Lambda_k}\theta(\alpha)\frac{ a_{k-1,(\alpha_1+1,\alpha')} }{ \alpha_1+1 }t^{\alpha_1}\lambda^{\alpha'}.
	\end{equation}
	Étant donnée le lemme \ref{LEMooZDPSooXxPkYs},
	\begin{equation}
		| a_{k-1,(\alpha_1-1,\alpha')} |\leq CR_t^{-(\alpha_1-1)}R_{\lambda}^{| \alpha' |}.
	\end{equation}
	De plus étant donné notre choix de \( t\) et \( \lambda\) nous avons \( | t |^{\alpha_1}\leq r_t^{\alpha_1}\) et \( | \lambda |^{\alpha'}\leq | r_{\lambda} |^{| \alpha' |}\) parce que \( | \lambda |^{\alpha'}=\prod| \lambda_i^{\alpha'_i} |\) et que pour chaque \( i\) nous avons \( | \lambda_i |\leq r_{\lambda}\).

	En prenant la valeur absolue de \eqref{EQooJGTDooDhcKFF}, en majorant \( \theta(\alpha)\leq 1\) et \( 1/(\alpha_1+1)\leq 1\) nous avons
	\begin{equation}
		| b_k(t,\lambda) |\leq C\sum_{\alpha\in\Lambda_k}R_t\left( \frac{ r_t }{ R_t } \right)^{\alpha_1}\left( \frac{ r_{\lambda} }{ R_{\lambda} } \right)^{| \alpha' |}.
	\end{equation}
	Nous posons \( q=\max(r_t/R_t,r_{\lambda}/R_{\lambda})\), nous avons \( 0<q<1\) et la majoration
	\begin{equation}		\label{EQooDGFQooLyiGKd}
		| b_k(t,\lambda) |\leq CR_t\sum_{\alpha\in\Lambda_k}q^{| \alpha |}=R_tCq^k\Card(\Lambda_k).
	\end{equation}
	Ici nous travaillons avec \( m+1\) variables, donc quand nous écrivons \( \Lambda_k\), nous voulons dire \( \Lambda_k^{(m+1)}\) et la proposition \ref{PROPooRBMVooIGkctj} nous donne
	\begin{equation}
		\Card(\Lambda_k)=\binom{ n+1+k-1 }{ m+1-1 }=\binom{ m+k }{ m }=\frac{ (m+k)! }{ m!k! }=\frac{1}{ m!}\prod_{l=1}^m(l+l)=P(k)
	\end{equation}
	où \( P\) est n polynôme de degré \( m-1\). En absorbant le facteur \( R_tC\) dans une redéfinition de \( P\), la relation \eqref{EQooDGFQooLyiGKd} donne
	\begin{equation}
		| b_k(t,\lambda) |\leq P(kq^k)
	\end{equation}
	comme demandé.
\end{proof}


%-------------------------------------------------------
\subsection{Différentielle}
%----------------------------------------------------


\begin{lemma}[\cite{BIBooTIAZooFwCEtZ,BIBooPWRQooGjpqBi}]	\label{LEMooVIINooOUwAUQ}
	Soient des espaces de Banach \( E\) et \( F\) ainsi qu'une application analytique
	\begin{equation}
		\begin{aligned}
			f\colon F & \to F                                       \\
			x         & \mapsto \sum_{n=0}^{\infty}\alpha_n(x-x_0).
		\end{aligned}
	\end{equation}
	Alors \( f\) est différentiable en \( x_0\) et
	\begin{equation}
		df_{x_0}=\alpha_1.
	\end{equation}
\end{lemma}

\begin{proof}
	Le candidat différentielle est \( T(h)=\alpha_1(h)\). Nous testons la définition de la différentielle. D'abord
	\begin{equation}
		f(x_0+h)-f(x_0)-\alpha_1(h)=\sum_{n=2}^{\infty}\alpha_n(h).
	\end{equation}
	Ensuite
	\begin{equation}
		\frac{ \| \sum_{n=2}^{\infty}\alpha_n(h) \| }{ \| h \| }\leq\sum_{n=2}^{\infty}\| \alpha_n \|\| h \|^{n-1}
	\end{equation}
	Nous savons, de la définition d'une application analytique que si \( t\) est assez petit, \( \sum_{n=0}^{\infty}\| \alpha_n \|t^{n}\). Le lemme conclu que \( \lim_{h\to 0}\sum_{n=2}^{\infty}\| \alpha_n \|\| h \|^{n-1}=0\).
\end{proof}


\begin{theorem}[\cite{BIBooTIAZooFwCEtZ}]	\label{THOooCESLooZxAzOg}
	Soient deux espaces de Banach \( E\) et \( F\) ainsi que des formes \( \alpha_n\in\aL_n(E,F)\) et \( x_0\in E\). Nous supposons que l'application
	\begin{equation}
		f(x)=\sum_{n=0}^{\infty}\alpha_n(x)
	\end{equation}
	est analytique sur \( B(x_0,r)\).

	Alors \( f\) est différentiable sur \( B(x_0,r)\) et pour tout \( x\in B(x_0,r)\) nous avons
	\begin{equation}
		df_x=\sum_{n=1}^{\infty}n\alpha_n(x-x_0)^{n-1}.
	\end{equation}
\end{theorem}

\begin{proof}
	Nous savons déjà que \( f\) est différentiable en \( x_0\) par le lemme \ref{LEMooVIINooOUwAUQ} que \( f\) est différentiable et \( df_{x_0}=\alpha_1\).

	Si \( x_1\in B(x_0,r)\), nous pouvons aller voir le théorème \ref{THOooHSXLooMCzTTD} pour développer en
	\begin{equation}
		f(x)=\sum_{k=0}^{\infty}\beta_k(x-x_1)
	\end{equation}
	avec les \( \beta_k\) donné par \eqref{EQooXVAIooOXGaQz}. Comme précédemment nous avons \( df_{x_1}=\beta_1\). Mais
	\begin{equation}
		\beta_1=\sum_{n=0}^{\infty}\underbrace{\binom{ n+1 }{ n }}_{=n+1}\alpha_{n+1}(x_1-x_0)^n=\sum_{n=0}^{\infty}(n+1)\alpha_{n+1}(x_1-x_0)^n=\sum_{n=0}^{\infty}n\alpha_n(x_1-x_0)^{n-1}.
	\end{equation}
\end{proof}


\begin{proposition}[\cite{MonCerveau}]	\label{PROPooGMWRooPIzwus}
	Toute application analytique entre espaces de Banach est de classe \( C^{\infty}\).
	%TODOooAOAEooZKQydc. Prouver ça.
\end{proposition}


\begin{proposition}[Composition d'applications analytiques\cite{MonCerveau}]	\label{PROPooXKHBooQvvNmN}
	Soient des espaces de Banach \( E_1\), \( E_2\) et \( E_3\). Soient des applications analytiques \(f \colon E_1\to E_2  \) et \(g \colon E_2\to E_3  \). Alors la composée \(g\circ f \colon E_1 \to E_2  \) est analytique.
	%TODOooOXWKooPeUOND. Prouver ça.
\end{proposition}

\begin{proposition}[\cite{MonCerveau}]	\label{PROPooKHAYooCxMgep}
	Soit une application analytique \(f \colon V\times W\to  E \). Si \( v_0\in V\) est fixé, alors l'application partielle
	\begin{equation}
		\begin{aligned}
			f_0\colon W & \to E            \\
			w           & \mapsto f(v_0,w)
		\end{aligned}
	\end{equation}
	est analytique.
\end{proposition}

\begin{proof}
	Par hypothèse il existe \( \alpha_k\in\aL_k(V\times W,E) \) telles que
	\begin{equation}
		f(v,w)=\sum_{k=0}^{\infty}\alpha_k(v,w).
	\end{equation}
	En posant
	\begin{equation}
		\begin{aligned}
			\beta_k\colon W & \to E                    \\
			w               & \mapsto \alpha_k(v_0,w),
		\end{aligned}
	\end{equation}
	nous avons bien que \( \beta_k\in\aL_k(W,E)\) est positif et symétrique. Et bien entendu \( f_0(w)=\sum_{k=0}^{\infty}\beta_k(w)\).
\end{proof}

\begin{theorem}[Inversion locale, version analytique\cite{BIBooTIAZooFwCEtZ,BIBooKWIMooEYRhWj}]	\label{THOooSZHVooKSEmuI}
	Soient des espaces de Banach \( X\) et \( Y\) ainsi qu'une application \(f \colon X\to Y  \) satisfaisant
	\begin{enumerate}
		\item
		      \( f\) est de classe \( C^1\),
		\item
		      \( f\) est analytique en \( x_0\),
		\item
		      \( df_{x_0}\) est continue\quext{J'ai un doute sur l'hypothèse. À mon avis c'est \( df\) qui est continue en \( x_0\).}  et d'inverse continue.
	\end{enumerate}
	Alors \( f\) est localement inversible en \( x_0\) et son inverse est analytique en \( f(x_0)\).
	%TODOooKXRKooOaomaP. Prouver ça.
	% quand c'est fait, donner un lien sur https://math.stackexchange.com/questions/4345396/local-inverse-of-analytic-function
\end{theorem}

%-------------------------------------------------------
\subsection{Polynômes}
%----------------------------------------------------

\begin{propositionDef}[Polynômes\cite{MonCerveau}]	\label{DEFooCJGHooXFTsNf}
	Soient des espaces de Banach \( E\) et \( F\). Nous considérons une boule \( B(0,r)\) et l'espace \( \mP_N\) des applications de la forme
	\begin{equation}
		P(x)=\sum_{k=0}^Na_k(x)
	\end{equation}
	avec \( a_k\in\aL_k(E,F)\)\footnote{Applications \( k\)-multilinéaires, définition \ref{DefFRHooKnPCT}.}. De telles applications sont des \defe{polynômes}{polynôme sur espace de Banach} entre espaces de Banach.

	Plusieurs choses à propos de \( \mP_N\).
	\begin{enumerate}
		\item
		      Si \( \sum_{k=0}^Na_k(x)=\sum_{k=0}^Nb_k(x)\) alors \( a_k=b_k\) pour tout \( k\).
		\item
		      L'application
		      \begin{equation}
			      \begin{aligned}
				      N_1\colon \mP_N & \to \eR                    \\
				      P               & \mapsto \sup_{x\in B(0,r)}
			      \end{aligned}
		      \end{equation}
		      est une norme sur \( \mP_N\).
		\item
		      L'application
		      \begin{equation}
			      \begin{aligned}
				      N_2\colon \mP_N & \to \eR                 \\
				      P               & \mapsto \max_k\| a_k \|
			      \end{aligned}
		      \end{equation}
		      est une norme sur \( \mP_N\).
		\item
		      L'application
		      \begin{equation}
			      \begin{aligned}
				      N_3\colon \mP_N & \to \eR                                  \\
				      P               & \mapsto \sqrt{ \sum_{i=1}^N\| a_i \|^2 }
			      \end{aligned}
		      \end{equation}
		      est une norme sur \( \mP_N\)
		\item		\label{ITEMooVVDSooFzRfrT}
		      Toute suite de Cauchy dans \( \mP_N\) pour une des normes \( N_i\) est une suite de Cauchy pour les deux autres normes.
		\item		\label{ITEMooUZQDooNqfNNQ}
		      Toute suite de Cauchy dans \( \mP_N\) pour une des normes \( N_i\) est convergente pour n'importe laquelle de ces trois normes.
	\end{enumerate}
	%TODOooHAMEooUtpokG. Prouver ça.
\end{propositionDef}


%-------------------------------------------------------
\subsection{Weierstrass et Cauchy-Lipschitz analytique}
%----------------------------------------------------

\begin{probleme}
	Tous les résultats de cette section (en particulier le lemme \ref{LEMooRRUMooRqDwYr} et le théorème \ref{THOooZHXMooICpUZx}) sont de ceux qui demanderaient une bonne relecture. Soyez \randomGender{attentif}{attentive} en lisant la preuve; il peut encore y avoir pas mal de pièges que je n'aurais pas vus. Si ça peut vous motiver à relire avec un œil critique, sachez que la preuve est entièrement due à ChatGPT.
\end{probleme}

\begin{lemma}[\cite{MonCerveau}]	\label{LEMooVXTLooHYvAWO}
	Soient des nombres \( a_{n,k}\in \eC\) tels que pour chaque \( n\) nous ayons \( \sum_{k=0}^{\infty}| a_{n,k} |<\infty\). Alors
	\begin{equation}
		\lim_{n\to \infty}\sum_{k=0}^{\infty}| a_{n,k} |=\sum_{k=0}^{\infty}\lim_{n\to \infty}| a_{n,k} |.
	\end{equation}
	%TODOooIUFDooNBbPCA. Prouver ça.
\end{lemma}
À mon avis c'est Fubini avec la mesure de comptage. À vous de vérifier et de m'écrire quand vous avez une preuve.

\begin{theorem}[\cite{BIBChatGPT}]	\label{THOooZHXMooICpUZx}
	Soient des espaces de Banach \( E\) et \( F\) ainsi qu'un ouvert \( U\subset E\). Soient :
	\begin{enumerate}
		\item
		      des fonctions analytiques \(f_n \colon U\to F  \),
		\item
		      \( x_0\in U\), \( r>0\) et \( M>0\)
	\end{enumerate}
	tels que
	\begin{enumerate}
		\item
		      Pour tout \( n\) et pour tout \( x\in B(x_0,r)\), nous avons
		      \begin{equation}
			      f_n(x)=\sum_{k=0}^{\infty}a_{n,k}(x-x_0).
		      \end{equation}
		\item		\label{ITEMooISLSooIfUEXH}
		      Pour tout \( n\) nous avons la majoration
		      \begin{equation}
			      \sum_{k=0}^{\infty}\| a_{n,k} \|r^k<M<\infty.
		      \end{equation}
		\item
		      \( f_n\to f\) uniformément sur \( B(x_0,r)\).
	\end{enumerate}
	Alors :
	\begin{enumerate}
		\item		\label{ITEMooIKWBooXwNBoU}
		      Pour chaque \( k\), il existe une application \( k\)-multilinéaire \( a_k\) telle que \( a_{n,k}\to a_k\).
		\item		\label{ITEMooIDSZooUjZgRl}
		      La série
		      \begin{equation}
			      \sum_{k=0}^{\infty}a_k(x-x_0)^k
		      \end{equation}
		      converge normalement sur \( B(x_0,r)\).
		\item
		      La fonction \( f\) vaut
		      \begin{equation}
			      f(x)=\sum_{k=0}^{\infty}a_k(x-x_0)^k
		      \end{equation}
		\item
		      \( f\) est analytique en \( x_0\).
	\end{enumerate}
\end{theorem}

\begin{proof}
	Nous commençons par supposer que \( x_0=0\). Pour chaque \( n\) et \( N\) nous posons
	\begin{equation}
		\begin{aligned}
			P_{n,N}\colon B(0,r) & \to \eR                         \\
			x                    & \mapsto \sum_{k=0}^Na_{n,k}(x).
		\end{aligned}
	\end{equation}
	et le reste
	\begin{equation}
		R_{n,N}(x)=f_n(x)-P_{n,N}(x)=\sum_{k=N+1}^{\infty}a_{n,k}(x).
	\end{equation}
	\begin{subproof}
		\spitem[Une majoration pour le reste]
		%-----------------------------------------------------------
		Soit \( 0<\rho<r\). Nous avons :
		\begin{subequations}
			\begin{align}
				\sup_n\sup_{\| x \|\leq \rho}\| R_{n,N}(x) \| & \leq \sup_n\sup_{\| x \|\leq \rho}\sum_{k=N+1}^{\infty}\| a_{n,k} \|\| x \|^k     \\
				                                              & \leq\sup_n\sup_{\| x \|\leq \rho}\sum_{k=N+1}^{\infty}\| a_{n,k} \|\rho^k         \\
				                                              & = \sup_n\sum_{k=N+1}^{\infty}\| a_{n,k} \|r^k\left( \frac{ \rho }{ r } \right)^k.
			\end{align}
		\end{subequations}
		Dans la somme, \( k\geq N+1\). Vu que \( \rho/r<1\) nous avons la majoration \( (\rho/r)^k\leq (\rho/r)^{N+1}\). Nous continuons le calcul
		\begin{subequations}
			\begin{align}
				\sup_n\sup_{\| x \|\leq \rho}\| R_{n,N}(x) \| & \leq \sup_n\left( \frac{ \rho }{ r } \right)^{N+1}\sum_{k=N+1}^{\infty}\| a_{n,k} \|r^k \\
				                                              & \leq \left( \frac{ \rho }{ r } \right)^{N+1}\sup_n\sum_{k=0}^{\infty}\| a_{n,k} \|r^k   \\
				                                              & \leq \left( \frac{ \rho }{ r } \right)^{N+1}M.
			\end{align}
		\end{subequations}
		Au final, pour tout \( N\) et pour tout \( 0<\rho<r\) nous avons :
		\begin{equation}		\label{EQooNBYDooQRWbaF}
			\sup_n\sup_{\| x \|\leq \rho}\| R_{n,N}(x) \| \leq  \left( \frac{ \rho }{ r } \right)^{N+1}M.
		\end{equation}

		\spitem[Suites de Cauchy]
		%-----------------------------------------------------------
		Soit \( \epsilon>0\). La majoration \eqref{EQooNBYDooQRWbaF} nous permet de choisir \( N\) assez grand pour avoir
		\begin{equation}
			\sup_n\sup_{\| x \|\leq \rho}\| R_{n,N}(x) \|\leq \epsilon.
		\end{equation}

		Par ailleurs, nous avons la convergence \( f_n\to f\) uniforme sur \( \overline{B(0,r)}\); donc la suite \( (f_n)_{n\in \eN}\) est de Cauchy pour la norme uniforme \( \| . \|_{\overline{B(0,r)}}\). Donc il existe \( N_0\) tel que si \( p,q\geq N_0\) alors
		\begin{equation}
			\sup_{\| x \|\leq \rho}\| f_p(x)-f_q(x) \|< \epsilon.
		\end{equation}
		Nous avons aussi
		\begin{equation}
			\| P_{p,N}(x)-P_{q,N}(x) \|\leq \| f_p(x)-f_q(x) \|+\| R_{p,N}(x) \|+\| R_{q,N}(x) \|\leq 3\epsilon.
		\end{equation}
		Cela prouve que si \( N\) est assez grand, alors la suite \( (P_{n,N})_{n\in \eN}\) est de Cauchy pour la norme \( \| . \|_{\overline{B(0,\rho)}}\).

		Relisez l'énoncé de la définition-proposition \ref{DEFooCJGHooXFTsNf}, et en particulier les points \ref{ITEMooVVDSooFzRfrT} et \ref{ITEMooUZQDooNqfNNQ}. Vu que \( P_{n,N}\in\mP_N\) pour chaque \( N\) et que c'est une suite de Cauchy pour ce qui est appelé \( N_1\) dans \ref{DEFooCJGHooXFTsNf}, nous savons que c'est une suite de Cauchy pour n'importe laquelle de ces normes.

		Nous avons donc des \( a_k\in\aL_k\) tels que \( a_{n,k}\stackrel{ \aL_k}{\longrightarrow}  a_k\) et en posant \( P_N(x)=\sum_{k=0}^Na_k(x)\) nous avons
		\begin{equation}
			\lim_{n\to \infty}\| P_{n,N}-P_N \|_{\overline{B(0,\rho)}}=0.
		\end{equation}

		\spitem[Convergence normale]
		%-----------------------------------------------------------
		Nous vérifions à présent que la série \( \sum_{k=0}^{\infty}a_k(x)\) converge normalement. Nous avons
		\begin{subequations}
			\begin{align}
				\| a_k \|\| x \|^k & =\lim_{n\to \infty}\| a_{n,k} \|\| x \|^k  \\
				                   & \leq \lim_{n\to \infty}\| a_{n,k} \|\rho^k
			\end{align}
		\end{subequations}
		Donc
		\begin{subequations}
			\begin{align}
				\sum_{k=0}^{\infty}\| a_k \|\| x \|^k & \leq\sum_{k=0}^{\infty}\lim_{n\to \infty}\| a_{n,k} \|\rho^k                                        \\
				                                      & =\lim_{n\to \infty}\sum_{k=0}^{\infty}\| a_{n,k} \|\rho^k    & \text{lem. \ref{LEMooVXTLooHYvAWO}}  \\
				                                      & <M                                                           & \text{hyp. \ref{ITEMooISLSooIfUEXH}} \\
				                                      & <\infty.
			\end{align}
		\end{subequations}


		\spitem[Point sur la situation]
		%-----------------------------------------------------------
		Nous avons déjà prouvé les points \ref{ITEMooIKWBooXwNBoU} et \ref{ITEMooIDSZooUjZgRl}. De plus en posant
		\begin{equation}
			g(x)=\sum_{k=0}^{\infty}a_k(x),
		\end{equation}
		nous avons bien que \( g\) est analytique.

		\spitem[\( f=g\)]
		%-----------------------------------------------------------
		Il nous reste à prouver que l'application \( g\) est en réalité la limite \( f\) dont on parle dans l'énoncé. Nous devons calculer \( \lim_{N\to\infty}\| f(x)-\sum_{k=0}^Na_k(x) \|\). Nous avons le calcul suivant :
		\begin{subequations}
			\begin{align}
				f(x)-\sum_{k=0}^Na_k(x) & =\big( f(x)-f_n(x) \big)+\sum_{k=0}^Na_{n,k}(x)+\sum_{k=N+1}^{\infty}a_{n,k}(x)-\sum_{k=0}^Na_k(x) \\
				                        & =\big( f(x)-f_n(x) \big)+\sum_{k=0}^N(a_{n,k}-a_k)(x)+\sum_{k=N+1}^{\infty}a_{n,k}(x)
			\end{align}
		\end{subequations}
		Cette égalité étant valable pour tout \( n\), nous pouvons passer à la limite \( n\to \infty\), et il reste
		\begin{equation}
			f(x)-\sum_{k=0}^{N}a_k(x)=\lim_{n\to \infty}\sum_{k=N+1}^{\infty}a_{n,k}(x).
		\end{equation}
		C'est le moment de ressortir \eqref{EQooNBYDooQRWbaF}, et de calculer (encore !) :
		\begin{equation}
			\| f(x)-\sum_{k=0}^Na_k(x) \|\leq \lim_{n\to 0}\| \sum_{k=N+1}^{\infty}a_{n,k}(x) \|=\lim_{n\to \infty}\| R_{n,N}(x) \|\leq M\left( \frac{ \rho }{ r } \right)^{N+1}
		\end{equation}
		Et voilà. Il suffit maintenant de faire \( N\to \infty\) des deux côtés pour avoir
		\begin{equation}
			\| f(x)-\sum_{k=0}^{\infty}a_k(x) \|=0.
		\end{equation}

		\spitem[Si \( x_0\neq 0\)]
		%-----------------------------------------------------------
		Appliquer le tout à la limite \( g_n\to g\) où \( g(x)=f(x-x_0)\) et \( g_n(x)=f_n(x-x_0)\). Ensuite appliquer le lemme \ref{LEMooVGUFooSmJHhl}.
	\end{subproof}
\end{proof}

\begin{lemma}[\cite{BIBChatGPT}]	\label{LEMooRRUMooRqDwYr}
	Soit une application \(f \colon \eR\times \eR^m\to \eR  \) analytique sur un voisinage de \( (0,0)\). Nous posons
	\begin{equation}
		g(t,\lambda)=\int_{0}^tf(s,\lambda)ds.
	\end{equation}
	Alors \( g\) est analytique sur un voisinage de \( (0,0)\).
\end{lemma}

\begin{proof}
	Nous notons \( \Lambda_k^{(n)}\) l'ensemble des multiindices de longueur \( n\) dont la somme des composantes vaut \( k\).
	Si \( (t_0,\lambda_0)\) est un point où \( f\) est analytique. Pour un point \( (t,\lambda)\) dans un voisinage nous avons
	\begin{equation}
		f(t,\lambda)=\sum_{k=0}^{\infty}\sum_{\alpha\in\Lambda_k^{(m+1)}}a_{k,\alpha}\big( (t-t_0),(\lambda-\lambda_0) \big)^{\alpha}.
	\end{equation}
	Nous pouvons réarranger les termes comme montré dans \ref{PROPooZMXDooHLRvCd} :
	\begin{subequations}
		\begin{align}
			f(t,\lambda) & =\sum_{k=0}^{\infty}\sum_{\alpha\in\Lambda_k^{(m+1)}}a_{k,\alpha}\big( (t-t_0),(\lambda-\lambda_0) \big)^{\alpha}  \\
			             & =\sum_{l=0}^{\infty}\sum_{\alpha\in \Gamma_l}a_{| \alpha |,\alpha}\big( (t-t_0),(\lambda-\lambda_0) \big)^{\alpha} \\
			             & =\sum_{l=0}^{\infty}\sum_{\beta\in \Lambda^{(m)}}a_{| \beta |+1,(l\beta)}(t-t_0)^l(\lambda-\lambda_0)^{\beta}.
		\end{align}
	\end{subequations}
\end{proof}


Vous saviez qu'en anglais ce théorème était nommé « Picard–Lindelöf » au lieu de Cauchy-Lipschitz ?

\begin{theorem}[Cauchy-Lipschitz analytique\cite{BIBChatGPT}]	\label{THOooZEBOooQJOSQj}
	Soient \( n,m\in \eN\), soit \( U\) un voisinage de \( 0\) dans \( \eR^n\) et \( P\) un voisinage de \( 0\) dans \( \eR^m\). Nous considérons \( y_0\in U\) et une application analytique\footnote{Définition \ref{DEFooAIHMooKbWsBt}.} \(f \colon U\times P\to \eR^n  \).

	Alors
	\begin{enumerate}
		\item
		      il existe \( T>0\) et un voisinage \( W\subset P\) de \( 0\) tel que pour tout \( p\in W\) l'équation différentielle
		      \begin{subequations}
			      \begin{numcases}{}
				      y'(t)=f\big( y(t),p \big)\\
				      y(0)=0
			      \end{numcases}
		      \end{subequations}
		      possède une unique solution \(y_p \colon \mathopen[ -T,T\mathclose]\to \eR^n  \).
		\item
		      L'application
		      \begin{equation}
			      \begin{aligned}
				      \sigma\colon \mathopen[ -T,T\mathclose]\times W & \to \eR^n      \\
				      (t,p)                                           & \mapsto y_p(t)
			      \end{aligned}
		      \end{equation}
		      est analytique.
	\end{enumerate}
	%TODOooYTNTooHUngNA. Prouver ça.
	% Quand la démonstration sera finie, poser [1] comme exemple de théorème manquant sur internet dans un des commentaires sur linuxfr.
	% [1] https://math.stackexchange.com/questions/5101596/analytic-picard-lindel%c3%b6f-theorem
\end{theorem}


%-------------------------------------------------------
\subsection{Série de puissance sur \( \eC\)}
%----------------------------------------------------

\begin{proposition}[\cite{MonCerveau}]	\label{PROPooBFGJooYVvYaw}
	Si \(f \colon \eC\to \eC  \) est une série de puissances\footnote{Définition \ref{DEFooIXGBooPgJTzB}.} sur \( \eC\), alors il existe des \( c_k\in \eC\) tels que
	\begin{equation}
		f(z)=\sum_{k=0}^{\infty}c_kz^k.
	\end{equation}
\end{proposition}

\begin{proof}
	En effet soit une application \( \alpha\in \aL_k(\eC,\eC)\). Nous avons \( \alpha(z,\ldots,z)=z\alpha(1,z,\ldots,z)\) et donc par récurrence,
	\begin{equation}
		\alpha(z,\ldots,z)=z^{k}\alpha(1,\ldots,1).
	\end{equation}
	En posant \( c_k=\alpha_k(1,\ldots,1)\), nous avons
	\begin{equation}
		f(z)=\sum_k\alpha_k(z,\ldots,z)=\sum_k\alpha_k(1,\ldots,1)z^n=\sum_kc_kz^k.
	\end{equation}
\end{proof}

%-------------------------------------------------------
\subsection{L'opérateur d'inversion est analytique}
%----------------------------------------------------

La proposition suivante indique que si \( A\) est un opérateur sur un espace de Banach, alors ce que nous noterions naïvement
\begin{equation}
	\sum_ka_kA^k
\end{equation}
est effectivement une série de puissances au sens de la définition \ref{DEFooIXGBooPgJTzB}.

L'ensemble \( \End^0(E)\) est l'ensemble des endomorphismes bornés de \( E\). De façon équivalente\footnote{Proposition \ref{PROPooQZYVooYJVlBd}.}, ce sont les endomorphismes continus de \( E\). Je ne suis pas totalement certain que la proposition \ref{PROPooGCLEooBVPHcu} ait besoin de se restreindre à \( \End^0(E)\).

\begin{proposition}[\cite{MonCerveau}]	\label{PROPooGCLEooBVPHcu}
	Soit un espace de Banach \( E\). Si \( A\in \End^0(E)\) et si \( \alpha\in\eC \), il existe
	\begin{equation}
		\alpha\in\aL_n\big( \End^0(E),\End^0(E) \big)
	\end{equation}
	qui est symétrique, continue et telle que
	\begin{equation}
		\alpha(A,\ldots,A)=\lambda A^n
	\end{equation}
	où \( A^n=A\circ\ldots\circ A\).
\end{proposition}

\begin{proof}
	Nous posons
	\begin{equation}
		\begin{aligned}
			\alpha\colon (\End(E)^0)^n & \to \End(E)^0                                                                               \\
			A_1,\ldots,A_n             & \mapsto \frac{\lambda}{ n!}\sum_{\sigma\in S_n}A_{\sigma(1)}\circ\ldots\circ A_{\sigma(n)}.
		\end{aligned}
	\end{equation}
	Il est vite vu que \( \alpha\) est \( n\)-linéaire. Et vu que \( | S_n |=n!\), nous avons bien \( \alpha(A,\ldots,A)=A^n\).

	Pour prouver que \( \alpha\) est continue, nous utilisons la proposition \ref{PROPooDQBOooByBvmj}. Nous avons
	\begin{subequations}
		\begin{align}
			\| \alpha(A_1,\ldots,A_n) \| & \leq\frac{1}{ n!}\sum_{\sigma\in S_n}\| A_{\sigma(1)}\circ\ldots\circ A_{\sigma(n)} \|                                         \\
			                             & \leq \frac{1}{ n!}\sum_{\sigma}\| A_{\sigma(1)} \|\ldots \| A_{\sigma(n)} \|           & \text{prop. \ref{PROPooDQBOooByBvmj}} \\
			                             & =\| A_1 \|\ldots\| A_n \|.
		\end{align}
	\end{subequations}
	Donc en posant \( \lambda=1\) avons l'inégalité \eqref{EQooGTVEooZsvzAM}.
\end{proof}


\begin{proposition}[\cite{MonCerveau}]	\label{PROPooKZNWooLdjDTP}
	Soit un espace de Banach \( E\). Soient deux opérateurs \( A,T\in\End^0(E)\). Nous avons
	\begin{equation}
		T\circ\sum_{k=0}^{\infty}A^k=\sum_{k=0}^{\infty}(TA^k).
	\end{equation}
\end{proposition}

\begin{proof}
	L'application
	\begin{equation}
		\begin{aligned}
			\varphi\colon \GL^0(E) & \to \GL^0(E)     \\
			X                      & \mapsto T\circ X
		\end{aligned}
	\end{equation}
	est continue. Donc
	\begin{subequations}
		\begin{align}
			\varphi\Big( \lim_{N\to \infty}\sum_{k=0}^{N}A^k \Big) & =\lim_{N\to \infty}\varphi\Big( \sum_{k=0}^NA^k \Big) \\
			                                                       & =\lim_{N\to \infty}\sum_{k=0}^N\varphi(A^k)           \\
			                                                       & =\sum_{k=0}^{\infty}(TA^k).
		\end{align}
	\end{subequations}
\end{proof}

\begin{proposition}[\cite{BIBooKXKIooZAOciI}]	\label{PROPooPVZBooESAiRv}
	Soit un espace de Banach \( E\).

	\begin{enumerate}
		\item
		      L'application
		      \begin{equation}
			      \begin{aligned}
				      f\colon B(0,1) & \to \End(E)                    \\
				      A              & \mapsto \sum_{k=0}^{\infty}A^k
			      \end{aligned}
		      \end{equation}
		      où \( B(0,1)\) est le boule de rayon \( 1\) pour la norme opérateur est analytique.
		\item
		      Soit \( A\in \End(E)\) avec \( \| A \|<1\). Alors \( A\) est inversible et
		      \begin{equation}
			      A^{-1}=\sum_{k=0}^{\infty}A^k.
		      \end{equation}
	\end{enumerate}
\end{proposition}

\begin{proof}
	En plusieurs parties.
	\begin{subproof}
		\spitem[Analytique]
		%-----------------------------------------------------------
		Nous posons
		\begin{equation}
			\begin{aligned}
				f\colon B(0,1) & \to \End(E)                    \\
				A              & \mapsto \sum_{k=0}^{\infty}A^k
			\end{aligned}
		\end{equation}
		Vu que \( \| A \|<1\), la série converge absolument\footnote{Proposition \ref{PROPooWOWQooWbzukS}\ref{ITEMooAFAMooGuXqBm}.}. Grâce à la proposition \ref{PROPooGCLEooBVPHcu}, l'application \( f\) est une série de puissances. Le théorème \ref{THOooHSXLooMCzTTD}\ref{ITEMooWBTAooGrKzpo} nous dit alors que \( f\) est analytique sur \( B(0,1)\).

		\spitem[Inverse]
		%-----------------------------------------------------------
		Nous calculons maintenant \( (\mtu-A)\sum_{k=0}^{\infty}A^k\) en utilisant la proposition \ref{PROPooWOWQooWbzukS}. Nous avons :
		\begin{subequations}
			\begin{align}
				(\mtu-A)\sum_{k=0}^{\infty}A^k & =\sum_{k=0}^{\infty}(\mtu-A)A^k                                                     \\
				                               & =\sum_{k=0}^{\infty}\big( A^k-A^{k+1} \big)                                         \\
				                               & =A^0                                        & \text{prop. \ref{PROPooQLOUooTDWfFF}} \\
				                               & =\mtu
			\end{align}
		\end{subequations}
		Cela prouve que \( (\mtu-A)\) est inversible et que son inverse est \( \sum_{k=0}^{\infty}A^k\).
	\end{subproof}
\end{proof}

\begin{proposition}[\cite{BIBooKXKIooZAOciI}]	\label{PROPooCHTEooWWzSqK}
	Soit un espace de Banach \( E\). Soit \( T\) inversible et continu dans \( \End(E)\). Nous posons
	\begin{equation}
		\rho=\frac{1}{ \| T^{-1} \|}.
	\end{equation}
	Pour tout \( S\in B\big( 0,1/\| T^{-1} \| \big)\), nous avons :
	\begin{enumerate}
		\item
		      \( (T+S)\) est inversible.
		\item
		      La série \( \sum_{k=0}^{\infty}(T^{-1}S)^k\) converge absolument.
		\item
		      Nous avons la formule
		      \begin{equation}
			      (T+S)^{-1}=\sum_{k=0}^{\infty}(-T^{-1}S)^kT.
		      \end{equation}
		\item
		      L'application
		      \begin{equation}
			      \begin{aligned}
				      i\colon B(T,\rho) & \to \GL(E)     \\
				      A                 & \mapsto A^{-1}
			      \end{aligned}
		      \end{equation}
		      est analytique\footnote{Définition \ref{DEFooIXGBooPgJTzB}.}.
	\end{enumerate}
\end{proposition}

\begin{proof}
	Nous commençons par considérer \( T=\id\).
	Nous passons maintenant au cas général. Soient un opérateur inversible \( T\) ainsi que \( S\in B\big( T, 1/\| T^{-1} \| \big)\). Nous considérons
	\begin{equation}
		\phi(S)=\sum_{k=0}^{\infty}(-T^{-1}S)^kT^{-1}.
	\end{equation}

	\begin{subproof}
		\spitem[Rayon de convergence]
		%-----------------------------------------------------------
		Nous prouvons que cette série a un rayon de convergence \( \rho=1/\| T^{-1} \|\). En effet supposons que \( S\in B(0,\rho)\). Vu que \( T\) est borné (la continuité est dans les hypothèses), nous pouvons utiliser le lemme \ref{LEMooFITMooBBBWGI} :
		\begin{equation}
			\| T^{-1}S \|\leq \| T^{-1} \|\cdot\| S \|<1.
		\end{equation}
		Nous avons donc convergence absolue de \( \phi\) sur \( B(0,\rho)\). La fonction \( \phi\) est donc analytique sur \( B(0,\rho)\).

		\spitem[Inverse]
		%-----------------------------------------------------------
		Vu que \( \| -T^{-1}S \|<1\), nous pouvons utiliser la proposition \ref{PROPooPVZBooESAiRv} : l'opérateur \( \mtu-(-T^{-1}S) \) est inversible et son inverse est \( \sum_k(-T^{-1}S)^k\).

		\spitem[Lien avec \( (T+S)^{-1}\)]
		%-----------------------------------------------------------
		Petit calcul. Nous avons :
		\begin{subequations}
			\begin{align}
				\sum_k(-T^{-1}S)^kT^{-1} & =\Big[   \sum_k(-T^{-1}S)^k   \Big]T^{-1}             \\
				                         & =\Big[  \big( \mtu-(-T^{-1}S) \big)  \Big]^{-1}T^{-1} \\
				                         & =\Big[ T(\mtu+T^{-1}S)  \Big]^{-1}                    \\
				                         & =(T+S)^{-1}.
			\end{align}
		\end{subequations}
		Cela prouve que si \( S\in B(0,\rho)\), alors \( (T+S)^{-1}=\phi(S)\).

		\spitem[Analycité de \( i\)]
		%-----------------------------------------------------------
		Pour \( A\in B(T,\rho)\), nous posons \( S=A-T\), de telle sorte à avoir \( \| S \|<\rho\) et \( (T+S)^{-1}=\phi(S)\). Nous avons donc
		\begin{equation}
			i(A)=\phi(A-T)
		\end{equation}
		Vu que \( \phi\) est analytique et que \( A\mapsto A-T\) est analytique (proposition \ref{PROPooFEMWooDwAYyO}), par composition, l'application \( i\) est analytique (proposition \ref{PROPooXKHBooQvvNmN}).
	\end{subproof}
\end{proof}

\begin{proposition}[\cite{MonCerveau}]	\label{PROPooNRXBooTdEKsu}
	Soit une isométrie \(\varphi \colon E\to F  \) entre espaces de Banach. Les applications
	\begin{equation}
		\begin{aligned}
			u\colon \GL(E) & \to \GL(F,E)          \\
			g              & \mapsto g\circ\varphi
		\end{aligned}
	\end{equation}
	et
	\begin{equation}
		\begin{aligned}
			s\colon  \aL(E,F) & \to \End(E)             \\
			f                 & \mapsto \varphi\circ f.
		\end{aligned}
	\end{equation}
	sont analytiques.
	%TODOooCQYFooDbLHge. Prouver ça.
\end{proposition}


\begin{proposition}	\label{PROPooHJETooZHzodH}
	Soient deux espaces de Banach isométrique \( E\) et \( F\). La partie \( \GL(E,F)\) est ouverte dans \( \aL(E,F)\).
	%TODOooCFKGooOdPInU. Prouver ça.
\end{proposition}

\begin{proposition}[\cite{MonCerveau}]	\label{PROPooYJWGooEbbLVw}
	Soient deux espaces de Banach isométrique \( E\) et \( F\). L'opérateur d'inversion
	\begin{equation}
		\begin{aligned}
			j\colon \GL(E,F) & \to \GL(F,E)   \\
			f                & \mapsto f^{-1}
		\end{aligned}
	\end{equation}
	est analytique.
\end{proposition}

\begin{proof}
	Nous considérons une isométrie \(\varphi \colon F\to E  \), et l'application
	\begin{equation}
		\begin{aligned}
			s\colon  \aL(E,F) & \to \End(E)             \\
			f                 & \mapsto \varphi\circ f.
		\end{aligned}
	\end{equation}
	\begin{subproof}
		\spitem[\( \varphi\) est linéaire]
		%-----------------------------------------------------------
		Vérification immédiate.
		\spitem[\( s\) est une injection]
		%-----------------------------------------------------------
		Suppose que \( s(f)=s(g)\). Alors pour tout \( x\in E\), nous avons \( (\varphi\circ f)(x)=(\varphi\circ g)(x)\). Et comme \( \varphi\) est bijective, cela implique \( f(x)=g(x)\) et donc que \( f=g\).
		\spitem[\( \varphi\) est surjective]
		%-----------------------------------------------------------
		Soit \( f\in\End(E)\). Nous avons \( f=s(f\circ\varphi^{-1})\).

		\spitem[\( s\) est une isométrie]
		%-----------------------------------------------------------
		Nous avons
		\begin{subequations}
			\begin{align}
				\| s(f) \| & =\sum_{\| x \|=1}\| s(f)(x)  \|                                                  \\
				           & =\sup_{\| x \|=1}\| (\varphi\circ f)(x) \|                                       \\
				           & =\sup_{\| x \|=1}\| f(x) \|                & \text{\( \varphi\) est isométrique} \\
				           & =\| f \|
			\end{align}
		\end{subequations}
	\end{subproof}
	Nous avons prouvé que \(s \colon \aL(E,F)\to \End(E)  \) est une bijection isométrique.

	L'application \( s\) se restreint en \(s \colon \GL(E,F)\to \GL(E)  \). Pour \( f\in \GL(E,F) \), nous avons \( j(f)=  i\big( s(f) \big)\circ\varphi \). En effet
	\begin{equation}
		i\big( s(f) \big)\circ\varphi=i\big( \varphi\circ f \big)\circ\varphi=f^{-1}\circ\varphi^{-1}\circ\varphi=f^{-1}.
	\end{equation}
	En utilisant l'application \( u\) de la proposition \ref{PROPooNRXBooTdEKsu}, nous avons alors
	\begin{equation}
		j=u\circ i\circ s.
	\end{equation}
	Vu que \( s\), \( i\) et \( u\) sont analytiques\footnote{Propositions \ref{PROPooNRXBooTdEKsu} et \ref{PROPooCHTEooWWzSqK}.}, \( j\) est analytique.
\end{proof}



\begin{proposition}[\cite{MonCerveau}]	\label{PROPooPESTooQmWGRJ}
	Soient des espaces vectoriels normés \( X_1, X_2,Y_1,Y_2\) ainsi que des applications \(f \colon X_1\to Y_1  \) et \(g \colon X_2\to Y_2  \) de classe \( \mA\) (différentiable, \( C^k\) ou analytique\footnote{Définition \ref{DEFooIXGBooPgJTzB}.}). Alors l'application
	\begin{equation}
		\begin{aligned}
			f\times g\colon X_1\times X_2 & \to Y_1\times Y_2               \\
			(x,y)                         & \mapsto \big( f(x), f(y) \big).
		\end{aligned}
	\end{equation}
	est dans la classe \( \mA\).
\end{proposition}

\begin{proof}

	La proposition \ref{PROPooCOBHooICFDMU} donne déjà le résultat pour \( f\) et \( g\) différentiables et \( C^k\). Nous nous concentrons sur l'analytique.

	Nous supposons que \( f\) et \( g\) sont analytiques. Nous avons donc des \( k\)-formes symétriques \(\alpha_k \colon X_1\times\ldots\times X_1\to Y_1  \) telles que
	\begin{equation}
		f(x)=\sum_{k=0}^{\infty}\alpha_k(x)
	\end{equation}
	et des \( k\)-formes symétriques \(\beta_k \colon X_2\times \ldots X_2\to Y_2  \) telles que
	\begin{equation}
		g(y)=\sum_{k=0}^{\infty}\beta_k(y).
	\end{equation}
	Nous considérons les \( k\)-formes symétriques
	\begin{equation}
		\begin{aligned}
			\gamma_k\colon (X_1\times X_2)^k & \to Y_1\times Y_2                                                     \\
			(x_1,y_1),\ldots,(x_k,y_k)       & \mapsto \big( \alpha_k(x_1,\ldots,x_k),\beta_k(y_1,\ldots,y_k) \big).
		\end{aligned}
	\end{equation}

	Pour chaque \( N\in \eN\) nous avons
	\begin{equation}
		\sum_{k=0}^N\gamma_k(x,y)=\big( \sum_{k=0}^N\alpha_k(x),\sum_{k=0}^N\beta_k(y) \big).
	\end{equation}
	En prenant la limite \( N\to \infty\), la proposition \ref{PROPooMHAVooRgJjMB} donne
	\begin{equation}
		\sum_{k=0}^{\infty}\gamma_k(x,y)=\big( \sum_{k=0}^{\infty}\alpha_k(x),\sum_{k=0}^{\infty}\beta_k(y) \big)=(f\times g)(x,y).
	\end{equation}
	c'est-à-dire que nous avons bien écrit \( f\times g\) comme série de formes symétriques.
\end{proof}
