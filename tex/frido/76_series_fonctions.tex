% This is part of Mes notes de mathématique
% Copyright (c) 2011-2019
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Étude d'asymptote}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Lorsqu'une fonction tend vers l'infini pour \( x\to \infty\), une question qui peut venir est : à quelle vitesse tend-t-elle vers l'infini ?

Il est «visible» que la fonction logarithme ne tend pas très vite vers l'infini : certes
\begin{equation}
    \lim_{x\to \infty} \ln(x)=+\infty,
\end{equation}
mais par exemple \( \ln(100000)\simeq 11.5\) tandis que \(  e^{100000}\simeq 10^{43429}\). Sans contestations possibles, l'exponentielle croit plus vite que le logarithme.

Soient \( f\) et \( g\) deux fonctions dont la limite \( x\to \infty\) est \( \infty\). Si
\begin{equation}
    \lim_{x\to \infty} \frac{ f(x) }{ g(x) }=0
\end{equation}
nous disons que \( g\) tend vers \( \infty\) plus vite que \( f\); si
\begin{equation}
    \lim_{x\to \infty} \frac{ f(x) }{ g(x) }=\infty
\end{equation}
nous disons que \( f\) tend vers \( \infty\) plus vite que \( g\), et si
\begin{equation}
    \lim_{x\to \infty} \frac{ f(x) }{ g(x) }=a\in \eR
\end{equation}
avec \( a\neq 0\) alors nous disons que \( f\) tend vers l'infini à la même vitesse que \( ag(x)\).

\begin{example}
    La fonction \( x\mapsto x^2\) tend vers l'infini plus vite que la fonction \( x\mapsto \sqrt{x}\).
\end{example}

Dans cette section nous allons nous contenter de déterminer les fonctions qui tendent vers l'infini aussi vite qu'une droite oblique, que nous appellons asymptote et que nous voulons déterminer.


\begin{example}
    Déterminer les asymptotes obliques (s'ils existent) de la fonction
    \begin{equation}
        f(x)= e^{1/x}\sqrt{1+4x^2}.
    \end{equation}
    Tout d'abord nous remarquons que \( \lim_{x\to \infty} f(x)=\infty\). Nous sommes donc en présence d'une branche du graphe qui tend vers l'infini. Ensuite,
    \begin{equation}
        \lim_{x\to \infty} \frac{ f(x) }{ x }=\lim_{x\to \infty}  e^{1/x}\sqrt{\frac{1}{ x^2 }+4}=2.
    \end{equation}
    Donc le graphe de \( f\) tend vers l'infini à la même vitesse que le graphe de la fonction \( y=2x\). Nous aurons donc une asymptote oblique de coefficient directeur \( 2\). De façon imagée, nous pouvons penser que le graphe de \( f\) et celui de \( y=2x\) sont presque parallèles si \( x\) est assez grand. Afin de déterminer l'ordonnée à l'origine de l'asymptote, il nous reste à voir quelle est la «distance» entre le graphe de \( f\) et celui de \( y=2x\) :
    \begin{equation}
        \lim_{x\to \infty} f(x)-2x=\lim_{x\to \infty}  e^{1/x}\sqrt{1+4x^2}-2x.
    \end{equation}
    Cette limite a été calculée dans l'exemple~\ref{ExBCDookjljhjk} et vaut $2$.

	Nous concluons que le graphe de la fonction $f$ admet l'asymptote
    \begin{equation}
	y=2x+2.
    \end{equation}
\end{example}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Développement en série}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Série génératrice d'une suite}
%---------------------------------------------------------------------------------------------------------------------------

Soit \( u_n\) une suite telle que le rayon de convergence de
\begin{equation}
    f(z)=\sum_{n=0}^{\infty}u_nz^n
\end{equation}
soit strictement positif. Alors la série \( f\) est la \defe{série génératrice}{série!génératrice d'une suite} de la suite \( (u_n)\).

Grâce au théorème~\ref{ProptzOIuG} nous pouvons la dériver terme à terme autour de \( z=0\). En utilisant la petite formule \eqref{EqSOFdwhw} nous trouvons
\begin{equation}    \label{EqNGhVCpP}
    f^{(l)}(z)=\sum_{n=l}^{\infty}u_n\frac{ n! }{ (n-l)! }z^{n-l},
\end{equation}
et donc
\begin{equation}
    u_l=\frac{ f^{(l)}(0) }{ l! }.
\end{equation}
D'où le nom de série génératrice. Cela est évidemment intéressant seulement si nous connaissons une autre forme pour \( f\) par ailleurs.

Nous en utiliserons une pour déterminer les partitions d'un nombre en parts fixes, proposition~\ref{PropWUFpuBR}.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Développement en série et Taylor}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}  \label{DefwmRzKh}
    Soit une fonction \( f\colon \eC\to \eC\) et \( z_0\in \eC\). Nous disons que \( f\) est \defe{développable en série entière}{développable!en série entière} dans un voisinage de \( z_0\) s'il existe une série \( \sum_n a_nz^n\) de rayon de convergence \( R>0\) et \( r\leq R\) tel que
    \begin{equation}
        f(z)=\sum_{n=0}^{\infty}a_n(z-z_0)^n
    \end{equation}
    pour tout \( z\in B(z_0,r)\).
\end{definition}

\begin{proposition}
    Si \( V\) est un ouvert dans \( \eC\) alors l'ensemble des fonctions \( V\to \eC\) développables en série entière forme une \( \eC\)-algèbre.
\end{proposition}

\begin{proof}
    Les séries entières passent aux sommes et aux produits en gardant des rayons de convergence non nuls.
\end{proof}

\begin{proposition} \label{ThoTGPtDj}
    Si \( f\) est développable en série entière à l'origine alors elle est \( C^{\infty}\) sur un voisinage de l'origine et le développement est celui de \defe{Taylor}{Taylor!série entière} :
    \begin{equation}
        f(x)=\sum_{n=0}^{\infty}\frac{ f^{(n)}(0) }{ n! }x^n
    \end{equation}
    pour tout \( x\) dans un voisinage de \( 0\).
\end{proposition}

\begin{proof}
    Si \( f(x)=\sum a_nx^n\), nous savons que \( f\) est \( C^1\) et que nous pouvons dériver terme à terme (au moins dans un voisinage). De plus le fait de dériver ne change pas le domaine. Par récurrence, la fonction est \( C^{\infty}\) sur le voisinage. En dérivant \( k\) fois la série \( \sum a_nx^n\) nous trouvons
    \begin{equation}
        f^{(k)}(x)=\sum_{n=k}^{\infty}n(n-1)\ldots (n-k+1)a_nx^{n-k}.
    \end{equation}
    En calculant en \( x=0\) nous trouvons
    \begin{equation}
        f^{(k)}(0)=k! a_k,
    \end{equation}
    d'où le terme général
    \begin{equation}
        a_k=\frac{ f^{(k)}(0) }{ k! }.
    \end{equation}
\end{proof}

Si \( f\) est une fonction et si la série
\begin{equation}
    T_f(x)=\sum_{n=0}^{\infty}\frac{ f^{(n)}(0) }{ n! }x^n
\end{equation}
converge, alors cette série est la \defe{série de Taylor}{série!Taylor} de \( f\).

\begin{remark}
    La série de Taylor d'une fonction n'est pas liée à sa fonction de façon aussi raide qu'on pourrait le croire. Même dans le cas d'une fonction \( C^{\infty}\) il peut arriver que \( T_f(x)\neq f(x)\).

    Il peut aussi arriver que \( f\) ne soit pas développable en série entières.
\end{remark}

\begin{example}
    Nous considérons la fonction
    \begin{equation}
        f(x)=\begin{cases}
            e^{-1/x^2}    &   \text{si } x\neq 0\\
            0    &    \text{si } x=0\text{.}
        \end{cases}
    \end{equation}
    Nous avons
    \begin{equation}
        f'(x)=\begin{cases}
            \frac{ 2 }{ x^3 } e^{-1/x^2}    &   \text{si } x\neq 0\\
            0    &    \text{si } x=0.
        \end{cases}
    \end{equation}
    Note : pour la seconde ligne nous devons faire explicitement le calcul
    \begin{equation}
        f'(0)=\lim_{t\to 0} \frac{ f(t)-f(0) }{ t }=\lim_{t\to 0} \frac{1}{ t } e^{-1/t^2}=0.
    \end{equation}
    Plus généralement nous avons \( f^{(k)}(0)=0\), et par conséquent la série de Taylor converge (trivialement) vers la fonction identiquement nulle.

    Cette fonction n'est donc pas développable en série entière vu qu'il n'existe aucun voisinage de zéro sur lequel la série de \( f\) coïncide avec \( f\).
\end{example}

\begin{example}     \label{ExwobBAW}
    Développement de \( f(x)=\arctan(x)\). Nous savons que
    \begin{equation}
        f'(x)=\frac{1}{ 1+x^2 },
    \end{equation}
    alors que nous connaissons le développement
    \begin{equation}    \label{EqVmuaqT}
        \frac{1}{ 1-x }=\sum_{n=0}^{\infty}x^n
    \end{equation}
    pour tout \( x\in B(0,1)\). Nous avons donc successivement
    \begin{subequations}
        \begin{align}
            \frac{1}{ 1+x }&=\sum_{n=0}(-x)^n\\
            \frac{ 1 }{ 1+x^2 }&=\sum_{n=0}(-1)^nx^{2n}\\
            \arctan(x)&=\sum_{n=1}^{\infty}(-1)^n\frac{ x^{2n+1} }{ 2n+1 }+C.
        \end{align}
    \end{subequations}
    Notons que dans la dernière nous avons évité d'écrire la somme depuis \( n=0\) (qui serait un terme constant) et nous avons écris explicitement «\( +C\)». Étant donné que \( \arctan(0)=0\), nous devons poser \( C=0\) et donc
    \begin{equation}
        \arctan(x)=\sum_{n=1}^{\infty}(-1)^n\frac{ x^{2n+1} }{ 2n+1 }.
    \end{equation}
\end{example}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Resommer une série}
%---------------------------------------------------------------------------------------------------------------------------

Nous avons vu comment trouver la série correspondant à une fonction donnée. Un exercice difficile consiste à trouver la fonction qui correspond à une somme donnée.

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Les sommes du type \texorpdfstring{$ \sum_nP(n)x^n$}{P}}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Pour calculer
\begin{equation}
    \sum_{n=0}^{\infty}P(n)x^n
\end{equation}
où \( P\) est un polynôme de degré \( m\) nous commençons par écrire
\begin{equation}
    P(n)=\alpha_0+\alpha_1(n+1)+\alpha_2(n+1)(n+2)+\cdots +\alpha_m(n+1)\ldots (n+m).
\end{equation}
Nous décomposons alors la somme en \( m\) sommes de la forme
\begin{equation}
    \sum_{n=0}^{\infty}\alpha_k\frac{ (n+k)! }{ n! }x^n=\alpha_k\left( \sum_{n=0}^{\infty}x^{n+k} \right)^{(k)}.
\end{equation}
Effectuons par exemple
\begin{equation}
    \sum_{n=0}^{\infty}x^{n+3}=\frac{1}{ 1-x }-1-x-x^2
\end{equation}
Notons que dans un usage pratique, ce terme devra être ensuite dérivé trois fois, de telle manière que les termes «correctifs» n'interviennent pas. Cette méthode ne demande donc que de calculer les dérivées successives de \( 1/(1-x)\).

\begin{example}
    Calculons la fonction
    \begin{equation}
        f(x)=\sum_{n=0}^{\infty}n^3x^n.
    \end{equation}
    D'abord nous écrivons
    \begin{equation}
        n^3=-1+7(n+1)-6(n+1)(n+2)+(n+1)(n+2)(n+3).
    \end{equation}
    Nous avons
    \begin{equation}
        \sum_{n=0}^{\infty}(n+1)x^n=\left( \sum_{n=0}^{\infty}x^{n+1} \right)'=\left( \frac{1}{ 1-x }-1 \right)'=\frac{1}{ (x-1)^2 }.
    \end{equation}
    De la même façon,
    \begin{subequations}
        \begin{align}
            \sum_n (n+1)(n+2)x^n&=\left( \sum x^{n+2} \right)''=\frac{ -2 }{ (x-1)^3 }\\
            \sum_n (n+1)(n+2)(n+3)x^n=\frac{ 6 }{ (x-1)^4 }.
        \end{align}
    \end{subequations}
    En remettant tout ensemble nous obtenons
    \begin{equation}
        \sum_{n=0}^{\infty}n^3x^n=-\frac{1}{ 1-x }+\frac{ 7 }{ (x-1)^2 }+\frac{ 12 }{ (x-1)^3 }+\frac{ 6 }{ (x-1)^4 }.
    \end{equation}

    Nous pouvons vérifier ce résultat en traçant les deux courbes et en remarquant qu'elles coïncident.
\begin{verbatim}
----------------------------------------------------------------------
| Sage Version 4.7.1, Release Date: 2011-08-11                       |
| Type notebook() for the GUI, and license() for information.        |
----------------------------------------------------------------------
sage: n=var('n')
sage: S(x)=sum(  [ n**3*x**n for n in range(0,30)  ]   )
sage: f(x)=-1/(1-x)+7/((x-1)**2)+12/((x-1)**3)+6/( (x-1)**4  )
sage: S(0.1)
0.214906264288980
sage: f(0.1)
0.214906264288981
sage: f.plot(-0.5,0.5)+S.plot(-0.5,0.5)
\end{verbatim}

\end{example}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Les sommes du type \texorpdfstring{$ \sum_nx^n/P(n)$}{P}}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Si \( P(n)\) a des racines entières, nous pouvons le décomposer en fractions simples et utiliser la somme
\begin{equation}
    \sum_{n=1}^{\infty}\frac{ x^n }{ n }=-\ln(1-x).
\end{equation}
Nous avons par exemple
\begin{subequations}
    \begin{align}
        \sum_{n=0}^{\infty}\frac{x^n}{ n+1 }&=\frac{1}{ x }\sum_{n=0}\frac{ x^{n+1} }{ n+1 }\\
        &=\frac{1}{ x }\sum_{n=1}^{\infty}\frac{ x^n }{ n }=-\frac{ \ln(1-x) }{ x }.
    \end{align}
\end{subequations}
Notez le changement de point de départ de la somme au passage.

Autre exemple :
\begin{subequations}
    \begin{align}
        \sum_{n=0}^{\infty}\frac{ x^n }{ n+3 }&=\frac{1}{ x^3 }\left( \sum_{n=1}^{\infty}\frac{ x^n }{ n }-x-\frac{ x^2 }{ 2 } \right)\\
        &=-\frac{ \ln(x-1) }{ x^3 }-\frac{1}{ x^2 }-\frac{1}{ 2x }.
    \end{align}
\end{subequations}

Si le polynôme possède des racines non entières, les choses se compliquent.

\begin{example}
Calculons
\begin{equation}
    \sum_{n=0}^{\infty}\frac{ x^n }{ 2n+1 }.
\end{equation}
Si \( x\geq\), en posant \( t=\sqrt{x}\) nous trouvons
\begin{equation}
    \sum_{n=0}^{\infty}\frac{ x^n }{ 2n+1 }=\frac{1}{ t }\sum_{n=0}^{\infty}\frac{ t^{2n+1} }{ 2n+1 }.
\end{equation}
Étudions
\begin{equation}
    H(t)=\sum_{n=0}^{\infty}\frac{ t^{2n+1} }{ 2n+1 }.
\end{equation}
Nous avons
\begin{equation}     \label{EqBuPjcM}
    H'(t)=\sum_{n=0}^{\infty}t^{2n}=\sum_{n=0}(t^2)^n=\frac{1}{ 1-t^2 }.
\end{equation}
Une primitive de cette fonction est
\begin{equation}
    \frac{ 1 }{2}\ln\left| \frac{ t+1 }{ t-1 } \right|.
\end{equation}
En \( t=0\), cette fonction vaut \( 0\) qui est la bonne valeur. Donc nous avons bien
\begin{equation}
    H(t)=\frac{ 1 }{2}\ln\left| \frac{ t+1 }{ t-1 } \right|.
\end{equation}

Notons que ce que l'équation \eqref{EqBuPjcM} nous dit est que \( H(t)\) est une primitive de \( 1/(1-t^2)\). Il faut choisir la bonne primitive en fixant une valeur.

Nous avons donc
\begin{equation}
    \sum_{n=0}^{\infty}\frac{ x^n }{ 2n+1 }=\frac{ 1 }{2\sqrt{x}}\ln\left| \frac{ \sqrt{x}+1 }{ \sqrt{x}-1 } \right|
\end{equation}
pour \( x>0\). Nous devons encore trouver ce que cela vaut pour \( x<0\).

    Nous posons successivement \( X=-x\) puis \( g(X)=f(-X)\). Ce que nous devons calculer est
    \begin{equation}
        g(t)=\frac{1}{ t }\sum_{n=0}^{\infty}\frac{ (-1)^nt^{2n+1} }{ 2n+1 }.
    \end{equation}
    Si nous posons
    \begin{equation}
        h(t)=\sum \frac{ (-1)^nt^{2n+1} }{ 2n+1 },
    \end{equation}
    alors
    \begin{equation}
        h'(t)=\sum (-1)^nt^{2n}=\sum (-t^2)^n=\frac{1}{ 1+t^2 },
    \end{equation}
    par conséquent \( h(t)=\arctan(t)\) (cela avait déjà été déduit à l'envers dans l'exemple~\ref{ExwobBAW}).

    Au final
    \begin{equation}        \label{EqIHlDjG}
        f(x)=\sum_{n=0}^{\infty}\frac{ x^n }{ 2n+1 }=\begin{cases}
            \frac{ 1 }{2\sqrt{x}}\ln\left| \frac{ \sqrt{x}+1 }{ \sqrt{x}-1 } \right|     &   \text{si } x>0\\
            \frac{ \arctan(\sqrt{-x}) }{ \sqrt{-x} }    &    \text{si } x<0\\
            1   &\text{si } x=0.
        \end{cases}
    \end{equation}
    Notons qu'elle est continue en zéro à gauche et à droite.

\end{example}

\begin{example}
Nous considérons l'exemple suivant :
\begin{equation}
    f(x)=\sum_{n=0}^{\infty}\frac{ x^n }{ 3n+2 }.
\end{equation}
Nous posons \( t=\sqrt[3]{x}\), et nous substituons :
\begin{equation}
    \frac{ x^n }{ 3n+2 }=\frac{ t^{3n} }{ 3n+2 }=\frac{1}{ t^2 }\frac{ t^{3n+2} }{ 3n+2 }.
\end{equation}
Nous devons étudier la fonction
\begin{equation}
    g(t)=\sum_{n=0}^{\infty}\frac{ t^{3n+2} }{ 3n+2 }
\end{equation}
Nous avons
\begin{equation}
    g'(t)=\sum_{n=0}t^{3n+1}=t\sum_{n=0}t^{3n}=\frac{ t }{ 1-t^3 }.
\end{equation}
Notons que \( g(0)=0\).
\end{example}

\begin{example}
    Calculer le nombre
    \begin{equation}        \label{EqgUyKYe}
        \sum_{n=0}^{\infty}\frac{ (-1)^n }{ 2n+1 }.
    \end{equation}
    Nous aurions envie de dire que cela est \( f(-1)\) pour la fonction \( f\) donnée en \eqref{EqIHlDjG}. Le problème est que le rayon de convergence de \( f\) étant \( 1\), rien n'est garantit quand au fait que la fonction y soit continue en \( x=-1\). En particulier nous devons justifier le fait que
    \begin{equation}
        \lim_{x\to -1} \sum_n\frac{ x^n }{ 2n+1 }=\lim_{x\to -1} \frac{1}{ \sqrt{-x} }\arctan(\sqrt{-x}).
    \end{equation}
    Ce qui nous sauve est le critère d'Abel radial (théorème~\ref{ThoLUXVjs}). En effet la série
    \begin{equation}        \label{EqAFrXRB}
        \sum\frac{ r^n }{ 2n+1 }
    \end{equation}
    étant convergente avec \( r=-1\), la série correspondante est continue sur \( \mathopen[ -1 , 0 \mathclose]\). Nous pouvons donc calculer la série \eqref{EqgUyKYe} en posant \( x=-1\) dans \eqref{EqIHlDjG} :
    \begin{equation}
        \sum_{n=0}^{\infty}\frac{ (-1)^n }{ 2n+1 }=\frac{ \pi }{ 4 }.
    \end{equation}

    Note : la série \eqref{EqAFrXRB} ne converge pas avec \( r=1\). La fonction \( f\) n'est pas continue en \( x=1\).
\end{example}

\begin{example}     \label{ExGxzLlP}
    Nous avons
    \begin{equation}
        \sum_{n=1}^{\infty}nx^{n-1}=\frac{1}{ (1-x)^2 }.
    \end{equation}
    En effet si nous désignons par \( f\) la somme à gauche, nous trouvons que \( f=g'\) avec
    \begin{equation}
        g(x)=\sum_{n=1}^{\infty}x^n.
    \end{equation}
    Nous savons par ailleurs que \( g(x)=1/(1-x)\). Par conséquent
    \begin{equation}
        f(x)=\left( \frac{1}{ 1-x } \right)'=\frac{1}{ (1-x)^2 }.
    \end{equation}
\end{example}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Sage, primitives et logarithme complexe}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

\begin{normaltext}\label{ooOPWYooDDSZWx}

Attention : Sage pourrait nous induire en erreur si nous n'y prenions pas garde. En effet ce que vous ne savez pas mais que Sage sait, c'est que
\begin{equation}
    \ln(-1)=i\pi.
\end{equation}
Par conséquent Sage se permet de donner des primitives sans valeurs absolues dans le logarithme :
\begin{verbatim}
sage: f(x)=1/x
sage: f.integrate(x)
x |--> log(x)
\end{verbatim}
La primitive à laquelle on s'attend d'habitude est \( \ln(| x |)\). Ici la réponse est correcte parce que si \( x\) est négatif nous avons
\begin{equation}
    \ln(x)=\ln\big( (-1)| x | \big)=\ln(-1)+\ln(| x |).
\end{equation}
Cette fonction est donc décalée de la primitive usuelle seulement de la constante \( \ln(-1)\).

Un exemple plus élaboré :
\begin{verbatim}
sage: h(x)=1/(1-x**2)
sage: H=h.integrate(x)
sage: H
x |--> -1/2*log(x - 1) + 1/2*log(x + 1)
sage: H(0)
-1/2*I*pi
\end{verbatim}
\end{normaltext}

\begin{example}
Encore une fois il faut faire attention en demandant la primitive à Sage :
\begin{verbatim}
----------------------------------------------------------------------
| Sage Version 4.7.1, Release Date: 2011-08-11                       |
| Type notebook() for the GUI, and license() for information.        |
----------------------------------------------------------------------
sage: f(x)=x/(1-x**3)
sage: F=f.integrate(x)
sage: F(0)
-1/3*I*pi - 1/3*sqrt(3)*arctan(1/3*sqrt(3))
\end{verbatim}
Cette fois la primitive proposée diffère de celle qu'on cherche de la constante complexe
\begin{equation}
    -\frac{ \pi }{ 3 }i.
\end{equation}
Mais il y a pire si nous voulons tracer. Nous voudrions définir la fonction \( F_2(x)=F(x)-F(0)\). Mathématiquement c'est bien de cette fonction que nous parlons, mais :
\begin{verbatim}
sage: F2(x)=F(x)-F(0)
sage: F2(x)
1/3*I*pi - 1/3*sqrt(3)*arctan(1/3*(2*x + 1)*sqrt(3)) +
    +1/3*sqrt(3)*arctan(1/3*sqrt(3)) - 1/3*log(x - 1) + 1/6*log(x^2 + x + 1)
sage: F2.plot(x,-0.1,0.1)
verbose 0 (4101: plot.py, generate_plot_points) 
        WARNING: When plotting, failed to evaluate function at 200 points.
verbose 0 (4101: plot.py, generate_plot_points) 
        Last error message: 'unable to simplify to float approximation'
\end{verbatim}
Il refuse de tracer. Pourquoi ? La partie complexe de l'expression de \( F_2\) est mathématiquement nulle, mais elle est en deux parties :
\begin{equation}
    \frac{ \pi }{ 3 }+\text{la partie imaginaire de} -\frac{1}{ 3 }\ln(x-1).
\end{equation}
Lorsque Sage tente de tracer, il donne à \( x\) un certain nombre de valeurs et calcule une \emph{valeur approchée} de \( \ln(x-1)\). Cette dernière ne se simplifie pas avec le nombre \emph{exact} \( \pi/3\). Sage reste donc avec une partie imaginaire qu'il ne peut pas tracer.

Notez la nuance :
\begin{verbatim}
sage: ln(-0.1)
-2.30258509299405 + 3.14159265358979*I
sage: ln(-1/10)
I*pi + log(1/10)
\end{verbatim}
Du coup nous avons aussi
\begin{verbatim}
sage: F2(-0.1)
1/3*I*pi - 1/3*sqrt(3)*arctan(0.266666666666667*sqrt(3))
    + 1/3*sqrt(3)*arctan(1/3*sqrt(3)) - 0.0474885065133152 - 1.04719755119660*I
\end{verbatim}

\end{example}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Nombres de Bell}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Ici nous montrerions bien le théorème~\ref{ThoYFAzwSg} sur les nombres de Bell parce que c'est essentiellement un résultat sur les séries entières et leurs manipulations. Hélas, il demande un tout petit peu d'équation différentielle (presque rien). Donc il est postposé jusqu'en page \pageref{ThoYFAzwSg}.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Séries entières de matrices}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\label{secEVnZXgf}

Nous nous proposons d'étudier des séries de la forme
\begin{equation}
    \sum_{k=0}^{\infty}a_kA^k
\end{equation}
où \( A\) est une matrice. L'essentiel de la théorie va rester. Nous considérons une norme algébrique (définition~\ref{DefJWRWQue}), c'est-à-dire \( \| AB \|\leq \| A \|\| B \|\).

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Rayon de convergence}
%---------------------------------------------------------------------------------------------------------------------------

La notion de rayon de convergence de cette série reste la même : c'est la définition~\ref{DefZWKOZOl} qui ne dépend que des coefficients \( a_k\) et pas du tout de ce qu'on met à côté dans la somme. Évidemment il faudra montrer que dans le cas des matrices, le nom «rayon de convergence» n'est pas usurpé.

\begin{proposition} \label{PropFIPooSSmJDQ}
    Soit \( (a_n)\) une suite dans \( \eC\) de rayon de convergence \( R\) et \( A\in \eM(n,\eR)\) une matrice vérifiant \( \| A \|<R\). Alors la série
    \begin{equation}
        \sum_{k=0}^{\infty}a_kA^k
    \end{equation}
    converge absolument, c'est-à-dire que \( \sum_k\| a_kA^k \|<\infty\).
\end{proposition}

\begin{proof}
    Nous avons les majorations
    \begin{equation}
        \| a_n A^n\|\leq | a_n |\| A^n \|\leq | a_n |\| A \|^n.
    \end{equation}
    Par hypothèse \( \| A \|<R\) et \( R\) est un supremum, donc il existe \( r\) tel que \( \| A \|<r<R\) avec \( (a_nr^n)\) borné. Nommons \( M\) un majorant de la suite \( (a_nr^n)\). Alors nous avons
    \begin{equation}
        \| A_nA^n \|\leq | a_n |r^n\frac{ \| A \|^n }{ r^n }\leq M\left( \frac{ \| A \| }{ r } \right)^n.
    \end{equation}
    La série du membre de droite converge parce que c'est une série géométrique de raison plus petite que \( 1\); voir l'exemple~\ref{ExZMhWtJS}.
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Convergence et rayon spectral}
%---------------------------------------------------------------------------------------------------------------------------

Le concept de rayon spectral permet aussi de donner des informations sur la convergence de séries de matrices. Pour rappel le rayon spectral d'une matrice est le maximum du module de ses valeurs propres (définition~\ref{DEFooEAUKooSsjqaL}). Le rayon spectral de la matrice \( A\) est noté \( \rho(A)\).

La proposition suivante sera redémontrée indépendamment dans le théorème~\ref{THOooMNLGooKETwhh}.

\begin{proposition}[\cite{fJhCTE}]      \label{PROPooDJFLooBqqEPT}
    Si \( A\in \eM(n,\eC)\) est telle que \( \rho(A)<1\), alors \( A^n\to 0\).
\end{proposition}

\begin{proof}
    Nous nous plaçons dans une base des espaces caractéristiques\footnote{Voir le théorème~\ref{ThoSpectraluRMLok}} de \( A\), c'est-à-dire que nous supposons que la matrice \( A\) a la forme
    \begin{equation}        \label{EqWMvkgLo}
        A=\begin{pmatrix}
            \lambda_1\mtu+N_1    &       &       \\
                &   \ddots    &       \\
                &       &   \lambda_s\mtu+N_s
        \end{pmatrix}
    \end{equation}
    où les \( \lambda_i\) sont les valeurs propres de \( A\) et les \( N_i\) sont nilpotentes. En effet nous savons que l'espace caractéristique \( F_{\lambda_i}\) est l'espace de nilpolence de \( A-\lambda_i\mtu\). Si nous notons \( A_i\) la restriction de \( A\) à cet espace, la matrice \( N_i=A_i-\lambda_i\mtu\) est nilpotente. Du coup \( A_i=\lambda_I\mtu+N_i\) et nous avons bien la décomposition \eqref{EqWMvkgLo}.

    Nous avons donc \( A^n\to 0\) si et seulement si \( (N_i+\lambda_i\mtu)^n\to 0\) pour tout \( i\). Soit donc \( N\) nilpotente et \( \lambda<1\) (parce que nous savons que toutes les valeurs propres de \( A\) sont inférieures à un). Nous avons
    \begin{equation}
            (\lambda\mtu+N)^n=\sum_{k=0}^n\binom{ n }{ k }\lambda^{n-k}N^{k}
            =\sum_{k=0}^{r-1}\binom{ n }{ k }\lambda^{n-k}N^{k}.
    \end{equation}
    Nous voyons que le nombre de termes dans la somme ne dépend pas de \( n\). De plus pour chacun de termes, la puissance de \( N\) ne dépend pas non plus de \( n\). Le terme
    \begin{equation}
        \binom{ n }{ k }\lambda^{n-k}\leq P(n)\lambda^{n-k}
    \end{equation}
    où \( P\) est un polynôme tend vers zéro lorsque \( n\) devient grand parce que c'est une cas polynôme fois exponentielle.
\end{proof}

\begin{theorem}[Thème~\ref{THEMEooPQKDooTAVKFH}\cite{ooETMNooSrtWet}]   \label{THOooMNLGooKETwhh}
    Soit \( A\in \eM(n,\eK)\) (\( \eK=\eR\) ou \( \eC\)). Les affirmations suivantes sont équivalentes.
    \begin{enumerate}
        \item       \label{ITEMooCGLSooZsMXSt}
            \( \lim_{k\to \infty} A^k=0\)
        \item       \label{ITEMooYBGEooXAzVbD}
            \( \rho(A)<1\)
        \item       \label{ITEMooEJSQooTqkBbo}
            \( \sum_{k=0}^{\infty}A^k\) converge.
    \end{enumerate}
    Dans le cas où ces conditions sont vérifiées, nous avons aussi
    \begin{itemize}
        \item \( \mtu-A\) est inversible,
        \item
        \(\sum_{k=0}^{\infty}A^k=(\mtu - A)^{-1}\)
    \end{itemize}
\end{theorem}

\begin{proof}
    Nous supposons qu'une norme est donnée sur \( \eK^n\) et nous considérons sur \( \eM(n,\eK)\) la topologie associée à la norme subordonnée\footnote{Si on parle de convergence d'une suite, c'est qu'il y a une topologie quelque part.}. Nous subdivisons la preuves en différentes implications.
    \begin{subproof}
        \item[\ref{ITEMooCGLSooZsMXSt} implique~\ref{ITEMooYBGEooXAzVbD}]
            Si \( \rho(A)\leq 1\), en combinant la proposition~\ref{PROPooWZJBooTPLSZp} avec la proposition~\ref{PROPooYPLGooWKLbPA}, nous avons
            \begin{equation}
                \| A^m \|\geq \big( \rho(A) \big)^m\geq 1
            \end{equation}

            Mais la limite \( A^k\stackrel{\eM(n,\eK)}{\longrightarrow} 0\) signifie la limite \( \| A^k \|\stackrel{\eR}{\longrightarrow}0\). Le fait que tous les éléments de la suite soient plus grand que \( 1\) empêche cette limite.
        \item[\ref{ITEMooYBGEooXAzVbD} implique~\ref{ITEMooCGLSooZsMXSt}]

            Vu que \( \rho(A)<1\), il existe \( \epsilon>0\) tel que \( \rho(A)+\epsilon<1\). Par le lemme~\ref{LEMooGBLJooCPvxNl} il existe une norme \( N\) sur \( \eM(n,\eK)\) telle que \( N(A)\leq \rho(A)+\epsilon<1\). Notons que cette norme \( N\) dépend de \( A\) et de \( \epsilon\).

            Avec cette norme nous avons
            \begin{equation}
                N(A^k)\leq N(A)^k\stackrel{\eR}{\longrightarrow}0.
            \end{equation}
            Cela signifie que \( A^k\stackrel{N}{\longrightarrow}0\). L'équivalence entre toutes les normes sur \( \eM(n,\eK)\) donne alors la convergence \( A^k\stackrel{\| . \|}{\longrightarrow}0\).

            Pour une preuve alternative de cette implication, voir la proposition~\ref{PROPooDJFLooBqqEPT}.

        \item[\ref{ITEMooEJSQooTqkBbo} implique~\ref{ITEMooCGLSooZsMXSt}]

            La convergence d'une série implique que la norme du terme général converge vers zéro par la proposition~\ref{PROPooYDFUooTGnYQg}. Nous avons donc \( \| A^k \|\to 0\), ce qui signifie \( A^k\to 0\), et donc \( \rho(A)<1\) parce que~\ref{ITEMooCGLSooZsMXSt} implique~\ref{ITEMooYBGEooXAzVbD}.

        \item[\( \rho(A)<1\) implique \( \mtu-A\) est inversible]

            Si \( \mu\) est une valeur propre de \( \mtu-A\) alors
            \begin{equation}
                \det\big( (\mtu-A)-\mu\mtu \big)=\det\big( A-(1-\mu)\mtu \big),
            \end{equation}
            donc \( 1-\mu\) est une valeur propre de \( A\). Donc les valeurs propres de \( \mtu-A\) sont les nombres \( 1-\lambda_i\) où les \( \lambda\i\) sont les valeurs propres de \( A\). Par hypothèse, nous avons \( \lambda_i<1\) pour tout \( i\), donc les valeurs propres de \( \mtu-A\) sont toutes non nulles. Donc \( \mtu-A\) est inversible (pas de noyau).

        \item[Le reste]
            Nous montrons à présent que si \( \rho(A)<1\) alors \( \sum_{k=0}^{\infty}A^k\) converge vers \(\mtu-A\). Pour cela nous savons déjà que \( \mtu-A\) est inversible. Nous posons
            \begin{equation}
                B_m=\mtu+A+\ldots +A^m,
            \end{equation}
            ce qui donne immédiatement \( AB_m=A+A^2+\ldots +A^{m+1}\). Nous avons donc
            \begin{equation}
                (\mtu-A)B_m=\mtu-A^{m+1}.
            \end{equation}
            Nous savons que \( \lim_{m\to0}A^m=0\), donc
            \begin{equation}
                (\mtu-A)\sum_{k=0}^{\infty}A^k=\lim_{k\to \infty} (\mtu-A)B_k=\lim_{k\to \infty} (\mtu-A^{k+1})=\mtu.
            \end{equation}
            Notez au passage que nous avons permuté la somme avec le produit matriciel (voir~\ref{SUBSECooOAWAooFcyUfI}).
    \end{subproof}
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Exponentielle et logarithme de matrice}
%---------------------------------------------------------------------------------------------------------------------------
\label{subsecXNcaQfZ}

La définition de l'exponentielle dans le cas des matrices est celle sur les algèbres normées non commutatives,~\ref{THOooFGTQooZPiVLO}.
\begin{proposition} \label{PropXFfOiOb}
    L'application
    \begin{equation}
        \begin{aligned}
            \exp\colon \eM(n,\eR)&\to \eM(n,\eR) \\
            A&\mapsto \sum_{k=0}^{\infty}\frac{ A^k }{ k! }
        \end{aligned}
    \end{equation}
    est une application de classe \(  C^{\infty}\). Sa différentielle en zéro est l'identité : \( (d\exp)_0=\id\).
\end{proposition}
\index{exponentielle!de matrice}

\begin{proof}
    En ce qui concerne la continuité, nous savons que le rayon de convergence de la suite \( \frac{1}{ k! }\) est infini; la proposition~\ref{PropQIIURAh} conclu.

    Pour la différentielle, c'est la proposition~\ref{PropAMBXKgV} qui nous permet d'écrire
    \begin{equation}
        d\exp_0(U)=\Dsdd{ \exp(tU) }{t}{0}=\Dsdd{ \sum_{k=0}^{\infty}\frac{ t^kU^k }{ k! } }{t}{0}=\left. \sum_{k=0}^{\infty}\frac{ kt^{k-1}U^k }{ k! }\right|_{t=0}=U
    \end{equation}
    parce que seul le terme \( k=1\) n'est pas nul.
\end{proof}

Nous avons vu par la proposition~\ref{PropKKdmnkD} que toute matrice complexe inversible a un logarithme. Nous allons maintenant parler de logarithme de matrices réelles avec une condition sur la norme. La formule ci-dessous montre explicitement que le logarithme est réel.
\begin{equation}
    \begin{aligned}
        \ln\colon \{ A\in \eM(n,\eR)\tq \| A-\mtu \| <1 \}&\to \eM(n,\eR) \\
        A&\mapsto \sum_{k=0}^{\infty}(-1)^k\frac{ (A-\mtu)^{k+1} }{ k+1 }.
    \end{aligned}
\end{equation}

\begin{lemma}   \label{LemQZIQxaB}
    Si \( \| m \|<1\) dans \( \eM(n,\eR)\), alors nous posons
    \begin{equation}    \label{EqIKgMabb}
        \ln(\mtu+m)=\sum_{k=0}^{\infty}(-1)^k\frac{ m^{k+1} }{ k+1 }.
    \end{equation}
    Cette fonction a les propriétés suivantes.
    \begin{enumerate}
        \item
            Elle est de classe \(  C^{\infty}\).
        \item
            Elle est un bon logarithme au sens où
            \begin{equation}
                e^{\ln(\mtu+m)}=\mtu+m.
            \end{equation}
        \item
            Elle vérifie l'approximation
            \begin{equation}
                \ln(1+m)=m+\sigma(m)
            \end{equation}
            où \( \sigma\) a la propriété que
            \begin{equation}
                \lim_{k\to \infty} k\sigma\left( \frac{ m }{ k } \right)=0.
            \end{equation}
    \end{enumerate}
\end{lemma}
\index{logarithme!de matrice}
%TODO : le reste de la preuve, en particulier le point avec l'exponentielle.

\begin{proof}

    Le rayon de convergence de la suite \( a_k=\frac{ (-1)^k }{ k+1 }\) est \( 1\). Donc l'application donnée est \(  C^{\infty}\) sur \( B(0,1)\) par le théorème~\ref{PropQIIURAh}.

    D'après la formule \eqref{EqIKgMabb} nous avons
    \begin{equation}
        \sigma(m)=\sum_{l=1}^{\infty}(-1)^l\frac{ m^{l+1} }{ l+1 }.
    \end{equation}
    Nous avons alors
    \begin{equation}
        k\sigma(\frac{ m }{ k })=\sum_{l=1}^{\infty}(-1)^l\frac{ m^{l+1} }{ k^l(l+1) },
    \end{equation}
    et donc
    \begin{equation}
        \| k\sigma(\frac{ m }{ k }) \|\leq \sum_{l=1}^{\infty}\frac{ \| m \|^{l+1} }{ k^l(l+1) }\leq\frac{1}{ k }\sum_{l=1}^{\infty}\frac{ \| m \|^{l+1} }{ l+1 }\stackrel{k\to\infty}{\to} 0
    \end{equation}
    Cela prouve la dernière assertion.
\end{proof}

\begin{proposition}
    Soit \( V\) un espace vectoriel de dimension finie et \( A\in\End(V)\). Nous considérons la fonction
    \begin{equation}
        \begin{aligned}
            f\colon \eR&\to \End(V) \\
            t&\mapsto  e^{tA}.
        \end{aligned}
    \end{equation}
    Cette fonction vérifie
    \begin{equation}
        f'(t)=\big(  e^{tA} \big)'=A e^{tA}.
    \end{equation}
\end{proposition}

\begin{proof}
    Si nous posons \( f_k(t)=\frac{ t^kA^k }{ k! }\) alors la fonction \( f\) est la somme : \( f=\sum_{k=0}^{\infty}f_k\). Nous allons permuter la somme et la dérivation à l'aide du théorème~\ref{ThoLDpRmXQ}. Vu que
    \begin{equation}
        f'_k(t)=\frac{ kt^{k-1}A^k }{ k! },
    \end{equation}
    la suite suite des dérivées converge normalement sur \( \eR\), nous pouvons dériver terme à terme pour obtenir
    \begin{equation}
        \Big( \sum_{k=0}^{\infty}t^k\frac{ A^k }{ k! } \Big)=\sum_{k=0}^{\infty}kt^{k-1}\frac{ A^k }{ k! }=\sum_{k=1}^{\infty}kt^{k-1}\frac{ A^k }{ k! }=A\sum_{k=1}^{\infty}\frac{ A^{k-1}t^{k-1} }{ (k-1)! }=A e^{tA}.
    \end{equation}
    Notez le jeu au niveau du point départ de la somme : elle passe de \( 0\) à \( 1\) parce que le terme zéro est nul, mais la simplification \( \frac{ k }{ k! }=\frac{ 1 }{ (k-1)! }\) n'a pas de sens pour \( k=0\).
\end{proof}

\begin{lemma}[\cite{DOAooAgGKTi}]   \label{LemQEARooLRXEef}
    Soit \( A\in\End(V)\) où \( V\) est un espace vectoriel réel de dimension finie. Si nous notons \( \lambda_i\) (\( i=1,\ldots, r\)) les valeurs propres distinctes de $A$ alors il existe un polynôme \( P\in \eR[X]\) tel que
    \begin{equation}
        \|  e^{tA} \|\leq P\big( | t | \big)\sum_{i=1}^r e^{t\real(\lambda_i)}.
    \end{equation}
\end{lemma}

\begin{proof}
    Le polynôme caractéristique de \( A\) se note, d'après le corollaire~\ref{CorUNZooAZULXT} de la façon suivante :
    \begin{equation}
        \chi_A(X)=\prod_{i=1}^r(X-\lambda_i)^{m_i}
    \end{equation}
    où \( m_i\) est la multiplicité de la valeur propre \( \lambda_i\). Le lemme des noyaux~\ref{ThoDecompNoyayzzMWod} nous dit qu'en posant
    \begin{equation}
        V_i=\ker(A-\lambda_i\mtu)^{m_i}
    \end{equation}
    nous avons \( V=\bigoplus_{i=1}^rV_i\). Nous nommons \( p_i\colon V\to V\) la projection canonique de \( E\) sur \( V_i\) ainsi que \( x_i\) la composante de \( x\in V\) dans l'espace caractéristique \( V_i\) et nous posons \( A_i=p_i\circ A\). Les espaces caractéristiques sont stables par \( A\) (lemme~\ref{LemBLPooHMAoyJ}), donc \( (Ax_i)_i=Ax_i\). Par conséquent \( \sum_i A_ip_i=A\) parce que
    \begin{equation}
        \big( \sum_ip_iAp_i \big)(x)=\sum_i(Ax_i)_i=\sum_iAx_i=A\sum_ix_i=Ax.
    \end{equation}
    En ce qui concerne les puissances de \( A\) nous avons de même
    \begin{equation}
        A_i^nx_I=A_i\underbrace{A_i^{n-1}x_i}_{\in V_i}=AA_i^{n-1}x_i=A^nx_i,
    \end{equation}
    et donc
    \begin{equation}
        \sum_{i=1}^rA_i^np_i=A^n.
    \end{equation}
    En particulier,
    \begin{equation}    \label{EqPVIooGxwFBH}
        e^{tA}=\sum_i e^{tA_i}p_i.
    \end{equation}
    C'est de cette exponentielle de matrice que nous devons étudier la norme.

    La décomposition de Dunford du théorème~\ref{ThoRURcpW} est toujours un bon plan pour traiter avec les exponentielles : nous avons \( A=s+n\) avec
    \begin{equation}
        \begin{aligned}[]
            s&=\sum_k\lambda_kp_k,&n=\sum_k(A-\lambda_k\mtu)p_k.
        \end{aligned}
    \end{equation}
    Nous montrons que la décomposition de Dunford de \( p_iA\) est \( p_iA=p_is+p_in\). Nous avons
    \begin{equation}
        p_is=\sum_k\lambda_kp_ip_k=\lambda_ip_i
    \end{equation}
    qui est bien diagonalisable. De plus les espaces caractéristiques sont stables par \( n\), donc \( p_in\) est nilpotent. Enfin ils commutent :
    \begin{equation}    \label{EqNJIooDxKlxn}
        [p_is,p_in]=\lambda_i(p_in-p_inp_i).
    \end{equation}
    Vu que \( n\) préserve les espaces caractéristiques, lorsque \( v\in V_k\) avec \( k\neq i\) nous avons \( p_inp_iv=0\) et \( p_inv=0\). Mais si \( v\in V_i\) alors
    \begin{equation}
        p_inp_iv=p_inv=nv
    \end{equation}
    et \( p_inv=nv\), donc les opérateurs \( p_in\) et \( p_inp_i\) sont égaux et \eqref{EqNJIooDxKlxn} donne bien zéro. En ce qui concerne l'exponentielle de \( A_i\) nous avons
    \begin{equation}
        e^{p_iA}= e^{p_is} e^{p_in}= e^{\lambda_ip_i} \exp\big( (A-\lambda_i\mtu)p_i\big).
    \end{equation}

    Nous pouvons maintenant sérieusement nous attaquer à la norme de \(  e^{tA}\) de l'équation \eqref{EqPVIooGxwFBH}. D'abord nous avons \( \| p_i \|=1\) parce que l'opérateur \( p_i\) est l'identité sur au moins un vecteur (en fait tout ceux de l'espace caractéristique \( V_i\)). En utilisant les propriétés de la norme opérateur\footnote{Surtout le fait que ce soit une norme d'algèbre, lemme~\ref{LEMooFITMooBBBWGI}.}, nous trouvons dans un premier temps\footnote{Si les valeurs propres de \( A\) sont \( \lambda_i\), celles de \( tA\) sont \( t\lambda_i\).} :
    \begin{equation}
        \|  e^{tA} \|\leq \sum_{i=1}^r\|  e^{tA_i} \|\leq \sum_{i=1}^r|  e^{t\lambda_i} |\underbrace{\sum_{k=0}^{m_i}\frac{ | t |^k }{ k! }\| A-\lambda_i\mtu_i \|^k}_{=P_i( | t | }
    \end{equation}
    où \( \mtu_i\) est l'opérateur identité sur \( V_i\). Petit détail dans le calcul :
    \begin{equation}
        \|  e^{\lambda_ip_i} \|\leq \sum_{l=0}^{\infty}\frac{ \lambda_i^l }{ k! }\| p_i \|^l= e^{\lambda_i}.
    \end{equation}
    Notons que tous les termes de \( P_i(| t |)\) et \( P_i\big( | t | \big)\) sont positifs, de telle sorte que nous pouvons majorer en ajoutant des termes partout. À la place d'avoir \( P_i(| t |)\) comme coefficient de \( |  e^{t\lambda_i} |\) nous majorons en mettant \( \sum_{j=1}^rP_j(| t |)\) comme coefficient :
    \begin{equation}
        \|  e^{tA} \|\leq    \sum_{i=1}^r|  e^{t\lambda_i} |P_i\big( | t | \big)
        =\sum_{i=1}^r|  e^{t\lambda_i} |\sum_{j=1}^rP_j\big( | t | \big)=P\big( | t | \big)\sum_{i=1}^r e^{t\real(\lambda_i)}.
    \end{equation}
    L'arrivée de la partie réelle est une égalité usuelle pour les nombres complexes : $|  e^{a+bi} |= e^{a}|  e^{bi} |= e^{a}$.
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Calcul effectif de l'exponentielle d'une matrice}
%---------------------------------------------------------------------------------------------------------------------------
\label{SUBSECooGAHVooBRUFub}

Nous reprenons l'exemple de \cite{MneimneReduct}. Soit \( A\) une matrice dont le polynôme minimum s'écrit
\begin{equation}
    P(X)=(X-1)^2(X-2).
\end{equation}
Par le théorème~\ref{ThoDecompNoyayzzMWod} de décomposition des noyaux nous avons
\index{théorème!décomposition des noyaux!et exponentielle de matrice}
\begin{equation}
    E=\ker(A-1)^2\oplus\ker(A-2).
\end{equation}
En suivant les notations de ce théorème nous avons \( P_1(X)=(X-1)^2\), \( P_2(X)=X-2\) et
\begin{subequations}
    \begin{align}
        Q_1(X)&=X-2\\
        Q_2(X)&=(X-1)^2.
    \end{align}
\end{subequations}
Les polynômes \( R_i\) dont l'existence est assurée par le théorème de Bézout sont
\begin{equation}
    \begin{aligned}[]
        R_1(X)&=-X\\
        R_2(X)&=1.
    \end{aligned}
\end{equation}
Nous avons
\begin{equation}
    R_1Q_1+R_2Q_2=1.
\end{equation}
Le projecteur \( p_i\) sur \( \ker P_i\) est \( R_iQ_i\) :
\begin{equation}
    \begin{aligned}[]
        p_1&=-A(A-2)=\pr_{\ker(u-1)^2}\\
        p_2&=(A-1)^2=\pr_{\ker(u-2)}.
    \end{aligned}
\end{equation}
Passons maintenant au calcul de l'exponentielle\footnote{Définition~\ref{THOooFGTQooZPiVLO}. Thème~\ref{THEMEooKXSGooCsQNoY}}. Nous avons évidemment
\begin{equation}
    e^A=e^Ap_1+e^Ap_2.
\end{equation}
Étant donné que \( p_1\) est le projecteur sur le noyau de \( (A-1)^2\), nous avons
\begin{equation}
    e^Ap_1=ee^{A-1}p_1=ep_1+e(u-1)1=ep_1=-Ae(A-2).
\end{equation}
En effet \( e^{A-1}p_1=\sum_{k=0}^{\infty}(A-1)^k\circ p_1\). De la même façon nous avons
\begin{equation}
    e^Ap_2=e^2e^{A-2}p_2=e^2p_2=e^2(A-1)^2.
\end{equation}
Au final,
\begin{equation}
    e^A=-Ae(A-2)+e^2(A-1)^2.
\end{equation}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Lemme de Borel}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Fonctions plateaux}
%---------------------------------------------------------------------------------------------------------------------------
\label{subsecOSYAooXXCVjv}

Soient \( a<b<c<d\) dans \( \eR\). Nous voulons trouver une fonction \( f\in C^{\infty}(\eR)\) à valeurs positives telle que
\begin{enumerate}
    \item
        \( f(x)=1\) si \( x\in\mathopen[ b , c \mathclose]\)
    \item
        \( \supp(f)\subset\mathopen[ a , d \mathclose]\).
\end{enumerate}

Nous commençons par l'exemple classique de fonction \(  C^{\infty}\) qui n'est pas nulle partout :
\begin{equation}
    \varphi(x)=\begin{cases}
        e^{-1/x}    &   \text{si } x>0\\
        0    &    \text{sinon}.
    \end{cases}
\end{equation}
Il est facile de vérifier que \( \varphi\) est de classe \(  C^{\infty}\) parce que
$\lim_{x\to 0^+} e^{-1/x/} P(x) =0 $
pour tout polynôme \( P\). De plus c'est une fonction qui vaut zéro sur \( \mathopen] -\infty , 0 \mathclose]\). Ensuite nous construisons la fonction
\begin{equation}
    \psi_m(x)=1-\frac{ \int_0^x \varphi(t)dt }{ \int_0^m\varphi(t)dt}=\begin{cases}
        1    &   \text{si } x<0\\
        0    &    \text{si } x>m\\
        \text{positive} &\text{si } x\in\mathopen[ 0 , m \mathclose].
    \end{cases}
\end{equation}
Cette fonction est encore de classe $ C^{\infty}$. À partir de là nous considérons les fonctions
\begin{subequations}
    \begin{align}
        f_1(x)&=\psi_{d-c}(x-c)=\begin{cases}
            1    &   \text{si } x<c\\
            0    &    \text{si } x>d\\
            \text{positive} &\text{si } x\in\mathopen[ c , d \mathclose].
        \end{cases}\\
        f_2(x)&=\psi(b-a)(b-x)=\begin{cases}
            0    &   \text{si } x<a\\
            1    &    \text{si } x>b\\
            \text{positive} &\text{si } x\in \mathopen[ a , b \mathclose].
        \end{cases},
    \end{align}
\end{subequations}
et finalement la fonction suivante répond à la question des fonctions plateaux sur \( \eR\) :
\begin{equation}    \label{EqIHAFooXjfcll}
    f(x)=f_1(x)f_2(x).
\end{equation}
\index{fonction!définie par une intégrale}

Une variation sur le même thème est l'existence de fonctions infiniment dérivables à support compact, c'est-à-dire des fonctions dans \(  C^{\infty}_c(\eR^d)=\swD(\eR^d)\). Ces espaces ne sont pas vides, par exemple nous avons la fonction
\begin{equation}    \label{EqOBYNEMu}
    \xi(x)=\begin{cases}
        e^{-1/(1-| x |^2)}    &   \text{si } x\in B(0,1)\\
        0    &    \text{sinon}.
    \end{cases}
\end{equation}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Le lemme de Borel}
%---------------------------------------------------------------------------------------------------------------------------

\begin{lemma}[Lemme de Borel\cite{KXjFWKA}] \label{LemRENlIEL}
    Soit \( (a_n)\) une suite dans \( \eR\). Il existe une fonction \( u\in C^{\infty}(\eR)\) telle que \( u^{(k)}(0)=a_k\) pour tout \( k\geq 0\).
\end{lemma}
\index{lemme!Borel}
\index{prolongement!de fonctions!lemme de Borel}
\index{dérivabilité!lemme de Borel}

\begin{proof}
    Soit \( \varphi\in C^{\infty}_c(\eR)\) une fonction telle que \( \varphi(x)=1\) si \( | x |\leq \frac{ 1 }{2}\) et telle que \( \supp(\varphi)\subset\mathopen] -1 , 1 \mathclose[\).

    Nous commençons par considérer une suite de réels strictement positifs \( (\lambda_k)\) dont nous fixerons une valeur précise plus tard, et nous posons
    \begin{equation}
        f_k(x)=\varphi(\lambda_k x)\frac{ a_k }{ k! }x^k.
    \end{equation}
    Nous allons étudier la convergence et les propriétés de \( u(x)=\sum_{k=0}^{\infty}f_k(x)\).

    Calculons (formellement) la \( m\)\ieme dérivée de \( f_k\) :
    \begin{subequations}
        \begin{align}
            f_k^{(m)}(x)&=\frac{ a_k }{ k! }\sum_{l=0}^{m}\binom{ m }{ l }\lambda_k^{m-l}\varphi^{(m-l)}(\lambda_kx)(x^k)^{(l)}\\
            &=a_k\sum_{l=0}^{m}\binom{ l }{ m }\lambda_k^{m-l}\varphi^{(m-l)}(\lambda_kx)\frac{ x^{k-l} }{ (k-l)! }.
        \end{align}
    \end{subequations}
    Notons que nous travaillons à \( m\) fixé et que nous ne nous intéressons qu'aux termes avec \( k\) assez grand; nous pouvons donc supposer \( k\geq m\). De toutes façons pour \( \sum_{k=0}^mf_k\), on a la classe \(  C^{\infty}\), et la permutation de la somme avec tout ce qu'on veut. Vu que \( \varphi\) est continue à support compact nous pouvons poser
    \begin{equation}
        M_m=\max_{0\leq j\leq m}\| \varphi^{j} \|_{\infty}=\max_{0\leq j\leq m}\max_{x\in \eR}| \varphi^{(j)}(x) |.
    \end{equation}
    Nous continuons en nous fixant un \( x\in \eR\) et un \( k\geq m\).

    Si \( | x |>\frac{1}{ \lambda_k }\), alors \( \varphi^{(m)}(\lambda_kx)=0\) parce que \( \lambda_kx\) est strictement hors du support de \( \varphi\) qui est \( \mathopen] -1 , 1 \mathclose[\). Donc pour \( | x |>\frac{1}{ \lambda_k }\).

    Si par contre \( | x |\leq\frac{1}{ \lambda_k }\), nous avons les majorations
    \begin{subequations}
        \begin{align}
        | f^{(m)}_k(x) |&\leq  |a_k|\sum_{l=0}^{m}\binom{ l }{ m }|\lambda_k|^{m-l}\underbrace{\varphi^{(m-l)}(\lambda_kx)}_{\leq M_m}\frac{ 1 }{ (k-l)! }\underbrace{| x |^{k-l}}_{\leq (1/\lambda_k)^{k-l}}\\
        &\leq | a_k |M_m| \lambda_k |^{m-k}\frac{1}{ (k-m)! }\sum_{l=0}^{m}\binom{ m }{ l }\\
        &\leq \frac{ | a_k |M_m | \lambda_k |^{m-k}2^m }{ (k-m)! }\\
        &= \frac{ | a_k |M_m 2^m }{ (k-m)!  | \lambda_k |^{k-m} }       \label{EqQSPUaun}
        \end{align}
    \end{subequations}
    où pour faire disparaitre la somme de coefficients binomiaux, nous avons remarqué que \( \sum_{l=0}^m\binom{ m }{ l }\) est le nombre total de termes dans le développement de \( (a+b)^m\), c'est-à-dire \( 2^m\). Nous voulons, pour \( m\) fixé, étudier la convergence de la somme de cela. Notons que le \( 2^m\) n'a en particulier strictement aucune importance parce qu'on travaille à \( m\) fixé.

    Nous fixons maintenant la valeur des \( \lambda_k\) :
    \begin{equation}
        \lambda_k=\max\{ | a_k |,1 \}.
    \end{equation}
    Avec cela, en nous souvenant que nous n'étudions que les termes \( k>m\), le dénominateur de \eqref{EqQSPUaun} est réellement croissant en \( k\), donc nous avons la majoration
    \begin{equation}
        | f^{(m)}_k(x) |\leq \frac{ M_m2^m }{ (k-m)! }.
    \end{equation}
    Au final nous avons
    \begin{equation}
        \| f_k^{(m)} \|_{\infty}\leq \frac{ 2^mM_m }{ (k-m)! }.
    \end{equation}
    Et la somme de cela converge sans difficultés. Donc la série
    \begin{equation}
        u(x)=\sum_{k=0}^{\infty}f_k^{(m)}(x)
    \end{equation}
    converge normalement et donc uniformément sur \( \eR\). Nous pouvons alors permuter la somme et la dérivation par le théorème~\ref{ThoCSGaPY}. Donc
    \begin{equation}
        u^{(m)}=\sum_{k=0}^{\infty}f_k^{(m)}
    \end{equation}
    est continue. En particulier, pour évaluer en zéro, on peut faire
    \begin{equation}
        u^{(m)}(0)=\sum_{k=0}^{\infty}f_k^{(m)}(0).
    \end{equation}
    Nous avons
    \begin{equation}
        f_k(x)=\varphi(\lambda_kx)\frac{ a_k }{ k! }x^k.
    \end{equation}
    Pour calculer la dérivée en zéro, il suffit de la calculer sur un voisinage sur lequel \( \varphi(\lambda_kx)\) est la constante \( 1\); un tel voisinage existe pour tout \( k\). À ce moment le calcul est classique :
    \begin{equation}
        f_k^{(m)}(x)=\begin{cases}
            a_k    &   \text{si } k=m\\
            0    &    \text{sinon}.
        \end{cases}
    \end{equation}
    Finalement nous avons bien
    \begin{equation}
        u^{(m)}(0)=\sum_{k=0}^{\infty}f_k^{(m)}(0)=a_k.
    \end{equation}

\end{proof}

\begin{remark}
    Pour prouver le lemme de Borel, la première chose qui passe par la tête est la fonction toute simple
    \begin{equation}
        u(x)=\sum_{k=0}^{\infty}\frac{ a_k }{ k! }x^k.
    \end{equation}
    Évidemment si on calcule les dérivées successives de cette fonction, nous trouvons les bons résultats. Le problème est la convergence.  Rien qu'en prenant \( a_k=k!k^k\), la série ne converge pour aucun \( x\) positif. L'idée de multiplier chacun de \( f_k\) par une fonction plateau sur un petit intervalle autour de zéro a plusieurs avantages. D'abord on conserve les dérivées correctes parce qu'on ne touche pas à la valeur des \( f_k\) sur un petit voisinage. Ensuite cela ne modifie pas la continuité; et enfin en multipliant par \( \varphi(\lambda_kx)\), ça calme méchamment les divergences parce que \( \lambda_kx\) passe vite au dessus de \( 1\) (et donc en dehors du support de \( \varphi\)) si \( \lambda_k\) est grand. D'où le fait qu'il soit normal que les \( \lambda_k\) soient de l'ordre des \( a_k\).
\end{remark}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Nombres de Bell}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{theorem}[Nombres de Bell\cite{KXjFWKA}]  \label{ThoYFAzwSg}
    Soient \( n\geq 1\) et \( B_n\) le nombre de partitions distinctes de l'ensemble \( \{ 1,\ldots, n \}\) avec la convention que \( B_0=0\). Alors
    \begin{enumerate}
        \item
            La série entière
            \begin{equation}    \label{EqYCMGBmP}
                \sum_{n=0}^{\infty}\frac{ B_n }{ n! }x^n
            \end{equation}
            a un rayon de convergence \( R>0\) et sa somme est donnée par
            \begin{equation}
                f(x)= e^{ e^{x}-1}
            \end{equation}
            pour tout \( x\in\mathopen] -R , R \mathclose[\).
        \item
            Pour tout \( k\in \eN\),
            \begin{equation}
                B_n=\frac{1}{ e }\sum_{k=0}^{\infty}\frac{ k^n }{ k! }.
            \end{equation}
            \item
                Le rayon de convergence de la série \eqref{EqYCMGBmP} est en réalité infini : \( R=\infty\).
    \end{enumerate}
\end{theorem}
\index{anneau!de séries formelles}
\index{dénombrement!partitions de \( \{ 1,\ldots, n \} \)}
\index{série!numérique}
\index{série!entière}
\index{limite!inversion}

\begin{proof}
    \begin{enumerate}
        \item
            Soient \( n\geq 1\) et \( 0\leq k\leq n\). Nous notons \( E_k\) l'ensemble des partitions de \( \{ 1,\ldots, n+1 \}\) pour lesquelles le «paquet» contenant \( n+1\) soit de cardinal \( k+1\). Calculons le cardinal de \( E_k\).

            Pour construire un élément de \( E_k\), il faut d'abord prendre le nombre \( n+1\) et lui adjoindre \( k\) éléments choisis dans \( \{ 1,\ldots, n \}\), ce qui donne \( n\choose k\) possibilités. Ensuite il faut trouver une partition des \( (n+1)-(k+1)=n-k\) éléments restants, ce qui fait \( B_{n-k}\) possibilités. Donc
            \begin{equation}
                \Card(E_k)={n\choose k}B_{n-k}.
            \end{equation}
            L'intérêt des ensembles \( E_k\) est que \( \{ E_0,\ldots, E_n \}\) est une partition de l'ensemble des partitions de \( \{ 1,\ldots, n+1 \}\), c'est-à-dire que \( B_{n+1}=\sum_{k=0}^n\Card(E_k)\), ce qui va nous donner une relation de récurrence pour les \( B_n\) :
\begin{equation}
                    B_{n+1}=\sum_{k=0}^n\Card(E_k)
                   =\sum_{k=0}^n{n\choose k}B_{n-k}
                    =\sum_{l=0}^n{n\choose n-l}B_l
                    =\sum_{l=0}^n{n\choose l}B_l.
\end{equation}
où nous avons utilisé un petit changement de variables \( l=n-k\). Afin d'étudier la convergence de la série \eqref{EqYCMGBmP}, nous allons montrer par récurrence que pour tout \( n\), \( B_n<n!\). D'abord pour \( n=0\) c'est bon : \( B_1=1\) parce que la seule partition de \( \{ 1 \}\) est \( \{ 1 \}\). Supposons que l'inégalité soit vraie pour une certaine valeur \( k\), et montrons qu'elle est vraie pour la valeur \( k+1\) :
\begin{equation}
                    B_{k+1}=\sum_{l=0}^n{n\choose k}B_k
                   \leq \sum_{l=0}^n{n\choose k}k!
                    =k!\sum_{l=0}^k\underbrace{\frac{1}{ (n-k)! }}_{\leq 1}
                    \leq n!(n+1)
                    =(n+1)!
\end{equation}
            où nous avons utilisé la formule \( {n\choose k}=\frac{ n! }{ k!(n-k)! }\).

            Donc pour tout \( x\in \eR\) nous avons
            \begin{equation}
                0\leq \frac{ B_n }{ n! }| x^n |\leq | x |^n,
            \end{equation}
            et donc la série a un rayon de convergence au moins aussi grand que celui de la série géométrique, c'est-à-dire que \( 1\). Donc \( R\geq 1\). Nous nommons \( R\) ce rayon de convergence.

        \item

            Soit \( x\in\mathopen] -R , R \mathclose[\). Pour une telle valeur de \( x\) à l'intérieur du disque de convergence, la proposition~\ref{ProptzOIuG} nous permet de dériver terme à terme la série\footnote{C'est ici qu'on utilise la convention \( B_0=0\) et ça aura une influence sur le choix de la constante \( K\) plus bas.}
                \begin{equation}
                    f(x)=\sum_{k=0}^{\infty}\frac{ B_k }{ k! }x^k=1+\sum_{k=0}^{\infty}\frac{ B_{k+1} }{ (k+1)! }x^{k+1},
                \end{equation}
                pour obtenir
                \begin{subequations}
                    \begin{align}
                    f'(x)=\sum_{k=0}^{\infty}\frac{ B_{k+1} }{ (k+1) }(k+1)x^k&=\sum_{k=0}^{\infty}\frac{ B_{k+1} }{ k! }x^k\\
                        &=\sum_{k=0}^{\infty}\left( \sum_{l=0}^k{k\choose l}B_l \right)\frac{ x^k }{ k! }=\sum_{k=0}^{\infty}\left( \sum_{l=0}^k\frac{ B_l }{ l!(l-k)! } \right)x^k.
                    \end{align}
                \end{subequations}
                <++>
                En cette expression, nous reconnaissons un produit de Cauchy (proposition~\ref{ThokPTXYC}) avec \( a_l=\frac{ B_l }{ l! }\) et \( b_n=\frac{ 1 }{ n! }\). Vu que ce sont deux séries ayant un rayon de convergence plus grand que zéro, le produit a encore un rayon de convergence plus grand que zéro et nous pouvons prendre le produit des séries :
                \begin{equation}
                    f'(x)=\left( \sum_{l=0}^{\infty}\frac{ B_l }{ l! }x^l \right)\left( \sum_{k=0}^{\infty}\frac{1}{ k! }x^k \right)=f(x) e^{x}.
                \end{equation}
            Étudions l'équation différentielle \( y'=ye^x\). D'abord par un argument en lacet de chaussure\footnote{Genre ce qui est fait pour prouver~\ref{ThoRWOZooYJOGgR}\ref{ItemYTLTooSnfhOu}.}, une solution est de classe \(  C^{\infty}\). Ensuite si une solution est non nulle, elle est de signe constant. En effet si \( y(x_0)<0\) et \( y(x_1)=0\) (on choisit \( x_1\) minimum pour cette propriété parmi les nombres plus grands que \( x_0\)) alors il existe\footnote{Théorème de Rolle~\ref{ThoRolle}.} un \( t\in\mathopen] x_0 , x_1 \mathclose[\) tel que \( y'(t)>0\), ce qui donnerait \( y(t)>0\), ce qui contredirait la minimalité de \( x_1\).

                Nous prétendons\footnote{Ou alors on utilise le théorème~\ref{ThoNYEXqxO} avec \( M(x)=e^x\) dans les cas \( n=1\) et \( I=\mathopen] -R , R \mathclose[\).} que cette équation différentielle a un espace de solutions de dimension \( 1\). En effet, si \( y'=ye^x\) et \( g'=ge^x\) alors en posant \( \varphi=y/g\) nous obtenons tout de suite \( \varphi'=0\), ce qui signifie que \( \varphi\) est constante, ou encore que \( y\) et \( g\) sont multiples l'un de l'autre.

                 Si nous en trouvons une non nulle par n'importe quel moyen, c'est bon. Une solution étant dérivable est continue, donc l'équation \( f'=f e^{x}\) nous indique que \( f'\) est continue. Une solution non nulle va automatiquement accepter un petit voisinage sur lequel la manipulation suivante a un sens :
                    \begin{equation}
                        \frac{ f'(x) }{ f(x) }= e^{x},
                    \end{equation}
                    donc \( \ln\big( | f(x) | \big)= e^{x}+C\) et \( f(x)=K e^{ e^{x}}\) pour une certaine constante. Il est vite vérifié que cette fonction est une solution de l'équation différentielle \( y'(x)=y(x) e^{x}\) et par unicité, toutes les solutions sont de cette forme. Autrement dit, l'espace des solutions est l'espace vectoriel \( \Span\{ x\mapsto e^{e^x} \}\). Étant donné que \( f(0)=0\), nous devons choisir \( K=\frac{1}{ e }\) et donc
                    \begin{equation}
                        f(x)=\frac{1}{ e } e^{e^x}= e^{e^x-1}.
                    \end{equation}

                \item

                    Nous commençons par écrire la fonction \( f\) comme une série de puissance. La partie simple du calcul : pour \( x\in \mathopen] -R , R \mathclose[\), nous avons
                        \begin{equation}    \label{EqODjgjDN}
                        e^{e^x}=\sum_{k=0}^{\infty}\frac{ (e^x)^k }{ k! }=\sum_{k=0}^{\infty}\frac{1}{ k! }\sum_{l=0}^{\infty}\frac{ (kx)^l }{ l! }=\sum_{k=0}^{\infty}\sum_{l=0}^{\infty}\frac{k^l}{k! }\frac{ x^l }{ l! }.
                    \end{equation}
                    Notons que cela n'est pas une série de puissance en \( x\) parce qu'il y a la double somme. Nous allons inverser les sommes au moyen du théorème de Fubini sous la forme du corollaire~\ref{CorTKZKwP}. Pour cela nous considérons la fonction
                    \begin{equation}
                        \begin{aligned}
                            a\colon \eN\times \eN&\to \eR \\
                            (k,l)&\mapsto \frac{ (kx)^l }{ k!l! }
                        \end{aligned}
                    \end{equation}
                    et nous mettons la mesure de comptage\footnote{Nous passons outre les avertissements et menaces de Arnaud Girand.} sur \( \eN\) et \( \eN^2\). Nous commençons donc à vérifier l'intégrabilité variable par variable de \( | a |\) :
                    \begin{subequations}    \label{SubEqsFHsBfhk}
                        \begin{align}
                            \int_{\eN}\left( \int_{\eN}| a(k,l) |dm(l) \right)dm(k)&=\sum_{k=0}^{\infty}\frac{1}{ k! }\frac{ (k| x |)^l }{ l! }\\
                            &=\sum_{k=0}^{\infty}\frac{1}{ k! } e^{k| x |}.
                        \end{align}
                    \end{subequations}
                    Nous devons montrer que cette dernière somme va bien. Pour cela nous posons \( u_k=\frac{ e^{k| x |} }{ k! }\) et nous remarquons que \( \frac{ u_{k+1} }{ u_k }\to 0\). Donc la double intégrale \eqref{SubEqsFHsBfhk} converge, ergo \( a\in L^1(\eN\times \eN)\), ce qui nous permet d'utiliser le théorème de Fubini~\ref{ThoFubinioYLtPI} pour inverser les \sout{sommes} \sout{intégrales} sommes dans l'équation \eqref{EqODjgjDN} :
                    \begin{equation}
                        \frac{1}{ e }e^{e^x}=\frac{1}{ e }\sum_{k=0}^{\infty}\sum_{l=0}^{\infty}\frac{1}{ k! }\frac{1}{ l! }(kx)^l=\sum_{l=0}\frac{1}{ e }\frac{1}{ l! }\left( \sum_{k=0}^{\infty}\frac{ k^l }{ k! } \right)x^l.
                    \end{equation}
                    Cela est un développement en série entière pour la fonction \( \frac{1}{ e } e^{e^x}\), dont nous savions déjà le développement \eqref{EqYCMGBmP}; par unicité du développement nous pouvons identifier les coefficients :
                    \begin{equation}
                        B_l=\frac{1}{ e }\sum_{k=0}^{\infty}\frac{ k^l }{ k! }.
                    \end{equation}

                \item

                    Le développement \eqref{EqODjgjDN} étant en réalité valable pour tout \( x\) et tous les calculs subséquents l'étant aussi, le développement
                    \begin{equation}
                        e^{e^x-1}=\sum_{n=0}^{\infty}\frac{ B_n }{ n! }x^n
                    \end{equation}
                    est en fait valable pour tout \( x\), ce qui donne à la série entière un rayon de convergence infini.
    \end{enumerate}
\end{proof}
