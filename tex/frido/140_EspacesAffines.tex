% This is part of Mes notes de mathématique
% Copyright (c) 2011-2014,2020-2023, 2025
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Vecteurs agissant sur un espace}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{definition}
	Soit \( E\), un espace vectoriel. Un \defe{espace affine modelé sur}{affine!espace} \( E\) est un ensemble \( \affE\) sur lequel le groupe \( (E,+)\) agit à droite transitivement et librement\footnote{Définition \ref{DEFooQDHPooCfDEuL}.}.
\end{definition}

Étant donné que \( E\) est un groupe commutatif, l'action peut être vue indifféremment à gauche ou à droite. Si \( M\in\affE\) et si \( x\in E\) nous notons \( M+x\) au lieu de \( x\cdot M\) le résultat de l'action de \( x\) sur \( M\).

\begin{normaltext}      \label{NORMooZANAooQdXqlh}
	Lorsque nous écrivons «\( M+x\)», le symbole plus n'est pas une loi de composition interne de \( \affE\), mais une action.
\end{normaltext}

\begin{propositionDef}      \label{DEFooWAYTooMLbqEE}
	Soient \( N,M\in\affE\). Il existe un unique \( x\in E\) tel que \( M+x=N\).

	Nous noterons \( \vect{ MN }\) ce vecteur.
\end{propositionDef}

\begin{proof}
	La transitivité de l'action assure l'existence et la liberté assure l'unicité.
\end{proof}

\begin{lemma}       \label{LEMooFZCRooQxzObv}
	Pour tout élément \( A\) nous avons \( A+0=A\).
\end{lemma}

\begin{proof}
	Soit \( B\in \affE\). Nous avons :
	\begin{equation}
		B+0=B+(0+0)=(B+0)+0
	\end{equation}
	parce que le \( +\) dénote une action.

	En appliquant cette égalité à l'élément \( B=A-0\) nous trouvons l'égalité demandée.
\end{proof}

\begin{proposition}     \label{PROPooCOZCooCghwaR}
	Soit un espace affine \( \affE\) modelé sur l'espace vectoriel \( E\). Soient \( A,B,C\in \affE\). Nous avons les égalités suivantes dans \( E\) :
	\begin{enumerate}
		\item   \label{ITEMooSDMIooUQiKeW}
		      \( \vect{ AB }+\vect{ BC }=\vect{ AC }\) (relations de Chasles)\index{relations!de Chasles}\index{Chasles},
		\item   \label{ITEMooWZAVooGfGBwd}
		      \( \vect{ AA }=0\),
		\item   \label{ITEMooLDVXooFZMbsQ}
		      \( \vect{ BA }=-\vect{ AB }\).
	\end{enumerate}
\end{proposition}

\begin{proof}
	Point par point.
	\begin{subproof}
		\spitem[Pour \ref{ITEMooSDMIooUQiKeW}]
		Nous avons, par définition \ref{DEFooWAYTooMLbqEE} les égalités
		\begin{subequations}
			\begin{numcases}{}
				C=A+\vect{ AC }\\
				B=A+\vect{ AB }\\
				C=B+\vect{ BC }
			\end{numcases}
		\end{subequations}
		En substituant les deux premières dans la troisième, nous trouvons \( A+\vect{ AB }+\vect{ BC }=A+\vect{ AC }\). Par liberté de l'action, nous pouvons «simplifier» par \( A\) et trouver la relation de Chasles.
		\spitem[Pour \ref{ITEMooWZAVooGfGBwd}]
		Nous avons \( A+\vect{ AA }=A\), mais aussi \( A+0=A\). Par unicité nous avons \( \vect{ AA }=0\).
		\spitem[Pour \ref{ITEMooLDVXooFZMbsQ}]
		Nous avons \( B+\vect{ BA }=A\) et \( A+\vect{ AB }=B\). En mettant bout à bout,
		\begin{equation}
			B+\vect{ BA }+\vect{ AB }=B.
		\end{equation}
		Donc \( \vect{ BA }+\vect{ AB }=0\).
	\end{subproof}
\end{proof}

\begin{normaltext}      \label{NORMooXAJLooIupekj}
	Si \( E\) est un espace vectoriel, le groupe \( (E,+)\) agit sur \( E\) par l'action \( t_y(x)=y+x\). Utilisant cette action nous construisons l'\defe{espace affine canonique}{canonique!espace affine} de \( E\). En particulier nous notons \( \affE_n(\eK)\) l'espace affine canonique de \( \eK^n\) vu comme espace vectoriel sur \( \eK\).
	\begin{itemize}
		\item
		      En tant qu'ensembles, \( \affE_n(\eK)=\eK^n\).
		\item
		      Sur cet espace en particulier, si \( M,N\in\affE_n(\eK)\), nous avons \( \vect{ MN }=N-M\) où à droite, la différence est la différence vectorielle dans \(\eK^n\).
	\end{itemize}

	Ces deux points se généralisent immédiatement à un espace vectoriel \( E\) au lieu de \( \eK^n\).
\end{normaltext}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Repères cartésiens affines}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Soit \( E\) un \( \eK\)-espace vectoriel de dimension \( n\) et \( \affE\) un espace affine construit sur \( E\).
\begin{definition}      \label{DEFooQELZooEXvxgw}
	Un multiplet \( (A,e_1,\ldots, e_n)\) où \( A\) est un point de \( \affE\) et \( \{ e_i \}\) est une base de \( E\) est un \defe{repère cartésien}{repère!cartésien!espace affine} de \( \affE\).

	Nous disons que \( \{ e_i \}\) est la \defe{base associée}{base associée à un repère cartésien} au repère.
\end{definition}

\begin{proposition}
	Si \( \affE\) est un espace affine modelé sur l'espace vectoriel \( E\) de dimension \( n\) sur le corps \( \eK\), et si \(  \big( A,\{ e_i \}_{i=1,\ldots, n} \big)\) est un repère cartésien, alors
	\begin{equation}
		\begin{aligned}
			\phi\colon \eK^n  & \to \affE               \\
			(x_1,\ldots, x_n) & \mapsto A+\sum_ix_ie_i.
		\end{aligned}
	\end{equation}
	est une bijection.

	Ces nombres \( x_i\) sont les \defe{coordonnées}{coordonnées!dans un espace affine} du point \( A+\sum_ix_ie_i\) dans le repère \( (A,e_i)\).
\end{proposition}

\begin{proof}
	L'application \( \phi\) est surjective parce que l'action de \( E\) sur \( \affE\) est transitive et injective parce que l'action est libre.
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Classification affine des coniques}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Soit une conique \( f(x,y)=0\) avec
\begin{equation}
	f(x,y)=ax^2+2bxy+cy^2+2dx+2ey+f
\end{equation}
dans le repère \( R=(A,e_i)\).

\begin{lemma}[\cite{BIBooHKYXooLwkilK}]       \label{LEMooXZURooSVySRT}
	Nous considérons la forme quadratique
	\begin{equation}
		\begin{aligned}
			q\colon \eR^2 & \to \eR                   \\
			(x,y)         & \mapsto    ax^2+bxy+cy^2.
		\end{aligned}
	\end{equation}
	\begin{enumerate}
		\item
		      Si la signature de \( q\) est \( (1,1)\), alors il existe une bijection linéaire \(A \colon \eR^2\to \eR^2  \) telle que
		      \begin{equation}
			      (q\circ A)(x,y)=x^2-y^2.
		      \end{equation}
		\item
		      Si la signature de \( q\) est \( (2,0)\), alors il existe une bijection linéaire \(A \colon \eR^2\to \eR^2  \) telle que
		      \begin{equation}
			      (q\circ A)(x,y)=x^2+y^2.
		      \end{equation}
		\item
		      Si la signature de \( q\) est \( (1,0)\), alors il existe une bijection linéaire \(A \colon \eR^2\to \eR^2  \) telle que
		      \begin{equation}
			      (q\circ A)(x,y)=x^2.
		      \end{equation}
	\end{enumerate}
\end{lemma}

\begin{proof}
	Nous séparons selon la valeur de \( a\).
	\begin{subproof}
		\spitem[Si \( a\neq 0\)]
		%-----------------------------------------------------------
		Alors nous avons
		\begin{equation}
			q(x,y)=a\left( x+\frac{ b }{ 2a }y \right)^2+\left( \frac{ 4ax-b^2 }{ 4a } \right)y^2.
		\end{equation}
		Donc en posant \( \alpha=a\) et \( \beta=(4ac-b^2)/4a\), nous avons
		\begin{equation}
			q(x,y)=(f_{\alpha\beta}\circ A)(x,y)
		\end{equation}
		où
		\begin{equation}
			\begin{aligned}
				f_{\alpha\beta}\colon \eR^2 & \to \eR                       \\
				(x,y)                       & \mapsto \alpha x^2+\beta y^2.
			\end{aligned}
		\end{equation}
		Vu que \( A\) est une bijection linéaire, si \( q\) est positive sur \( E\), alors \(f_{\alpha\beta}=q\circ A^{-1} \) sera positive sur \( A(E)\). Donc \( f_{\alpha\beta}\) a la même signature que \( q\). La signature de \( f_{\alpha\beta}\) est facile : elle est donnée par les signes de \( \alpha\) et \( \beta\).

		Supposons que la signature de \( q\) soit \( (2,0)\) alors la signature de \( f_{\alpha\beta}\) est également \( (2,0)\), c'est-à-dire que \( \alpha,\beta>0\). Alors en posant
		\begin{equation}
			\begin{aligned}
				B_{\alpha\beta}\colon \eR^2 & \to \eR^2                                                                    \\
				(x,y)                       & \mapsto \left( \frac{1}{ \sqrt{\alpha}}x,\frac{1}{ \sqrt{ \beta }}y \right),
			\end{aligned}
		\end{equation}
		nous avons \( (f_{\alpha\beta}\circ B_{\alpha\beta})(x,y)=x^2+y^2\) et donc
		\begin{equation}
			(q\circ A^{-1}\circ B_{\alpha\beta})(x,y)=x^2+y^2,
		\end{equation}
		ce qu'il fallait.

		Les cas de signature \( (1,1)\) ou \( (0,1)\) se traitent de façon similaire. Voyons le cas de signature \( (0,1)\) pour le sport. Si la signature de \( f_{\alpha\beta}\) est \( (0,1)\) alors nous avons soit \( \alpha=0\) et \( \beta<0\) soit \( \alpha<0\) et \( \beta=0\). Dans le premier cas nous avons \( f_{\alpha\beta}(x,y)=-\beta'y^2\) avec \( \beta'=-\beta>0\). En posant
		\begin{equation}
			B_{\alpha\beta}(x,y)=\left( x,\frac{1}{ \sqrt{ \beta' }}y \right)
		\end{equation}
		nous avons \( (f_{\alpha\beta}\circ B_{\alpha\beta})(x,y)=y^2\).

		\spitem[Si \( a=0\)]
		%-----------------------------------------------------------
		Si \( b\neq 0\) nous avons tous les mêmes cas qu'avant, en inversant \( x\) et \( y\). Si \( b=0\) alors nous avons \( q(x,y)=xy^2\) qui est déjà sous la bonne forme.
	\end{subproof}
\end{proof}


Nous cherchons maintenant à savoir si un point \( I=(x_0,y_0)\) est un centre de symétrie de \( f(x,y)=0\). Pour cela nous choisissons le repère centré en \( I\), c'est-à-dire que nous posons
\begin{subequations}
	\begin{numcases}{}
		x=x_0+\tilde x\\
		y=y_0+\tilde y.
	\end{numcases}
\end{subequations}
Un peu de calcul montre qu'alors la conique s'écrit
\begin{equation}
	f(x_0,y_0)+q(\tilde x,\tilde y)+(2ax_0+2by_0+2d)\tilde x+(2bx_0+2cy_0+2e)\tilde y=0.
\end{equation}


\begin{lemma}       \label{LEMooMVIDooVEUJsp}
	Soit la forme quadratique
	\begin{equation}		\label{EQooMOPBooBkePFH}
		q(x,y)=ax^2+2bxy+cy^2+dx+ey+f.
	\end{equation}
	Le point \( (x_0,y_0)\) est un centre de symétrie de \( q\) si et seulement si
	\begin{subequations}\label{SyskhiOvW}
		\begin{numcases}{}
			2ax_0+2bx_0+d=0\\
			2bx_0+2cy_0+e=0,
		\end{numcases}
	\end{subequations}
	qui a lieu si et seulement si
	\begin{subequations}
		\begin{numcases}{}
			(\partial_xq)(x_0,y_0)=0\\
			(\partial_yq)(x_0,y_0)=0.
		\end{numcases}
	\end{subequations}
\end{lemma}

\begin{proof}

	Nous décomposons \( q\) en parties quadratiques, linéaires et constant :
	\begin{equation}
		q(x,y)=Q(x,y)+L(x,y)+f
	\end{equation}
	avec \( Q(x,y)=ax^2+2bxy+cy^2\) et \( L(x,y)=dx+ey\).

	Nous posons \( r(x,y)=q(x+x_0, y+y_0)\). Le point \( (x_0,y_0)\) sera centre de symétrie si et seulement si \( r(-x,-y)=r(x,y)\) pour tout \( (x,y)\in \eR^2\). Nous calculons donc un bon coup :
	\begin{subequations}
		\begin{align}
			q(x+x_0,y+y_0) & =Q(x,y)                                 \\
			               & \qquad +2ax_0x+ax_0^2         \nonumber \\
			               & \qquad +2by_0x+2bx_0y	\nonumber         \\
			               & \qquad+2bx_0y_0\nonumber                \\
			               & \qquad +2cy_0y+cy_0^2\nonumber          \\
			               & +L(x+x_0,y+y_0)+f.
		\end{align}
	\end{subequations}
	En développant encore un peu et en regroupant, nous trouvons
	\begin{equation}
		r(x,y)=Q(x,y)+S(x,y)+f'
	\end{equation}
	où
	\begin{subequations}
		\begin{align}
			S(x,y) & =(2ax_0+2by_0+d)x+(2bx_0+2cy_0+e)y   \\
			f'     & =f+ax_0^2+2bx_0y_0+cy_0^2+dx_0+ey_0.
		\end{align}
	\end{subequations}
	La condition \( r(-x,-y)=r(x,y)\) est équivalente à \( S(x,y)=0\) et donc à
	\begin{subequations}		\label{EQooJRYCooADgxxL}
		\begin{numcases}{}
			2ax_0+2bx_0+d=0\\
			2bx_0+2cy_0+e=0.
		\end{numcases}
	\end{subequations}

	Il suffit de calculer \( \partial_xq\) et \( \partial_yq\) directement sur l'expression \eqref{EQooMOPBooBkePFH} pour remarquer que les conditions \eqref{EQooJRYCooADgxxL} sont équivalentes à
	\begin{subequations}
		\begin{numcases}{}
			(\partial_xq)(x_0,y_0)=0\\
			(\partial_yq)(x_0,y_0)=0
		\end{numcases}
	\end{subequations}
\end{proof}

\begin{normaltext}
	Le fait que le centre de symétrie de \( q\) coïncide avec le point où le gradient de \( q\) s'annule semble être une simple coïncidence numérique. On a fait les deux calculs et on a trouvé le même résultat.

	Je suis certain qu'il y a une raison plus profonde. Si vous la connaissez, écrivez-moi.
\end{normaltext}


Nous supposons que \( (d,e)\neq (0,0)\), sinon la conique de départ serait déjà centrée. Le déterminant du système \eqref{SyskhiOvW} est
\begin{equation}
	\delta=ac-b^2.
\end{equation}
Si ce dernier est différent de zéro, le système possède une unique solution et la conique aura alors un unique centre de symétrie.

Si le déterminant du système est nul, il y a soit aucun centre de symétrie, soit une infinité. Dans le premier cas nous sommes en présence d'une parabole, et dans le second cas de deux droites parallèles.

\begin{example}
	Soit
	\begin{equation}    \label{EqOgsEcz}
		f(x,y)=x^2+2xy-y^2-6x+2y-1=0
	\end{equation}
	donnée dans le repère affine \( R=(A,\{ e_i \})\). Nous commençons par étudier la signature de \( q(x,y)=x^2+2xy-y^2\) dont la matrice symétrique est
	\begin{equation}
		Q=\begin{pmatrix}
			1 & 1  \\
			1 & -1
		\end{pmatrix}.
	\end{equation}
	Son polynôme caractéristique est \( \lambda^2-2\) dont les racines sont \( \pm\sqrt{2}\). La signature est donc \( (1,1)\) et nous sommes en présence d'une conique de genre hyperbole. Nous cherchons le centre en suivant le lemme \ref{LEMooMVIDooVEUJsp}. Nous posons \( x=\tilde x+x_0\), \( y=\tilde y+y_0\), et nous cherchons à résoudre le système
	\begin{subequations}
		\begin{numcases}{}
			x_0+y_0-3=0\\
			x_0-y_0+1=0.
		\end{numcases}
	\end{subequations}
	L'unique solution est \( (x_0,y_0)=(1,2)\). Nous considérons le repère centré en \( (x_0,y_0)\), c'est-à-dire le repère
	\begin{equation}
		R'=(I,\{ e_i \})
	\end{equation}
	avec \( I=A+x_0e_1+y_0e_2\) où \( A\) est l'origine du repère dans lequel l'équation \eqref{EqOgsEcz} était donnée.

	Par construction dans ce repère nous avons la conique
	\begin{equation}
		f(x_0,y_0)+q(\tilde x,\tilde y)=0,
	\end{equation}
	c'est-à-dire
	\begin{equation}
		\tilde x^2+2\tilde x\tilde y-\tilde y^2 -2 = 0.
	\end{equation}
	Maintenant, nous avons une quadrique centrée que nous voulons mettre sous une forme plus canonique :
	\begin{equation}
		\left( \frac{1}{ \sqrt{2} }(\tilde x+\tilde y) \right)^2-\tilde y^2-1=0.
	\end{equation}
	Nous posons donc
	\begin{subequations}
		\begin{numcases}{}
			X=\frac{1}{ \sqrt{2} }(\tilde x+\tilde y)\\
			Y=\tilde y,
		\end{numcases}
	\end{subequations}
	pour trouver l'hyperbole
	\begin{equation}
		X^2-Y^2-1=0.
	\end{equation}


	Cherchons le changement de base correspondant. Pour trouver les coordonnées de \( e'_1\) dans la base \(  (e_1, e_2) \) nous cherchons pour quelles valeurs de \( x,y\) nous avons \( e'_1=xe_1+ye_2\). Le point \( e'_1\) étant caractérisé par \( X=1\), \( Y=0\) nous avons à résoudre
	\begin{subequations}
		\begin{numcases}{}
			\frac{1}{ \sqrt{ 2 } }(x+y)=1\\
			y=0,
		\end{numcases}
	\end{subequations}
	ce qui donne \( x=\sqrt{ 2 }\) et \( y=0\). Donc
	\begin{equation}
		e'_1=\sqrt{ 2 }e_1.
	\end{equation}
	Pour trouver \( e'_2\), c'est le même raisonnement en posant \( X=0\) et \( Y=1\). Le résultat est :
	\begin{equation}
		e'_2=-e_1+e_2.
	\end{equation}

	Résumons :
	\begin{subequations}    \label{EqfiVwym}
		\begin{numcases}{}
			e'_1=\sqrt{2}e_1\\
			e'_2=-e_1+e_2.
		\end{numcases}
	\end{subequations}

	Il y a un dicton qui dit que les vecteurs de base se transforment avec la matrice inverse des coefficients. Prenons la matrice \( M\) donnée par
	\begin{equation}
		\begin{pmatrix}
			X \\
			Y
		\end{pmatrix}=\begin{pmatrix}
			1/\sqrt{2} & 1/\sqrt{2} \\
			0          & 1
		\end{pmatrix}\begin{pmatrix}
			\tilde x \\
			\tilde y
		\end{pmatrix}=
		M\begin{pmatrix}
			\tilde x \\
			\tilde y
		\end{pmatrix}
	\end{equation}
	Calculons la matrice inverse.
	\lstinputlisting{tex/sage/sageSnip023.sage}
	Nous voyons que les colonnes de la matrice \( M^{-1}\) donnent les coordonnées des vecteurs \( e'_1\) et \( e'_2\).


\end{example}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Applications affines}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Voici la définition d'une application affine entre deux espaces affines. La définition \ref{DEFooVTXWooVXfUnc} donnera le définition d'une application affine entre espaces vectoriels.

\begin{definition}      \label{DEFooUAWZooXcMKve}
	Soient \( \affE\) et \( \affE'\) deux espaces affines sur les espaces vectoriels \( E\) et \( E'\) (sur le même corps \( \eK\)). Une application \( f\colon \affE\to \affE'\) est dite \defe{affine}{affine!application} si pour tout \( M\in \affE\), il existe une application linéaire\footnote{Définition \ref{DEFooULVAooXJuRmr}.} \( u_M\colon E\to E'\) telle que
	\begin{equation}    \label{EqMqIoWX}
		f(M+x)=f(M)+u_M(x)
	\end{equation}
	pour tout \( x\in E\).
\end{definition}

La définition suivante permet de décomposer une application affine en une partie linéaire et une translation. À partir de là, la proposition \ref{PROPooBPKKooJRAMeT} nous donnera une structure de groupe sur \( \Aff(\eR^n)\).

\begin{lemmaDef}[partie linéaire d'une application affine\cite{MonCerveau}]       \label{LEMooYJCDooOGAHkF}
	Soient \( \affE\) et \( \affE'\) deux espaces affines sur les espaces vectoriels \( E\) et \( E'\) (sur le même corps \( \eK\)). Nous considérons une application affine \( f\colon \affE\to \affE'\).

	Il existe une unique application linéaire \( u\colon E\to E'\) telle que
	\begin{equation}
		f(M+x)=f(M)+u(x)
	\end{equation}
	pour tout \( x\in E\) et pour tout \( M\in \affE\).

	Cette application linéaire est appelée \defe{partie linéaire}{partie linéaire} de \( f\). Pour varier les notations, nous noterons souvent \( f=\alpha\circ\tau_v\) pour une application linéaire \( \alpha\) et la translation \( \tau_v\) de vecteur \( v\).
\end{lemmaDef}

\begin{proof}
	En plusieurs étapes.
	\begin{subproof}
		\spitem[Unicité]
		Supposons que \( u_1\) et \( u_2\) vérifient la propriété, alors pour tout \( x\in E\) et tout \( M\in \affE\) nous avons \( f(M+x)=f(M)+u_1(x)\) et \( f(M+x)=f(M)+u_2(x)\). Cela suffit à nous convaincre que \( u_1=u_2\).
		\spitem[\( u_M=u_N\)]
		Avant de prouver l'existence, nous considérons \( M,N\in \affE\) et les applications linéaires \( u_M\) et \( u_N\) vérifiant l'équation \eqref{EqMqIoWX} pour \( M\) et \( N\) respectivement. Prouvons que \( u_M=u_N\).

		Posons
		\begin{subequations}
			\begin{align}
				f(M+x) & =f(M)+u_M(x)  \\
				f(N+y) & =f(N)+u_N(y).
			\end{align}
		\end{subequations}
		Définissons \( a\in E\) par \( N=M+a\); nous avons d'une part
		\begin{equation}
			f(N+y)=f(M+y+a)=f(M)+u_M(y+a),
		\end{equation}
		et d'autre part
		\begin{equation}
			f(N+y)=f(M+a)+u_N(y)=f(M)+u_M(a)+u_N(y).
		\end{equation}
		Par conséquent \( u_M(y+a)=u_M(a)+u_N(y)\). Par linéarité \( u_N=u_M\).
		\spitem[Existence]
		Soit \( M\in \affE\). Nous affirmons que \( u_M\) fait l'affaire. En effet, soient \( N\in \affE\) et \( x\in E\). Puisque \( u_M=u_N\) nous avons
		\begin{equation}
			f(N+x)=f(N)+u_N(x)=f(N)+u_M(x).
		\end{equation}
		Donc effectivement \( u_M\) peut être utilisé en tout point de \( \affE\).
	\end{subproof}
\end{proof}
Ce lemme est important car il permet de démontrer qu'une application est affine en prouvant la linéarité des \( u_M\) séparément sans devoir prouver qu'elles sont égales.

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Autres propriétés}
%---------------------------------------------------------------------------------------------------------------------------

\begin{lemma}[\cite{MonCerveau}]       \label{LEMooXXTPooKYFGGM}
	Soient \( M\in \affE\) et \( A,B\in \affE\) deux points donnés par \( A=M+x_a\), \( B=M+x_b\). Soit encore une application affine \( f\) sur \( \affE\). Alors
	\begin{equation}
		\vect{  f(A)f(B)  } =u_f(x_b-x_a).
	\end{equation}
\end{lemma}

\begin{proof}
	En appliquant \( f\) à \( A=M+x_a\) et \( B=M+x_b\),
	\begin{subequations}
		\begin{align}
			f(A) & =f(M)+u_f(x_a)  \\
			f(B) & =f(M)+u_f(x_b).
		\end{align}
	\end{subequations}
	Donc \( f(B)=f(A)-u_f(x_a)+u_f(x_b)\) ou encore
	\begin{equation}
		f(B)=f(A)+u_f(x_b-x_a).
	\end{equation}
\end{proof}

\begin{remark}
	La condition \eqref{EqMqIoWX} pour tout \( M\in\affE\) est équivalente à demander
	\begin{equation}
		f\circ t_x=t_{u(x)}\circ f
	\end{equation}
	pour tout \( x\in E\).
\end{remark}

\begin{proposition}[\cite{MonCerveau}]     \label{PROPooALXYooHoMdqQ}
	Soit une application affine \( f\colon \affE\to \affE'\).
	\begin{enumerate}
		\item       \label{ITEMooSKCYooHyRZYN}
		      Il existe une unique application linéaire \( u_f\) telle que \( f(M+x)=f(M)+u_f(x)\) pour tout \( M\in \affE\) et tout \( x\in E\).
		\item
		      L'application \( u_f\) est injective si et seulement si \( f\) est injective.
		\item
		      L'application \( u_f\) est surjective si et seulement si \( f\) est surjective.
	\end{enumerate}
\end{proposition}

\begin{proof}
	En plein de parties.
	\begin{subproof}
		\spitem[Pour \ref{ITEMooSKCYooHyRZYN}]

		La partie \ref{ITEMooSKCYooHyRZYN} est le lemme \ref{LEMooYJCDooOGAHkF}.
		\spitem[Si \( u_f\) est injective]
		% -------------------------------------------------------------------------------------------- 
		Soient \( M,N\in\affE\) tels que \( f(M)=f(N)\). Nous avons
		\begin{equation}
			f(M)=f(N)=f\big( M+(N-M) \big)=f(M)+u_f(N-M),
		\end{equation}
		donc \( u_f(N-M)=0\). Vu que \( u_f\) est injective, nous déduisons que \( N-M=0\).
		\spitem[Si \( f\) est injective]
		% -------------------------------------------------------------------------------------------- 
		Soient \( x,y\in E\) tels que \( u_f(x)=u_f(y)\). Soit \( M\) quelconque dans \( \affE\); nous avons
		\begin{equation}
			f(M+x)=f(M)+u_f(x)=f(M)+u_f(y)=f(M+y).
		\end{equation}
		L'injectivité de \( f\) nous indique alors que \( M+x=M+y\) et donc que \( x=y\) parce que l'action de \( E\) sur \( \affE\) est libre.
		\spitem[Si \( u_f\) est surjective]
		% -------------------------------------------------------------------------------------------- 
		Soit \( M\in \affE\). Nous allons trouver un élément de \( \affE\) dont l'image par \( f\) est \( M\). Soient \( N\in\affE\) et \( x\in E\) tels que \( u_f(x)=M-f(N)\).

		Alors nous avons \( f(N+x)=f(N)+u_f(x)=M\).
		\spitem[Si \( f\) est surjective]
		% -------------------------------------------------------------------------------------------- 
		Soit \( a\in E\). Nous voulons \( x\in E\) tel que \( u_f(x)=a\). Soit \( M\in E\). Vu que \( f\) est surjective, il existe \( N\in \affE\) tel que \( f(N)=f(M)+a\).

		Posons \( x=N-M\). Nous avons d'une part
		\begin{equation}
			f(M+x)=f(M)+u_f(x)
		\end{equation}
		et d'autre part
		\begin{equation}
			f(M+x)=f\big( M+(N-M) \big)=f(N)=f(M)+a.
		\end{equation}
		En égalisant nous trouvons \( u_f(x)=a\).
	\end{subproof}
\end{proof}

\begin{proposition}
	Soient des espaces affines \( \affE\) et \( \affE'\) de même dimension. Une application affine \( f\colon \affE\to \affE'\) est injective si et seulement si elle est surjective.
\end{proposition}

\begin{proof}
	Nous allons utiliser les équivalences de la proposition \ref{PROPooALXYooHoMdqQ}, ainsi que le corolaire \ref{CORooCCXHooALmxKk} pour la partie linéaire. Nous avons les équivalences :
	\begin{equation}
		\text{\( f\) est injective} \Leftrightarrow \text{\( u_f\) est injective} \Leftrightarrow \text{\( u_f\) est surjective} \Leftrightarrow \text{\( f\) est surjective}.
	\end{equation}
\end{proof}

\begin{example}     \label{EXooAGINooYmvPML}
	L'espace \( \eR^n\) est très particulier parce qu'il agit sur lui-même; il est donc un espace affine à lui tout seul : \( \affE=E=\eR^n\).

	Dans le cas de \( \eR^n\), en posant \( M=0\) dans la condition \eqref{EqMqIoWX}, si \( f\) est une application affine il existe une application linéaire \( \alpha\) et un vecteur \( v\) tel que \( f=\tau_v\circ \alpha\).

	Notons que ça n'a pas de sens de poser \( M=0\), et la décomposition \( f=\tau_v\circ \alpha\) n'a aucun sens en général. En particulier, nous ne pouvons pas appliquer une application linéaire à un élément d'un espace affine général.
\end{example}

\begin{proposition}     \label{PROPooOUNEooQUZetW}
	Si \( f\colon \affE\to \affE'\) et \( g\colon \affE'\to \affE''\) sont des applications affines, alors \( g\circ f\colon \affE\to \affE''\) est affine et \( u_{g\circ f}=u_g\circ u_f\).
\end{proposition}

\begin{proof}
	Si \( M\in\affE\) et \( x\in E\) nous avons
	\begin{equation}
		\begin{aligned}[]
			(g\circ f)(M+x) & =g\big( f(M)+u_f(x) \big)                \\
			                & =g\big( f(M) \big)+u_g\big( u_f(x) \big) \\
			                & =(g\circ f)(M)+(u_g\circ u_f)(x).
		\end{aligned}
	\end{equation}
\end{proof}

\begin{theorem}     \label{THOooBAPDooEUtBgF}
	Soient \( \affE\) et \( \affE'\) deux espaces affines de dimensions finies \( p\) et \( q\) sur \( \eK\). Soient les repères cartésiens \( R=(O,\{ e_i \})\) et \( R'=(O',\{ e_i' \})\). Une application \( f\colon \affE\to \affE'\) est affine si et seulement si il existe une matrice \( a\in\eM_{p,q}(\eK)\) et \( b\in \eK^q\) tels que\footnote{L'équation \eqref{EqCmNHjs} est écrite en utilisant un abus de notation entre le vecteur \( x\in \eK^p\) et le point de \( \affE\) qui est représenté par \( x\) dans le repère \( (O,\{ e_i \})\).}
	\begin{equation}    \label{EqCmNHjs}
		f(x)=b+ax.
	\end{equation}
\end{theorem}

\begin{proof}
	En deux parties.
	\begin{subproof}
		\spitem[\( \Rightarrow\)]
		%-----------------------------------------------------------
		C'est la définition \ref{DEFooUAWZooXcMKve}.
		\spitem[\( \Leftarrow\)]
		%-----------------------------------------------------------
		Nous savons par la proposition \ref{PROPooALXYooHoMdqQ} qu'il existe une application linéaire \(u_f \colon \eK^n\to \eK^n  \) telle que
		\begin{equation}
			f(M+x)=f(M)+u_f(x).
		\end{equation}
		En prenant \( M=O\) et en écrivant \( x\) au lieu de \( O+x\), nous avons
		\begin{equation}
			f(x)=f(O)+u_f(x).
		\end{equation}
		La partie \( f(O)\) est le \( b\) que nous cherchions\footnote{En réalité le \( b\) qu'on cherche est le \( b\in \eK^n\) tel que \( f(O)=O'+b\).}. Par ailleurs, vu que \( u_f\) est linéaire, elle est donnée par le produit avec une matrice. La matrice \( a\) qu'on cherche est la matrice de \( u_f\).

	\end{subproof}
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Isomorphismes}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{definition}
	Un \defe{isomorphisme}{isomorphisme!espace affine} entre les espaces affines \( \affE\) et \( \affE'\) est une application affine \( f\colon \affE\to \affE'\) inversible dont l'inverse est affine.
\end{definition}

\begin{proposition} \label{PropxtFeDE}
	Une application affine bijective est un isomorphisme. Si \( f\) est un isomorphisme d'espaces affines, alors \( u_{f^{-1}}=(u_f)^{-1}\).
\end{proposition}

\begin{proposition}
	Un espace affine de dimension finie \( n\) sur un corps \( \eK\) est isomorphe à l'espace affine canonique \( \affE_n(\eK)\).
\end{proposition}

\begin{proof}
	Si nous considérons le repère \( R=(A,\{ e_i \})\) de l'espace affine \( \affE\) alors l'application
	\begin{equation}
		\begin{aligned}
			\varphi\colon \eK^n & \to \affE              \\
			(x_1,\ldots,x_n)    & \mapsto A+\sum_ix_ie_i
		\end{aligned}
	\end{equation}
	est un isomorphisme.
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Sous espaces affines}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{definition}      \label{DEFooJSUHooJjtpwz}
	Soit \( \affE\) un espace affine sur l'espace vectoriel \( E\). Un \defe{sous-espace affine}{affine!sous-espace} de \( \affE\) est une orbite de l'action d'un sous-espace vectoriel de \( E\).
\end{definition}

Si \( \affF\) est un sous-ensemble de \( \affE\), il sera un sous-espace affine de \( \affE\) si et seulement si l'ensemble
\begin{equation}
	F=\{ AB\tq A,B\in\affF \}
\end{equation}
est un sous-espace vectoriel de \( E\). Dans ce cas nous disons que \( F\) est la \defe{direction}{direction!sous-espace affine} de \( \affF\). Si \( A\in\affF\), alors l'orbite de \( A\) sous \( F\) est \( \affF\). La \defe{dimension}{dimension!sous espace affine} de \( \affF\) est la dimension de sa direction.

Si \( \affF\) et \( \affG\) sont des sous-espaces affines de \( \affE\) de directions \( F\) et \( G\), nous disons que \( \affF\) est \defe{parallèle}{parallèle!sous-espaces affines} à \( \affG\) si \( F\subset G\).

\begin{proposition}		\label{PROPooAAPZooDWCuTL}
	Soit \( \affF\) un sous-espace affine de dimension \( k\) dans l'espace affine \( \affE\) de dimension \( n\). Alors il existe une application affine \( f\colon \affE\to \eK^{n-k}\) telle que \( \affF=f^{-1}(0)\).
\end{proposition}

\begin{proof}
	Soient \( F\) la direction de \( \affF\) et \( A\in\affF\). Nous considérons une base \( \{ e_i \}\) adaptée à \( F\) au sens \( \{ e_1,\ldots, e_k \}\) est une base de \( F\). Nous considérons maintenant le repère cartésien \( (A,\{ e_i \})\) et nous construisons l'application affine
	\begin{equation}
		\begin{aligned}
			f\colon \affE        & \to \eK^{n-k}          \\
			A+\sum_{i=1}^nx_ie_i & \mapsto \begin{pmatrix}
				                               x_{k+1} \\
				                               \vdots  \\
				                               x_n
			                               \end{pmatrix}.
		\end{aligned}
	\end{equation}
	Par construction nous avons \( f(M)=0\) si et seulement si \( M\in\affF\).
\end{proof}

\begin{proposition}[Sous-espace engendré\cite{Combes}]      \label{PropomhBwi}
	Soit \( \sigma\) une partie de l'espace affine \( \affE\).
	\begin{enumerate}
		\item
		      L'intersection de tous les sous-espaces affines contenant \( \sigma\) est un sous-espace affine, noté \( \Aff(\sigma)\).
		\item	\label{ITEMooNXXQooCxRUcz}
		      Si \( A\in \sigma\), alors la direction de \( \Aff(\sigma)\) est le sous-espace vectoriel
		      \begin{equation}        \label{EqnRAUfg}
			      F=\Span\{ \overrightarrow{ AM }\tq M\in \sigma \}.
		      \end{equation}
	\end{enumerate}
	%TODOooKNREooCojPIX. Prouver ça.
\end{proposition}
Le sous-espace affine donné par la proposition~\ref{PropomhBwi} est le sous-espace affine \defe{engendré}{sous-espace!affine engendré par une partie} par la partie~\( \sigma\), et il est noté \( \eae(\sigma)\). \index{engendré!sous-espace affine}

\begin{proposition}     \label{PROPooAKJBooMkmsiV}
	Soit \( \affE\) un espace affine de dimension \( n\) sur \( \eK\), soit \( f\colon \affE\to \eK^r\) une fonction affine. Pour tout \( a=(a_1,\ldots, a_r)\in \eK^r\), l'ensemble \( f^{-1}(a)\) est un sous-espace affine\footnote{Définition \ref{DEFooJSUHooJjtpwz}.} de dimension \( \dim\ker(u_f)\).
\end{proposition}

\begin{proof}
	Nous considérons le repère \( (A,\{ e_i \})\) de \( \affE\). Étant donné que \( f\) est affine nous avons
	\begin{equation}
		f\big( A+\sum_ix_ie_i \big)=f(A)+u_f\big( \sum_ix_ie_i \big).
	\end{equation}
	Nous avons donc \( f\big( A+\sum_ix_ie_i \big)=a\) lorsque
	\begin{equation}
		u_f(\sum_ix_ie_i)=a-f(A).
	\end{equation}
	En utilisant le lemme \ref{LEMooIQJMooJWRbub}, nous avons donc
	\begin{equation}
		f^{-1}(a)=A+(u_f)^{-1}\big( a-f(A) \big)=A+m+\ker(u_f)
	\end{equation}
	où \( m\) est n'importe que élément de \( u_f^{-1}\big(a-f(A)\big)\).
\end{proof}

\begin{proposition}     \label{PropPoNpPz}
	Soit \( A\) un ensemble convexe\footnote{Définition \ref{DEFooQQEOooAFKbcQ}.} dans un espace vectoriel et \( v_1,\ldots, v_n\) des éléments de \( A\). Alors toute combinaison
	\begin{equation}
		a_1v_1+\cdots +a_nv_n
	\end{equation}
	telle que \( a_1+\cdots +a_n=1\) et \( a_i\in\mathopen[ 0 , 1 \mathclose]\) appartient à \( A\).
\end{proposition}

\begin{proof}
	Nous prouvons la proposition pour \( n=3\). Nous devons trouver des nombres \( t_1,t_2\in \mathopen[ 0 , 1 \mathclose]\) tels que
	\begin{equation}
		t_2\big( t_1v_1+(1-t_1)v_2 \big)+(1-t_2)v_3=av_1+bv_2+cv_3.
	\end{equation}
	La réponse est immédiatement donnée par
	\begin{subequations}
		\begin{align}
			t_2a=1-c \\
			t_1=a/t_2.
		\end{align}
	\end{subequations}
	Étant donné que \( c\in \mathopen[ 0 , 1 \mathclose]\) nous avons \( t_2\in\mathopen[ 0 , 1 \mathclose]\). En ce qui concerne \( t_1\) nous avons
	\begin{equation}
		t_1=\frac{ a }{ t_2 }\leq \frac{ 1-c }{ 1-c }=1.
	\end{equation}
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Barycentre}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Soit \( \affE\) un espace affine sur le \( \eK\)-espace vectoriel \( E\). Un couple \( (A,\lambda)\) avec \( A\in \affE\) et \( \lambda\in \eK\) est un \defe{point pondéré}{point!pondéré}.

\begin{lemmaDef}[\cite{sZiwBQ}]        \label{LemtEwnSH}
	Soit une famille de points pondérés \( \{ (A_i,\lambda_i) \}_{i=1\ldots r}\). Si \( \sum_i\lambda_i\neq 0\), alors il existe un unique \( G\in \affE\) tel que
	\begin{equation}
		\sum_{i=1}^r\lambda_i\overrightarrow{ GA_i }=0.
	\end{equation}
	Le point \( G\) donné par le lemme~\ref{LemtEwnSH} est le \defe{barycentre}{barycentre!cas affine} des points pondérés \( (A_i,\lambda_i)\).
\end{lemmaDef}


Notons que l'on peut toujours supposer que \( \sum_i\lambda_i=1\) parce que le barycentre ne change pas lorsque tous les \( \lambda_i\) sont multipliés par un même nombre.
\begin{definition}[Combinaison convexe]\label{DefIMZooLFdIUB}
	Des nombres positifs ou nuls \( \lambda_1\),\ldots, \( \lambda_n\) vérifiant \( \sum_i\lambda_i=1\) forment une \defe{combinaison convexe}{combinaison!convexe}.
\end{definition}

Le théorème suivant donne quelques caractérisations équivalentes du barycentre.
\begin{theorem}[\cite{sZiwBQ}]      \label{ThoIJVzxr}
	Soient \( \{ (A_i,\lambda_i) \}_{i=1,\ldots, r}\) une famille de points pondérés. Les conditions suivantes sur le point \( G\in \affE\) sont équivalentes.
	\begin{enumerate}
		\item
		      Le point \( G\) est le barycentre de la famille.
		\item
		      Pour tout \( \alpha\in \eR^*\), \( \sum_i(\alpha\lambda_i)\overrightarrow{ GA_i }=0\).
		\item
		      Il existe \( A\in\affE\) tel que \( \big( \sum_i\lambda_i \big)\overrightarrow{ AG }=\sum_i\lambda_i\overrightarrow{ AA_i }\).
		\item   \label{ItemEgOQBX}
		      Pour tout \( B\in\affE\), nous avons \( \big( \sum_i\lambda_i \big)\overrightarrow{ BG }=\sum_i\lambda_i\overrightarrow{ BA_i }\).
	\end{enumerate}
\end{theorem}

\begin{definition}
	Si \( A,B\in \affE\), le \defe{segment}{segment!dans un espace affine} \( [AB]\) est l'ensemble des barycentres de \( A\) et \( B\) pondérés par des poids positifs (ouvert ou fermé suivant que l'on accepte que l'un ou l'autre des poids soit nul).
\end{definition}

Lorsque tous les \( \lambda_i\) sont égaux, nous parlons d'\defe{isobarycentre}{isobarycentre}. Autrement dit, l'isobarycentre des points \( A_i\) est le barycentre des points pondérés \( (A_i,1)\).

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Sous-espaces affines}
%---------------------------------------------------------------------------------------------------------------------------

\begin{proposition}
	Une partie \( \affF\) de \( \affE\) est un sous-espace affine si et seulement si elle est stable par barycentrisation.
\end{proposition}

\begin{proof}
	Soit \( \affF\) un sous-espace affine de direction \( F\) et \( A_1,\ldots, A_n\) des points de \( \affF\). Nous devons voir que le barycentre des points \( A_i\) pondérés de n'importe quelles masses appartient à \( \affF\). Pour ce faire nous faisons appel à la caractérisation~\ref{ItemEgOQBX} du théorème~\ref{ThoIJVzxr} : pour tout \( B\in\affF\),
	\begin{equation}
		\overrightarrow{ BG }=\sum_i\lambda_i\overrightarrow{ BA_i }.
	\end{equation}
	Puisque \( B\) et \( A_i\) sont dans \( \affF\), nous avons \( \overrightarrow{ BA_i }\in F\) et donc \( \overrightarrow{ BG }\in F\). Mais comme \( B\in\affF\), le point \( G\) est à son tour dans \( \affF\).

	Réciproquement, nous supposons que \( \affF\) est stable par barycentrisme. Nous voudrions montrer que l'ensemble
	\begin{equation}        \label{EqCmyWGi}
		F=\{ \overrightarrow{ AB }\tq A,B\in \affF \}
	\end{equation}
	est un sous-espace vectoriel. Soit \( A\in\affF\). Nous commençons par prouver que les vecteurs de la forme \( \overrightarrow{ AX }\) (\( X\in \affF\)) forment un espace vectoriel. Considérons \( \overrightarrow{ AX }+\overrightarrow{ AY }\) qui est un élément de \( E\); il existe donc \( V\in \affE\) tel que
	\begin{equation}
		\overrightarrow{ AV }=\overrightarrow{ AX }+\overrightarrow{ AY }.
	\end{equation}
	Par les relations de Chasles,
	\begin{equation}
		\overrightarrow{ AV }=\overrightarrow{ AV }+\overrightarrow{ VX }+\overrightarrow{ AV }+\overrightarrow{ VY },
	\end{equation}
	donc
	\begin{equation}
		0=\overrightarrow{ VX }-\overrightarrow{ VA }+\overrightarrow{ VY },
	\end{equation}
	ce qui prouve que \( V\) est un barycentre de \( X,A,Y\), et donc que \( V\in\affF\). De la même manière si \( W\in \affE\) est défini par \( \overrightarrow{ AW }=\mu \overrightarrow{ AX }\), alors
	\begin{equation}
		\overrightarrow{ AW }=\mu\overrightarrow{ AX }=\mu(\overrightarrow{ AW }+\overrightarrow{ WX }),
	\end{equation}
	ce qui signifie que
	\begin{equation}
		(1-\mu)\overrightarrow{ AW }+\mu\overrightarrow{ XW }=0
	\end{equation}
	et que \( W\) est un barycentre.

	Afin de montrer que \eqref{EqCmyWGi} est bien un espace vectoriel, nous devons considérer \( A,B,X,Y\in\affF\) et prouver que \( \overrightarrow{ AX }+\overrightarrow{ BY }\in F\). Nous avons
	\begin{subequations}
		\begin{align}
			\overrightarrow{ AX }+\overrightarrow{ BY } & =\overrightarrow{ AX }+\overrightarrow{ BA }+\overrightarrow{ AY }                                          \\
			                                            & =\overrightarrow{ AV }+\overrightarrow{ BA }                       & V\text{ est celui donné plus haut}     \\
			                                            & =\overrightarrow{ AV }-\overrightarrow{ AB }                                                                \\
			                                            & =\overrightarrow{ AV }+\overrightarrow{ AW }                       & W\text{ est donné par } \mu=-1\text{.} \\
			                                            & =\overrightarrow{ AV' }.
		\end{align}
	\end{subequations}
\end{proof}

\begin{proposition}[\cite{sZiwBQ}]      \label{PropBVbCOS}
	Soient \( A_0,\ldots, A_r\) des points de \( \affE\). L'ensemble des barycentres de ces points (avec des masses de somme \( 1\)) est le sous-espace affine engendré par les \( A_i\) que nous nommons \( \affF\).
\end{proposition}

\begin{proof}
	Soit \( G\) le barycentre associé aux poids \( \lambda_i\). Nous avons
	\begin{equation}
		G=A_0+\overrightarrow{ A_0G }=A_0+\sum_{i=1}^r\lambda_i\overrightarrow{ A_0A_i }.
	\end{equation}
	Notons que les vecteurs \( \overrightarrow{ A_0A_i }\) sont dans la direction du sous-espace affine engendré par les \( A_i\) par \eqref{EqnRAUfg}. Donc \( G\) est bien dans \( \affF\).

	Inversement si \( X\) est dans \( \affF\), on a
	\begin{equation}
		X=A_0+\sum_i\lambda_i\overrightarrow{ A_0A_i }
	\end{equation}
	parce que \( \sum_i\lambda_i\overrightarrow{ A_0A_i }\) est un élément général de la direction de \( \affF\). Donc
	\begin{equation}
		\overrightarrow{ A_0X }=\sum_i\lambda_i\overrightarrow{ A_0A_i },
	\end{equation}
	et en utilisant la relation de Chasles sur chacun des \( \overrightarrow{ A_0A_i }\),
	\begin{equation}
		\overrightarrow{ A_0X }=\sum_i\lambda_i\big( \overrightarrow{ A_0X }+\overrightarrow{ XA_i } \big).
	\end{equation}
	De là nous concluons que
	\begin{equation}
		\big( 1-\sum_i\lambda_i \big)\overrightarrow{ A_0X }+\sum_i\lambda_i\overrightarrow{ A_iX }=0,
	\end{equation}
	ce qui signifie précisément que \( X\) est un barycentre des \( A_i\).
\end{proof}

\begin{proposition}
	Soient \( r+1\) point \( A_0,\ldots, A_r\) dans \( \affE\). Le sous-espace affine engendré par les \( A_i\) est au plus de dimension \( r\).
\end{proposition}

\begin{proof}
	La direction de l'espace engendré \( \Aff\{ A_i \}\) est l'espace
	\begin{equation}
		\Span\{ \overrightarrow{ A_0A_i }_{i=1,\ldots, r} \}
	\end{equation}
	qui est engendré par \( r\) vecteurs et donc est au plus de dimension \( r\).
\end{proof}

En deux mots, la proposition suivante signifie que le barycentre des barycentres est le barycentre.
\begin{proposition}[Associativité des barycentres\cite{NOojwDf}]        \label{PropSFvjFZb}
	Soit une partition \( J_0, \ldots, J_r\) de \( I=\{ 0,1,\ldots, n \}\). Soient des points \( a_0,\ldots, a_n\in \affE\) et \( \lambda_0,\ldots, \lambda_n\) des nombres tels que \( \sum_i\lambda_i\neq 0\). Nous supposons que \( \mu_k=\sum_{i\in J_k}\lambda_i\neq 0\) pour tout \( k\), et enfin nous nommons \( b_k\) le barycentre de la famille \( \{ (a_i,\lambda_i),i\in J_k \}\).

	Alors le barycentre de la famille \( \{ (b_k,\mu_k) \}_{k=1,\ldots, r}\) est le barycentre de la famille \( \{ (a_i,\lambda_i) \}_{i\in I}\).
\end{proposition}

\begin{proof}
	Nous nommons \( b\) le barycentre des \( b_k\) pondérés par les \( \mu_k\), donc par définition
	\begin{subequations}
		\begin{align}
			0=\sum_{k=0}^r\mu_k\vect{ bb_k }                                                                                              \\
			 & =\sum_{k}\sum_{i\in J_k}\lambda_i\vect{ bb_k }                                                                             \\
			 & =\sum_{k=0}^r\sum_{i\in J_k}\lambda_i(\vect{ ba_i }+\vect{ a_ib_k })                                                       \\
			 & =\sum_{k=0}^r\sum_{i\in J_k}\lambda_i\vect{ ba_i }  +\sum_{k=0}^r\underbrace{\sum_{i\in J_k}\lambda_i\vect{ a_ib_k }}_{=0} \\
			 & =\sum_{i\in I}\lambda_i\vect{ ba_i }.
		\end{align}
	\end{subequations}
	Donc \( b\) est bien barycentre des \( a_i\) avec les poids \( \lambda_i\).
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Enveloppe convexe}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}      \label{DefNLYYooXUHFUY}
	Soit \( A\) une partie d'un espace vectoriel \( E\). L'\defe{enveloppe convexe}{enveloppe!convexe} de \( A\), notée \( \Conv(A)\)\nomenclature[G]{\( \Conv(A)\)}{enveloppe convexe} est l'intersection de tous les convexes contenant \( A\).
\end{definition}
L'enveloppe convexe est un convexe. En effet soit \( C\) un convexe contenant \( A\) et \( x,y\in\Conv(A)\); alors \( x\) et \( y \) sont dans \( C\) et par conséquent le segment \( [x,y]\) est inclus dans \( C\). Ce segment étant inclus dans tout convexe contenant \( A\), il est inclus dans \( \Conv(A)\).

\begin{proposition}[\cite{IQeaKlP}] \label{PropSVvAQzi}
	Soit \( C\) un convexe dans l'espace affine \( \affE\) et une famille de points pondérés \( \{ (a_i,\lambda_i) \}_{i=1,\ldots, r}\) dont tous les poids sont positifs (et non tous nuls). Alors le barycentre est aussi dans \( C\).

	En d'autre termes, un convexe est stable par barycentrage à poids positifs\footnote{Sauf si on prend tous les poids nuls; mais contre ce genre d'idées, on ne peut rien faire.}.
\end{proposition}
\index{convexité!barycentre}

\begin{proof}
	Nous prouvons par récurrence. D'abord pour \( r=2\). Le barycentre des points pondérés \( (a_1,\lambda_1)\), \( (a_2,\lambda_2)\) est le point \( b\) tel que
	\begin{equation}        \label{EqFWEErRX}
		\lambda_1\vect{ ba_1 }+\lambda_2\vect{ ba_2 }=0.
	\end{equation}
	Par définition, ce qui est noté \( \vect{ ab }\) n'est rien d'autre que \( b-a\); en déballant \eqref{EqFWEErRX}, nous trouvons
	\begin{equation}
		\lambda_1(a_1-b)+\lambda_2(a_2-b)=0
	\end{equation}
	et donc
	\begin{equation}
		b=\frac{ \lambda_1 }{ \lambda_1+\lambda_2 }a_1+\frac{ \lambda_2 }{ \lambda_1+\lambda_2 }a_2,
	\end{equation}
	qui est bien un point du segment \( [a_1,a_2]\) parce que c'est une combinaison à coefficients positifs de somme \( 1\).

	Nous passons maintenant à la vraie récurrence avec un ensemble de points pondérés
	\begin{equation}
		A_r=\{ (a_1,\lambda_1),\ldots, (a_r,\lambda_r) \}
	\end{equation}
	de masse totale non nulle; et en vous laissant deviner ce que va désigner \( A_{r-1}\). Si une des masses est nulle (disons \( \lambda_r\)), alors le barycentre de \( A_r\) est le même que celui de \( A_{r-1}\) et l'hypothèse de récurrence nous enseigne que ledit barycentre est dans \( C\). Nous supposons donc que \( \lambda_i\neq 0\) pour tout \( i\). Dans ce cas le théorème d'associativité des barycentres~\ref{PropSFvjFZb} dit que le barycentre de \( A_r\) est le barycentre entre le barycentre de \( A_{r-1}\) et \( (a_r,\lambda_r)\), qui sont deux points de \( C\) par hypothèse de récurrence.
\end{proof}

Si \( E\) est un espace vectoriel et si \( x_i\in E\) et \( \lambda_i\in \eR\), alors le barycentre des couples \( (x_i,\lambda_i)\) est le point \( g\) tel que \( \sum_i\lambda_i\vect{ gx_i }\), c'est-à-dire \( \sum_i\lambda_i(x_i-g)=0\) ou encore
\begin{equation}
	\sum_i\lambda_ix_i=\sum_i\lambda_ig.
\end{equation}
Donc, quitte à diviser tous les \( \lambda_i\) par la somme, nous pouvons supposer que la somme des poids est \( 1\). C'est pourquoi lorsque nous parlerons de barycentre dans un espace vectoriel sans contexte affine, nous allons toujours supposer \( \sum_i\lambda_i=1\) et avoir le barycentre
\begin{equation}
	g=\sum_i\lambda_ix_i.
\end{equation}

\begin{proposition} \label{PropYHMTmZX}
	Soit \( E\), un espace vectoriel et \( A\subset E\). L'enveloppe convexe \( \Conv(A)\) est l'ensemble des barycentres de familles finies de points affublés de masses positives.
\end{proposition}

\begin{proof}
	Nous notons \( \mB\) l'ensemble des dits barycentres. Par la proposition~\ref{PropSVvAQzi}, ces barycentres sont dans l'enveloppe convexe et donc \( \mB\subset\Conv(A)\). A contrario, si nous prouvons que \( \mB\) était convexe, alors nous aurions \( \Conv(A)\subset\mB\) parce que l'enveloppe convexe est l'intersection des convexes contenant \( A\).

	Soient \( a,b\in\mB\), c'est-à-dire que l'on a \( a_0,\ldots, a_n\) et \( b_0,\ldots, b_m\) dans \( A\) ainsi que les nombres strictement positifs \( \lambda_0,\ldots, \lambda_n\) et \( \mu_0,\ldots, \mu_m\) tels que
	\begin{subequations}
		\begin{align}
			a & =\sum_i\lambda_ia_i & \sum_{i=1}^n\lambda_i & =1 \\
			b & =\sum_j\mu_jb_j     & \sum_{j=1}^n\mu_j     & =1
		\end{align}
	\end{subequations}
	Un point du segment \( \mathopen[ a , b \mathclose]\) est de la forme \( p=ta+(1-t)b\) avec \( t\in \mathopen[ 0 , 1 \mathclose]\). En développant,
	\begin{equation}
		p=\sum_{i=0}^n(t\lambda_i)a_i+\sum_{j=0}^m(1-t)\mu_jb_j.
	\end{equation}
	C'est le barycentre de la famille \( \{ (a_i,\lambda_i),(b_j,\mu_j) \}\), parce que la somme des coefficients vaut bien \( 1\) :
	\begin{equation}
		\sum_i(t\lambda_i)+\sum_j(1-t)\mu_j=t+(1-t)=1.
	\end{equation}
\end{proof}


\begin{theorem}[Carathéodory\cite{KXjFWKA}] \label{ThoJLDjXLe}
	Dans un espace affine de dimension \( n\), l'enveloppe convexe\footnote{Définition~\ref{DefNLYYooXUHFUY}.} de \( A\) est l'ensemble des barycentres à coefficients positifs ou nuls de familles de \( n+1\) points.
\end{theorem}
\index{barycentre!enveloppe convexe}
\index{dimension!utilisation}
\index{théorème!Carathéodory}

\begin{proof}
	Soit \( x\in\Conv(A)\); on sait par la proposition~\ref{PropYHMTmZX} que \( x\) est barycentre de points de \( A\) avec des coefficients positifs :
	\begin{equation}    \label{EqWJDwOTH}
		x=\sum_{k=1}^p\lambda_kx_k
	\end{equation}
	avec \( \sum_k\lambda_k=1\). Nous supposons que \( p>n+1\) (sinon le théorème est réglé), et nous allons faire une récurrence à l'envers en montrant qu'on peut aussi écrire \( x\) sous forme d'un barycentre de strictement moins de \( p\) points.

	Étant donné que \( p-1>n\), la famille \( \{ x+i-x_1 \}_{i=2,\ldots, p}\) est liée et il existe donc \( \alpha_1,\ldots, \alpha_p\in \eR\) tels que \( \sum_{i=2}^p\alpha_i(x_i-x_1)=0\), c'est-à-dire telle que
	\begin{equation}
		\sum_{i=2}^p\alpha_ix_i=\sum_{i=2}^p\alpha_ix_1.
	\end{equation}
	Nous posons \( \alpha_1=-\sum_{i=2}^p\alpha_1\). Remarquons qu'alors \( \sum_{i=1}^p\alpha_ix_i=0\) parce que
	\begin{equation}
		\sum_{i=1}^p\alpha_ix_i=\alpha_1x_1+\sum_{i=2}^p\alpha_ix_i=\alpha_1x_1+\sum_{i=2}^p\alpha_ix_1=\sum_{i=1}^p\alpha_ix_1=0.
	\end{equation}
	Par conséquent ça ne coûte rien de récrire \eqref{EqWJDwOTH} sous la forme
	\begin{equation}
		x=\sum_{i=1}^p(\lambda_i+t\alpha_i)x_i.
	\end{equation}
	Les \( \alpha_i\) ne sont pas tous nuls, mais leur somme est nulle, donc il y en a au moins un négatif. Nous notons
	\begin{equation}
		\tau=\min\{ -\frac{ \lambda_i }{ \alpha_i }\tq \alpha_i<0 \},
	\end{equation}
	et \( J\) l'ensemble de \( i\) pour lesquels ce minimum est atteint. Nous considérons aussi les nombres \( \mu_i=\lambda_i+\tau\alpha_i\). Plusieurs remarques.
	\begin{enumerate}
		\item
		      Si \( j\in J\), alors \( \mu_j=0\)
		\item
		      Si \( \alpha_i>0\) alors \( \mu_i\geq 0\), mais si \( \alpha_i<0\) alors
		      \begin{equation}
			      \lambda_i+\tau\alpha_i\geq \lambda_i+(-\frac{ \lambda_i }{ \alpha_i })\alpha_i=0
		      \end{equation}
		      donc \( \mu_i\geq 0\) quand même.
		\item
		      \( \sum_{i=1}^p\mu_i=1\), toujours parce que \( \sum_{i=1}^p\alpha_i=0\).
	\end{enumerate}
	Avec tout ça, nous avons
	\begin{equation}
		\sum_{i\notin J}\mu_ix_i=\sum_{i=1}^p\mu_ix_i=x.
	\end{equation}
	Et voilà, nous avons écrit \( x\) comme un barycentre à coefficients positifs de moins de \( p\) éléments parce que \( J\) n'est pas vide.
\end{proof}

\begin{corollary}   \label{CorOFrXzIf}
	Dans un espace affine de dimension finie, l'enveloppe convexe d'un compact est compacte.
\end{corollary}

\begin{proof}
	Soit \( A\) une partie compacte de l'espace vectoriel \( E\), et \( \Conv(A)\) son enveloppe convexe. Nous allons montrer que toute suite dans \( \Conv(A)\) admet une sous-suite convergente en écrivant un point de \( \Conv(A)\) comme le théorème de Carathéodory~\ref{ThoJLDjXLe} nous le suggère. Pour cela nous considérons le simplexe
	\begin{equation}
		\Lambda=\left\{  \lambda\in \eR^{n+1}\tq \sum_{k=1}^{n+1}\lambda_k=1\text{ et } \lambda_k\geq 0\forall k   \right\}.
	\end{equation}
	Montrons en passant que \( \Lambda\) est compact. Si \( \lambda_k\in \Lambda\) est une suite, alors chacun des \( \lambda_k\) est un \( (n+1)\)-uple de nombres dans \( \mathopen[ 0 , 1 \mathclose]\) :
	\begin{equation}
		k\mapsto (\lambda_k)_i
	\end{equation}
	est une suite qui possède une sous-suite convergente. En passant \( n+1\) fois à une sous-suite, nous tombons sur une suite convergente vers \( \lambda\in\Lambda\), grâce à la convergence composante par composante. De plus pour chaque \( k\) nous avons \( \sum_{i=1}^{n+1}(\lambda_k)_i=1\), et en passant à la limite, la somme étant une application continue, \( \sum_{i}\lambda_i=1\).

	Considérons l'application
	\begin{equation}
		\begin{aligned}
			f\colon \Lambda\times A^{n+1} & \to \Conv(A)                          \\
			(\lambda,x)                   & \mapsto \sum_{k=1}^{n+1}\lambda_kx_k.
		\end{aligned}
	\end{equation}
	C'est une application continue parce qu'elle est bilinéaire en dimension finie; son image est contenue dans \( \Conv(A)\) par la proposition~\ref{PropSVvAQzi}, et elle est surjective par le théorème de Carathéodory~\ref{ThoJLDjXLe}. Bref, \( \Conv(A)=f(\Lambda\times A^{n+1})\) est donc l'image d'un compact par une application continue; elle est donc compacte par le théorème~\ref{ThoImCompCotComp}.
\end{proof}
Notons que sans le théorème de Carathéodory, peut être que le nombre de points utiles pour décomposer les différents \( a_k\) n'était pas borné; dans ce cas nous aurions du prendre une infinité de sous-suites et rien n'aurait été sûr.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Applications affines et barycentre}
%---------------------------------------------------------------------------------------------------------------------------

\begin{proposition}[\cite{ooXDCOooDkRJHF}]      \label{PROPooGSPZooRnVgiU}
	Une application \( f\colon \affE\to \affE'\) entre deux espaces affines est affine si et seulement si pour tout système \( \{ (A_i,\lambda_i) \}_{i=1,\ldots, k}\) de barycentre \( G\) et de poids total non nul, le point \( f(G)\) est barycentre du système \( \{ \big(f(A_i),\lambda_i\big) \}\).
\end{proposition}

\begin{proof}
	En deux parties.
	\begin{subproof}
		\spitem[Si \( f\) est affine]

		Par définition d'un barycentre,
		\begin{equation}
			\sum_i\lambda_i\vect{ GA_i }=0.
		\end{equation}
		Nous considérons un point arbitraire \( O\in\affE\) et nous écrivons \( A_i=O+x_i\), \( G=O+x_g\). Ensuite nous utilisons le lemme~\ref{LEMooXXTPooKYFGGM} pour le calcul suivant :
		\begin{subequations}
			\begin{align}
				\sum_i\lambda_i\vect{ f(G)f(A_i) } & =\sum_i\lambda_iu_f(x_i-x_g)                 \\
				                                   & =u_f\big( \sum_i\lambda_i(x_i-x_g) \big)     \\
				                                   & =u_f\big( \sum_i\lambda_i\vect{ GA_i } \big) \\
				                                   & =u_f(0)=0.
			\end{align}
		\end{subequations}
		Donc \( f(G)\) est bien le barycentre du nouveau système.

		\spitem[Si \( f\) conserve les barycentres]

		Nous définissons \( u\) par \( f(O+x)=f(O)+u(x)\). À priori, ce \( u\) dépend de \( O\) et n'est pas linéaire.
		\begin{subproof}
			\spitem[\( u\) est linéaire]

			Soient \( M,N\in\affE\) et les éléments \( x_m,x_n\in E\) tels que \( \vect{ OM }=x_m\) et \( \vect{ ON }=x_n\). Nous définissons enfin \( P\) par
			\begin{equation}
				\vect{ OP }=\alpha \vect{ OM }+\beta\vect{ ON },
			\end{equation}
			et \( P=O+x_p\). En décomposant \( \vect{ MO }\) et \( \vect{ NO }\) par les relations de Chasles de la proposition~\ref{PROPooCOZCooCghwaR}\ref{ITEMooSDMIooUQiKeW} nous avons
			\begin{equation}
				(\alpha+\beta-1)\vect{ PO }-\alpha\vect{ PM }-\beta\vect{ PN }=0
			\end{equation}
			et donc \( P\) est barycentre du système
			\begin{equation}
				\big\{ (O,\alpha+\beta-1),(M,\alpha),(N,\beta) \}.
			\end{equation}
			Le point \( f(P)\) sera barycentre du système
			\begin{equation}
				\Big\{ \big( f(O), \alpha+\beta-1 \big),\big( f(M), \alpha \big), \big( f(N), \beta \big) \}.
			\end{equation}
			Cela signifie que
			\begin{equation}
				(\alpha+\beta-1)\vect{ f(P)f(O) }-\alpha\vect{ f(P)f(M) }-\beta\vect{ f(P)f(N) }=0.
			\end{equation}
			En y substituant \( \vect{ f(P)f(O) }=u(-x_p)\), \( \vect{ f(P)f(M) }=u(x_m-x_p)\) et \( \vect{ f(P)f(N) }=u(x_n-x_p)\) ainsi que \( x_p=\alpha x_m+\beta x_b\) nous trouvons
			\begin{equation}
				u(\alpha x_m+\beta x_n)=\alpha u(x_m)+\beta u(x_n).
			\end{equation}
			Donc \( u\) est linéaire.

			\spitem[\( u\) ne dépend pas du point \( O\)]

			Il n'est pas besoin de démontrer cela parce que la définition~\ref{DEFooUAWZooXcMKve} ne le demande pas. Note : c'est le lemme~\ref{LEMooYJCDooOGAHkF} qui dit que c'est par ailleurs vrai.
		\end{subproof}
	\end{subproof}
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Repères, coordonnées cartésiennes et barycentriques}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{definition}
	On dit que les points \( A_0,\ldots, A_r\in \affE\) sont \defe{affinement indépendants}{indépendance!affine} si le sous-espace affine engendré est de dimension \( r\).
\end{definition}

\begin{proposition}[\cite{sZiwBQ}]  \label{PropGAneHg}
	Pour \( r+1\) points \( A_0,\ldots, A_r\) dans \( \affE\), les propriétés suivantes sont équivalentes.
	\begin{enumerate}
		\item		\label{ITEMooONZHooWIzXdw}
		      Les \( A_i\) sont affinement indépendants.
		\item \label{ITEMooOMCRooNiRtSW}
		      Pour tout \( i=0,\ldots, r\), le point \( A_i\) n'est pas dans \( \Aff\{ A_0,\ldots, A_{i-1}, A_{i+1},\ldots, A_r \}\).
		\item\label{ItemrAzkIl}
		      Les points \( A_0,\ldots, A_{r-1}\) sont affinement indépendants et \( A_r\notin\Aff\{ A_0,\ldots, A_{r-1} \}\).
		\item		\label{ITEMooSLMDooFOHLEG}
		      Il existe \( i_0\in\{ 0,\ldots,r \}\) tel que la partie \( \{ \overrightarrow{ A_kA_{i_0} } \}_{k\neq i_0}\) est libre.
		\item\label{ItemFBfcuq}
		      Pour tout \( i\in\{ 1,\ldots, r \}\), les vecteurs \( \overrightarrow{ A_kA_i }\) (\( k\neq i\)) sont linéairement indépendants.
	\end{enumerate}
\end{proposition}

\begin{proof}
	Nous allons montrer que tout est équivalent à \ref{ITEMooONZHooWIzXdw}. Ce point \ref{ITEMooONZHooWIzXdw} signifie que tous les vecteurs \( v_i=\overrightarrow{A_0A_i}\) sont linéairement indépendants.
	%-----------------------------------------------------------
	\begin{subproof}
		\spitem[\ref{ITEMooONZHooWIzXdw} implique \ref{ITEMooOMCRooNiRtSW}]
		%-----------------------------------------------------------
		Si \( A_j\) était dans \( \Aff\{ A_k \}_{k\neq j }\), cela signifierait que \( A_j=A_0+\sum_{k\neq j}\lambda_kv_k\), et donc \( v_j=\sum_{k\neq j}v_k\) et donc que ces vecteurs ne sont pas linéairement indépendants.
		\spitem[\ref{ITEMooONZHooWIzXdw} implique \ref{ItemrAzkIl}]
		%-----------------------------------------------------------
		Vu que \( \{ v_i \}_{i=1,\ldots,r}\) sont linéairement indépendants, les \( \{ v_i \}_{i=1,\ldots,r-1}\) le sont aussi. De plus \( A_r\not\in\Aff\{ A_0,\ldots,A_{r-1} \}\) par \ref{ITEMooOMCRooNiRtSW}.
		\spitem[\ref{ITEMooONZHooWIzXdw} implique \ref{ITEMooSLMDooFOHLEG}]
		%-----------------------------------------------------------
		Par exemple \( i=0\) fait l'affaire.
		\spitem[\ref{ITEMooONZHooWIzXdw} implique \ref{ItemFBfcuq}]
		%-----------------------------------------------------------
		Le sous-espace vectoriel \( F\) de \eqref{EqnRAUfg} est de dimension \( r\) et peut être écrit \( \Span\{ \overrightarrow{MA_k} \}_{k=0,\ldots,r}\) pour n'importe que \( M\in\{ A_0,\ldots,A_r \}\).
		\spitem[\ref{ITEMooOMCRooNiRtSW} implique \ref{ITEMooONZHooWIzXdw}]
		%-----------------------------------------------------------
		Si les \( A_i\) n'étaient pas affinement indépendants, on aurait in \( A_j\) et un \( A_k\) tels que
		\begin{equation}
			A_j=A_k+\sum\substack{ i\neq j \\ i\neq k }\lambda_i \overrightarrow{A_kA_i} .
		\end{equation}
		Cela donnerait
		\begin{equation}
			\overrightarrow{A_kA_j}-\sum\substack{ i\neq j \\ i\neq k } \lambda_i\overrightarrow{A_kA_i},
		\end{equation}
		ce qui contredirait le fait que les \( \{ v_i \}_{i=1,\ldots,r}\) sont linéairement indépendants parce que chacun des \( \overrightarrow{A_kA_i}\) peut être écrit comme une combinaison des \( v_i\).
		\spitem[\ref{ItemrAzkIl} implique \ref{ITEMooONZHooWIzXdw}]
		%-----------------------------------------------------------
		Nous avons par hypothèse que \( \{ v_i \}_{i=1,\ldots,r-1}\) est libre. Si \( \{ v_i \}_{i=1,\ldots,r}\) n'était pas libre, nous aurions \( v_r=\sum_{i=1}^{r-1}\lambda_iv_i \), et donc
		\begin{equation}
			A_r=A_0+v_r=A_0+\sum_{i=1}^{r-1}\overrightarrow{A_0A_i},
		\end{equation}
		c'est-à-dire que \( A_r\in \Aff\{ 1_0,\ldots,A_{r-1} \}\).
		\spitem[\ref{ITEMooSLMDooFOHLEG} implique \ref{ITEMooONZHooWIzXdw}]
		%-----------------------------------------------------------
		D'après la proposition \ref{PropomhBwi}\ref{ITEMooNXXQooCxRUcz}, l'espace \( \Aff\{ A_0,\ldots,A_r \}\) est modelé sur
		\begin{equation}
			F=\Span\{ \overrightarrow{A_{i_0}A_k} \}_{k\neq i_0}.
		\end{equation}
		Par hypothèse la partie \( \{ \overrightarrow{A_{i_0}A_k} \}_{k\neq i_0}\) est libre. Donc \( \dim(F)=r\).
		\spitem[\ref{ItemFBfcuq} implique \ref{ITEMooONZHooWIzXdw}]
		%-----------------------------------------------------------
		L'hypothèse de \ref{ITEMooSLMDooFOHLEG} est validée à fortiori.
	\end{subproof}
\end{proof}

Notons à propos de la condition~\ref{ItemrAzkIl} que l'existence d'un \( i\) pour lequel \( A_i\) n'est pas dans \(\Aff\{ A_0,\ldots, A_{i-1},A_{i+1},\ldots, A_r \}\) n'implique pas l'indépendance des \( r+1\) points. En effet dans \( \eR^2\) nous considérons les \( 4\) points \( A_0=(0,0)\), \( A_1=(1,0)\), \( A_2=(2,0)\) et \( A_3=(0,1)\). Évidemment le point \( A_3\) n'est pas dans l'espace engendré par les trois autres; il n'empêche que ces points ne sont pas affinement indépendants parce que la direction est de dimension \( 2\) au lieu de \( 3\).

\begin{definition}  \label{DefguuwEO}
	Soit \( \affE\) un espace affine de dimension \( n\) et \( \affF\) un sous-espace affine de dimension \( k\). Un \defe{repère affine}{repère!affine} de \( \affF\) est la donnée de \( k+1\) points affinement indépendants de \( \affF\).
\end{definition}
Si \( \{ A_0,\ldots, A_n \}\) est un repère affine, le point \( A_0\) est l'\defe{origine}{origine!repère affine}. C'est un choix complètement arbitraire; et c'est bien cet arbitraire qui nous amènera à considérer les coordonnées barycentriques au lieu des coordonnées cartésiennes.

Soit \( M\in \affE\); par définition nous avons
\begin{equation}
	M=A_0+\overrightarrow{ A_0M }.
\end{equation}
Mais nous savons que les vecteurs \( \overrightarrow{ A_0A_i }\) forment une base de \( E\), nous avons donc des nombres \( \lambda_i\) tels que
\begin{equation}
	\overrightarrow{ A_0M }=\sum_{i=1}^n\lambda_i\overrightarrow{ A_0A_i }.
\end{equation}
Les nombres \( \lambda_i\) ainsi construits sont les \defe{coordonnées cartésiennes}{coordonnées!cartésiennes!dans un espace affine} du point \( M\) dans le repère \( \{ A_0,\ldots, A_n \}\) d'origine \( A_0\).

À partir de ces coordonnées, le point \( M\in\affE\) se retrouve par la formule
\begin{equation}
	M=A_0+\sum_{i=1}^n\lambda_i\overrightarrow{ A_0A_i }.
\end{equation}

\begin{proposition}[\cite{MonCerveau}]      \label{PROPooIXVBooPpKsDE}
	La paire \( \big( O,\{ e_1,\ldots, e_n \} \big)\) est un repère cartésien de \( \affE\) si et seulement si \( \{ O,O+e_1,\ldots, O+e_n \}\) est un repère affine.
\end{proposition}

\begin{proof}
	En deux parties.
	\begin{subproof}
		\spitem[Sens direct]
		Vue la proposition \ref{PropGAneHg}, il suffit de prouver que les vecteurs \( \overrightarrow{O(O+e_i)}\) sont linéairement indépendants. Mais \( \overrightarrow{O(O+e_i)}=e_i\), donc oui, ils sont linéairement indépendants.
		\spitem[Sens inverse]
		Il s'agit d'utiliser la même proposition \ref{PropGAneHg} qui est encore applicable parce que c'est une équivalence.
	\end{subproof}
\end{proof}

\begin{normaltext}
	Soient \( (A,e_i)\) et \( (A',e'_i)\) deux repères cartésiens pour l'espace affine \( \affE\). Soit \( (s_{ij})\) la matrice de changement de base entre \( \{ e_i \}\) et \( \{ e'_i \}\) dans \( E\). Nous voudrions trouver les \( x_i\) en termes des \( x'_i\).

	Pour cela nous considérons un point \( M\) dans \( \affE\) et nous l'écrivons dans les deux bases. Cela fournit l'égalité
	\begin{equation}        \label{EqcYfuMg}
		A+\sum_ix_ie_i=A'+\sum_ix'_ie'_i.
	\end{equation}
	Nous considérons les coordonnées \( (a_i)\) de \( A'\) dans le repère \( (A,e_i)\), c'est-à-dire
	\begin{equation}    \label{EqZNwPHE}
		A'=A+\sum_ia_ie_i.
	\end{equation}
	En substituant \( e'_i=\sum_ks_{jk}e_k\) et \eqref{EqZNwPHE} dans \eqref{EqcYfuMg} nous trouvons
	\begin{equation}
		\sum_kx_ke_k=\sum_ka_ke_k+\sum_{jk}s_{jk}x'_je_k,
	\end{equation}
	et par conséquent
	\begin{equation}
		x_k=a_k+\sum_js_{jk}x'_j.
	\end{equation}
\end{normaltext}

Les coordonnées barycentriques sont données par la proposition suivante.
\begin{proposition}[\cite{sZiwBQ}]      \label{PROPooTIRXooLAipRa}
	Soient \( A_0,\ldots, A_r\) des points affinement indépendants dans \( \affE\) et \( \affF=\Aff\{ A_0,\ldots, A_r \}\). Tout point \( M\in\affF\) s'écrit de façon unique comme barycentre\footnote{Définition \ref{LemtEwnSH}.} des \( A_i\) affectés de poids \( \lambda_i\) tels que \( \sum_{i=0}^r\lambda_i=1\).
\end{proposition}

\begin{proof}
	Nous avons vu plus haut (définition~\ref{DefguuwEO}) que l'affine indépendance des points \( A_i\) assurait que \( (A_0,\ldots, A_r)\) était un repère de \( \affF\).

	En ce qui concerne l'existence de l'écriture de \( M\) comme barycentre, nous savons que les sous-espace affines sont exactement les ensembles de barycentres (proposition~\ref{PropBVbCOS}), c'est-à-dire que si on a des points dans un sous-espace affine, alors les barycentres de ces points est encore dans le sous-espace affine.

	L'unicité est comme suit. Si \( M\) est barycentre des \( A_i\) avec poids \( \lambda_i\), nous écrivons la caractérisation~\ref{ItemEgOQBX} du théorème~\ref{ThoIJVzxr} avec \( B=A_0\) :
	\begin{equation}
		\overrightarrow{ A_0M }=\sum_{i=1}^r\lambda_i\overrightarrow{ A_0A_i }
	\end{equation}
	où la somme à droite s'étend à priori de \( 0\) à \( r\), mais comme \( \overrightarrow{ A_0A_0 }=0\), nous l'avons limitée à \( 1\). Si \( M\) s'écrit comme barycentre de deux façons différentes, nous aurions
	\begin{equation}
		\overrightarrow{ A_0M }=\sum_{i=1}^r\lambda_i\overrightarrow{ A_0A_i }=\sum_{i=1}^r\mu_i\overrightarrow{ A_0A_i }
	\end{equation}
	avec \( \sum_i\lambda_i=\sum_i\mu_i=1\). Étant donné que les points \( A_0,\ldots, A_r\) forment un repère, les vecteurs \( \overrightarrow{ A_0A_i }\) sont linéairement indépendants (point~\ref{ItemFBfcuq} de la proposition~\ref{PropGAneHg}) et donc \( \lambda_i=\mu_i\) pour \( i=1,\ldots, r\). La condition de somme des poids égale à \( 1\) impose alors immédiatement \( \lambda_0=\mu_0\).
\end{proof}

\begin{definition}      \label{DEFooTXPPooQdacbO}
	Soit un espace affine \( \affE\) de dimension \( n\). Soient des points affinement indépendants \( A_1,\ldots, A_n \). Pour \( M\in\affE\), la proposition \ref{PROPooTIRXooLAipRa} indique qu'il existe un unique choix de \( \lambda_i\) tel que
	\begin{subequations}
		\begin{numcases}{}
			\sum_i\lambda_i=1\\
			\sum_i\lambda_i \overrightarrow{MA_i}=0.
		\end{numcases}
	\end{subequations}
	Ces \( \lambda_i\) sont les \defe{coordonnées barycentriques}{coordonnées barycentrique} de \( M\) dans le repère \( \{ A_i \}_{i=1,\ldots, n}\).
\end{definition}

\begin{normaltext}      \label{NORMooOGHBooMjmouu}
	Soit \( \eR^2\) et les points non alignés \( A\), \( B\), \( C\). Les coordonnées barycentriques \( (\alpha,\beta,\gamma)\) dans ce système correspondent à l'unique \( X\in \eR^2\) tel que
	\begin{equation}
		\alpha \vect{ XA }+\beta\vect{ XB }+\gamma\vect{ XC }=0.
	\end{equation}
\end{normaltext}

\begin{example}
	Soient les points \( A=(3,1)\), \( B=(-1,2)\) et \( C=(0,-1)\) dans \( \eR^2\). Nous allons montrer qu'il forment un repère affine de \( \eR^2\). L'espace engendré par ces trois points est l'espace des
	\begin{equation}
		A+\alpha\overrightarrow{ AB }+\beta\overrightarrow{ AC },
	\end{equation}
	et la direction correspondante est l'espace vectoriel donné par \( \alpha\overrightarrow{ AB }+\beta\overrightarrow{ AC }\) qui est de dimension deux. Donc l'espace affine engendré par \( A\), \( B\) et \( C\) est de dimension \( 2\).
\end{example}

\begin{example}
	Dans le repère \( (A,B,C)\), quel est le point de coordonnées barycentriques \( (\frac{1}{ 6 },\frac{1}{ 3 },\frac{1}{ 2 })\) ? D'abord nous vérifions que
	\begin{equation}
		\frac{1}{ 6 }+\frac{1}{ 3 }+\frac{1}{ 2 }=1.
	\end{equation}
	Ensuite nous cherchons \( X\in \eR^2\) tel que
	\begin{equation}
		\frac{1}{ 6 }\overrightarrow{ AX }+\frac{1}{ 3 }\overrightarrow{ BX }+\frac{1}{ 2 }\overrightarrow{ CX }=0,
	\end{equation}
	c'est-à-dire
	\begin{equation}
		\frac{1}{ 6 }\begin{pmatrix}
			x-3 \\
			y-1
		\end{pmatrix}+\frac{1}{ 3 }\begin{pmatrix}
			x+1 \\
			y-2
		\end{pmatrix}+\frac{1}{ 2 }\begin{pmatrix}
			x \\
			y+1
		\end{pmatrix}=0.
	\end{equation}
	Nous trouvons immédiatement \( x=1/6\) et \( y=1/3\). Le point cherché est donc le point \( \begin{pmatrix}
		1/6 \\
		1/3
	\end{pmatrix}\).
\end{example}

\begin{lemma}[\cite{MonCerveau}]       \label{LEMooDUMVooFtfFOe}
	Une application affine \( f\colon \affE\to \affE\) qui préserve les points d'une base affine de \( \affE\) est l'identité.
\end{lemma}

\begin{proof}
	Une base affine de \( \affE\) consiste en \( n+1\) points \( \{ A_0,\ldots, A_n \}\) affinement indépendants. Nous utilisons la proposition \ref{PROPooIXVBooPpKsDE} pour dire que \( \big( A_0, \{ \overrightarrow{A_0A_i} \}_{i=1,\ldots, n} \big)\) est un repère cartésien.

	En utilisant la formule du lemme \ref{LEMooYJCDooOGAHkF},
	\begin{equation}
		f(A_i)=f(A_0+\overrightarrow{A_0A_i})=f(A_0)+u(\overrightarrow{A_0A_i}).
	\end{equation}
	Donc \( A_i=A_0+u(\overrightarrow{A_0A_i})\), ce qui signifie que
	\begin{equation}        \label{EQooAJYWooBTucpp}
		u(\overrightarrow{A_0A_i})=\overrightarrow{A_0A_i}
	\end{equation}

	Par ailleurs, tout point \( M\)\footnote{Même les points qui ne s'appellent pas «\( M \)» en fait.} de \( \affE\) peut être écrit sous la forme
	\begin{equation}
		M=A_0+\sum_i\lambda_i\overrightarrow{A_0A_i}.
	\end{equation}
	En appliquant \( f\), et en utilisant \eqref{EQooAJYWooBTucpp},
	\begin{equation}
		f(M)=f(A_0)+\sum_i\lambda_iu(\overrightarrow{A_0A_i})=A_0+\sum_i\lambda_i\overrightarrow{A_0A_i}=M.
	\end{equation}

	Donc tout point de \( \affE\) est fixé par \( f\), ce qui signifie que \( f\) est l'identité.
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Équation de droite}
%---------------------------------------------------------------------------------------------------------------------------


\begin{propositionDef}       \label{DEFooCYDPooEdRbyl}
	Soit \( \affE\) un espace affine de dimension trois muni d'un repère barycentrique\footnote{Définition \ref{DEFooTXPPooQdacbO}.} \( (A_1, A_2,A_3)\). Nous notons \( D(a,b,c)\) l'ensemble des éléments de \( \affE\) dont les coordonnées barycentriques (normalisées) \( (x,y,z)\) vérifient \( ax+by+cz=0\), c'est-à-dire l'ensemble des \( M\in \affE\) tels que
	\begin{subequations}
		\begin{numcases}{}
			x+y+z=1\\
			x \overrightarrow{MA_1}+y\overrightarrow{MA_2}+z\overrightarrow{MA_3}=0.
		\end{numcases}
	\end{subequations}
	Alors l'ensemble \( D(a,b,c)\) est un sous-espace de dimension \( 1\) de \( \affE\).

	Nous nommons \defe{droite affine}{droite affine} une telle partie de \( \affE\).
	%TODOooIXUMooNWRSEs. Prouver ça.
\end{propositionDef}

Idée de preuve : ne pas oublier la condition \( x+y+z=1\) parce que la somme des coordonnées barycentriques doit valoir \( 1\).


\begin{example}
	La droite \( D(1,1,1)\) n'existe pas parce que ce serait \( x+y+z=0\), qui est incompatible avec \( x+y+z=1\).
\end{example}

Les droites \( D(a,b,c)\) et \( D(a',b',c')\) s'intersectent selon les solutions du système
\begin{subequations}
	\begin{numcases}{}
		x+y+z=1\\
		ax+by+cz=0\\
		a'x+b'y+c'z=0
	\end{numcases}
\end{subequations}
Donc deux droites affines ont un unique point d'intersection si et seulement si
\begin{equation}
	d=\begin{vmatrix}
		1  & 1  & 1  \\
		a  & b  & c  \\
		a' & b' & c'
	\end{vmatrix}\neq 0.
\end{equation}
Elles seront parallèles ou confondues si et seulement si \( d=0\).

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Associativité, coordonnées barycentriques dans un triangle}
%---------------------------------------------------------------------------------------------------------------------------

\begin{lemma}[\cite{ooIXMCooHQKnee}]
	Soient trois points non alignés \( A\), \( B\), \( C\) ainsi que des nombres \( \alpha\), \( \beta\), \( \gamma\) tels que \( \alpha+\beta\neq 0 \) et \( \alpha+\beta+\gamma\neq 0\).

	Soit \( H\) le barycentre du système \( \{ (A,\alpha),(B,\beta) \}\) et \( G\) le barycentre de \( \{ (A,\alpha), (B,\beta),(C,\gamma) \}\).

	Alors \( G\) est barycentre de \( \{ (H,\alpha+\beta),(C,\gamma) \}\).
\end{lemma}

\begin{proof}
	Vues les définitions de \( H\) et \( G\) nous avons
	\begin{subequations}
		\begin{align}
			\alpha\vect{ HA }+\beta\vect{ HB }                   & =0  \\
			\alpha\vect{ GA }+\beta\vect{ GB }+\gamma\vect{ GC } & =0.
		\end{align}
	\end{subequations}
	En utilisant les relations de Chasles nous introduisons \( H\) dans la seconde relation :
	\begin{subequations}
		\begin{align}
			\alpha(\vect{ GH }+\vect{ HA })+\beta(\vect{ GH }+\vect{ HB })+\gamma\vect{ GC }                      & =0  \\
			(\alpha+\beta)\vect{ GH }+\underbrace{  \alpha\vect{ HA }+\beta\vect{ HB }   }_{=0}+\gamma\vect{ GC } & =0  \\
			(\alpha+\beta)\vect{ GH }+\gamma\vect{ GC }                                                           & =0.
		\end{align}
	\end{subequations}
\end{proof}

Les coordonnées barycentriques dans un triangle (et plus généralement en fait) permettent de faire des projections.

\begin{proposition}     \label{PROPooBCUVooWKttiH}
	Soient trois points non alignés \( A\), \( B\), \( C\) ainsi qu'un point \( N\) de coordonnées barycentriques  \( (\alpha,\beta,\gamma) \) dans le système \( (A,B,C)\). Si \( P\) est l'intersection \( (AN)\cap(BC)\) alors les coordonnées de \( P\) sont \( (0,\beta,\gamma)\).
\end{proposition}

\begin{proof}
	Un dessin de la situation :

	\begin{center}
		\input{auto/pictures_tex/Fig_GYODoojTiGZSkJ.pstricks}
	\end{center}

	Dire que les coordonnées de \( N\) sont \( (\alpha,\beta,\gamma)\) signifie que
	\begin{equation}
		\alpha\vect{ NA }+\beta\vect{ NB }+\gamma\vect{ NC }=0.
	\end{equation}
	Nous voudrions montrer que le point \( P\) est bien le point de coordonnées \( (0,\beta,\gamma)\). Soit donc le point \( P\) tel que
	\begin{equation}        \label{EQooYLGDooWqKKOM}
		\beta\vect{ PB }+\gamma\vect{ PC }=0
	\end{equation}
	et montrons que ce point est l'intersection \( (BC)\cap (NA)\).

	D'abord la relation \eqref{EQooYLGDooWqKKOM} nous dit immédiatement que \( P\) est sur la droite \( (BC)\). Ensuite, en utilisant les relations de Chasles pour introduire \( N\) :
	\begin{equation}
		\beta(\vect{ PN }+\vect{ NB })+\gamma(\vect{ PN }+\vect{ NC })=0.
	\end{equation}
	Nous remplaçons \( \beta\vect{ NB }+\gamma\vect{ NC }\) par \( -\alpha\vect{ NA }\) pour obtenir :
	\begin{equation}
		(\beta+\gamma)\vect{ PN }-\alpha\vect{ NA }=0.
	\end{equation}
	Cela montre que les vecteurs \( \vect{ PN }\) et \( \vect{ NA }\) sont colinéaires, et donc que \( P\), \( N\) et \( A\) sont alignés.
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Applications affines sur \( \eR^n\)}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Soit \( v\in \eR^n\); nous notons \( \tau_v\colon \eR^n\to \eR^n\) la translation donnée par \( \tau_v(x)=x+v\). Le groupe de toutes les translations de \( \eR^n\) est noté \( T(n)\) et est isomorphe au groupe abélien \( (\eR^n,+)\).

Nous avons déjà discuté de la structure d'un espace vectoriel (en particulier \( \eR^n\)) comme espace affine en~\ref{NORMooXAJLooIupekj}.


\begin{lemma}\label{LEMooZZAIooOMiayy}
	Décomposition d'une application affine.
	\begin{enumerate}
		\item       \label{ITEMooSJBFooYHURto}
		      Une application \( f\colon E\to E\) est affine si et seulement si il existe \( v\in E\) et une application linéaire \( \alpha\) sur \( E\) telle que \( f=\tau_v\circ\alpha\).
		\item       \label{ITEMooPYEOooKIesYm}
		      Dans ce cas, le choix de \( (v,\alpha)\) est unique.
		\item       \label{ITEMooHIAUooRxfTqx}
		      Si \( f\) est bijective, alors \( \alpha\) est bijective.
	\end{enumerate}
\end{lemma}

\begin{proof}
	Nous supposons d'abord que \( f\) est affine. Alors il existe une application linéaire \( u_f\) sur \( E\) telle que
	\begin{equation}
		f(M+x)=f(M)+u_f(x)=(\tau_{f(M)}\circ u_f)(x)
	\end{equation}
	pour tout \( x\) et \( M\). De plus l'application \( u_f\) ne dépend ni de \( M\) ni de \( x\) (c'est la proposition~\ref{PROPooALXYooHoMdqQ}\ref{ITEMooSKCYooHyRZYN}). En posant \( M=0\) nous avons :
	\begin{equation}
		f(x)=(\tau_{f(0)}\circ u_f)(x).
	\end{equation}

	Dans l'autre sens nous supposons avoir \( v\in E\) et \( \alpha\) linéaire sur \( E\) telles que
	\begin{equation}
		f(M)=(\tau_v\circ\alpha)(M).
	\end{equation}
	Notons qu'il y a un abus de notation entre \( \alpha\) qui est linéaire sur l'espace \emph{vectoriel} \( E\) et l'application \( \alpha\) qui est une application sur l'espace \emph{affine} \( E\). Cet abus est légitime parce que les deux espaces sont identiques en tant qu'ensembles. Ce qui est vraiment abuser par contre, c'est de se poser ce genre de questions.

	Nous avons :
	\begin{equation}
		\begin{aligned}[]
			f(M+x)=\tau_v\big( \alpha(M+x) \big)=\alpha(M+x)+v & =\alpha(M)+v+\alpha(x)
			\\&=(\tau_v\circ\alpha)(M)+\alpha(x)=f(M)+\alpha(x).
		\end{aligned}
	\end{equation}
	Donc la fonction \( f\) vérifie la définition~\ref{DEFooUAWZooXcMKve}. La partie \ref{ITEMooSJBFooYHURto} est prouvée.

	Pour prouver l'unicité de la partie \ref{ITEMooPYEOooKIesYm}, nous supposons que \( \tau_v\circ\alpha=\tau_w\circ \alpha\). En appliquant cela à \( 0\) nous trouvons \( v=w\). Nous avons donc \( \tau_v\circ \alpha=\tau_v\circ\beta\). Comme \( \tau_v\) est inversible, nous en déduisons \( \alpha=\beta\).

	Enfin le point \ref{ITEMooHIAUooRxfTqx} est relativement évident du fait que \( \tau_v\), elle, est surement bijective.
\end{proof}

\begin{corollary}       \label{CORooATCNooUwEPNI}
	Une application affine qui conserve l'origine est linéaire.
\end{corollary}

\begin{proof}
	Conserver l'origine demande de poser \( v=0\) dans l'expression du lemme~\ref{LEMooZZAIooOMiayy}.
\end{proof}

\begin{proposition}     \label{PROPooYRCJooIcmUVI}
	Soit une application affine \( f\colon \eR^n\to \eR^n\). L'ensemble des points fixes
	\begin{equation}
		\Fix(f)=\{ x\in \eR^n\tq f(x)=x \}
	\end{equation}
	est soit vide soit un sous-espace affine de \( \eR^n\).
\end{proposition}

\begin{proof}
	Soit \( f=\tau_v\circ \alpha\); nous avons \( x\in\Fix(f)\) si et seulement si
	\begin{equation}
		x=\tau_v\big( \alpha(x) \big)=\alpha(x)+v,
	\end{equation}
	autrement dit, en considérant l'application linéaire \( \beta=\id-\alpha\), si et seulement si \( \beta(x)=v\). Nous écrivons \( \Fix(f)=\beta^{-1}(v)\). Supposons que cet ensemble soit non vide et considérons \( x_0\in\beta^{-1}(v)\). Nous avons
	\begin{subequations}
		\begin{align}
			\beta^{-1}(v) & =\{ x\in \eR^n\tq \beta(x)=\beta(x_0) \} \\
			              & =\{ x\tq \beta(x-x_0)=0 \}               \\
			              & =\{ x\tq x-x_0\in \ker(\beta) \}         \\
			              & =\ker(\beta)+x_0                         \\
			              & =\tau_{x_0}\big( \ker(\beta) \big).
		\end{align}
	\end{subequations}
	Mais comme \( \ker(\beta)\) est un sous-espace vectoriel, \( \beta^{-1}(v)\) est le translaté d'un sous-espace vectoriel, c'est-à-dire un sous-espace affine.
\end{proof}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Structure de groupe pour les applications affines}
%---------------------------------------------------------------------------------------------------------------------------

\begin{propositionDef}[\cite{MonCerveau}]      \label{PROPooBPKKooJRAMeT}
	L'ensemble des applications affines bijectives de \( \eR^n\) forment un groupe pour la composition. Les lois de groupe sont données par les formules suivantes :
	\begin{enumerate}
		\item
		      Le neutre est l'identité.
		\item       \label{ITEMooGUFRooMuhXds}
		      Le produit est donné par
		      \begin{equation}        \label{EQooMIFSooKIvPnW}
			      (\tau_v\circ \alpha)(\tau_w\circ \beta)=\tau_{\alpha(w)+v}\circ \alpha\beta.
		      \end{equation}
		\item       \label{ITEMooYOMSooRUDSdm}
		      L'inverse est donné par
		      \begin{equation}
			      (\tau_v\circ\alpha)^{-1}=\tau_{-\alpha^{-1}(v)}\circ \alpha^{-1}.
		      \end{equation}
	\end{enumerate}
	Ce groupe est noté \( \Aff(\eR^n)\)\nomenclature[R]{\( \Aff(\eR^n)\)}{Le groupe des applications affines bijectives de \( \eR^n\).}.
\end{propositionDef}

\begin{proof}
	Pour l'identité, oui, composer par l'identité est neutre.

	Le fait que la formule \eqref{EQooMIFSooKIvPnW} soit vraie est un simple calcul :
	\begin{equation}
		(\tau_v\circ\alpha)\circ(\tau_w\circ\beta)(x)=(\alpha\beta)(x)+\alpha(w)+v=\big( \tau_{\alpha(w)+v}\circ \alpha\beta\big)x.
	\end{equation}

	Le fait que la formule \eqref{EQooMIFSooKIvPnW} donne bien un produit pour tous les éléments de \( \Aff(\eR^n)\) est le lemme \ref{LEMooZZAIooOMiayy}.

	En ce qui concerne l'inverse, c'est un calcul :
	\begin{subequations}
		\begin{align}
			(\tau_{-\alpha^{-1}(v)}\alpha^{-1})(\tau_v\alpha)(x) & =(\tau_{-\alpha^{-1}(v)}\alpha^{-1})\big( \alpha(x)+v \big) \\
			                                                     & =\tau_{-\alpha^{-1}(v)}\big( x+\alpha^{-1}(v) \big)         \\
			                                                     & =x.
		\end{align}
	\end{subequations}
\end{proof}

Si \( f\colon \eR^n\to \eR^n\) est une application affine, la proposition \ref{LEMooZZAIooOMiayy} affirme qu'il existe une application linéaire \( u\) telle que
\begin{equation}
	f(x+y)=f(x)+u(y).
\end{equation}
En écrivant cela pour \( x=0\),
\begin{equation}
	f(y)=f(0)+u(y),
\end{equation}
ou encore \( f=\tau_{f(0)}\circ u\).

\begin{proposition}  \label{PROPooTPFZooKtFxhg}
	L'ensemble \( \Aff(\eR^n)\) est isomorphe au produit semi-direct\footnote{Définition~\ref{DEFooKWEHooISNQzi}.}
	\begin{equation}
		\Aff(\eR^n)\simeq  T(n)\times_{\AD}\GL(n,\eR)
	\end{equation}
	où \( \AD\) est l'action adjointe, c'est-à-dire
	\begin{equation}
		\begin{aligned}
			\AD\colon \GL(n,\eR) & \to \Aut\big( T(n) \big)                                           \\
			\alpha               & \mapsto\big( \tau_v\mapsto \alpha\circ\tau_v\circ\alpha^{-1}\big).
		\end{aligned}
	\end{equation}
\end{proposition}

\begin{proof}
	En plusieurs points.
	\begin{subproof}
		\spitem[Égalité d'ensembles]
		Il faut que \( \Aff(\eR^n)\) soit en bijection avec \( T(n)\times \GL(n,\eR)\). En effet si \( f\in \Aff(\eR^n)\), la décomposition \(f=\tau_v\circ\alpha \) est unique. D'abord en appliquant à \( 0\), \( f(0)=\tau_v\big( \alpha(v) \big)=v\). Donc \( v\) est fixé par la valeur de \( f(0)\). Ensuite \( \alpha=f\circ\tau_v^{-1}\), donc \( \alpha \) fixé.
		\spitem[L'action adjointe fonctionne]
		Il faut vérifier que \( \alpha\circ\tau_v\circ\alpha^{-1}\) est bien dans \( T(n)\). Pour cela, en agissant sur \( x\in \eR^n\) nous trouvons
		\begin{equation}
			\alpha\tau_v\alpha^{-1}(x)=\alpha\big( \alpha^{-1}(x)+v \big)=x+\alpha(v)=\tau_{\alpha(v)}(x).
		\end{equation}
		Le fait que \( \AD(\alpha)\) soit un automorphisme est toujours correct.
		\spitem[Morphisme]
		Nous montrons que
		\begin{equation}
			\begin{aligned}
				\psi\colon T(n)\times \GL(n,\eR) & \to \Aff(\eR^n)            \\
				(\tau_v,\alpha)                  & \mapsto \tau_v\circ \alpha
			\end{aligned}
		\end{equation}
		est un isomorphisme de groupes. D'abord la loi de groupe sur \( \Aff(\eR^n)\) est donnée par
		\begin{equation}
			(\tau_v\circ \alpha)\circ(\tau_w\circ\beta)=\tau_{v+\alpha(w)}\circ(\alpha\circ\beta).
		\end{equation}
		Ensuite la loi de groupe du produit semi-direct est donnée par
		\begin{equation}
			(\tau_v,\alpha)\cdot(\tau_w,\beta)=\big( \tau_v\AD(\alpha)\tau_w,\alpha\beta \big)=\big( \tau_v\tau_{\alpha(w)},\alpha\beta \big)=\big( \tau_{\alpha(w)+v},\alpha\beta \big).
		\end{equation}
		Nous avons donc bien
		\begin{equation}
			\psi\big( (\tau_v,\beta)\cdot(\tau_w,\beta) \big)=\psi(\tau_v,\beta)\circ\psi(\tau_w,\beta).
		\end{equation}
	\end{subproof}
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Isométries}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{definition}[Isométrie d'espace affine]       \label{DEFooZGKBooGgjkgs}
	Si \( \affE\) est un espace affine muni d'une distance \( d\), une isométrie de \( \affE\) est une application \( f\colon \affE\to \affE\) préservant \( d\), c'est-à-dire telle que
	\begin{equation}
		d( x,y )=d\big( f(x), f(y) \big).
	\end{equation}
\end{definition}
Notons que toutes les applications affines ne sont pas des isométries : par exemple les homothéties.

\begin{proposition}     \label{PROPooHSOGooBbFTYt}
	Si \( \affE\) est modelé sur un espace euclidien \( (E,\| . \|)\) alors la formule
	\begin{equation}
		d(A,B)=\| \vect{ AB } \|
	\end{equation}
	définit une distance\footnote{Définition \ref{DefMVNVFsX}.} sur \( \affE\).
\end{proposition}

\begin{proof}
	Étant donné la proposition \ref{DEFooWAYTooMLbqEE}, la formule a un sens parce qu'à \( A\) et \( B\) donnés dans \( \affE\), il est associé un unique vecteur \( \vect{ AB }\in E\).

	Pour vérifier que \( d\) est une distance, nous vérifions les points de la définition \ref{DefMVNVFsX} et nous utilisons les propriétés correspondantes dans la définition \ref{DefNorme} d'une norme.
	\begin{enumerate}
		\item
		      \( d(A,B)= \| \vect{ AB } \|\geq 0\).
		\item
		      Si \( d(A,B)=0\), alors \( \| \vect{ AB } \|=0\), ce qui implique que \( \vect{ AB }=0\). Nous avons donc
		      \begin{subequations}
			      \begin{align}
				      B & =A+\vect{ AB } & \text{proposition \ref{DEFooWAYTooMLbqEE}} \\
				        & =A+0                                                        \\
				        & =A             & \text{lemme \ref{LEMooFZCRooQxzObv}.}
			      \end{align}
		      \end{subequations}
		\item
		      En utilisant la proposition \ref{PROPooCOZCooCghwaR}\ref{ITEMooLDVXooFZMbsQ},
		      \begin{equation}
			      d(A,B)=\| \vect{ AB } \|=\| -\vect{ BA } \|=\| \vect{ BA } \|=d(B,A)
		      \end{equation}
		\item
		      En utilisant les relation de Chasles \ref{PROPooCOZCooCghwaR}\ref{ITEMooSDMIooUQiKeW} ainsi que l'inégalité triangulaire \ref{DefNorme}\ref{ItemDefNormeiii}
		      \begin{equation}
			      d(A,B)=\| \vect{ AB } \|=\| \vect{ AC }+\vect{ CB } \|\leq \| \vect{ AC } \|+\| \vect{ CB } \|=d(A,C)+d(C,B).
		      \end{equation}
	\end{enumerate}
\end{proof}

Nous parlons d'isométries affines ou linéaires dans le thème \ref{THMooVUCLooCrdbxm}.
