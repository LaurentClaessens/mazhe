% This is part of Mes notes de mathématique
% Copyright (c) 2008-2009,2011-2019
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Autour de Cauchy-Lipschitz}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\label{SECooNKICooDnOFTD}

Dans cette section nous étudions les équations différentielles du type
\begin{subequations}
    \begin{numcases}{}
        y'(t)=f\big( t,y(t) \big)\\
        y(t_0)=y_0.
    \end{numcases}
\end{subequations}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Fuite des compacts et explosion en temps fini}
%---------------------------------------------------------------------------------------------------------------------------

\begin{theorem}[Fuite des compacts\cite{GPRooZkclFA,ZPNooLNyWjX}]
Nous considérons l'équation différentielle
\begin{subequations}
    \begin{numcases}{}
        y'(t)=f\big( t,y(t) \big)\\
        y(t_0)=y_0,
    \end{numcases}
\end{subequations}
où \( f\colon I\times \Omega\to \eR^n\) est continue et \( \Omega\) ouvert dans \( \eR^n\). Soit la solution maximale \( y_M\colon J_M=\mathopen] t_{min} , t_{max} \mathclose[\to \Omega\). Si \( t_{max}<\sup(I)\) alors \( y_M(t)\) sort de tout compact de \( \Omega\) lorsque \( t\to t_{max}\).
\end{theorem}
\index{théorème!fuite des compacts}

\begin{proof}
Soit \( K\) un compact de \( \Omega\) et nous considérons une suite \( (t_m)\) dans \( \mathopen] t_{min} , t_{max} \mathclose[\) telle que \( t_m\to t_{max}\). Si nous supposons que \( y_M(t)\) ne sort pas de \( K\) alors nous avons \( y_M(t_m)\in K\), c'est-à-dire une suite dans un compact. Quitte à passer à une sous-suite, nous supposons qu'elle est convergente. Soit \( x_1\in K\) la limite \( \lim_{m\to \infty}y_M(t_m)=x_1\).

    Vu que \( t_{max}\in I\), la condition initiale \( y(t_{max})=x_1\) est valide et le théorème de Cauchy-Lipschitz~\ref{ThokUUlgU} nous donne une unique solution maximale \( y_P\) définie sur un ouvert \( J_P\) autour de \( t_{max}\).

    Nous allons maintenant construire une solution au problème initial qui contredit la maximalité de \( y_M\). Attention : il n'est pas évident à priori que \( y_P(t)=y_M(t)\) sur l'intersection des domaines. Si c'était évident, la proposition serait démontrée.

    Soit \( \tilde J=J_M\cup J_P\cap\mathopen] t_{min} , +\infty \mathclose[\) et la fonction
        \begin{equation}
            \tilde y(t)=\begin{cases}
                y_M(t)    &   \text{si } t<t_{max}\\
                y_P(t)    &    \text{si } t\geq t_{max}.
            \end{cases}
        \end{equation}
        La fonction \( \tilde y\) est continue par construction parce que
        \begin{equation}
            \lim_{t\to t_{max}} y_M(t)=x_1=y_P(t_{max}).
        \end{equation}
        Nous vérifions à présent que \( \tilde y\) est une solution : \( \tilde y'(t_{max})=f\big( t_{max},y(t_{max}) \big)\) :
        \begin{subequations}
            \begin{align}
                \lim_{\epsilon\to 0}\frac{ \tilde y(t_{max}-\epsilon)-\tilde y(t_{max}) }{ \epsilon }&=\lim_{\epsilon\to 0}\frac{ y_M(t_{max}-\epsilon)-y_P(t_{max}) }{ \epsilon }\\
                &=\lim_{\epsilon\to 0}\frac{ y_M(t_{max}-\epsilon)-y_P(t_{max}-\epsilon)+y_P(t_{max}-\epsilon)-y_P(t_{max}) }{ \epsilon }\\
                &=\lim_{\epsilon\to 0}\frac{ y_P(t_{max}-\epsilon)-y_P(t_{max}) }{ \epsilon }\\
                &=y'_P(t_{max}).
            \end{align}
        \end{subequations}
        Donc \( \tilde y\) est solution pour la condition initiale \( \tilde y(t_{max})=x_1\) et coïncide avec \( y_P\) en \( t_{max}\) et avec \( y_M\) avant \( t_{max}\). Donc en réalité \( y_P\), \( y_M\) et \( \tilde y\) sont identiques et cela contredit la maximalité de \( y_M\).
\end{proof}

\begin{corollary}[Explosion en temps fini]      \label{CorGDJQooNEIvpp}
    Soit \( (y_m,J)\) la solution maximale du problème de Cauchy \eqref{XtiXON} :
    \begin{subequations}
        \begin{numcases}{}
            y'=f(t,y)\\
            y(t_0)=y_0,
        \end{numcases}
    \end{subequations}
    avec \( f\colon U=I\times \Omega\to \eR^n\) où \( I\) est ouvert dans \( \eR\) et \( \Omega\) ouvert dans \( \eR^n\). Nous supposons que \( f\) est continue sur \( U\) et localement Lipschitz par rapport à \( y\).

    Si la solution maximale est définie sur \( J=\mathopen] t_{min} , t_{max} \mathclose[\) alors nous avons l'alternative suivante :
    \begin{enumerate}
        \item   \label{ItemOLYYooJVkRfj}
            Soit \( t_{max}=\sup(I)\),
        \item       \label{ITEMooUKFAooXwRNSB}
            soit \( t_{max}<\sup(I)\) et \( \lim_{t\to t_{max}}  \| y(t) \|= \infty\).
    \end{enumerate}

    Le résultat tient aussi \emph{mutatis mutandis} pour \( t_{\min}\).
\end{corollary}

\begin{remark}
    Attention : ceci n'est pas une simple paraphrase de la fuite des compacts. L'information supplémentaire que ce corolaire donne est que la solution sort de tout compact \emph{pour ne plus y retourner}.
\end{remark}

\begin{proof}
    L'hypothèse \( t_{max}<\sup(I)\) signifie que la solution finit d'exister avant que les hypothèses sur \( f\) cessent d'être vraies. C'est-à-dire que la solution maximale est moindre que ce que nous aurions pu espérer.

Soit un compact \( K\). Supposons que que pour tout \( t_0<t_{max}\) il existe \( t\in\mathopen] t , t_{max} \mathclose[\) tel que \( y_M(t)\in K\). Alors cela crée une suite \( t_k\) dans \( J\) telle que \( y_M(t_k)\) est dans \( K\). Comme dans le théorème de la fuite des compacts nous concluons l'impossibilité de la chose.

    Donc pour tout compact \( K\) de \( \Omega\), il existe \( T<t_{max}\) tel que \( y_M(t)\in \Omega\setminus K\) pour tout \( t\in\mathopen[ T , t_{max} [\). En prenant des boules fermées de plus en plus grandes en guise de compacts nous concluons que
        \begin{equation}
            \lim_{t\to t_{max}} \| y_M(t) \|=\infty.
        \end{equation}
\end{proof}

\begin{normaltext}      \label{NORMooZROGooZfsdnZ}
    Notons que si \( t_{max}<\infty\), si nous sommes dans l'alternative~\ref{CorGDJQooNEIvpp}\ref{ITEMooUKFAooXwRNSB} et si la solution maximale \( y\) est de classe \( C^1\) (ce qui est le cas lorsqu'on utilise Cauchy-Lipschitz~\ref{ThokUUlgU}) alors la dérivée de \( y\) est également non bornée dans un voisinage de \( t_{max}\).

    Mais si \( f\) est globalement bornée, alors dans l'équation \( y'=f(t,y)\), la dérivée \( y'\) sera globalement bornée. Dans ce cas, la solution ne peut pas exploser en temps fini et existe donc globalement.
\end{normaltext}

\begin{probleme}
    Êtes-vous d'accord avec~\ref{NORMooZROGooZfsdnZ} ?
\end{probleme}

\begin{example}
    Soit l'équation différentielle
    \begin{subequations}
        \begin{numcases}{}
            y'=y(y-1)\sin(yt)\\
            y(0)=\frac{1}{2}.
        \end{numcases}
    \end{subequations}
    La fonction \( f(t,y)=y(y-1)\sin(yt)\) ayant une dérivée bornée partout, elle est localement Lipschitz et le théorème de Cauchy-Lipschitz~\ref{ThokUUlgU} s'applique. Pour toute condition initiale, une solution maximale unique existe.

    Si nous oublions la condition initiale, il est facile de trouver des solutions constantes : \( y'=0\) avec \( y(t)=k\) donne l'équation
    \begin{equation}
        0=k(k-1)\sin(kt).
    \end{equation}
    Les solutions \( y_1(t)=0\) et \( y_2(t)=1\) sont des solutions existant pour tout \( t\).

    Le graphe de la solution correspondante à la condition initiale \( y(0)=\frac{ 1 }{2}\) ne pouvant pas croiser les graphes de \( y_1\) et \( y_2\), elle est obligée d'exister pour tout \( t\) parce qu'elle ne peut pas exploser en temps fini.
\end{example}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Écart entre deux conditions initiales}
%---------------------------------------------------------------------------------------------------------------------------

\begin{proposition}[\cite{ooBSUCooIKClhZ,ooUQOJooSPNjlt}]      \label{PROPooOPRRooQgYFDk}
    Soit une fonction \( f\colon I\times \Omega\to \eR^n\) continue et globalement Lipschitz en sa seconde variable (\( \Omega\) est un ouvert de \( \eR^n\)). Soient deux solutions \( y_1\colon I_1\to \eR^n\) et \( y_2\colon I_2\to \eR^n\) aux problèmes
    \begin{subequations}
        \begin{numcases}{}
            y_i'(t)=f\big( t,y_i(t) \big)\\
            y_i(t_0)=a_i.
        \end{numcases}
    \end{subequations}
    Alors pour tout \( t\in I_1\cap I_2\) nous pouvons estimer l'écart entre \( y_1\) et \( y_2\) par la formule
    \begin{equation}
        \| y_1(t)-y_2(t) \|\leq  e^{L| t-t_0 |}\| a_1-a_2 \|,
    \end{equation}
    où \( L\) est la constante de Lipschitz de \( f\).
\end{proposition}

\begin{proof}
    Nous avons d'abord les majorations suivantes, qui semblent juste jouer avec les notations, mais qui utilisent le fait (contenu dans le théorème de Cauchy-Lipschitz) que \( y_i\) soit de classe \( C^1\) :
    \begin{subequations}
        \begin{align}
            \| y_1(t)-y_2(t) \|&=\| \int_{t_0}^t\big( y'_1(s)-y'_1(s) \big) \|\\
            &\leq L\int_{t_0}^t\| f\big( s,y_1(s) \big)-f\big( s,y_2(s) \big) \|ds\\
            &=L\int_{t_0}^t\| y_1(s)-y_2(s) \|ds.
        \end{align}
    \end{subequations}
    C'est à ce moment que nous utilisons le lemme de Grönwall. Vu que
    \begin{equation}
            \| y_1(t)-y_2(t) \|\leq L\int_{t_0}^t\| y_1(s)-y_2(s) \|ds,
    \end{equation}
    nous sommes dans les hypothèses de Grönwall~\ref{LEMooUGZGooCczAmKa} en posant
    \begin{subequations}
        \begin{align}
            u(t)&=\| y_1(t)-y_2(t) \|\\
            b(t)&=\| y_1(0)-y_2(0) \|\\
            a(t)&=L.
        \end{align}
    \end{subequations}
    Nous avons la majoration
    \begin{equation}
        \| y_1(t)-y_2(t) \|\leq \| y_1(0)-y_2(0) \|+L\int_0^t\| y_1(0)-y_2(0) \| e^{L(t-s)}ds.
    \end{equation}
    Le calcul de l'intégrale intérieure donne
    \begin{equation}
        \int_0^t e^{L(t-s)}ds=-\frac{1}{ L }( e^{-Lt}-1).
    \end{equation}
    Avec ça, nous avons
    \begin{equation}
        \| y_1(t)-y_2(t) \|\leq  e^{Lt}\| y_1(0)-y_2(0) \|.
    \end{equation}
\end{proof}

\begin{normaltext}
    Notons que la proposition~\ref{PROPooOPRRooQgYFDk} est plutôt une mauvaise nouvelle parce que les solutions restent seulement linéairement proches l'une de l'autre lorsqu'on rapproche les conditions initiales, mais elle divergent exponentiellement vite avec le temps. Donc deux trajectoires arbitrairement proches au départ finissent assez vite par être bien séparées.

   Cette proposition est cependant cruciale parce qu'elle explique que pour des petits \( t\), les solutions ne s'écartent pas beaucoup, c'est-à-dire que pour \( t\) fixé, l'application qui à une donnée initiale fait correspondre la solution en \( t\) est continue. C'est le premier pas pour parler de régularité du flot.

\end{normaltext}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Flot d'un champ de vecteurs}
%---------------------------------------------------------------------------------------------------------------------------

Nous reprenons l'équation différentielle du théorème de Cauchy-Lipschitz~\ref{ThokUUlgU}. En ce qui concerne les notations, \( I\) est un intervalle ouvert de \( \eR\) contenant \( 0\) et l'application \( f\colon I\times \eR^n\to \eR^n \) est continue et localement Lipschitz en sa seconde variable. Pour \( a\in \eR^n\), nous notons \( (J_a,y_a)\) la solution maximale (donc \( y_a\colon J_a\to \eR^n\)) du problème
\begin{subequations}        \label{EQooADJMooRAZWfm}
    \begin{numcases}{}
        y_a(t)=f\big( t,y_a(t) \big)\\
        y_a(0)=a.
    \end{numcases}
\end{subequations}
Nous noterons aussi de temps en temps \( \varphi(t,a)=y_a(t)\).

Nous savons que \( t\mapsto y_a(t)\) est de classe \( C^1\), et cela est directement dans le théorème de Cauchy-Lipschitz. Une question d'une toute autre difficulté est la régularité de \( a\mapsto y_a(t)\) pour \( t\) fixé, et encore pire : celle de \( (t,a)\mapsto y_a(t)\).

Il se fait que l'application \( (t,a)\mapsto y_a(t)\) a la même régularité que celle de \( f\), mais cela va être un peu long à prouver. En ce qui concerne la régularité \( C^1\), ce sera le théorème~\ref{THOooSTHXooXqLBoT} dont la démonstration, comme vous pouvez le voir sera copieuse et demandera des propositions intermédiaires pas simples.

\begin{definition}
    Si \( t\) est fixé, l'application
    \begin{equation}
        \begin{aligned}
            \varphi_t\colon \eR^n&\to \eR^n \\
            x&\mapsto \varphi(t,x) = y_x(t),
        \end{aligned}
    \end{equation}
    est le \defe{flot}{flot} du problème de Cauchy \eqref{EQooADJMooRAZWfm}.

    L'application \( t\mapsto \varphi_t\) est ce qui est appelé le groupe à un paramètre de flot, pour des raisons qui arriverons plus tard\quext{ou pas\ldots}.
\end{definition}

Le but est d'étudier les propriétés du flot : est-il continu, un difféomorphisme, existe, pour quels \( t\) ? Où se cache le champ de vecteurs du titre dans l'équation différentielle ?

Nous posons
\begin{equation}
    \mD=\bigcup_{x\in\Omega}\big( J_x\times \{ x \} \big).
\end{equation}

Comme tout produit d'espaces métrique, l'ensemble \( \mD\) est muni d'une métrique via la définition~\ref{DefZTHxrHA}.

\begin{proposition}[\cite{ooBSUCooIKClhZ}]      \label{PROPooUDQWooNFrNOQ}
    Soit un intervalle \( I\) ouvert de \( \eR\) contenant \( 0\) et \( \Omega\) un ouvert connexe de \( \eR^n\). Soit une application \( f\colon I\times \eR^n\to \eR^n \) continue et localement Lipschitz en sa seconde variable. Pour \( a\in \eR^n\), nous notons \( (J_a,y_a)\) la solution maximale (donc \( y_a\colon J_a\to \eR^n\)) du problème
    \begin{subequations}
        \begin{numcases}{}
            y_a(t)=f\big( t,y_a(t) \big)\\
            y_a(0)=a.
        \end{numcases}
    \end{subequations}

    Nous posons
    \begin{equation}
        \mD=\bigcup_{x\in\Omega}\big( J_x\times \{ x \} \big).
    \end{equation}
    Nous définissons la fonction \( \varphi\) par \( \varphi(t,x)=y_x(t)\) là où ça existe.

    L'ensemble \( \mD\) est ouvert. L'application \( \varphi\colon \mD\to \Omega\) est localement Lipschitz.
\end{proposition}

\begin{proof}
    Soit \( (s,a)\in\mD\) et \( (J_a,y_a)\) la solution maximale passant par \( a\) en \( t=0\). Par définition de \( \mD\) nous avons \( s\in J_a\). Nous considérons \( J\), un compact inclus dans \( J_a\) et contenant \( 0\) et \( s\) en son intérieur. Nous posons
    \begin{equation}
        K=J\times y_a(J).
    \end{equation}
    Vu que \( y_a\) est continue, cela est un compact. Chaque point de \( K\) possède un voisinage ouvert sur lequel \( f\) est Lipschitz\footnote{Cela est à peu près la définition d'être localement Lipschitz :~\ref{DefJSFFooEOCogV}, voir aussi~\ref{NORMooYNRAooBgobcK}.}; nous considérons un sous recouvrement fini et le maximum des constantes de Lipschitz. Cela nous crée un voisinage \( V\) de \( K\) dans \( I\times \Omega\) dans lequel \( f\) est Lipschitz.

    Vu que \( V\) est ouvert et \( K\) est compact avec \( K\subset V\), nous pouvons trouver un ouvert \( V'\) et un compact \( K'\) tels que
    \begin{equation}
        K\subset V'\subset K'\subset V.
    \end{equation}
    Sur ce \( V'\), la fonction \( f\) est de plus bornée parce que continue sur le compact \( K'\). Nous renommons \( V'\) en \( V\). Sur \( V\) nous avons :
    \begin{itemize}
        \item \( \| f \|_{\infty,V}\leq M\),
        \item \( f\) est Lipschitz en sa seconde variable, de constante de Lipschitz \( L\).
    \end{itemize}


    En tant qu'espace produit, nous avons une distance sur \( I\times \Omega\) donnée en~\ref{DefZTHxrHA} :
    \begin{equation}
        d\big( (t,y),(t',y') \big)=\max\big\{  | t-t' |,\| y-y' \|   \big\}.
    \end{equation}
    Nous posons
    \begin{subequations}
        \begin{align}
            V_{\epsilon}(K)=\{ z\in I\times \Omega \tq\,d(z,K)<\epsilon  \}\\
            W_{\epsilon}=\{ (t,y)\in J\times \Omega\tq\,\| y- y_a(t) \|<\epsilon \}.
        \end{align}
    \end{subequations}

    \begin{subproof}
    \item[\( \overline{ W_{\epsilon} }\subset \overline{  V_{\epsilon}(K) }\)]

        Soit \( (t,y)\in W_{\epsilon}\). Nous avons :
        \begin{subequations}
            \begin{align}
                d\big( (t,y),K \big)&=\inf_{(t',y')\in K}d\big( (t,y),(t',y') \big)\\
                &=\inf_{(t',y')\in K}\max\{ | t-t' |,\| y-y' \| \}.     \label{SUBEQooUCZXooRpAitk}
            \end{align}
        \end{subequations}
        Mais demander \( (t,y)\in W_{\epsilon}\) signifie que \( t\in J\) et \( \| y-y_a(t) \|\leq \epsilon\). Dans \( K \) nous avons l'élément \( \big( t,y_a(t) \big)\) qui vérifie
        \begin{equation}
            d\big( (t,y),(t,y_a(t)) \big)=\| y-y_a(t) \|\leq \epsilon.
        \end{equation}
        Donc l'infimum de \eqref{SUBEQooUCZXooRpAitk} est majoré par \( \epsilon\). Nous avons prouvé que \( W_{\epsilon}\subset V_{\epsilon}(K)\) et donc même inclusion pour les fermetures.

    \item[Il existe \( \epsilon>0\) tel que \( \overline{ V_{\epsilon}(K) }\subset V\)]

        Supposons que \( \overline{ V_{\epsilon}(K) }\) ne soit inclus dans \( V\) pour aucun \( \epsilon\). Alors nous considérons
        \begin{equation}
            z_n\in \overline{ V_{1/n}(K) }\setminus V.
        \end{equation}
        Nous avons par définition \( d(z_n,K)\leq \frac{1}{ n }\). Vu que \( K\) est compact, il comprend (au moins) un élément réalisant la distance : soit \( z'_n\in K\) tel que
        \begin{equation}
            d(z_n,z'_n)=d(z_n,K).
        \end{equation}
        Nous avons \( d(z_n,z'_n)\to 0\), de telle sorte que les valeurs d'adhérence de \( (z_n)\) et \( (z'_n)\) sont les mêmes. Et comme \( (z'_n)\) est une suite dans un compact, elle a des valeurs d'adhérence. Soit \( z_{\infty}\) l'une d'elles. Vu que c'est une valeur d'adhérence d'une suite contenue dans le compact \( K\), elle est également dans \( K\) : \( z_{\infty}\in K\). Mais en même temps, \( z_n\) est hors de l'ouvert \( V\), et donc dans le fermé \( V^c\). Les valeurs d'adhérences restent dans le fermé, c'est-à-dire \( z_{\infty}\notin V\). Vu que \( K\subset V\), il y a contradiction.

        Donc il existe \( \epsilon>0\) tel que \( \overline{ V_{\epsilon}(K) }\subset V\).

    \item[Il existe \( \epsilon\) tel que \( \overline{ W_{\epsilon} }\subset V\)]

        Il suffit de prendre le \( \epsilon\) dont nous venons de parler pour avoir
        \begin{equation}
            \overline{ _{\epsilon} }\subset \overline{ V_{\epsilon}(K) }\subset V.
        \end{equation}

    \end{subproof}
    Soit le \( \epsilon\) en question, et \( T>0\) tel que \( J\subset \mathopen[ -T , T \mathclose]\). Nous posons \( r=\epsilon e^{-LT}\). Soit \( b\in \overline{ B(a,r) } \) et
    \begin{equation}
    X=\{ \tau\in J_{+}\tq\,\mathopen] 0 , \tau \mathclose]\subset J_b\text{ et }    \big( t,y_b(t) \big)\in \overline{ W_{\epsilon} }\,\forall\,t\in\mathopen[ 0 , \tau \mathclose]     \}.
    \end{equation}
Nous allons prouver que \( X=J_{+}\) en prouvant qu'il est ouvert, fermé et non vide dans \( J_+=J\cap\mathopen] 0 , \infty \mathclose[\). Nous parlons bien de la topologie de \( J_+\), celle induite\footnote{Définition~\ref{DefVLrgWDB}.} de \( \eR\). Vu que \( 0\in J\), l'ensemble \( J_+\) est ouvert à gauche, mais comme il est compact, il ne va certainement pas jusqu'à \( +\infty\), de telle sorte qu'il est fermé à gauche. Les ouverts de \( J_+\) sont les ensembles de la forme \( \mO\cap J_+\) où \( \mO\) est ouvert de \( \eR\). Il y en a de la forme \( \mathopen] 0 , m \mathclose]\).

    \begin{subproof}
        \item[\( X\) est fermé]

            C'est parce que \( \overline{ W_{\epsilon} }\) et \( J_b\) sont fermés.

        \item[\( X\) est ouvert]

            Soit \( \tau\in X\). Si \( \tau=\sup J_+\) alors \( X=J_+\) est un ouvert de \( J_+\). Supposons donc que \( 0<\tau<\sup J_+\). Dans ce cas nous avons
            \begin{equation}
                \big( \tau,y_b(\tau) \big)\in\overline{ W_{\epsilon} }\subset V,
            \end{equation}
            et nous pouvons résoudre localement le problème de Cauchy
            \begin{subequations}
                \begin{numcases}{}
                    y'(t)=f\big( t,y(t) \big)\\
                    y(\tau)=\varphi(\tau,b)=y_b(\tau).
                \end{numcases}
            \end{subequations}
            Ce \( y\) existe jusqu'à \( \tau+\eta\) (pour au moins un petit \( \eta\)), et par l'unicité de la solution, \( y=y_b\) sur \( \mathopen[ \tau , \tau+\eta \mathclose[\). Ceci pour dire que le flot \( \varphi(.,b)\) existe au moins jusqu'à \( \tau+\eta\).

                Grâce à la proposition~\ref{PROPooOPRRooQgYFDk} nous pouvons évaluer
                \begin{equation}
                    \| \varphi(\tau,b)-\varphi(\tau,a) \|=\| y_a(\tau)-y_b(\tau) \|\leq  e^{L\tau}\| b-a \|.
                \end{equation}
                Comme nous avions choisi \( r=\epsilon e^{-LT}\) et \( b\in\overline{ B(a,r) }\) nous avons aussi \( \| b-a \|\leq \epsilon e^{-LT}\) et donc
                \begin{equation}
                    \| \varphi(\tau,b)-\varphi(\tau,a) \|\leq\epsilon e^{L(\tau-T)}<\epsilon
                \end{equation}
                parce que nous avions \( \tau<\sup J_+\leq T\), ce qui garantit que \(  e^{L(\tau-T)}<1\).

                Est-ce que ceci nous garantit que \( \tau+\eta\in X\) ? Il faudrait \( \big( \tau+\eta,y_b(\tau+\eta) \big)\in \overline{ W_{\epsilon} }\), c'est-à-dire \(  \| y_b(\tau+\eta)-y_a(\tau+\eta) \|\leq\epsilon   \). L'ensemble \( J_+\) étant fermé dans l'ouvert \( J_a\), ce dernier déborde certainement. Prenons donc \( \eta\) assez petit pour que \( y_a\) existe jusqu'en \( \tau+\eta\).

                Vu que \( y_a\) et \( y_b\) sont continues, et qu'en \( \tau\) elles sont distantes de moins de \( \epsilon\), en \( \tau+\eta\), elles restent distantes de moins de \( \epsilon\) (quitte à prendre encore \( \eta\) plus petit).

                Ceci nous permet de conclure que \( X\) est ouvert.

            \item[\( X\) est non vide]

                La solution \( y_b\) au problème
                \begin{subequations}
                    \begin{numcases}{}
                        y_b'(t)=f\big( t,y_b(t) \big)\\
                        y_b(0)=b
                    \end{numcases}
                \end{subequations}
                existe au moins localement et vérifie \( \| y_b(0)-y_a(0) \|=\| b-a \|\leq \epsilon e^{-LT}<\epsilon\). Par continuité nous avons
                \begin{equation}
                    \| y_b(t)-y_a(t) \|<\epsilon
                \end{equation}
                pour tout \( t\) dans un voisinage de \( 0\). Donc \( X\) est non vide.

            \item[Conclusion pour \( X\)]

                La partie \( X\) est ouverte, fermée et non vide dans \( J_+\) qui est connexe. Donc \( X=J_+\) par la proposition~\ref{PropHSjJcIr}\ref{ITEMooNIPZooIDPmEf}.

    \end{subproof}

    La conclusion \( X=J_+\) nous enseigne que pour tout \( t\in J_+\) nous avons \( \mathopen] 0 , t \mathclose]\in J_b\) et \( \big( t,y_b(t) \big)\in \overline{ W_{\epsilon} }\). Nous pouvons faire la même chose pour \( J_-\) et au final nous avons que pour tout \( \tau\in J\) nous avons d'abord \( \tau\in J_b\), ce qui prouve \( J\subset J_b\). De plus pour tout \( t\in J\) nous avons aussi
    \begin{equation}
        \big( t,y_b(t) \big)\in\overline{ W_{\epsilon} }\subset V.
    \end{equation}
    Nous en concluons que
    \begin{equation}
        J\times \overline{ B(a,r) }\subset V.
    \end{equation}

    Nous savons de plus que pour tout \( b\in \overline{ B(a,r) }\), \( J\subset J_b\). Cela signifie que
    \begin{equation}
        J\times \overline{ B(a,r) }\subset \mD.
    \end{equation}

    Mais \( J\times \overline{ B(a,r) }\) est un voisinage de \( (s,a)\) qui était au début de la preuve un point générique choisi dans \( \mD\). Donc \( \mD\) est ouvert parce qu'il contient un voisinage de chacun de ses points.

    Il nous reste à voir que \( \varphi\colon \mD\to \Omega\) est localement Lipschitz. Soit donc le point générique \( (s,a)\) dans \( \mD\) et l'ensemble $V$ qui avait été construit plus haut. Nous allons montrer que \( \varphi\) est Lipschitz sur \( J\times \overline{ B(a,r) }\subset V\). D'abord sur \( V\), l'application \( f\) est Lipschitz, donc
    \begin{equation}
         \| \varphi(t,b_1)-\varphi(t,b_2) \|\leq  e^{Lt}\| b_1-b_2 \|
         \leq  e^{LT}\| b_1-b_2 \|
    \end{equation}
    pour tout \( t\in J\) et \( b_1,b_2\in \overline{ B(a,r) }\).

    Ensuite, \( f\) est bornée, majorée par \( M\) sur $V$, donc
    \begin{subequations}
        \begin{align}
            \| \varphi(t_1,b)-\varphi(t_2,b) \|&=| \int_{\mathopen[ t_1 , t_2 \mathclose]} y'_(s)ds |\\
            &=| \int_{\mathopen[ t_1 , t_2 \mathclose]}f\big( s,y_b(s) \big) |\\
            &\leq \int_{\mathopen[ t_1 , t_2 \mathclose]}| f\big( s,y_b(s) \big) |ds\\
            &\leq M| t_1-t_2 |.
        \end{align}
    \end{subequations}
    Et enfin nous prouvons que \( \varphi\) est localement Lipschitz. En posant \( k=\max\{  e^{LT},M \}\) nous avons
    \begin{subequations}
        \begin{align}
            \| \varphi(t_1,b_1)-\varphi(t_2,b_2) \|&\leq \| \varphi(t_1,b_1)-\varphi(t_1,b_2) \|+\| \varphi(t_1,b_2)-\varphi(t_2,b_2) \|\\
            &\leq  e^{LT}\| b_1-b_2 \|+M| t_1-t_2 |\\
            &\leq k\big( \| b_1-b_2 \|+| t_1-t_2 | \big)\\
            &\leq 2k\max\{ \| b_1-b_2 \|,| t_1-t_2 | \}\\
            &=2kd\big(  (b_1,t_2),(b_2,t_2)  \big).
        \end{align}
    \end{subequations}
    Le flot \( \varphi\) est donc Lipschitz de constante \( 2k\).
\end{proof}

\begin{example}

        \begin{probleme}
            Cet exemple doit être lu attentivement. Il me semble prouver que le flot n'est pas dérivable en la condition initiale sans que \( f\) le soit. Le document \cite{ooPMPXooEpbDkm} semble dire le contraire. Je ne suis pas assez sûr de mon coup pour contredire.
        \end{probleme}

    Il n'y a pas de raisons de penser que \( a\mapsto y_a(t)\) soit mieux que continue en sans hypothèses supplémentaires sur \( f\). Pour illustrer cela nous considérons l'équation différentielle
    \begin{subequations}
        \begin{numcases}{}
            \frac{ \partial X }{ \partial s }=f\big( X(s),s \big)\\
            X(t)=x
        \end{numcases}
    \end{subequations}
    où \( t\) et \( x\) sont des paramètres fixés. Nous allons étudier la dérivabilité de \( X\) en \( x\) lorsque
    \begin{equation}
        f(x,t)=| x |.
    \end{equation}
    Cela est un exemple typique de fonction autant Lipschitz que l'on veut sans être dérivable. L'équation différentielle est
    \begin{equation}
        \frac{ \partial X }{ \partial s }(s)=| X(s) |.
    \end{equation}
    Si \( x>0\) alors \( X(s)>0\) dans un voisinage de \( s=t\) et nous avons \( X(s)=K e^{s}\). La constante \( K\) se fixe par la condition initiale \( X(t)=x\) :
    \begin{equation}
        X(s)=x e^{s-t}.
    \end{equation}
    Et cette solution tient en réalité pour tout \( s\) parce que \( X(s)\) est alors toujours positif.

    Si au contraire \( x<0 \) nous avons la solution
    \begin{equation}
        X(s)=x e^{t-s}.
    \end{equation}
    Au final,
    \begin{equation}
        X(s;x,t)=
        \begin{cases}
            x e^{t-s}    &   \text{si } x<0\\
            0    &    \text{si }x=0\\
            x e^{s-t}    &    \text{si }x>0
        \end{cases}
    \end{equation}
    L'application \( (s,x,t)\mapsto X(s;x,t)\) est continue. En ce qui concerne la dérivée partielle \( \partial_xX\) en \( x=0\) nous avons :
    \begin{equation}        \label{EQooTQXQooAtRxNT}
        \frac{ \partial X }{ \partial x }(s,0,t)=\lim_{\epsilon\to 0}\frac{ X(s,\epsilon,t)-X(s,0,t) }{ \epsilon }=\lim_{\epsilon\to 0}\frac{ X(s,\epsilon,t) }{ \epsilon }.
    \end{equation}
    La limite à droite donne :
    \begin{equation}
        \lim_{\epsilon\to 0^+}\frac{ X(s,\epsilon,t) }{ \epsilon }=\frac{ \epsilon e^{s-t} }{ \epsilon }= e^{s-t}.
    \end{equation}
    La limite à gauche donne :
    \begin{equation}
        \lim_{\epsilon\to 0^-}\frac{ X(s,\epsilon,t) }{ \epsilon }= e^{t-s}.
    \end{equation}
    Les deux limites n'étant pas égales, la limite \eqref{EQooTQXQooAtRxNT} n'existe pas\footnote{Si vous comptez donner ça à manger au jury d'un concours, soyez prudent et n'écrivez pas l'équation \eqref{EQooTQXQooAtRxNT} au tableau. Réfléchissez comment rédiger cela correctement.} et l'application \( (s,x,t)\mapsto X(s,x,t) \) n'est pas dérivable par rapport à \( x\).
\end{example}

\begin{lemma}[\cite{ooGQTBooJKpoVP}]        \label{LEMooOJSNooXTJoEf}
    Soit un application \( A\colon \overline{ B(t_0,\tau) }\times \overline{ B(a,R) }\to \aL(\eR^n)\) continue par rapport à sa première variable (\( t_0\in \eR\) et \( a\in \eR^n\)). Alors en posant l'équation
    \begin{subequations}
        \begin{numcases}{}
            \frac{ \partial \psi }{ \partial t }(t,b)=A(t,b)\psi(t,b)\\
            \psi(t_0,b)=\psi_0.
        \end{numcases}
    \end{subequations}
    Nous avons l'estimation
    \begin{equation}
        \begin{aligned}[]
        \| \psi(t,v)-\psi(t,w) \|\leq \| \psi_0 \|\tau\max_{s\in\overline{ B(t_0,\tau) }}\| A(s,v)&-A(s,w) \|\times\\
        &\times \exp\left( \tau\max_{s\in\overline{ B(t_0,\tau) }}\max\{ \| A(s,v) \|,\| A(s,w) \| \} \right)
        \end{aligned}
    \end{equation}
    pour tout \( t\in\overline{ B(t_0,\tau) }\) et \( v,w\in V\).
\end{lemma}

\begin{theorem}[Régularité \( C^1\) du flot \cite{ooGQTBooJKpoVP}]      \label{THOooSTHXooXqLBoT}
    Soit un intervalle ouvert \( I \) de \( \eR\) et un ouvert connexe \( \Omega\) de \( \eR^n\). Soit une fonction \( f\in C^1\big( I\times \Omega,\eR \big)\), \( a\in \Omega\) et \( t_0\in I\).

    Il existe un voisinage \( W\times V = \overline{ B(t_0,\tau) }\times \overline{ B(a,r) }\) de \( (t_0,a)\) dans \( I\times \Omega\) et une unique application \( \varphi\colon W\times V\to \Omega\) telle que
    \begin{subequations}
        \begin{numcases}{}
            \frac{ \partial \varphi }{ \partial t }(t,x)=f\big( t,\varphi(t,x) \big)\\
            \varphi(t_0,x)=x
        \end{numcases}
    \end{subequations}
    pour tout \( x\in V\).

    L'application \( (t,x)\mapsto \varphi(t,x)\) est de classe \( C^1\).
\end{theorem}

\begin{probleme}
    La preuve qui suit doit être lue avec beaucoup d'attention, en particulier sur les incohérences possibles de notations, et sur les oublis possibles de précautions oratoires type «quitte à encore réduire les voisinages \( V\) et $W$».
\end{probleme}

\begin{proof}
    En termes de notations, pour \( x\in \Omega \) fixé nous écrivons \( y_x(t)\) pour \( \varphi(t,x)\) et pour \( t\in I\) fixé nous notons \( \varphi_t(x)\) pour \( \varphi(t,x)\).

    De plus lorsque nous écrirons des choses comme \( g\colon \eR\to \eR\), nous n'entendrons pas que \( g\) est effectivement définie sur tout \( \eR\). La notation «\( g\colon \eR\to \eR\)» indiquera seulement que la variable de \( g\) est réelle, et que nous comptons préciser le domaine plus tard. Cette remarque s'applique seulement à cette démonstration et non à l'ensemble du livre.

    Nous considérons \( R>0\) tel que \( \overline{ B(a,2R) }\subset\Omega\) et ensuite nous posons \( V=\overline{ B(a,R) }\). La fonction \( y_x\), solution pour la condition initiale \( y_x(t_0)=x\) est définie sur \( W=\mathopen[ t_0-\tau , t_0+\tau  \mathclose]\) et prend ses valeurs dans \( \overline{ B(x,R) }\). Ceci est parce que \( y_x\) est continue, alors en prenant \( \tau\) assez petit, la valeur de \( y_x(t)\) ne va pas s'éloigner de \( x\) lorsque \( t\) ne s'éloigne pas de \( t_0\).

    Nous savons déjà de la proposition~\ref{PROPooUDQWooNFrNOQ} que \( \varphi\) est \( C^1\) en \( t\) et localement Lipschitz en sa seconde variable, avec une constante Lipschitz uniforme sur \( W\times V\). Elle est donc continue en tant que fonction
    \begin{equation}
        \varphi\colon V\times W\to \eR^d.
    \end{equation}

    \begin{subproof}
        \item[La différentielle partielle \( Df\)]
            Pout \( t\) fixé nous notons \( Df_{(t,x)}\) la différentielle de \( f\) par rapport à \( x\). C'est-à-dire que
            \begin{equation}
                \begin{aligned}
                    Df_{(t,x)}\colon \eR^n&\to \eR^n \\
                    u&\mapsto \Dsdd{ f(t,x+su) }{s}{0}.
                \end{aligned}
            \end{equation}
            C'est un élément de \( \aL(\eR^n)\), l'ensemble des applications linéaires de \( \eR^n\) vers \( \eR^n\). Nous allons montrer que
            \begin{equation}
                (t,x)\mapsto Df_{(t,x)}
            \end{equation}
            est continue en tant qu'application \( \eR\times \eR^n\to\aL(\eR^n)\). Pour cela nous introduisons l'application d'inclusion \( i\colon \eR^n\to \eR\times \eR^n\), \( i(u)=(0,u)\). Elle donne
            \begin{equation}
                Df_{(t,x)}(u)=\Dsdd{ f\big( (t,x)+s(0,u) \big) }{s}{0}=df_{(t,x)}\circ i (u).
            \end{equation}
            Autrement dit
            \begin{equation}
                Df_{(t,x)}=df_{(t,x)}\circ i.
            \end{equation}
            Or l'application \( (t,x)\mapsto df_{(t,x)} \) est continue par hypothèse (\( f\) est de classe \( C^1\)) et l'application
            \begin{equation}        \label{EQooZTAPooCduWcl}
                \begin{aligned}
                     \aL(\eR\times \eR^n,\eR^n)&\to \aL(\eR^n,\eR^n) \\
                    A&\mapsto A\circ i
                \end{aligned}
            \end{equation}
            est également continue. Donc \( (t,x)\mapsto Df_{(t,x)}\) est continue\quext{Si quelqu'un peut prouver ça de façon moins verbeuse, je suis preneur. Il me semble que quel que soit la façon dont on s'y prend, sous le capot, on passe par la continuité de l'application \eqref{EQooZTAPooCduWcl}.}.

        \item[L'équation aux variations]

            Soit \( x\in \Omega\). Nous introduisons l'opérateur
            \begin{equation}
                \begin{aligned}
                    S_x\colon \eR\times \aL(\eR^n)&\to \aL(\eR^n) \\
                    S_x(t,\psi)&=Df_{(t,y_x(t))}\circ \psi.
                \end{aligned}
            \end{equation}
            Par ce que nous avons raconté, cela est une fonction continue en sa première variable et Lipschitz en sa seconde variable. Nous identifions \( \aL(\eR^n)\) à \( \eR^{2^n}\).

            Toujours pour chaque \( x\) considéré nous posons l'équation différentielle ordinaire
            \begin{subequations}        \label{EQooQONGooBrxuSA}
                \begin{numcases}{}
                    \frac{ \partial\psi }{ \partial t }(t,x)=S_x\big( t,\psi(t,x) \big)\\
                    \psi(t_0,x)=\id.
                \end{numcases}
            \end{subequations}
            qui est une équation différentielle ordinaire pour \( \psi\colon \eR\times \eR^n\to \aL(\eR^n)\) rentrant dans le cadre de Cauchy-Lipschitz.

            Quel est le domaine de définition de \( \psi\) pour sa première variable ? C'est un ouvert autour de \( t_0\). Nous réduisons \( W\) de telle sorte que la solution \( \psi\) soit définie sur \( W\). Idem pour la variable \( x\) qui est dans un voisinage de \( a\).

            L'équation \eqref{EQooQONGooBrxuSA} s'appelle l'\defe{équation aux variations}{équation!aux variations}. Nous allons montrer dans la douleur que \( \psi\) est continue et est la différentielle de \( \varphi_t\), c'est-à-dire que
            \begin{equation}
                (d\varphi_t)_b=\psi(t,b).
            \end{equation}

        \item[\( \psi\) est continue en \( (t,x)\) (début)]


            Il s'agit de majorer les deux termes de
            \begin{equation}        \label{EQooVUNUooExeQba}
                \| \psi(t_1,a_1)-\psi(t_2,a_2) \|\leq \| \psi(t_1,a_1)-\psi(t_2,a_1) \|+\| \psi(t_2,a_1)-\psi(t_2,a_2) \|.
            \end{equation}

            \begin{subproof}

        \item[Premier terme]

            Nous avons
            \begin{subequations}
                \begin{align}
                    \| \psi(t_1,b)-\psi(t_2,b) \|&=\| \int_{\mathopen[ t_1 , t_2 \mathclose]}\frac{ \partial \psi }{ \partial t }(s,b)ds \|\\
                    &\leq\int_{\mathopen[ t_1 , t_2 \mathclose]}\| Df_{(s,y_b(s))}\circ\psi(s,b) \|ds\\
                    &\leq\int_{\mathopen[ t_1 , t_2 \mathclose]}\| Df_{(s,t_b(s))} \|\| \psi(s,b) \|ds\\
                    &\leq | t_1-t_2 |\max_{s\in\mathopen[ t_1 , t_2 \mathclose]}\| Df_{(s,y_b(s))} \|\max_{s\in\mathopen[ t_1 , t_2 \mathclose]}\| \psi(s,b) \|.\label{SUBEQooLYMAooRMaMhn}
                \end{align}
            \end{subequations}

            Nous allons majorer le second maximum. Prenons \( t\in\mathopen[ 0 , \tau \mathclose]\); et posons \( A(u,b)=Df_{(u,y_b(u))}\) pour alléger les notations. Par l'équation de définition de \( \psi\) nous avons
            \begin{equation}
                \psi(t,b)=\psi(0,b)+\int_{\mathopen[ 0 , t \mathclose]}A(u,b)\psi(u,b)du,
            \end{equation}
            et donc
            \begin{equation}
                \| \psi(t,b) \|\leq \| \psi_0 \|+\int_{\mathopen[ 0 , t \mathclose]} \| A(u,b) \|  \| \psi(u,b) \|du.
            \end{equation}
            En y appliquant le lemme de Grönwall dans sa version~\ref{LemuBVozy} nous trouvons
            \begin{subequations}
                \begin{align}
                \| \psi(s,b) \|&\leq \| \psi_0 \|\exp\left( \int_{\mathopen[ 0 , s \mathclose]}\| A(u,b) \|du \right)\\
                &\leq \| \psi_0 \|\exp\left( s\max_{u\in\mathopen[ 0 , s \mathclose]}\| A(u,b) \| \right).
                \end{align}
            \end{subequations}
            En retournant à \eqref{SUBEQooLYMAooRMaMhn} nous avons \( \psi_0=\id\) et donc \( \| \psi_0 \|=1\) et
            \begin{equation}
                \max_{s\in\mathopen[ t_1 , t_2 \mathclose]}\| \psi(s,b) \|\leq \max_{s\in \mathopen[ t_1 , t_2 \mathclose]}\exp\left( s\max_{u\in \mathopen[ 0 , t \mathclose]}\| Df_{(u,y_b(u))} \| \right)
            \end{equation}
            Là dedans nous pouvons remplacer \( t\) par \( \max\{ | t_1 |,| t_2 | \}\). Posons enfin, pour alléger les expressions
            \begin{equation}
                a(t_1,t_2,b)=\max_{s\in\mathopen[ t_1 , t_2 \mathclose]}\| Df_{(s,y_b(s))} \|.
            \end{equation}
            La majoration que nous retenons est :
            \begin{equation}
                \| \psi(t_1,b)-\psi(t_2,b) \|\leq | t_1-t_2 |a(t_1,t_2,b)\exp\big( \max\{ | t_1 |,| t_2 | \}a(0,t,b) \big).
            \end{equation}
            Cela tend vers zéro lorsque \( t_1\to t_2\).

        \item[Deuxième terme]

            En ce qui concerne le second terme,
            \begin{equation}
                \| \psi(t,b_1)-\psi(t,b_2) \|
            \end{equation}
            nous utilisons le lemme~\ref{LEMooOJSNooXTJoEf} qui donne, pour \( t\in\mathopen[ t_0 -\tau, t_0+\tau \mathclose]\),
            \begin{equation}
                \begin{aligned}[]
                    \| \psi(t,b_1)-\psi(t,b_2) \|\leq\tau\max_{s\in \overline{ B(0,\tau) }}&\| Df_{s,y_{b_1}(s)}-Df_{s,y_{b_2}(s)} \|\times\\
                    &\times \exp\left( \tau\max\{ \| Df_{s,y_{b_1}(s)},\| Df_{s,y_{b_2}(s)} \| \| \} \right).
                \end{aligned}
            \end{equation}
            Dans notre cas, \( t_0=0\), donc \( t\in\mathopen[ -\tau , \tau \mathclose]\). Vu la continuité de \( Df\), nous avons
            \begin{equation}
                    \max_{s\in \overline{ B(0,\tau) }}\| Df_{s,y_{b_1}(s)}-Df_{s,y_{b_2}(s)} \|\to 0
            \end{equation}
            lorsque \( b_1\to b_2\).

        \item[\( \psi\) est continue en \( (t,x)\) (fin)]

            Les deux bons calculs faits, nous avons, en repartant de \eqref{EQooVUNUooExeQba},
            \begin{equation}
                \lim_{(t_1,b_1)\to(t_2,b_2)}\| \psi(t_1,b_1)-\psi(t_2,b_2) \|=0,
            \end{equation}
            ce qui signifie que \( \psi\) est une fonction continue de ses deux variables en même temps.
            \end{subproof}

        \item[Différentiabilité de \( \varphi\) (début)]

            Nous montrons maintenant que \( D\varphi(t,x)\) existe. Pour rappel, \( D\) est la différentielle par rapport à la seconde variable. Nous sommes à étudier l'existence de \( D\varphi_{(t,b)}=d(\varphi_t)_b\). Nous posons
            \begin{equation}
                \theta(t,h)=\varphi(t,b+h)-\varphi(t,b)=y_{b+h}(t)-y_b(t)
            \end{equation}
            où \( b\) est le point où nous étudions la différentiabilité. Il est dans un voisinage du point \( a\) fixé depuis le début et autour duquel il existe un voisinage qui donne un sens à tout ce que nous avons fait jusqu'à présent. La dépendance de \( \theta\) en \( b\) est implicite. Vu que \( \varphi\) est Lipschitz en sa seconde variable, nous avons la majoration
            \begin{equation}        \label{EQooKYELooZlfeed}
                \| \theta(t,h) \|\leq C\| h \|
            \end{equation}
            dès que \( t\in V\) et \( b,b+h\in W\).

            De plus, parce que \( t_0\) est le temps de la condition initiale nous avons
            \begin{equation}
                \theta(t_0,h)=y_{b+h}(t_0)-y_{b}(t_0)=a+h-a=h.
            \end{equation}
            Et aussi, par définition de \( \psi\) :
            \begin{equation}
                    \psi(t,b)=\psi_0+\int_{t_0}^t\frac{ \partial \psi }{ \partial t }(s,b)ds =\psi_0+\int_{t_0}^tDf_{(s,y_b(s))}\circ\psi(s,b)
            \end{equation}
            En appliquant à \( h\) et en se souvenant que \( \psi_0=\id\),
            \begin{equation}
                    \psi(t,b)h=h+\int_{t_0}^t\Big( Df_{s,y_b(s)}\circ\psi(s,b)\Big)h\,ds.
            \end{equation}
            Puis on peut faire un calcul assez classique en se souvenant que \( \theta(t_0,h)=h\) :
            \begin{subequations}
                \begin{align}
                    \theta(t,h)&=\theta(t_0,h)+\int_{t_0}^t\big[ \frac{ \partial \varphi }{ \partial t }(s,b+h)-\frac{ \partial \varphi }{ \partial t }(s,b) \big]ds\\
                    &=h+\int_{t_0}^t\big[   f\big( s,y_{b+h}(s) \big)-f\big( s,y_b(s) \big)   \big]ds.
                \end{align}
            \end{subequations}
            On fait la différence entre les deux :
            \begin{equation}
                \theta(t,h)-\psi(t,b)h=-\int_{t_0}^t\big[ Df_{s,y_b(s)}\circ\psi(s,b)h-f\big( s,y_{b+h}(s)\big)+f\big( s,y_b(s) \big) \big]ds.
            \end{equation}
            Nous y ajoutons et soustrayons \( Df_{s,y_{b}(s)}\theta(s,h)\) et nous retenons la majoration suivante :
            \begin{equation}        \label{EQooODHPooDYyBoH}
                \begin{aligned}[]
                    \| \theta(t,h)-\psi(t,b)h \|\leq &\int_{t_0}^t\| Df_{(s,y_b(s))}\psi(s,b)-Df_{(s,y_b(s))} \theta(s,h)\| ds\\
                    &+\int_{t_0}^t\| f(s,y_{b+h}(s))-f(s,y_b(s))+Df_{(s,y_b(s))}\theta(s,h)  \|ds.
                \end{aligned}
            \end{equation}
            Nous allons encore majorer ces deux termes séparément. Soit \( \epsilon>0\).

            \begin{subproof}

        \item[Premier terme]

             Ce qui est dans la norme à majorer est
             \begin{equation}
                 Df_{(s,y_b(s))}\big( \psi(s,b)h-\theta(s,h) \big).
             \end{equation}
             Vu que \( Df\) est continue et que \( y_b\) est continue\footnote{Il faut encore réduire les voisinages \( V\) et \( W\) pour que ceci ait un sens.}, l'application \( s\mapsto Df_{s,y_b(s)}\) est continue et donc de norme majorée sur le compact \( \mathopen[ t_0 , t \mathclose]  \). Nous rapellons la notation
             \begin{equation}
                 a(t_0,t,b)=\max_{s\in\mathopen[ t_0 , t \mathclose]}\| Df_{s,y_b(s)} \|,
             \end{equation}
             et nous majorons encore et toujours. D'abord
             \begin{equation}
                 \int_{t_0}^t\| Df_{(s,y_b(s))}\big( \psi(s,b)h-\theta(s,h) \big) \|ds\leq a(t_0,t,b)\int_{t_0}^t\| \psi(s,b)-\theta(s,h) \|ds.
             \end{equation}

        \item[Deuxième terme]

            Pour traiter le deuxième terme, nous allons provisoirement noter \( x=y_b(s)\) et \( y=y_{b+h}(s)\); entre autres, \( y-x=\theta(s,h)\). Ce qui est écrit dans le second terme de \eqref{EQooODHPooDYyBoH} est
            \begin{equation}
                f(s,y)-f(s,x)+Df_{(s,x)}\theta(s,h)=f(s,y)-f(s,x)+Df_{(s,x)}(y-x)
            \end{equation}
            Comme \( D\) ne s'applique pas à la variable \( s\), nous pouvons alléger la notation et déduire de la différentiabilité de \( f\) qu'il existe un \( \eta>0\) tel que \( x,y\in W\) avec \( \| y-w \|\leq \eta\) implique
            \begin{equation}
                \| f(y)-f(x)-Df_x(y-x) \|\leq \epsilon\| y-x \|.
            \end{equation}
            Prenons \( \| h \|\leq \eta/C\) (le \( C\) de \eqref{EQooKYELooZlfeed}); en déballant les notations,
            \begin{equation}
                \| f\big( s,y_{b+h}(s) \big)-f\big( s,y_b(s) \big) -Df_{(s,y_b(s))}\theta(s,h)\|\leq \epsilon\| \theta(s,h) \|\leq \epsilon C\| h \|.
            \end{equation}


        \item[Les deux termes ensemble]

            En remettant les deux dans \eqref{EQooODHPooDYyBoH} nous trouvons la majoration
            \begin{equation}
                \| \theta(t,h)-\psi(t,b)h \|\leq | t-t_0 |\epsilon C\| h \|+a(t_0,t,v)\int_{t_0}^t\| \psi(s,b)h-\theta(s,h) \|ds
            \end{equation}
            qui est encore de la graine à Grönwall avec
            \begin{subequations}
                \begin{numcases}{}
                    u(t)=\| \theta(t,h)-\psi(t,b) \|\\
                    b(t)=| t-t_0 |\epsilon C\| h \|\\
                    a(s)=a(t_0,t,v),
                \end{numcases}
            \end{subequations}
            la troisième étant une fonction constante. Cela donne, pour \( t\in\mathopen[ t_0-\tau , t_0+\tau \mathclose]\),
            \begin{equation}
                \| \theta(t,h)-\psi(t,b)h \|\leq| t-t_0 |\epsilon C\| h \|+\int_{t_0}^t(s-t_0)\epsilon C\| h \|a(t_0,t,b)\exp\left( \int_{s}^ta(t_0,t,b)du \right)ds.
            \end{equation}
            En valeur absolue, la différence \( s-t_0\) est majorée par \( \tau\), l'intégrale dans l'exponentielle vaut \( (t-s)a(t_0,t,b)\), et restons avec
            \begin{equation}
                \| \theta(t,h)-\psi(t,b)h \|\leq \tau \epsilon C\| h \|+\tau\int_{t_0}^t\epsilon C\| h \|a(t_0,t,b) e^{a(t_0,t,b)(t-s)}ds.
            \end{equation}
            En supposant \( t>t_0\) nous pouvons calculer l'intégrale. Si vous m'avez suivi jusqu'ici, vous devriez avoir de tels maux de tête que je vous donne la réponse :
            \begin{equation}
                \int_{t_0}^ta(t_0,t,b) e^{(t-s)a(t_0,t,b)}ds= e^{(t_0-t)a(t_0,t,b)}-1.
            \end{equation}
            En remettant dans l'expression,
            \begin{equation}
                \| \theta(t,h)-\psi(t,b)h \|\leq \tau\epsilon C\| h \|+\epsilon C\| h \|a(t_0,t,b)\tau\big(  e^{(t-t_0)}-1 \big)=\tau\epsilon C\| h \| e^{(t-t_0)a(t,t_0,b)}.
            \end{equation}
            Nous pouvons majorer \( t-t_0\) par \( \tau\) et \( a(t,t_0,b) \) par \( a(t_0-\tau,t_0+\tau,b)\) pour avoir la majoration
            \begin{equation}
                \| \theta(t,h)-\psi(t,b)h \|\leq \tau\epsilon C\| h \| e^{\tau a(t_0-\tau,t_0+\tau,b)}.
            \end{equation}

        \item[Différentiabilité de \( \varphi(t,b)\) (fin)]

            Nous écrivons la définition~\ref{DefDifferentiellePta} de la différentiabilité : nous voulons vérifier que
            \begin{equation}
                \lim_{h\to 0} \frac{ \varphi(t,b+h)-\varphi(t,b)-\psi(t,b)h }{ \| h \| }=0.
            \end{equation}
            Nous remplaçons \( \varphi(t,b+h)-\varphi(t,b)\) par \( \theta(t,h)\) et prenons la norme avec les majorations données :
            \begin{equation}
                \lim_{h\to 0} \frac{ \|  \varphi(t,b+h)-\varphi(t,b)-\psi(t,b)h  \|   }{ \| h \| }\leq \lim_{h\to 0} \tau\epsilon C e^{\tau e(t_0-\tau,t_0+\tau,b)}.
            \end{equation}
            Cela étant valable pour tout \( \epsilon\), nous en déduisons la nullité de la limite.

            Nous avons démontré que \( \varphi\) était différentiable par rapport à sa deuxième variable et que
            \begin{equation}        \label{EQooPJFOooHuOIuw}
                D\varphi_{(t,b)}=\psi(t,b).
            \end{equation}
            \end{subproof}

        \item[Conclusion : \( \varphi\) est de classe \( C^1\)]

            Nous avons déjà prouvé que \( (t,b)\mapsto \psi(t,b)\) est continue. Donc de \eqref{EQooPJFOooHuOIuw} nous déduisons que les dérivées partielles \(  (t,b)\mapsto\frac{ \partial \varphi }{ \partial x_i } (t,b)\) sont continues. Mais comme \( \varphi\) est Lipschitz en \( t\), la dérivée partielle \( (t,b)\mapsto \frac{ \partial \varphi }{ \partial t }(t,b)\) est également continue.

            La continuité de toutes les dérivées partielles de \( \varphi\) nous donne la classe \( C^1\) pour \( \varphi\) par le théorème \ref{THOooBEAOooBdvOdr}.
    \end{subproof}
\end{proof}

\begin{proposition}[Régularité \( C^p\) du flot\cite{ooEGXQooRwPKcC}]        \label{PROPooINLNooDVWaMn}
    Soit un intervalle ouvert \( I \) de \( \eR\) et un ouvert connexe \( \Omega\) de \( \eR^n\). Soit une fonction \( f\in C^p\big( I\times \Omega,\eR \big)\),  ainsi que \( a\in \Omega\) et \( t_0\in I\).

    Il existe un voisinage \( W\times V = \overline{ B(t_0,\tau) }\times \overline{ B(a,r) }\) de \( (t_0,a)\) dans \( I\times \Omega\) et une unique application \( \varphi\colon W\times V\to \Omega\) telle que
    \begin{subequations}
        \begin{numcases}{}
            \frac{ \partial \varphi }{ \partial t }(t,x)=f\big( t,\varphi(t,x) \big)\\
            \varphi(t_0,x)=x
        \end{numcases}
    \end{subequations}
    pour tout \( x\in V\).

    L'application \( (t,x)\mapsto \varphi(t,x)\) est de classe \( C^p\).
\end{proposition}

\begin{proof}
    Nous savons déjà par le théorème~\ref{THOooSTHXooXqLBoT} que \( (t,x)\mapsto \varphi(t,x)\) est de classe \( C^1\). Nous supposons que \( f\) est de classe \( C^p\) avec \( p\geq 2\).

    Vu que \( \varphi\) et \( f\) sont de classe \( C^1\), nous avons aussi que l'application \( (t,x)\mapsto f\big( t,\varphi(t,x) \big)\) est de classe \( C^1\). L'équation donne alors immédiatement le fait que
    \begin{equation}
        (t,x)\mapsto\frac{ \partial \varphi }{ \partial t }(t,x)
    \end{equation}
    est de classe \( C^1\).

    En ce qui concerne la régularité par rapport aux autres variables, il faudra travailler un peu plus.

    \begin{subproof}
    \item[Une équation différentielle pour le flot]
    Nous allons commencer par un habile jeu d'écriture : la formule
    \begin{equation}
        \varphi(t,x)=x+\int_{t_0}^tf\big( s,\varphi(s,x) \big)ds
    \end{equation}
    devient
    \begin{equation}        \label{EQooQGVOooYMEgcM}
        \varphi_t(x)=x+\int_{t_0}^tf\big( s,\varphi_s(x) \big)ds.
    \end{equation}
    Dans le même ordre d'idée nous notons \( f_s(x)=f(s,x)\), et ce qui se trouve dans l'intégrale \eqref{EQooQGVOooYMEgcM} n'est autre que la fonction
    \begin{equation}
        g_s(x)=(f_s\circ\varphi_s)(x).
    \end{equation}
    Tout cela pour différentier l'égalité \eqref{EQooQGVOooYMEgcM} par la proposition~\ref{PropAOZkDsh} :
    \begin{subequations}
        \begin{align}
            (d\varphi_t)_x&=\id+\int_{t_0}^t(dg_s)_xds\\
            &=\id+\int_{t_0}^t(df_s)_{\varphi_s(x)}\circ(d\varphi_s)_sds.
        \end{align}
    \end{subequations}
    Nous dérivons ensuite cela par rapport à \( t\) :
    \begin{equation}        \label{EQooBETGooXKWRxX}
        \frac{ \partial  }{ \partial t }\Big( (d\varphi_t)_x \Big)=(df_t)_{\varphi_t(x)}\circ(d\varphi_t)_x.
    \end{equation}
    Cela est une égalité dans \( \aL(\eR^n)\).

    Nous introduisons la fonction
    \begin{equation}
        \begin{aligned}
            F\colon I\times \aL(\eR^n)\times \Omega&\to \aL(\eR^n)  \\
            (t,A,x)&\mapsto (df_t)_{\varphi_t(x)}\circ A.
        \end{aligned}
    \end{equation}
    En fait, à la place de \( I\) et \( \Omega\) il faut prendre des petits voisinages dans lesquels les choses ont un sens. Ce que dit l'équation~\ref{EQooBETGooXKWRxX} est que l'application
    \begin{equation}
        \begin{aligned}
            A\colon I \times \Omega&\to \aL(\eR^n) \\
            (t,x)&\mapsto (d\varphi_t)_x
        \end{aligned}
    \end{equation}
    vérifie l'équation différentielle
        \begin{subequations}\label{EQooTOJMooLXLfVv}
            \begin{numcases}{}
                    \frac{ \partial A }{ \partial t }(t,x)=F\big( t,A(t,x),x \big)\\
                    A(t_0,x)=\id.
            \end{numcases}
        \end{subequations}

    \item[Une autre équation différentielle]

        Nous n'oublions pas l'équation différentielle pour la dérivée par rapport à \( t\) :
        \begin{equation}        \label{EQooYOJPooKEgiec}
            \frac{ \partial \varphi }{ \partial t }(t,x)=f\big( t,\varphi(t,x) \big).
        \end{equation}

    \item[Réécriture pour la différentielle]

        Nous allons récrire l'équation \eqref{EQooTOJMooLXLfVv} de façon à ce que le paramètre \( x\) soit inclus dans la condition initiale. De cette manière, la solution pourra profiter de la régularité \( C^1\) du flot déjà prouvée dans le théorème~\ref{THOooSTHXooXqLBoT}.

        Soit
        \begin{equation}
            \begin{aligned}
                g\colon I\times \big( \aL(\eR^n)\times \Omega \big)&\to \aL(\eR^n)\times \Omega \\
                \big( t,(A,x) \big)&\mapsto \Big( F(t,a,x),0 \Big).
            \end{aligned}
        \end{equation}
        Nous posons \( E=\aL(\eR^n)\times \Omega\); c'est cet espace qui va jouer le rôle de \( \Omega\). Nous considérons à présent l'équation différentielle suivante pour \( z_x\colon I\to E\) :
        \begin{subequations}        \label{EQooSMYOooDaxgQx}
            \begin{numcases}{}
                \begin{pmatrix}
                    z_1'(t)    \\
                    z_2'(t)
                \end{pmatrix}=
                z'(t)=g(t,z(t))=
                \begin{pmatrix}
                F\big( t,z_1(t),z_2(t) \big)\\
                    0
                \end{pmatrix}\\
                z(t_0)=(\id,x).
            \end{numcases}
        \end{subequations}
        Il devrait y avoir un indice \( (\id,x)\) à \( z\) parce que c'est sa condition initiale. La fonction \( g\) est de classe \( C^p\), donc cette équation admet une unique solution dont le flot est de classe \( C^1\). Autrement dit, si \( S\) est dans un voisinage de \( \id\), l'application
        \begin{equation}
            (t,x)\mapsto z(t)
        \end{equation}
        est de classe \( C^1\). Nous allons montrer qu'en posant \( A(t,x)=z_1(t)\), nous avons une solution de \eqref{EQooTOJMooLXLfVv} (l'unicité de la solution impose que cette solution est effectivement la différentielle de \( d\varphi_t\)). D'abord, la seconde ligne de l'équation différentielle est \( z'_2(t)=0\), c'est-à-dire \( z_2(t)=x\) pour tout \( t\).

        Sachant cela, la première équation devient
        \begin{subequations}
            \begin{numcases}{}
                z_1'(t)=F\big( t,z_1(t),x \big)\\
                z_1(t_0)=\id,
            \end{numcases}
        \end{subequations}
        qui est l'équation différentielle pour \( A\). Rappel : il y a partout une dépendance de \( z\) en sa condition initiale \( x\) que nous n'avons pas écrite pour des raisons de légèreté notionnelle. Il n'en reste pas moins que le flot de l'équation différentielle pour \( z\) est \( C^1\), c'est-à-dire que \( (t,x)\mapsto z_1(t)\) est de classe \( C^1\).

        Par conséquent, \( (t,x)\mapsto A(t,x)\) est également \( C^1\).


    \item[Régularité \( C^2\) du flot]

        Le fait que \( A\) soit \( C^1\) n'implique pas que le flot le soit parce que le flot suit la même équation différentielle que \( A\) ne signifie pas que il soit égal. Il y a un raisonnement à faire.

        Le fait est que si \( A\) est une solution de \eqref{EQooTOJMooLXLfVv}, alors \( z(t)=\big( A(t,x),x \big)\) est solution de \eqref{EQooSMYOooDaxgQx}. C'est l'unicité de cette dernière qui permet de déduire l'unicité de la solution pour \( A\).

        Nous avons donc que l'unique solution \( A\) du système \eqref{EQooTOJMooLXLfVv} est égale à \( A(t,x)=(d\varphi_t)_x\) et est de classe \( C^1\) par rapport à \( (t,x)\).

        Donc \( (t,x)\mapsto  \varphi(t,x)\) est de classe \( C^2\).

    \item[Régularité \( C^p\)]

        Nous avons vu que le flot de \( y'=f(t,y)\) est de classe \( C^2\) dès que \( f\) est de classe \( C^2\). Supposons que \( f\) soit de classe \( C^p\) et montrons que si le flot est de classe \( C^k\) (\( k<p\)) alors il est de classe \( C^{k+1}\).

        Vu que le flot d'une équation différentielle de classe \( C^p\) est de classe \( C^k\), en particulier celui de \eqref{EQooSMYOooDaxgQx} est de classe \( C^k\). Donc aussi la solution pour \( A(t,x)=(d\varphi_t)_x\) est de classe \( C^k\). Et vu que \(  (t,x)\mapsto (d\varphi_t)_x   \) est de classe \( C^k\), l'application \( \varphi\) est de classe \( C^{k+1}\).

    \end{subproof}
\end{proof}

\begin{normaltext}      \label{NORMooWEWVooXbGmfE}
    % Attention : ce 'normaltext' est référentié dans l'index thématique sur l'inversion locale. Si on développe ici, il faudra modifier là-bas.
    % position 1051229132
    Le théorème d'inversion locale~\ref{ThoXWpzqCn} nous permet de dire que, pour \( t\) fixé, le flot \( x\mapsto \varphi_t(x)\) est un \( C^p\)-difféomorphisme local.
\end{normaltext}

\begin{proposition}[Cauchy-Lipschitz avec paramètre, régularité \( C^p\)\cite{ooCMJNooHgCXBS,ooSDCGooACTQQH,ooZWJZooBocVPb}]       \label{PROPooPYHWooIZhQST}
    Soit un intervalle ouvert \( I\) de \( \eR\), un connexe ouvert \( \Omega\) de \( \eR^n\) et un intervalle ouvert \( \Lambda\) de \( \eR^d\). Soit une fonction \( f\in C^p( I\times \Omega\times \Lambda, \eR^n)\) localement Lipschitz en \( \Omega\). Soient \( t_0\in I\), \( y_0\in \Omega\) et \( \lambda_0\in \Lambda\). Il existe un voisinage compact de \( (t_0,y_0,\lambda_0)\) sur lequel le problème
    \begin{subequations}
        \begin{numcases}{}
            y'_{\lambda}(t)=f\big( t,y_{\lambda}(t),\lambda \big)\\
            y_{\lambda}(t_0)=y_0
        \end{numcases}
    \end{subequations}
    possède une unique solution. De plus \( (t,\lambda)\mapsto y_{\lambda}(t)\) est de classe \( C^p\) par rapport à ses deux variables.
\end{proposition}

\begin{proof}
    Nous récrivons immédiatement le problème pour la fonction \( y\colon I\times \Lambda\to \eR^n\) donné par \( y(t,\lambda)=y_{\lambda}(t)\) :
    \begin{subequations}        \label{SUBEQooXMYMooKfpqQW}
        \begin{numcases}{}
            \frac{ \partial y }{ \partial t }(t,\lambda)=f\big( t,y(t,\lambda),\lambda \big)\\
            y(t_0)=y_0.
        \end{numcases}
    \end{subequations}
    Nous allons montrer que ce problème est en réalité équivalent à un problème sans paramètre. Nous posons \( E=\Omega\times \Lambda\) et
    \begin{equation}
        \begin{aligned}
            g\colon I\times E&\to E \\
            (t,x)&\mapsto \big(f(t,x_1,x_2) ,0\big)
        \end{aligned}
    \end{equation}
    où \( x_1\) est la composante \( \Omega\) de \( x\) et \( x_2\) est la composante \( \Lambda\) de \( x\). Pour une valeur \( \mu\in \Lambda\) donnée nous considérons le problème au condition initiales
    \begin{subequations}        \label{SUBEQSooIBTNooHzYImh}
        \begin{numcases}{}
            x'(t)=g\big( t,x(t) \big)\\
            x(t_0)=(y_0,\mu).
        \end{numcases}
    \end{subequations}
    Le théorème de Cauchy-Lipschitz que nous prenons sous la forme~\ref{PROPooINLNooDVWaMn} nous indique que ce problème admet une unique solution maximale et que le flot \(   \big( t,(y_0,\mu) \big)     \mapsto  x_{(y_0,\mu)}(t)   \) est de classe \( C^p\).

    Nous passons maintenant à la résolution du problème \eqref{SUBEQooXMYMooKfpqQW}

    \begin{subproof}
    \item[Existence d'une solution \( C^1\)]

    Nous montrons à présent que la fonction \( y\) donnée par
    \begin{equation}
        y(t,\mu)=x_{(t_0,\mu)}(t)_1
    \end{equation}
    est solution de \eqref{SUBEQooXMYMooKfpqQW}. Vu que \( x\) a deux composantes, nous pouvons un peu déballer l'équation. Afin d'éviter les notations laborieuses nous allons noter \( x\) pour \( x_{(t_0,\mu)}\) et donc \( x_1(t)\) pour \( x_{(t_0,\mu)}(t)\). Nous avons l'équation différentielle
    \begin{equation}
        \begin{pmatrix}
            x_1'(t)    \\
            x_2'(t)
        \end{pmatrix}=\begin{pmatrix}
            f\big( t,x_1(t),x_2(t) \big)    \\
            0
        \end{pmatrix}
    \end{equation}
    avec la condition initiale
    \begin{equation}
        \begin{pmatrix}
            x_1(t_0)    \\
            x_2(t_0)
        \end{pmatrix}=\begin{pmatrix}
            y_0    \\
            \mu
        \end{pmatrix}.
    \end{equation}
    La seconde ligne de l'équation donne immédiatement \( x_2(t)=\mu\) pour tout \( t\). En injectant dans la première ligne :
    \begin{equation}
        x_1'(t)=f\big( t,x_1(t),\mu \big).
    \end{equation}
    Or vue la définition de \( y\), le nombre \( x_1'(t)\) n'est autre que \( \frac{ \partial y }{ \partial t }(t,\mu)\). La fonction \( y\) que nous avons définie vérifie donc
    \begin{equation}
        \frac{ \partial y }{ \partial t }(t,\mu)=f\big( t,y(t,\mu),\mu \big)
    \end{equation}
    et la condition initiale \( y(t_0)=x_1(t_0)=y_0\). Elle est donc bien solution du problème initial.

    De plus l'application \( (t,\mu)\mapsto y(t,\mu)=x_{(t_0,\mu)}(t)_1\) est de classe \( C^p\).

    \item[Unicité]

        Pour l'unicité, soit on invoque la proposition~\ref{THOooDTCWooSPKeYu} qui donne l'unicité dans les fonctions continues et a fortiori dans les fonctions \( C^1\). Soit on fait le jeu inverse : on prouve qu'à chaque solution de \eqref{SUBEQooXMYMooKfpqQW} correspond une solution de \eqref{SUBEQSooIBTNooHzYImh}, et l'unicité de la solution \( x\) donne l'unicité du côté de \( y\).
    \end{subproof}
\end{proof}

\begin{lemma}           \label{LEMooQWDNooOjNXhl}
    Soit le problème
    \begin{subequations}        \label{EQooKHSKooEFCsMQ}
        \begin{numcases}{}
            \frac{ \partial y }{ \partial s }(s)=f\big( y(s),s \big)\\
            y(t)=x
        \end{numcases}
    \end{subequations}
    avec \( t\) et \( x\) fixés. Nous supposons que \( f\) est de classe \( C^p\).

    Alors l'application \( t\mapsto  y_x(s)   \) est de classe \( C^p\).
\end{lemma}

\begin{proof}
    Soit \( t\) fixé, et l'équation différentielle
    \begin{subequations}
        \begin{numcases}{}
            \frac{ \partial z }{ \partial s }(s)a-=f\big( z(s),t-s \big)\\
            z(0)=x.
        \end{numcases}
    \end{subequations}
    Par le théorème~\ref{PROPooINLNooDVWaMn}, La solution \( z\) est de classe \( C^p\) en \( (s,x)\). En posant \( y(s)=z(t-s)\) il est vite vérifié que \( y\) est solution de \eqref{EQooKHSKooEFCsMQ}. C'est alors bien de classe \( C^p\) en \( t\).
\end{proof}
