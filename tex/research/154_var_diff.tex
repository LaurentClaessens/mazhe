% This is part of (almost) Everything I know in mathematics
% Copyright (c) 2010-2017, 2019, 2021
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.

\section{Differentiable manifolds}
%+++++++++++++++++++++++++++++++++

Most of the results about differential geometry come from \cite{kobayashi, madore, Helgason, ms_book, dgbook}.

\subsection{Definition, charts}
%------------------------------

\begin{definition}
    Let \( \mA\) be a class of functions as \(  C^{\infty}\), \( C^k\), or analytic. A $n$-dimensional \( \mA\)-\defe{manifold}{differentiable!manifold}\index{manifold} is a set $M$ and a set of maps $\{(\mU_{\alpha},\varphi_{\alpha})\}_{\alpha\in I}$ where each set $\mU_{\alpha}$ is open in $\eR^n$ and the maps $\dpt{\varphi_{\alpha}}{\mU_{\alpha}}{M}$ are injective and satisfy the three following conditions:

    \begin{itemize}
    \item every $x\in M$ is contained in at least one set $\varphi_{\alpha}(\mU_{\alpha})$,
    \item for any two maps $\dpt{\varphi_{\alpha}}{\mU_{\alpha}}{M}$ and $\dpt{\varphi_{\beta}}{\mU_{\beta}}{M}$, the set
    \[
       \varphi_{\alpha}^{-1}( \varphi_{\alpha}(\mU_{\alpha})\cap\varphi_{\beta}(\mU_{\beta}) )
    \]
    is an open subset of $\mU_{\alpha}$,
    \item the map
    \[
      \dpt{  (\varphi_{\beta}^{-1}\circ\varphi_{\alpha})  }{   \varphi_{\alpha}^{-1}( \varphi_{\alpha}(\mU_{\alpha})\cap\varphi_{\beta}(\mU_{\beta})  )   }{\mU_{\beta}}
    \]
    is in the class \( \mA\) as map from $\eR^n$ to $\eR^n$.
    \end{itemize}
    In most of the cases, we will use \(  C^{\infty}\) or analytic manifolds. The expression ``smooth manifold'' means \(  C^{\infty}\) manifold.

    The maps \( (U_{\alpha}, \varphi_{\alpha})\) are said ``definition charts'', but the definition \ref{DEFooQLPIooPGagtz} and the proposition \ref{PROPooUDVFooEJeluM} will show that they are not really special.
\end{definition}

\begin{example}
    Any open set of $\eR^n$ is a smooth manifold if we choose the identity map as maps.
\end{example} 

Most of surfaces $z=f(x,y)$ in $\eR^3$ are manifolds, depending on certain regularity conditions on~$f$.

\begin{definition}[\cite{MonCerveau}]       \label{DEFooQLPIooPGagtz}
    Let \( M\) be a manifold with its maps \(  \{ (U_{\alpha}, \varphi_{\alpha}) \}_{\alpha\in I}   \). A \( C^k\)-\defe{chart}{chart} of \( M\) is a couple \( (V,\psi)\) where \( V\) is open in \( \eR^n\) and \( \psi\colon V\to M\) is such that for every \( \alpha\in I\), the maps
    \begin{equation}
        \psi^{-1}\circ \varphi_{\alpha}\colon \varphi_{\alpha}^{-1}\big( \psi(V) \big)\to V
    \end{equation}
    and
    \begin{equation}
        \varphi_{\alpha}^{-1}\circ \psi\colon \psi^{-1}\big( \varphi_{\alpha}(U_{\alpha}) \big)\to U_{\alpha}
    \end{equation}
    are of class \( C^k\).
\end{definition}

\begin{definition}[\cite{MonCerveau}]       \label{DEFooUFHTooTXUVpN}
    Let \( \mA\) be a class of functions (\( C^k\), smooth, analytic). Let \( M,N\) be two manifolds. We consider the charts \( (U,\varphi)\) and \( (V,\phi)\) of \( M\) and \( N\). We say that a map \(f\colon M\to N \) is in the class \( \mA\) with respect to these charts if the map
    \begin{equation}
        \phi^{-1}\circ f\circ\varphi\colon \varphi^{-1}\big( \phi(V) \big)\to V
    \end{equation}
    is in the class \( \mA\).

    If \( A\) is a set of charts of \( M\) and \( B\) is a set of charts of \( N\), we say that \( f\) is in the class \( \mA\) if it is in the class \( \mA\) for every choice of charts in \( A\) and \( B\).
\end{definition}

\begin{definition}[\cite{MonCerveau}]       \label{DEFooMLNQooEgEfdq}
    Let \( M\) be a manifold. An \defe{atlas}{atlas} for \( M\) is a set of charts\footnote{Definition \ref{DEFooQLPIooPGagtz}.} \( \{  (U_j,\phi_j)  \}_{j\in J}\) such that \( \bigcup_{j\in J}\phi_j(U_j)=M\).
\end{definition}

\begin{propositionDef}          \label{PROPooUFGQooACIjVL}
    Let \( A\) be an atlas\footnote{Definition \ref{DEFooMLNQooEgEfdq}.} of \( M\) and \( B\) an atlas of \( N\). If a map \( f\colon M\to N\) is in the class\footnote{Being in a class, definition \ref{DEFooUFHTooTXUVpN}.} \( \mA\) for these atlas, it is in the same class \( \mA\) for every charts of \( M\) and \( N\).

    In this case, one say that the map \( f\) is in the class \( \mA\).
\end{propositionDef}

\begin{lemma}       \label{LEMooGAMVooIWUzmy}
    Let \( (M,\{ (U_{\alpha}, \varphi_{\alpha}) \}_{\alpha\in I}) \) be a manifold. If \( (V,\psi)\) is a chart, the set
    \begin{equation}
        \psi^{-1}\big(\varphi_{\alpha}(U_{\alpha})\big)
    \end{equation}
    is open in \(\eR^n\).
\end{lemma}

\begin{proof}
    By definition \ref{DEFooQLPIooPGagtz}, the map \( \varphi_{\alpha}\circ \psi \colon V\to U_{\alpha}\) is \( C^k\) and, in particular, continuous\footnote{Definition \ref{DefOLNtrxB}\ref{ITEMooEHGWooDdITRV}.}. Thus if \( \mO\) is open in \( U_{\alpha}\), then \( (\varphi_{\alpha}^{-1}\circ\psi)^{-1}(\mO)\) is open in \( V\). Since \( V\) is open in \( \eR^n\), an open set in \( V\) is open in \( \eR^n\). The set \( U_{\alpha}\) is in particular open in \( U_{\alpha}\), thus the part
    \begin{equation}
        (\varphi_{\alpha}^{-1}\circ \psi)^{-1}(U_{\alpha})=(\psi^{-1}\circ\varphi_{\alpha})(U_{\alpha})
    \end{equation}
    is open in \( \eR^n\).
\end{proof}

\begin{proposition}[\cite{MonCerveau}]      \label{PROPooUDVFooEJeluM}
    If \( (V_1,\psi_1)\) and \( (V_2,\psi_2)\) are \( C^k\)-charts, then the map
    \begin{equation}
        \psi_2^{-1}\circ \psi_1\colon \psi_1^{-1}\big( \psi_2(V_2) \big)\to V_2
    \end{equation}
    is of class \( C^k\).
\end{proposition}

\begin{proof}
    Let \( q\in \psi_1^{-1}\big( \psi_2(V_2) \big)\). We will prove that \( \psi_2^{-1}\circ\psi_1\) is \( C^k\) on a neighbourhood of \( q\).  Let \( p=\psi_1(q)\) and \( (U_{\alpha},\varphi_{\alpha})\) be a definition chart around \( p\). We consider
    \begin{equation}
        A=\varphi_{\alpha}(U_{\alpha})\cap\psi_1(V_1)\cap\psi_2(V_2).
    \end{equation}
    The point \( p\) belongs to \( A\). We set \( U'=\varphi_{\alpha}^{-1}(A)\), \( V_1'=\psi_1^{-1}(A)\) and \( V_2'=\psi_2^{-1}(A)\). We show that
    \begin{equation}
        \psi_2^{-1}\circ\psi_1\colon V_1'\to V_2'
    \end{equation}
    is \( C^k\).

    We have
    \begin{equation}
        \psi_2^{-1}\circ\psi_1=\psi_2^{-1}\circ\varphi\circ\varphi^{-1}\circ\psi_1.
    \end{equation}
    Since \( \psi_1\) and \( \psi_2\) are charts, the maps \( \psi_2^{-1}\circ \varphi\) and \( \varphi^{-1}\circ\psi_1\) are \( C^k\), so that the compound function is \( C^k\) by theorem \ref{ThoAGXGuEt}.
\end{proof}

\begin{lemma}       \label{LEMooOPPJooXezOHS}
    Let \( M\) be a \( C^k\) manifold and \( p\in M\). There exists a chart \( (V,\psi)\) of \( M\) around \( p\) such that \( 0\in V\) and \( p=\psi(0)\).
\end{lemma}

\begin{proof}
    By definition there exists a chart \( (U_{\alpha},\varphi_{\alpha})\) around \( p\) and \( u\in U_{\alpha}\) such that \( p=\varphi_{\alpha}(u)\). Let \( V=U-u\) and \( \psi(x)=\varphi_{\alpha}(x+u)\).

    Then \( V\) is an open set and \( \psi(0)=\varphi_{\alpha}(u)=p\).
\end{proof}

\subsection{Topology}
%--------------------

\begin{propositionDef}      \label{DEFooHGNOooNqGmxE}
    Let \( M\) be a manifold. A subset $V\subset M$ is \defe{open}{topology!on manifold} if for every chart $\dpt{\varphi}{\mU}{M}$, the set $\varphi^{-1}(V\cap\varphi(\mU))$ is open in $\mU$. 

    The set of open sets in \( M\) is a topology.
\end{propositionDef}

\begin{proof}
    First we prove that the open system defines a topology. For this, remark that $\varphi_{\alpha}^{-1}$ is injective (if not, there should be some multivalued points). Then $\varphi^{-1}(A\cap B)=\varphi^{-1}(A)\cap\varphi^{-1}(B)$. If $V_1$ and $V_2$ are open in $M$, then
    \begin{equation}
        \varphi^{-1}(V_1\cap V_2\cap\varphi(\mU))=\varphi^{-1}(V_1\cap\varphi(\mU))\cap\varphi^{-1}(V_2\cap\varphi(\mU))
    \end{equation}
    which is open in $\eR^n$. The same property works for the unions.
\end{proof}

\begin{theorem}     \label{THOooIAXUooDqMrav}
    Let \( M\) be a manifold. Its topology has the following properties.
    \begin{enumerate}
        \item the charts maps are continuous,
        \item the sets $\varphi_{\alpha}(\mU_{\alpha})$ are open.
    \end{enumerate}
\end{theorem}

\begin{proof}
    We proof the continuity of $\dpt{\varphi}{\mU}{M}$; for an open set $V$ in $M$, we have to show that $\varphi^{-1}(V)$ is open in $\mU\subset\eR^n$. But the definition of the topology on $M$, is precisely the fact that $\varphi^{-1}(V\cap\varphi(\mU))$ is open.
\end{proof}

\begin{lemma}       \label{LEMooGDMZooLCtnuA}
    The topology of \( \eR^n\) as manifold is the same as the usual one.
\end{lemma}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Regularity}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}      \label{DEFooMELXooEkEnwz}
    If $M$ and $M$ are two analytic manifolds, a map $\dpt{\phi}{M}{N}$ is \defe{regular}{regular}\label{PgDefRegular} at $p\in M$ if it is analytic at $p$ and $\dpt{d\phi_p}{T_pM}{T_{\phi(p)}N}$ is injective.
\end{definition}

\begin{definition}[\cite{BIBooXDPUooVeTGwz}]        \label{DEFooFNTHooEwsqXB}
    Let \( M\) and \( N\) be \( C^k\)-manifolds. We say that a map \( h\colon M\to N\) is \( C^k\) if the two following conditions hold:
    \begin{enumerate}
        \item
            The map \( h\) is continuous\footnote{With respect to the topology of the definition \ref{DEFooHGNOooNqGmxE}.}.
        \item
            for every \( p\in M\), there exists charts \( (U,\varphi)\) around \( p\) and \( (V,\psi)\) around \( h(p)\) such that
            \begin{enumerate}
                \item
                    \( h\big( \varphi(U) \big)\subset\psi(V)\)
                \item       \label{SUBITEMooXQFUooRxMVnw}
                    the map \( \psi^{-1}\circ h\circ\varphi\colon U \to V \) is \( C^k\) (definition \ref{DefPNjMGqy}).
            \end{enumerate}
    \end{enumerate}
\end{definition}

For the sake of the following lemma, we say «\( mC^k\)» for «manifold»-\( C^k\) (definition \ref{DEFooFNTHooEwsqXB}) and «\( uC^k\)» for «usual» \( C^k\) (definition \ref{DefPNjMGqy} for normed vector spaces). The lemma will say that the two notions are the same, so that we can only say «\( C^k\)».
\begin{lemma}[\cite{MonCerveau}]
    We consider the manifolds \( M=\eR^m\) and \( N=\eR^n\) with the identify as charts. A map \( f\colon M\to N\) is \( mC^k\) if and only if it is \( uC^k\).
\end{lemma}

\begin{proof}
    For the sake of notations, we set the charts \( U=\eR^m\), \( V=\eR^n\) and \( \psi_m\colon U\to M\), \( \psi_n\colon V\to N\). The maps \( \psi_n\) and \( \psi_m\) are the identity.
    \begin{subproof}
    \item[\( \Rightarrow\)]
        The hypothesis that \( f\colon M\to N\) is \( mC^k\) says that the map \( \psi_n^{-1}\circ f\circ\psi_m\) is \( uC^k\). Thus the map
        \begin{equation}
            f=\psi_n\circ\psi_n^{-1}\circ f\circ\psi_m\circ\psi_m^{-1}
        \end{equation}
        is \( uC^k\) too.
    \item[\( \Leftarrow\)]
        Since \( f\) is \( uC^k\) and since \( \psi_n\) and \( \psi_m\) are the identity, the map \( \psi_n^{-1}\circ f\circ\psi_m\) is \( uC^k\), which means that \( f\) is \( mC^k\).
    \end{subproof}
\end{proof}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Product of manifolds}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}      \label{DEFooYOLXooDPrnHa}
    TODO: Definition of \( M\times N\) if \( M\) and \( N\) are manifolds.
    %TODOooQYWUooJWOFaM
\end{definition}

\begin{proposition}[\cite{MonCerveau}]      \label{PROPooCHVLooVFScOl}
    Let \( \mA\) be a class of functions: \( C^k\), smooth or analytic.  Let \( M\) and \( N\) be \( \mA\)-Lie groups.
    \begin{enumerate}
        \item
            The permutation
            \begin{equation}
                \begin{aligned}
                    \sigma\colon G\times H&\to H\times G \\
                    (g,h)&\mapsto (h,g) 
                \end{aligned}
            \end{equation}
            is in the class \( \mA\).
        \item
            The projection
            \begin{equation}
                \begin{aligned}
                    p\colon G\times H&\to G \\
                    (g,h)&\mapsto g 
                \end{aligned}
            \end{equation}
            is in the class \( \mA\).
        \item
            Let \( g_0\in G\). The inclusion map
            \begin{equation}
                \begin{aligned}
                    \iota\colon H&\to G\times H \\
                    h&\mapsto (g_0,h) 
                \end{aligned}
            \end{equation}
            is in the class \( \mA\).
    \end{enumerate}
\end{proposition}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Tangent vector}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


\begin{definition}
    An open set \( \Omega\subset \eR^n\) is a manifold with the identify chart \( (\Omega, \varphi)\) where \( \phi\colon \Omega\to \Omega\) is the identity.
\end{definition}

\begin{lemma}
    Let \( \gamma\colon \eR\to M\) be a \( C^1\) path. Let \( f\colon M\to \eR\) be a \( C^1\)-function. Then the map \( f\circ \gamma\colon \eR\to \eR\) is \( C^1\).   
\end{lemma}

\begin{proof}
    Let \( a\in \eR\) and \( p=\gamma(a)\). We consider a chart \( (U,\varphi)\) of \( M\) around \( p\). We decompose
    \begin{equation}
        f\circ \gamma= f\circ \varphi\circ \varphi^{-1}\circ\gamma.
    \end{equation}
    Since \( \varphi\) is a chart, the maps \( f\circ\varphi\) and \( \varphi^{-1}\circ\gamma\) are \( C^1\).
\end{proof}


\subsection{Tangent vector}
%--------------------------

\begin{definition}      \label{DEFooJJVIooDUBwDJ}
    Let \( \gamma\colon \eR\to M\) be a \( C^1\) path\footnote{The concept of map of class \( C^k\) between two manifolds is the definition \ref{DEFooFNTHooEwsqXB}.}. We consider the operator
    \begin{equation}
        \begin{aligned}
            \nabla_{\gamma}\colon C^k(M,\eR)&\to \eR \\
            f&\mapsto \Dsdd{ (f\circ\gamma)(t) }{t}{0}. 
        \end{aligned}
    \end{equation}
    We define
    \begin{equation}
        T_aM=\{ \nabla_{\gamma}\tq \gamma\in C^k(\eR,M),\gamma(0)=a \}.
    \end{equation}
    This is the \defe{tangent space}{tangent space} at \( a\).
\end{definition}

If \( \gamma\colon \eR\to M\) is a path, we also use the notation
\begin{equation}        \label{EQooJQVRooLziKoH}
    \nabla_{\gamma}=\Dsdd{ \gamma(t) }{t}{0}.
\end{equation}
If one sees \( \eR\) as a manifold, then the expression \( \Dsdd{ 2t+1 }{t}{0}\) can stand for the number \( 1\) (usual derivative of \( t\mapsto 2t+1\) at \( t=0\)) or for the operator
\begin{equation}
    \Dsdd{ 2t+1 }{t}{0}\phi=2\phi'(1).
\end{equation}

\begin{remark}      \label{REMooJQFHooQuoZxt}
    The notation \( \gamma'(0)\) for the tangent vector to the curve \( \gamma\) has to be taken with caution. In particular, \( \gamma'(0)\) is not defined by the limit
    \begin{equation}        \label{EQooVMGFooFUCNEY}
        \lim_{\epsilon\to 0} \frac{ \gamma(\epsilon)-\gamma(0) }{ \epsilon }
    \end{equation}
    because when \( M\) is a manifold, there is in general no notion of difference between the points of \( M\), so that the difference \( \gamma(\epsilon)-\gamma(0)\) has no meaning.

    The only definition of \( \gamma'(0)\) is as differential operator.
\end{remark}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Vector space structure on the tangent space}
%---------------------------------------------------------------------------------------------------------------------------

If \( X\) and \( Y \) are elements of \( T_pM\), and if \( \lambda\in \eR\) the definitions of \( \lambda X\) and \( X+Y\) are just the usual definitions: 
\begin{equation}
    \begin{aligned}
        \lambda X\colon  C^{\infty}(M)&\to \eR \\
        f&\mapsto \lambda X(f) 
    \end{aligned}
\end{equation}
and
\begin{equation}
    \begin{aligned}
        X+Y\colon  C^{\infty}(M)&\to \eR \\
        f&\mapsto X(f)+Y(f). 
    \end{aligned}
\end{equation}
The real questions is: are \( \lambda X\) and \( X+Y\) elements of \( T_pM\) ?

\begin{proposition}[\( T_pM\) is  a vector space\cite{MonCerveau}]  \label{PROPooEJBWooSbvypo}
    Let \( M\) be a \( C^k\) manifold.
    \begin{enumerate}
        \item
            The set \( T_pM\) is  a vector space
        \item
            The dimension of \( T_pM\) is the same as the dimension of \( M\).
    \end{enumerate}
\end{proposition}

\begin{proof}
    Let \( p\in M\) and a chart \( (U,\varphi)\) of \( M\) around \( p\) such that \( p=\varphi(0)\) (lemma \ref{LEMooOPPJooXezOHS}). We consider \( X,Y\in T_pM\) and paths \( \gamma\colon \eR\to M\), \( \sigma\colon \eR\to M\) such that \( X=\nabla_{\gamma}\) and \( Y=\nabla_{\sigma}\).

    \begin{subproof}
    \item[Sum]
        

    We aim to find a path \( s\colon \eR\to M\) such that \( \nabla_s=X+Y\). We set
    \begin{equation}        \label{EQooYNAOooKkKmxo}
        \begin{aligned}
            s\colon \eR&\to M \\
            t&\mapsto \varphi\Big( \varphi^{-1}\big( \gamma(t) \big)+\varphi^{-1}\big( \sigma(t) \big) \Big). 
        \end{aligned}
    \end{equation}
    This path satisfy \( s(0)=\varphi\Big( \varphi^{-1}(p)+\varphi^{-1}(p) \Big)=\varphi(0)=p\). In order to prove that \( \nabla_s=X+Y\) we consider \( f\in C^k(M,\eR)\) and we compute \( \nabla_s(f)\) :
    \begin{subequations}        \label{SUBEQSooKOGNooGISCax}
        \begin{align}
            \Dsdd{ (f\circ s)(t) }{t}{0}&=\Dsdd{ (f\circ\varphi)\Big( \varphi^{-1}\big( \gamma(t) \big)+\varphi^{-1}\big( \sigma(t) \big) \Big) }{t}{0}\\
            &=\sum_k\partial_k(f\circ \varphi)(0)\Dsdd{ \varphi^{-1}\big( \gamma(t) \big)_k+\varphi^{-1}\big( \sigma(t) \big)_k }{t}{0}.
        \end{align}
    \end{subequations}
    We used the theorem \ref{THOooKBTYooWFtoSF} with the maps \( f\circ \varphi\colon \eR^n\to \eR\) and
    \begin{equation}
        \begin{aligned}
            g\colon \eR&\to \eR^n \\
            t&\mapsto \varphi^{-1}\big( \gamma(t) \big)+\varphi^{-1}\big( \sigma(t) \big). 
        \end{aligned}
    \end{equation}
    We focus on one term:
    \begin{subequations}
        \begin{align}
            \sum_k\partial_k(f\circ \varphi)(0)\Dsdd{ \varphi^{-1}\big( \gamma(t) \big)_k }{t}{0} &=\Dsdd{ (f\circ\varphi)\big( \varphi^{-1}(\gamma(t)) \big) }{t}{0}\\
            &=\Dsdd{ f\big( \gamma(t) \big) }{t}{0}\\
            &=\nabla_{\gamma}(f).
        \end{align}
    \end{subequations}
    The two terms of \eqref{SUBEQSooKOGNooGISCax} sum to \( \nabla_{\gamma}(f)+\nabla_{\sigma}(f)\), so that \( \nabla_s=\nabla_{\gamma}+\nabla_{\sigma}=X+Y\).

\item[Product]

        We ail to find a path \( s\colon \eR\to M\) such that \( \nabla_s=\lambda X\). The answer is easy: \( s(t)=\gamma(\lambda t)\). Indeed:
        \begin{equation}
            \Dsdd{ (f\circ s)(t) }{t}{0}=\Dsdd{ (f\circ \gamma)(\lambda t) }{t}{0}=\lambda \Dsdd{ (f\circ \gamma)(t) }{t}{0}=\lambda X(f).
        \end{equation}
        We used the lemma \ref{LEMooXHVBooHYjXdq}.
    \end{subproof}
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Differential of a map}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{propositionDef}[Differential of a map\cite{MonCerveau}]      \label{DEFooDRGUooDPFIJa}
    Let \( M\), \( N\) be \( C^1\)-manifolds. Let \( a\in M\). Let \( \phi\in C^1(M,N)\). We consider two paths \( \gamma\) and \( \sigma\) such that \( \gamma(0)=\sigma(0)=a\) and
    \begin{equation}
        \nabla_{\gamma}=\nabla_{\sigma}.
    \end{equation}
    Then
    \begin{equation}
        \nabla_{\phi\circ \gamma}=\nabla_{\phi\circ \sigma}.
    \end{equation}
    We define
    \begin{equation}        \label{EQooQNZPooMVaSQC}
        \begin{aligned}
            d\phi_a\colon T_aM&\to T_{\phi(a)}N \\
            \nabla_{\gamma}&\mapsto \nabla_{\phi\circ \gamma}. 
        \end{aligned}
    \end{equation}
    We have the formula
    \begin{equation}
        d\phi_a(\nabla_{\gamma})f=\nabla_{\phi\circ \gamma}(f)=\Dsdd{ (f\circ\phi\circ\gamma)(t) }{t}{0}
    \end{equation}
    where \( a=\gamma(0)\).
\end{propositionDef}

\begin{proof}
    Let \( f\in C^1(N,\eR)\). The map \( f\circ\phi\colon M\to \eR\) belongs to \( C^1(M,\eR)\) so that we can apply \( \nabla_{\gamma}\) and \( \nabla_{\sigma}\) on it. By hypothesis,
    \begin{equation}
        \nabla_{\gamma}(f\circ \phi)=\nabla_{\sigma}(f\circ \phi).
    \end{equation}
    Using the definition of \( \nabla\),
    \begin{equation}
        \nabla_{\gamma}(f\circ\phi)=\Dsdd{ (f\circ \phi\circ \gamma)(t) }{t}{0}=\nabla_{\phi\circ\gamma}(f).
    \end{equation}
    and
    \begin{equation}
        \nabla_{\sigma}(f\circ\phi)=\Dsdd{ (f\circ \phi\circ \sigma)(t) }{t}{0}=\nabla_{\phi\circ\sigma}(f).
    \end{equation}
\end{proof}

\begin{lemma}[\cite{MonCerveau}]        \label{LEMooBOZBooNJMccB}
    Let \( M,N\) be \( C^1\)-manifolds. We consider \( C^1\)-maps \( f\colon M\to N\) and \( \phi\colon N\to \eR\). Let \( \gamma\colon \eR\to M\) be a \( C^1\)-path. We have
    \begin{equation}
        \nabla_{\gamma}(\phi\circ f)=\nabla_{f\circ \gamma}(\phi).
    \end{equation}
\end{lemma}

\begin{proof}
    By definition,
    \begin{equation}
        \nabla_{\gamma}(\phi\circ f)=\Dsdd{ (\phi\circ f\circ \gamma)(t) }{t}{0}=\Dsdd{ \phi\big( (f\circ \gamma)(t) \big) }{t}{0}=\nabla_{f\circ\gamma}(\phi).
    \end{equation}
\end{proof}

Here we prove that \( df_a\) is linear. The proposition \ref{PROPooPEMLooPQcywG} will provide the reciprocal map : \( (df_a)^{-1}=(df^{-1})_{f(a)}\).
\begin{proposition}     \label{PROPooNRLVooChhiIS}
    Let \( M\) and \( N\) be \( C^1\)-manifolds. Let \( f\in C^1(M,N)\) and \( a\in M\). The map \( df_a\colon T_aM\to T_{f(a)}N\) is linear.
\end{proposition}

\begin{proof}
    We consider two tangent vectors \( \nabla_{\gamma}\) and \( \nabla_{\sigma}\) to \( M\) at \( a\). We know that there exists a path \( s\colon \eR\to M\) such that \( \nabla_{\gamma}+\nabla_{\sigma}=\nabla_s\). This is proposition \ref{PROPooEJBWooSbvypo}, see equation \eqref{EQooYNAOooKkKmxo}.

    Let \( \phi\in C^1(N,\eR)\) be a test function; we have
    \begin{subequations}
        \begin{align}
            df_a(\nabla_{\gamma}+\nabla_{\sigma})\phi&=df_a(\nabla_s)\phi  \label{EQooIMZIooQlZODR}\\
            &=\nabla_s(\phi\circ f)     \label{EQooXMHHooGpbAge}\\
            &=\nabla_{\gamma}(\phi\circ f)+\nabla_{\sigma}(\phi\circ f)\\
            &=\nabla_{f\circ \gamma}(\phi)+\nabla_{f\circ \sigma}(\phi)     \label{EQooHMZAooArgfTN}\\
            &=df_a(\nabla_{\gamma})\phi+df_a(\nabla_{\sigma})\phi.
        \end{align}
    \end{subequations}
    Justifications:
    \begin{itemize}
        \item For \eqref{EQooIMZIooQlZODR}: definition od the path \( s\).
        \item For \eqref{EQooXMHHooGpbAge}: definition \eqref{EQooQNZPooMVaSQC} of \( df_a\).
        \item For \eqref{EQooHMZAooArgfTN}: lemma \ref{LEMooBOZBooNJMccB}.
    \end{itemize}
\end{proof}


The following lemma will be generalized to vector fields in \ref{LEMooZWFAooDlYaJm}.
\begin{lemma}       \label{LEMooSCVHooYPiGse}
    Let \( \varphi\colon U\to M\) be a chart around \( a\in M\) with \( \varphi(s)=a\) (\( s\in U\)). We have \( v\in T_aM\) if and only if there exists reals numbers \( \{ v_k \}_{k=1,\ldots, n}\) such that
    \begin{equation}        \label{EQooNEDSooOhyrCZ}
        v(f)=\sum_{k=1}^nv_k\partial_k(f\circ \varphi)(s).
    \end{equation}
\end{lemma}

\begin{proof}
    Two parts.
    \begin{subproof}
    \item[\( \Rightarrow\)]
    Let \( \gamma\colon \eR\to M\) be a path for the vector \( v\): \( v=\nabla_{\gamma}\). By the regularity hypothesis\footnote{The manifold \( M\) is \( C^k\), the charts maps are \( C^k\) and all that.}, the maps \( f\circ \varphi\colon U\to \eR\) and \( \varphi^{-1}\circ\gamma\colon \eR \to U \) are differentiable usual maps.

    Thus, using the equalities of lemma \ref{LemdfaSurLesPartielles} and theorem \ref{THOooIHPIooIUyPaf}, we can write
    \begin{subequations}
        \begin{align}
            \nabla_{\gamma}f&=\Dsdd{ (f\circ\gamma)(t) }{t}{0}\\
            &=\Dsdd{ (f\circ\varphi)\circ(\varphi^{-1}\circ\gamma)(t) }{t}{0}\\
            &=d(f\circ \varphi)_{(\varphi^{-1}\circ\gamma)(0)}\big( (\varphi^{-1}\circ\gamma)'(0) \big)\\
            &=d(f\circ \varphi)_{s}\big( (\varphi^{-1}\circ\gamma)'(0) \big)\\
            &=\sum_k\partial_k(f\circ \varphi)(s)(\varphi^{-1}\circ\gamma)'(0)_k
        \end{align}
    \end{subequations}
    Let \( v_k=(\varphi^{-1}\circ\gamma)'(0)_k\) and we have the result.
\item[$ \Leftarrow$ ]
    \end{subproof}
\end{proof}

\begin{lemma}       \label{LEMooZXEFooZgXbNP}
    Let \( \varphi\colon U\to M\) be a chart around \( a\in M\) with \( \varphi(s)=a\) (\( s\in U\)). Let \( v\in T_aM\). We have
    \begin{equation}       
        v(f)=\sum_{k=1}^nv_k\partial_k(f\circ \varphi)(s)
    \end{equation}
    with \( v= (\varphi^{-1}\circ \gamma)'(0)\).
\end{lemma}

\begin{normaltext}      \label{NORMooXAJGooDNyxjv}
    If \( v\in \eR^n\) and if \( a\in \eR^n\), we can speak of \( v\in T_a\eR^n\) with the abuse of notation \( v=\nabla_{\gamma}\) where
    \begin{equation}
        \begin{aligned}
            \gamma\colon \eR&\to \eR^n \\
            t&\mapsto a+tv.
        \end{aligned}
    \end{equation}
    You have to keep in mind that \( v\) is an element of \( \eR^n\) (a list of numbers) while \( \nabla_{\gamma}\) is an element of \( T_a\eR^n\) (a differential operator). Writing «\( v=\nabla_{\gamma}\)» is an abuse of notation.

    The object \( \nabla_{\gamma}\) is what one could name «the vector \( v\) tied to the point \( a\)».
\end{normaltext}

This remark is formalised by the following proposition which provides a canonical isomorphism between \( \eR^n\) and \( T_a\eR^n\).

\begin{proposition}     \label{PROPooRXIIooFmhqJd}
    Let \( M\) be a \( C^k\) manifold and \( a\in M\). We consider a chart \( \varphi\colon U\to M\) around \( a\). For \( v\in \eR^n\) we define
    \begin{equation}
        \gamma_{a,v}(t)=\varphi\big( \varphi^{-1}(a)+tv \big).
    \end{equation}
    \begin{enumerate}
        \item
            The map \( \gamma_{a,v}\colon \eR\to M\) is \( C^k\).
        \item
            The map
            \begin{equation}
                \begin{aligned}
                    \psi\colon \eR^n&\to T_aM \\
                    v&\mapsto \nabla_{\gamma_{a,v}} 
                \end{aligned}
            \end{equation}
            is a bijection.
        \item
            We have the handy equalities
            \begin{equation}
                \psi(v)f=d\varphi_s(v)f=\nabla_{s,v}(f)=\Dsdd{ (f\circ\varphi)\big( \varphi^{-1}(a)+tv \big) }{t}{0}=\sum_kv_k\partial_k(f\circ\varphi)\big( \varphi^{-1}(x) \big)
            \end{equation}
            where \( \nabla_{s,v}\) is the operator defined in proposition \ref{PROPooRXIIooFmhqJd}.
    \end{enumerate}
\end{proposition}

\begin{proof}
    The map \( \gamma_{a,v}\) is continuous as composed of continuous maps. The set \( \eR\) is a manifold with the identity as charts. Thus the condition \ref{DEFooFNTHooEwsqXB}\ref{SUBITEMooXQFUooRxMVnw} to be checked reduces to 
    \begin{equation}
        \tilde \gamma_{a,v}=\varphi^{-1}\circ\gamma_{a,v}.
    \end{equation}
    We consider the \(  C^{\infty}\) map
    \begin{equation}
        \begin{aligned}
            l\colon \eR&\to \eR^n \\
            t&\mapsto \varphi^{-1}(a)+tv. 
        \end{aligned}
    \end{equation}
    We have \( \tilde \gamma_{a,v}=\varphi^{-1}\circ\varphi \circ l\). Thus \( \tilde \gamma\) is \(  C^{\infty}\).

    Remain to prove that \( \psi\) is a bijection.
    \begin{subproof}
        \item[Injective]
            Suppose that \( \psi(v)=\psi(w)\). For every \( f\in C^k(M)\) we have \( \nabla_{a,v}(f)=\nabla_{a,w}(f)\), which means
            \begin{equation}        \label{EQooMXJWooQKpzCG}
                \Dsdd{ f\Big( \varphi\big( \varphi^{-1}(a)+tv \big) \Big) }{t}{0}=\Dsdd{ f\Big( \varphi\big( \varphi^{-1}(a)+tw \big) \Big) }{t}{0}.
            \end{equation}
            We apply this to the function \( f=\pr_k\circ\varphi^{-1}\) :
            \begin{equation}
                f\Big( \varphi\big( \varphi^{-1}(a)+tv \big) \Big)=\varphi^{-1}(a)_k+tv_k,
            \end{equation}
            so that
            \begin{equation}
                \nabla_{a,v}(f)=\Dsdd{ \varphi^{-1}(a)_k+tv_k }{t}{0}=v_k.
            \end{equation}
            The equation \eqref{EQooMXJWooQKpzCG} implies \( v_k=w_k\) for every \( k\).
        \item[Surjective]
            The map \( f\circ \varphi\colon U \to \eR \) is a usual \( C^k\) function. The formulas of the lemma \ref{LemdfaSurLesPartielles} are valid; in particular the ones concerning the directional derivative. We have
            \begin{subequations}
                \begin{align}
                    \nabla_{a,v}(f)&=\Dsdd{ (f\circ \varphi)\big( \varphi^{-1}(a)+tv \big) }{t}{0}\\
                    &=\partial_v(f\circ \varphi)\big( \varphi^{-1}(a) \big)\\
                    &=\sum_k v_k\partial_k(f\circ\varphi)\big( \varphi^{-1}(a) \big).
                \end{align}
            \end{subequations}
            This is the general form \eqref{EQooNEDSooOhyrCZ} for the action of a tangent vector on \( f\).
    \end{subproof}
\end{proof}

\begin{proposition}     \label{PROPooKMCGooDEuaWz}
    Let \( \varphi\colon U\to M\) be a chart satisfying \( \varphi(s)=a\). 
    \begin{enumerate}
        \item       \label{ITEMooSFUBooNXgGuu}
            The set\footnote{We use the abuse of notation of \ref{NORMooXAJGooDNyxjv}.} \( \{ d\varphi_s(e_i) \}_{i=1,\ldots, n}\) is a basis of \( T_aM\).
        \item       \label{ITEMooPYPVooKkHrkQ}
            For every \( X\in T_aM\), there exists an unique \( v\in \eR^n\) such that 
            \begin{equation}
                X=d\varphi_{s}(v).
            \end{equation}
    \end{enumerate}
\end{proposition}

\begin{proof}
    For part \ref{ITEMooSFUBooNXgGuu}, we have to prove that the vectors of the form \( d\varphi_s(e_i)\) are linearly independent and spanning \( T_aM\).
    \begin{subproof}
        \item[Spanning]
            Lemma \ref{LEMooSCVHooYPiGse} says that, if \( v\in T_aM\), there exist numbers \( v_k\) such that
            \begin{equation}
                v(f)=\sum_{k=1}^nv_k\partial_k(f\circ\varphi)(s)
            \end{equation}
            We consider the path
            \begin{equation}
                \begin{aligned}
                    \gamma_k\colon \eR&\to U \\
                    t&\mapsto s+te_k. 
                \end{aligned}
            \end{equation}
            Now we have
            \begin{subequations}
                \begin{align}
                    v(f)&=\sum_{k=1}^nv_k\partial_k(f\circ\varphi)(s)\\
                    &=\sum_kv_k\Dsdd{ (f\circ\varphi)(s+te_k) }{t}{0}\\
                    &=\sum_kv_k\Dsdd{ (f\circ\varphi\circ\gamma_k)(t) }{t}{0}\\
                    &=\sum_kv_kd\varphi_{\gamma_k(0)}(\nabla_{\gamma_k})f\\
                    &=\sum_kv_kd\varphi_s(\nabla_{\gamma_k})f\\
                    &=\sum_kv_kd\varphi_s(e_k).
                \end{align}
            \end{subequations}
            The last equality is the abuse of notation explained in \ref{NORMooXAJGooDNyxjv}.
        \item[Independent]
            We suppose that
            \begin{equation}
                \sum_{k=1}^nv_kd\varphi_s(e_k)=0
            \end{equation}
            for some numbers \( v_k\). It means that for every \( C^k\) functions \( f\colon M\to \eR\) we have
            \begin{equation}
                \sum_{k}v_k\partial_k(f\circ \varphi)(s)=0.
            \end{equation}
            Since the function
            \begin{equation}
                \begin{aligned}
                    \pr_i\colon \eR^n&\to \eR \\
                    x&\mapsto x_i 
                \end{aligned}
            \end{equation}
            is \(  C^{\infty}\), we can choose \( f=\pr_k\circ\varphi^{-1}\). Then we have
            \begin{subequations}
                \begin{align}
                    0&=\sum_kv_k\partial_k(\pr_i\circ\varphi^{-1}\circ\varphi)(s)\\
                    &=\sum_kv_k\partial(s\mapsto s_i)(s)\\
                    &=\sum_kv_k\delta_{ki}\\
                    &=v_i.
                \end{align}
            \end{subequations}
            We conclude that \( v_i=0\) for every \( i\) and we are done.
    \end{subproof}
    Now we prove part \ref{ITEMooPYPVooKkHrkQ}. From part \ref{ITEMooSFUBooNXgGuu} there is a set of numbers \( v_i\) such that
    \begin{equation}
        X=\sum_iv_i
    \end{equation}
    We pose \( v=\sum_iv_ie_i\) and we use the linearity of \( d\varphi_s\) :
    \begin{equation}
        X=\sum_iv_id\varphi_s(e_i)=\sum_id\varphi_s(v_ie_i)=d\varphi_s\big( \sum_iv_ie_i \big)=d\varphi_s(v).
    \end{equation}
    For the unicity, let \( v,w\in \eR^n\) such that \( d\varphi_s(v)=d\varphi_s(w)\). Thus we have \( d\varphi_s(v-w)=0\) which implies \( v=w\).
\end{proof}

\begin{lemma}[\cite{MonCerveau}]
    Let \( a\) and \( b\) be different points in the manifold \( M\). Then
    \begin{equation}
        T_aM\cap T_bM=\{ 0 \}.
    \end{equation}
\end{lemma}

\begin{proof}
    The operator which maps every function to zero belongs to \( T_aM\) and \( T_bM\). This is easy. The tricky part is the contrary. Let \( v\in T_aM\) and \( w\in T_bM\) both non zero. We consider charts \( \varphi\colon U\to M\) and \( \psi\colon V\to M\) such that
    \begin{itemize}
        \item \( U\cap V=\emptyset\)
        \item \( \varphi(U)\cap \psi(V)=\emptyset\)
        \item \( a=\varphi(s)\) and \( b=\psi(t)\) with \( s\in U\) and \( t\in V\).
    \end{itemize}
    Let \( \phi\in C^k(M,\eR)\). By lemma \ref{LEMooSCVHooYPiGse} we have
    \begin{equation}        \label{EQooTQKZooIeQNaU}
        v(\phi)=\sum_kv_k\partial_k(\phi\circ \varphi)(s)
    \end{equation}
    and
    \begin{equation}
        w(\phi)=\sum_kw_k\partial_k(\phi\circ \varphi)(t).
    \end{equation}
    The trick now is to build a function \( \phi\) for which \( v(\phi)\neq w(\phi)\).

    Let \( r>0\) such that \( \overline{ B(s,r) }\subset U\). We use the Urysohn lemma \ref{PROPooBOZIooAhKbPs} to create a function \( p\colon U\to \eR\) such that
    \begin{itemize}
        \item \( p=1\) on a neighbourhood of \( s\),
        \item \( p=0\) outside \( \overline{ B(s,r) }\),
        \item \( p\in  C^{\infty}(U)\).
    \end{itemize}
    We also consider a \(  C^{\infty}\) function \( q\colon U\to \eR\) such that \( (\partial_kq)(s)=\alpha_k\) for some numbers \( \alpha_k\) to be fixed later.

    Finally we build
    \begin{equation}
        \begin{aligned}
            \phi\colon M&\to \eR \\
            x&\mapsto \begin{cases}
                (pq)\big( \varphi^{-1}(x) \big)    &   \text{if }  x\in \varphi(U)\\
                0    &    \text{otherwise. }
            \end{cases}
        \end{aligned}
    \end{equation}
    This function is \( C^k\). Indeed there are two possibilities : \( x\in \varphi(U)\) or \( x\notin\varphi(U)\). In the first case \( \phi\) is the composition of \( pq\) (which is \(  C^{\infty}\)) with \( \varphi^{-1}\) which is \( C^k\). If \( x\notin\varphi(U)\), then it is in particular outside \( \varphi\big( \overline{ B(s,r) } \big)\) which is closed.

    The set of points outside of \( \varphi\big( \overline{ B(s,r) } \big)\) is open. Thus there is a neighbourhood of \( x\) which does not intersect \( \varphi\big( \overline{ B(r,s) } \big)\). The function \( \phi\) is zero in this neighbourhood, so that \( \phi\) is \(  C^k\).

    We can compute the values of \( v(\phi)\) and \( w(\phi)\). The easiest if \( w(\phi)=0\) because \( \phi=0\) on a neighbourhood of \( b\). For \( v(\phi)\) we use the formula \ref{EQooTQKZooIeQNaU}. We have
    \begin{equation}
        \partial_k(\phi\circ\varphi)(s)=\partial_k(q)(s)=\alpha_k
    \end{equation}
    because \( p=1\) on a neighbourhood of \( \varphi^{-1}(a)\). Thus we have
    \begin{equation}
        v(\phi)=\sum_kv_k\alpha_k.
    \end{equation}
    We can choose the \( \alpha_k\) in such a way that \( v(\phi)\neq 0\) because \( v\neq 0\).
\end{proof}

\begin{lemma}\label{lem:var_cont_diff}
    Let $V,M$ be two manifolds and $\varphi\colon V\to M$, a differentiable map. We suppose that $\varphi(V)$ is contained in a submanifold $S$ of $M$. If $\dpt{\varphi}{V}{S}$ is continuous\footnote{This hypothesis states the continuity for the topology of \( S\), which is different from the continuity with respect to the topology of \( M\).}, then it is differentiable.
\end{lemma}

\begin{proof}
Let $p\in V$. By proposition~\ref{PROPooLJYEooMjevio}, we have  a coordinate system $\{x_1,\ldots,x_m\}$ valid on a neighbourhood $N$ of $\varphi(p)$ in $M$ such that the set
\[
  \{r\in N\tq x_j(r)=0\, \forall s<j\leq m  \}
\]
with the restriction of $(x_1,\ldots x_s)\in N_S$ form a local chart which contains $\varphi(p)$. From the continuity of $\varphi$, there exists a chart $(W,\psi)$ around $p$ such that $\varphi(W)\subset N_S$. The coordinates $x_j(\varphi(q))$ are differentiable functions of  the coordinates of $q$ in $W$. In particular, the coordinates $x_j(\varphi(q))$ for $1\leq j\leq s$ are differentiable and $\dpt{\varphi}{V}{S}$ is differentiable because its expression in a chart is differentiable.
\end{proof}

A consequence of this lemma: if $V$ and $S$ are submanifolds of $M$ with $V\subset S$, and if $S$ has the induced topology from $M$, then $V$ is a submanifold of $S$. Indeed, we can consider the inclusion $\dpt{\iota}{V}{S}$: it is differentiable from $V$ to $M$ and continuous from $V$ to $S$ then it is differentiable from $V$ to $S$ by the lemma. Thus $V=\iota^{-1}(S)$ is a submanifold of $S$ (this is a classical result of differential geometry).


%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Chain rule and inverse}
%---------------------------------------------------------------------------------------------------------------------------

\begin{lemma}       \label{LEMooEGITooXbAPDe}
    If \( M\) is a \( C^k\) manifold, and if \( \id\colon M\to M\) is the identity map, we have
    \begin{equation}
        d\id_a=\id_{T_aM}.
    \end{equation}
    In other words, the differential of the identity map is the identity.
\end{lemma}

\begin{lemma}[Chain rule\cite{BIBooJMRFooTAhhcg}]       \label{LEMooGRRAooXxDMuw}
    Let \( M_i\) be \( C^k\) manifolds. If the maps \( g\colon M_1\to M_2\) and \( f\colon M_2\to M_3 \) are \( C^k\), thus the composition \( f\circ g\) is \( C^k\) and for every \( a\in M_1\) we have
    \begin{equation}
        d(f\circ g)_a=df_{g(a)}\circ dg_a.
    \end{equation}
\end{lemma}


\begin{proposition}[\cite{BIBooJMRFooTAhhcg}]       \label{PROPooPEMLooPQcywG}
    Let \( f\colon M\to N\) be a diffeomorphism between the \( C^k\) manifolds \( M\) and \( N\). For every \( a\in M\), the map \( df_a\colon T_aM\to T_{f(a)}N\) is a vector space isomorphism and the inverse is given by
    \begin{equation}
        (df_a)^{-1}=(df^{-1})_{f(a)}.
    \end{equation}
\end{proposition}

\begin{proof}
    The linearity of \( df_a\) is the proposition \ref{PROPooNRLVooChhiIS}. Since \( f\) is a diffeomorphism we have the equality \( f^{-1}\circ f=\id_M\). Using the chain rule of lemma \ref{LEMooGRRAooXxDMuw} and the differential of the identity of lemma \ref{LEMooEGITooXbAPDe}, we get
    \begin{equation}
        (df^{-1})_{f(a)}\circ df_a=\id.
    \end{equation}
    The same with \( f\circ f^{-1}=\id\) provides
    \begin{equation}
        df_a\circ(df^{-1})_{f(a)}=\id.
    \end{equation}
    This proves that \( df_a\) is invertible and that its inverse is \( (df^{-1})_{f(a)}\).
\end{proof}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Topology on a tangent space}
%---------------------------------------------------------------------------------------------------------------------------

\begin{propositionDef}[\cite{BIBooDLJSooYWJiIT}]        \label{PROPooHJOXooMGANfd}
    Let \( M\) be a \( C^k\) manifold. Let \( a\in M\) and \( \varphi\colon U\to M\) be a chart around \( a\). We define \( s=\varphi^{-1}(a)\). For \( v\in T_aM\) we define
    \begin{equation}
        \| v \|_{T_aM}=\| (d\varphi_s)^{-1}(v) \|_{\eR^n}.
    \end{equation}
    This is a norm on the vector space \( T_aM\).

    The topology on \( T_aM\) is the one induced by this norm\footnote{Keep in mind that, since \( T_aM\) is finite dimensional, all the norm are equivalent (theorem \ref{ThoNormesEquiv}), so that this norm is not special.}.
\end{propositionDef}

\begin{proof}
    Several points.
    \begin{subproof}
    \item[\( \| v \|\geq 0\)]
        From the very definition, yes.
    \item[\( \| v \|=0\) si et seulement si \( v=0\)]
        If \( \| v \|=0\), then \( \| (d\varphi_s)^{-1}(v) \|_{\eR^n}=0\). Since the norm on \( \eR^n\) is a norm, this implies \( (d\varphi_s)^{-1}(v)=0\). And since \( d\varphi_s\) is a linear bijection, we conclude \( v=0\).
    \item[\( \| \lambda v \|=| \lambda |\| v \|\)]
        Because \( d\varphi_s^{-1}\) is linear.
    \item[\( \| v+w \|\leq \| v \|+\| v \|\)]
        Because \( d\varphi_s^{-1}\) is linear and the corresponding property on \( \eR^n\).
    \end{subproof}
\end{proof}

Now we are allowed to write \( \| v \|\) when \( v\in T_aM\). But we have to keep in mind that it depends on the choice of a local chart.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Vector field}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{lemma}       \label{LEMooXFNQooXwCMNB}
    Let \( M\) be a manifold and \( (U,\varphi)\) be a chart and \( \gamma\) be a path. We set \( a=\varphi^{-1}\big( \gamma(0) \big)\), \(v= (\varphi^{-1}\circ\gamma)'(0)\) and
    \begin{equation}
        \begin{aligned}
            \sigma\colon \eR&\to M \\
            t&\mapsto \varphi(a+tv). 
        \end{aligned}
    \end{equation}
    Then we have \( \nabla_{\gamma}=\nabla_{\sigma}\).   
\end{lemma}

\begin{proof}
    Let \( \phi\in C^k(M, \eR)\). 
    \begin{subequations}
        \begin{align}
            \nabla_{\sigma}(\phi)&=\Dsdd{ \phi\big( \sigma(t) \big) }{t}{0}\\
            &=\Dsdd{ (\phi\circ \varphi)\big( a+t(\varphi^{-1}\circ\gamma)'(0) \big) }{t}{0}\\
            &=\sum_k\partial_k(\phi\circ\varphi)(a)(\varphi^{-1}\circ\gamma)'(0)_k  \label{SUBEQooFDVFooFzACbX}\\
            &=\Dsdd{ (\phi\circ\varphi)\big( (\varphi^{-1}\circ\gamma)(t) \big) }{t}{0}\\
            &=\Dsdd{ (\phi\circ\varphi\circ\varphi^{-1}\circ\gamma)(t) }{t}{0}\\
            &=\Dsdd{ (\phi\circ\gamma)(t) }{t}{0}\\
            &=\nabla_{\gamma}(\phi).
        \end{align}
    \end{subequations}
    For \eqref{SUBEQooFDVFooFzACbX}: the maps \( \phi\circ\varphi\colon U\to \eR\) and \( \varphi^{-1}\circ\gamma\colon \eR\to U\) are \( C^k\) maps, so that we can apply the formula \eqref{EQooZMAUooIusxgD}:
\end{proof}

\begin{lemma}       \label{LEMooGPCBooXMTddG}
    Let \( M\) be a manifold, \( (U,\varphi)\) be a chart, \( a\in U\) and \( v,w\in \eR^n\). We define \( \gamma_v(t)=\varphi(a+tv)\) and \( \gamma_w(t)=\varphi(a+tw)\). If \( v\neq w\) then 
    \begin{equation}
        \nabla_{\gamma_v}\neq \nabla_{\gamma_w}.
    \end{equation}
\end{lemma}

\begin{proof}
    We suppose \( v\neq w\). If \( w\) is a multiple of \( v\), an adaptation of the «product» part of proposition \ref{PROPooEJBWooSbvypo} shows that \( \nabla_{\gamma_v}\neq \nabla_{\gamma_w}\).

    Of \( v\) and \( w\) are nor aligned, we consider a basis \( \{ e_1,\ldots, e_n \}\) of \( \eR^n\) such that \( e_1=v\) and \( e_2=w\) (theorem \ref{THOooOQLQooHqEeDK}). Now we consider the function
    \begin{equation}
        \begin{aligned}
            f\colon \eR^n&\to \eR \\
            x&\mapsto (x-a)_1. 
        \end{aligned}
    \end{equation}
    We will show that the result of \( \nabla_{\gamma_v}\) and \( \nabla_{\gamma_w}\) on the function \( f\circ\varphi^{-1}\) are not equal. First we have
    \begin{subequations}
        \begin{align}
            \nabla_{\gamma_v}(f\circ\varphi^{-1})&=\Dsdd{ (f\circ\varphi^{-1})\big( \gamma_v(t) \big) }{t}{0}\\
            &=\Dsdd{ (f\circ\varphi^{-1}\circ\varphi)(a+tv) }{t}{0}\\
            &=\Dsdd{ f(a+tv) }{t}{0}\\
            &=\Dsdd{ (tv)_1 }{t}{0}\\
            &=\Dsdd{ t }{t}{0}\\
            &=1.
        \end{align}
    \end{subequations}
    In the same way we get
    \begin{equation}
        \nabla_{\gamma_w}(f\circ\varphi^{-1})=\Dsdd{ f(a+tw) }{t}{0}=\Dsdd{ (tw)_1 }{t}{0}=\Dsdd{ 0 }{t}{0}=0.
    \end{equation}
\end{proof}


\begin{proposition}     \label{PROPooMEPPooRonxuh}
    Let \( M\) be a manifold, \( (U, \varphi)\) a chart. If \( s\in U\) the map\footnote{We use the notation \eqref{EQooJQVRooLziKoH}.}
    \begin{equation}        \label{EQooJMTJooZNzREy}
        \begin{aligned}
            \psi\colon \eR^n&\to T_{\varphi(s)}M \\
            v&\mapsto \Dsdd{ \varphi(s+tv) }{t}{0} 
        \end{aligned}
    \end{equation}
    is a vector space isomorphism.
\end{proposition}

\begin{proof}
    We need to prove that \( \psi\) is surjective, injective and linear.
    \begin{subproof}
    \item[Surjective] Lemma \ref{LEMooXFNQooXwCMNB}.
    \item[Injective] Lemme \ref{LEMooGPCBooXMTddG}.
    \item[Linear]
        Let \( v,w\in \eR^n\). If set \( \sigma(t)=s+t(v+w)\), we have
        \begin{subequations}
            \begin{align}
                \psi(v+w)\phi&=\Dsdd{ (\phi\circ \varphi)\big( s+t(v+w) \big) }{t}{0}\\
                &=\Dsdd{ (\phi\circ \varphi)\circ \sigma(t) }{t}{0}\\
                &=\sum_k\partial_k(\phi\circ\varphi)\big( \sigma(0) \big)\sigma'(0)_k\\
                &=\sum_k\partial_k(\phi\circ\varphi)\big( \sigma(0) \big)(v_k+w_k)\\
                &=\sum_k\partial_k(\phi\circ\varphi)\big( \sigma(0) \big)v_k+\sum_k\partial_k(\phi\circ\varphi)\big( \sigma(0) \big)w_k\\
                &=\Dsdd{ (\phi\circ\varphi)\big( \sigma(0)+tv \big) }{t}{0}+\Dsdd{ (\phi\circ\varphi)\big( \sigma(0)+tw \big) }{t}{0}\\
                &=\psi(v)\phi+\psi(w)\phi.
            \end{align}
        \end{subequations}
        In the same way, if \( \lambda\in \eR\) we set \( \sigma(t)=s+t\lambda v\) and we have
        \begin{subequations}
            \begin{align}
                \psi(\lambda v)\phi&=\Dsdd{ (\phi\circ\varphi)(s+t\lambda v) }{t}{0}\\
                &=\Dsdd{ (\phi\circ\varphi)\big( \sigma(t) \big) }{t}{0}\\
                &=d(\phi\circ\varphi)_{\sigma(0)}\sigma'(0)\\
                &=\lambda d(\phi\circ\varphi)_{\sigma(0)}(v)\\
                &=\lambda\psi(v)\phi.
            \end{align}
        \end{subequations}
    \end{subproof}
\end{proof}

\begin{lemma}[\cite{MonCerveau}]        \label{LEMooZWFAooDlYaJm}
    Let \( M\) be a \( C^k\) manifold, and \( \varphi\colon U\to M\) be a local chart. A map \( X\colon M\to TM\) is a \( C^k\) vector field on \( \varphi(U)\) if and only it can be written under the form
    \begin{equation}
        X_x(f)=\sum_{k=1}^nv_k(x)\partial_k(f\circ\varphi)\big( \varphi^{-1}(x) \big)
    \end{equation}
    for some \( C^k\) maps \( v_k\colon M\to \eR\).
\end{lemma}

\begin{lemma}       \label{LEMooIQZWooOSLNXB}
    If \( x\in M\) and \( v\in \eR^n\). The isomorphism \( \psi\) of proposition \ref{PROPooMEPPooRonxuh} satisfies
    \begin{equation}        \label{EQooBVOBooBTfYWC}
        \psi(v)f=\sum_kv_k\partial_k(f\circ\varphi)(s)
    \end{equation}
    where \( s=\varphi^{-1}(x)\).
\end{lemma}

\begin{proof}
    We use the linearity of proposition \ref{PROPooMEPPooRonxuh}:
    \begin{subequations}
        \begin{align}
            \psi(v)f&=\sum_kv_k\psi(e_k)f\\
            &=\sum_kv_k\Dsdd{ f\big( \varphi(s+te_k) \big) }{t}{0}\\
            &=\sum_kv_k\Dsdd{ (f\circ\varphi)(s+te_k) }{t}{0}\\
            &=\sum_kv_k\partial_k(f\circ\varphi)(s).
        \end{align}
    \end{subequations}
\end{proof}

\begin{theorem}     \label{THOooTSQXooLvJMQb}
    Let \( M\) be a manifold. We consider the definition maps \( \{ U_{\alpha}, \varphi_{\alpha} \}\) of \( M\). Then the set \( TM\) becomes a manifold with the maps \( V_{\alpha}=U_{\alpha}\times \eR^n\) and
    \begin{equation}
        \begin{aligned}
            \psi_{\alpha}\colon U_{\alpha}\times \eR^n&\to TM \\
            (x,v)&\mapsto \Dsdd{ \varphi_{\alpha}(x+tv) }{t}{0}. 
        \end{aligned}
    \end{equation}
\end{theorem}


%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Vector field}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}[Vector field]        \label{DEFooAATTooLhNqDb}
    Let \( M\) be a \(  C^{\infty}\) manifold. A \defe{vector field}{vector field} is a map \( X\colon M\to TM\) such that \( X(p)\in T_pM\) for every \( p\in M\).

    We will always write \( X_p\) instead of \( X(p)\).
\end{definition}

\begin{proposition}         \label{PROPooGYWRooPIyocN}
    Let \( M\) be a \( C^{k+1}\) manifold, \( X\) be a \( C^k\) vector field and \( f\colon M \to \eR\) be a \( C^k\) function. Then the map
    \begin{equation}
        \begin{aligned}
            X(f)\colon M&\to \eR \\
            p&\mapsto X_p(f) 
        \end{aligned}
    \end{equation}
    is \( C^{k-1}\).
\end{proposition}


%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Tangent and cotangent bundle}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

If $M$ is a $n$ dimensional manifold, as set the tangent bundle\index{tangent!space} is the \emph{disjoint} union of tangent spaces
\begin{equation}
  TM=\bigcup_{x\in M}T_xM.
\end{equation}

\begin{theorem}
	The tangent bundle admits a $2n$ dimensional manifold structure for which the projection
	\begin{equation}
		\begin{aligned}
			\pi \colon TM &\to M\\
			T_pM&\mapsto p
		\end{aligned}
	\end{equation}
	is a submersion.
\end{theorem}

The structure is easy to guess. If $\dpt{\varphi_{\alpha}}{\mU_{\alpha}}{M}$ is a coordinate system on $M$ (with $\mU_{\alpha}\subset\eR^n$), we define $\dpt{\psi_{\alpha}}{\mU_{\alpha}\times \eR^n}{TM}$ by
\[
  \psi( \underbrace{x_1,\ldots x_n}_{\in\mU_{\alpha}},\underbrace{a_1,\ldots a_n}_{\in\eR^n}  )
          =\sum_i a_i\left.\dsd{}{x_i}\right|_{\varphi(x_1,\ldots,x_n)}.
\]
The map $\psi_{\beta}^{-1}\circ\psi_{\beta}$ is differentiable because
\[
(\psi_{\beta}^{-1}\circ\psi_{\beta})(x,a)=( y(x),\sum_i a_i\left.\dsd{y_j}{x_i}\right|_{y(x)}  )
\]
which is a composition of differentiable maps. The set $TM$ endowed with this structure is called the \defe{tangent bundle}{tangent!bundle}.


%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Decomposition of vectors}
%---------------------------------------------------------------------------------------------------------------------------

If \( X,Y\in T_pM\) are tangent vectors, one can define \( X+Y\) and \( \lambda X\) for every \( \lambda\in\eR\). The second one is easy:
\begin{equation}
    \lambda X=\Dsdd{ X(\lambda t) }{t}{0}.
\end{equation}
In order to define the sum of two vectors one has to consider a neighbourhood \( \mU\) of \( p\) in \( M\) and a chart \( \varphi\colon \mU\to \mO\) where \( \mO\) is an open set in \( \eR^n\). Then one consider a basis \( \{ e_i \}_{1\leq i\leq n}\) of \( \eR^n\) at the point \( \varphi(p)\). With these choices we define the ``basis'' path
\begin{equation}
    \gamma_i(t)=\varphi^{-1}(te_i)
\end{equation}
and we write
\begin{equation}
    \partial_i=\frac{ \partial  }{ \partial x_i }=\Dsdd{ \varphi^{-1}(te_i) }{t}{0}.
\end{equation}
The vectors \( \partial_i\) form a basis of \( T_pM\) in the sense of the following lemma.

\begin{lemma}       \label{LEMooXDESooHXzIJU}
    The action of a vector \( X\in T_pM\) on a function \( f\colon M\to \eR\) can be decomposed into
    \begin{equation}
        Xf=\sum_{i=1}^n X_i(\partial_if)
    \end{equation}
    with \( X_i\in\eR\)
\end{lemma}

\begin{proof}
    Let \( \varphi\colon M\to \eR^n\) be a chart of a neighbourhood of \( p\) with \( \varphi(p)=0\). We determine the value of \( X_i\) using the function
    \begin{equation}
        f_i(x)=\varphi(x)_i,
    \end{equation}
    that is the \( i\)th component of the point \( \varphi(x)\in\eR^n\). Then if we write \( \varphi\big( X(t) \big)=\sum_j a_j(t)e_j\) we have
    \begin{subequations}
        \begin{align}
            X(f_i)=\Dsdd{ f_i\big( X(t) \big) }{t}{0}=\Dsdd{ \big[ \sum_ja_j(t)e_j \big]_i }{t}{0}=\Dsdd{ ai_(t) }{t}{0}=a_i'(0).
        \end{align}
    \end{subequations}
    Notice that \( a_i(0)=0\) since \( X(0)=p\) and \( \varphi(p)=0\). The combination \( f\circ\varphi^{-1}\) is an usual function from \( \eR^n\) to \( \eR\), so that we can use the chain rule on it. The following computation thus make sense:
    \begin{subequations}
        \begin{align}
            Xf&=\Dsdd{ f\big( X(t) \big) }{t}{0}\\
            &=\Dsdd{ f\Big( \varphi^{-1}\varphi\big( X(t) \big) \Big) }{t}{0}\\
            &=\Dsdd{ (f\circ\varphi^{-1})\big( \sum_ja_j(t)e_j \big) }{t}{0}\\
            &=\sum_k \frac{ \partial (f\circ\varphi^{-1}) }{ \partial x_k }\big( \underbrace{\sum_ja_j(0)e_j}_{=\varphi(p)=0} \big)\underbrace{\frac{ d\big[ \sum_ja_j(t)e_j \big]_k  }{ dt }}_{=a'_k(0)}\\
            &=\sum_k a'_k(0)\frac{ \partial (f\circ\varphi^{-1}) }{ \partial x_k }(0).
        \end{align}
    \end{subequations}
    Now using the definition of a derivative of a function \( \eR^n\to \eR\) and of the ``basis'' tangent vector \( \partial_k\),
    \begin{subequations}
        \begin{align}
            \frac{ \partial (f\circ\varphi^{-1}) }{ \partial x_k }(0)&=\Dsdd{ (f\circ\varphi^{-1})(te_k) }{t}{0}\\
            &=\partial_k f
        \end{align}
    \end{subequations}
   At the end of the day we have
   \begin{equation}
       Xf=\sum_k a'_k(0)\partial_kf.
   \end{equation}
\end{proof}

This lemma allows us to define the sum in \( T_pM\) as\quext{This is not really true because we still have to prove that for every choice of \( X_i\), there exists a path \( \alpha\) such that \( \alpha'(0)=\sum_iX_i\partial_i\).}      %TODOooNHVGooLYbUkg
\begin{equation}
    \left( \sum_kX_k\partial_k \right)+\left( \sum_kY_k\partial_k \right)=\sum_k (X_k+Y_k)\partial_k
\end{equation}
when \( X_k\) and \( Y_k\) are reals.

The tangent space \( T_pM\) is thus a vector space.

\begin{lemma}       \label{LEMooVCSJooEuDZFz}
    Let \( M\) and \( N\) be smooth manifolds of dimension \( m\) and \( n\) with charts \( \varphi\colon U\to M\) and \( \psi\colon V\to N\) around \( p\in M\) and \( f(p)\in N\). We consider basis \( \{ e_i \}_{i=1,\ldots, m}\) of \( \eR^m\) and \( \{ e'_{\alpha} \}_{\alpha=1,\ldots, n}\) of \( \eR^n\).

    The matrix of \( df_p\colon T_pM\to T_{f(p)}N\) in the basis \( \{ d\varphi_{\varphi^{-1}(p)}(e_i) \}\) and \( \{ d\psi_{\psi^{-1}(f(p))}(e'_{\alpha}) \}\) is the same as the matrix of \( d(\psi^{-1}\circ f\circ\varphi)_{\varphi^{-1}(p)}\) as map from \( \eR^m\) to \( \eR^n\).
\end{lemma}

\begin{proof}
    Let subdivise.
    \begin{subproof}
        \item[Notations]
            As a preliminary remark, the fact that the proposed sets are basis is the proposition \ref{PROPooKMCGooDEuaWz}\ref{ITEMooSFUBooNXgGuu}. For the notations, we write
            \begin{subequations}
                \begin{align}
                    \frac{ \partial  }{ \partial x_i }&=d\varphi_{\varphi^{-1}(p)}(e_i),\\
                    \frac{ \partial  }{ \partial y_{\alpha} }&=d\psi_{\psi^{-1}\big( f(p) \big)}(e'_{\alpha}).
                \end{align}
            \end{subequations}
        \item[Component]
            Let \( v\in T_{f(p)}N\). We prove that
            \begin{equation}        \label{EQooISXNooJOzUmS}
                v_{\alpha}=\Big( (d\psi^{-1})_{f(p)}v \Big)_{\alpha}
            \end{equation}
            where in the left-hand side we are speaking of component with respect to the basis \( \{ \partial_{y_{\alpha}} \}\) while in the right-hand side, the ones with respect to the basis \( \{ e'_{\alpha} \}\).

            First we decompose \( v\):
            \begin{equation}
                v=\sum_{\alpha}v_{\alpha}\frac{ \partial  }{ \partial y_{\alpha} }=\sum_{\alpha}v_{\alpha}d\psi_{\psi^{-1}\big( f(p) \big)}e'_{\alpha},
            \end{equation}
            then we apply \( d\psi^{-1}_{f(p)}\) to that equation:
            \begin{equation}
                d\psi^{-1}_{f(p)}v=\sum_{\alpha}v_{\alpha}e'_{\alpha}.
            \end{equation}
            Taking the \( \alpha\)\th\ component on both side we have our result \eqref{EQooISXNooJOzUmS}.
        \item[Matrix]
            The matrix of a linear map is defined by the proposition \ref{PROPooGXDBooHfKRrv}. In our case,
            \begin{equation}
                    (df_p)_{\alpha i}=\left( df_p\big( \frac{ \partial  }{ \partial x_i } \big) \right)_{\alpha} =\Big( df_p\circ d\varphi_{\varphi^{-1}(p)}e_i \Big)_{\alpha}.
            \end{equation}
            Using the formula \eqref{EQooISXNooJOzUmS},
            \begin{subequations}
                \begin{align}
                    (df_p)_{\alpha i}&=\Big( df_p\circ d\varphi_{\varphi^{-1}(p)}e_i \Big)_{\alpha}\\
                    &=\big( (d\psi^{-1})_{f(p)}\circ df_p\circ d\varphi_{\varphi^{-1}(p)}e_i \big)_{\alpha}\\
                    &=\big( (d\psi^{-1})_{f(p)}\circ df_p\circ d\varphi_{\varphi^{-1}(p)} \big)_{\alpha i}\\
                \end{align}
            \end{subequations}
    \end{subproof}
\end{proof}

\subsection{Commutator of vector fields}

\begin{lemma}       \label{LEMooPSWEooVKLWMQ}
    If \( X\) is a \( c^k\) vector field on the \( C^k\) manifold \( M\) and if \( f\) is a \( c^k\) function, then the formula
    \begin{equation}
        (Xf)(x)=X_x(f)
    \end{equation}
    defines a \( C^{k-1}\) function \( Xf\) on \( M\).
\end{lemma}

\begin{propositionDef}      \label{DEFooHOTOooRaPwyo}
    Let \( M\) be a \( C^k\) manifold with \( k\geq 2\). Let $X$, $Y\in\cvec(M)$.
    \begin{enumerate}
        \item       \label{ITEMooZKKUooQjYftU}
    For every \( x\in M\), the operator \( [X,Y]_x\) defined by
    \begin{equation}        \label{EQooDSKWooXdjPPP}
      [X,Y]_xf=X_x(Yf)-Y_x(Xf)
    \end{equation}
    is an element of \( T_xM\).

    Here, \( Yf\) and \( Xf\) are defined by virtue of lemma \ref{LEMooPSWEooVKLWMQ}.
\item       \label{ITEMooPGPLooQrKxWY}
    The map \( x\mapsto [X,Y]_x\) is a vector field of class \( C^{k-1}\).
    \end{enumerate}

    The so-defined vector field \( [X,Y]\) is the \defe{commutator}{commutator of vector fields} of \( X\) and \( Y\).
\end{propositionDef}

\begin{proof}
    Point by point.
    \begin{subproof}
        \item[\ref{ITEMooZKKUooQjYftU}]
            From lemma \ref{LEMooZWFAooDlYaJm}, we have \( C^k\) functions \( v_k\colon M\to \eR\) such that
            \begin{equation}
                X_x(f)=\sum_kv_k(x)\partial_k(f\circ \varphi)\big( \varphi^{-1}(x) \big),
            \end{equation}
            and the same for \( Y\) :
            \begin{equation}
                Y_y(f)=\sum_lw_l(y)\partial_l(f\circ\varphi)\big( \varphi^{-1}(y) \big).
            \end{equation}
            We need to compute \( X_x(Yf)\), that is
            \begin{equation}        \label{EQooAHMYooWRttQr}
                X_x(Yf)=\sum_kv_k(x)\partial_k(Yf\circ\varphi)\big( \varphi^{-1}(x) \big).
            \end{equation}
            The easy part of that is
            \begin{equation}
                (Yf\circ\varphi)(s)=(Yf)\big( \varphi(s) \big)=\sum_l(w_l\circ\varphi)(s)\partial_l(f\circ \varphi)(s).
            \end{equation}
            This is a product of two functions \( w_l\circ\varphi\colon U\to \eR\) and \( f\circ\varphi\colon U\to \eR\). For computing the partial derivative, we use the usual Leibnitz rule :
            \begin{equation}
                \partial_k(Yf\circ\varphi)(s)=\sum_{l}\partial_k(w_l\circ\varphi)(s)\partial_l(f\circ\varphi)(s)+\sum_l(w_l\circ\varphi)(s)\partial_k\partial_l(f\circ\varphi)(s).
            \end{equation}
            We can put that in \eqref{EQooAHMYooWRttQr}, with the definition \( s=\varphi^{-1}(x)\in U\subset \eR^n\) :
            \begin{subequations}
                \begin{align}
                    X_x(Yf)&=\sum_kv_k(x)\sum_l\partial_k(w_l\circ\varphi)(s)\partial_l(f\circ\varphi)(s)\\
                    &\quad +\sum_{kl}v_k(x)(w_l\circ\varphi)(s)\partial_k\partial_l(f\circ\varphi)(s)\\
                    &=\sum_{kl}v_k(x)\partial_k(w_l\circ\varphi)(s)\partial_l(f\circ\varphi)(s)\\
                    &\quad+\sum_{kl}v_k(x)w_l(x)\partial_k\partial_l(f\circ\varphi)(s).
                \end{align}
            \end{subequations}
            The expression of \( Y_x(Xf)\) is the same, permuting \( v\) and \( w\). The commutator has \( 4\) terms :
            \begin{equation}
                \begin{aligned}[]
                    [X,Y]_xf&=\sum_{kl}v_k(x)\partial_k(w_l\circ\varphi)(s)\partial_l(f\circ\varphi)(s)\\
                    &\quad+\sum_{kl}v_k(x)w_l(x)\partial_k\partial_l(f\circ\varphi)(s)\\
                    &\quad -\sum_{kl}w_k(x)\partial_k(v_l\circ\varphi)(s)\partial_l(f\circ\varphi)(s)\\
                    &\quad -\sum_{kl}w_k(x)v_l(x)\partial_k\partial_l(f\circ\varphi)(s).
                \end{aligned}
            \end{equation}
            By virtue of theorem \ref{Schwarz}, the two terms with second derivatives cancel out because the maps are of class \( C^k\) with \( k\geq 2\). Only two terms remain :
            \begin{equation}
                [X,Y]_xf=\sum_l\big[ \sum_kv_k(x)\partial_k(w_l\circ\varphi)(s)-w_k(x)\partial_k(v_l\circ\varphi)(s) \big].
            \end{equation}
            We pose
            \begin{equation}
                \begin{aligned}
                    u_l\colon M&\to \eR \\
                    x&\mapsto  \sum_k\big[ v_k(x)\partial_k(w_l\circ\varphi)\big( \varphi^{-1}(x) \big)-w_k(x)\partial_k(v_l\circ\varphi)\big( \varphi^{-1}(x) \big) \big].
                \end{aligned}
            \end{equation}
            For each \( x\) we have
            \begin{equation}        \label{EQooVUOKooAyGoae}
                [X,Y]_x(f)=\sum_lu_l(x)\partial_l(f\circ\varphi)(s).
            \end{equation}
            By lemma \ref{LEMooSCVHooYPiGse}, this means that \( [X,Y]_x\in T_xM\).

        \item[\ref{ITEMooPGPLooQrKxWY}]

            Now the functions \( u_l\) are of of class \( C^{k-1}\) (theorem \ref{THOooPZTAooTASBhZ}) which satisfies, so that the lemma \ref{LEMooPSWEooVKLWMQ} makes \( [X,Y] \) a vector field of class \( C^{k-1}\).
    \end{subproof}
\end{proof}

\begin{lemma}       \label{LEMooPWMUooRalWxC}
    Let \( M\) be a \( C^k\) manifold. Let \( \varphi\colon U\to M\) be a chart around \( a\in M\). Let \( \psi_a\colon \eR^n\to T_aM \) be the map defined in proposition \ref{PROPooMEPPooRonxuh}.

    A map \( X\colon M\to TM\) is a \( C^k\) vector field on \( \varphi(U)\) if and only if there exist a \( C^k\) function \( v\colon M\to \eR^n\) such that 
    \begin{equation}
        X=\psi\circ v
    \end{equation}
    where it is understood that \( (\psi\circ v)(x)=\psi_x\big( v(x) \big)\).
\end{lemma}


\begin{lemma}
    Let \( M\) be a smooth manifold\footnote{When one deal with commutators, the natural setting is (at least) \(  C^{\infty}\) manifolds since the bracket diminishes by \( 1\) the regularity of the vector fields.}. Let \( X,Y\) be smooth vector fields given by \( X=\psi\circ v\) and \( Y=\psi\circ w\). Then we have
    \begin{equation}
        [\psi\circ v,\psi\circ w]=\psi\circ u
    \end{equation}
    with
    \begin{equation}
        \begin{aligned}
            u_l\colon \varphi(U)&\to \eR \\
            x&\mapsto X_x(w_l)-Y_x(v_l). 
        \end{aligned}
    \end{equation}
    This equation can be shorthanded into
    \begin{equation}
        u=X(w)-Y(v).
    \end{equation}
\end{lemma}

\begin{proof}
    We start from the expression \ref{EQooVUOKooAyGoae} in which we substitute the values of \eqref{LEMooZWFAooDlYaJm} :
    \begin{equation}
        u_l(x)=\sum_k\underbrace{v_k(x)\partial_k(w_l\circ\varphi)(s)}_{=X_x(w_l)}-w_k(x)\partial_k(v_l\circ\varphi)(s)=X_x(w_l)-Y_x(v_l).
    \end{equation}
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Submanifold}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{definition}      \label{DEFooLQHWooMOTgzq}
    If $M$ is a differentiable manifold and $S$, a subset of $M$, we say that $S$ is a \defe{submanifold}{submanifold} of dimension $k$ if $\forall\,p\in S$, there exists a chart $\dpt{\varphi}{\mU}{M}$ around $p$ such that
    \begin{equation}        \label{EQooLWQRooQJCQbA}
       \varphi^{-1}(\varphi(\mU)\cap S)=\eR^k\cap\mU:=\{(x_1,\ldots,x_k,0\ldots,0)\in\mU\}.
    \end{equation}
\end{definition}

Let \( k\leq n\) in \( \eN\). We consider the maps
\begin{equation}
    \begin{aligned}
        \proj_k\colon \eR^n&\to \eR^k \\
        x&\mapsto (x_1,\ldots, x_k). 
    \end{aligned}
\end{equation}
and
\begin{equation}
    \begin{aligned}
        j\colon \eR^k&\to \eR^n \\
        x&\mapsto (x_1,\ldots, x_k,0,\ldots 0). 
    \end{aligned}
\end{equation}

\begin{proposition}[\cite{BIBooDUPSooZjcTHL}]
    Let \( S\) be a smooth submanifold of the smooth manifold \( M\). Let \( p\in S\). We consider a map \( \varphi\colon U\to M\) around \( p\) such that\footnote{we write the condition \ref{EQooLWQRooQJCQbA} in a more condensed way.}
    \begin{equation}
        \varphi^{-1}\big( \varphi(U)\cap S \big)=U\cap j(\eR^k).
    \end{equation}
    Let \( X=\varphi(U)\cap S\) and \( Y=(\proj_k\circ\varphi^{-1})(X)\). Then we define
    \begin{equation}
        \begin{aligned}
            \psi\colon Y&\to X \\
            x&\mapsto (\varphi\circ j)(x). 
        \end{aligned}
    \end{equation}
    We have:
    \begin{enumerate}
        \item
            \( \psi\) is bijective,
        \item
            for every chart \( \varphi_{\alpha}\colon U_{\alpha}\to M\) of \( M\), the maps
            \begin{equation}        \label{EQooBAGFooDnpctJ}
                    \psi^{-1}\circ\varphi_{\alpha}\colon \varphi_{\alpha}^{-1}\big( \psi(Y) \big)\to Y
            \end{equation}
            and
            \begin{equation}        \label{EQooKQIUooDCCczD}
                \varphi_{\alpha}^{-1}\circ\psi\colon \psi^{-1}\big( \varphi_{\alpha}(U_{\alpha}) \big)\to U_{\alpha}
            \end{equation}
            are smooth.
    \end{enumerate}
\end{proposition}

\begin{proof}
    In several parts.
    \begin{subproof}
        \item[\( \psi\) is injective]
            Let \( a,b\in Y\subset \eR^k\) such that \( \psi(a)=\psi(b)\), that is \( (\varphi\circ j)(a)=(\varphi\circ j)(b)\). Since \( \varphi\) and \( j\) are injective, we have \( a=b\).
        \item[\( j\circ\proj_k=\id|_{j(\eR^k)}\)]
            If \( a\in j(\eR^k)\), we have \( a=(a_1,\ldots, a_k,0,\ldots, 0)\), so that
            \begin{equation}
                j\circ\proj_k(a)=j(a_1,\ldots, a_k)=(a_1,\ldots, a_k,0,\ldots, 0)=a.
            \end{equation}
        \item[\( \psi\) is surjective]
            Let \( x\in X\). By definition of \( Y\), we have \( y=\proj_k\big( \varphi^{-1}(x) \big)\in Y\). We prove that \( \psi(y)=x\). We have
            \begin{equation}        \label{EQooFFSTooCddIyX}
                \psi(y)=(\psi\circ\proj_k\circ\varphi^{-1})(x)=(\varphi\circ j\circ\proj_k\circ\varphi^{-1})(x).
            \end{equation}
            Since \( x\in X=\varphi(U)\cap S\) we have \( \varphi^{-1}(x)\subset U\cap j(\eR^k)\). We know that \( j\circ\proj_k=\id|_{j(\eR^k)}\), so that
            \begin{equation}
                (j\circ\proj_k)\big( \varphi^{-1}(x) \big)=\varphi^{-1}(x).
            \end{equation}
            We continue \eqref{EQooFFSTooCddIyX}:
            \begin{equation}
                \psi(y)=(\varphi\circ j\circ\proj_k\circ\varphi^{-1})(x)=\varphi\big( \varphi^{-1}(x) \big)=x.
            \end{equation}
            So \( \psi\) is surjective. And we proved that \( \psi\) is a bijection.

            By the way, we have a formula for the inverse of \( \psi\) :
            \begin{equation}        \label{EQooQSZUooWsAqCz}
                \psi^{-1}=\proj_k\circ\varphi^{-1}\colon X\to Y.
            \end{equation}
        \item[First smoothness]
            We prove that \eqref{EQooBAGFooDnpctJ} is smooth. First notice that
            \begin{equation}
                \varphi_{\alpha}\Big( \varphi_{\alpha}^{-1}\big( \psi(Y) \big) \Big)\subset\psi(Y)=X=\varphi(U)\cap S\subset \varphi(U).
            \end{equation}
            Thus it makes sense to write
            \begin{equation}        \label{EQooOTSUooXHGAZz}
                \psi^{-1}\circ\varphi_{\alpha}=\psi^{-1}\circ\varphi\circ\varphi^{-1}\circ\varphi_{\alpha}
            \end{equation}
            as maps defined on \( \varphi_{\alpha}^{-1}\big( \psi(Y) \big)\). Since \( \varphi\) and \( \varphi_{\alpha}\) are charts, the map \( \varphi^{-1}\circ\varphi_{\alpha}\) is smooth.

            We know the inverse of \( \psi\) from equation \eqref{EQooQSZUooWsAqCz}. We have
            \begin{equation}
                \psi^{-1}\circ\varphi=\proj_k\circ\varphi^{-1}\circ\varphi=\proj_k,
            \end{equation}
            which is smooth.

            Equation \eqref{EQooOTSUooXHGAZz} is now the composition of two smooth functions.
        \item[Second smoothness]
            We prove that \eqref{EQooKQIUooDCCczD} is smooth. We have
            \begin{equation}
                \varphi_{\alpha}^{-1}\circ\psi=\varphi_{\alpha}^{-1}\circ\varphi\circ j
            \end{equation}
            while \( \varphi_{\alpha}^{-1}\), \( \varphi\) and \( j\) are smooth.
    \end{subproof}
\end{proof}

The following proposition shows that a submanifold is a manifold for itself.
\begin{proposition}[\cite{MonCerveau}]      \label{PROPooRZIHooXIhnpq}
    Let \( S\) be a smooth submanifold of the smooth manifold \( M\). For each \( p\in S\), we consider the set \( \{ \varphi_{p,i} \}_{i\in I}\) of the charts \( \varphi_{p,i}\colon U_{p,i}\to M\) around \( p\) such that
    \begin{equation}
        \varphi_{p,i}^{-1}\big( \varphi(U_{p,i})\cap S \big)=U_{p,i}\cap j(\eR^k).
    \end{equation}
    Let \( X_{p,i}=\varphi_{p,i}(U_{p,i})\cap S\) and \( Y_{p,i}=(\proj_k\circ\varphi_{p,i}^{-1})(X_{p,i})\). Then we define
    \begin{equation}
        \begin{aligned}
            \psi_{p,i}\colon Y_{p,i}&\to X_{p,i} \\
            x&\mapsto (\varphi_{p,i}\circ j)(x). 
        \end{aligned}
    \end{equation}
    The couple \( \big( S,\{ (U_{p,i},\varphi_{p,i}) \}_{i\in I} \big)\) is a manifold\footnote{Well. The index set \( I\) may depend on \( p\), but the notations are already complicated enough.}.

    When \( S\) is a submanifold, we will always consider this manifold structure on \( S\).
\end{proposition}

\begin{definition}      \label{DEFooZKUIooXWVGvh}
    A map $\dpt{f}{M_1}{M_2}$ is an \defe{immersion}{immersion} at $p\in M_1$ if $\dpt{df_p}{T_pM_1}{T_{f(p)}M_2}$ is injective\footnote{Differential of map, definition \ref{DEFooDRGUooDPFIJa}.}. It is a \defe{submersion}{submersion} if $df_p$ is surjective.
\end{definition}

\begin{proposition}       \label{PROPooLJYEooMjevio}
    Let $M$ be a submanifold of the manifold $N$. If $p\in M$, then there  exists a coordinate system $\{x_1,\ldots,x_n\}$ on a neighbourhood of $p$ in $N$ such that $x_1(p)=\ldots=x_n(p)=0$ and such that the set
    \[
    U=\{q\in V\tq x_j(q)=0\,\forall\, m+1\leq j\leq n\}
    \]
    gives a local chart of $M$ containing $p$.
\end{proposition}

The sense of this proposition is that one can put $p$ at the center of a coordinate system on $N$ such that $M$ is just a submanifold of $N$ parametrised by the fact that its last $m-n$ components are zero.

\begin{proposition}[\cite{BIBooDUPSooZjcTHL}]       \label{PROPooEWUCooTStAvb}
    If \( S\) is a submanifold of \( M\), the inclusion map \( \iota\colon S \to M\) is an immersion\footnote{Definition \ref{DEFooZKUIooXWVGvh}}.
\end{proposition}

\begin{proposition}     \label{PROPooZACHooCNgLSl}
    A manifold \( S\) is a submanifold of \( M\) if \( S\subset M\) (as sets) and the identity \( \iota\colon S\to M\) is regular\footnote{Definition \ref{DEFooMELXooEkEnwz}.}.
\end{proposition}

\begin{proposition}\label{prop:topo_sub_manif}
    The own topology of a submanifold is finer than the induced one from the manifold.
\index{topology!on submanifold}
\end{proposition}

\begin{proof}
Let $M$ be a manifold of dimension $n$ and $N$ a submanifold\footnote{In the whole proof, we should say ``there exists a sub-neighbourhood such that\ldots``} of dimension $k<n$. We consider $V$, an open subset of $N$ for the induced topology, so $V=N\cap\mO$ for a certain open subset $\mO$ of $M$. The aim is to show that $V$ is an open subset in the topology of $N$.

Let us define $\mP=\varphi^{-1}(\mO)$.  The charts of $N$ are the projection to $\eR^k$ of the ones of $M$. We have to consider $W=\varphi^{-1}(V)$, since $N$ is a submanifold, $\varphi^{-1}(\mO\cap N)=\eR^k\cap\mP$. It is clear that $W=\eR^k\cap\mP$ is an open subset of $\eR^k$ because it is the projection on the $k$ first coordinates of an open subset of $\eR^n$.

The subset $V$ of $N$ will be open in the sense of the own topology of $N$ if $\varphi'{}^{-1}(V\cap\varphi'(\mU'))$ is open in $\eR^k$ where $\varphi'$ is the restriction of $\varphi$ to his $k$ first coordinates: $\varphi'(a)=\varphi(a,0)$ and $\mU'$ is the projection of $\mU$.
\end{proof}


\begin{proposition}\label{prop:subvar_ouvert}
    A submanifold is open if and only if it has the same dimension as the main manifold.
\end{proposition}

\begin{proof}
\subdem{Necessary condition}
We consider some charts $\dpt{\varphi_i}{U_i}{M}$ on some open subsets $U_i$ of $\eR^n$. If $N$ is open in $M$, then this can be written as
\[
  N=\bigcup_iU_i.
\]
If we choose the charts on $M$ in such a manner that $\dpt{\varphi_i}{U_i\cap \eR^k}{N}$ are charts of $N$, we must have $\varphi_i(U_i\cap\eR^k)=\varphi_i(U_i)$. Then it is clear that $k=n$ is necessary.
\subdem{Sufficient condition}
If $N$ has same dimension as $M$, the charts $\dpt{\varphi_i}{U_i}{M}$ are trivially restricted to $N$.
\end{proof}

The following result allow to extend a smooth function defined on a submanifold to an open set of the «larger» manifold. 
\begin{proposition}     \label{PROPooOTZQooIfboXV}
    Let \( N\) be a submanifold of \( M\) and \( f\in  C^{\infty}(N)\). Let \( p\in N\). There exists a neighbourhood \( W\) of \( p\) in \( M\) and a function \( \tilde f\in  C^{\infty}(W)\) such that
    \begin{equation}
        \tilde f(n)=f(n)
    \end{equation}
    for every \( n\in N\).
\end{proposition}

\begin{proof}
    Since \( N\) is a submanifold of \( M\), the definition \ref{DEFooLQHWooMOTgzq} provides a chart \( \varphi\colon U\to M\) around \( p\) such that 
    \begin{equation}
        \varphi^{-1}\big( \varphi(U)\cap N \big)=\{ (x_1,\ldots, x_n,0,\ldots, 0) \}.
    \end{equation}
    From the function \( f\colon N\to \eR\) we consider 
    \begin{equation}
        \begin{aligned}
            f_1\colon \varphi^{-1}\big( \varphi(U)\cap N \big)&\to \eR \\
            f_1&=f\circ\varphi
        \end{aligned}
    \end{equation}
    This is the function \( f\) seen trough the chart. The function \( f_1\) is only defined on the ``\( N\)'' part of the chart, but can be extended as
    \begin{equation}
        \begin{aligned}
            \tilde f_1\colon U&\to \eR \\
            (x_1,\ldots, x_m)&\mapsto f_1(x_1,\ldots, x_n,0,\ldots, 0), 
        \end{aligned}
    \end{equation}
    which is a good definition since \( (x_1,\ldots, x_n,0,\ldots, 0)\) is in \( \varphi^{-1}\big( \varphi(U)\cap N \big)\).

    Finally we write
    \begin{equation}
        \begin{aligned}
            \tilde f\colon \varphi(U)&\to \eR \\
            \tilde f&=\tilde f_1\circ\varphi^{-1}.
        \end{aligned}
    \end{equation}
    This is the extension we are searching for. Indeed it is defined on \( \varphi(U)\) which is an open set in \( M\) which contains \( p\) and if \( q\in N\cap\varphi(U)\) we have \( q=\varphi(x_1,\ldots, x_n,0,\ldots, 0)\) and then
    \begin{subequations}
        \begin{align}
            \tilde f(q)&=(\tilde f_\circ\varphi^{-1})\varphi(x_1,\ldots, x_n,0,\ldots, 0)\\
            &=\tilde f_1(x_1,\ldots, x_n,0,\ldots, 0)\\
            &=f_1(x_1,\ldots, x_n,0,\ldots, 0)\\
            &=(f\circ\varphi)(x_1,\ldots, x_n,0,\ldots, 0)\\
            &=f(q).
        \end{align}
    \end{subequations}
    Thus \( \tilde f=f\) on \( \varphi(U)\cap N\).
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Distribution and Frobenius theorem}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{definition}      \label{DEFooYOMHooZJvsSt}
    Let \( M\) be a manifold. A \( k\) dimensional \defe{distribution}{distribution on a manifold} is the data, for each \( p\in M\) of a \( k\) dimensional vector subspace \( \mD_p\) of \( T_pM\).

    The distribution \( \mD\) is said to be \defe{smooth}{smooth distribution} if for each \( p\in M\), there exists a neighbourhood \( U\) of \( p\) and smooth vector fields\footnote{Definition \ref{DEFooAATTooLhNqDb}.} \( \{ X_i \}_{i=1,\ldots, k}\) in \( U\) such that
    \begin{equation}
        \mD_p=\Span\{ X_i(p) \}.
    \end{equation}

    We denote by \( \Gamma^{\infty}(\mD) \) the set of smooth vector fields with values in \( \mD\). These are the smooth vector fields \( X\) such that \( X_p\in \mD_p\) for every \( p\). More precisely,
    \begin{equation}
        \Gamma^{\infty}(\mD)=\{ X\in \Gamma(TM)\tq X_p\in\mD_p\,\forall p\in M \}.
    \end{equation}
\end{definition}

\begin{definition}
    Let \( \mD\) be a distribution on \( M\). A smoothly immersed\footnote{Definition \ref{DEFooZKUIooXWVGvh}.} submanifold \( N\subset M\) is an \defe{integral manifold}{integral manifold} of \( \mD\) if for every \( p\in N\) we have
    \begin{equation}
        di_p(T_pN)=\mD_p
    \end{equation}
    where \( i\colon N\to M\) is the immersion.

    When an integral submanifold exists, we say that the distribution is \defe{integrable}{integrable distribution}.
\end{definition}

\begin{definition}
    A distribution \( \mD\) is \defe{involutive}{involutive distribution} if we have
    \begin{equation}
        [X,Y]\in \Gamma^{\infty}(\mD)
    \end{equation}
    for every \( X,Y\in \Gamma^{\infty}\).
\end{definition}

\begin{proposition}
    An smooth integrable distribution is involutive.
\end{proposition}

\begin{proof}
    Let \( N\) be a smooth integral manifold for the distribution \( \mD\).  Let \( X,Y\in\Gamma^{\infty}(\mD)\). Since \( T_pN=\mD_p\), for each \( p\in M\), we have \( X,Y\in\Gamma^{\infty}(TN)\). So
    \begin{equation}
        [X,Y]\in\Gamma^{\infty}(TN)=\Gamma^{\infty}(\mD)
    \end{equation}
    and \( \mD\) is involutive.
\end{proof}

\begin{theorem}[Frobenius\cite{BIBooJMRFooTAhhcg}]      \label{THOooVRDYooIusxwW}
    About distributions.
    \begin{enumerate}
        \item
            A distribution is integrable if and only if it is involutive.
        \item
            If \( \mD\) is involutive, for every \( p\in M\), there exists a unique maximal\quext{As far as undestand, here «maximal» means that every integral manifold containing \( p\) is contained in that one. It is used in that sense during the proof the theorem \ref{THOooXALIooGiPVdD}.} connected integral submanifold containing \( p\).
    \end{enumerate}
\end{theorem}


%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Flow and integral curve}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{definition}      \label{DEFooWTNZooTbxJAH}
    Let \( X\) be a vector field on \( M\). Let \( I\subset \eR\) be an interval. An injective \( C^k\) map \( \gamma\colon I\to M\) is an \defe{integral curve}{integral curve} of \( X\) if for every \( a\in I\) we have
    \begin{equation}
        \gamma'(a)=X_{\gamma(a)}.
    \end{equation}
    More explicitly we request that
    \begin{equation}       
        X_{\gamma(a)}(f)=\Dsdd{ (f\circ \gamma) }{t}{a}
    \end{equation}
    for every \( C^k\) functions \( f\) on \( M\).
\end{definition}

\begin{definition}
    A vector field \( X\) is \defe{complete}{complete vector field} if for every \( p\in M\), thee exists an integral curve \( \gamma\colon \eR\to M\) such that \( \gamma(0)=p\).
\end{definition}

The point of a complete vector field is that the integral curves are defined on \( \eR\), not just a neighbourhood of \( 0\).

\begin{proposition}[\cite{MonCerveau}]     \label{PROPooZOOCooExoXOv}
    Let \( X\) be a \( C^k\) vector field on \( M\). For every \( p\in M\), there exists an interval \( I\subset \eR\) such that there exists a unique integral curve \( \gamma\colon \eR\to M\) satisfying \( \gamma(0)=p\).
\end{proposition}

\begin{proof}
    We consider \( p\in M\) and a local chart \( \varphi\colon U\to M\) around \( p\). We know from lemma \ref{LEMooZWFAooDlYaJm} that there exist functions \( v_k\in C^k(M,\eR)\) such that
    \begin{equation}
        X_x(f)=\sum_{k=1}^nv_k(x)\partial_k(f\circ \varphi)\big( \varphi^{-1}(x) \big).
    \end{equation}
    We consider the map \( \tilde \gamma\colon I\to U\) defined by
    \begin{equation}
        \tilde \gamma=\varphi^{-1}\circ \gamma,
    \end{equation}
    and, if \( f\) is a function on \( M\) we define \( \tilde f\colon U\to \eR\) by \( \tilde f=f\circ\varphi\).

    On the one hand,
    \begin{equation}
        \gamma'(a)f=\Dsdd{ (f\circ \varphi\circ\varphi^{-1}\circ\gamma)(t) }{t}{a}=\Dsdd{ (\tilde f\circ\tilde \gamma) }{t}{a}.
    \end{equation}
    On the other hand,
    \begin{equation}
        X_{\gamma(a)}(f)=\sum_k(\partial_k\tilde f)\big( \tilde \gamma(a) \big)\Dsdd{ \tilde \gamma_k(t) }{t}{a}=\sum_k(\partial_k\tilde f)\big( \varphi^{-1}(p) \big)\tilde \gamma'_k(a)=\sum_k(\partial_k\tilde f)\big(a)\tilde \gamma'_k(a)
    \end{equation}
    where \( \tilde \gamma_k'\) is an usual derivative.

    So in order to be an integral curve, we need the equality
    \begin{subequations}        \label{SUBEQSooXSIYooPlVcEI}
        \begin{numcases}{}
            v_k\big( \varphi(a) \big)=\tilde \gamma_k'(a)\\
            \tilde \gamma(0)=\varphi^{-1}(p).
        \end{numcases}
    \end{subequations}
    for every \( a\in I\). The function \( v_k\circ\varphi\colon U\to \eR\) is a \( C^k\) function. By unicity of the primitive, the problem \eqref{SUBEQSooXSIYooPlVcEI} has an unique solution.
\end{proof}

The integral curve given by proposition \ref{PROPooZOOCooExoXOv} is only valid on a neighbourhood given by a local chart.


\begin{proposition}[\cite{MonCerveau}]
    Let \( X\) be a complete \( C^k\) vector field on \( M\). For every \( p\in M\), there is an unique integral curve \( \gamma_p\colon \eR\to M\) such that \( \gamma_p(0)=p\).
\end{proposition}

\begin{proof}
    The existence is not an issue because it is part of the definition of a complete vector field. The trick is the unicity. We already know from proposition \ref{PROPooZOOCooExoXOv} that we have the unicity on each chart. The difficulty is to glue them together.

    Let \( \gamma\colon \eR\to M\) and \( \sigma\colon \eR\to M\) be integral curves satisfying \( \gamma(0)=\sigma(0)=p\).

    Let \( K\) be a compact interval containing \( 0\) in \( \eR\). For each \( a\in K\), the proposition \ref{PROPooZOOCooExoXOv} provides us an open interval \( I_a\) containing \( a\) and such that there exists a unique \( \alpha\colon I_a\to M\) satisfying
    \begin{subequations}        \label{EQSooCEPBooJCuFJL}
        \begin{numcases}{}
            \alpha\text{ is an integral curve of} X\\
            \alpha(a)=\gamma(a).
        \end{numcases}
    \end{subequations}
    Since \( \gamma\) satisfy these requirements, we know that every map satisfying the conditions \eqref{EQSooCEPBooJCuFJL} is equal to \( \gamma\) on \( I_a\).

    The intervals \( I_a\) make a cover of \( K\) which is compact; we extract a finite subcover \( \{ I_i \}_{i=1,\ldots, n}\). Lemma \ref{LEMooNMGWooTfQDeO} allows us to sort these intervals in such a way that \( 0\in I_1\) and
    \begin{equation}
        I_m\cap\bigcup_{i=1}^{m-1}I_i\neq \emptyset
    \end{equation}
    for every \( m=1,\ldots, n\).

    From unicity on \( I_1\) we know that \( \gamma=\sigma\) on \( I_1\) because \( \gamma(0)=\sigma(0)\) and \( 0\in I_1\). We make a induction. We suppose that, for some \( m\) we have \( \gamma=\sigma\) on \( \bigcup_{i=1}^mI_i\). Let
    \begin{equation}
        t_0\in I_{m+1}\cap\bigcup_{i=1}^mI_i.
    \end{equation}
    From the induction hypothesis, we have \( \gamma(t_0)=\sigma(t_0)\) because \( t_0\in \bigcup_{i=1}^mI_i\).

    The curve \( \sigma\) is, on \( I_{m+1}\) an integral curve of \( X\) satisfying \( \sigma(t_0)=\gamma(t_0)\) with \( t_0\in I_{m+1}\). Thus \( \sigma=\gamma\) on \( I_{m+1}\). We deduce that \( \sigma=\gamma\) on \( \bigcup_{i=1}^nI_i\) and in particular \( \sigma=\gamma\) on \( K\).

    Since the whole is valid for every compact \( K\subset \eR\) we conclude that \( \sigma=\gamma\) on \( \eR\).
\end{proof}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Next stuff}
%---------------------------------------------------------------------------------------------------------------------------

    The manifold could, of course have some additional structure which allows to write the differential quotient \eqref{EQooVMGFooFUCNEY}. This is the case when \( M=\eR^n\) or when \( M\) is a matrix group. In these cases, the question of the link between \( \gamma'(0)\) and the ``true'' derivative of \( \gamma\) has to be studied.

    In that case we have the same notational problem with ``$df$''. Let \( f\colon M\to \eR\) where \( M\) is a manifold like \( \eR^n\). The symbol \( df_a\) with \( a\in M\) can be the differential of \( f\) as function \( M\to \eR\), so that \( df_a\) is a linear map from \( \eR^n\) to \( \eR\). But \( df_a\) can also be the linear map \( df_a\colon T_aM\to T_{f(a)}\eR\) where the spaces \( T_aM\) and \( T_{f(a)}\eR\) are made of differential operators.

    This is the point of the section \ref{SECooTSAJooNtjgMD}.

Using the chain rule $d(g\circ f)(a)=dg(f(a))\circ df(a)$ for the differentiation in $\eR^n$, one sees that this equivalence notion doesn't depend on the choice of $\varphi$. In other words, if $\varphi$ and $\tilde{\varphi}$ are two charts for a neighbourhood of $x$, then $(\varphi^{-1} \circ\gamma)'(0)=(\varphi^{-1} \circ\sigma)'(0)$ if and only if $(\tilde{\varphi}^{-1} \circ\gamma)'(0)=(\tilde{\varphi}^{-1} \circ\sigma)'(0)$. The space of all tangent vectors at $x$ is denoted by $T_xM$. There exists a bijection $[\gamma]\leftrightarrow (\varphi^{-1}\circ\gamma)'(0)$ between $T_xM$ and $\eR^n$, so $T_xM$ is endowed with a vector space structure.

If $(\mU,\varphi)$ is a chart around $X(0)$, we can express $Xf$ using only well know objects by defining the function $\tilde f =f\circ\varphi$ and $\tX=\varphi^{-1}\circ X$
\[
  Xf=\Dsdd{ (\tilde f \circ\tX)(t) }{t}{0}=\left.\dsd{\tilde f }{x^{\alpha}}\right|_{x=\tX(0)}\left.\frac{d\tX^{\alpha}}{dt}\right|_{t=0}.
\]
In this sense, we write
\begin{equation}
  X=\frac{d\tX^{\alpha}}{dt} \dsd{}{x^{\alpha}}
\end{equation}
and we say that $\{\partial_1,\ldots,\partial_n\}$ is a basis of $T_xM$. As far as notations are concerned, from now a tangent vector is written as $X=X^{\alpha}\partial_{\alpha}$ where $X^{\alpha}$ is related to the path $\dpt{X}{\eR}{M}$ by $X^{\alpha}=d\tX^{\alpha}/dt$. We will no more mention the chart $\varphi$ and write
\[
  Xf=\Dsdd{f(X(t))}{t}{0}.
\]
Correctness of this short notation is because the equivalence relation is independent of the choice of chart. When we speak about a tangent vector to a given path $X(t)$ without specification, we think about $X'(0)$.

All this construction gives back the notion of tangent vector when $M\subset \eR^m$. In order to see it, think to a surface in $\eR^3$. A tangent vector is precisely given by a derivative of a path: if $\dpt{c}{\eR}{\eR^n}$ is a path in the surface, a tangent vector to this curve is given by
\[
   \lim_{t\to 0}\frac{c(t_0)-c(t_0+t)}{t}
\]
which is a well know limit of a difference in $\eR^n$.

\label{pg:vecto_vecto}Let us precise how does a tangent vector acts on maps others than $\eR$-valued functions. If $V$ is a vector space and $\dpt{f}{M}{V}$, we define
\[
   Xf=(Xf^i)e_i
\]
where $\{e_i\}$ is a basis of $V$ and the functions $\dpt{f^i}{M}{\eR}$, the decomposition of $f$ with respect to this basis. If we consider a map $\dpt{\varphi}{M}{N}$ between two manifolds, the natural definition is $Xf:=dfX$. More precisely, if we consider local coordinates $x^{\alpha}$ and a function $\dpt{f}{M}{\eR}$,
\begin{equation}\label{eq:dvp_phi}
   (d\varphi X)f=\Dsdd{  (f\circ\varphi\circ X)(t) }{t}{0}=\dsd{f}{x^{\alpha}}\dsd{\varphi^{\alpha}}{x\hbeta}\frac{dX\hbeta}{dt}.
\end{equation}
Now we are in a notational trouble: when we write $X=X^{\alpha}\partial_{\alpha}$, the ``$X^{\alpha}$``{} is the derivative of the ``$X^{\alpha}$``{} which appears in the path $X(t)=(X^1(t),\ldots,X^n(t))$ which gives $X$ by $X=X'(0)$. So equation \eqref{eq:dvp_phi} gives
\begin{equation}
   X(\varphi):=d\varphi X=X\hbeta(\partial_{\beta}\varphi^{\alpha})\partial_{\alpha}.
\end{equation}

\subsection{Differential of a map}
%------------------------------------------

Let $\dpt{f}{M_1}{M_2}$ be a differentiable map, $x\in M_1$ and $X\in T_xM_1$, i.e. $\dpt{X}{\eR}{M_1}$ with $X(0)=x$ and $X'(0)=X$. We can consider the path $Y=f\circ X$ in $M_2$. The tangent vector to this path is written $df_x X$.

\begin{proposition}
If $\dpt{f}{M_1}{M_2}$ is a differentiable map between two differentiable manifolds, the map
		\begin{equation}
		\begin{aligned}
			df_x \colon T_xM_1 &\to T_{f(x)}M_2\\
			X'(0)&\mapsto (f\circ X)'(0)
		\end{aligned}
	\end{equation}
is linear.
\end{proposition}

\begin{proof}
We consider local coordinates $\dpt{x}{\eR^n}{M_1}$ and $\dpt{y}{\eR^m}{M_2}$. The maps $\dpt{f}{M_1}{M_2}$ and $\dpt{y^{-1}\circ f\circ x}{\eR^n}{\eR^m}$ will sometimes be denoted by the same symbol $f$. We have $(x^{-1}\circ X)(t)=(x_1(t),\ldots,x_n(t))$ and $(y^{-1}\circ Y)(t)=\big( y_1(x_1(t),\ldots,x_n(t),\ldots, y_m(x_1(t),\ldots,x_n(t)  \big)$, so that
\[
  Y'(0)=\left(   \sum_{i=1}^n \dsd{y_1}{x_i}x_i'(0),\ldots,\sum_{i=1}^n \dsd{y_m}{x_i}x_i'(0)   \right)\in\eR^m
\]
which can be written in a more matricial way under the form
\[
   Y'(0)=\left( \dsd{y_i}{x_j}x'_j(0) \right).
\]
So in the parametrisations $x$ and $y$, the map $df_x$ is given by the matrix $\partial y^i/\partial x_j$ which is well defined from the only given of $f$.
\end{proof}


Let $\dpt{x}{\mU}{M}$ and $\dpt{y}{\mV}{M}$ be two charts systems around $p\in M$. Consider the path $c(t)=x(0,\ldots,t,\ldots 0)$ where the $t$ is at the position $k$. Then, with respect to these coordinates,
\[
  c'(0)f=\Dsdd{ f(c(t))  }{t}{0}=\dsd{f}{x^i}\frac{dc^i}{dt}=\dsd{f}{x^k},
\]
so $c'(0)=\partial/\partial x^k$. Here, implicitly, we wrote $c^i=(x^i)^{-1}\circ c$ where $(x^i)^{-1}$ is the $i$th component of $x^{-1}$ seen as element of $\eR^n$. We can make the same computation with the system $y$. With these abuse of notation,
\begin{equation}
   \dsd{}{x^i}=\sum_j\dsd{y^j}{x^i}\dsd{}{y^j}
\end{equation}
as it can be seen by applying it on any function $\dpt{f}{M}{\eR}$. More precisely if $\dpt{x}{\mU}{M}$ and $\dpt{y}{\mU}{M}$ are two charts (let $\mU$ be the intersection of the domains of $x$ and $y$), let $\dpt{f}{M}{\eR}$ and $\ovf=f\circ x$, $\tilde f =f\circ y$. The action of the vector $\partial_{x^i}$ of the function $f$ is given by
\[
  \partial_{x^i}f=\dsd{\ovf}{x^i}
\]
where the right hand side is a real number that can be computed with usual analysis on $\eR^n$. This real \emph{defines} the left hand side. Now, $\ovf=\tilde f \circ y^{-1}\circ x$, so that
\[
   \dsd{\ovf}{x^i}=\dsd{ (\tilde f \circ y^{-1}\circ x) }{x^i}=\dsd{\tilde f }{y^j}\dsd{y^j}{x^i}
\]
where $\dsd{\tilde f }{y^j}$ is precisely what we write now by $\partial_{y^j}f$ and $\dsd{y^j}{x^i}$ must be understood as the derivative with respect to $x^i$ of the function $\dpt{(y^{-1}\circ x)}{\eR^n}{\eR^n}$.

Let $\dpt{f}{M}{N}$ and $\dpt{g}{N}{\eR}$; the definitions gives
\[
  (df_xX)g=\Dsdd{(g\circ f)(X(t))}{t}{0}
          =\dsd{g}{y^i}\dsd{f^i}{x^{\alpha}}\frac{dX^{\alpha}}{dt}.
\]
This shows that $\dsd{f^i}{x^{\alpha}}\frac{dX^{\alpha}}{dt}$ is $(df_xX)^i$.  But $dX^{\alpha}/dt$ is what we should call $X^{\alpha}$ in the decomposition $X=X^{\alpha}\partial_{\alpha}$ then the matrix of $df$ is given by $\dsd{f^i}{x^{\alpha}}$. So we find back the old notion of differential.

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Examples}
%---------------------------------------------------------------------------------------------------------------------------

\subsubsection{Example: the sphere}\index{sphere}

The sphere $S^n$ is the set
\[
  S^n=\{  (x_1,\ldots, x_{n+1})\in\eR^{n+1}\tq \|x\|=1  \}
\]
for which we consider the following open set in $\eR^n$:
\[
   \mU=\{  (u_1,\ldots,u_n)\in\eR^n\tq\|u\|<1  \}
\]
and the charts $\dpt{\varphi_i}{\mU}{S}$, and $\dpt{\tilde{\varphi}_i}{\mU}{S}$
\begin{subequations}
\begin{align}
   \varphi_i(u_1,\ldots,u_n)&=(u_1,\ldots,u_{i-1}, \sqrt{  1-\|u\|^2  },u_i,\ldots,u_n )\\
   \tilde{\varphi}_i(u_1,\ldots,u_n)&=(u_1,\ldots,u_{i-1}, -\sqrt{  1-\|u\|^2  },u_i,\ldots,u_n ).
\end{align}
\end{subequations}
These map are clearly injective. To see that $\varphi(\mU)\cup\tilde{\varphi}(\mU)=S$, consider $(x_1,\ldots,x_{n+1})\in S$. Then at least one of the $x_i$ is non zero. Let us suppose $x_1\neq 0$, thus $x_1^2=1-(x_2^2+\cdots+x_{n+1}^2)$ and
\begin{equation}\label{eq:xupm}
   x_1=\pm\sqrt{1-(\ldots)}.
\end{equation}
If we put $u_i=x_{i+1}$, we have $x=\varphi(u)$ or $x=\tilde{\varphi}(u)$ following the sign in relation \eqref{eq:xupm}. The fact that $\varphi^{-1}\circ\tilde{\varphi}$ and $\tilde{\varphi}^{-1}\circ\varphi$ are differentiable is a ``first year in analysis exercise``.

\subsubsection{Example: projective space}

On $\eR^{n+1}\setminus\{o\}$, we consider the equivalence relation $v\sim\lambda w$ for all non zero $\lambda\in\eR$, and we put
\[
  \eR P^n=\left(\eR^{n+1}\setminus\{o\}\right)/\sim.
\]
This is the set of all the one dimensional subspaces of $\eR^{n+1}$. This is the real \defe{projective space}{projective!real space} of dimension $n$. We set $\mU=\eR^n$ and
\[
  \varphi_i(u_1,\ldots,u_n)=\Span\{ (u_1,\ldots,u_{i-1},1,u_i,\ldots,u_n) \}.
\]
One can see that this gives a manifold structure to $\eR P^n$. Moreover, the map
		\begin{equation}
		\begin{aligned}
			A \colon S^n &\to \eR P^n\
			v&\mapsto \Span v
		\end{aligned}
	\end{equation}
is differentiable.

Let us show how to identify $\eR\cup\{ \infty \}$ to $\eR P^1$, the set of directions in the plane $\eR^2$. Indeed consider any vertical line $l$ (which does contain the origin). A non vertical vector subspace of $\eR^2$ intersects $l$ in one and only one point, while the vertical vector subspace is associated with the infinite point.

\subsection{Some Leibnitz formulas}

\begin{lemma}[\cite{kobayashi}]
If $M$ and $N$ are two manifolds, we have a canonical isomorphism
\[
     T_{(p,q)}(M\times N)\simeq T_pM+T_qN.
\]
\label{lemLeibnitz}
\end{lemma}

\begin{proof}
A $Z\in T_{(p,q)}(M\times N)$ is the tangent vector to a curve $(x(t),y(y))$ in $M\times N$. We can consider $X\in T_pM$ given by $X=x'(0)$ and $Y\in T_qN$ given by $Y=y'(0)$. The isomorphism is the identification $(X,Y)\simeq Z$. Indeed, let us define $\oX\in T_{(p,q)}(M\times N)$, the tangent vector to the curve $(x(t),q)$, and $\oY\in T_{(p,q)}(M\times N)$, the tangent vector to the curve $(p,y(t))$. Then $Z=\oX+\oY$ because for any $\dpt{f}{M\times N}{\eR}$,
\begin{equation}
 Zf=\dsdd{f(x(t),y(t))}{t}{0}
   =\dsdd{f(x(t),y(0))}{t}{0}+\dsdd{f(x(0),y(t))}{t}{0}
   =\oX f+\oY f.
\end{equation}
\end{proof}

\begin{proposition}[Leibnitz formula] \label{Leibnitz}
Let us consider $M,N,V$, three manifold; a map $\dpt{\varphi}{M\times N}{V}$ and a vector $Z\in T_{(p,q)}(M\times N)$ which corresponds (lemma~\ref{lemLeibnitz}) to $(X,Y)\in T_pM+T_qN$.

If we define $\dpt{\varphi_1}{M}{V}$ and  $\dpt{\varphi_2}{N}{V}$ by $\varphi_1(p')=\varphi(p',q)$ and $\varphi_2(q')=\varphi(p,q')$, we have the \defe{Leibnitz formula}{Leibnitz formula}:
\begin{equation}
    d\varphi(Z)=d\varphi_1(X)+d\varphi_2(Y).
\end{equation}
\end{proposition}
\begin{proof}
 Since $Z=\oX+\oY$, we just have to remark that
\[
                  d\varphi(\oX)=\dsdd{\varphi(x(t),q)}{t}{0}=d\varphi_1(X),
\]
so $d\varphi(Z)=d\varphi(\oX+\oY)=d\varphi_1(X)+d\varphi_2(Y)$.
\end{proof}
One of the most important application of the Leibnitz rule is the corollary~\ref{cor_PrincLeib} on principal bundles.

\subsection{Cotangent bundle}

A form on a vector space $V$ is a linear map $\dpt{\alpha}{V}{\eR}$. The set of all forms on $V$ is denoted by $V^*$ and is called the \defe{dual space}{dual!of a vector space} of $V$. On each point of a manifold, one can consider the tangent bundle which is a vector space. Then one can consider, for each $x\in M$ the dual space $T^*_xM:=(T_xM)^*$ which is called the \defe{cotangent bundle}{cotangent bundle}. A $1$-\defe{differential form}{differential!form} on $M$ is a smooth map $\dpt{\omega}{M}{T^*M}$ such that $\omega_x:=\omega(x)\in T^*_xM$. So, for each $x\in M$, we have a $1$-form $\dpt{\omega_x}{T_xM}{\eR}$.

Here, the smoothness is the fact that for any smooth vector field $X\in\cvec(M)$, the map $x\to\omega_x(X_x)$ is smooth as function on $M$. One often considers vector-valued forms. This is exactly the same, but $\omega_xX_x$ belongs to a certain vector space instead of $\eR$. The set of $V$-valued $1$-forms on $M$ is denoted by $\Omega(M,V)$ \nomenclature{$\Omega(M,V)$}{$V$ valued $1$-forms} and simply $\Omega(M)$ if $V=\eR$
The cotangent space $T^*_pM$ of $M$ at $p$ is the dual space of $T_pM$, i.e. the vector space of all the (real valued) linear\footnote{When we say \emph{a form}, we will always mean \emph{a linear form}.} $1$-forms on $T_pM$. In the coordinate system $\dpt{x}{\mU}{M}$, we naturally use, on $T^*_pM$, the dual basis of the basis $\{\partial/\partial_{x^i},\ldots\partial/\partial_{x^i}\}$ of $T_pM$. This dual basis is denoted by $\{dx_1,\ldots,dx_n\}$, the definition being as usual:
\begin{equation}\label{eq:dx_v}
  dx_i(\partial^j)=\delta^j_i.
\end{equation}
The notation comes from the fact that equation \eqref{eq:dx_v} describes the action of the differential of the projection $\dpt{x_i}{\mU}{\eR}$ on the vector $\partial^j$.

If $(\mU_{\alpha},\varphi_{\alpha})$ is a chart of $M$, then the maps
		\begin{equation}
		\begin{aligned}
			\phi_{\alpha} \colon \mU_{\alpha}\times\eR^n &\to T^*M\
			(x,a)&\mapsto a^idx_i|_x
		\end{aligned}
	\end{equation}
give to $T^*M$ a $2n$ dimensional manifold structure such that the canonical projection $\dpt{\pi}{T^*M}{M}$ is an immersion.

When $V$ is a finite-dimensional vector space, we denote by $V^*$ its dual\footnote{The vector space of all the linear map $V\to \eR$.} and we often use the identifications $V\simeq V^*\simeq T_vV\simeq T_wV\simeq T^*_vV$ where $v$ and $w$ are any elements of $V$. Note however that there are no \emph{canonical} isomorphism between these spaces, unless we consider some basis.

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Immersion, embedding}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}[\cite{BIBooECJTooEfmLsr}]    \label{DEFooZEWNooMVOzWI}
    A smooth map \( f\colon M\to N\) between the manifolds \( M\) and \( N\) is an \defe{immersion}{immersion} if its differential \( df_p\colon T_pM\to T_{f(p)N}\) is injective for every \( p\in M\).
\end{definition}

\begin{definition}[Topological embedding\cite{BIBooTUOOooJZFtGe}]
    Let \( X\), \( Y\) be topological spaces. A map \( f\colon X\to Y\) is a \defe{topological embedding}{topological embedding} if
    \begin{enumerate}
        \item
            \( f\) is continuous
        \item
            \( f\) is injective
        \item
            \( f\colon X\to f(X)\) is an homeomorphism when \( f(X)\) is equipped with the induced topology from \( Y\).
    \end{enumerate}
\end{definition}

\begin{definition}[Embedding\cite{BIBooTUOOooJZFtGe}]       \label{DEFooQLGLooNyXaOV}
    Let \( M\) and \( N\) be smooth manifolds. A smooth function \( f\colon M\to N\) is an \defe{embedding}{embedding} if
    \begin{enumerate}
        \item
            \( f\) is an immersion,
        \item
            \( f\) is a topological embedding.
    \end{enumerate}
\end{definition}

\begin{definition}[Tensor algebra]      \label{DEFooHPQXooETvEyn}
    Let \( V\) be a vector space over \( \eC\). The \defe{tensor algebra}{tensor algebra} of \( V\) is the vector space
    \begin{equation}
        T(V)=\bigoplus_{n\geq 0}\left(\otimes^nV\right)=\eC\oplus V\oplus(V\otimes V)\oplus\ldots
    \end{equation}
\end{definition}


%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Rank theorem}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

We proof a generalization of the rank theorem \ref{ThoGkkffA}.

\begin{definition}
    Let \( M\) and \( N\) be smooth manifolds of dimension \( m\) and \( n\). Let a smooth map \( f\colon M\to N\). The \defe{rank}{rank} of \( f\) at \( p\in M\) is the rank of the linear map \( df_p\colon T_pM\to T_{f(p)N}\).
\end{definition}

\begin{lemma}
    Let a smooth map \( f\colon M\to N\) and \( p\in M\). Let \( \varphi\colon U\to M\) and \( \psi\colon V\to N\) be chats around \( p\) and \( f(p)\). Then
    \begin{equation}
        \rang(df_p)=\rang\big( f_{\varphi^{-1}(p)}(\psi^{-1}\circ f\circ \varphi) \big)
    \end{equation}
    where the rank on the right han side is the usual rank of a map \( \eR^m\to \eR^n\).
\end{lemma}

\begin{proof}
    By proposition \ref{PROPooEGNBooIffJXc} we can compute the rank of a linear map in whatever base. When a basis is chosen in \( \eR^m\) and \( \eR^n\) we know from lemma \ref{LEMooVCSJooEuDZFz} that the matrix of \( df_p\) is the same as the one of \(  f_{\varphi^{-1}(p)}(\psi^{-1}\circ f\circ \varphi) \). Since these two linear maps have the same matrix, they have the same rank.
\end{proof}

\begin{theorem}[Rank theorem\cite{BIBooVYIRooZyqygg}]       \label{THOooSWKVooTJQsXc}
    Let \( M\) and \( N\) be smooth manifolds of dimension \( m\) and \( n\). Let \( f\colon M\to N\) be a smooth map. Let \( p\in M\). We suppose that the rank of \( f\) is equal to \( k\) at every point \( x\) in a neighbourhood of \( p\). 

    There exists charts \( \varphi\colon U\to M\) around \( p\in M\) and \( \psi\colon V\to N\) around \( f(p)\in M\) such that 
    \begin{enumerate}
        \item
            \( \varphi(0)=p\),
        \item
            \( \psi(0)=f(p)\)
        \item
            the function \( f\) is more or less trivialized in the sense that
            \begin{equation}
                (\psi^{-1}\circ f\circ\varphi)(x_1,\ldots, x_m)=(x_1,\ldots, x_k,0,\ldots, 0)
            \end{equation}
            for every \( (x_1,\ldots, x_m)\in U\).
    \end{enumerate}
\end{theorem}

\begin{proof}
    We prove in two parts. Fist we consider the case in which \( M\) and \( N\) are open sets of \( \eR^m\) and \( \eR^n\). Then we will generalize to any smooth manifolds.
    \begin{subproof}
        \item[The case of \( \eR^m\) and \( \eR^n\)]
            Let \( W\) be open in \( \eR^m\), \( W'\) be open in \( \eR^n\). We consider a smooth map \( f\colon W\to W'\) such that \( f(0)=0\) and \( \rang(f)=k\) on \( W\).

            By hypothesis, the rank of \( df_0\) is \( k\), so that is one chooses good bases on \( \eR^m\) and \( \eR^n\) we can suppose that the matrix of \( df_0\) has a upper-left square \( k\times k\) with non-zero determinant. We write \( A\) that square matrix:
            \begin{equation}
                A_{ij}=\frac{ \partial f_i }{ \partial x_j }(0)
            \end{equation}
            with \( i,j\leq k\).

            \begin{subproof}
                \item[On the \( \eR^m\) side]

                    We consider the map
                    \begin{equation}
                        \begin{aligned}
                            \varphi\colon W\subset \eR^m&\to \eR^m \\
                            (x_1,\ldots, x_m)&\mapsto \big( f_1(x_1,\ldots, x_m),\ldots, f_k(x_1,\ldots, x_m),x_{k+1},\ldots, x_m \big). 
                        \end{aligned}
                    \end{equation}
                    We have \( \varphi(0)=0\) because \( f_i(0)=f(0)_i=0\). The matrix of the differential is
                    \begin{equation}
                        d\varphi_0=\begin{pmatrix}
                            A    &   *    \\ 
                            0    &   \mtu_{n-k}    
                        \end{pmatrix}
                    \end{equation}
                    where \( A\) is \( k\times k\) and \( *\) is some \( k\times (n-k)\) matrix. Thus we have \( \det(d\varphi_0)=\det(A)\neq 0\). From the inverse function theorem \ref{ThoXWpzqCn}, the map \( \varphi\) is a local diffeomorphism, more precisely there exists an open set \( W_1\subset W\subset \eR^m\) such that the restriction
                    \begin{equation}
                        \varphi\colon W_1\to W_1
                    \end{equation}
                    is a diffeomorphism. From now on we only consider \( \varphi\) as being that restriction.

                    The vector \( (y_1,\ldots, y_m)\) such that \( \varphi^{-1}(x_1,\ldots, x_m)=(y_1,\ldots, y_m)\) has the property that
                    \begin{equation}
                        \varphi(y_1,\ldots, y_m)=(x_1,\ldots, x_m),
                    \end{equation}
                    which means that\footnote{At this point, it is really important that \( f\) takes its values in \( \eR^n\), not in a general manifold: if \( (y)\) was in a manifold, the expression \( f_i(y)\) would not make sense.}
                    \begin{equation}
                        f_i(y_1,\ldots, y_m)=x_i
                    \end{equation}
                    when \( i=1,\ldots, k\) and
                    \begin{equation}
                        y_l=x_l
                    \end{equation}
                    when \( l=k+1,\ldots, m\).

                \item[On the middle side]

                    Thus we have
                    \begin{subequations}
                        \begin{align}       \label{EQooAQJGooLqlnXJ}
                            (f\circ \varphi^{-1})(x_1,\ldots, x_m)&=f(y_1,\ldots, y_m)\\
                            &=\big( x_1,\ldots, x_k,f_{k+1}(y_1,\ldots, y_m),\ldots, f_n(y_1,\ldots, y_m) \big)\\
                            &=\big( x_1,\ldots, x_k,\tilde f_{k+1}(x),\ldots, \tilde f_n(x)\big)
                        \end{align}
                    \end{subequations}
                    where \( \tilde f_i=f_i\circ \varphi^{-1}\colon W_1\to \eR\) are some smooth functions.

                    For every \( x\in W_1\) we have
                    \begin{equation}        \label{EQooEDJIooLyPslk}
                        f(f\circ \varphi^{-1})_x=\begin{pmatrix}
                            \mtu_{k\times k}    &   0    \\ 
                            *    &   d\tilde f_x    
                        \end{pmatrix}
                    \end{equation}
                    where \( d\tilde f_x\) is the matrix whose elements are \( \left( \frac{ \partial \tilde f_i }{ \partial x_s } \right)\) with \( i=k+1,\ldots, n\) and \( s=k+1,\ldots, m\). This is not a square matrix by the way. We have, by theorem \ref{THOooIHPIooIUyPaf},
                    \begin{equation}
                        d(f\circ\varphi^{-1})_x=df_{\varphi^{-1}(x)}\circ(d\varphi^{-1})_x
                    \end{equation}
                    while \( (d\varphi^{-1})_x\) is invertible. Thus
                    \begin{equation}
                        \rang\big( d(f\circ\varphi^{-1})_x \big)=\rang\big( df_{\varphi^{-1}(x)} \big)=k.
                    \end{equation}
                    So the rank of \( f\circ\varphi^{-1}\) is \( k\) all over \( W_1\). But the image of \( d(f\circ\varphi^{-1})_x\) is spanned by the columns of its differential given by \eqref{EQooEDJIooLyPslk}. The \( k \) columns spanned by the identity matrix are obviously linearly independent; these are thus a basis of the image. Since the vectors in the ``\( d\tilde f_x\)'' part are linearly independent of these \( k\) vectors, they must be vanishing:
                    \begin{equation}
                        \frac{ \partial \tilde f_i }{ \partial x_s }(x)=0
                    \end{equation}
                    for every \( x\in W_1\), \( i=k+1,\ldots, m\) and \( s=k+1,\ldots, n\).

                \item[On the \( \eR^n\) side]

                    We do not know if \( n\geq m\) or \( m\geq n\). If \( n\geq n\), we choose \( V_1\) such that the projection of \( V_1\) on its \( m\) first components is included in \( W_1\). If \( n<m\) we choose \( V_1\) such that the projection of \( W_1\) on its \( n\) first components is included in \( V_1\)\quext{This precision about the choice of \( V_1\) is not done in \cite{BIBooVYIRooZyqygg} and seems strange to me. Am I correct ? By the way, there could be a misprint in the definition of \( T\) in \cite{BIBooVYIRooZyqygg}: \( y\) must have \( n\) components, not \( m\).}.

                    With that choice of \( V_1\) in mind we can remember the functions \( \tilde f_i\colon W_1\to \eR\). If \( y\in V_1\), we define \( \tilde f(y)\) as \( \tilde f(x)\) with \( x\in W_1\) created from \( y\) either by adding zeroes or by projecting on \( \eR^m\). In both cases, the resulting \( y\) belongs to \( V_1\).

                    So now we consider the map
                    \begin{equation}        \label{EQooKEZOooSOTBlo}
                        \begin{aligned}
                            T\colon V_1&\to \eR^n \\
                            (y_1,\ldots, y_n)&\mapsto \big( y_1,\ldots, y_k,y_{k+1}+\tilde f_{k+1}(y),\ldots, y_n+\tilde f_n(y) \big). 
                        \end{aligned}
                    \end{equation}
                    If \( y\in V_1\), the differential is the matrix given by
                    \begin{equation}
                        (dT_y)_{ij}=\frac{ \partial T_i }{ \partial y_j }(y)
                    \end{equation}
                    where
                    \begin{itemize}
                        \item 
                    The upper-left \( k\times k\) corner is \( \mtu_{k\times k}\).
                \item
                    The upper-right \( k\times (n-k)\) corner (non square in general) is given by elements of the form
                    \begin{equation}
                        \frac{ \partial y_i }{ \partial y_{j} }
                    \end{equation}
                    with \( i\leq k\) and \( j>k\). So this is vanishing.
                \item
                    The lower-left (non square in general) corner is made of
                    \begin{equation}
                        \frac{ \partial (y_i+\tilde f_i(y)) }{ \partial y_j }=\frac{ \partial \tilde f_i(y) }{ \partial y_j }
                    \end{equation}
                    with \( i>k\) and \( j\leq k\). The elements in this pars are some numbers.
                \item
                    The lower-right square \( (n-k)\times (n-k)\) corner is made of
                    \begin{equation}
                        \frac{ \partial (y_i+\tilde f_i(y)) }{ \partial y_j }=\delta_{ij}+\frac{ \partial \tilde f_i }{ \partial y_j }
                    \end{equation}
                    with \( i>k\) and \( j\geq k\). For these elements we have \( \frac{ \partial \tilde f_i(y) }{ \partial y_j }=0\) and then the identity matrix.
                    \end{itemize}
                    With all that,
                    \begin{equation}
                        dT_y=\begin{pmatrix}
                            \mtu_{k\times k}    &   0    \\ 
                            *    &   \mtu_{n-k}    
                        \end{pmatrix}.
                    \end{equation}
                    Moreover \( T(0)=0\) because
                    \begin{equation}
                        \tilde f_i(0)=f_i\big( \varphi^{-1}(0) \big)=f_i(0)=0.
                    \end{equation}
                    We deduce that there exist an open set \( V\subset \eR^n\) included in \( V_1\) such that \( T\colon V\to T(V)\) is a diffeomorphism. We restrict \( V\) in such a way that \( T(V)\subset V_1\).

                \item[The final map]

                    Finally we consider the map
                    \begin{equation}
                        T^{-1}\circ f\circ \varphi^{-1}\colon W_1 \to V.
                    \end{equation}
                    If \( (x_1,\ldots, x_m)\in W_1\) from \eqref{EQooAQJGooLqlnXJ} we have
                    \begin{equation}
                        (f\circ \varphi^{-1})(x_1,\ldots, x_m)=\big( x_1,\ldots, x_k,\tilde f_{k+1}(x),\ldots, \tilde f_n(x) \big).
                    \end{equation}
                    Using the definition \eqref{EQooKEZOooSOTBlo} we see that
                    \begin{equation}
                        T(x_1,\ldots, x_k,0,\ldots, 0)=\big( x_1,\ldots, x_k,\tilde f_{k+1}(x),\ldots, \tilde f_n(x) \big)
                    \end{equation}
                    which proves that
                    \begin{equation}
                        T^{-1}\big( x_1,\ldots, ,x_k,\tilde f_{k+1}(x),\ldots, \tilde f_n(x) \big)=(x_1,\ldots, x_k,\,\ldots, 0).
                    \end{equation}
            \end{subproof}

        \item[The general case]

            Now we consider the manifolds \( M\) and \( N\) with the map \( f\colon M\to N\). Let \( p\in M\) and charts \( \varphi_0\colon U_0\to M\), \( \psi_0\colon V_0\to N\) where \( U_0\) is a neighbourhood of \( 0\) in \( \eR^m\) and \( V_0\) a neighbourhood of \( 0\) in \( \eR^n\). We suppose that \( \varphi_0(0)=p\) and \( \psi_0(0)=f(p)\).

            Now we consider the function \( \tilde f=\psi_0^{-1}\circ f\circ \varphi_0\) from \( U_0\) to \( V_0\) and we are left in the previous case.
    \end{subproof}
\end{proof}

If the differential is bijective, then the function is a local diffeomorphism.
\begin{theorem}[local inversion\cite{MonCerveau}]       \label{THOooDWEXooMClWVi}
    Let \( M,N\) be \( C^k\) manifolds. Consider a \( C^k\) map \( f\colon M\to N\). If \( df_p\colon T_pM\to T_{f(p)}N\) is a bijection, the \( f\) is a local \( C^k\)-diffeomorphism.

    More precisely, there exists a neighbourhood \( V_1\) of \( p\) in \( M\) and a neighbourhood \( V_2\) of \( f(p)\) in \( M\) such that \( f\colon V_1\to V_2\) is a \( C^k\)-diffeomorphism.
\end{theorem}

Due to proposition \ref{PropUssGpGenere}, a local diffeomorphism can be often converted into a global diffeomorphism.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Exterior calculus}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%---------------------------------------------------------------------------------------------------------------------------
\subsection{The exterior algebra}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}[Exterior product]
    If $V$ is a vector space, we denote by $\Lambda^kV^*$ the space of all the $k$-form on $V$. We define the \defe{exterior product}{product!exterior} $\dpt{\wedge}{\Lambda^kV^*\times\Lambda^lV^*}{\Lambda^{k+l}V^*}$ by
    \begin{equation}
      (\omega^k\wedge\eta^l)(v_1,\ldots,v_{k+l})
      =\us{k!l!}\sum_{\sigma\in S_{k+l}} (-1)^{\sigma}   \omega(v_{\sigma(1)},\ldots,v_{\sigma(k)})\eta(v_{\sigma(k+1)},v_{\sigma(k+1)})
    \end{equation}
\end{definition}
If $\{e_1,\ldots,e_n\}$ is a basis of $V$, the dual basis $\{\sigma^1,\ldots,\sigma^n\}$ of $V^*$ is defined by $\sigma^i(e_j)=\delta^i_j$.

If $I=\{1\leq i_1\leq\ldots i_k\leq n\}$, we write $\sigma^I=\sigma^{i_1}\wedge\ldots\sigma^{i_k}$ any $k$-form can be decomposed as
\[
  \omega=\sum_{I}\omega_I\sigma^I.
\]
The exterior algebra is provided with the \defe{interior product}{interior!product} denoted by $\iota$. It is defined by\label{pg_DefProdExt}
\begin{equation}
\begin{aligned}
 \iota(v_0)\colon\Lambda^kW&\to \Lambda^{k-1}W \\
(\iota(v_0)\omega)(v_1,\ldots,v_{k-1})& =\omega(v_0,v_1,\ldots,v_{k-1}).
\end{aligned}
\end{equation}

\begin{lemma}
    Let \( \sigma\) be an element of the symmetric group\footnote{Definition~\ref{DEFooJNPIooMuzIXd}.} of the set \( \{ a_1,\ldots, a_n \}\) where the \( a_i\) are integers. Then
    \begin{equation}
        (dx_{a_1}\wedge\ldots \wedge dx_{a_n})(e_{\sigma(a_1)},\ldots, e_{\sigma(a_n)})=(-1)^{\sigma}.
    \end{equation}
\end{lemma}

\begin{proof}
    We make it by induction over \( n\). With \( n=1\) the only permutation is the identity; the claim reduces to \( dx_{a_1}(e_{a_1})=1\). Let us try with \( n=2\). Up to renumbering we have
    \begin{equation}
        (dx_1\wedge dx_2)(e_1,e_2)=1
    \end{equation}
    and
    \begin{equation}
        (dx_1\wedge dx_2)(e_2,e_1)=-1.
    \end{equation}
    We pass to the induction. Let \( \sigma\in S_n\). We have
    \begin{subequations}
        \begin{align}
            (dx_{a_1}\wedge dx_{a_n})(&e_{\sigma(a_1)},\ldots, e_{\sigma(a_n)})=dx_{a_1}\wedge (dx_{a_n})(e_{\sigma(a_1)},\ldots, e_{\sigma(a_n)})\\
            &=\sum_{\phi\in S_n}(-1)^{\phi}\frac{1}{ (n-1)! }dx_{a_1}\big( e_{\phi\sigma(a_1)} \big)(dx_{a_2}\wedge\ldots\wedge dx_{a_n})(e_{\phi\sigma(a_2)},\ldots, e_{\phi\sigma(a_n)})\\
            &=\sum_{\phi\in S_n}(-1)^{\phi}\frac{1}{ (n-1)! }\delta_{a_1,\phi\sigma(a_1)}(-1)^{\phi\sigma}\\
            &=\sum_{\phi\in S_n}\delta_{a_1,\phi\sigma(a_1)}(-1)^{\sigma}\frac{1}{ (n-1)! }
        \end{align}
    \end{subequations}
    where we used the fact that the sign of a permutation provides a morphism between \( S_n\) and \( \{ -1,1 \}\) (proposition~\ref{ProphIuJrC}\ref{ITEMooBQKUooFTkvSu}). In the sum over \( S_n\), only the \( \phi\) that make \( \sigma(a_1)\to a_1\) remain; there are \( | S_{n-1} |=(n-1)!\) such elements. Thus the whole evaluates to \( (-1)^{\sigma}\).
\end{proof}

\begin{lemma}[\cite{MonCerveau}]    \label{LEMooICRXooFKPCRd}
    Let \( \tau_i\colon \eR^n\to \eR^{n-1}\) defined by
    \begin{equation}
        \tau_i(v)_k=\begin{cases}
            v_k    &   \text{if } k<i\\
            v_{k+1}    &    \text{if } k\geq i\text{.}
        \end{cases}
    \end{equation}
    Then we have
    \begin{equation}
        (dx_1\wedge\ldots\wedge\widehat{dx_i}\wedge\ldots\wedge dx_n)(v_1,\ldots, \widehat{v_i},\ldots, v_n)=
        \det\Big(  \tau_i(v_1),\ldots, \widehat{\tau_i(v_i)},\ldots, \tau_i(v_n)  \Big)
    \end{equation}
    where the hat denotes a non present term.
\end{lemma}

\begin{proof}
    We extend \( \tau_i\) to the dual : \( \tau_i\colon(\eR^n)^*  \to (\eR^{n-1})^*\) is defined by
    \begin{equation}
        \tau_i(dx_k)=\begin{cases}
            dy_k    &   \text{if } k<i\\
            dy_{k-1}    &    \text{if } k>i
        \end{cases}
    \end{equation}
    (not defined on \( dx_i\)). It is easy to check that, if \( k\neq i\),
    \begin{equation}
        \tau_i(dx_k)\tau_i(v)=dx_k(v).
    \end{equation}
    The value of  $(dx_1\wedge\ldots\wedge\widehat{dx_i}\wedge\ldots\wedge dx_n)(v_1,\ldots, \widehat{v_i},\ldots, v_n)$ is a polynomial in the variables \( dx_k(v_l)\) (with \( k\neq l\)). Since \( dx_k(v_l)=\tau\i(dx_k)\big( \tau_iv_l \big)\), the same polynomial will give the value of
    \begin{equation}
        (\tau_idx_1\wedge\ldots\wedge \widehat{\tau_idx_i}\wedge\ldots\wedge \tau_idx_n  )(\tau_i v_1,\ldots, \widehat{\tau_iv_i},\ldots, \tau_iv_n).
    \end{equation}
    Thus we have
    \begin{subequations}
        \begin{align}
            (dx_1\wedge\ldots\wedge\widehat{dx_i}&\wedge\ldots\wedge dx_n)(v_1,\ldots, \widehat{v_i},\ldots, v_n)\\
            &=(\tau_idx_1\wedge\ldots\wedge \widehat{\tau_idx_i}\wedge\ldots\wedge \tau_idx_n  )(\tau_i v_1,\ldots, \widehat{\tau_iv_i},\ldots, \tau_iv_n)\\
            &=(dy_1\wedge\ldots\wedge dy_{n-1})(\tau_iv_1,\ldots,\widehat{\tau_iv_i},\ldots, \tau_iv_n) \label{SUBEQooQGSKooSgfxJh}\\
            &=\det\big( \tau_iv_1,\ldots, \widehat{\tau_i v_i},\ldots, \tau_iv_n \big)
        \end{align}
    \end{subequations}
    The last equality is because \eqref{SUBEQooQGSKooSgfxJh} is is a \( (n-1)\)-form applied to \( n-1\) vectors in \( \eR^{n-1}\) and so is the determinant.
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Differential of \texorpdfstring{$k$}{k}-forms}
%---------------------------------------------------------------------------------------------------------------------------

The differential of a $k$-form is defined by the following theorem.

\begin{theorem}
Let $M$ be a differentiable manifold. Then for each $k\in \eN$, there exists an unique map
\[
  \dpt{d}{\Omega^k(M)}{\Omega^{k+1}(M)}
\]
such that

\begin{enumerate}
\item $d$ is linear,
\item for $k=0$, we find back the $\dpt{d}{\Cinf(M)}{\Omega^1(M)}$ previously defined,
\item if $f$ is a function and $\omega^k$ a $k$-form, then
\begin{equation}
d(f\omega^k)=df\wedge\omega^k+fd\omega^k,
\end{equation}


\item $d(\omega^k\wedge\eta^l)=d\omega^k\wedge\eta^l+(-1)^k\omega^k\wedge d\eta^l$,
\item $d\circ d=0$.
\end{enumerate}
\end{theorem}

An explicit expression for $d\omega^k$ is actually given by
\begin{equation}
   d\omega^k=\sum d\omega_I\wedge dx^I
\end{equation}
if $\omega^k=\sum\omega_I dx^I$.
An useful other way to write it is the following. If $\omega$ is a $k$-form and $X_1,\ldots,X_{p+1}$ some vector fields,
\begin{equation}\label{eq:formule_domega}
\begin{split}
  (k+1)d\omega(X_1,\ldots,X_{p+1})&=\sum_{i=1}^{p+1}(-1)^{i+1}X_i\omega(X_1,\ldots\hat{X}_i,\ldots,X_{p+1})\\
                                  &\quad+\sum_{i<j}(-1)^{i+j}\omega([X_i,X_j],X_1,\ldots,\hX_i,\hX_j,\ldots,X_{p+1}).
\end{split}
\end{equation}
Let us show it with $p=1$. Let $\omega=\omega_i dx^i$ and compute $d\omega(X,Y)=\partial_i\omega_j(dx^i\wedge dx^j)(X,Y)$. For this, we have to keep in mind that the $\partial_i$ acts only on $\omega_j$ while, in equation \eqref{eq:formule_domega}, a term $X\omega(Y)$ means --pointwise-- the action of $X$ on the function $\dpt{\omega(Y)}{M}{\eR}$. So we have to use Leibnitz formula:
\[
  (\partial_i\omega_j)X^iY^j=(X\omega_j)Y^j
                            =X(\omega_j Y^j)-\omega_j XY^j.
\]
On the other hand, we know that $[X,Y]^i=XY^i-YX^i$, so
\begin{equation}
   d\omega(X,Y)=X\omega(Y)-Y\omega(X)-\omega([X,Y]).
\end{equation}

\subsubsection{Hodge dual operator}
%/////////////////////////////
Let us take a manifold $M$ endowed with a metric $g$.  We can define a map $\dpt{r}{T^*_xM}{T_xM}$ by, for $\alpha\in T^*_xM$,
\[
   \scal{r(\alpha)}{v}=\alpha(v).
\]
for all $v\in T_xM$, where $\scal{\cdot}{\cdot}$ stands for the product given by the metric $g$. If we have $\alpha,\beta\in T^*_xM$, we can define
\[
   \scal{\alpha}{\beta}=\scal{r(\alpha)}{r(\beta)}.
\]
With this, we define an inner product on $\Lambda^p(T^*_xM)$:
\[
   \scal{\alpha_1\wedge\ldots\alpha_p}{\beta_1\wedge\ldots\beta_p}=\det_{ij}\scal{\alpha_i}{\beta_j}.
\]

\begin{definition}      \label{DEFooUOJQooSzKjNR}
    The \defe{Hodge operator}{Hodge operator} is $\dpt{\hodge}{\Lambda^p(T^*_xM)}{\Lambda^{n-p}(T^*_xM)}$ such that for any $\phi\in\Lambda^p(T^*_xM)$,
    \begin{equation}
       \phi\wedge(\hodge\psi)=\scal{\phi}{\psi}\Omega=\langle \phi,\psi \rangle\sqrt{|\det(g)|}dx^1\wedge\ldots\wedge dx^n.
    \end{equation}
\end{definition}

\begin{example} \label{EXooCIYIooFPMLMU}
    We consider \( \eR^n\) with the euclidian metric. If \( \sigma=dx_j\), then we expect \( \hodge\sigma\) to be \( sdx_1\wedge\ldots\wedge \widehat{dx_j}\wedge\ldots\wedge dx_n\) for a certain factor \( s\) to be fixed (something like \( (-1)^j\)).

    For every \( 1\)-form \( \phi\) we need \( \phi\wedge(\hodge \sigma)=\langle \phi, \sigma\rangle dx_1\wedge\ldots\wedge dx_n\). A basis of \( \Wedge^1(TM)\) is \( \{ dx_k \}_{k=1,\ldots, n}\), so we test on \( dx_k\).

    First we have
    \begin{equation}
        \langle dx_k, dx_j\rangle =\langle e_k, e_j\rangle =\delta_{kj}.
    \end{equation}
    Then
    \begin{equation}
        s\,dx_k\wedge dx_1\wedge\ldots\wedge \widehat{dx_j}\wedge\ldots\wedge dx_n=s\delta_{kj}(-1)^{j+1}dx_1\wedge\ldots\wedge dx_n.
    \end{equation}
    Thus we need \( s=(-1)^{j+1}\) and we have
    \begin{equation}
        \hodge dx_j=(-1)^{j+1}dx_1\wedge\ldots\wedge \widehat{dx_j}\wedge\ldots\wedge dx_n.
    \end{equation}
\end{example}

\subsubsection{Volume form and orientation}
%//////////////////////////////////////////

Let $M$ be a $n$ dimensional smooth manifold. A \defe{volume form}{volume!form} on $M$ is a nowhere vanishing $n$-form and the manifold itself is said to be \defe{orientable}{orientable manifold} if such a volume form exists. Two volume forms $\mu_1$ and $\mu_2$ are describe the same orientation if there exists a function $f>0$ such that\footnote{Recall that the space of $n$-forms is one-dimensional.} $\mu_1=f\mu_2$.

\begin{proposition}
There exists only two orientations on a connected orientable manifold.
\end{proposition}
\begin{probleme}
    Check if the statement of that proposition is correct. Find a reference.
\end{probleme}

One says that the \emph{ordered} basis $(v_1,\cdots,v_n)$ of $T_xM$ is \defe{positively oriented}{positive!orientation} with respect to the volume form $\mu$ is $\mu_x(v_1,\cdots,v_n)>0$.

\subsection{Musical isomorphism}\label{subsec_musique}\index{musical isomorphism}
%---------------------------------

In some literature, we find the symbols $v^{\flat}$ and $\alpha^{\sharp}$. What does it mean ? For $X\in\cvec(M)$ and $\omega\in\Omega^2(M)$, the \defe{flat}{flat} operation $v^{\flat}\in\Omega^1(M)$ is simply defined by the inner product:
\begin{equation}        \label{EQooBTWXooTqoNxa}
  v^{\flat}=i(v)\omega
\end{equation}
 In the same way, we define the \defe{sharp}{sharp} operation by taking a $1$-form $\alpha$ and defining $\alpha^{\sharp}$ by
\begin{equation}
   i(\alpha^{\sharp})\omega=\alpha.
\end{equation}
An immediate property is, for all $v\in\cvec(M)$, $v^{\flat\sharp}=v$, and for all $\alpha\in\Omega^1(M)$, $\alpha^{\sharp\flat}=\omega$.

\subsection{Pull-back and push-forward}

\begin{normaltext}
Let $\dpt{\varphi}{M}{N}$ be a smooth map, $\alpha$ a $k$-form on $N$, and $Y$ a vector field on $N$. Consider the map $\dpt{d\varphi}{T_xM}{T_{\varphi(x)}M}$. The aim is to extend it to a map from the tensor algebra\footnote{Definition \ref{DEFooHPQXooETvEyn}} of ${T_xM}$ to the one of $T_{\varphi(x)}M$.
\end{normaltext}

The \defe{pull-back}{pull-back!of a $k$-form} of $\varphi$ on a $k$-form $\alpha$ is the map
\[
 \dpt{\varphi^*}{\Omega^k(N)}{\Omega^k(M)}
\]
 defined by
\begin{equation}\label{306e1}
 (\varphi^*\alpha)_m(v_1,\ldots,v_k)
 =\alpha_{\varphi(m)}(d\varphi_mv_1,\ldots,d\varphi_mv_k)
\end{equation}
for all $m\in M$ and $v_i\in\cvec(M)$.

Note the particular case $k=0$. In this case, we take --instead of $\alpha$-- a function $\dpt{f}{N}{\eR}$ and the definition \eqref{306e1} gives $\dpt{\varphi^*f}{M}{\eR}$ by
\[
     \varphi^*f=f\circ\varphi.
\]

The \defe{push-forward}{push-forward!of a $k$-form} of $\varphi$ on a $k$-form is the map
\[
 \dpt{\varphi_*}{\Omega^k(M)}{\Omega^k(N)}
\]
defined by $\varphi_*=(\varphi^{-1})^*$. For $v\in T_nN$, we explicitly have:
\[
                   (\varphi_*\alpha)_n(v)=\alpha_{\varphi^{-1}(n)}(d\varphi_n^{-1} v).
\]

Let now $\dpt{\varphi}{M}{N}$ be a diffeomorphism. The \defe{pull-back}{pull-back!of a vector field} of $\varphi$ on a vector field is the map
\[
           \dpt{\varphi^*}{\cvec(N)}{\cvec(M)}
\]
defined by
\[
              (\varphi^*Y)(m)=[(d\varphi^{-1})_m\circ Y\circ\varphi](m),
\]
or
\[
 (\varphi^*Y)_{\varphi^{-1}(n)}=(d\varphi^{-1})_nY_n,
\]
for all $n\in N$ and $m\in M$. Notice that \[\dpt{(d\varphi^{-1})_n}{T_nN}{T_{\varphi^{-1}(n)}M},\] and that  $\varphi^{-1}(n)$ is well defined because $\varphi$ is an homeomorphism.

The \defe{push-forward}{push-forward!of a vector field} is, as before, defined by $\varphi_*=(\varphi^{-1})^*$. In order to show how to manipulate these notations, let us prove the following equation:
\[
   f_{*\xi}=(df)_{\xi}.
\]
For $\dpt{\varphi}{M}{N}$ and $Y$ in $\cvec(N)$, we just defined $\dpt{\varphi^*}{\cvec(N)}{\cvec(M)}$, by
\begin{eqnarray}
 \label{2112r1}(\varphi^*Y)_{\varphi^{-1}(n)}=(d\varphi^{-1})_nY_n.
\end{eqnarray}
Take $\dpt{f}{M}{N}$; we want to compute $f_*=(f^{-1})^*$ with $\dpt{(f^{-1})^*}{\cvec(M)}{\cvec(N)}$. Replacing the ``$^{-1}$``\ on the right places, the definition \eqref{2112r1} gives us
\[
 \Big[(f^{-1})^*X\Big]_{f(m)}=(df)_mX_m,
\]
if $X\in\cvec(M)$, and $m\in M$.

We can rewrite it without  any indices: the coherence of the spaces automatically impose the indices: $(f^{-1})^*X=(df)X$. It can also be rewritten as $(f^{-1})^*=df$, and thus $f_*=df$. From there to $f_{* \xi}=(df)_{\xi}$, it is straightforward.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Partition of unity}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


\begin{definition}[\cite{ooQCDSooCpqDvB}]       \label{DEFooKFXLooFRLaBG}
    Let \( X\) be a topological space. A \defe{partition of unity}{partition!of unity} of \( X\) is a family of continuous functions \( \{ \psi_j \}_{j\in J}\) such that
    \begin{enumerate}
        \item
            \( \psi_j\colon X\to \mathopen[ 0 , 1 \mathclose]\);
        \item
            for every \( x\in X\) there exists a neighbourhood of \( x\) in \( X\) in which only a finite number of the \( \psi_j\)'s is non zero;
        \item
            for every \( x\in X\) we have
            \begin{equation}
                \sum_{j\in J}\psi_j(x)=1.
            \end{equation}
    \end{enumerate}
\end{definition}

\begin{definition}[\cite{ooQCDSooCpqDvB}]
    Let \( X\) be a topological space and \( \{ U_i \}_{i\in I}\) be a locally finite cover of \( X\). A partition of unity is \defe{subordinate}{partition!of unity!subordinate} to that cover if it is indexed by \( I\) (\( J=I\) in the definition~\ref{DEFooKFXLooFRLaBG}) and such that \( \supp(\psi_i)\subset U_i\) for every \( i\in I\).
\end{definition}

\begin{theorem}[\cite{ooQCDSooCpqDvB}]      \label{THOooPCHDooITWKpC}
    Let \( \Omega\) be an open set in \( \eR^d\) and \( \{ U_i \}_{i\in I}\) be an open cover of \( \Omega\). There exists
    \begin{enumerate}
        \item
            a \(  C^{\infty}\) partition of unity \( \{ \psi_j \}_{j\in J}\) such that \( \supp(\psi_j)\) is compact in one of the \( U_i\);
        \item       \label{ITEMooFGMJooQPLqGY}
            a \(  C^{\infty}\) partition of unity \( \{ \alpha_i \}_{i\in I}\) subordinated to the cover, such that for every compact \( K\) only a finite number of these \( \psi_i\)'s is non zero.
    \end{enumerate}
\end{theorem}

\begin{remark}
    This theorem does not furnish a smooth compactly supported partition of unity subordinated to the given cover. Either you choose the partition to be compactly supported, either you choose them subordinated to the cover.
\end{remark}

\begin{corollary}  \label{CORooMSWPooCxvuhm}
    If \( \Omega\) is bounded and \( \{U_i \}_{i\in I}\) is an open cover of \( \Omega\), there exists a partition of unity subordinated to \( \{ U_i \}_{i\in I}\) such that each \( \psi_i\) belongs to \( \swD(U_i)\).
\end{corollary}

\begin{proof}
    If \( \Omega\) is bounded in \( \eR^d\) we can consider \( U'_i=U_i\cap \Omega\) and use the point~\ref{ITEMooFGMJooQPLqGY} of theorem~\ref{THOooPCHDooITWKpC} for the cover \( \{ U'_i \}_{i\in I}\). So we have a partition of unity subordinated to that cover with supports in the \( U'_i\)'s. Since the support is closed and the \( U_i\)'s are bounded, the supports are compact. The functions of this partition of unity are also subordinated to the original \( U_i\)'s.
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Integration of a differential form}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Open set in \( \eR^n\)}
%---------------------------------------------------------------------------------------------------------------------------

Let \( U\) be an open set of \( \eR^n\). A differential form of degree \( n\) over \( U\) can always be written under the form
\begin{equation}
    \omega_x=f(x)dx_1\wedge\ldots\wedge dx_n;
\end{equation}
this is proposition~\ref{ProprbjihK}.

\begin{definition}      \label{DEFooEYRFooRQTmRF}
    The integral of \( \omega\) on \( U\) is
    \begin{equation}
        \int_{U}f\,dx_1\wedge\ldots\wedge dx_n=\int_Uf
    \end{equation}
    The second integral is the integral of a function on \( \eR^n\), that is definition~\ref{DefTVOooleEst} where the measure is the Lebesgue measure on \( \eR^n\).
\end{definition}

\begin{lemma}[Change of variable]       \label{LEMooNCYSooXtnCKq}
    Let \( f\colon V\to U\) be a diffeomorphism of open sets in \( \eR^n\) and \( \omega\) be a \( n\)-form on \( U\). Then we have
    \begin{equation}
        \int_U\omega=\int_{f^{-1}(U)}f^*\omega
    \end{equation}
    if \( \det(f)>0\). A sign change if \( \det(df)<0\).
\end{lemma}

\begin{proof}
    Let, for \( y\in U\), write the form \( \omega\) as \( \omega_y=h(y)dy_1\wedge\ldots\wedge dy_n\). Taking \( v_i\in \Gamma(TV)\) we have
    \begin{subequations}
        \begin{align}
            (f^*\omega)_x(v_1,\ldots, v_n)&=\omega_{f(x)}\big( df_xv_1,\ldots, df_xv_n \big)\\
            &=h\big( f(x) \big)\det\begin{pmatrix}
                df_xv_1    \\
                \vdots    \\
                df_xv_n
            \end{pmatrix}\\
            &=(h\circ f)(x)\det(df_x)\det\begin{pmatrix}
                v_1    \\
                \vdots    \\
                v_n
            \end{pmatrix}\\
            &=(h\circ f)(x)\det(df_x)(dx_1\wedge\ldots\wedge dx_n)(v_1,\ldots, v_n).
        \end{align}
    \end{subequations}
    Thus
    \begin{equation}
        f^*\omega= (h\circ f)\det(df)dx_1\wedge\ldots\wedge dx_n
    \end{equation}
    Using the usual change of variable theorem~\ref{THOooUMIWooZUtUSg}\ref{ITEMooAJGDooGHKnvj} (and taking a sign if \( \det(df)<0\) because there is an absolute value in around the jacobian in \eqref{EQooLYAWooTArAZR}) :
    \begin{equation}
        \int_{f^{-1}(U)}f^*\omega=\int_V(h\circ f)\det(df)=\int_{f(V)}h=\int_Uh=\int_U\omega.
    \end{equation}
\end{proof}

That is for integrating a differential form on an open set of \( \eR^n\). In order to integrate on a manifold we ``simply'' use a pull-back with a chart system. There will be three complications
\begin{itemize}
    \item If an atlas is made from more than one chart, what about the intersections ?
    \item Independence with respect to the choice of the chart.
    \item Integrating a vector field (that is not obviously a \( n\)-form).
\end{itemize}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{One chart on a manifold}
%---------------------------------------------------------------------------------------------------------------------------

We suppose \( (M,g)\) to be a \( n\)-dimensional Riemannian manifold and \( S\) to be a \( (n-1)\)-dimensional submanifold. We suppose that both are inside only one chart
\begin{equation}
    \phi\colon U\subset \eR^n\to M
\end{equation}
and
\begin{equation}
    \varphi\colon A\subset \eR^{n-1}\to S.
\end{equation}
We also consider a differential form \( \omega\in \Wedge^n(T^*M)\) and \( \sigma\in\Wedge^{n-1}(T^*M)\). These are respectively \( n\) and \( n-1\) differential forms on \( M\).  We also consider \( v\), a vector field on \( M\) and \( \tau\), a \( 1\)-form on \(M\).

Let us see what is possible to integrate.

\begin{definition}[\cite{ooMLEZooCKxedX}]       \label{DEFooPDRCooPiBklC}
    Let \( \omega\) be a \( n\)-form defined on \( \phi(U)\) (vanishing everywhere else). Its integral is :
    \begin{equation}
        \int_{\phi(U)}\omega=\int_U\phi^*\omega.
    \end{equation}
    The last integral is an integral of type \( \int_{U}F(x_1,\ldots, x_n)dx_1\wedge\ldots \wedge dx_n\) on an open set in \( \eR^n\). That is definition~\ref{DEFooEYRFooRQTmRF}.
\end{definition}

This definition is nothing if it depend on the parametrisation. The following proposition show slightly more than the independence.
\begin{proposition}[\cite{MonCerveau,ooBTXRooUEBLMV}]       \label{PROPooNJCLooMqeeeX}
    Let be the charts \( \phi\colon U\to M\) and \( \psi\colon V\to N\) and a map \( f\colon M\to N\). The whole is supposed to be minimal :
    \begin{equation}
        f\big( \phi(U) \big)=\psi(V).
    \end{equation}
    Then we have the ``change of variable'' formula :
    \begin{equation}
        \int_{\phi(U)}\omega=\int_{\psi(V)}(f^{-1})^*\omega.
    \end{equation}
\end{proposition}

\begin{proof}
    By definition \( \int_{\phi(U)}\omega=\int_U\phi^*\omega\) and we have the diffeomorphism
    \begin{equation}
        \phi^{-1}\circ f^{-1}\circ \psi\colon V\to U,
    \end{equation}
    so that we can use the result of lemma~\ref{LEMooNCYSooXtnCKq} :
    \begin{equation}
        \int_U\phi^*\omega=\int_{(\phi^{-1}\circ f^{-1}\circ \psi)^{-1}(U)}  (\phi^{-1}\circ f^{-1}\circ \psi)^*\phi^*\omega=\int_{(\psi^{-1}\circ f\circ \phi )U}\psi^*(f^{-1})^*\omega=\int_{\psi^{-1}(N)}\psi^*(f^{-1})^*\omega.
    \end{equation}
    The last integral is the definition of an integral on \( N\) :
    \begin{equation}
        \int_{\psi^{-1}(N)}\psi^*(f^{-1})^*\omega=\int_N(f^{-1})^*\omega.
    \end{equation}
\end{proof}

Here is the lemma that shows the independence of definition~\ref{DEFooPDRCooPiBklC} with respect to the change of chart system.
\begin{lemma}
    Let \( \varphi\colon V\to M\) be a chart such that \( \varphi(V)\cap \varphi(U)=N\) is not empty. We define \( U'=\phi^{-1}(N)\) and \( V'=\varphi^{-1}(N)\). Then
    \begin{equation}        \label{EQooLSZMooPcyMWN}
        \int_{\phi(U')}\omega=\int_{\varphi(V')}\omega.
    \end{equation}
\end{lemma}
This lemma allows us to write \( \int_N\omega\) the common value of both sides of \eqref{EQooLSZMooPcyMWN}.

\begin{proof}
    Taking \( f=\id\) and two charts for the same open set in \( M\) in proposition~\ref{PROPooNJCLooMqeeeX} shows the result.
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{On manifold that require a finite atlas}
%---------------------------------------------------------------------------------------------------------------------------

We restrict ourself to manifolds that accept a finite atlas.

\begin{definition}[\cite{ooBTXRooUEBLMV}]      \label{DEFooITDTooWwrPPr}
    If \( \omega\) is a \( n\)-form on \( M\) and if \( \{ f_{\alpha} \} \) is a partition of unity\footnote{See theorem~\ref{THOooPCHDooITWKpC}.} subordinate to the finite atlas \( \{ U_{\alpha} \}\) then
    \begin{equation}
        \int_M\omega=\sum_{\alpha}\int_{\phi_{\alpha}(U_{\alpha})}f_{\alpha}\omega.
    \end{equation}
\end{definition}

We show that this definition does not depend on the choice of the partition of unity.
\begin{lemma}[\cite{MonCerveau,ooBTXRooUEBLMV}] \label{LEMooCMIZooHhHaHV}
    The definition~\ref{DEFooITDTooWwrPPr} is independent of the choice of atlas and partition of unity.
\end{lemma}

\begin{proof}
    Let \(  \{ U_{\alpha},\phi_{\alpha},f_{\alpha} \}_{\alpha\in A}  \) and \( \{ V_i,\varphi_i,g_i \}_{i\in I}\) be two choices of atlas, charts and subordinate partition of unity. We have to show that
    \begin{equation}        \label{EQooPVQZooHvbioJ}
        \sum_{\alpha\in A}\int_{\phi_{\alpha}(U_{\alpha})}f_{\alpha}\omega=\sum_{i\in I}\int_{\varphi_i(V_i)}g_i\omega.
    \end{equation}
    Since \( \{ g_i \}\) is a partition of unity,
    \begin{equation}
            \spadesuit=\sum_{\alpha}\int_{\phi_{\alpha}(U_{\alpha})}f_{\alpha}\omega=\sum_{\alpha}\int_{\phi_{\alpha}(U_{\alpha})}\sum_ig_if_{\alpha}\omega.
    \end{equation}
    Since the atlas are finite, the sums are finite and can be permuted with the integral. Moreover the function \( g_if_{\alpha}\) is nonzero only on \( \phi_{\alpha}(U_{\alpha})\cap\varphi_i(V_i)\) so that the integral can be taken on \( \phi_{\alpha}(U_{\alpha})\), \( \phi_{\alpha}(U_{\alpha})\cap\varphi_i(V_i)\) or \( \varphi_i(V_i)\). We have
    \begin{subequations}
        \begin{align}
            \spadesuit=\sum_i\sum_{\alpha}\int_{\phi_{\alpha(U_{\alpha})}}g_if_{\alpha}\omega&=  \sum_i\sum_{\alpha}\int_{\phi_{\alpha(U_{\alpha})}\cap \varphi_i(V_i)}g_if_{\alpha}\omega\\
            &=  \sum_i\sum_{\alpha}\int_{\varphi_i(V_i)}g_if_{\alpha}\omega\\
            &= \sum_i\int_{\varphi_i(V_i)}g_i\sum_{\alpha}f_{\alpha}\omega\\
            &=\sum_i\int_{\varphi_i(V_i)}g_i\omega.
        \end{align}
    \end{subequations}
\end{proof}
The common values of both sides of \eqref{EQooPVQZooHvbioJ} is denoted by \( \int_M\omega\).

The following is not really a definition, but a particular case of~\ref{DEFooPDRCooPiBklC}. The integral of a \( n-1\)-form on a \( (n-1)\)-submanifold is
\begin{equation}        \label{EQooYPOGooRYOXQe}
    \int_S\sigma=\int_A\varphi^*\sigma.
\end{equation}
Once again the last integral is an integral of a \( n-1\)-form on an open set in \( \eR^{n-1}\).

\begin{definition}[\cite{ooMLEZooCKxedX}]       \label{DEFooAXFXooWiMLKP}
    The integral of a \( 1\)-form on a \( n-1\) dimensional submanifold is :
    \begin{equation}
        \int_S\tau=\int_S\hodge\tau
    \end{equation}
    where \( \hodge\) is the Hodge dual defined by~\ref{DEFooUOJQooSzKjNR}.
\end{definition}
The last integral is the integral of a \( (n-1)\)-form on a \( (n-1)\)-submanifold, given by \eqref{EQooYPOGooRYOXQe}.

\begin{definition}      \label{DEFooAXZGooJairMQ}
    The integral of a vector field on a \( (n-1)\)-submanifold is :
    \begin{equation}
        \int_Sv=\int_Sv^{\flat}
    \end{equation}
    where \( v^{\flat}\) is the \( 1\)-form defined by the musical isomorphism \eqref{EQooBTWXooTqoNxa}.
\end{definition}

The following proposition provides a much more explicit formula for the integral of a vector field.

\begin{proposition}     \label{PROPooETLZooAVsrwy}
    Let \( \varphi\colon A\subset \eR^{n-1}\to \eR^n\) be an hypersurface and \( X\) be a vector field in \( \eR^n\). Then
    \begin{subequations}
        \begin{align}
            \int_SX&=\int_A\det\big( X,\frac{ \partial \varphi }{ \partial y_1 },\ldots, \frac{ \partial \varphi }{ \partial y_{n-1} } \big)  \label{SUBEQooWJSPooImJjQN}\\
            &=\int_A X\cdot\det\begin{pmatrix}
                e_1    &   \ldots    &   e_n    \\
                &   \partial_{y_1}\varphi    &       \\
                &    \vdots   &       \\
                &   \partial_{y_{n-1}}\varphi    &
            \end{pmatrix}\\
            &=\int_A X\cdot n
        \end{align}
    \end{subequations}
    where \( \{ y_1,\ldots, y_{n-1} \}\) are the coordinates on \( A\) and \( n\) is the normal vector to the parametrization.
\end{proposition}
Note : thanks to lemma~\ref{LEMooCMIZooHhHaHV}, the value of \( n\) can depend on the choice of coordinates, but the integral will not depend.

\begin{proof}
    If \( X=\sum_{i=1}^nX_i\partial_i\), then \( X^{\flat}=\sum_{i}X_idx_i\) and its Hodge dual is
    \begin{equation}
        \sum_{i}(-1)^i dx_1\wedge\ldots\wedge\widehat{dx_i}\wedge\ldots\wedge dx_n
    \end{equation}
    where the hat denotes a factor that is not present. Using the definitions~\ref{DEFooAXZGooJairMQ},~\ref{DEFooAXFXooWiMLKP} and~\ref{DEFooPDRCooPiBklC} it remains to integrate
    \begin{equation}
        \int_A\sum_i(-1)^iX_i\varphi^*\big( dx_1\wedge\ldots\wedge\widehat{dx_i}\wedge\ldots\wedge dx_n \big).
    \end{equation}
    If \( u_1,\ldots, u_{n-1}\) are vectors on \( A\) (that is on \( T_xA\) where \( x\) is the integration variable) we have
    \begin{subequations}
        \begin{align}
            \varphi^*(dx_1\wedge\ldots\wedge \widehat{dx_i}\wedge\ldots\wedge dx_n)(u_1,\ldots, u_{n-1})&= (dx_1\wedge\ldots\wedge \widehat{dx_i}\wedge\ldots\wedge dx_n)(d\varphi u_1,\ldots, d\varphi u_{n-1})\\
            &=\det\big( \tau_id\varphi u_1,\ldots, \tau_id\varphi u_{n-1} \big)
        \end{align}
    \end{subequations}
    where we used the lemma~\ref{LEMooICRXooFKPCRd}.

    What lies in the integral is the \( (n-1)\) differential form
    \begin{subequations}        \label{EQooEVAPooSbRfaj}
        \begin{align}
           (u_1,\ldots, u_{n-1})\mapsto \sum_{i}(-1)^iX_i&\det\big(    \tau_id\varphi u_1,\ldots, \tau_id\varphi u_{n-1}  \big)\\
            &=\det\big( X,d\varphi u_1,\ldots, d\varphi u_{n-1} \big).
        \end{align}
    \end{subequations}
    Since this is a \( (n-1)\) differential form over \( \eR^{n-1}\), this has to be proportional to \( dy_1\wedge\ldots dy_{n-1}\). The proportionality factor is found by applying \eqref{EQooEVAPooSbRfaj} to the basis \( \{ e_1,\ldots, e_n \}\). Since \( d\varphi(e_i)=\frac{ \partial \varphi }{ \partial y_i }\) we have the proportionality factor
    \begin{equation}
        \det\left( X,\frac{ \partial \varphi }{ \partial y_1 },\ldots, \frac{ \partial \varphi }{ \partial y_n } \right)
    \end{equation}
    and the integral to be computed is
    \begin{equation}
        \int_A\det\left( X,\frac{ \partial \varphi }{ \partial y_1 },\ldots, \frac{ \partial \varphi }{ \partial y_n } \right)dy_1\wedge\ldots\wedge dy_{n-1}=\int_A\det\left( X,\frac{ \partial \varphi }{ \partial y_1 },\ldots, \frac{ \partial \varphi }{ \partial y_n } \right).
    \end{equation}
    The formula \eqref{SUBEQooWJSPooImJjQN} is proven. The two others are application of lemma~\ref{LEMooFRWKooVloCSM}.
\end{proof}

\begin{example}
    Let us make the example with \( n=3\). We have
    \begin{equation}
        \varphi^*(dx\wedge dy)(v_1,v_2)=(dx\wedge dy)(d\varphi v_1 , d\varphi v_2)=\det
        \begin{pmatrix}
            d\varphi(v_1)_x    &   d\varphi(v_2)_x    \\
            d\varphi(v_1)_y    &   d\varphi(v_2)_y
        \end{pmatrix},
    \end{equation}
    and then
    \begin{equation}
        \sum_i(-1)^iX_i \varphi^*(   \Wedge_{k\neq i}dx_k    )(v_1,v_2)=\sum_i(-1)^iX_i
        \begin{pmatrix}
            d\varphi(v_1)_x    &   d\varphi(v_2)_x    \\
            d\varphi(v_1)_y    &   d\varphi(v_2)_y
        \end{pmatrix}=
        \det\begin{pmatrix}
             X_1  &   d\varphi (v_1)_x    &   d\varphi(v_2)_x    \\
             X_2  &   d\varphi (v_1)_y    &   d\varphi(v_2)_y    \\
             X_3  &   d\varphi (v_1)_z    &   d\varphi(v_2)_z
        \end{pmatrix}
    \end{equation}
\end{example}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Integrating by part}
%---------------------------------------------------------------------------------------------------------------------------

\begin{proposition}[\cite{MonCerveau}]
    Let \( \Omega\) be an open set in an manifold \( M\) of dimension \( n\) and \( \varphi\colon A\to \eR^n\) be a parametrisation of the boundary \( \partial\Omega\) with tangent vector field \( n\) (defined on \( \partial\Omega\)). Let \( u,v\in  C^{\infty}(M)\). Then we have
    \begin{equation}        \label{EQooQSMNooKHwbqp}
        \int_{\partial \Omega}uv\,n_j=\int_{\Omega}\frac{ \partial u }{ \partial x_j }v+\int_{\Omega}u\frac{ \partial v }{ \partial x_j }.
    \end{equation}
\end{proposition}

\begin{proof}
    We use the Stokes formula (theorem~\ref{ThoATsPuzF}) on the \( (n-1)\)-form
    \begin{equation}
        \omega=uv\,dx_1\wedge\ldots\wedge\widehat{dx_j}\wedge\ldots\wedge dx_n,
    \end{equation}
    and we know from example~\ref{EXooCIYIooFPMLMU} that \( \omega=(-1)^{j+1}\hodge dx_j\). On the other hand,
    \begin{equation}
        d\omega=\sum_k\frac{ \partial (uv) }{ \partial x_k }dx_j\wedge dx_1\wedge\ldots\wedge\widehat{dx_j}\wedge\ldots\wedge dx_n=\frac{ \partial (uv) }{ \partial x_j }(-1)^{j+1}dx_1\wedge\ldots\wedge dx_n.
    \end{equation}
    We can use the Stokes formula :
    \begin{equation}
        \int_{\partial \Omega} uv dx_1\wedge\ldots\wedge\widehat{dx_j}\wedge\ldots\wedge dx_n=  (-1)^{j+1} \int_{\Omega}\frac{ \partial (uv) }{ \partial x_j }.
    \end{equation}
    The left-hand side can be transformed as
    \begin{equation}
        \int_{\partial\Omega}\hodge(dx_j)=\int_{\partial\Omega}uv\partial_j=\int_{\partial\Omega}uv\,n_j
    \end{equation}
    where we used the definition~\ref{DEFooAXFXooWiMLKP} and the proposition~\ref{PROPooETLZooAVsrwy}.

    The coefficients \( (-1)^{j+1}\) simplify and the derivation of product produce the result.
\end{proof}

\begin{example}     \label{EXooWLUVooNamnKG}
    If we integrate by part the function \( u\frac{ \partial^2 v }{ \partial x_j^2 }\) we have
    \begin{equation}
        \int_{\omega}u\frac{ \partial^2 }{ \partial x_j^2 }=-\int_{\Omega}\frac{ \partial u }{ \partial x_j }\frac{ \partial v }{ \partial x_j }+\int_{\partial \Omega}u\frac{ \partial v }{ \partial x_j }n_j.
    \end{equation}
    Summing over \( j\) we have the interesting formula
    \begin{equation}        \label{EQooJLDTooIMtxEX}
        \int_{\Omega}u\Delta v=-\int_{\Omega}\nabla u\cdot\nabla v+\int_{\partial \Omega}u\frac{ \partial v }{ \partial n }
    \end{equation}
    where \( \Delta v=\sum_j\frac{ \partial^2v }{ \partial x_j^2 }\) and \( \frac{ \partial v }{ \partial n }\) is a notation for \( \nabla v\cdot n\).
\end{example}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Lie derivative}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Consider $X\in\cvec(M)$ and $\alpha\in\Omega^p(M)$. Let $\dpt{\varphi_t}{M}{M}$ be the flow of $X$. The \defe{Lie derivative}{Lie!derivative!of a $p$-form} of $\alpha$ is
\begin{equation}\label{liesurforme}
         \mL_X\alpha=\lim_{t\to 0}\us{t}[(\varphi^*_t\alpha)-\alpha]=\dsdd{\varphi^*_t\alpha}{t}{0}.
\end{equation}
More explicitly, for $x\in M$ and $v\in T_xM$,
\[
             (\mL_X\alpha)_x(v)=\lim_{t\to 0}\us{t}\left[(\varphi_t^*\alpha)_x(v)-\alpha_x(v)\right]
\]
In the definition of the \defe{Lie derivative}{Lie!derivative!of a vector field} for a vector field, we need an extra minus sign:
\begin{equation}		\label{EqDefLieDerivativeVect}
            (\mL_XY)_x=\dsdd{\varphi_{-t*}Y_{\varphi_t(x)}}{t}{0}.
\end{equation}
Why a minus sign ? Because $Y_{\varphi_t(x)}\in T_{\varphi_t(x)}M$, but $\dpt{(d\varphi_{-t})_a}{T_aM}{T_{\varphi_{-t}(a)}M}$ so that, if we want, $\varphi_{-t*}Y_{\varphi_t(x)}$ to be a vector at $x$, we can't use $\varphi_{t*}$.

These two definitions can be embedded in only one. Let $X\in\cvec(M)$ and $\varphi_t$ its integral curve\footnote{\textit{i.e.} for all $x\in M$, $\varphi_0(x)=x$ and $\dsdd{\varphi_{u+t}(x)}{t}{0}=X_{\varphi_u(x)}$.}\index{integral!curve}. We know that $\varphi_{t*}$ is an isomorphism $\dpt{\varphi_{t*}}{T_{\varphi^{-1}(x)}M}{T_xM}$. It can be extended to an isomorphism of the tensor algebras at $\varphi^{-1}(x)$ and $x$. We note it $\tilde{\varphi}_t$. For all tensor field $K$ on $M$, we define
\[
            (\mL_XK)_x=\lim_{t\to 0}[K_x-(\tilde{\varphi_t}K)_x].
\]

On a Riemannian manifold $(M,g)$, a vector field $X$ is a \defe{\href{http://en.wikipedia.org/wiki/Killing_vector_fields}{Killing vector field}}{killing!vector field} if $\mL_Xg=0$.



\begin{lemma}
Let $\dpt{f}{(-\epsilon,\epsilon)\times M}{\eR}$ be a differentiable map with $f(0,p)=0$ for all $p\in U$. Then there exists $\dpt{g}{(-\epsilon,\epsilon)\times M}{\eR}$, a differentiable map such that $f(t,p)=tg(t,p)$ and
\[
                g(0,q)=\left.\dsd{f(t,q)}{t}\right|_{t=0}.
\]
\end{lemma}
\begin{proof}
Take
\[
                g(t,q)=\int_0^1\dsd{f(ts,p)}{(ts)}ds,
\]
and use the change of variable $s\to ts$.
\end{proof}

\begin{lemma}
If $\varphi_t$ is the integral curve of $X$, for all function $\dpt{f}{M}{\eR}$, there exists a map $g$, $g_t(p)=g(t,p)$ such that
$f\circ\varphi_t=f+tg_t$ and $g_0=Xf$.
\end{lemma}

\begin{proof}
Consider $\overline{f}(t,p)=f(\varphi_t(p))-f(p)$, and apply the lemma:
\[
          f\circ\varphi_t=tg_t(p)+f(p).
\]
Thus we have
\[
      Xf=\lim_{t\to 0}\us{t}[f(\varphi_t(p))-f(p)]=\lim_{t\to 0}g_t(p)=g_0(p).
\]
\end{proof}

One of the main properties of the Lie derivative is the following:
\begin{theorem}		\label{ThoLieDerrComm}
Let $X$, $Y\in\cvec(M)$ and $\varphi_t$ be the integral curve of $X$. Then
\[
         [X,Y]_p=\lim_{t\to 0}\us{t}[Y-d\varphi_tY](\varphi_t(p)),
\]
or
\begin{equation}
          \mL_XY=[X,Y].
\end{equation}
where the commutator is given by the definition \ref{DEFooHOTOooRaPwyo}.
\end{theorem}
\begin{proof}
Take $\dpt{f}{M}{\eR}$ and the function given by the lemma: $\dpt{g_t}{M}{\eR}$ such that $f\circ \varphi_t=f+tg_t$ and $g_0=Xf$. Then put $p(t)=\varphi_t^{-1}(p)$. The rest of the proof is a computation:
\[
            (\varphi_{t*}Y)_pf=Y(f\circ\varphi_t)_{p(t)}=(Yf)_{p(t)}+t(Yg_t)_{p(t)},
\]
so
\begin{equation}
\begin{split}
  \lim_{t\to 0}\us{t}[Y_p-(\varphi_{t*}Y)_p]f&=\lim_{t\to 0}\us{t}[(Yf)_p-(Yf)_{p(t)}]-\lim_{t\to 0}(Yg_t)_{p(t)}\\
                                         &=X_p(Yf)-Y_pg_0\\
                                         &=[X,Y]_pf.
\end{split}
\end{equation}

\end{proof}

A second important property is
\begin{theorem}
For any function $f\colon M\to V$,
\[
           \mL_Xf=Xf.
\]
\end{theorem}

\begin{proof}
If $X(t)$ is the path which defines the vector $X$, it is obvious that at $t=0$, $X(t)$ is an integral curve to $X$, so that we can take $X(t)$ instead of $\varphi_t$ in \eqref{liesurforme}. Therefore we have:
\begin{equation}
    \mL_Xf=\dsdd{\varphi_t^*f}{t}{0}
          =Xf
\end{equation}
by definition of the action of a vector on a function.
\end{proof}
