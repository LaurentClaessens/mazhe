% This is part of (almost) Everything I know in mathematics
% Copyright (c) 2010-2017, 2019
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.

\section{Differentiable manifolds}
%+++++++++++++++++++++++++++++++++

Most of the results about differential geometry come from \cite{kobayashi, madore, Helgason, ms_book, dgbook}.

\subsection{Definition and examples}
%-----------------------------------

\begin{definition}
    A $n$-dimensional \defe{differentiable manifold}{differentiable!manifold}\index{manifold} is a set $M$ and a system of charts $\{(\mU_{\alpha},\varphi_{\alpha})\}_{\alpha\in I}$ where each set $\mU_{\alpha}$ is open in $\eR^n$ and the maps $\dpt{\varphi_{\alpha}}{\mU_{\alpha}}{M}$ are injective and satisfy the three following conditions:

    \begin{itemize}
    \item every $x\in M$ is contained in at least one set $\varphi_{\alpha}(\mU_{\alpha})$,
    \item for any two charts $\dpt{\varphi_{\alpha}}{\mU_{\alpha}}{M}$ and $\dpt{\varphi_{\beta}}{\mU_{\beta}}{M}$, the set
    \[
       \varphi_{\alpha}^{-1}( \varphi_{\alpha}(\mU_{\alpha})\cap\varphi_{\beta}(\mU_{\beta}) )
    \]
    is an open subset of $\mU_{\alpha}$,
    \item the map
    \[
      \dpt{  (\varphi_{\beta}^{-1}\circ\varphi_{\alpha})  }{   \varphi_{\alpha}^{-1}( \varphi_{\alpha}(\mU_{\alpha})\cap\varphi_{\beta}(\mU_{\beta})  )   }{\mU_{\beta}}
    \]
    is differentiable\footnote{In the sequel, by ``differentiable'' we always mean smooth. If this map is differentiable, $C^k$, analytic,\ldots then the manifold is said to be differentiable, $C^k$, analytic,\ldots} as map from $\eR^n$ to $\eR^n$.
    \end{itemize}
\end{definition}

Each time we say ``manifold``, we mean ``differentiable manifold``. We will only consider manifolds with Hausdorff topology (see later for the definition of a topology on a manifold). Any open set of $\eR^n$ is a differentiable manifold if we choose the identity map as chart system. Most of surfaces $z=f(x,y)$ in $\eR^3$ are manifolds, depending on certain regularity conditions on~$f$.

If $M_1$ and $M_2$ are two differentiable manifolds, a map $\dpt{f}{M_1}{M_2}$ is \defe{differentiable}{differentiable!map} if $f$ is continuous and for each two coordinate systems $\dpt{\varphi_1}{\mU_1}{M_1}$ and $\dpt{\varphi_2}{\mU_2}{M_2}$, the map $\varphi_2^{-1}\circ f\circ\varphi_1$ is differentiable on its domain. One can show that if $\dpt{f}{M_1}{M_2}$ and $\dpt{g}{M_2}{M_3}$ are differentiable, then $\dpt{g\circ f}{M_1}{M_3}$ is differentiable.

\subsubsection{Example: the sphere}\index{sphere}

The sphere $S^n$ is the set
\[
  S^n=\{  (x_1,\ldots, x_{n+1})\in\eR^{n+1}\tq \|x\|=1  \}
\]
for which we consider the following open set in $\eR^n$:
\[
   \mU=\{  (u_1,\ldots,u_n)\in\eR^n\tq\|u\|<1  \}
\]
and the charts $\dpt{\varphi_i}{\mU}{S}$, and $\dpt{\tilde{\varphi}_i}{\mU}{S}$
\begin{subequations}
\begin{align}
   \varphi_i(u_1,\ldots,u_n)&=(u_1,\ldots,u_{i-1}, \sqrt{  1-\|u\|^2  },u_i,\ldots,u_n )\\
   \tilde{\varphi}_i(u_1,\ldots,u_n)&=(u_1,\ldots,u_{i-1}, -\sqrt{  1-\|u\|^2  },u_i,\ldots,u_n ).
\end{align}
\end{subequations}
These map are clearly injective. To see that $\varphi(\mU)\cup\tilde{\varphi}(\mU)=S$, consider $(x_1,\ldots,x_{n+1})\in S$. Then at least one of the $x_i$ is non zero. Let us suppose $x_1\neq 0$, thus $x_1^2=1-(x_2^2+\cdots+x_{n+1}^2)$ and
\begin{equation}\label{eq:xupm}
   x_1=\pm\sqrt{1-(\ldots)}.
\end{equation}
If we put $u_i=x_{i+1}$, we have $x=\varphi(u)$ or $x=\tilde{\varphi}(u)$ following the sign in relation \eqref{eq:xupm}. The fact that $\varphi^{-1}\circ\tilde{\varphi}$ and $\tilde{\varphi}^{-1}\circ\varphi$ are differentiable is a ``first year in analysis exercise``.

\subsubsection{Example: projective space}

On $\eR^{n+1}\setminus\{o\}$, we consider the equivalence relation $v\sim\lambda w$ for all non zero $\lambda\in\eR$, and we put
\[
  \eR P^n=\left(\eR^{n+1}\setminus\{o\}\right)/\sim.
\]
This is the set of all the one dimensional subspaces of $\eR^{n+1}$. This is the real \defe{projective space}{projective!real space} of dimension $n$. We set $\mU=\eR^n$ and
\[
  \varphi_i(u_1,\ldots,u_n)=\Span\{ (u_1,\ldots,u_{i-1},1,u_i,\ldots,u_n) \}.
\]
One can see that this gives a manifold structure to $\eR P^n$. Moreover, the map
		\begin{equation}
		\begin{aligned}
			A \colon S^n &\to \eR P^n\
			v&\mapsto \Span v
		\end{aligned}
	\end{equation}
is differentiable.

Let us show how to identify $\eR\cup\{ \infty \}$ to $\eR P^1$, the set of directions in the plane $\eR^2$. Indeed consider any vertical line $l$ (which does contain the origin). A non vertical vector subspace of $\eR^2$ intersects $l$ in one and only one point, while the vertical vector subspace is associated with the infinite point.

\subsection{Topology}
%--------------------

\begin{propositionDef}
    Let \( M\) be a manifold. A subset $V\subset M$ is \defe{open}{topology!on manifold} if for every chart $\dpt{\varphi}{\mU}{M}$, the set $\varphi^{-1}(V\cap\varphi(\mU))$ is open in $\mU$. 

    The set of open sets in \( M\) is a topology.
\end{propositionDef}

\begin{proof}
    First we prove that the open system defines a topology. For this, remark that $\varphi_{\alpha}^{-1}$ is injective (if not, there should be some multivalued points). Then $\varphi^{-1}(A\cap B)=\varphi^{-1}(A)\cap\varphi^{-1}(B)$. If $V_1$ and $V_2$ are open in $M$, then
    \begin{equation}
        \varphi^{-1}(V_1\cap V_2\cap\varphi(\mU))=\varphi^{-1}(V_1\cap\varphi(\mU))\cap\varphi^{-1}(V_2\cap\varphi(\mU))
    \end{equation}
    which is open in $\eR^n$. The same property works for the unions.
\end{proof}

\begin{theorem}
    Let \( M\) be a manifold. Its topology has the following properties.
    \begin{enumerate}
        \item the charts maps are continuous,
        \item the sets $\varphi_{\alpha}(\mU_{\alpha})$ are open.
    \end{enumerate}
\end{theorem}

\begin{proof}
    We proof the continuity of $\dpt{\varphi}{\mU}{M}$; for an open set $V$ in $M$, we have to show that $\varphi^{-1}(V)$ is open in $\mU\subset\eR^n$. But the definition of the topology on $M$, is precisely the fact that $\varphi^{-1}(V\cap\varphi(\mU))$ is open.
\end{proof}

\begin{definition}
    If $M$ and $M$ are two analytic manifolds, a map $\dpt{\phi}{M}{N}$ is \defe{regular}{regular}\label{PgDefRegular} at $p\in M$ if it is analytic at $p$ and $\dpt{d\phi_p}{T_pM}{T_{\phi(p)}N}$ is injective.
\end{definition}


%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Tangent and cotangent bundle}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\subsection{Tangent vector}
%--------------------------

As first attempt, we define a tangent vector of $M$ at the point $x\in M$ as the ``derivative'' of a path $\dpt{\gamma}{(-\epsilon,\epsilon)}{M}$ such that $\gamma(0)=x$. It is denoted by
\[
\gamma'(0)= \dsdd{\gamma(t)}{t}{0}.
\]
The question is to correctly define de derivative in the right hand side. Such a definition is achieved as follows. 

\begin{definition}      \label{DEFooJJVIooDUBwDJ}
    A \defe{tangent vector}{} to the manifold $M$ is a linear map $X\colon  C^{\infty}(M)\to \eR$ which can be written under the form
    \begin{equation}  \label{eq_deftgpath}
       Xf=(f\circ X)'(0)=\Dsdd{f(X(t))}{t}{0}
    \end{equation}
    for a certain path $X\colon \eR\to M$. Notice the abuse of notation between the tangent vector and the path which defines it.

    A more formal way to define a tangent vector is to say that it is an equivalent class of path in the sense that two path are equivalent if and only if they induced maps by \eqref{eq_deftgpath} are equals.
\end{definition}

\begin{remark}      \label{REMooJQFHooQuoZxt}
    The notation \( \gamma'(0)\) for the tangent vector to the curve \( \gamma\) has to be taken with caution. In particular, \( \gamma'(0)\) is not defined by the limit
    \begin{equation}        \label{EQooVMGFooFUCNEY}
        \lim_{\epsilon\to 0} \frac{ \gamma(\epsilon)-\gamma(0) }{ \epsilon }
    \end{equation}
    because when \( M\) is a manifold, there is in general no notion of difference between the points of \( M\), so that the difference \( \gamma(\epsilon)-\gamma(0)\) has no meaning.

    The only definition of \( \gamma'(0)\) is as differential operator.

    The manifold could, of course have some additional structure which allows to write the differential quotient \eqref{EQooVMGFooFUCNEY}. This is the case when \( M=\eR^n\) or when \( M\) is a matrix group. In these cases, the question of the link between \( \gamma'(0)\) and the ``true'' derivative of \( \gamma\) has to be studied.

    In that case we have the same notational problem with ``$df$''. Let \( f\colon M\to \eR\) where \( M\) is a manifold like \( \eR^n\). The symbol \( df_a\) with \( a\in M\) can be the differential of \( f\) as function \( M\to \eR\), so that \( df_a\) is a linear map from \( \eR^n\) to \( \eR\). But \( df_a\) can also be the linear map \( df_a\colon T_aM\to T_{f(a)}\eR\) where the spaces \( T_aM\) and \( T_{f(a)}\eR\) are made of differential operators.

    This is the point of the section \ref{SECooTSAJooNtjgMD}.
\end{remark}

Using the chain rule $d(g\circ f)(a)=dg(f(a))\circ df(a)$ for the differentiation in $\eR^n$, one sees that this equivalence notion doesn't depend on the choice of $\varphi$. In other words, if $\varphi$ and $\tilde{\varphi}$ are two charts for a neighbourhood of $x$, then $(\varphi^{-1} \circ\gamma)'(0)=(\varphi^{-1} \circ\sigma)'(0)$ if and only if $(\tilde{\varphi}^{-1} \circ\gamma)'(0)=(\tilde{\varphi}^{-1} \circ\sigma)'(0)$. The space of all tangent vectors at $x$ is denoted by $T_xM$. There exists a bijection $[\gamma]\leftrightarrow (\varphi^{-1}\circ\gamma)'(0)$ between $T_xM$ and $\eR^n$, so $T_xM$ is endowed with a vector space structure.

If $(\mU,\varphi)$ is a chart around $X(0)$, we can express $Xf$ using only well know objects by defining the function $\tilde f =f\circ\varphi$ and $\tX=\varphi^{-1}\circ X$
\[
  Xf=\Dsdd{ (\tilde f \circ\tX)(t) }{t}{0}=\left.\dsd{\tilde f }{x^{\alpha}}\right|_{x=\tX(0)}\left.\frac{d\tX^{\alpha}}{dt}\right|_{t=0}.
\]
In this sense, we write
\begin{equation}
  X=\frac{d\tX^{\alpha}}{dt} \dsd{}{x^{\alpha}}
\end{equation}
and we say that $\{\partial_1,\ldots,\partial_n\}$ is a basis of $T_xM$. As far as notations are concerned, from now a tangent vector is written as $X=X^{\alpha}\partial_{\alpha}$ where $X^{\alpha}$ is related to the path $\dpt{X}{\eR}{M}$ by $X^{\alpha}=d\tX^{\alpha}/dt$. We will no more mention the chart $\varphi$ and write
\[
  Xf=\Dsdd{f(X(t))}{t}{0}.
\]
Correctness of this short notation is because the equivalence relation is independent of the choice of chart. When we speak about a tangent vector to a given path $X(t)$ without specification, we think about $X'(0)$.

All this construction gives back the notion of tangent vector when $M\subset \eR^m$. In order to see it, think to a surface in $\eR^3$. A tangent vector is precisely given by a derivative of a path: if $\dpt{c}{\eR}{\eR^n}$ is a path in the surface, a tangent vector to this curve is given by
\[
   \lim_{t\to 0}\frac{c(t_0)-c(t_0+t)}{t}
\]
which is a well know limit of a difference in $\eR^n$.

\label{pg:vecto_vecto}Let us precise how does a tangent vector acts on maps others than $\eR$-valued functions. If $V$ is a vector space and $\dpt{f}{M}{V}$, we define
\[
   Xf=(Xf^i)e_i
\]
where $\{e_i\}$ is a basis of $V$ and the functions $\dpt{f^i}{M}{\eR}$, the decomposition of $f$ with respect to this basis. If we consider a map $\dpt{\varphi}{M}{N}$ between two manifolds, the natural definition is $Xf:=dfX$. More precisely, if we consider local coordinates $x^{\alpha}$ and a function $\dpt{f}{M}{\eR}$,
\begin{equation}\label{eq:dvp_phi}
   (d\varphi X)f=\Dsdd{  (f\circ\varphi\circ X)(t) }{t}{0}=\dsd{f}{x^{\alpha}}\dsd{\varphi^{\alpha}}{x\hbeta}\frac{dX\hbeta}{dt}.
\end{equation}
Now we are in a notational trouble: when we write $X=X^{\alpha}\partial_{\alpha}$, the ``$X^{\alpha}$``{} is the derivative of the ``$X^{\alpha}$``{} which appears in the path $X(t)=(X^1(t),\ldots,X^n(t))$ which gives $X$ by $X=X'(0)$. So equation \eqref{eq:dvp_phi} gives
\begin{equation}
   X(\varphi):=d\varphi X=X\hbeta(\partial_{\beta}\varphi^{\alpha})\partial_{\alpha}.
\end{equation}

\subsection{Differential of a map}
%------------------------------------------

Let $\dpt{f}{M_1}{M_2}$ be a differentiable map, $x\in M_1$ and $X\in T_xM_1$, i.e. $\dpt{X}{\eR}{M_1}$ with $X(0)=x$ and $X'(0)=X$. We can consider the path $Y=f\circ X$ in $M_2$. The tangent vector to this path is written $df_x X$.

\begin{proposition}
If $\dpt{f}{M_1}{M_2}$ is a differentiable map between two differentiable manifolds, the map
		\begin{equation}
		\begin{aligned}
			df_x \colon T_xM_1 &\to T_{f(x)}M_2\
			X'(0)&\mapsto (f\circ X)'(0)
		\end{aligned}
	\end{equation}
is linear.
\end{proposition}

\begin{proof}
We consider local coordinates $\dpt{x}{\eR^n}{M_1}$ and $\dpt{y}{\eR^m}{M_2}$. The maps $\dpt{f}{M_1}{M_2}$ and $\dpt{y^{-1}\circ f\circ x}{\eR^n}{\eR^m}$ will sometimes be denoted by the same symbol $f$. We have $(x^{-1}\circ X)(t)=(x_1(t),\ldots,x_n(t))$ and $(y^{-1}\circ Y)(t)=\big( y_1(x_1(t),\ldots,x_n(t),\ldots, y_m(x_1(t),\ldots,x_n(t)  \big)$, so that
\[
  Y'(0)=\left(   \sum_{i=1}^n \dsd{y_1}{x_i}x_i'(0),\ldots,\sum_{i=1}^n \dsd{y_m}{x_i}x_i'(0)   \right)\in\eR^m
\]
which can be written in a more matricial way under the form
\[
   Y'(0)=\left( \dsd{y_i}{x_j}x'_j(0) \right).
\]
So in the parametrisations $x$ and $y$, the map $df_x$ is given by the matrix $\partial y^i/\partial x_j$ which is well defined from the only given of $f$.
\end{proof}


Let $\dpt{x}{\mU}{M}$ and $\dpt{y}{\mV}{M}$ be two charts systems around $p\in M$. Consider the path $c(t)=x(0,\ldots,t,\ldots 0)$ where the $t$ is at the position $k$. Then, with respect to these coordinates,
\[
  c'(0)f=\Dsdd{ f(c(t))  }{t}{0}=\dsd{f}{x^i}\frac{dc^i}{dt}=\dsd{f}{x^k},
\]
so $c'(0)=\partial/\partial x^k$. Here, implicitly, we wrote $c^i=(x^i)^{-1}\circ c$ where $(x^i)^{-1}$ is the $i$th component of $x^{-1}$ seen as element of $\eR^n$. We can make the same computation with the system $y$. With these abuse of notation,
\begin{equation}
   \dsd{}{x^i}=\sum_j\dsd{y^j}{x^i}\dsd{}{y^j}
\end{equation}
as it can be seen by applying it on any function $\dpt{f}{M}{\eR}$. More precisely if $\dpt{x}{\mU}{M}$ and $\dpt{y}{\mU}{M}$ are two charts (let $\mU$ be the intersection of the domains of $x$ and $y$), let $\dpt{f}{M}{\eR}$ and $\ovf=f\circ x$, $\tilde f =f\circ y$. The action of the vector $\partial_{x^i}$ of the function $f$ is given by
\[
  \partial_{x^i}f=\dsd{\ovf}{x^i}
\]
where the right hand side is a real number that can be computed with usual analysis on $\eR^n$. This real \emph{defines} the left hand side. Now, $\ovf=\tilde f \circ y^{-1}\circ x$, so that
\[
   \dsd{\ovf}{x^i}=\dsd{ (\tilde f \circ y^{-1}\circ x) }{x^i}=\dsd{\tilde f }{y^j}\dsd{y^j}{x^i}
\]
where $\dsd{\tilde f }{y^j}$ is precisely what we write now by $\partial_{y^j}f$ and $\dsd{y^j}{x^i}$ must be understood as the derivative with respect to $x^i$ of the function $\dpt{(y^{-1}\circ x)}{\eR^n}{\eR^n}$.

Let $\dpt{f}{M}{N}$ and $\dpt{g}{N}{\eR}$; the definitions gives
\[
  (df_xX)g=\Dsdd{(g\circ f)(X(t))}{t}{0}
          =\dsd{g}{y^i}\dsd{f^i}{x^{\alpha}}\frac{dX^{\alpha}}{dt}.
\]
This shows that $\dsd{f^i}{x^{\alpha}}\frac{dX^{\alpha}}{dt}$ is $(df_xX)^i$.  But $dX^{\alpha}/dt$ is what we should call $X^{\alpha}$ in the decomposition $X=X^{\alpha}\partial_{\alpha}$ then the matrix of $df$ is given by $\dsd{f^i}{x^{\alpha}}$. So we find back the old notion of differential.

\begin{remark}
If $X\in T_xM$ and $f$ is a \emph{vector valued} function on $M$, then one can define $Xf$ by exactly the same expression. In this case,
\[
  df X=\Dsdd{f(v(t))}{t}{0}=Xf.
\]
\end{remark}

A map $\dpt{f}{M_1}{M_2}$ is an \defe{immersion}{immersion} at $p\in M_1$ if $\dpt{df_p}{T_pM_1}{T_{f(p)}M_2}$ is injective. It is a \defe{submersion}{submersion} if $df_p$ is surjective.

\subsection{Tangent and cotangent bundle}
%--------------------------------------

If $M$ is a $n$ dimensional manifold, as set the tangent bundle\index{tangent!space} is the \emph{disjoint} union of tangent spaces
\[
  TM=\bigcup_{x\in M}T_xM.
\]

\begin{theorem}
	The tangent bundle admits a $2n$ dimensional manifold structure for which the projection
	\begin{equation}
		\begin{aligned}
			\pi \colon TM &\to M\
			T_pM&\mapsto p
		\end{aligned}
	\end{equation}
	is a submersion.
\end{theorem}

The structure is easy to guess. If $\dpt{\varphi_{\alpha}}{\mU_{\alpha}}{M}$ is a coordinate system on $M$ (with $\mU_{\alpha}\subset\eR^n$), we define $\dpt{\psi_{\alpha}}{\mU_{\alpha}\times \eR^n}{TM}$ by
\[
  \psi( \underbrace{x_1,\ldots x_n}_{\in\mU_{\alpha}},\underbrace{a_1,\ldots a_n}_{\in\eR^n}  )
          =\sum_i a_i\left.\dsd{}{x_i}\right|_{\varphi(x_1,\ldots,x_n)}.
\]
The map $\psi_{\beta}^{-1}\circ\psi_{\beta}$ is differentiable because
\[
(\psi_{\beta}^{-1}\circ\psi_{\beta})(x,a)=( y(x),\sum_i a_i\left.\dsd{y_j}{x_i}\right|_{y(x)}  )
\]
which is a composition of differentiable maps. The set $TM$ endowed with this structure is called the \defe{tangent bundle}{tangent!bundle}.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Vector space structure on the tangent space}
%---------------------------------------------------------------------------------------------------------------------------

If \( X,Y\in T_pM\) are tangent vectors, one can define \( X+Y\) and \( \lambda X\) for every \( \lambda\in\eR\). The second one is easy:
\begin{equation}
    \lambda X=\Dsdd{ X(\lambda t) }{t}{0}.
\end{equation}
In order to define the sum of two vectors one has to consider a neighbourhood \( \mU\) of \( p\) in \( M\) and a chart \( \varphi\colon \mU\to \mO\) where \( \mO\) is an open set in \( \eR^n\). Then one consider a basis \( \{ e_i \}_{1\leq i\leq n}\) of \( \eR^n\) at the point \( \varphi(p)\). With these choices we define the ``basis'' path
\begin{equation}
    \gamma_i(t)=\varphi^{-1}(te_i)
\end{equation}
and we write
\begin{equation}
    \partial_i=\frac{ \partial  }{ \partial x_i }=\Dsdd{ \varphi^{-1}(te_i) }{t}{0}.
\end{equation}
The vectors \( \partial_i\) form a basis of \( T_pM\) in the sense of the following lemma.

\begin{lemma}       \label{LEMooXDESooHXzIJU}
    The action of a vector \( X\in T_pM\) on a function \( f\colon M\to \eR\) can be decomposed into
    \begin{equation}
        Xf=\sum_{i=1}^n X_i(\partial_if)
    \end{equation}
    with \( X_i\in\eR\)
\end{lemma}

\begin{proof}
    Let \( \varphi\colon M\to \eR^n\) be a chart of a neighbourhood of \( p\) with \( \varphi(p)=0\). We determine the value of \( X_i\) using the function
    \begin{equation}
        f_i(x)=\varphi(x)_i,
    \end{equation}
    that is the \( i\)th component of the point \( \varphi(x)\in\eR^n\). Then if we write \( \varphi\big( X(t) \big)=\sum_j a_j(t)e_j\) we have
    \begin{subequations}
        \begin{align}
            X(f_i)=\Dsdd{ f_i\big( X(t) \big) }{t}{0}=\Dsdd{ \big[ \sum_ja_j(t)e_j \big]_i }{t}{0}=\Dsdd{ ai_(t) }{t}{0}=a_i'(0).
        \end{align}
    \end{subequations}
    Notice that \( a_i(0)=0\) since \( X(0)=p\) and \( \varphi(p)=0\). The combination \( f\circ\varphi^{-1}\) is an usual function from \( \eR^n\) to \( \eR\), so that we can use the chain rule on it. The following computation thus make sense:
    \begin{subequations}
        \begin{align}
            Xf&=\Dsdd{ f\big( X(t) \big) }{t}{0}\\
            &=\Dsdd{ f\Big( \varphi^{-1}\varphi\big( X(t) \big) \Big) }{t}{0}\\
            &=\Dsdd{ (f\circ\varphi^{-1})\big( \sum_ja_j(t)e_j \big) }{t}{0}\\
            &=\sum_k \frac{ \partial (f\circ\varphi^{-1}) }{ \partial x_k }\big( \underbrace{\sum_ja_j(0)e_j}_{=\varphi(p)=0} \big)\underbrace{\frac{ d\big[ \sum_ja_j(t)e_j \big]_k  }{ dt }}_{=a'_k(0)}\\
            &=\sum_k a'_k(0)\frac{ \partial (f\circ\varphi^{-1}) }{ \partial x_k }(0).
        \end{align}
    \end{subequations}
    Now using the definition of a derivative of a function \( \eR^n\to \eR\) and of the ``basis'' tangent vector \( \partial_k\),
    \begin{subequations}
        \begin{align}
            \frac{ \partial (f\circ\varphi^{-1}) }{ \partial x_k }(0)&=\Dsdd{ (f\circ\varphi^{-1})(te_k) }{t}{0}\\
            &=\partial_k f
        \end{align}
    \end{subequations}
   At the end of the day we have
   \begin{equation}
       Xf=\sum_k a'_k(0)\partial_kf.
   \end{equation}
\end{proof}

This lemma allows us to define the sum in \( T_pM\) as\quext{This is not really true because we still have to prove that for every choice of \( X_i\), there exists a path \( \alpha\) such that \( \alpha'(0)=\sum_iX_i\partial_i\).}      %TODOooNHVGooLYbUkg
\begin{equation}
    \left( \sum_kX_k\partial_k \right)+\left( \sum_kY_k\partial_k \right)=\sum_k (X_k+Y_k)\partial_k
\end{equation}
when \( X_k\) and \( Y_k\) are reals.

The tangent space \( T_pM\) is thus a vector space.

\begin{proposition}     \label{PROPooOHLQooCNetuD}
    Let \( M\) be a differentiable manifold and \( x\in M\). The set of tangent vectors of \( M\) at \( x\) is a vector space denoted by \( T_xM\).
\end{proposition}
% when it is proved, remove the quext TODOooNHVGooLYbUkg.

\begin{proposition}     \label{PROPooWXNDooPeORjA}
    Let \( p\in M\) and \( \varphi\colon U\to M\) be a chart around \( p\) with \( U\) open in \( \eR^m\). If \( a\in U\) and \( p=\varphi(a)\), then  the set \( \{  d\varphi_a(e_i) \}\) is a basis of \( T_pM\).
\end{proposition}

\begin{lemma}       \label{LEMooVCSJooEuDZFz}
    Let \( M\) and \( N\) be smooth manifolds of dimension \( m\) and \( n\) with charts \( \varphi\colon U\to M\) and \( \psi\colon V\to N\) around \( p\in M\) and \( f(p)\in N\). We consider basis \( \{ e_i \}_{i=1,\ldots, m}\) of \( \eR^m\) and \( \{ e'_{\alpha} \}_{\alpha=1,\ldots, n}\) of \( \eR^n\).

    The matrix of \( df_p\colon T_pM\to T_{f(p)}N\) in the basis \( \{ d\varphi_{\varphi^{-1}(p)}(e_i) \}\) and \( \{ d\psi_{\psi^{-1}(f(p))}(e'_{\alpha}) \}\) is the same as the matrix of \( d_{\varphi^{-1}(p)}(\psi^{-1}\circ f\circ\varphi)\) as map from \( \eR^m\) to \( \eR^n\).
\end{lemma}

\begin{proof}
    Let subdivise.
    \begin{subproof}
        \item[Notations]
            As a preliminary remark, the fact that the proposed sets are basis is the proposition \ref{PROPooWXNDooPeORjA}. For the notations, we write
            \begin{subequations}
                \begin{align}
                    \frac{ \partial  }{ \partial x_i }&=d\varphi_{\varphi^{-1}(p)}(e_i),\\
                    \frac{ \partial  }{ \partial y_{\alpha} }&=d\psi_{\psi^{-1}\big( f(p) \big)}(e'_{\alpha}).
                \end{align}
            \end{subequations}
        \item[Component]
            Let \( v\in T_{f(p)}N\). We prove that
            \begin{equation}        \label{EQooISXNooJOzUmS}
                v_{\alpha}=\Big( (d\psi^{-1})_{f(p)}v \Big)_{\alpha}
            \end{equation}
            where in the left-hand side we are speaking of component with respect to the basis \( \{ \partial_{y_{\alpha}} \}\) while in the right-hand side, the ones with respect to the basis \( \{ e'_{\alpha} \}\).

            First we decompose \( v\):
            \begin{equation}
                v=\sum_{\alpha}v_{\alpha}\frac{ \partial  }{ \partial y_{\alpha} }=\sum_{\alpha}v_{\alpha}d\psi_{\psi^{-1}\big( f(p) \big)}e'_{\alpha},
            \end{equation}
            then we apply \( d\psi^{-1}_{f(p)}\) to that equation:
            \begin{equation}
                d\psi^{-1}_{f(p)}v=\sum_{\alpha}v_{\alpha}e'_{\alpha}.
            \end{equation}
            Taking the \( \alpha\)\th\ component on both side we have our result \eqref{EQooISXNooJOzUmS}.
        \item[Matrix]
            The matrix of a linear map is defined by the formula \eqref{EQooOMSCooGsSBIA}. In our case,
            \begin{equation}
                    (df_p)_{\alpha i}=\left( df_p\big( \frac{ \partial  }{ \partial x_i } \big) \right)_{\alpha} =\Big( df_p\circ d\varphi_{\varphi^{-1}(p)}e_i \Big)_{\alpha}.
            \end{equation}
            Using the formula \eqref{EQooISXNooJOzUmS},
            \begin{subequations}
                \begin{align}
                    (df_p)_{\alpha i}&=\Big( df_p\circ d\varphi_{\varphi^{-1}(p)}e_i \Big)_{\alpha}\\
                    &=\big( (d\psi^{-1})_{f(p)}\circ df_p\circ d\varphi_{\varphi^{-1}(p)}e_i \big)_{\alpha}\\
                    &=\big( (d\psi^{-1})_{f(p)}\circ df_p\circ d\varphi_{\varphi^{-1}(p)} \big)_{\alpha i}\\
                \end{align}
            \end{subequations}
    \end{subproof}
\end{proof}

\subsection{Commutator of vector fields}

\begin{lemma}       \label{LEMooPSWEooVKLWMQ}
    If \( X\) is a smooth vector field on the manifold \( M\) and if \( f\) is a smooth function, then the formula
    \begin{equation}
        (Xf)(x)=X_x(f)
    \end{equation}
    defines a smooth function \( Xf\) on \( M\).
\end{lemma}

\begin{propositionDef}      \label{DEFooHOTOooRaPwyo}
    If $X$, $Y\in\cvec(M)$, one defines the \defe{commutator}{commutator of vector fields} $[X,Y]$ by
    \begin{equation}
      [X,Y]_xf=X_x(Yf)-Y_x(Xf).
    \end{equation}
    where \( Yf\) and \( Xf\) are defined by virtue of lemma \ref{LEMooPSWEooVKLWMQ}.
\end{propositionDef}

If $X=X^i\partial_i$ and $Y=Y^j\partial_j$, then
$XY(f)=X^i\partial_i(Y^j\partial_jf)
     =X^i\partial_i Y^j\partial_j f+X^iY^j\partial^2_{ij}f$.
From symmetry $\partial^2_{ij}f=\partial^2_{ji}f$, the difference $XYf-YXf$ is only $X^i\partial_iY^j-Y^i\partial_iX^j$, so that
\begin{equation}
  [X,Y]^i=XY^i-YX^i
\end{equation}
where $X^i$ and $Y^i$ are seen as functions from $M$ to $\eR$.

\begin{proposition}[\cite{BIBooWSHFooKoDjAs}]       \label{PROPooSWQSooSEfTuX}
    The set of all the smooth vector fields on a manifold is a Lie algebra.
\end{proposition}

\subsection{Some Leibnitz formulas}

\begin{lemma}[\cite{kobayashi}]
If $M$ and $N$ are two manifolds, we have a canonical isomorphism
\[
     T_{(p,q)}(M\times N)\simeq T_pM+T_qN.
\]
\label{lemLeibnitz}
\end{lemma}

\begin{proof}
A $Z\in T_{(p,q)}(M\times N)$ is the tangent vector to a curve $(x(t),y(y))$ in $M\times N$. We can consider $X\in T_pM$ given by $X=x'(0)$ and $Y\in T_qN$ given by $Y=y'(0)$. The isomorphism is the identification $(X,Y)\simeq Z$. Indeed, let us define $\oX\in T_{(p,q)}(M\times N)$, the tangent vector to the curve $(x(t),q)$, and $\oY\in T_{(p,q)}(M\times N)$, the tangent vector to the curve $(p,y(t))$. Then $Z=\oX+\oY$ because for any $\dpt{f}{M\times N}{\eR}$,
\begin{equation}
 Zf=\dsdd{f(x(t),y(t))}{t}{0}
   =\dsdd{f(x(t),y(0))}{t}{0}+\dsdd{f(x(0),y(t))}{t}{0}
   =\oX f+\oY f.
\end{equation}
\end{proof}

\begin{proposition}[Leibnitz formula] \label{Leibnitz}
Let us consider $M,N,V$, three manifold; a map $\dpt{\varphi}{M\times N}{V}$ and a vector $Z\in T_{(p,q)}(M\times N)$ which corresponds (lemma~\ref{lemLeibnitz}) to $(X,Y)\in T_pM+T_qN$.

If we define $\dpt{\varphi_1}{M}{V}$ and  $\dpt{\varphi_2}{N}{V}$ by $\varphi_1(p')=\varphi(p',q)$ and $\varphi_2(q')=\varphi(p,q')$, we have the \defe{Leibnitz formula}{Leibnitz formula}:
\begin{equation}
    d\varphi(Z)=d\varphi_1(X)+d\varphi_2(Y).
\end{equation}
\end{proposition}
\begin{proof}
 Since $Z=\oX+\oY$, we just have to remark that
\[
                  d\varphi(\oX)=\dsdd{\varphi(x(t),q)}{t}{0}=d\varphi_1(X),
\]
so $d\varphi(Z)=d\varphi(\oX+\oY)=d\varphi_1(X)+d\varphi_2(Y)$.
\end{proof}
One of the most important application of the Leibnitz rule is the corollary~\ref{cor_PrincLeib} on principal bundles.

\subsection{Cotangent bundle}

A form on a vector space $V$ is a linear map $\dpt{\alpha}{V}{\eR}$. The set of all forms on $V$ is denoted by $V^*$ and is called the \defe{dual space}{dual!of a vector space} of $V$. On each point of a manifold, one can consider the tangent bundle which is a vector space. Then one can consider, for each $x\in M$ the dual space $T^*_xM:=(T_xM)^*$ which is called the \defe{cotangent bundle}{cotangent bundle}. A $1$-\defe{differential form}{differential!form} on $M$ is a smooth map $\dpt{\omega}{M}{T^*M}$ such that $\omega_x:=\omega(x)\in T^*_xM$. So, for each $x\in M$, we have a $1$-form $\dpt{\omega_x}{T_xM}{\eR}$.

Here, the smoothness is the fact that for any smooth vector field $X\in\cvec(M)$, the map $x\to\omega_x(X_x)$ is smooth as function on $M$. One often considers vector-valued forms. This is exactly the same, but $\omega_xX_x$ belongs to a certain vector space instead of $\eR$. The set of $V$-valued $1$-forms on $M$ is denoted by $\Omega(M,V)$ \nomenclature{$\Omega(M,V)$}{$V$ valued $1$-forms} and simply $\Omega(M)$ if $V=\eR$
The cotangent space $T^*_pM$ of $M$ at $p$ is the dual space of $T_pM$, i.e. the vector space of all the (real valued) linear\footnote{When we say \emph{a form}, we will always mean \emph{a linear form}.} $1$-forms on $T_pM$. In the coordinate system $\dpt{x}{\mU}{M}$, we naturally use, on $T^*_pM$, the dual basis of the basis $\{\partial/\partial_{x^i},\ldots\partial/\partial_{x^i}\}$ of $T_pM$. This dual basis is denoted by $\{dx_1,\ldots,dx_n\}$, the definition being as usual:
\begin{equation}\label{eq:dx_v}
  dx_i(\partial^j)=\delta^j_i.
\end{equation}
The notation comes from the fact that equation \eqref{eq:dx_v} describes the action of the differential of the projection $\dpt{x_i}{\mU}{\eR}$ on the vector $\partial^j$.

If $(\mU_{\alpha},\varphi_{\alpha})$ is a chart of $M$, then the maps
		\begin{equation}
		\begin{aligned}
			\phi_{\alpha} \colon \mU_{\alpha}\times\eR^n &\to T^*M\
			(x,a)&\mapsto a^idx_i|_x
		\end{aligned}
	\end{equation}
give to $T^*M$ a $2n$ dimensional manifold structure such that the canonical projection $\dpt{\pi}{T^*M}{M}$ is an immersion.

When $V$ is a finite-dimensional vector space, we denote by $V^*$ its dual\footnote{The vector space of all the linear map $V\to \eR$.} and we often use the identifications $V\simeq V^*\simeq T_vV\simeq T_wV\simeq T^*_vV$ where $v$ and $w$ are any elements of $V$. Note however that there are no \emph{canonical} isomorphism between these spaces, unless we consider some basis.

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Immersion, embedding}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}[\cite{BIBooECJTooEfmLsr}]    \label{DEFooZEWNooMVOzWI}
    A smooth map \( f\colon M\to N\) between the manifolds \( M\) and \( N\) is an \defe{immersion}{immersion} if its differential \( df_p\colon T_pM\to T_{f(p)N}\) is injective for every \( p\in M\).
\end{definition}

\begin{definition}[Topological embedding\cite{BIBooTUOOooJZFtGe}]
    Let \( X\), \( Y\) be topological spaces. A map \( f\colon X\to Y\) is a \defe{topological embedding}{topological embedding} if
    \begin{enumerate}
        \item
            \( f\) is continuous
        \item
            \( f\) is injective
        \item
            \( f\colon X\to f(X)\) is an homeomorphism when \( f(X)\) is equipped with the induced topology from \( Y\).
    \end{enumerate}
\end{definition}

\begin{definition}[Embedding\cite{BIBooTUOOooJZFtGe}]
    Let \( M\) and \( N\) be smooth manifolds. A smooth function \( f\colon M\to N\) is an \defe{embedding}{embedding} if
    \begin{enumerate}
        \item
            \( f\) is an immersion,
        \item
            \( f\) is a topological embedding.
    \end{enumerate}
\end{definition}

\begin{definition}[Tensor algebra]      \label{DEFooHPQXooETvEyn}
    Let \( V\) be a vector space over \( \eC\). The \defe{tensor algebra}{tensor algebra} of \( V\) is the vector space
    \begin{equation}
        T(V)=\bigoplus_{n\geq 0}\left(\otimes^nV\right)=\eC\oplus V\oplus(V\otimes V)\oplus\ldots
    \end{equation}
\end{definition}


%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Rank theorem}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

We proof a generalization of the rank theorem \ref{ThoGkkffA}.

\begin{definition}
    Let \( M\) and \( N\) be smooth manifolds of dimension \( m\) and \( n\). Let a smooth map \( f\colon M\to N\). The \defe{rank}{rank} of \( f\) at \( p\in M\) is the rank of the linear map \( df_p\colon T_pM\to T_{f(p)N}\).
\end{definition}

\begin{lemma}
    Let a smooth map \( f\colon M\to N\) and \( p\in M\). Let \( \varphi\colon U\to M\) and \( \psi\colon V\to N\) be chats around \( p\) and \( f(p)\). Then
    \begin{equation}
        \rang(df_p)=\rang\big( f_{\varphi^{-1}(p)}(\psi^{-1}\circ f\circ \varphi) \big)
    \end{equation}
    where the rank on the right han side is the usual rank of a map \( \eR^m\to \eR^n\).
\end{lemma}

\begin{proof}
    By proposition \ref{PROPooEGNBooIffJXc} we can compute the rank of a linear map in whatever base. When a basis is chosen in \( \eR^m\) and \( \eR^n\) we know from lemma \ref{LEMooVCSJooEuDZFz} that the matrix of \( df_p\) is the same as the one of \(  f_{\varphi^{-1}(p)}(\psi^{-1}\circ f\circ \varphi) \). Since these two linear maps have the same matrix, they have the same rank.
\end{proof}

\begin{theorem}[Rank theorem\cite{BIBooVYIRooZyqygg}]       \label{THOooSWKVooTJQsXc}
    Let \( M\) and \( N\) be smooth manifolds of dimension \( m\) and \( n\). Let \( f\colon M\to N\) be a smooth map. Let \( p\in M\). We suppose that the rank of \( f\) is equal to \( k\) at every point \( x\) in a neighbourhood of \( p\). 

    There exists charts \( \varphi\colon U\to M\) around \( p\in M\) and \( \psi\colon V\to N\) around \( f(p)\in M\) such that 
    \begin{enumerate}
        \item
            \( \varphi(0)=p\),
        \item
            \( \psi(0)=f(p)\)
        \item
            the function \( f\) is more or less trivialized in the sense that
            \begin{equation}
                (\psi^{-1}\circ f\circ\varphi)(x_1,\ldots, x_m)=(x_1,\ldots, x_k,0,\ldots, 0)
            \end{equation}
            for every \( (x_1,\ldots, x_m)\in U\).
    \end{enumerate}
\end{theorem}

\begin{proof}
    We prove in two parts. Fist we consider the case in which \( M\) and \( N\) are open sets of \( \eR^m\) and \( \eR^n\). Then we will generalize to any smooth manifolds.
    \begin{subproof}
        \item[The case of \( \eR^m\) and \( \eR^n\)]
            Let \( W\) be open in \( \eR^m\), \( W'\) be open in \( \eR^n\). We consider a smooth map \( f\colon W\to W'\) such that \( f(0)=0\) and \( \rang(f)=k\) on \( W\).

            By hypothesis, the rank of \( df_0\) is \( k\), so that is one chooses good bases on \( \eR^m\) and \( \eR^n\) we can suppose that the matrix of \( df_0\) has a upper-left square \( k\times k\) with non-zero determinant. We write \( A\) that square matrix:
            \begin{equation}
                A_{ij}=\frac{ \partial f_i }{ \partial x_j }(0)
            \end{equation}
            with \( i,j\leq k\).

            \begin{subproof}
                \item[On the \( \eR^m\) side]

                    We consider the map
                    \begin{equation}
                        \begin{aligned}
                            \varphi\colon W\subset \eR^m&\to \eR^m \\
                            (x_1,\ldots, x_m)&\mapsto \big( f_1(x_1,\ldots, x_m),\ldots, f_k(x_1,\ldots, x_m),x_{k+1},\ldots, x_m \big). 
                        \end{aligned}
                    \end{equation}
                    We have \( \varphi(0)=0\) because \( f_i(0)=f(0)_i=0\). The matrix of the differential is
                    \begin{equation}
                        d\varphi_0=\begin{pmatrix}
                            A    &   *    \\ 
                            0    &   \mtu_{n-k}    
                        \end{pmatrix}
                    \end{equation}
                    where \( A\) is \( k\times k\) and \( *\) is some \( k\times (n-k)\) matrix. Thus we have \( \det(d\varphi_0)=\det(A)\neq 0\). From the inverse function theorem \ref{ThoXWpzqCn}, the map \( \varphi\) is a local diffeomorphism, more precisely there exists an open set \( W_1\subset W\subset \eR^m\) such that the restriction
                    \begin{equation}
                        \varphi\colon W_1\to W_1
                    \end{equation}
                    is a diffeomorphism. From now on we only consider \( \varphi\) as being that restriction.

                    The vector \( (y_1,\ldots, y_m)\) such that \( \varphi^{-1}(x_1,\ldots, x_m)=(y_1,\ldots, y_m)\) has the property that
                    \begin{equation}
                        \varphi(y_1,\ldots, y_m)=(x_1,\ldots, x_m),
                    \end{equation}
                    which means that\footnote{At this point, it is really important that \( f\) takes its values in \( \eR^n\), not in a general manifold: if \( (y)\) was in a manifold, the expression \( f_i(y)\) would not make sense.}
                    \begin{equation}
                        f_i(y_1,\ldots, y_m)=x_i
                    \end{equation}
                    when \( i=1,\ldots, k\) and
                    \begin{equation}
                        y_l=x_l
                    \end{equation}
                    when \( l=k+1,\ldots, m\).

                \item[On the middle side]

                    Thus we have
                    \begin{subequations}
                        \begin{align}       \label{EQooAQJGooLqlnXJ}
                            (f\circ \varphi^{-1})(x_1,\ldots, x_m)&=f(y_1,\ldots, y_m)\\
                            &=\big( x_1,\ldots, x_k,f_{k+1}(y_1,\ldots, y_m),\ldots, f_n(y_1,\ldots, y_m) \big)\\
                            &=\big( x_1,\ldots, x_k,\tilde f_{k+1}(x),\ldots, \tilde f_n(x)\big)
                        \end{align}
                    \end{subequations}
                    where \( \tilde f_i=f_i\circ \varphi^{-1}\colon W_1\to \eR\) are some smooth functions.

                    For every \( x\in W_1\) we have
                    \begin{equation}        \label{EQooEDJIooLyPslk}
                        f(f\circ \varphi^{-1})_x=\begin{pmatrix}
                            \mtu_{k\times k}    &   0    \\ 
                            *    &   d\tilde f_x    
                        \end{pmatrix}
                    \end{equation}
                    where \( d\tilde f_x\) is the matrix whose elements are \( \left( \frac{ \partial \tilde f_i }{ \partial x_s } \right)\) with \( i=k+1,\ldots, n\) and \( s=k+1,\ldots, m\). This is not a square matrix by the way. We have, by proposition \ref{PROPooBWZFooTxKavX},
                    \begin{equation}
                        d(f\circ\varphi^{-1})_x=df_{\varphi^{-1}(x)}\circ(d\varphi^{-1})_x
                    \end{equation}
                    while \( (d\varphi^{-1})_x\) is invertible. Thus
                    \begin{equation}
                        \rang\big( d(f\circ\varphi^{-1})_x \big)=\rang\big( df_{\varphi^{-1}(x)} \big)=k.
                    \end{equation}
                    So the rank of \( f\circ\varphi^{-1}\) is \( k\) all over \( W_1\). But the image of \( d(f\circ\varphi^{-1})_x\) is spanned by the columns of its differential given by \eqref{EQooEDJIooLyPslk}. The \( k \) columns spanned by the identity matrix are obviously linearly independent; these are thus a basis of the image. Since the vectors in the ``\( d\tilde f_x\)'' part are linearly independent of these \( k\) vectors, they must be vanishing:
                    \begin{equation}
                        \frac{ \partial \tilde f_i }{ \partial x_s }(x)=0
                    \end{equation}
                    for every \( x\in W_1\), \( i=k+1,\ldots, m\) and \( s=k+1,\ldots, n\).

                \item[On the \( \eR^n\) side]

                    We do not know if \( n\geq m\) or \( m\geq n\). If \( n\geq n\), we choose \( V_1\) such that the projection of \( V_1\) on its \( m\) first components is included in \( W_1\). If \( n<m\) we choose \( V_1\) such that the projection of \( W_1\) on its \( n\) first components is included in \( V_1\)\quext{This precision about the choice of \( V_1\) is not done in \cite{BIBooVYIRooZyqygg} and seems strange to me. Am I correct ? By the way, there could be a misprint in the definition of \( T\) in \cite{BIBooVYIRooZyqygg}: \( y\) must have \( n\) components, not \( m\).}.

                    With that choice of \( V_1\) in mind we can remember the functions \( \tilde f_i\colon W_1\to \eR\). If \( y\in V_1\), we define \( \tilde f(y)\) as \( \tilde f(x)\) with \( x\in W_1\) created from \( y\) either by adding zeroes or by projecting on \( \eR^m\). In both cases, the resulting \( y\) belongs to \( V_1\).

                    So now we consider the map
                    \begin{equation}        \label{EQooKEZOooSOTBlo}
                        \begin{aligned}
                            T\colon V_1&\to \eR^n \\
                            (y_1,\ldots, y_n)&\mapsto \big( y_1,\ldots, y_k,y_{k+1}+\tilde f_{k+1}(y),\ldots, y_n+\tilde f_n(y) \big). 
                        \end{aligned}
                    \end{equation}
                    If \( y\in V_1\), the differential is the matrix given by
                    \begin{equation}
                        (dT_y)_{ij}=\frac{ \partial T_i }{ \partial y_j }(y)
                    \end{equation}
                    where
                    \begin{itemize}
                        \item 
                    The upper-left \( k\times k\) corner is \( \mtu_{k\times k}\).
                \item
                    The upper-right \( k\times (n-k)\) corner (non square in general) is given by elements of the form
                    \begin{equation}
                        \frac{ \partial y_i }{ \partial y_{j} }
                    \end{equation}
                    with \( i\leq k\) and \( j>k\). So this is vanishing.
                \item
                    The lower-left (non square in general) corner is made of
                    \begin{equation}
                        \frac{ \partial (y_i+\tilde f_i(y)) }{ \partial y_j }=\frac{ \partial \tilde f_i(y) }{ \partial y_j }
                    \end{equation}
                    with \( i>k\) and \( j\leq k\). The elements in this pars are some numbers.
                \item
                    The lower-right square \( (n-k)\times (n-k)\) corner is made of
                    \begin{equation}
                        \frac{ \partial (y_i+\tilde f_i(y)) }{ \partial y_j }=\delta_{ij}+\frac{ \partial \tilde f_i }{ \partial y_j }
                    \end{equation}
                    with \( i>k\) and \( j\geq k\). For these elements we have \( \frac{ \partial \tilde f_i(y) }{ \partial y_j }=0\) and then the identity matrix.
                    \end{itemize}
                    With all that,
                    \begin{equation}
                        dT_y=\begin{pmatrix}
                            \mtu_{k\times k}    &   0    \\ 
                            *    &   \mtu_{n-k}    
                        \end{pmatrix}.
                    \end{equation}
                    Moreover \( T(0)=0\) because
                    \begin{equation}
                        \tilde f_i(0)=f_i\big( \varphi^{-1}(0) \big)=f_i(0)=0.
                    \end{equation}
                    We deduce that there exist an open set \( V\subset \eR^n\) included in \( V_1\) such that \( T\colon V\to T(V)\) is a diffeomorphism. We restrict \( V\) in such a way that \( T(V)\subset V_1\).

                \item[The final map]

                    Finally we consider the map
                    \begin{equation}
                        T^{-1}\circ f\circ \varphi^{-1}\colon W_1 \to V.
                    \end{equation}
                    If \( (x_1,\ldots, x_m)\in W_1\) from \eqref{EQooAQJGooLqlnXJ} we have
                    \begin{equation}
                        (f\circ \varphi^{-1})(x_1,\ldots, x_m)=\big( x_1,\ldots, x_k,\tilde f_{k+1}(x),\ldots, \tilde f_n(x) \big).
                    \end{equation}
                    Using the definition \eqref{EQooKEZOooSOTBlo} we see that
                    \begin{equation}
                        T(x_1,\ldots, x_k,0,\ldots, 0)=\big( x_1,\ldots, x_k,\tilde f_{k+1}(x),\ldots, \tilde f_n(x) \big)
                    \end{equation}
                    which proves that
                    \begin{equation}
                        T^{-1}\big( x_1,\ldots, ,x_k,\tilde f_{k+1}(x),\ldots, \tilde f_n(x) \big)=(x_1,\ldots, x_k,\,\ldots, 0).
                    \end{equation}
            \end{subproof}

        \item[The general case]

            Now we consider the manifolds \( M\) and \( N\) with the map \( f\colon M\to N\). Let \( p\in M\) and charts \( \varphi_0\colon U_0\to M\), \( \psi_0\colon V_0\to N\) where \( U_0\) is a neighbourhood of \( 0\) in \( \eR^m\) and \( V_0\) a neighbourhood of \( 0\) in \( \eR^n\). We suppose that \( \varphi_0(0)=p\) and \( \psi_0(0)=f(p)\).

            Now we consider the function \( \tilde f=\psi_0^{-1}\circ f\circ \varphi_0\) from \( U_0\) to \( V_0\) and we are left in the previous case.
    \end{subproof}
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Exterior calculus}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%---------------------------------------------------------------------------------------------------------------------------
\subsection{The exterior algebra}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}[Exterior product]
    If $V$ is a vector space, we denote by $\Lambda^kV^*$ the space of all the $k$-form on $V$. We define the \defe{exterior product}{product!exterior} $\dpt{\wedge}{\Lambda^kV^*\times\Lambda^lV^*}{\Lambda^{k+l}V^*}$ by
    \begin{equation}
      (\omega^k\wedge\eta^l)(v_1,\ldots,v_{k+l})
      =\us{k!l!}\sum_{\sigma\in S_{k+l}} (-1)^{\sigma}   \omega(v_{\sigma(1)},\ldots,v_{\sigma(k)})\eta(v_{\sigma(k+1)},v_{\sigma(k+1)})
    \end{equation}
\end{definition}
If $\{e_1,\ldots,e_n\}$ is a basis of $V$, the dual basis $\{\sigma^1,\ldots,\sigma^n\}$ of $V^*$ is defined by $\sigma^i(e_j)=\delta^i_j$.

If $I=\{1\leq i_1\leq\ldots i_k\leq n\}$, we write $\sigma^I=\sigma^{i_1}\wedge\ldots\sigma^{i_k}$ any $k$-form can be decomposed as
\[
  \omega=\sum_{I}\omega_I\sigma^I.
\]
The exterior algebra is provided with the \defe{interior product}{interior!product} denoted by $\iota$. It is defined by\label{pg_DefProdExt}
\begin{equation}
\begin{aligned}
 \iota(v_0)\colon\Lambda^kW&\to \Lambda^{k-1}W \\
(\iota(v_0)\omega)(v_1,\ldots,v_{k-1})& =\omega(v_0,v_1,\ldots,v_{k-1}).
\end{aligned}
\end{equation}

\begin{lemma}
    Let \( \sigma\) be an element of the symmetric group\footnote{Definition~\ref{DEFooJNPIooMuzIXd}.} of the set \( \{ a_1,\ldots, a_n \}\) where the \( a_i\) are integers. Then
    \begin{equation}
        (dx_{a_1}\wedge\ldots \wedge dx_{a_n})(e_{\sigma(a_1)},\ldots, e_{\sigma(a_n)})=(-1)^{\sigma}.
    \end{equation}
\end{lemma}

\begin{proof}
    We make it by induction over \( n\). With \( n=1\) the only permutation is the identity; the claim reduces to \( dx_{a_1}(e_{a_1})=1\). Let us try with \( n=2\). Up to renumbering we have
    \begin{equation}
        (dx_1\wedge dx_2)(e_1,e_2)=1
    \end{equation}
    and
    \begin{equation}
        (dx_1\wedge dx_2)(e_2,e_1)=-1.
    \end{equation}
    We pass to the induction. Let \( \sigma\in S_n\). We have
    \begin{subequations}
        \begin{align}
            (dx_{a_1}\wedge dx_{a_n})(&e_{\sigma(a_1)},\ldots, e_{\sigma(a_n)})=dx_{a_1}\wedge (dx_{a_n})(e_{\sigma(a_1)},\ldots, e_{\sigma(a_n)})\\
            &=\sum_{\phi\in S_n}(-1)^{\phi}\frac{1}{ (n-1)! }dx_{a_1}\big( e_{\phi\sigma(a_1)} \big)(dx_{a_2}\wedge\ldots\wedge dx_{a_n})(e_{\phi\sigma(a_2)},\ldots, e_{\phi\sigma(a_n)})\\
            &=\sum_{\phi\in S_n}(-1)^{\phi}\frac{1}{ (n-1)! }\delta_{a_1,\phi\sigma(a_1)}(-1)^{\phi\sigma}\\
            &=\sum_{\phi\in S_n}\delta_{a_1,\phi\sigma(a_1)}(-1)^{\sigma}\frac{1}{ (n-1)! }
        \end{align}
    \end{subequations}
    where we used the fact that the sign of a permutation provides a morphism between \( S_n\) and \( \{ -1,1 \}\) (proposition~\ref{ProphIuJrC}\ref{ITEMooBQKUooFTkvSu}). In the sum over \( S_n\), only the \( \phi\) that make \( \sigma(a_1)\to a_1\) remain; there are \( | S_{n-1} |=(n-1)!\) such elements. Thus the whole evaluates to \( (-1)^{\sigma}\).
\end{proof}

\begin{lemma}[\cite{MonCerveau}]    \label{LEMooICRXooFKPCRd}
    Let \( \tau_i\colon \eR^n\to \eR^{n-1}\) defined by
    \begin{equation}
        \tau_i(v)_k=\begin{cases}
            v_k    &   \text{if } k<i\\
            v_{k+1}    &    \text{if } k\geq i\text{.}
        \end{cases}
    \end{equation}
    Then we have
    \begin{equation}
        (dx_1\wedge\ldots\wedge\widehat{dx_i}\wedge\ldots\wedge dx_n)(v_1,\ldots, \widehat{v_i},\ldots, v_n)=
        \det\Big(  \tau_i(v_1),\ldots, \widehat{\tau_i(v_i)},\ldots, \tau_i(v_n)  \Big)
    \end{equation}
    where the hat denotes a non present term.
\end{lemma}

\begin{proof}
    We extend \( \tau_i\) to the dual : \( \tau_i\colon(\eR^n)^*  \to (\eR^{n-1})^*\) is defined by
    \begin{equation}
        \tau_i(dx_k)=\begin{cases}
            dy_k    &   \text{if } k<i\\
            dy_{k-1}    &    \text{if } k>i
        \end{cases}
    \end{equation}
    (not defined on \( dx_i\)). It is easy to check that, if \( k\neq i\),
    \begin{equation}
        \tau_i(dx_k)\tau_i(v)=dx_k(v).
    \end{equation}
    The value of  $(dx_1\wedge\ldots\wedge\widehat{dx_i}\wedge\ldots\wedge dx_n)(v_1,\ldots, \widehat{v_i},\ldots, v_n)$ is a polynomial in the variables \( dx_k(v_l)\) (with \( k\neq l\)). Since \( dx_k(v_l)=\tau\i(dx_k)\big( \tau_iv_l \big)\), the same polynomial will give the value of
    \begin{equation}
        (\tau_idx_1\wedge\ldots\wedge \widehat{\tau_idx_i}\wedge\ldots\wedge \tau_idx_n  )(\tau_i v_1,\ldots, \widehat{\tau_iv_i},\ldots, \tau_iv_n).
    \end{equation}
    Thus we have
    \begin{subequations}
        \begin{align}
            (dx_1\wedge\ldots\wedge\widehat{dx_i}&\wedge\ldots\wedge dx_n)(v_1,\ldots, \widehat{v_i},\ldots, v_n)\\
            &=(\tau_idx_1\wedge\ldots\wedge \widehat{\tau_idx_i}\wedge\ldots\wedge \tau_idx_n  )(\tau_i v_1,\ldots, \widehat{\tau_iv_i},\ldots, \tau_iv_n)\\
            &=(dy_1\wedge\ldots\wedge dy_{n-1})(\tau_iv_1,\ldots,\widehat{\tau_iv_i},\ldots, \tau_iv_n) \label{SUBEQooQGSKooSgfxJh}\\
            &=\det\big( \tau_iv_1,\ldots, \widehat{\tau_i v_i},\ldots, \tau_iv_n \big)
        \end{align}
    \end{subequations}
    The last equality is because \eqref{SUBEQooQGSKooSgfxJh} is is a \( (n-1)\)-form applied to \( n-1\) vectors in \( \eR^{n-1}\) and so is the determinant.
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Differential of \texorpdfstring{$k$}{k}-forms}
%---------------------------------------------------------------------------------------------------------------------------

The differential of a $k$-form is defined by the following theorem.

\begin{theorem}
Let $M$ be a differentiable manifold. Then for each $k\in \eN$, there exists an unique map
\[
  \dpt{d}{\Omega^k(M)}{\Omega^{k+1}(M)}
\]
such that

\begin{enumerate}
\item $d$ is linear,
\item for $k=0$, we find back the $\dpt{d}{\Cinf(M)}{\Omega^1(M)}$ previously defined,
\item if $f$ is a function and $\omega^k$ a $k$-form, then
\begin{equation}
d(f\omega^k)=df\wedge\omega^k+fd\omega^k,
\end{equation}


\item $d(\omega^k\wedge\eta^l)=d\omega^k\wedge\eta^l+(-1)^k\omega^k\wedge d\eta^l$,
\item $d\circ d=0$.
\end{enumerate}
\end{theorem}

An explicit expression for $d\omega^k$ is actually given by
\begin{equation}
   d\omega^k=\sum d\omega_I\wedge dx^I
\end{equation}
if $\omega^k=\sum\omega_I dx^I$.
An useful other way to write it is the following. If $\omega$ is a $k$-form and $X_1,\ldots,X_{p+1}$ some vector fields,
\begin{equation}\label{eq:formule_domega}
\begin{split}
  (k+1)d\omega(X_1,\ldots,X_{p+1})&=\sum_{i=1}^{p+1}(-1)^{i+1}X_i\omega(X_1,\ldots\hat{X}_i,\ldots,X_{p+1})\\
                                  &\quad+\sum_{i<j}(-1)^{i+j}\omega([X_i,X_j],X_1,\ldots,\hX_i,\hX_j,\ldots,X_{p+1}).
\end{split}
\end{equation}
Let us show it with $p=1$. Let $\omega=\omega_i dx^i$ and compute $d\omega(X,Y)=\partial_i\omega_j(dx^i\wedge dx^j)(X,Y)$. For this, we have to keep in mind that the $\partial_i$ acts only on $\omega_j$ while, in equation \eqref{eq:formule_domega}, a term $X\omega(Y)$ means --pointwise-- the action of $X$ on the function $\dpt{\omega(Y)}{M}{\eR}$. So we have to use Leibnitz formula:
\[
  (\partial_i\omega_j)X^iY^j=(X\omega_j)Y^j
                            =X(\omega_j Y^j)-\omega_j XY^j.
\]
On the other hand, we know that $[X,Y]^i=XY^i-YX^i$, so
\begin{equation}
   d\omega(X,Y)=X\omega(Y)-Y\omega(X)-\omega([X,Y]).
\end{equation}

\subsubsection{Hodge dual operator}
%/////////////////////////////
Let us take a manifold $M$ endowed with a metric $g$.  We can define a map $\dpt{r}{T^*_xM}{T_xM}$ by, for $\alpha\in T^*_xM$,
\[
   \scal{r(\alpha)}{v}=\alpha(v).
\]
for all $v\in T_xM$, where $\scal{\cdot}{\cdot}$ stands for the product given by the metric $g$. If we have $\alpha,\beta\in T^*_xM$, we can define
\[
   \scal{\alpha}{\beta}=\scal{r(\alpha)}{r(\beta)}.
\]
With this, we define an inner product on $\Lambda^p(T^*_xM)$:
\[
   \scal{\alpha_1\wedge\ldots\alpha_p}{\beta_1\wedge\ldots\beta_p}=\det_{ij}\scal{\alpha_i}{\beta_j}.
\]

\begin{definition}      \label{DEFooUOJQooSzKjNR}
    The \defe{Hodge operator}{Hodge operator} is $\dpt{\hodge}{\Lambda^p(T^*_xM)}{\Lambda^{n-p}(T^*_xM)}$ such that for any $\phi\in\Lambda^p(T^*_xM)$,
    \begin{equation}
       \phi\wedge(\hodge\psi)=\scal{\phi}{\psi}\Omega=\langle \phi,\psi \rangle\sqrt{|\det(g)|}dx^1\wedge\ldots\wedge dx^n.
    \end{equation}
\end{definition}

\begin{example} \label{EXooCIYIooFPMLMU}
    We consider \( \eR^n\) with the euclidian metric. If \( \sigma=dx_j\), then we expect \( \hodge\sigma\) to be \( sdx_1\wedge\ldots\wedge \widehat{dx_j}\wedge\ldots\wedge dx_n\) for a certain factor \( s\) to be fixed (something like \( (-1)^j\)).

    For every \( 1\)-form \( \phi\) we need \( \phi\wedge(\hodge \sigma)=\langle \phi, \sigma\rangle dx_1\wedge\ldots\wedge dx_n\). A basis of \( \Wedge^1(TM)\) is \( \{ dx_k \}_{k=1,\ldots, n}\), so we test on \( dx_k\).

    First we have
    \begin{equation}
        \langle dx_k, dx_j\rangle =\langle e_k, e_j\rangle =\delta_{kj}.
    \end{equation}
    Then
    \begin{equation}
        s\,dx_k\wedge dx_1\wedge\ldots\wedge \widehat{dx_j}\wedge\ldots\wedge dx_n=s\delta_{kj}(-1)^{j+1}dx_1\wedge\ldots\wedge dx_n.
    \end{equation}
    Thus we need \( s=(-1)^{j+1}\) and we have
    \begin{equation}
        \hodge dx_j=(-1)^{j+1}dx_1\wedge\ldots\wedge \widehat{dx_j}\wedge\ldots\wedge dx_n.
    \end{equation}
\end{example}

\subsubsection{Volume form and orientation}
%//////////////////////////////////////////

Let $M$ be a $n$ dimensional smooth manifold. A \defe{volume form}{volume!form} on $M$ is a nowhere vanishing $n$-form and the manifold itself is said to be \defe{orientable}{orientable manifold} if such a volume form exists. Two volume forms $\mu_1$ and $\mu_2$ are describe the same orientation if there exists a function $f>0$ such that\footnote{Recall that the space of $n$-forms is one-dimensional.} $\mu_1=f\mu_2$.

\begin{proposition}
There exists only two orientations on a connected orientable manifold.
\end{proposition}
\begin{probleme}
    Check if the statement of that proposition is correct. Find a reference.
\end{probleme}

One says that the \emph{ordered} basis $(v_1,\cdots,v_n)$ of $T_xM$ is \defe{positively oriented}{positive!orientation} with respect to the volume form $\mu$ is $\mu_x(v_1,\cdots,v_n)>0$.

\subsection{Musical isomorphism}\label{subsec_musique}\index{musical isomorphism}
%---------------------------------

In some literature, we find the symbols $v^{\flat}$ and $\alpha^{\sharp}$. What does it mean ? For $X\in\cvec(M)$ and $\omega\in\Omega^2(M)$, the \defe{flat}{flat} operation $v^{\flat}\in\Omega^1(M)$ is simply defined by the inner product:
\begin{equation}        \label{EQooBTWXooTqoNxa}
  v^{\flat}=i(v)\omega
\end{equation}
 In the same way, we define the \defe{sharp}{sharp} operation by taking a $1$-form $\alpha$ and defining $\alpha^{\sharp}$ by
\begin{equation}
   i(\alpha^{\sharp})\omega=\alpha.
\end{equation}
An immediate property is, for all $v\in\cvec(M)$, $v^{\flat\sharp}=v$, and for all $\alpha\in\Omega^1(M)$, $\alpha^{\sharp\flat}=\omega$.

\subsection{Pull-back and push-forward}

\begin{normaltext}
Let $\dpt{\varphi}{M}{N}$ be a smooth map, $\alpha$ a $k$-form on $N$, and $Y$ a vector field on $N$. Consider the map $\dpt{d\varphi}{T_xM}{T_{\varphi(x)}M}$. The aim is to extend it to a map from the tensor algebra\footnote{Definition \ref{DEFooHPQXooETvEyn}} of ${T_xM}$ to the one of $T_{\varphi(x)}M$.
\end{normaltext}

The \defe{pull-back}{pull-back!of a $k$-form} of $\varphi$ on a $k$-form $\alpha$ is the map
\[
 \dpt{\varphi^*}{\Omega^k(N)}{\Omega^k(M)}
\]
 defined by
\begin{equation}\label{306e1}
 (\varphi^*\alpha)_m(v_1,\ldots,v_k)
 =\alpha_{\varphi(m)}(d\varphi_mv_1,\ldots,d\varphi_mv_k)
\end{equation}
for all $m\in M$ and $v_i\in\cvec(M)$.

Note the particular case $k=0$. In this case, we take --instead of $\alpha$-- a function $\dpt{f}{N}{\eR}$ and the definition \eqref{306e1} gives $\dpt{\varphi^*f}{M}{\eR}$ by
\[
     \varphi^*f=f\circ\varphi.
\]

The \defe{push-forward}{push-forward!of a $k$-form} of $\varphi$ on a $k$-form is the map
\[
 \dpt{\varphi_*}{\Omega^k(M)}{\Omega^k(N)}
\]
defined by $\varphi_*=(\varphi^{-1})^*$. For $v\in T_nN$, we explicitly have:
\[
                   (\varphi_*\alpha)_n(v)=\alpha_{\varphi^{-1}(n)}(d\varphi_n^{-1} v).
\]

Let now $\dpt{\varphi}{M}{N}$ be a diffeomorphism. The \defe{pull-back}{pull-back!of a vector field} of $\varphi$ on a vector field is the map
\[
           \dpt{\varphi^*}{\cvec(N)}{\cvec(M)}
\]
defined by
\[
              (\varphi^*Y)(m)=[(d\varphi^{-1})_m\circ Y\circ\varphi](m),
\]
or
\[
 (\varphi^*Y)_{\varphi^{-1}(n)}=(d\varphi^{-1})_nY_n,
\]
for all $n\in N$ and $m\in M$. Notice that \[\dpt{(d\varphi^{-1})_n}{T_nN}{T_{\varphi^{-1}(n)}M},\] and that  $\varphi^{-1}(n)$ is well defined because $\varphi$ is an homeomorphism.

The \defe{push-forward}{push-forward!of a vector field} is, as before, defined by $\varphi_*=(\varphi^{-1})^*$. In order to show how to manipulate these notations, let us prove the following equation:
\[
   f_{*\xi}=(df)_{\xi}.
\]
For $\dpt{\varphi}{M}{N}$ and $Y$ in $\cvec(N)$, we just defined $\dpt{\varphi^*}{\cvec(N)}{\cvec(M)}$, by
\begin{eqnarray}
 \label{2112r1}(\varphi^*Y)_{\varphi^{-1}(n)}=(d\varphi^{-1})_nY_n.
\end{eqnarray}
Take $\dpt{f}{M}{N}$; we want to compute $f_*=(f^{-1})^*$ with $\dpt{(f^{-1})^*}{\cvec(M)}{\cvec(N)}$. Replacing the ``$^{-1}$``\ on the right places, the definition \eqref{2112r1} gives us
\[
 \Big[(f^{-1})^*X\Big]_{f(m)}=(df)_mX_m,
\]
if $X\in\cvec(M)$, and $m\in M$.

We can rewrite it without  any indices: the coherence of the spaces automatically impose the indices: $(f^{-1})^*X=(df)X$. It can also be rewritten as $(f^{-1})^*=df$, and thus $f_*=df$. From there to $f_{* \xi}=(df)_{\xi}$, it is straightforward.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Submanifold}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{definition}      \label{DEFooLQHWooMOTgzq}
    If $M$ is a differentiable manifold and $N$, a subset of $M$, we say that $N$ is a \defe{submanifold}{submanifold} of dimension $k$ if $\forall\,p\in N$, there exists a chart $\dpt{\varphi}{\mU}{M}$ around $p$ such that
    \begin{equation}
       \varphi^{-1}(\varphi(\mU)\cap N)=\eR^k\cap\mU:=\{(x_1,\ldots,x_k,0\ldots,0)\in\mU\}.
    \end{equation}
\end{definition}

\begin{lemma}
    If \( N\) is a submanifold of the manifold \( M\), then \( N\) is a manifold for its own.
\end{lemma}

\begin{definition}
    Let us consider $M$ and $N$, two differentiable manifolds, $\dpt{f}{M}{N}$ a $\Cinf$ map and $x\in M$. We say that $f$ is an \defe{immersion}{immersion} at $x$ if $\dpt{df_x}{T_xM}{T_{f(x)}N}$ is injective and that $f$ is a \defe{submersion}{submersion} if $df_x$ is surjective.
\end{definition}

\begin{proposition}
Let $M$ be a submanifold of the manifold $N$. If $p\in M$, then there  exists a coordinate system $\{x_1,\ldots,x_n\}$ on a neighbourhood of $p$ in $N$ such that $x_1(p)=\ldots=x_n(p)=0$ and such that the set
\[
   U=\{q\in V\tq x_j(q)=0\,\forall\, m+1\leq j\leq n\}
\]
gives a local chart of $M$ containing $p$.
\label{prop:var_coord}
\end{proposition}

\begin{proof}
No proof.
\end{proof}

The sense of this proposition is that one can put $p$ at the center of a coordinate system on $N$ such that $M$ is just a submanifold of $N$ parametrised by the fact that its last $m-n$ components are zero.

Now we can give a characterization for a submanifold: $N$ is a submanifold of $M$ when $N\subset M$ (as set) and the identity $\dpt{\iota}{N}{M}$ is regular.\label{pg:caract_subvar}

\begin{proposition}
The own topology of a submanifold is finer than the induced one from the manifold.
\label{prop:topo_sub_manif}
\index{topology!on submanifold}
\end{proposition}

\begin{proof}
Let $M$ be a manifold of dimension $n$ and $N$ a submanifold\footnote{In the whole proof, we should say ``there exists a sub-neighbourhood such that\ldots``} of dimension $k<n$. We consider $V$, an open subset of $N$ for the induced topology, so $V=N\cap\mO$ for a certain open subset $\mO$ of $M$. The aim is to show that $V$ is an open subset in the topology of $N$.

Let us define $\mP=\varphi^{-1}(\mO)$.  The charts of $N$ are the projection to $\eR^k$ of the ones of $M$. We have to consider $W=\varphi^{-1}(V)$, since $N$ is a submanifold, $\varphi^{-1}(\mO\cap N)=\eR^k\cap\mP$. It is clear that $W=\eR^k\cap\mP$ is an open subset of $\eR^k$ because it is the projection on the $k$ first coordinates of an open subset of $\eR^n$.

The subset $V$ of $N$ will be open in the sense of the own topology of $N$ if $\varphi'{}^{-1}(V\cap\varphi'(\mU'))$ is open in $\eR^k$ where $\varphi'$ is the restriction of $\varphi$ to his $k$ first coordinates: $\varphi'(a)=\varphi(a,0)$ and $\mU'$ is the projection of $\mU$.
\end{proof}


\begin{lemma}
Let $V,M$ be two manifolds and $\varphi\colon V\to M$, a differentiable map. We suppose that $\varphi(V)$ is contained in a submanifold $S$ of $M$. If $\dpt{\varphi}{V}{S}$ is continuous, then it is differentiable.
\label{lem:var_cont_diff}
\end{lemma}

\begin{remark}
The map $\varphi$ is certainly continuous as map from $V$ to $M$ (this is in the assumptions). But this don't imply that it is continuous for the topology on $S$ (which is the induced one from $M$). So the continuity of $\dpt{\varphi}{V}{S}$ is a true assumption.
\end{remark}

\begin{proof}
Let $p\in V$. By proposition~\ref{prop:var_coord}, we have  a coordinate system $\{x_1,\ldots,x_m\}$ valid on a neighbourhood $N$ of $\varphi(p)$ in $M$ such that the set
\[
  \{r\in N\tq x_j(r)=0\, \forall s<j\leq m  \}
\]
with the restriction of $(x_1,\ldots x_s)\in N_S$ form a local chart which contains $\varphi(p)$. From the continuity of $\varphi$, there exists a chart $(W,\psi)$ around $p$ such that $\varphi(W)\subset N_S$. The coordinates $x_j(\varphi(q))$ are differentiable functions of  the coordinates of $q$ in $W$. In particular, the coordinates $x_j(\varphi(q))$ for $1\leq j\leq s$ are differentiable and $\dpt{\varphi}{V}{S}$ is differentiable because its expression in a chart is differentiable.
\end{proof}

A consequence of this lemma: if $V$ and $S$ are submanifolds of $M$ with $V\subset S$, and if $S$ has the induced topology from $M$, then $V$ is a submanifold of $S$. Indeed, we can consider the inclusion $\dpt{\iota}{V}{S}$: it is differentiable from $V$ to $M$ and continuous from $V$ to $S$ then it is differentiable from $V$ to $S$ by the lemma. Thus $V=\iota^{-1}(S)$ is a submanifold of $S$ (this is a classical result of differential geometry).

\begin{proposition}
A submanifold is open if and only if it has the same dimension as the main manifold.
\label{prop:subvar_ouvert}
\end{proposition}

\begin{proof}
\subdem{Necessary condition}
We consider some charts $\dpt{\varphi_i}{U_i}{M}$ on some open subsets $U_i$ of $\eR^n$. If $N$ is open in $M$, then this can be written as
\[
  N=\bigcup_iU_i.
\]
If we choose the charts on $M$ in such a manner that $\dpt{\varphi_i}{U_i\cap \eR^k}{N}$ are charts of $N$, we must have $\varphi_i(U_i\cap\eR^k)=\varphi_i(U_i)$. Then it is clear that $k=n$ is necessary.
\subdem{Sufficient condition}
If $N$ has same dimension as $M$, the charts $\dpt{\varphi_i}{U_i}{M}$ are trivially restricted to $N$.
\end{proof}

The following result allow to extend a smooth function defined on a submanifold to an open set of the «larger» manifold. 
\begin{proposition}     \label{PROPooOTZQooIfboXV}
    Let \( N\) be a submanifold of \( M\) and \( f\in  C^{\infty}(N)\). Let \( p\in N\). There exists a neighbourhood \( W\) of \( p\) in \( M\) and a function \( \tilde f\in  C^{\infty}(W)\) such that
    \begin{equation}
        \tilde f(n)=f(n)
    \end{equation}
    for every \( n\in N\).
\end{proposition}

\begin{proof}
    Since \( N\) is a submanifold of \( M\), the definition \ref{DEFooLQHWooMOTgzq} provides a chart \( \varphi\colon U\to M\) around \( p\) such that 
    \begin{equation}
        \varphi^{-1}\big( \varphi(U)\cap N \big)=\{ (x_1,\ldots, x_n,0,\ldots, 0) \}.
    \end{equation}
    From the function \( f\colon N\to \eR\) we consider 
    \begin{equation}
        \begin{aligned}
            f_1\colon \varphi^{-1}\big( \varphi(U)\cap N \big)&\to \eR \\
            f_1&=f\circ\varphi
        \end{aligned}
    \end{equation}
    This is the function \( f\) seen trough the chart. The function \( f_1\) is only defined on the ``\( N\)'' part of the chart, but can be extended as
    \begin{equation}
        \begin{aligned}
            \tilde f_1\colon U&\to \eR \\
            (x_1,\ldots, x_m)&\mapsto f_1(x_1,\ldots, x_n,0,\ldots, 0), 
        \end{aligned}
    \end{equation}
    which is a good definition since \( (x_1,\ldots, x_n,0,\ldots, 0)\) is in \( \varphi^{-1}\big( \varphi(U)\cap N \big)\).

    Finally we write
    \begin{equation}
        \begin{aligned}
            \tilde f\colon \varphi(U)&\to \eR \\
            \tilde f&=\tilde f_1\circ\varphi^{-1}.
        \end{aligned}
    \end{equation}
    This is the extension we are searching for. Indeed it is defined on \( \varphi(U)\) which is an open set in \( M\) which contains \( p\) and if \( q\in N\cap\varphi(U)\) we have \( q=\varphi(x_1,\ldots, x_n,0,\ldots, 0)\) and then
    \begin{subequations}
        \begin{align}
            \tilde f(q)&=(\tilde f_\circ\varphi^{-1})\varphi(x_1,\ldots, x_n,0,\ldots, 0)\\
            &=\tilde f_1(x_1,\ldots, x_n,0,\ldots, 0)\\
            &=f_1(x_1,\ldots, x_n,0,\ldots, 0)\\
            &=(f\circ\varphi)(x_1,\ldots, x_n,0,\ldots, 0)\\
            &=f(q).
        \end{align}
    \end{subequations}
    Thus \( \tilde f=f\) on \( \varphi(U)\cap N\).
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Partition of unity}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


\begin{definition}[\cite{ooQCDSooCpqDvB}]       \label{DEFooKFXLooFRLaBG}
    Let \( X\) be a topological space. A \defe{partition of unity}{partition!of unity} of \( X\) is a family of continuous functions \( \{ \psi_j \}_{j\in J}\) such that
    \begin{enumerate}
        \item
            \( \psi_j\colon X\to \mathopen[ 0 , 1 \mathclose]\);
        \item
            for every \( x\in X\) there exists a neighbourhood of \( x\) in \( X\) in which only a finite number of the \( \psi_j\)'s is non zero;
        \item
            for every \( x\in X\) we have
            \begin{equation}
                \sum_{j\in J}\psi_j(x)=1.
            \end{equation}
    \end{enumerate}
\end{definition}

\begin{definition}[\cite{ooQCDSooCpqDvB}]
    Let \( X\) be a topological space and \( \{ U_i \}_{i\in I}\) be a locally finite covering of \( X\). A partition of unity is \defe{subordinate}{partition!of unity!subordinate} to that covering if it is indexed by \( I\) (\( J=I\) in the definition~\ref{DEFooKFXLooFRLaBG}) and such that \( \supp(\psi_i)\subset U_i\) for every \( i\in I\).
\end{definition}

\begin{theorem}[\cite{ooQCDSooCpqDvB}]      \label{THOooPCHDooITWKpC}
    Let \( \Omega\) be an open set in \( \eR^d\) and \( \{ U_i \}_{i\in I}\) be an open covering of \( \Omega\). There exists
    \begin{enumerate}
        \item
            a \(  C^{\infty}\) partition of unity \( \{ \psi_j \}_{j\in J}\) such that \( \supp(\psi_j)\) is compact in one of the \( U_i\);
        \item       \label{ITEMooFGMJooQPLqGY}
            a \(  C^{\infty}\) partition of unity \( \{ \alpha_i \}_{i\in I}\) subordinated to the covering, such that for every compact \( K\) only a finite number of these \( \psi_i\)'s is non zero.
    \end{enumerate}
\end{theorem}

\begin{remark}
    This theorem does not furnish a smooth compactly supported partition of unity subordinated to the given covering. Either you choose the partition to be compactly supported, either you choose them subordinated to the covering.
\end{remark}

\begin{corollary}  \label{CORooMSWPooCxvuhm}
    If \( \Omega\) is bounded and \( \{U_i \}_{i\in I}\) is an open covering of \( \Omega\), there exists a partition of unity subordinated to \( \{ U_i \}_{i\in I}\) such that each \( \psi_i\) belongs to \( \swD(U_i)\).
\end{corollary}

\begin{proof}
    If \( \Omega\) is bounded in \( \eR^d\) we can consider \( U'_i=U_i\cap \Omega\) and use the point~\ref{ITEMooFGMJooQPLqGY} of theorem~\ref{THOooPCHDooITWKpC} for the covering \( \{ U'_i \}_{i\in I}\). So we have a partition of unity subordinated to that covering with supports in the \( U'_i\)'s. Since the support is closed and the \( U_i\)'s are bounded, the supports are compact. The functions of this partition of unity are also subordinated to the original \( U_i\)'s.
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Integration of a differential form}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Open set in \( \eR^n\)}
%---------------------------------------------------------------------------------------------------------------------------

Let \( U\) be an open set of \( \eR^n\). A differential form of degree \( n\) over \( U\) can always be written under the form
\begin{equation}
    \omega_x=f(x)dx_1\wedge\ldots\wedge dx_n;
\end{equation}
this is proposition~\ref{ProprbjihK}.

\begin{definition}      \label{DEFooEYRFooRQTmRF}
    The integral of \( \omega\) on \( U\) is
    \begin{equation}
        \int_{U}f\,dx_1\wedge\ldots\wedge dx_n=\int_Uf
    \end{equation}
    The second integral is the integral of a function on \( \eR^n\), that is definition~\ref{DefTVOooleEst} where the measure is the Lebesgue measure on \( \eR^n\).
\end{definition}

\begin{lemma}[Change of variable]       \label{LEMooNCYSooXtnCKq}
    Let \( f\colon V\to U\) be a diffeomorphism of open sets in \( \eR^n\) and \( \omega\) be a \( n\)-form on \( U\). Then we have
    \begin{equation}
        \int_U\omega=\int_{f^{-1}(U)}f^*\omega
    \end{equation}
    if \( \det(f)>0\). A sign change if \( \det(df)<0\).
\end{lemma}

\begin{proof}
    Let, for \( y\in U\), write the form \( \omega\) as \( \omega_y=h(y)dy_1\wedge\ldots\wedge dy_n\). Taking \( v_i\in \Gamma(TV)\) we have
    \begin{subequations}
        \begin{align}
            (f^*\omega)_x(v_1,\ldots, v_n)&=\omega_{f(x)}\big( df_xv_1,\ldots, df_xv_n \big)\\
            &=h\big( f(x) \big)\det\begin{pmatrix}
                df_xv_1    \\
                \vdots    \\
                df_xv_n
            \end{pmatrix}\\
            &=(h\circ f)(x)\det(df_x)\det\begin{pmatrix}
                v_1    \\
                \vdots    \\
                v_n
            \end{pmatrix}\\
            &=(h\circ f)(x)\det(df_x)(dx_1\wedge\ldots\wedge dx_n)(v_1,\ldots, v_n).
        \end{align}
    \end{subequations}
    Thus
    \begin{equation}
        f^*\omega= (h\circ f)\det(df)dx_1\wedge\ldots\wedge dx_n
    \end{equation}
    Using the usual change of variable theorem~\ref{THOooUMIWooZUtUSg}\ref{ITEMooAJGDooGHKnvj} (and taking a sign if \( \det(df)<0\) because there is an absolute value in around the jacobian in \eqref{EQooLYAWooTArAZR}) :
    \begin{equation}
        \int_{f^{-1}(U)}f^*\omega=\int_V(h\circ f)\det(df)=\int_{f(V)}h=\int_Uh=\int_U\omega.
    \end{equation}
\end{proof}

That is for integrating a differential form on an open set of \( \eR^n\). In order to integrate on a manifold we ``simply'' use a pull-back with a chart system. There will be three complications
\begin{itemize}
    \item If an atlas is made from more than one chart, what about the intersections ?
    \item Independence with respect to the choice of the chart.
    \item Integrating a vector field (that is not obviously a \( n\)-form).
\end{itemize}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{One chart on a manifold}
%---------------------------------------------------------------------------------------------------------------------------

We suppose \( (M,g)\) to be a \( n\)-dimensional Riemannian manifold and \( S\) to be a \( (n-1)\)-dimensional submanifold. We suppose that both are inside only one chart
\begin{equation}
    \phi\colon U\subset \eR^n\to M
\end{equation}
and
\begin{equation}
    \varphi\colon A\subset \eR^{n-1}\to S.
\end{equation}
We also consider a differential form \( \omega\in \Wedge^n(T^*M)\) and \( \sigma\in\Wedge^{n-1}(T^*M)\). These are respectively \( n\) and \( n-1\) differential forms on \( M\).  We also consider \( v\), a vector field on \( M\) and \( \tau\), a \( 1\)-form on \(M\).

Let us see what is possible to integrate.

\begin{definition}[\cite{ooMLEZooCKxedX}]       \label{DEFooPDRCooPiBklC}
    Let \( \omega\) be a \( n\)-form defined on \( \phi(U)\) (vanishing everywhere else). Its integral is :
    \begin{equation}
        \int_{\phi(U)}\omega=\int_U\phi^*\omega.
    \end{equation}
    The last integral is an integral of type \( \int_{U}F(x_1,\ldots, x_n)dx_1\wedge\ldots \wedge dx_n\) on an open set in \( \eR^n\). That is definition~\ref{DEFooEYRFooRQTmRF}.
\end{definition}

This definition is nothing if it depend on the parametrisation. The following proposition show slightly more than the independence.
\begin{proposition}[\cite{MonCerveau,ooBTXRooUEBLMV}]       \label{PROPooNJCLooMqeeeX}
    Let be the charts \( \phi\colon U\to M\) and \( \psi\colon V\to N\) and a map \( f\colon M\to N\). The whole is supposed to be minimal :
    \begin{equation}
        f\big( \phi(U) \big)=\psi(V).
    \end{equation}
    Then we have the ``change of variable'' formula :
    \begin{equation}
        \int_{\phi(U)}\omega=\int_{\psi(V)}(f^{-1})^*\omega.
    \end{equation}
\end{proposition}

\begin{proof}
    By definition \( \int_{\phi(U)}\omega=\int_U\phi^*\omega\) and we have the diffeomorphism
    \begin{equation}
        \phi^{-1}\circ f^{-1}\circ \psi\colon V\to U,
    \end{equation}
    so that we can use the result of lemma~\ref{LEMooNCYSooXtnCKq} :
    \begin{equation}
        \int_U\phi^*\omega=\int_{(\phi^{-1}\circ f^{-1}\circ \psi)^{-1}(U)}  (\phi^{-1}\circ f^{-1}\circ \psi)^*\phi^*\omega=\int_{(\psi^{-1}\circ f\circ \phi )U}\psi^*(f^{-1})^*\omega=\int_{\psi^{-1}(N)}\psi^*(f^{-1})^*\omega.
    \end{equation}
    The last integral is the definition of an integral on \( N\) :
    \begin{equation}
        \int_{\psi^{-1}(N)}\psi^*(f^{-1})^*\omega=\int_N(f^{-1})^*\omega.
    \end{equation}
\end{proof}

Here is the lemma that shows the independence of definition~\ref{DEFooPDRCooPiBklC} with respect to the change of chart system.
\begin{lemma}
    Let \( \varphi\colon V\to M\) be a chart such that \( \varphi(V)\cap \varphi(U)=N\) is not empty. We define \( U'=\phi^{-1}(N)\) and \( V'=\varphi^{-1}(N)\). Then
    \begin{equation}        \label{EQooLSZMooPcyMWN}
        \int_{\phi(U')}\omega=\int_{\varphi(V')}\omega.
    \end{equation}
\end{lemma}
This lemma allows us to write \( \int_N\omega\) the common value of both sides of \eqref{EQooLSZMooPcyMWN}.

\begin{proof}
    Taking \( f=\id\) and two charts for the same open set in \( M\) in proposition~\ref{PROPooNJCLooMqeeeX} shows the result.
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{On manifold that require a finite atlas}
%---------------------------------------------------------------------------------------------------------------------------

We restrict ourself to manifolds that accept a finite atlas.

\begin{definition}[\cite{ooBTXRooUEBLMV}]      \label{DEFooITDTooWwrPPr}
    If \( \omega\) is a \( n\)-form on \( M\) and if \( \{ f_{\alpha} \} \) is a partition of unity\footnote{See theorem~\ref{THOooPCHDooITWKpC}.} subordinate to the finite atlas \( \{ U_{\alpha} \}\) then
    \begin{equation}
        \int_M\omega=\sum_{\alpha}\int_{\phi_{\alpha}(U_{\alpha})}f_{\alpha}\omega.
    \end{equation}
\end{definition}

We show that this definition does not depend on the choice of the partition of unity.
\begin{lemma}[\cite{MonCerveau,ooBTXRooUEBLMV}] \label{LEMooCMIZooHhHaHV}
    The definition~\ref{DEFooITDTooWwrPPr} is independent of the choice of atlas and partition of unity.
\end{lemma}

\begin{proof}
    Let \(  \{ U_{\alpha},\phi_{\alpha},f_{\alpha} \}_{\alpha\in A}  \) and \( \{ V_i,\varphi_i,g_i \}_{i\in I}\) be two choices of atlas, charts and subordinate partition of unity. We have to show that
    \begin{equation}        \label{EQooPVQZooHvbioJ}
        \sum_{\alpha\in A}\int_{\phi_{\alpha}(U_{\alpha})}f_{\alpha}\omega=\sum_{i\in I}\int_{\varphi_i(V_i)}g_i\omega.
    \end{equation}
    Since \( \{ g_i \}\) is a partition of unity,
    \begin{equation}
            \spadesuit=\sum_{\alpha}\int_{\phi_{\alpha}(U_{\alpha})}f_{\alpha}\omega=\sum_{\alpha}\int_{\phi_{\alpha}(U_{\alpha})}\sum_ig_if_{\alpha}\omega.
    \end{equation}
    Since the atlas are finite, the sums are finite and can be permuted with the integral. Moreover the function \( g_if_{\alpha}\) is nonzero only on \( \phi_{\alpha}(U_{\alpha})\cap\varphi_i(V_i)\) so that the integral can be taken on \( \phi_{\alpha}(U_{\alpha})\), \( \phi_{\alpha}(U_{\alpha})\cap\varphi_i(V_i)\) or \( \varphi_i(V_i)\). We have
    \begin{subequations}
        \begin{align}
            \spadesuit=\sum_i\sum_{\alpha}\int_{\phi_{\alpha(U_{\alpha})}}g_if_{\alpha}\omega&=  \sum_i\sum_{\alpha}\int_{\phi_{\alpha(U_{\alpha})}\cap \varphi_i(V_i)}g_if_{\alpha}\omega\\
            &=  \sum_i\sum_{\alpha}\int_{\varphi_i(V_i)}g_if_{\alpha}\omega\\
            &= \sum_i\int_{\varphi_i(V_i)}g_i\sum_{\alpha}f_{\alpha}\omega\\
            &=\sum_i\int_{\varphi_i(V_i)}g_i\omega.
        \end{align}
    \end{subequations}
\end{proof}
The common values of both sides of \eqref{EQooPVQZooHvbioJ} is denoted by \( \int_M\omega\).

The following is not really a definition, but a particular case of~\ref{DEFooPDRCooPiBklC}. The integral of a \( n-1\)-form on a \( (n-1)\)-submanifold is
\begin{equation}        \label{EQooYPOGooRYOXQe}
    \int_S\sigma=\int_A\varphi^*\sigma.
\end{equation}
Once again the last integral is an integral of a \( n-1\)-form on an open set in \( \eR^{n-1}\).

\begin{definition}[\cite{ooMLEZooCKxedX}]       \label{DEFooAXFXooWiMLKP}
    The integral of a \( 1\)-form on a \( n-1\) dimensional submanifold is :
    \begin{equation}
        \int_S\tau=\int_S\hodge\tau
    \end{equation}
    where \( \hodge\) is the Hodge dual defined by~\ref{DEFooUOJQooSzKjNR}.
\end{definition}
The last integral is the integral of a \( (n-1)\)-form on a \( (n-1)\)-submanifold, given by \eqref{EQooYPOGooRYOXQe}.

\begin{definition}      \label{DEFooAXZGooJairMQ}
    The integral of a vector field on a \( (n-1)\)-submanifold is :
    \begin{equation}
        \int_Sv=\int_Sv^{\flat}
    \end{equation}
    where \( v^{\flat}\) is the \( 1\)-form defined by the musical isomorphism \eqref{EQooBTWXooTqoNxa}.
\end{definition}

The following proposition provides a much more explicit formula for the integral of a vector field.

\begin{proposition}     \label{PROPooETLZooAVsrwy}
    Let \( \varphi\colon A\subset \eR^{n-1}\to \eR^n\) be an hypersurface and \( X\) be a vector field in \( \eR^n\). Then
    \begin{subequations}
        \begin{align}
            \int_SX&=\int_A\det\big( X,\frac{ \partial \varphi }{ \partial y_1 },\ldots, \frac{ \partial \varphi }{ \partial y_{n-1} } \big)  \label{SUBEQooWJSPooImJjQN}\\
            &=\int_A X\cdot\det\begin{pmatrix}
                e_1    &   \ldots    &   e_n    \\
                &   \partial_{y_1}\varphi    &       \\
                &    \vdots   &       \\
                &   \partial_{y_{n-1}}\varphi    &
            \end{pmatrix}\\
            &=\int_A X\cdot n
        \end{align}
    \end{subequations}
    where \( \{ y_1,\ldots, y_{n-1} \}\) are the coordinates on \( A\) and \( n\) is the normal vector to the parametrization.
\end{proposition}
Note : thanks to lemma~\ref{LEMooCMIZooHhHaHV}, the value of \( n\) can depend on the choice of coordinates, but the integral will not depend.

\begin{proof}
    If \( X=\sum_{i=1}^nX_i\partial_i\), then \( X^{\flat}=\sum_{i}X_idx_i\) and its Hodge dual is
    \begin{equation}
        \sum_{i}(-1)^i dx_1\wedge\ldots\wedge\widehat{dx_i}\wedge\ldots\wedge dx_n
    \end{equation}
    where the hat denotes a factor that is not present. Using the definitions~\ref{DEFooAXZGooJairMQ},~\ref{DEFooAXFXooWiMLKP} and~\ref{DEFooPDRCooPiBklC} it remains to integrate
    \begin{equation}
        \int_A\sum_i(-1)^iX_i\varphi^*\big( dx_1\wedge\ldots\wedge\widehat{dx_i}\wedge\ldots\wedge dx_n \big).
    \end{equation}
    If \( u_1,\ldots, u_{n-1}\) are vectors on \( A\) (that is on \( T_xA\) where \( x\) is the integration variable) we have
    \begin{subequations}
        \begin{align}
            \varphi^*(dx_1\wedge\ldots\wedge \widehat{dx_i}\wedge\ldots\wedge dx_n)(u_1,\ldots, u_{n-1})&= (dx_1\wedge\ldots\wedge \widehat{dx_i}\wedge\ldots\wedge dx_n)(d\varphi u_1,\ldots, d\varphi u_{n-1})\\
            &=\det\big( \tau_id\varphi u_1,\ldots, \tau_id\varphi u_{n-1} \big)
        \end{align}
    \end{subequations}
    where we used the lemma~\ref{LEMooICRXooFKPCRd}.

    What lies in the integral is the \( (n-1)\) differential form
    \begin{subequations}        \label{EQooEVAPooSbRfaj}
        \begin{align}
           (u_1,\ldots, u_{n-1})\mapsto \sum_{i}(-1)^iX_i&\det\big(    \tau_id\varphi u_1,\ldots, \tau_id\varphi u_{n-1}  \big)\\
            &=\det\big( X,d\varphi u_1,\ldots, d\varphi u_{n-1} \big).
        \end{align}
    \end{subequations}
    Since this is a \( (n-1)\) differential form over \( \eR^{n-1}\), this has to be proportional to \( dy_1\wedge\ldots dy_{n-1}\). The proportionality factor is found by applying \eqref{EQooEVAPooSbRfaj} to the basis \( \{ e_1,\ldots, e_n \}\). Since \( d\varphi(e_i)=\frac{ \partial \varphi }{ \partial y_i }\) we have the proportionality factor
    \begin{equation}
        \det\left( X,\frac{ \partial \varphi }{ \partial y_1 },\ldots, \frac{ \partial \varphi }{ \partial y_n } \right)
    \end{equation}
    and the integral to be computed is
    \begin{equation}
        \int_A\det\left( X,\frac{ \partial \varphi }{ \partial y_1 },\ldots, \frac{ \partial \varphi }{ \partial y_n } \right)dy_1\wedge\ldots\wedge dy_{n-1}=\int_A\det\left( X,\frac{ \partial \varphi }{ \partial y_1 },\ldots, \frac{ \partial \varphi }{ \partial y_n } \right).
    \end{equation}
    The formula \eqref{SUBEQooWJSPooImJjQN} is proven. The two others are application of lemma~\ref{LEMooFRWKooVloCSM}.
\end{proof}

\begin{example}
    Let us make the example with \( n=3\). We have
    \begin{equation}
        \varphi^*(dx\wedge dy)(v_1,v_2)=(dx\wedge dy)(d\varphi v_1 , d\varphi v_2)=\det
        \begin{pmatrix}
            d\varphi(v_1)_x    &   d\varphi(v_2)_x    \\
            d\varphi(v_1)_y    &   d\varphi(v_2)_y
        \end{pmatrix},
    \end{equation}
    and then
    \begin{equation}
        \sum_i(-1)^iX_i \varphi^*(   \Wedge_{k\neq i}dx_k    )(v_1,v_2)=\sum_i(-1)^iX_i
        \begin{pmatrix}
            d\varphi(v_1)_x    &   d\varphi(v_2)_x    \\
            d\varphi(v_1)_y    &   d\varphi(v_2)_y
        \end{pmatrix}=
        \det\begin{pmatrix}
             X_1  &   d\varphi (v_1)_x    &   d\varphi(v_2)_x    \\
             X_2  &   d\varphi (v_1)_y    &   d\varphi(v_2)_y    \\
             X_3  &   d\varphi (v_1)_z    &   d\varphi(v_2)_z
        \end{pmatrix}
    \end{equation}
\end{example}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Integrating by part}
%---------------------------------------------------------------------------------------------------------------------------

\begin{proposition}[\cite{MonCerveau}]
    Let \( \Omega\) be an open set in an manifold \( M\) of dimension \( n\) and \( \varphi\colon A\to \eR^n\) be a parametrisation of the boundary \( \partial\Omega\) with tangent vector field \( n\) (defined on \( \partial\Omega\)). Let \( u,v\in  C^{\infty}(M)\). Then we have
    \begin{equation}        \label{EQooQSMNooKHwbqp}
        \int_{\partial \Omega}uv\,n_j=\int_{\Omega}\frac{ \partial u }{ \partial x_j }v+\int_{\Omega}u\frac{ \partial v }{ \partial x_j }.
    \end{equation}
\end{proposition}

\begin{proof}
    We use the Stokes formula (theorem~\ref{ThoATsPuzF}) on the \( (n-1)\)-form
    \begin{equation}
        \omega=uv\,dx_1\wedge\ldots\wedge\widehat{dx_j}\wedge\ldots\wedge dx_n,
    \end{equation}
    and we know from example~\ref{EXooCIYIooFPMLMU} that \( \omega=(-1)^{j+1}\hodge dx_j\). On the other hand,
    \begin{equation}
        d\omega=\sum_k\frac{ \partial (uv) }{ \partial x_k }dx_j\wedge dx_1\wedge\ldots\wedge\widehat{dx_j}\wedge\ldots\wedge dx_n=\frac{ \partial (uv) }{ \partial x_j }(-1)^{j+1}dx_1\wedge\ldots\wedge dx_n.
    \end{equation}
    We can use the Stokes formula :
    \begin{equation}
        \int_{\partial \Omega} uv dx_1\wedge\ldots\wedge\widehat{dx_j}\wedge\ldots\wedge dx_n=  (-1)^{j+1} \int_{\Omega}\frac{ \partial (uv) }{ \partial x_j }.
    \end{equation}
    The left-hand side can be transformed as
    \begin{equation}
        \int_{\partial\Omega}\hodge(dx_j)=\int_{\partial\Omega}uv\partial_j=\int_{\partial\Omega}uv\,n_j
    \end{equation}
    where we used the definition~\ref{DEFooAXFXooWiMLKP} and the proposition~\ref{PROPooETLZooAVsrwy}.

    The coefficients \( (-1)^{j+1}\) simplify and the derivation of product produce the result.
\end{proof}

\begin{example}     \label{EXooWLUVooNamnKG}
    If we integrate by part the function \( u\frac{ \partial^2 v }{ \partial x_j^2 }\) we have
    \begin{equation}
        \int_{\omega}u\frac{ \partial^2 }{ \partial x_j^2 }=-\int_{\Omega}\frac{ \partial u }{ \partial x_j }\frac{ \partial v }{ \partial x_j }+\int_{\partial \Omega}u\frac{ \partial v }{ \partial x_j }n_j.
    \end{equation}
    Summing over \( j\) we have the interesting formula
    \begin{equation}        \label{EQooJLDTooIMtxEX}
        \int_{\Omega}u\Delta v=-\int_{\Omega}\nabla u\cdot\nabla v+\int_{\partial \Omega}u\frac{ \partial v }{ \partial n }
    \end{equation}
    where \( \Delta v=\sum_j\frac{ \partial^2v }{ \partial x_j^2 }\) and \( \frac{ \partial v }{ \partial n }\) is a notation for \( \nabla v\cdot n\).
\end{example}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Lie derivative}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Consider $X\in\cvec(M)$ and $\alpha\in\Omega^p(M)$. Let $\dpt{\varphi_t}{M}{M}$ be the flow of $X$. The \defe{Lie derivative}{Lie!derivative!of a $p$-form} of $\alpha$ is
\begin{equation}\label{liesurforme}
         \mL_X\alpha=\lim_{t\to 0}\us{t}[(\varphi^*_t\alpha)-\alpha]=\dsdd{\varphi^*_t\alpha}{t}{0}.
\end{equation}
More explicitly, for $x\in M$ and $v\in T_xM$,
\[
             (\mL_X\alpha)_x(v)=\lim_{t\to 0}\us{t}\left[(\varphi_t^*\alpha)_x(v)-\alpha_x(v)\right]
\]
In the definition of the \defe{Lie derivative}{Lie!derivative!of a vector field} for a vector field, we need an extra minus sign:
\begin{equation}		\label{EqDefLieDerivativeVect}
            (\mL_XY)_x=\dsdd{\varphi_{-t*}Y_{\varphi_t(x)}}{t}{0}.
\end{equation}
Why a minus sign ? Because $Y_{\varphi_t(x)}\in T_{\varphi_t(x)}M$, but $\dpt{(d\varphi_{-t})_a}{T_aM}{T_{\varphi_{-t}(a)}M}$ so that, if we want, $\varphi_{-t*}Y_{\varphi_t(x)}$ to be a vector at $x$, we can't use $\varphi_{t*}$.

These two definitions can be embedded in only one. Let $X\in\cvec(M)$ and $\varphi_t$ its integral curve\footnote{\textit{i.e.} for all $x\in M$, $\varphi_0(x)=x$ and $\dsdd{\varphi_{u+t}(x)}{t}{0}=X_{\varphi_u(x)}$.}\index{integral!curve}. We know that $\varphi_{t*}$ is an isomorphism $\dpt{\varphi_{t*}}{T_{\varphi^{-1}(x)}M}{T_xM}$. It can be extended to an isomorphism of the tensor algebras at $\varphi^{-1}(x)$ and $x$. We note it $\tilde{\varphi}_t$. For all tensor field $K$ on $M$, we define
\[
            (\mL_XK)_x=\lim_{t\to 0}[K_x-(\tilde{\varphi_t}K)_x].
\]

On a Riemannian manifold $(M,g)$, a vector field $X$ is a \defe{\href{http://en.wikipedia.org/wiki/Killing_vector_fields}{Killing vector field}}{killing!vector field} if $\mL_Xg=0$.



\begin{lemma}
Let $\dpt{f}{(-\epsilon,\epsilon)\times M}{\eR}$ be a differentiable map with $f(0,p)=0$ for all $p\in U$. Then there exists $\dpt{g}{(-\epsilon,\epsilon)\times M}{\eR}$, a differentiable map such that $f(t,p)=tg(t,p)$ and
\[
                g(0,q)=\left.\dsd{f(t,q)}{t}\right|_{t=0}.
\]
\end{lemma}
\begin{proof}
Take
\[
                g(t,q)=\int_0^1\dsd{f(ts,p)}{(ts)}ds,
\]
and use the change of variable $s\to ts$.
\end{proof}

\begin{lemma}
If $\varphi_t$ is the integral curve of $X$, for all function $\dpt{f}{M}{\eR}$, there exists a map $g$, $g_t(p)=g(t,p)$ such that
$f\circ\varphi_t=f+tg_t$ and $g_0=Xf$.
\end{lemma}

\begin{proof}
Consider $\overline{f}(t,p)=f(\varphi_t(p))-f(p)$, and apply the lemma:
\[
          f\circ\varphi_t=tg_t(p)+f(p).
\]
Thus we have
\[
      Xf=\lim_{t\to 0}\us{t}[f(\varphi_t(p))-f(p)]=\lim_{t\to 0}g_t(p)=g_0(p).
\]
\end{proof}

One of the main properties of the Lie derivative is the following:
\begin{theorem}		\label{ThoLieDerrComm}
Let $X$, $Y\in\cvec(M)$ and $\varphi_t$ be the integral curve of $X$. Then
\[
         [X,Y]_p=\lim_{t\to 0}\us{t}[Y-d\varphi_tY](\varphi_t(p)),
\]
or
\begin{equation}
          \mL_XY=[X,Y].
\end{equation}
where the commutator is given by the definition \ref{DEFooHOTOooRaPwyo}.
\end{theorem}
\begin{proof}
Take $\dpt{f}{M}{\eR}$ and the function given by the lemma: $\dpt{g_t}{M}{\eR}$ such that $f\circ \varphi_t=f+tg_t$ and $g_0=Xf$. Then put $p(t)=\varphi_t^{-1}(p)$. The rest of the proof is a computation:
\[
            (\varphi_{t*}Y)_pf=Y(f\circ\varphi_t)_{p(t)}=(Yf)_{p(t)}+t(Yg_t)_{p(t)},
\]
so
\begin{equation}
\begin{split}
  \lim_{t\to 0}\us{t}[Y_p-(\varphi_{t*}Y)_p]f&=\lim_{t\to 0}\us{t}[(Yf)_p-(Yf)_{p(t)}]-\lim_{t\to 0}(Yg_t)_{p(t)}\\
                                         &=X_p(Yf)-Y_pg_0\\
                                         &=[X,Y]_pf.
\end{split}
\end{equation}

\end{proof}

A second important property is
\begin{theorem}
For any function $f\colon M\to V$,
\[
           \mL_Xf=Xf.
\]
\end{theorem}

\begin{proof}
If $X(t)$ is the path which defines the vector $X$, it is obvious that at $t=0$, $X(t)$ is an integral curve to $X$, so that we can take $X(t)$ instead of $\varphi_t$ in \eqref{liesurforme}. Therefore we have:
\begin{equation}
    \mL_Xf=\dsdd{\varphi_t^*f}{t}{0}
          =Xf
\end{equation}
by definition of the action of a vector on a function.
\end{proof}
