% This is part of (almost) Everything I know in mathematics
% Copyright (c) 2016, 2024-2025
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.

\section*{Notations}
%+++++++++++++++++++

Some notations about functional spaces:

\begin{enumerate}
	\item $\cdE(X)$ is the set of smooth functions on $X$ also denoted by $ C^{\infty}(X)$,
	\item $\cdD(X;K)$ is the subspace of $\cdE(X)$ of functions with support in $K$,
	\item $\cdD(X)$ is the union of all $\cdD(X;K)$ when $K$ runs over the compact subsets of $X$,
	\item $C_{c}(X)$ compactly supported functions on $X$.
	\item $ C^{\infty}_{c}(X)$ smooth compactly supported functions on $X$.
	\item $\scrC_F(E)$ is the set of continuous maps from $E$ to $F$.
	\item $\cdD^{(0)}_{\eR}(X)$ is the set of continuous real functions with compact support in $X$,
	\item $\scrD^{(r)}_p(X;K)$ is the set of the differential $p$-forms of class $C^r$ on $K$ when $K$ is a compact subset of the manifold $X$,
	\item $\cdE^{(p)}_F(A)$ is the set of $p$ times continuously differentiable functions $A\to F$; if $p$ is not mentioned it means $\infty$,
	\item $\swS$, the space of smooth rapidly decreasing Schwartz functions, page \pageref{not_swS}.
\end{enumerate}

Some distribution spaces:

\begin{enumerate}
	\item $M(X)$ is the space of complex Borel measures on $X$, page \pageref{defMX}
	\item $M_0(X)$ is the subspace of $M(X)$ of compact supported measures, page \pageref{defMzX}.
	\item $R(G)$ is the dual of $ C^{\infty}(G)$. All element of this space are not measures.
\end{enumerate}

When $f$ and $g$ are real function, we write $f=O(g)$ if there exists $C\leq\infty$ such that $f(x)\leq Cg(x)$ for all $x$.

\section{Distributions}\label{sec:Distrib}
%++++++++++++++++++++++

Matter of this section is taken from \cite{Treves,Dieu3}

Let $X$ be an open set in $\eR^n$. A \defe{distribution}{distribution} on $X$ is a linear form on $\cdD(X)$ whose restriction to $\cdD(X;K)$ is continuous for each compact set $K\subset X$. We denote it by $\cdD'(X)$\nomenclature{$\cdD'$}{distribution space}. More generally, if $\cdA$ is a space of function, we denote by $\cdA'$ the set of linear form on $\cdA$ whose are continuous on each compact.

If $T$ is a linear form on $\cdD(X)$. For $T$ to be a distribution, it is necessary and sufficient that for all sequence $(f_k)\in C^{\infty}(X)$  with $f_k\in\cdD(X,K)$ such that $f_k\to 0$ in $\cdE(X)$, the sequence $(Tf_k)$ converges to $0$ in $\eC$.

Let $T$ be a distribution for which all the restrictions to $\cdD(X;K)$ are continuous for the induced topology from $\cdD^{(r)}(X;K)$. In this case, we say that $T$ has \defe{order}{order!of a distribution}\label{pg:reforder} lesser than $r$. The \emph{order} of $T$ is the smaller such $r$. If it doesn't exist, then we say that $T$ has order infinite.

\begin{proposition}
	Let $T$ be of order $\leq r$. Then $T$ is the restriction to $\cdD(X)$ of a linear form $T'$ on $\cdD^{(r)}(X)$ whose restriction to each $\cdD^{(r)}(X;K)$ is continuous. This $T'$ is unique.
\end{proposition}

I only give the beginning of the proof\quext{Il faudra la completer}.

\begin{proof}
	Let $K$ be a compact in  $X$ and $K'$ a compact neighbourhood of $K$ in $X$. There exists a function $h\in C^{\infty}(X)$ such that $h=1$ in a compact neighbourhood of $K$ and $h=0$ outside $K'$. Consider a function $g\in\cdD^{(r)}(X;K)$; there exists a sequence $(f_k\in\cdD(X))\to g$ for the topology of $\cdE^{(r)}$. This is the $ C^{\infty}$ approximation of $C^{(r)}$ functions. Note that in general, $g$ don't belong to $\cdD(X;K)$.

	Now, the sequence $(hf_k)$ which is contained in $\cdD(X;k')$ converges to $g$ in $\cdD^{(r)}(X;k')$. Then the closure of $\cdD(X;K')$ in $\cdE^{(r)}$ contains $\cdD^{(r)}(X;K)$ and is contained in $\cdD^{(r)}(X;K')$.
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Dirac distribution}
%---------------------------------------------------------------------------------------------------------------------------

The distribution $\dpt{\delta_a}{\swD(\eR^d)}{\eC}$ given by $f\to f(a)$ is the \defe{Dirac distribution}{Dirac!distribution} at $a$. It was already defined in~\ref{DEFooUSTNooYEZfPN}.

We have a two-dimensional generalisation of that.

\begin{lemmaDef}        \label{LEMooYABKooWPXIXZ}
	Let \( C\) be a curve in \( \eR^2\) and a function \( f\colon \eR^2\to \eC\) integrable on \( C\). The formula
	\begin{equation}
		\langle \delta_C^f, \phi\rangle =\int_Cf\phi.
	\end{equation}
	defines and element \( \delta_C^f\in \swD'(\eR^2) \).
\end{lemmaDef}

\begin{proof}
	Let \( \phi_n\stackrel{\swD(\eR^2)}{\longrightarrow}0\); we have
	\begin{equation}
		|\langle \delta_C^{f}, \phi_n\rangle |\leq\int_C|f\phi_n|\leq  \| \phi_n \|_{\infty}   \int_C| f |.
	\end{equation}
	Since \( f\) is integrable on \( C\), we have a majoration \( \int_C| f |\leq \alpha\) for some \( \alpha>0\) and then
	\begin{equation}
		|\langle \delta_C^{f}, \phi_n\rangle |\leq \alpha\| \phi_n \|_{\infty}.
	\end{equation}
	The definition of convergence in \( \swD(\eR^2)\) implies that \( \| \phi_n \|\to 0\).
\end{proof}

The usual Dirac distribution is obtained with \( C=\{ 0 \}\) and \( f(x)=1\) on $C$.

\subsection{Distribution defined from functions}
%-----------------------------------------------

If $\dpt{f}{X}{\eR}$ is an integrable function, we define the distribution $T_f$ by \nomenclature{$T_f$}{Distribution defined by a function}
\[
	T_j(g)=\int_Xfg.
\]
If $\mU\subset\eR^N$, is open and $K\subset\mU$ is compact, for all multi-index $\nu$, the map $f\to D^{\nu}f$ is continuous from $\cdD(\mU;K)$ to $\cdD(\mU;K)$. This leads us to define the \defe{derivative}{derivation!of a distribution} of the distribution $T\in\cdD'(\mU)$ by
\begin{equation} \label{eq:defpartialT}
	(D^{\nu}T)f=(-1)^{| \nu |}T(D^{\nu}f).
\end{equation}
In particular, if $T=T_f$, then
\begin{equation} \label{eq:defTpri}
	(\partial_iT_g)f=-\int g\partial_if
	=\int(\partial_ig)f
	=T_{\partial_ig}f.
\end{equation}
This relation explains the sign in definition \eqref{eq:defpartialT}. The boundary term which should appears in the integral by part is zero because $f\in\cdD(\mU;K)$ has compact support.

\subsection{Fourier transform and Schwartz functions}
%----------------------------------------------------

We consider $\{ e_1,\ldots,e_n \}$, a basis of $\eR^N$ and $\{ e'_1,\ldots,e'_n \}$ the dual basis defined by $\scal{e'_i}{e_j}=\delta_{ij}$. If $x=\sum_ix_ie_i$ and $\xi=\sum_j\xi_je'_j$, we write $\scal{x}{\xi}=\scal{\xi}{x}=\sum_i\xi_ix_i$.

The space $\swS(\eR^N)$\nomenclature{$\swS$}{Schwartz space}\label{not_swS} of \defe{Schwartz functions}{Schwartz functions} is the space of $ C^{\infty}$ functions $\varphi$ such that for all polynomials $P$ on $\eR^N$ and all multi-index $\nu$, the quantity
\begin{equation}
	| P(x)D_x^{\nu}\varphi(x) |
\end{equation}
is bounded.  The topology is given by seminorms
\begin{equation}
	\| \varphi \|_{P,\nu}=\sup_{x\in\eR^N}| P(x)D_x^{\nu}\varphi(x) |.
\end{equation}
It is possible to prove that it is a Fréchet space in which all bounded and closed sets are compact; the topology is independent of the basis. A function in this space has special property that its integral is absolutely convergent:
\[
	\int_{\eR^N}| \varphi(x) |\leq \infty.
\]
It is proved in \cite{Kirillov} that on $\swS(\eR^n)$, the following families of seminorms are equivalent:
\begin{subequations}
	\begin{align}
		p_{\alpha\beta}(f)   & =\sup_{x\in\eR^n}| x^{\alpha}\partial^{\beta}f(x) |                        \\
		p'_{\alpha\beta}(f)  & =\int_{\eR^n}| x^{\alpha}\partial^{\beta}f(s) |\,ds                        \\
		p''_{\alpha\beta}(f) & =\left( \int_{\eR^n}| x^{\alpha}\partial^{\beta}(s) |^2\,ds \right)^{1/2}.
	\end{align}
\end{subequations}

Let $\xi\in(\eR^N)^*$ and consider the function  $x\to e^{-2\pi i\scal{x}{\xi}}\varphi(x)$
which belongs to $\swS(\eR^N)$ as long as $\varphi\in\swS(\eR^N)$. The \defe{Fourier transform}{Fourier transform} of $\varphi\in\swS(\eR^N)$ is the function $\dpt{\hat\varphi}{(\eR^N)^*}{\eC}$ given by
\begin{equation}
	\hat\varphi(\xi)=\int \varphi(x)e^{-2\pi i\scal{x}{\xi}}dx.
\end{equation}

Classical results are summarized in the following theorem (proof in the case of space $\swS$ is given in \cite{Treves}):

\begin{theorem}
	The Fourier transform is a topological vector space isomorphism from $\swS(\eR^N)$ into $\swS(\eR^N)$ and the inverse is given by formula
	\[
		\varphi(x)=\int \hat\varphi(\xi)e^{2\pi i\scal{x}{\xi}}d\xi.
	\]
	Equalities of Parseval and Plancherel\index{Perceval}\index{Plancherel} holds:
	\begin{align}
		\int \phi\overline{\psi}=\int \hat\phi\overline{\hat\psi}\textrm{ and }
		\int| \phi |^2=\int| \hat\phi |^2
	\end{align}
	where the bar denotes the usual complex conjugation. Left hand side integrals are taken on $\eR^N$ and right integrals over $(\eR^N)^*$.
\end{theorem}

\begin{corollary}
	Fourier transform can be extended to an isometry $L^2(\eR^N)\to L^2\big( (\eR^N)^* \big)$.
\end{corollary}

\subsection{Support of a distribution}
%-------------------------------------

Let $\mU$ be an open set in $X$ and $K$, a compact in $\mU$. The map $\cdD(X;K)\to\cdD(\mU;K)$ given by $f\to f_{\mU}$ is an isomorphism whose inverse is $f\to f^{\mU}$ where $f^{\mU}$ is just the prolongation of $f$ with zero outside $\mU$. For a distribution $T$ on $X$, we consider $\dpt{T|_{\mU}}{\cdD(\mU;K)}{\eC}$,
\[
	T|_{\mU}(f)=T(f^{\mU}).
\]
This is a distribution on $\mU$ called the \defe{induced}{induced!distribution} from $T$ on $\mU$. A distribution on $\mU$ is not always the restriction of a distribution on $X$ and when it is, the prolongation is not unique in general. There exists a prolongation theorem in certain cases:

\begin{theorem}
	Let $(\mU_{\lambda})_{\lambda\in L}$ be an open covering of $X$ and for each $\lambda\in L$, a distribution $T_{\lambda}$ on $\mU_{\lambda}$. We suppose that for all $\lambda,\mu\in L$, $T_{\lambda}|_{\mU_{\lambda}\cap\mU_{\mu}}=T_{\mu}|_{\mU_{\lambda}\cap\mU_{\mu}}$. Then there exists an unique distribution $T$ on $X$ such that for all $\lambda\in L$, $T|_{\mU_{\lambda}}=T_{\lambda}$.
\end{theorem}

Now if the restriction  of $T$ to each $\mU_{\lambda}$ is zero, then the restriction to the union is zero too because the null distribution answers the theorem. So the union of all the open set on which $T$ is zero is an open on which $T$ is zero. It is the largest open $V\subset X$ on which $T$ is zero. The complementary $S=\complement V$ is the \defe{support}{support of a distribution} of the distribution $T$. We note it $\Supp(T)$.

Let $x\in\Supp T$: there exists no open containing $x$ on which $T$ is zero. With other words, for all  neighbourhood $V$ of $x$, there exists a function $f\in\cdD(X)$ with support contained in $V$ with $T(f)\neq 0$.

\subsection{Duality}
%-------------------

If $L$ and $M$ are algebras, the set $\Hom(L,M)$\nomenclature{$\Hom(L,M)$}{Space of linear maps from $L$ to $M$} contains all the maps $\dpt{f}{L}{M}$ such that $f(xy)=f(x)f(y)$. We are mainly interested in $\eC$-algebras: algebras $L$ endowed with a product $\eC\times L\to L$. Then we are leads to look at $\Hom_{\eC}(L,\eC)$, the subset of $\Hom(L,\eC)$ of maps which commutes with the latter product: $A\in\Hom_{\eC}(L,\eC)$ when $A\in\Hom(L,\eC)$ and $A(zl)=zA(l)$. We denote\nomenclature{$L^*$}{Linear maps from $L$ to $\eC$}.
\begin{equation}
	L^*=\Hom_{\eC}(L,\eC).
\end{equation}
This is defined when $L$ is a $\eC$-module.

We consider now a \emph{topological} vector space: $L$ is a topological group for addition and the map $\eC\times L\to L$, $(\lambda,x)\to \lambda x$ is continuous with respect to the two variables. We denote by $L'$\nomenclature{$L'$}{Topological dual of $L$} the space of linear \emph{and continuous} maps $L\to \eC$; this is the \defe{topological dual}{dual!topological}\index{topological!dual} of $L$.

Elements of $L^*$ have no continuity condition. In the general case, $L'\subset L^*$, and in the finite dimensional case, $L'=L^*$. The space $L^*$ is the \defe{dual module}{dual!module} of $L$ while $L'$ is the \defe{topological conjugate}{topological!conjugate} space of $L$. In both cases, we speak about \defe{dual space}{dual!space} of $L$.


\begin{proposition}
	Dual space $\cdE'(X)$ is the space of distribution with compact support.
	\label{prop:dualCinfcompact}
\end{proposition}

We can consider the sequence $ C^{\infty}_c\subset\swS\subset C^{\infty}$ of inclusion with dense images. The transposition of this gives the continuous inclusion sequence
\[
	\cdE'\subset\swS'\subset\cdD'.
\]
We say that an element of $\swS'(\eR^N)$ is a \defe{tempered distribution}{tempered!distribution}\nomenclature{$\swS'$}{Tempered distributions}.

\begin{proposition}
	A distribution on $\eR^N$ is tempered if and only if it is a finite sum of derivatives of continuous functions which are bounded at infinity by a polynomial.
	\label{prop_distr_temp_sum}
\end{proposition}

A continuous function is not necessarily derivable. By ``derivative of a continuous function'' we mean a distribution of the form $(T_f)'$ (derivative in the sense of distributions) which we write $T_{f'}$ by abuse of notation. This notation is motivated by equation \eqref{eq:defTpri}.

\begin{proof}[Proof of proposition~\ref{prop_distr_temp_sum} ]
	Let us first proof that a distribution $T$ is tempered if and only if the map $\varphi\to T\varphi$ is continuous on $ C^{\infty}_c$ for the topology induced from $\swS$. Let $\dpt{\tilde T}{ C^{\infty}_c}{\eC}$ be the map equals to $T$ on $ C^{\infty}_c$ and not defined anywhere else. If $\mO$ is open in $\eC$, then $\tilde T^{-1}(\mO)= C^{\infty}_c\cap T^{-1}(\mO)$. This is open in $ C^{\infty}_c$ (for the induced topology from $\swS$) if and only $T^{-1}(\mO)$ is open in $\swS$.


	Let $f$ be continuous and $T=T_{f'}$. We want $\varphi\to(T_f\varphi)'$ to be continuous on $\swS$. We can write it as
	\[
		(T_f)'\varphi=-T_f(\varphi')=\int_{\eR^N}f\varphi'.
	\]
	The integral exists because $\varphi\in\swS$, so $\varphi'$ is decreasing at infinity more rapidly than the inverse of any polynomials, while $f$ is bounded by a polynomial.

	Let us now consider, a tempered distribution $T$. We have to prove that $T=T_{f'}$ for a certain continuous function $f$ bounded by a polynomial. Since $T$ is linear, its continuity is assured by the only continuity at zero. A neighbourhood of zero in $\swS$ reads under the form
	\[
		A_{P,Q,\varepsilon}=\{ \varphi\in\swS\tq \sup_{x\in\eR^N}| P(X)Q(\partial_x)\varphi(x) |<\varepsilon \}
	\]
	for a choice of polynomials $P,Q$ and a $\varepsilon>0$. Let $\mO$ be a neighbourhood of rayon $\varepsilon$ around $0$ in $\eC$; we have
	\[
		T^{-1}(\mO)=\{ \varphi\in\swS\tq | T\varphi |\leq \varepsilon \}.
	\]
	In order to be an open set, we have to find two polynomials $P$ and $Q$ (depending on $\varepsilon$ but not on $\varphi$) such that
	\[
		| T\varphi |\leq \sup_{x\in\eR^N}| P(x)Q(\partial_x)\varphi(x) |.
	\]
	The continuity of $T$ gives the existence of reals $m,h\geq 0$ and $C>0$ such that
	\[
		| T\varphi |\leq \sup_{| p |\leq m}\sup_{x\in\eR^N}| (1+| x |^2)^h(\partial_x)^p\varphi(x) |.
	\]
	Let us pose $\varphi_h(x)=(1+| x |^2)^h\varphi(x)$. It still belongs to $   C^{\infty}_c$ and moreover, the map $\varphi\to\varphi_g$ is a bijection on $ C^{\infty}_c$. By induction on $h$, we see that
	\begin{equation}
		| (\partial_x)^p\varphi(x) |\leq C_{p,h}(1+| x |^2)^{-h}\sum_{q\leq p}| (\partial_x)^q\varphi_h(x) |
	\end{equation}
	where $q\leq p$ means $q_1\leq p_1,\ldots, q_n\leq p_n$.
	\quext{je ne fais pas le reste de la démonstration}.

\end{proof}

The space of \defe{currents}{current} is the dual (with respect to $\eR$) space of the space of differential forms. Current is the generalization of differential forms in the same sense that distributions are a generalization of functions. An example of $k$-current is given by a $(n-k)$-form $\sigma$ by setting
\[
	C_{\sigma}(\omega)=\int_M \sigma\wedge\omega.
\]

\section{Measure, distribution and integral} \label{sec_distrib_mesure}
%----------------------------------------------

Do you know what is yellow and equivalent to the existence of non measurable functions? Answer in the footnote\footnote{The Zorn lemon!}.

Most of links between measure theory and distribution are given in \cite{Dieu2}. We will state a lot of results without proof; they can be found in this reference. We always suppose that $X$ is locally compact.

Let $\cdD^{(0)}(X;K)$ be the set of continuous functions on $X$ whose support is contained in a compact $K\subset X$. A \defe{measure}{measure} on $X$ is a linear form $\dpt{\mu}{\cdD^{(0)}(X)}{\eC}$ such that for all compact $K\subset X$, there exist a real $a_K\geq 0$ for which for all $f\in\cdD^{(0)}(X;K)$
\begin{equation}
	| \mu(f) |\leq a_K\| f \|.
\end{equation}
In this case, the restriction $\mu|_{\cdD^{\infty}}(X;K)$ is continuous for the induced topology from $\cdD^{(0)}(X;K)$. Indeed if $\mO$ is open in $\eC$, then
\begin{equation}  \label{eq:18105r1}
	\mu|_{\cdD(X;K)}^{-1}(\mO)=\cdD(X,K)\cap\mu^{-1}(\mO)
\end{equation}
but the continuity condition on $\dpt{\mu}{\cdD^{(0)}}{\eC}$ makes $\mu^{-1}(\mO)$ open in $\cdD^{(0)}$. Then expression \eqref{eq:18105r1} describes an open set in $\cdD(X;K)$ for the induced topology of $\cdD^{(0)}(X;K)$.

The measures are exactly the distribution of order zero, \emph{confer} page \pageref{pg:reforder}.

\subsection{Example: the Lebesgue measure}

Let $f\in\cdD^{(0)}(\eR)$. For all $a$, $b\in\eR$ such that $\Supp f\subset [a,b]$, the value of $\int_a^b f$ is the same and is denoted by $\int_{\eR}f$. The map $f\to\int_{\eR}f$ is a linear continuous function on $\cdD(\eR)$. This is a measure because if $f\in\cdD^{(0)}(\eR,K)$ with $K=[a,b]$, then
\[
	| \int_{\eR}f |\leq (b-a)\| f \|
\]
from the mean value theorem. We recognize the usual \defe{Lebesgue measure}{Lebesgue measure}\index{measure!Lebesgue} on~$\eR$.

The measure $\mu$ is \defe{positive}{positive!measure}\index{measure!positive} when for all $f\geq0\in\cdD^{(0)}_{\eR}$, we have $\mu(f)\geq0$. It is \defe{real}{measure!real} if $\mu(f)\in\eR$ whenever $f\in\cdD^{(0)}_{\eR}(X)$. Since any function can be decomposed into $f=f^+-f^-$, a positive measure is always real.

From now we only consider positive measures on a locally compact set.

\begin{proposition}
	If $\mu$ is a linear form on $\cdD^{(0)}_{\eR}(X)$ with $\mu(f)\geq0$ when $f\geq0$, then $\mu$ is a measure.
\end{proposition}

A function $\dpt{f}{X}{\overline{ \eR }}$ is \defe{lower semicontinuous}{semicontinuous!lower} at $x_0\in X$ when for all $\alpha\in\overline{ \eR }$ such that $\alpha<f(x_0)$, there exists a neighbourhood of $x_0$ in which $\alpha< f$. It is \defe{upper semicontinuous}{semicontinuous!upper} when for all $\alpha'>f(x_0)$, we have $\alpha'>f$ on a neighbourhood.

We consider the set $\mS(X)$ of lower semi continuous functions from $X$ to $\overline{ \eR }$ which are minored by a function of $\cdD^{(0)}_{\eR}(X)$. In particular, if $f\in\mS(X)$, one can define
\begin{equation}
	\mu^*(f)=\sup_{%
		\begin{subarray}{l}
			g\in\cdD^{(0)}_{\eR}(X)\\
			g\leq f
		\end{subarray}
	}\mu(g)
\end{equation}
which is  a well defined number in $\eR\cup\{ +\infty \}$


\begin{proposition}
	Let $(f_n\in\mS)$ an increasing sequence and $f=\sup_nf_n$. Then

	\begin{enumerate}
		\item $f$ exists and $f\in\mS$
		\item $\mu^*(f)=\sup_n\mu^*(f_n)=\lim_{n\to\infty}\mu^*(f_n)$
	\end{enumerate}

\end{proposition}

If $\dpt{f}{X}{\overline{ \eR }}$ is \emph{any} function, a function $h\in\mS(X)$ with $h\geq f$ always exists, so we can define
\begin{equation}
	\mu^*(f)=\inf_{%
		\begin{subarray}{l}
			h\geq f\\
			h\in\mS(X)
		\end{subarray}
	} \mu^*(h).
\end{equation}
This number $\mu^*(f)\in\overline{ \eR }$ is the \defe{upper integral}{integral!upper} of $f$.


\begin{proposition}
	If $(\dpt{f_n}{X}{\overline{ \eR }})$ is an increasing sequence with $\mu^*(f_n)>-\infty$, then
	\[
		\mu^*(\sup_nf_n)=\sup_n\mu^*(f_n)=\lim_{n\to\infty}\mu^*(f_n).
	\]

\end{proposition}

\begin{proposition}
	For all sequence of functions $(f_n\geq 0)$, we have
	\[
		\mu^*\left( \sum_{n=1}^{\infty}f_n\right)\leq\left(\sum_{n=1}^{\infty}\mu^*(f_n) \right).
	\]

\end{proposition}

Now, for a function $\dpt{f}{X}{\overline{ \eR }}$, we put
\begin{equation}
	\mu_*(f)=-\mu^*(-f)
\end{equation}
and we call it the \defe{lower integral}{integral!lower} of $f$ for the measure $\mu$. It fulfils
\[
	\mu_*(f)\leq\mu^*(f).
\]
When the equality are true, we define $\mu(A)$ for a subset $A\subset X$ by
\begin{equation}
	\mu(A)=\mu_*(1_A)=\mu_*(1_A).
\end{equation}

We consider $M(X)$\nomenclature{$M(X)$}{Set of Borel measures on $X$}\label{defMX}, the set of all the \defe{Borel measures}{Borel measures} on $X$: these are measure for which all Borel sets are measurable. When a measure $\mu$ is countably additive, we define
\begin{equation}
	| \mu |(E)=\sup \sum_{k=1}^{\infty}| \mu(E_k) |
\end{equation}
where the supremum is taken over all decomposition of $E$ in disjoints sets $E_k$. It induces a norm on $M(G)$ by
\[
	\| \mu \|=| \mu |(X).
\]
The subset  $M_0(X)$\nomenclature{$M_0(X)$}{Set of compact supported Borel measures}\label{defMzX} contains the Borel regular measures with compact support. A measure is \defe{regular}{regular!measure} when for all $B\subset X$ such that $\mu(B)$ exists, we have
\begin{equation}
	\begin{split}
		\mu(B) & =\sup\{ \mu(K)\tq K\subseteq B \textrm{ is compact} \}   \\
		       & =\inf\{ \mu(A)\tq B\subseteq A, \textrm{ $A$ is open} \}
	\end{split}
\end{equation}

\subsection{Integration on more general spaces}
%----------------------------------------------

Let $X$ be locally compact and $\mu$, a measure on $X$. We define\nomenclature{$\| \mu \|$}{Norm of a measure}
\begin{equation}
	\| \mu \|=\sup_{%
		\begin{subarray}{l}
			\| f \|\leq 1\\
			f\in\cdD^{(0)}(X)
		\end{subarray}
	}
	| \mu(f) |\in\eR\cup\{ +\infty \}
\end{equation}
We say that the \emph{positive measure} $\mu$ is \defe{bounded}{bounded!positive measure} when $\mu^*(X)=\mu^*(1_X)$ is a finite real.  Properties of $\| \mu \|$ are that
\begin{equation}
	\| \mu \|=| \mu |^*(1_X)
\end{equation}
and that $\| \mu \|$ is finite if and only if $| \mu |$ is bounded.


\begin{proposition}
	If $\mu$ is bounded, any bounded and measurable function $\dpt{f}{X}{\eR}$ is integrable and
	\begin{equation} \label{eq:bornintfmu}
		\Big| \int_Xf\,d\mu \Big|\leq \| f \|\mu(X)
	\end{equation}

\end{proposition}
When $\mu$ is not positive, we say that it is \defe{bounded}{bounded!measure} if $\| \mu \|$ is finite. Equation \eqref{eq:bornintfmu} shows that $f\to\int_Xf\,d\mu$ is a continuous linear form on $ C^{\infty}(X)$. All continuous linear form on this space are however not of the form \eqref{eq:bornintfmu}.


\subsection{Integration of vector valued functions}
%----------------------------------------------

Let us consider $E$, a vector space of \emph{finite} dimension and a function $\dpt{f}{X}{E}$. The functions $f_i$ are defined by
\[
	f(x)=\sum_{i=1}^{\infty}f_i(x)e_i
\]
where $\{ e_i \}$ is a basis of $E$. We define
\begin{equation}
	\int f\,d\mu=\sum [\int f_i]e_i
\end{equation}
when all the integrals of the right hand side make sense. The fact for $f$ to be integrable is equivalent to the fact that $x\to\xi(f(x))$ is integrable for all $\xi\in E'$ because $\xi\circ f$ is a linear combination of all the $f_i$.

Let $I$ be a set and consider a map $x\to\Fun(I,\eC)$, $x\to f_x$. We say that this is \defe{scalar integrable}{integrable scalar} if for all $\alpha\in I$, the map $x\to f_x(\alpha)$ is integrable.

The theorem which treat with infinite dimension is the following:

\begin{theorem}
	Let $\mF$ be a Fréchet space and $\mF'$ his dual. Let $x\to f_x$ be a map $X\to\mF'$ such that for all converging sequence $(a_n\in\mF)$, there exists a function  $\dpt{g}{X}{\eR}$, $g\geq0$ such that $\mu^*(g)\leq\infty$ and $| f_x(a_n) |\leq g(x)$ for all $n$. Then there exists one and only one $\xi\in\mF'$ such that
	\begin{equation}
		\xi(z)=\int_Xf_x(z)\,d\mu(x).
	\end{equation}

\end{theorem}

\subsection{Weak integral}
%------------------------

Let $(X,\mu)$ be a measured space and $\dpt{f}{X}{L}$ a map from $X$ to a locally convex space $L$. We say that $f$ is \emph{weakly integrable} if for all $\chi\in L'$, the map $x\to \chi(f(x))$ is integrable for the measure $\mu$, i.e. if $\mu(\chi\circ f)$ makes sense. The \defe{weak integral}{weak integral} of $f$ for with respect to the measure $\mu$ is defined by the requirement
\begin{equation} \label{eq:chbilemirhi}
	\chi\left( \int_Xf\,d\mu \right)=\int_X(\chi\circ f)\,d\mu
\end{equation}
for all $\chi\in L'$. The weak integral $\int_Xf$ is an element of $(L')^*$. In fact the left hand side of equation \eqref{eq:chbilemirhi} should better be noted
\[
	\left( \int_Xf\,d\mu \right)(\chi)
\]
We know that $(L')^*$ can be seen as a subset of $L$. It can be shown that if $f$ is continuous and $X$ compact, then $\int_Xf\in L$.
%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\section{Distribution on groups}
%
%%%%%%%%%%%%%%%%%%%%%%%%

Most of this section comes from \cite{Kirillov}.

We immediately put the attention to the reader on the fact that $(\eR^N,+)$ is a Lie group. Let $G$ be a Lie group, we define $R(G)$\nomenclature{$R(G)$}{Dual of $ C^{\infty}(G)$} as the dual of $ C^{\infty}(G)$. This is the space of compact supported distributions on $G$. The support of $T\in R(G)$ is the smallest compact $K$ for which $T(\phi)=0$ whenever $\phi|_K^{(r)}=0$ for all $r$. When $K$ is compact in $G$, we consider $R(G,K)$, the subspace of $R(G)$ of distributions with support contained in $K$.

We focus on $R(G,\{ e \})$: distributions in this space only depends on values of test functions (and derivatives) at $e$. It should be possible to reconstruct this space from the only data of the Lie algebra $\lG$ instead of then whole group. We'll see later that it is indeed possible.

\subsection{Convolution product}
%--------------------------------

The \defe{convolution}{convolution!product of distribution} of two distributions $T_1$ and $T_2$ in $R(G)$ is given by
\begin{equation}
	(T_1\star T_2)(\phi)=T_1(\phi_{T_2})
\end{equation}
where $\dpt{\phi_{T_2}}{G}{\eC}$ is given by
\begin{equation}
	\phi_{T_2}(g)=T_2(L_g^{-1}\phi)
\end{equation}
and $(L_g\phi)(g')=\phi(g^{-1}g')$ or in a more convenient way, $\phi_{\nu}(g)=\nu(\phi(g\cdot))$.

Let us show that one retrieve the well know distribution convolution in the case of $G=(\eR^N,+)$. We consider $T_f$ and $T_g$, the distributions defined from functions $f$ and $g$ on $\eR^N$. We have $\phi_{T_g}(t)=T_g(L_t^{-1}\phi)$ where $(L_t^{-1}\phi)(x)=\phi(x+t)$. Then
\begin{equation}
	\phi_{T_g}(t)=\int g(x)(L_t^{-1}\phi)(x)\,dx
	=\int g(x)\phi(x+t)\,dx.
\end{equation}
A change of variable gives
\begin{equation}
	(T_g\star T_g)(\phi)=\int f(t)\phi_{t_g}(t)\,dt
	=\int (f\star g)(u)\phi(u)\,du
	= T_{f\star g}\phi
\end{equation}
with the usual convolution product between function.

\begin{remark}
	We see that the convolution operation of functions on $\eR^N$, which has remarkable properties in experimental physics, naturally generalises to a convolution product on distribution which will give a homomorphism between these distributions and the enveloping algebra of the group. Wonderful isn't?
\end{remark}

\begin{lemma}
	The map $\dpt{\psi}{\mG}{R(G,\{ e \})}$ given by $\psi(\tilde X)f=Xf$ is a homomorphism.
\end{lemma}

\begin{proof}
	Let us prove that $[\psi(\tilde X)\star\psi(\tilde Y)]f=(\tilde X\tilde Yf)_e$. We have
	\begin{equation}
		\begin{split}
			[\psi(\tilde X)\star\psi(\tilde Y)] & =\psi(\tilde X)\big( c(\psi(\tilde Y),\phi) \big)   \\
			                                    & =\Dsdd{ c(\psi(\tilde Y),\phi)\tilde X_e(t) }{t}{0} \\
			                                    & =\DDsdd{ (L^{-1}_{X(t)}\phi)(Y(s)) }{t}{0}{s}{0}    \\
			                                    & =\DDsdd{ \phi(X(t)Y(s))) }{t}{0}{s}{0}.
		\end{split}
	\end{equation}

	Now, $\tilde Y\phi$ is a function from $G$ to $\eC$ on which we can apply the vector $\tilde X_e=X$. We have:
	\begin{equation}
		\begin{split}
			(\tilde X\tilde Y)_e\phi & =\tilde X_e(\tilde Y\phi)                                 \\
			                         & =\Dsdd{ (\tilde Y\phi)(\tilde X_e(t)) }{t}{0}             \\
			                         & =\Dsdd{ \tilde Y_{X(t)}\phi }{t}{0}                       \\
			                         & =\DDsdd{ \phi\big( \tilde Y_{X(t)}(s) \big) }{t}{0}{s}{0} \\
			                         & =\DDsdd{ \phi\big( X(t)Y(t) \big) }{t}{0}{s}{0}.
		\end{split}
	\end{equation}

\end{proof}

\subsection{Representations}
%--------------------------

Let $G$ be a locally compact metrisable Lie group and $V$, an Hausdorff topological vector space on $\eC$. We say that $\dpt{U}{G}{\End V}$ is a \defe{linear continuous representation}{representation!linear continuous} of $G$ on $V$ when
\begin{enumerate}
	\item $U(gh)=U(g)\circ U(h)$ for all $g$, $h\in G$,
	\item for each $v\in V$, then map $g\to U(g)v$ is continuous from $G$ into $V$.
\end{enumerate}
In most of cases, we want the representation to be \defe{unitary}{unitary!representation}\index{representation!unitary}: for all $g\in G$ and for all $v$, $w\in V$,
\begin{equation}
	\scal{U(g)v}{U(g)w}=\scal{v}{w}.
\end{equation}
In particular, $U(g)^*=U(g)^{-1}$. Let $v$, $w\in V$. The function $G\to\eC$ given by
\[
	g\to \scal{U(g)v}{w}
\]
is continuous and bounded. The boundary comes from Schwartz and the fact that $U(g)$ is an isometry:
\begin{equation}
	\scal{U(g)v}{w}\leq \| U(g)v \|\| w \|
	=\| v \|\| w \|.
\end{equation}
Equation \eqref{eq:chbilemirhi} then shows that it is an integrable function and that
\begin{equation} \label{eq:Tmuvborn}
	\left|    \int_G\scald{U(g)v}{w}\,d\mu(g)   \right|\leq\| \mu \|\| \scal{U(\cdot)v}{w} \|
	\leq \| \mu \|\| v \|\| w \|.
\end{equation}

\subsection{Representation on a Hilbert space}\index{Hilbert space}
%----------------------------------------------

Let $H$ be a Hilbert space and $v\in H$. The map $\dpt{\phi_v}{H}{\eC}$,
\[
	\phi_v(w)=\scal{v}{w}
\]
is linear of norm $\| w \|$ and then is bounded. This is an element of $H'$. A great theorem allows us to identify $H$ and $H'$ by $v\to\phi_v$.

\begin{theorem}[Riesz-Fisher]\index{Riesz-Fisher theorem}
	Let $H$ be a Hilbert space and $\xi\in H'$. Then there exists one and only one $v\in H$ such that
	\[
		\xi(w)=\scal{v}{w}
	\]
	for all $w\in H$. In particular, $H'\simeq H$.
\end{theorem}

Let us now consider a continuous, linear and unitary representation $\dpt{U}{G}{\End H}$. For given measure $\mu$ and vector $v$, we consider $\dpt{T_{\mu,v}}{H}{\eC}$,
\[
	T_{\mu,v}(w)=\int_G\scal{U(g)v}{w}.
\]
Equation \eqref{eq:Tmuvborn} shows that it is continuous and Riesz-Fischer gives us a vector $u$ such that $T_{\mu,v}(w)=\scal{u}{w}$. The so defined vector $u$ is written $U(\mu)v$:
\begin{equation}
	\int_G \scal{U(g)v}{w}\,d\mu(g)=\scal{U(\mu)v}{w}
\end{equation}
is the definition of $U(\mu)\in\End H$. As notation principle, we write
\[
	U(\mu)=\int_GU(g)\,d\mu(g).
\]

\begin{proposition}

	This constructions gives a morphism between algebra of bounded measures (the algebra product is the convolution) and $\End H$:
	\begin{equation}
		U( \mu\star\nu)=U(\mu)\circ U(\nu)
	\end{equation}

\end{proposition}


\begin{proof}
	We have
	\begin{equation}
		\scal{U(\mu\star\nu)v}{w}=\int_G \scal{U(g)v}{w}d(\mu\star\nu)(g)
		=(\mu\star\nu)\scal{U(\cdot)v}{w}
		=\mu(f_{\nu})
	\end{equation}
	where $f_{\nu}(g)=\int_G\scal{U(gh)v}{w}d\nu(h)$. Then
	\begin{equation}
		\begin{split}
			\scal{U(\mu\star\nu)v}{w} & =\int_G\int_G \scal{U(h)v}{U(g)^*w}\,d\nu(h)d\mu(g) \\
			                          & =\int_G\scal{U(\nu)v}{U(g)^*w}\,d\mu(g)             \\
			                          & =\scal{U(g)\circ U(\nu)v}{w}.
		\end{split}
	\end{equation}
\end{proof}

\subsection{Slightly more general}\quext{Tout ceci est \'a pr\'eciser.}
%--------------------------------

Let $\mu\in M_0(G)$ and a continuous representation $\dpt{T}{G}{\End V}$ where $V$ is locally convex\quext{Ce qui implique que $\End(V)$ est locallement convexe pour la topologie forte, il semble que cela joue un r\^ole.}. We can weakly integrate $T$ on $G$ for the measure $\mu$ by setting that
\[
	\int_G T(g)\,d\mu(g)\in\left( \End(V)' \right)^*
\]
such that for all $\chi\in\End(v)'$,
\begin{equation}
	\scal{\int_G T(g)\,d\mu(g)}{\chi}=\int_G\scal{\chi}{T(g)}\,d\mu(g).
\end{equation}
Since $T$ is continuous and $\mu$ has compact support, one can see that
\[
	\int_GT(g)\,d\mu(g)\in\End(V)
\]
in the sense of the usual embedding $\left( \End(v)' \right)^*\subset\End(V)$. This element is denoted by $T(\mu)$.

\subsection{Representation of \texorpdfstring{$M_0(G)$}{M0G}}
%--------------------------------------
\quext{Ceci n'est pas complètement compris non plus}

Let $\dpt{T}{G}{\End(V)}$, a representation, $\mu$ a compact supported measure on $G$. Then there exists one and only one $A\in\End(V)$ such that for all $\chi\in\End(V)'$, we have
\begin{equation}
	\chi(A)=\int_G\chi(T(g))\,d\mu(g),
\end{equation}
this $A$ is denoted by $T(\mu)$. It fulfils
\begin{equation}
	\chi(T(\mu))=\int_g\chi(T(g))\,d\mu(g).
\end{equation}
This way to define $\dpt{T}{M_0(G)}{\End(V)}$ is a representation. Indeed, $T(\mu\star\nu)$ is defined by
\begin{equation}
	\chi(T(\mu\star\nu))	=(\mu\star\nu)\scal{\chi}{T(.)}
	=\int_G\int_G\scal{\chi}{T(gh)}\,d\nu(h)\,d\mu(g).
\end{equation}
Let us suppose $\chi(T(g)\circ T(h))=\chi(T(g))\chi(T(h))$; in this case Fubini theorem gives
\begin{equation}
	\begin{split}
		(\mu\star\nu)\scal{\chi}{T(.)} & =\int_G\int_G\scal{\chi}{T(g)}d\mu(g)\scal{\chi}{T(h)}d\nu(h) \\
		                               & =\chi(T(\mu))\chi(T(\nu)).
	\end{split}
\end{equation}
So for all such $\chi$, we have
\[
	\chi\big(T(\mu\star\nu)\big)=\chi\big(T(\mu)\circ T(\nu)\big).
\]
It is not sufficient to conclude that $T(\mu\star\nu)=T(\mu)\circ T(\nu)$ because $G$ is not abelian\quext{D'où le fait que je ne considère pas ceci comme bien compris.}.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{A boundary aware Sobolev space}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

We want to define \( H_0^1(\Omega)\) as the subset of \( H^1(\Omega)\) made of the functions vanishing on \( \partial \Omega\).  But since the elements of \( H^1(\Omega)\) are class of functions, and since \( \partial\Omega\) is of zero measure, such a definition makes no sense. Instead we define
\begin{definition}      \label{DEFooFICWooBWCDyO}
	The space \( H^1_0(\Omega)\) is the closure of \( \swD(\Omega)\) in \( H^1(\Omega)\).
\end{definition}
Notice that \( \swD(\Omega)\) is included in \( H^1(\Omega)\), so that the definition makes sense.

\begin{normaltext}
	The intuitive setting of this definition is the following. If \( v\in H^1_0(\Omega)\), we have a sequence \( v_i\in \swD(\Omega)\) such that
	\begin{equation}
		\| v-v_i \|_{H^1(\Omega)}\to 0.
	\end{equation}
	If one forgets about the classes, for each \( i\) one has \( v_i(x)=0\) when \( x\in\partial\Omega\), so with the limit \( v=0\) on \( \partial\Omega\).

	Due to the class stuff, this is not the truth, but the motivation for the definition~\ref{DEFooFICWooBWCDyO}.
\end{normaltext}

\begin{lemma}[\cite{ooXRCOooCFWVg}]
	The formula
	\begin{equation}
		| u |_{1,\Omega}=\| \nabla u \|_{L^2(\Omega)}=\left( \sum_{i=1}^d\int_{\Omega}\left( \frac{ \partial u }{ \partial x_i } \right)^2 \right)^{1/2}
	\end{equation}
	is a norm\footnote{Definition~\ref{DefNorme}.} on \( H_0^1(\Omega)\).
\end{lemma}

\begin{proof}
	The condition \( | \lambda u |_{1,\Omega}=| \lambda | | u |_{1,\Omega}\) is immediate. The triangular inequality is shown in much the same way as the one for the euclidian norm, see \eqref{EQooRYNYooTzZpPz}.

	The point to be proven is that \( | u |_{1,\Omega}=0\) only if \( u=0\) in the sense of the classes. Let \( | u |_{1,\Omega}=0\); since each of the \( d\) integrals is positive we have
	\begin{equation}
		\int_{\Omega}\left( \frac{ \partial u }{ \partial x_i } \right)^2=0
	\end{equation}
	for every \( i=1,\ldots, d\). Since \( (\partial_i u)^2\geq 0\) we deduce \( \partial_iu=0\) almost everywhere. Now, from a dimensional generalization of proposition~\ref{PropLGoLtcS} we get the conclusion\quext{If you know a precise statement of the ``dimensional generalization'', let me know.}.
\end{proof}

So now we consider the metric space
\begin{equation}
	\big( H^1_0(\Omega),| . |_{1,\Omega} \big).
\end{equation}
The norm on \( H^1(\Omega)\) given by the inner product \eqref{EQooQRMKooLaMpcp} can be written
\begin{equation}
	\| u \|_{H^1(\Omega)}=\| u \|_{L^2(\Omega)}+\| \nabla u \|_{L^2(\Omega)}=\| u \|_{L^2(\Omega)}+| u |_{1,\Omega}.
\end{equation}

\begin{lemma}       \label{LEMooEVQKooYoZmbH}
	Let \( v_i\in H_0^1(\Omega)\) satisfying \( v_i\stackrel{H^1(\Omega)}{\longrightarrow}v\). Then
	\begin{enumerate}
		\item
		      \( v_i\stackrel{H_0^1(\Omega)}{\longrightarrow}v\)
		\item
		      \( v_i\stackrel{L^2(\Omega)}{\longrightarrow}v\)
		\item
		      \( \| v_i \|_{L^2}\to \| v \|_{L^2}\)
		\item
		      \( | v_i |_{1,\Omega}\to | v |_{1,\Omega}\).
	\end{enumerate}
\end{lemma}

\begin{proof}
	By hypothesis we have
	\begin{equation}
		\| v_i-v \|_{H^1}=\| v_i-v \|_{L^2}+| v_i-v |_{1,\Omega}\to 0.
	\end{equation}
	Since the two terms are positive, they separately converge to \( 0\). Thus \( \| v_i-v \|_{L^2}\to 0\) and \( | v_i-v |_{1,\Omega}\to 0\). This means \( v_i\stackrel{L^2}{\longrightarrow}v\) and \( v_i\stackrel{H_0^1}{\longrightarrow}v\).

	The two last statement about the norms are immediate consequences of the continuity of the norm.
\end{proof}

\begin{theorem}[Poincaré inequality\cite{ooXRCOooCFWVg}]        \label{THOooMIHQooYShOps}
	Let \( \Omega\) be an open part of \( \eR^d\) which is bounded in at least one direction. There exists a constant \( C\) (which can depend on \( \Omega\)) such that
	\begin{equation}
		\| v \|_{L^2(\Omega)}\leq C\| v \|_{1,\Omega}
	\end{equation}
	for every \( v\in H_0^1(\Omega)\)
\end{theorem}

\begin{proof}
	Let us first consider \( v\in\swD(\Omega)\) and extend \( v\) with \( 0\) outside \( \Omega\). For the sake of notational simplicity we suppose that \( \Omega\) is bounded in the direction \( x_1\), that is \( \Omega\subset \{ x\tq x_1\in \mathopen] a , b \mathclose[ \}\).

		Since \( v\) has compact support in \( \Omega\), we have \( v(a,x')=0\) for every \( x'\in \eR^{d-1}\) and we can write
		\begin{equation}
			v(x_1,x')=   \int_a^{x_1}(\partial_1v)(t,x')dt=\langle 1, \partial_1v\rangle_{L^2\big( \mathopen] a , x_1 \mathclose[ \big)},
		\end{equation}
		so that
		\begin{subequations}
			\begin{align}
				| v(x_1,x') |^2 & \leq \langle 1, 1\rangle \langle \partial_1v, \partial_1v\rangle \\
				                & =(x_1-a)\int_a^{x_1}| \partial_1 v|^2                            \\
				                & \leq(b-a)\int_a^b| \partial_1v |^2.
			\end{align}
		\end{subequations}
		Let us integrate that inequality over \( x'\in \eR^{d-1}\):
		\begin{equation}
			\int_{\eR^{d-1}}| v(x_1,x') |^2dx'\leq (b-a)\int_{\eR^{d-1}}\int_a^b| \partial_1v |^2=(b-a)\int_{\eR^d}| \partial_1v |^2=(b-a)\| \partial_1v \|^2_{L^2(\eR^d)}.
		\end{equation}
		We used the Fubini theorem~\ref{ThoFubinioYLtPI}. This is allowed because \( v\) is compactly supported, so that \( | \partial_1v |\) is integrable on \( \eR^{d-1}\times \mathopen] a , b \mathclose[\).

		We integrate with respect to \( x_1\) over \( \mathopen] a , b \mathclose[\). On the left we have
	\begin{equation}
		\int_a^b\int_{\eR^{d-1}}| v(x_1,x') |^2dx'dx_1=\int_{\eR^d}| v(x) |^2dx,
	\end{equation}
	And on the right the integration is a simple multiplication by \( (b-a)\):
	\begin{equation}
		\| v \|^2_{L^2(\eR^d)}\leq (b-a)^2\| \partial_1v \|^2_{L^2(\eR^d)}.
	\end{equation}
	Now we have
	\begin{equation}
		\| v \|^2_{L^2}\leq (b-a)^2\| \partial_1v \|^2\leq C\sum_{i=1}^d\| \partial_1v \|^2=C| v |_{1,\Omega}
	\end{equation}
	where \( C\) is a majoration of \( (b-a)^2\) and \( 1\).

	The result is proved for \( v\in\swD(\Omega)\).

	Let now consider \( u\in H_0^1(\Omega)\). By definition, there exists a sequence \( v_i\in\swD(\Omega)\) such that
	\begin{equation}
		v_i\stackrel{H^1(\Omega)}{\longrightarrow}u.
	\end{equation}
	For each \( i\) we have \( \| v_i \|^2_{L^2(\eR^d)}\leq C| v_i |_{1,\Omega}\). Taking the limit and using the lemma~\ref{LEMooEVQKooYoZmbH} to enter the limits inside the norms we get the result.
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Smooth diffeomorphisms}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

We already defined the Sobolev spaces \( H^s(\eR^d)\) in definition~\ref{DEFooWEAQooAIWBwx}. Let \( U\) and \( V\) be open parts of \( \eR^d\) and consider a \(  C^{\infty}\) diffeomorphism \( \psi\colon U\to V\) whose derivatives are bounded.

For \( u\in  C^{\infty}(U)\) we write
\begin{equation}        \label{EQooHSVBooIZRxzh}
	\begin{aligned}
		Tu\colon V & \to \eC                        \\
		x          & \mapsto (u\circ \psi^{-1})(x).
	\end{aligned}
\end{equation}

A diffeomorphism \( \psi\colon U\to V\) applies to the functions by
\begin{equation}        \label{EQooMZSEooATfSTR}
	\begin{aligned}
		\psi\colon \Fun(U) & \to \Fun(V)              \\
		u                  & \mapsto u\circ\psi^{-1}.
	\end{aligned}
\end{equation}

\begin{propositionDef}      \label{PROPooXAOKooQSBKHg}
	If \( T\in \swD'(U)\) we define \( \psi T\) by
	\begin{equation}
		\langle \psi T, \varphi\rangle_V=\langle T, J\cdot(\varphi\circ \psi)\rangle_U
	\end{equation}
	for every \( \varphi\in\swD'(V)\).

	\begin{enumerate}
		\item       \label{ITEMooXHELooYhXNRs}
		      This defines a distribution \( \psi T\in \swD'(V)\).
		\item       \label{ITEMooGDCYooVDFpuy}
		      The so defined map \( \psi\colon \swD'(U)\to \swD'(V)\) is bijective.
		\item       \label{ITEMooNGSJooEdRgHt}
		      The so defined map \( \psi\colon \swD'(U)\to \swD'(V)\) is continuous.
	\end{enumerate}

\end{propositionDef}

\begin{proof}
	We have to show that the map \( \psi T\colon \swD(V)\to \eC\) is continuous or, in other words, if \( \varphi_n\stackrel{\swD(V)}{\longrightarrow}0\) we have to show that \( \langle \psi T, \varphi_n\rangle_V\to 0\) in \( \eC\).

	In terms of the seminorms we have to prove that for every \( m\in \eN\) and every compact \( K\subset V\) we have
	\begin{equation}
		p_{K,m}\big( J\cdot(\varphi_n\circ \psi) \big)\to 0
	\end{equation}
	where \( J\) is the Jacobian of \( \psi\) and
	\begin{equation}
		p_{K,m}(f)=\sum_{| \alpha |\leq m}\| \partial^{\alpha}f \|_{K,\infty}.
	\end{equation}
	By definition of \( \psi T\) and the fact that \( T\) is continuous we have equivalence of these three facts:
	\begin{subequations}
		\begin{align}
			\langle \psi T, \varphi_n\rangle_V\stackrel{\eC}{\longrightarrow}0                  \\
			\langle  T, J\cdot (\varphi_n\circ \psi)  \rangle_U\stackrel{\eC}{\longrightarrow}0 \\
			J\cdot(\varphi_n\circ\psi)\stackrel{\swD(U)}{\longrightarrow}0.
		\end{align}
	\end{subequations}
	We are going to prove the last one. The first step is to use Leibniz formula and some obvious notations like \( \alpha-\beta\) where \( \alpha\) and \( \beta\) are multiindex:
	\begin{equation}
		\sum_{| \alpha |\leq m}\| \partial^{\alpha}J\cdot(\varphi_n\circ\psi) \|_{K}=\sum_{| \alpha |\leq m}\| \sum_{\beta\leq \alpha}(\partial^{\beta}J)\cdot \partial^{\alpha-\beta}(\varphi_n\circ\psi) \|_K
	\end{equation}
	Since \( \psi\) is a diffeomorphism, \( J\) is bounded and from the fact that \( K\) is compact, each of the \( \partial^{\gamma}J\) is bounded. Thus we have
	\begin{equation}
		p_{m,K}(J\cdot (\varphi_n\circ \psi))\leq \sum_{| \alpha |\leq m}\|c \sum_{\beta\leq \alpha} \partial^{\beta}(\varphi_n\circ\psi) \|_{K}
	\end{equation}
	where the constant \( c\) depends on \( K\) and \( m\).

	We show by induction on \( | \beta |\) that for every sequence \( ( \varphi_n)\) in \( \swD(V)\) with \( \varphi_n \stackrel{\swD(V)}{\longrightarrow}0\) we have \(  \| \partial^{\beta}(\varphi_n\circ\psi) \|_{K,\infty}\to 0\). Starting with \( | \beta |=0\) we have
	\begin{equation}
		\| | \varphi_n\circ\psi | \|_K=\| \varphi_n \|_{\psi(K)}.
	\end{equation}
	Since \( \psi(K)\) is compact (proposition~\ref{ThoImCompCotComp}), the latter is one of the seminorms on \( V\), so that \( \| \varphi_n \|_\psi(K)\to 0\). For the induction we compute
	\begin{subequations}
		\begin{align}
			\partial_i\big( \partial^{\beta}(\varphi_n\circ\psi) \big) & =\partial^{\beta}\big( \partial_i(\varphi_n\circ\psi) \big)                                                                                               \\
			                                                           & =\partial^{\beta}\left(  x\mapsto  \sum_k\frac{ \partial \varphi_n }{ \partial y_k }\big( \psi(x)\big)\frac{ \partial \psi_k }{ \partial x_i }(x) \right) \\
			                                                           & \leq c\partial^{\beta}\left( \sum_k\frac{ \partial \varphi_n }{ \partial y_k }\circ\psi \right)
		\end{align}
	\end{subequations}
	where we have done the majoration \( \frac{ \partial \psi_k }{ \partial x_i }(x)\leq c\) which is legal because the function is continuous on a compact and there is a finite number of couple \( (k,i)\), so the bound can be taken uniformly with respect to \( x\), \( k\) and \( i\) in the same time. Now the function \( \frac{ \partial \varphi_n }{ \partial y_n }\) is an element of \( \swD(V)\) and by the induction hypothesis,
	\begin{equation}
		\| \partial^{\beta}\left( \sum_k\frac{ \partial \varphi_n }{ \partial y_k }\circ\psi \right) \|_K\to 0.
	\end{equation}

	This finishes the proof of point~\ref{ITEMooXHELooYhXNRs}. We pass to the points~\ref{ITEMooGDCYooVDFpuy} and~\ref{ITEMooNGSJooEdRgHt}.
	\begin{subproof}
		\spitem[\( \psi\colon \swD'(U)\to \swD'(V)\) is surjective]

		Let \( T_2\in\swD'(V)\). We define \( T_1\) on \( \swD(U)\) by \( T_1=\psi^{-1} T_2\); proposition~\ref{PROPooXAOKooQSBKHg} shows that \( T_1\) is a distribution over \( \swD(U)\). Moreover \( \psi T_1=T_2\). So \( \psi\) is surjective.

		\spitem[\( \psi\colon \swD'(U)\to \swD'(V)\) is injective]

		Suppose \( \psi T_1=0\), so
		\begin{equation}
			\langle \psi T_1, \phi\rangle_V =\langle T_1, J\times (\phi\circ\psi)\rangle_U=0
		\end{equation}
		for every \( \phi\in \swD(V)\). Since \( J\) is itself a \(  C^{\infty}\) function, in fact every element \( \varphi\in \swD(U)\) can be written under the form \( J\times (\phi\circ\psi)\) for some \( \phi\in\swD(V)\). We deduce \( T_1=0\).

		\spitem[\( \psi\colon \swD'(U)\to \swD'(V)\) is continuous]

		Let \( T_n\stackrel{\swD'(U)}{\longrightarrow}O\); we have to show that \( \psi T_n\stackrel{\swD'(V)}{\longrightarrow}0\). We use the proposition~\ref{PropEUIsNhD}: for \( \phi\in\swD(V)\) we have to show that \( (\psi T_n)(\phi)\to 0\), that is:
		\begin{equation}
			\langle \psi T_n, \phi\rangle_V=\langle T_n, J\times (\phi\circ\psi)\rangle_U.
		\end{equation}
		Since \( T_n\) converges to zero in \( \swD'(U)\), the limit of the right hand side is zero.
	\end{subproof}
\end{proof}

\begin{lemma}       \label{LEMooJHFUooWdAlar}
	Let a smooth diffeomorphism \( \psi\colon U\to V\) and a smooth map \( u\colon U\to \eC\). We look at the composition
	\begin{equation}
		u\circ\psi^{-1}\colon V\to \eC.
	\end{equation}
	We denote by \( y\) the coordinates on \( V\) and by \( x\) the ones on \( U\). Let \( \alpha\) be a \( y\)-multiindex. Then
	\begin{equation}
		\partial^{\alpha}(u\circ\psi^{-1})(y)=\sum_{| I |\leq | \alpha |}c_{I \alpha}(y)(\partial^{I}u)\big( \psi^{-1}(y) \big)
	\end{equation}
	for some bounded functions \( c_{I \alpha}\).

	Written under a compact form,
	\begin{equation}
		\partial^{\alpha}(u\circ\psi^{-1})=\sum_{| I |\leq | \alpha |}c_{I \alpha}(\partial^Iu)\circ\psi^{-1}.
	\end{equation}
\end{lemma}

\begin{proof}
	To be clear: \( \beta\) is a \( x\)-mutiindex. For \( \alpha\) of length \( 1\) we have
	\begin{equation}
		\frac{ \partial  }{ \partial y_i }\big( u\circ\psi^{-1} \big)(y)=\sum_k\frac{ \partial u }{ \partial x_k }\big( \psi^{-1}(y) \big)\frac{ \partial \psi_k^{-1} }{ \partial y_i }(y).
	\end{equation}
	Then applying the Leibniz rule we will have multi-derivatives of \( u\) with respect to \( x\), always taken at the point \( \psi^{-1}(y)\) and then derivatives of the components of \( \psi^{-1}\) with respect to \( y\) taken at the point \( y\). The derivatives on \( u\) are derivatives with respect to \( x\), and each derivative with respect to \( y\) on \( u\circ\psi^{-1}\) will create derivatives on $u$ with respect to all the components of \( x\). Thus the sum is over the \( x\)-multiindiex of size lower or equal to the number of \( y\)-derivatives on \( u\circ\psi^{-1}\).
\end{proof}

\begin{proposition}[\cite{ooRRCQooJwnUgB}]
	Let \( m\in \eN\) and a diffeomorphism \( \psi\colon U\to V\) such that all the derivatives of \( \psi\) and \( \psi^{-1}\) are bounded. We consider the map
	\begin{equation}
		\begin{aligned}
			\psi\colon \Fun(U) & \to \Fun(V)              \\
			u                  & \mapsto u\circ\psi^{-1}.
		\end{aligned}
	\end{equation}
	\begin{enumerate}
		\item       \label{ITEMooNJZOooOrzQIT}
		      We have
		      \begin{equation}
			      \psi\colon L^2(U)\to L^2(V)
		      \end{equation}
		      surjectively.
		\item
		      We have the diffeomorphisms
		      \begin{subequations}
			      \begin{align}
				      \psi\colon H^m(U)\to H^m(V)                     \\
				      \psi\colon  C^{\infty}_0(U)\to  C^{\infty}_0(V) \\
				      \psi\colon \swD'(U)\to \swD'(V).
			      \end{align}
		      \end{subequations}
		      The last one is defined by
		      \begin{equation}
			      \langle \psi T, \varphi\rangle_V=\langle T, J\cdot(\varphi\circ\psi)\rangle_U.
		      \end{equation}
	\end{enumerate}
\end{proposition}

\begin{proof}
	The hypothesis on \( \psi\) implies in particular that \( d\psi\) and \( d\psi^{-1}\) are bounded.
	\begin{subproof}
		\spitem[\( \psi\colon L^2(U)\to L^2(V)\) is surjective]
		We consider the operation \( \psi\) on the functions as explained in equation \eqref{EQooMZSEooATfSTR}. We know that \( x\mapsto | f(x) |^2\) is integrable on \( U\). Thus the change of variable theorem~\ref{THOooUMIWooZUtUSg}\ref{ITEMooAJGDooGHKnvj} the function \( | f |^2\circ\psi^{-1}\times | J |\) is integrable on \( V\). That is the function \( y\mapsto | f\big( \psi^{-1}(y) \big) |^2| J_{\psi}(y) |\). Recall that
		\begin{equation}
			J_{\psi}(a)=\det(d\psi_a),
		\end{equation}
		and that by hypothesis, this is bounded. Also by hypothesis, the inverse is bounded. If \( c\) is a majoration of \( | 1/J |\), then
		\begin{equation}
			| f\circ\psi |^2=| f\circ\psi |^2\times | J |\times | 1/J |\leq c| f\circ\psi |^2\times | J |.
		\end{equation}
		The right hand side is integrable, so we deduce that \( | f\circ\psi |^2\) is integrable. At the end of the day, the function \( f\in L^2(V)\) is the image by \( \psi\) of \( f\circ\psi^{-1}\) which belongs to \( L^2(U)\).

		\spitem[\( \psi\colon \swD(U)\to \swD(V)\) is bijective and continuous]
		The bijection is the fact that \( \psi\) itself is a bijection of class \(  C^{\infty}\), and that it transforms a compact into a compact. The continuity is correct for topology of the norm \( \| . \|_{\infty}\) because \( \psi\) turns out to be an isometry.

		\spitem[\( \psi\colon \swD'(U)\to \swD'(V)\) is bijective and continuous]
		That is the proposition~\ref{PROPooXAOKooQSBKHg}.

		\spitem[\( \psi\colon H^m(U)\to H^m(V)\)]

		We denote by \( y\) the coordinates on \( V\) and by \( x\) the ones on \( U\). Let \( u\in H^m(U)\), let \( \phi\in\swD(V)\) and a \( y\)-multiindex \( \alpha\) with \( | \alpha |\leq m\). By definition of the weak derivative (and the fact that \( \phi\) is compactly supported, so that it vanishes at the boundaries of \( V\)) we have
		\begin{subequations}
			\begin{align}
				\langle u\circ\psi^{-1}, \partial^{\alpha}\phi\rangle_V & =\langle u, | J_{\psi}| \partial^{\alpha}\phi \rangle_V   \label{subEQooNSBJooCbtTNI}                                 \\
				                                                        & =\langle u, \sum_{| I |\leq | \alpha |}c_{\alpha I}\partial^I\tilde \phi\rangle_U  \label{SUBEQooYBCCooIdpsxE}        \\
				                                                        & =\sum_{ |I|\leq |\alpha|}\langle u, c_{\alpha I}\partial^{ I}\tilde\phi\rangle_U                                      \\
				                                                        & =\sum_{ |I|\leq |\alpha|}\langle \bar c_{\alpha I}u, \partial^{ I}\tilde \phi\rangle_U                                \\
				                                                        & =\sum_{ |I|\leq |\alpha|}\langle \partial^{ I}(c_{\alpha I}u), \tilde \phi\rangle_U       \label{SUBEQooCSHLooTdTHvf}
			\end{align}
		\end{subequations}
		Justifications:
		\begin{itemize}
			\item
			      For \eqref{subEQooNSBJooCbtTNI}: the change of variable formula under the form \eqref{EQooQKARooELPCFO}.
			\item
			      For \eqref{SUBEQooYBCCooIdpsxE}, we wrote \( \tilde \phi=\phi\circ\psi\) and used the lemma~\ref{LEMooJHFUooWdAlar} with \( \partial^{\alpha}(\tilde \psi\circ\psi^{-1})\). We have included the function \( | J |\) in the coefficients \( c_{\alpha I}\).

			      \spitem
			      For \eqref{SUBEQooCSHLooTdTHvf} we redefined \( c_{\alpha I}\) in order to include \( (-1)^{|  I |}\) and the complex conjugation.

		\end{itemize}

		Up to now we have
		\begin{equation}
			\langle u\circ\psi^{-1}, \partial^{\alpha}\phi\rangle_V =  \sum_{| I |\leq | \alpha |}\langle \partial^{I}(c_{\alpha I}u), \tilde \phi\rangle_U
		\end{equation}
		where \( \tilde \phi=\phi\circ\psi\in \swD(U)\) and the coefficients (and all the derivatives) \( c_{\alpha I}\) are smooth and bounded because they are combinations of derivatives of the \( \psi\)'s components.

		We can again use the Leibniz rule on the derivative \( \partial^{I}(c_{\alpha I} u)\). We will get all the derivatives \( \partial^Ju\) (\( J\) are sub-indices of \( I\)) with coefficients that are again derivatives of \( c_{\alpha I}\). Thus we write
		\begin{equation}
			\partial^I(c_{\alpha I}u)=\sum_{J\leq I}c'_{\alpha J}\partial^Ju,
		\end{equation}
		and since \( J\) takes any value contained in \( I\) and \( I\) every values with length lower than \( | \alpha |\) we can as well write
		\begin{equation}
			\langle u\circ\psi^{-1}, \partial^{\alpha}\phi\rangle_V =  \sum_{| I |\leq | \alpha |}\langle \partial^{I}(c_{\alpha I}u), \tilde \phi\rangle_U =\sum_{| I |\leq | \alpha |}\langle c'_{\alpha I}\partial^Iu, \tilde \phi\rangle_U.
		\end{equation}

		We have \( | I |\leq | \alpha |\leq m\), so \( \partial^Iu\in L^2(U)\). Since \( c'_{\alpha I}\) is bounded, the product \( c'_{\alpha I}\partial^Iu\) belongs to \( L^2(U)\) too. The integral change of variable formula \eqref{EQooQKARooELPCFO} reads in our case:
		\begin{equation}
			\langle f, g\rangle_U=\langle f\circ \psi^{-1}, (g\circ\psi^{-1})| J^{-1} |\rangle_V,
		\end{equation}
		with \( \tilde \phi\) in the role of \( g\):
		\begin{equation}
			\langle f, \tilde g\rangle =\langle | J^{-1} |(f\circ\psi^{-1}), \phi\rangle_V
		\end{equation}
		Now with \( \sum_{| I |\leq | \alpha |}c'_{\alpha I}\partial^Iu\) in the role of \( f\) we have \( | J^{-1} |(f\circ\psi^{-1})\in L^2(V)\) because of point~\ref{ITEMooNJZOooOrzQIT} and the fact that \( | J^{-1} |\) is bounded, so that the product makes sense and we have shown that the function
		\begin{equation}
			f'=| J^{-1} |\big( \sum_{| I |\leq | \alpha |}c'_{\alpha I}\partial^Iu \big)\circ\psi^{-1}
		\end{equation}
		is an element of \( L^2(V)\) satisfying
		\begin{equation}
			\langle u\circ\psi^{-1}, \partial^{\alpha}\phi\rangle_V =   \langle f', \phi\rangle_V
		\end{equation}
		for every \( \phi\in\swD(V)\). This condition is the definition of \(   (-1)^{\alpha} \partial^{\alpha}(u\circ\psi^{-1})\). Thus we have
		\begin{equation}
			\partial^{\alpha}(u\circ\psi^{-1})=(-1)^{\alpha}f'\in L^2(V).
		\end{equation}
		Notice that the fact that \( \partial^{\alpha}(u\circ\psi^{-1})\) exists is not a big deal: it always weakly exists. The very point we shown is that the derivative is \( L^2(V)\).

		Since \( \alpha\) is  amultiindex of any size up to \( m\) we shown that \( u\circ\psi^{-1}\in H^m(V)\).


		\spitem[\( \psi\colon H^m(U)\to H^m(V)\) is continuous]

		Let \( u\in H^m(U)\) and a smooth diffeomorphism \( \psi\colon U\to V\); we consider \( \psi u=u\psi^{-1}\) and we want to prove an estimation like \( \| \psi u \|_{H^m(V)}\leq C\| u \|_{H^m(U)}\). We use the proposition~\ref{PROPooVEMGooYKhMFy} with \( \lambda=1\), \( V=L^2(V)\) and \( A=\swD(V)\):
		\begin{equation}
			\| \partial^{\alpha}(\psi u) \|_{L^2(V)}=\sup\{ | \langle \partial^{\alpha}(\psi u), \phi\rangle_V |\tq \phi\in\swD(V)\text{ and }\| \phi \|_{L^2(V)}\leq 1 \}.
		\end{equation}
		Using lemme~\ref{LEMooJHFUooWdAlar} we have
		\begin{equation}
			\clubsuit=\langle \partial^{\alpha}(\psi u), \phi\rangle_V=\sum_{| I |\leq | \alpha |}\langle c_{\alpha I}(\partial^Iu)\circ\psi^{-1}, \phi\rangle_V\leq C\sum_{| I |\leq | \alpha |}\langle (\partial^Iu)\circ \psi^{-1}, \phi\rangle_V.
		\end{equation}
		The first majoration is \( C=\sup_{I,x}c_{\alpha I}(x)\). In the next lines, we will often modify \( C\) in order to include other majorations. With the change of variable formula \eqref{EQooQKARooELPCFO} and including a majoration of \( | J_{\psi} |\) in the constant \( C\),
		\begin{equation}
			\clubsuit=\sum_{| I |\leq | \alpha |}\langle \partial^Iu, (\phi\circ\psi)| J_{\psi} |\rangle_U\leq C\sum_{| I |\leq | \alpha |}\langle \partial^Iu, \phi\circ\psi\rangle_U.
		\end{equation}
		Now, again using the change of variable formula (but in the reverse sense) we have
		\begin{equation}
			\| \phi\circ\psi \|^2_{L^2(u)}=\langle \phi\circ\psi, \phi\circ\psi\rangle_U=\langle \phi, \phi| J^{-1} |\rangle_V\leq K\| \phi \|^2_{L^2(V)}
		\end{equation}
		where \( K\) is a majoration of \( | J^{-1} |\). We can continue the computation:
		\begin{subequations}
			\begin{align}
				\| \partial^{\alpha}(\psi u) \|_{L^2(V)} & =\sup\{ | \clubsuit |\tq \phi\in\swD(V)\text{ and }\| \phi \|_{L^2(V)}\leq 1 \}                                                                   \\
				                                         & \leq \sup\{ C|\sum_{| I |\leq | \alpha |}\langle \partial^Iu, \phi\circ\psi\rangle_U|\tq \phi\in\swD(V)\text{ and }\| \phi \|_{L^2(V)}\leq 1 \}   \\
				                                         & \leq C\sum_{| I |\leq | \alpha |} \sup\{ |\langle \partial^Iu, \varphi\rangle_U|\tq \varphi\in\swD(U)\text{ and }\| \varphi \|_{L^2(U)}\leq K  \} \\
				                                         & \leq C\sum_{| I |\leq | \alpha |}\| \partial^Iu \|_{L^2(U)}.
			\end{align}
		\end{subequations}
		We have:
		\begin{equation}
			\| \partial^{\alpha}(\psi u) \|_{L^2(V)}\leq C\sum_{| I |\leq | \alpha |}\| \partial^Iu \|_{L^2(U)}\leq C\| u \|_{H^m(U)}
		\end{equation}
		because of the expression \eqref{EQooMCWMooKKTqzM} of the norm on \( H^m(U)\). Now we can conclude:
		\begin{equation}
			\| \psi u \|_{H^m(V)}=\sum_{| \alpha |\leq m}\| \partial^{\alpha}(\psi u) \|_{L^2(V)}\leq C\sum_{| \alpha |\leq m}\| u \|_{H^m(V)} = a C\| u  \|_{H^m(U)}
		\end{equation}
		where \( a\) is the number of terms in the sum.

		\spitem[\( \psi\colon H^m(U)\to H^m(V)\) is a diffeomorphism]

		Replacing \( \psi\) by \( \psi^{-1}\) shows that \( \psi^{-1}\colon H^m(V)\to H^m(U)\) is continuous. Don't forget to show that this is actually the inverse:
		\begin{equation}
			\psi^{-1}(\psi u)=(\psi u)\circ \psi^{-1}=u\circ\psi\circ\psi^{-1}=u.
		\end{equation}
		Notice that in the later equation, the symbol ``$\psi$'' denotes sometimes the map \( \psi\colon U\to V\) and sometimes the map \( \psi\colon \Fun(U)\to \Fun(V)\).
	\end{subproof}
\end{proof}

\begin{remark}
	The hypothesis on the fact that the derivatives of \( \psi\) are bounded is not a weak one. As an example, the map
	\begin{equation}
		\begin{aligned}
			\psi\colon \mathopen] 0 , 1 \mathclose[ & \to \mathopen] 0 , 1 \mathclose[ \\
			x                                       & \mapsto x^2
		\end{aligned}
	\end{equation}
	is a diffeomorphism with Jacobian given by \( J_{\psi}(x)=2x\), so that \( 1/J\) is not bounded on \( \mathopen] 0 , 1 \mathclose[\).
\end{remark}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Restriction operator}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{definition}
	Let \( j=1,\ldots, d\) and \( h\in \eR\). We define the \defe{translation operator}{translation!operator}
	\begin{equation}
		\tau_{j,h}\colon \Fun(\eR^d)\to \Fun(\eR^d)
	\end{equation}
	given by the formula
	\begin{equation}
		\tau_{j,h}(f)(x)=f(x-h e_j)
	\end{equation}
	where \( e_j\) is the canonical unit vector.
\end{definition}

The adjoint operator (definition~\ref{DEFooERIYooIIRLuy}) \( \tau^*_{j,h}\colon L^2(\eR^d)\to L^2(\eR^d)\) is
\begin{equation}
	(\tau^*_{j,h}u)(x)=u(x+he_j).
\end{equation}
Indeed we have
\begin{equation}
	\langle \tau(u), v\rangle_{L^2(\eR^d)}=\int_{\eR^d}\overline{ u(x-he_j) }v(x)dx=\int_{\eR^d}\overline{ u(y) }v(y+he_j)dy=\langle u, \tau^*_{j,h}v\rangle_{L^2(\eR^d)}
\end{equation}
by a simple change of variable \( y=x-he_j\). We immediately see that \( \tau_{j,h}\) is an unitary operator of \( L^2(\eR^d)\).

If \( \Omega\) is an open part of \( \eR^d\) we define the restriction operator \( r_{\Omega}\) by
\begin{equation}
	r_{\Omega}=u|_{\Omega}.
\end{equation}

We define
\begin{equation}
	\eR^d_{+}=\{ x\in \eR^d\tq x_n>0 \},
\end{equation}
and the same for \( \eR^d_-\). We denote by \( r^{\pm}\) the restriction operator to \( \eR^d_{\pm}\). The extension operator is the extension by \( 0\) outside \( \Omega\):
\begin{equation}
	(e_{\Omega}f)(x)=\begin{cases}
		f(x) & \text{if } x\in \Omega \\
		0    & \text{else. }
	\end{cases}
\end{equation}

\begin{normaltext}
	Do you believe that there is a difference between \( \swD\big( \overline{ \eR^d_+ }\big)\) and \( \swD(\eR^d_+)\)? Let us see with \( d=1\). Since the support is closed, a function in \( \swD(\eR_+)\) has to be zero on \( \mathopen] -\infty , \delta \mathclose]\) with \( \delta>0\).

	On the other hand, a function in \( \swD\big( \overline{ \eR^d_+ } \big)\) can be nonzero immediately after \( x=0\):
	\begin{equation}
		f(x)=\begin{cases}
			0                & \text{if } x<0                               \\
			x                & \text{if  } x\in\mathopen[ 0 , 1 \mathclose] \\
			\text{something} & \text{if } x\in \mathopen[ 1 , 2 \mathclose] \\
			0                & \text{if } x>2.
		\end{cases}
	\end{equation}
	where ``something'' stands for something smooth.
\end{normaltext}

\begin{proposition}[\cite{ooRRCQooJwnUgB}]      \label{PROPooCXYRooPTgSLX}
	Some densities.
	\begin{enumerate}
		\item
		      The set \( \swD(\eR^d)\) is dense in \( H^m(\eR^d)\) for every integer \( m\geq 0\).
		\item
		      The set \( r^+\swD(\eR^d)\) is dense in \( H^m(\eR^d_+)\) for every \( m\geq 0\).
	\end{enumerate}
\end{proposition}

\begin{theorem}[\cite{ooRRCQooJwnUgB}]
	There exists a linear continuous operator
	\begin{equation}
		p_{(m)}\colon H^m(\eR^d_+)\to H^m(\eR^d)
	\end{equation}
	such that
	\begin{equation}
		(r^+\circ p_{(m)})u=u
	\end{equation}
	for every \( u\in H^m(\eR^d_+)\).
\end{theorem}

\begin{proof}
	The map \( r^+\) a defined as \( r^+\colon \Fun(\eR^d)\to \Fun(\eR^d)\). Since the norms \( L^2(\eR^d_+)\) are majored by the ones \( L^2(\eR^d)\) we have
	\begin{equation}
		r^+\colon H^m(\eR^d)\to H^m(\eR^d_+).
	\end{equation}

	We initiate by defining the operator \( p_{(m)}\) on a dense subset (see proposition~\ref{PROPooCXYRooPTgSLX}).  Let \( u\in r^+\swD(\eR^d)\). More precisely we choose \( u_0\in\swD(\eR^d)\) and we write \( u=r^+u_0\). We define
	\begin{equation}
		(p_{(m)}u)(x',x_d)=\begin{cases}
			u(x',x_d)                                & \text{if } x_d> 0 \\
			u_0(x',0)                                & \text{if }  x_d=0 \\
			\sum_{k=0}^{m-1}a_ku_0(x',-\lambda_kx_d) & \text{if } x_d<0.
		\end{cases}
	\end{equation}
	Here are some comments ont the definition.
	\begin{itemize}
		\item
		      The value of \( p_{(m)}u\) does not depend on the choice of \( u_0\) among all the elements in \( \swD(\eR^d)\) which restrict to \( u\).
		\item
		      The positivity of \( \lambda_k\) makes that \( -\lambda_kx_d>0\), so that the whole makes sense.
		\item
		      The numbers \( \lambda_0,\ldots,\lambda_{m-1}\) are strictly positive different reals that are arbitrarily chosen.
		\item
		      The coefficients \( a_k\) are the solution of the system
		      \begin{equation}        \label{EQooTHYTooUovXKT}
			      \sum_{k=0}^{m-1}\lambda_k^ja_k=(-1)^j
		      \end{equation}
		      for \( j=0,\ldots, m-1\).
		\item
		      The system \eqref{EQooTHYTooUovXKT} has an unique solution because its matrix is \( A_{kj}=\lambda_k^j\) whose determinant is the non vanishing Vandermonde determinant~\ref{PropnuUvtj}.
	\end{itemize}

	Let us show that \( p_{(m)}(u)\in C^{m-1}(\eR^d)\). The derivatives of \( p_{(m)}u\) with respect to the variables \( x_1\),\ldots, \( x_{d-1}\) do not create problems. Only the ones with respect to \( x_d\) at \( x_d=0\) can be difficult. Now we show by induction that
	\begin{equation}
		(\partial_n^lp_{(m)}u)(x',0)=(\partial_n^lu_0)(x',0)
	\end{equation}
	with several steps.
	\begin{subproof}
		\spitem[First: \( (\partial_np_{(m)}u)(x',0)=(\partial_nu_0)(x',0)\)]

		On the one hand we have
		\begin{equation}
			\lim_{t\to 0^+} \frac{ (p_{(m)}u)(x',t)-(p_(m)u)(x',0) }{ t }=\lim_{t\to 0^+} \frac{ u_0(x',t)-u_0(x',0) }{ t }=(\partial_nu_0)(x',0).
		\end{equation}
		The last equality comes from the fact that for \( u_0\) we know that the limits with \( t\to 0^+\) and \( t\to 0^-\) are equal. On the other hand, we know that \( \sum_{k=0}^{m-1}a_k=1\), so that
		\begin{subequations}
			\begin{align}
				\lim_{t\to 0^-} \frac{ (p_{(m)}u)(x',t)-(p_(m)u)(x',0) }{ t } & =\lim_{t\to 0^+} \frac{ \sum_{k=0}^{m-1}a_ku_0(x',-\lambda_kt)-u_0(x',0) }{ t } \\
				                                                              & =\sum_{k=0}^{m-1}a_k\lim_{t\to 0^-} \frac{ u_0(x',-\lambda_kt)-u_0(x',0) }{ t } \\
				                                                              & =-\sum_{k=0}^{m-1}a_k\lambda_k(\partial_n u_0)(x',0).
			\end{align}
		\end{subequations}
		We made the change of variable \( t'=-\lambda_kt\) to compute the limit.

		\spitem[Second: \( (\partial_n^lp_{(m)}u)(x',x_d)\) with \( x_d<0\)]

		In this case the computation is immediate:
		\begin{equation}
			(\partial_n^lp_{(m)}u)(x',x_d)=\sum_{k=0}^{m-1}a_k(-\lambda_k)^l(\partial_n^lu_0)(x',-\lambda_kx_d).
		\end{equation}

		\spitem[Induction]

		We are going to prove by induction over \( l\) that
		\begin{equation}        \label{EQooVJITooNRgryX}
			(\partial_n^lp_{(m)}u)(x',0)=(\partial_n^lu_0)(x',0).
		\end{equation}
		The case \( l=1\) is already done. So we compute with \( l+1\) assuming that \eqref{EQooVJITooNRgryX} holds. Once again we have to compute separately the limit with \( t\to 0^+\) and \( t\to 0^-\). We have
		\begin{subequations}
			\begin{align}
				\lim_{t\to 0^+} \frac{ (\partial_n^lp_{(m)}u)(x',t)-(\partial_n^lp_{(m)}u)(x',0) }{ t } & =\lim_{t\to 0^+} \frac{   (\partial_n^lu_0)(x',t)-  (\partial_n^lu_0)(x',0) }{ t } \\
				                                                                                        & =(\partial^{l+1}_nu_0)(x',0).
			\end{align}
		\end{subequations}
		Now, the limit with negative \( t\). To be computed:
		\begin{equation}    \label{EQooFKHJooPqYWeF}
			\lim_{t\to 0^-} \frac{ (\partial^l_np_{(m)}u)(x',t)-(\partial_n^lu_0)(x',0) }{ t }.
		\end{equation}
		The numerator can be expanded as
		\begin{equation}
			(-1)^l\sum_{k=0}^{m-1}a_k\lambda_k^l(\partial_n^lu_0)(x',-\lambda_kt)-(\partial_n^lu_0)(x',0).
		\end{equation}
		Since \( (-1)^l\sum_{k=0}^{m-1}a_k\lambda_k^l=1\) we can multiply the second term by that and enter \( (\partial_n^lu_0)(x',0)\) in the sum. What we get is
		\begin{equation}
			(-1)^l\sum_{k=0}^{m-1}a_k\lambda_k^l\big( (\partial_n^lu_0)(x',-\lambda_k t)-(\partial_{n}^lu_0)(x',0) \big).
		\end{equation}
		Back to the limit \eqref{EQooFKHJooPqYWeF} we permute the limit and the sum:
		\begin{subequations}
			\begin{align}
				\lim_{t\to 0^-} \frac{ (\partial^l_np_{(m)}u)(x',t)-(\partial_n^lu_0)(x',0) }{ t } & =(-1)^l\sum_{k=0}^{m-1}\lambda_k^l\lim_{t\to 0^-} \frac{ (\partial_n^lu_0)(x',-\lambda_kt)-(\partial_n^lu_0)(x',0) }{ t }        \\
				                                                                                   & =(-1)^l\sum_{k=0}^{m-1}\lambda_k^l\lim_{t\to 0^+} \frac{    (\partial_n^lu_0)(x',u)- (\partial_n^lu_0)(x',0)   }{ -u/\lambda_k } \\
				                                                                                   & =(-1)^{l+1}\sum_{k=0}^{m+1}\lambda_k^{l+1}(\partial_n^{l+1}u_0)(x',0)                                                            \\
				                                                                                   & =(\partial^{l+1}_nu_0)(x',0).
			\end{align}
		\end{subequations}
		The induction is finished.
	\end{subproof}
	We are now able to prove that \( p_{(m)}u\) is \( C^{m-1}(\eR^d)\). The only point is to show that \( (\partial^l_nu))\) is continuous at \( x_d=0\). The limit with \( x_d>0\) does not pone any problem. For \( x_d<0\),
	\begin{subequations}
		\begin{align}
			\lim_{x_d\to 0^-}(\partial_n^lp_{(m)}u)(x',x_d) & =\sum_{k=0}^{m-1}a_k(-\lambda_k)^l\lim_{x_d\to 0^-}(\partial_n^lu_0)(x',-\lambda_kx_d) \\
			                                                & =\sum_{k=0}^{m-1}a_k(-\lambda_k)^l(\partial_n^lu_0)(x',0)                              \\
			                                                & =(\partial_n^lu_0)(x',0)                                                               \\
			                                                & =(\partial^l_np_{(m)}u)(x',0).
		\end{align}
	\end{subequations}
	When one tries to derive more than \( m-1\) times, we have a possible discontinuity at \( x_d=0\) since we do not have any formula for the sum \( \sum_{k=0}^{m-1}k\lambda_k^m\).

	The function \(p_{(m)}u\) is compactly supported and the derivatives up to the (\( m-1\))-th are continuous. The \( m\)-th derivatives is continuous on \( x_d>0\) and \( x_d<0\). The whole makes
	\begin{equation}
		p_{(m)}u\in H^m(\eR^d).
	\end{equation}

	We still have to prove that \(p_{(m)}\colon r^+\swD(\eR^d)\to H^m(\eR^d)\) is continuous and extends to \( H^m(\eR^d_+)\). We start proving the inequality
	\begin{equation}
		\| p_{(m)}u \|_{H^m(\eR^d)}\leq C \| u \|_{H^m(\eR^d_+)}
	\end{equation}
	for some constant \( C\) that depend on the \( \lambda_i\)'s. By the definition \ref{EQooMCWMooKKTqzM} we know \( \| v \|_{H^m(\eR^d)}=\sum_{| \alpha |\leq m}\| \partial^{\alpha}v \|_{L^2(\eR^d)}\) and what happens on the hyperplane \( x_d=0\) is of no interest. Let's consider a multiindex \( \alpha\) containing \( l\) times the index \( x_d\); of \( x_d<0\) we have
	\begin{equation}
		(\partial^{\alpha}p_{(m)}u)(x',x_d)=\sum_{k=0}^{m-1}(-\lambda_k)^la_k(\partial^{\alpha}u)(x',-\lambda_kx_d).
	\end{equation}
	There is a finite number of combinations \( \lambda_k^l\) with \( k=0,\ldots, d-1\) and \( l=0,\ldots, m\) (and they are all strictly positive). We majore them all by \( K\). Taking the maximum of the numbers \( | a_k |\) and including it in the \( K\) we have
	\begin{equation}
		\big| (\partial^{\alpha}p_{(m)}u)(x',x_d) \big|\leq K \sum_{k=0}^{m-1}| (\partial^{\alpha}u)(x',-\lambda_k x_d) |.
	\end{equation}
	As far as the \( L^2(\eR^d)\) norm is concerned we have
	\begin{subequations}
		\begin{align}
			\| \partial^{\alpha}p_{(m)}u \|_{L^2(\eR^d_-)} & \leq K\sum_{k=0}^{m-1}\int_{\eR^d_-}\big| (\partial^{\alpha}u)(x',-\lambda_k x_d) \big|^2dx'\otimes dx_d                 \\
			                                               & =K\sum_{k=0}^{m-1}\int_{\eR^d_+}\lambda_k\big| (\partial^{\alpha}u)(x',y) \big|^2dx'\otimes dy  \label{EQooBTCBooHejadM} \\
			                                               & =K\sum_{k=0}^{m-1}\lambda_k\| \partial^{\alpha}u \|_{L^2(\eR^d_+)}                                                       \\
			                                               & \leq K\| \partial^{\alpha}u \|_{L^2(\eR^d_+)}.
		\end{align}
	\end{subequations}
	We made the change of variable \(y=-\lambda_k x_d\) (this is why a \( \lambda_k\) appeared as Jacobian in \eqref{EQooBTCBooHejadM}). In the last line we included the factor \( \sum_{k=0}^{m-1}\lambda_k\) into \( K\).

	From the definition we also have
	\begin{equation}
		\| \partial^{\alpha}p_{(m)}u \|_{L^2(\eR^d_+)}=\| \partial^{\alpha}u \|_{L^2(\eR^d_+)}.
	\end{equation}
	Making the sum (and neglecting the integral over \( x_d=0\)) and redefining \(K \) as \( \max\{ 1,K \}\),
	\begin{subequations}
		\begin{align}
			\| \partial^{\alpha}p_{(m)}u \|_{L^2(\eR^d)} & \leq K \| \partial^{\alpha}u \|_{L^2(\eR^d_+)}+\| \partial^{\alpha}u \|_{L^2(\eR^d_+)} \\
			                                             & =2K\| \partial^{\alpha}u \|_{L^2(\eR^d_+)}.
		\end{align}
	\end{subequations}
	Taking once again the sum over the \( | \alpha |\leq m\) we have the majoration
	\begin{equation}
		\| p_{(m)}u \|_{H^m(\eR^d)}\leq C \| u \|_{H^m(\eR^d_+)}.
	\end{equation}

	We have continuity of the map
	\begin{equation}
		p_{(m)}\colon \Big( r^+\swD(\eR^d),\| . \|_{H^m(\eR^d_+)} \Big)\to \Big( H^m(\eR^d),\| . \|_{H^m(\eR^d)} \Big).
	\end{equation}
	Taking advantage of the fact that the Sobolev space are complete (thus Banach) and the density of \( r^+H^m(\eR^d_+)   \) in \( H^m(\eR^d_+)\) we use the proposition~\ref{PropTTiRgAq} to build a continuous extension
	\begin{equation}
		p_{(m)}\colon \Big(  H^m(\eR^d_+)  ,\| . \|_{H^m(\eR^d_+)} \Big)\to \Big( H^m(\eR^d),\| . \|_{H^m(\eR^d)} \Big).
	\end{equation}
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Boundaries}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

We already made a small step in the world of boundaries and Sobolev space defining \( H_0^1(\Omega)\) as the part of \( H^1(\Omega)\) made from functions that vanishes on \( \partial\Omega\) (definition~\ref{DEFooFICWooBWCDyO}). This is far from being the end of the story. The main point in studying Sobolev spaces and boundaries is that the boundary has zero measure, so that the definitions of the usual functional spaces make no sense.

We need an integration theory on the boundary. Let \( a>0\) (in \( \eR\)) and define
\begin{subequations}
	\begin{align}
		Q_a   & =\{ x\in \eR^{d}\tq | x_j |<a,\,\forall j \}                   \\
		Q'_a  & =\{ x'\in \eR^{d-1}\st | x'_j |<a,\,\forall j=1,\ldots, d-1 \} \\
		Q^+_a & =\{ x\in Q_a\st | x_n |>0\}.
	\end{align}
\end{subequations}

\begin{definition}          \label{DEFooCDJTooYyibCc}
	A \defe{smooth diffeomorphism}{smooth!diffeomorphism} \( \varphi\colon A\to B\) is an invertible \(  C^{\infty}\)-map with \(  C^{\infty}\) inverse.
\end{definition}

\begin{definition}[\cite{ooRRCQooJwnUgB}]
	A open set \( \Omega\subset \eR^d\) is \defe{smooth}{smooth!open in $\eR^d$} if for every \( x_0\in \partial\Omega\) there exists a neighbourhood \( U\) of \( x_0\), a \( a>0\) and a smooth diffeomorphism\footnote{Définition~\ref{DEFooCDJTooYyibCc}.} \( \varphi\colon Q_a\to U\) such that
	\begin{enumerate}
		\item
		      \( \varphi(Q_a^+)=U\cap\Omega\)
		\item
		      \( \varphi(Q'_a)=U\cap\partial\Omega\)
		\item
		      \( \varphi(0)=x_0\).
	\end{enumerate}
\end{definition}
The restriction \( \varphi\colon Q'_a\to U\cap\partial\Omega\) will be denoted by \( \lambda\).

\begin{definition}
	A triple \( (\varphi,U,Q_a)\) is a \defe{local coordinates system}{coordinate!local} for \( \Omega\) around \( x_0\).
\end{definition}

\begin{lemma}
	Let \( (\varphi_1,U_1,Q_a)\) and \( (\varphi_2,U_2,Q_a)\) be local coordinates system around \( x_1\) and \( x_2\) in \( \partial\Omega\). The map
	\begin{equation}
		\varphi_2^{-1}\circ\varphi_1\colon \varphi_1^{-1}(U_1\cap U_2)\to \varphi_2^{-1}(U_1\cap U_2)
	\end{equation}
	is a smooth diffeomorphism such that if \( y\in Q_a\) is an element of \( \varphi_1^{-1}(U_1\cap U_2)\) with \( y_n=0\) we have
	\begin{equation}
		(\varphi_2^{-1}\circ\varphi_1)(y)_n=0.
	\end{equation}
\end{lemma}

\begin{proof}
	The fact that \( \varphi_2^{-1}\circ\varphi_1\) is a smooth diffeomorphism is true by composition, and by the careful choice of the domains.

	If \( y_n=0\), we have \( y\in Q'_a\) and \( \varphi_1(y)\in U_1\cap \partial\Omega\). In the same time, from the hypothesis, \( \varphi_1(y)\in U_1\cap U_2\), so that
	\begin{equation}
		\varphi_1(y)\in U_1\cap U_2\cap\partial\Omega.
	\end{equation}
	In particular, \( \varphi_2^{-1}\big( \varphi_1(y) \big)\in Q'_a\) and \( (\varphi_2^{-1}\circ\varphi_1)(y)_n=0\).
\end{proof}
One can restate the lemma saying that \( \varphi_2^{-1}\circ\varphi_1\) is a smooth diffeomorphism preserving the property \( y_n=0\).

\begin{normaltext}
	We suppose that \( \Omega\) is bounded, so that \( \partial\Omega\) is bounded and closed, thus compact (Borel-Lebesgue, theorem~\ref{ThoXTEooxFmdI}). If one has a local coordinate system \( (\varphi_x,U_x,Q_a)\) around each \( x\in \partial\Omega\), the union \( \bigcup_{x\in\partial \Omega}U_x\) contains \( \partial\Omega\). There exists a finite subcovering.

	We conclude that when \( \Omega\) is bounded, we have a finite family of local coordinates \( (\varphi_j,U_j,Q_a)\) (\( j=1,\ldots,\ldots, N\)). We also write \( U_0=\Omega\) so that \( \bigcup_{j=0}^NU_j\) covers \( \bar\Omega\).
\end{normaltext}

As allowed by the corollary~\ref{CORooMSWPooCxvuhm}, we consider a partition of the unity for \( \bar\Omega\) subordinated to the open sets \( \{ U_j \}_{j=0,\ldots, N}\). For each \( j=0,\ldots, N\) we have \( \psi_j\in\swD(U_j)\) and we have
\begin{equation}
	\sum_{j=0}^{N}\psi_j=1
\end{equation}
on a neighbourhood of \( \bar\Omega\).

If \( u\in Fun(\Omega)\) we have
\begin{equation}
	u=\sum_{j=0}^N\psi_ju
\end{equation}
and if \( v\in\Fun(\partial\Omega)\) we have
\begin{equation}
	b=\sum_{j=1}^N\psi_jv.
\end{equation}

The function \( \psi_ju\colon U_j\to \eC\) can be send to a function on \( Q_a^+\) by a chart because the support of \( \psi_ju\) is contained in the interior of \( U_j\) while \( \varphi_j^{-1}(U_j\cap\Omega)=Q_a^+\).

The diffeomorphism \( \varphi_j\colon Q_a\to U_j\) induces a diffeomorphism
\begin{equation}
	\lambda_j\colon Q_a'\to U_j\cap\partial \Omega
\end{equation}
This is because by definition of a chart, \( \varphi_j\colon U_j\cap\partial\Omega\to Q'_a\) is a bijection.

The following defines \( L^p_{loc}(\partial\Omega)\) with respect to a chart system. So this should be written \( L^p_{loc}(\partial\Omega,\{ \varphi_j \})\).
\begin{definition}      \label{DEFooFBVPooEeNwuU}
	Let \( p\geq 1\). The space \( L^p_{loc}(\partial \Omega)\) is the set of functions \( u\in\Fun(\partial\Omega)\) such that the map
	\begin{equation}
		u\circ\lambda_j\colon Q'_a\to \eC
	\end{equation}
	belongs to \( L^p_{loc}(Q'_a)\) for every \( j\).
\end{definition}

We prove that the set \( L^p_{loc}(\partial\Omega,\{ \varphi_j \})\) does not depend on \( \{ \varphi_j \}\).
\begin{lemma}
	The set defined in~\ref{DEFooFBVPooEeNwuU} does not depend on the choice of chart system.
\end{lemma}

\begin{proof}
	We consider two coordinates charts \( (U_j,\varphi_j,Q_a)_{j\in J}\) and \( (V_{\alpha},\psi_{\alpha},Q_aa_{\alpha\in A})\) and we have to show that when \( u\) is a \( L^p_{loc} \) function with respect to one chart system, it is \( L^p_{loc}\) for the other one. We consider the restrictions
	\begin{subequations}
		\begin{align}
			\lambda_j\colon Q'_a\to U_j\cap \partial\Omega \\
			\sigma_{\alpha}\colon Q'_a\to V_{\alpha}\cap\partial\Omega.
		\end{align}
	\end{subequations}
	So we suppose that \( u\circ\lambda_j\in L^p_{loc(Q_a')} \) for every \( j\) and we have to show that \( u\circ\sigma_{\alpha}\in L^p_{loc}(Q_a')\) for every \( \alpha\in A\) (from now on we fix some \( \alpha\in A\)). Let \( K\) be compact un \( Q_a'\) and we have to show that \( u\circ\sigma_{\alpha}\in L^p(K)\).

	Let \( L_j=U_j\cap\sigma_{\alpha}(K)\); this is a compact part of \( \eR^d\) and we have \( \sigma_{\alpha}(K)=\bigcup_{j\in J}L_j\). The latter union is however not disjoint. We have
	\begin{subequations}
		\begin{align}
			\int_K| u\circ\sigma_{\alpha} |^p & =\int_{\sigma_{\alpha}}| J_{\sigma_{\alpha}} |^p| u |^p                                                         \\
			                                  & \leq \sum_{i\in I}\int_{L_j}\underbrace{| J_{\sigma_{\alpha}} |^p}_{\leq C}| u |^p                              \\
			                                  & \leq C\sum_{i\in I}\int_{\lambda_i^{-1}(L_i)}\underbrace{| J_{\lambda_i^{-1}} |}_{\leq C'} |u\circ\lambda_i |^p
		\end{align}
	\end{subequations}
	The integrals are finites because the integration domain are compacts while the integrand is \( L^p_{loc}(Q'_a)\).
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Older work}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\label{SECooNJLDooFcUzQv}

A lot of theory about Sobolev spaces can be found in \cite{Maslov,Taylor_PDO}. The \defe{Fourier transform}{Fourier transform} of a function $\varphi$ on $\eR^n$ is defined by formulas
\begin{subequations}
	\begin{align}
		(F\varphi)(p)=\hat\varphi(p) & =\int_{\eR^N} e^{-2i\pi p\cdot x}\varphi(x)\,dx     \\
		\varphi(x)                   & =\int_{\eR^{N}} e^{2i\pi}x\cdot p\hat\varphi(p)\,dp
	\end{align}
\end{subequations}
Main properties of Fourier transform are
\begin{subequations} \label{subeq_prop_Four}
	\begin{align}
		(\partial_jF\varphi)(p) & =-2i\pi F(x_j\varphi)   \\
		(F\partial_j\varphi)    & =2i\pi p_j(F\varphi)(p)
	\end{align}
\end{subequations}

The associated formula for the delta Dirac ``function'' is
\begin{equation}
	\int e^{2i\pi k\cdot x}\,dx=\delta(x).
\end{equation}

\begin{proposition}
	If $\hat\swS$ denote the set of functions $\hat\varphi$ with $\varphi\in\swS$, then $\hat\swS=\swS$.
\end{proposition}

\begin{proof}
	No proof
\end{proof}

We consider the \defe{Laplace operator}{Laplace operator}\nomenclature{$\Delta f$}{Laplace operator}, or Laplacian,
\begin{equation}
	\Delta=\sum_{j=1}^{N}\partial_j^2
\end{equation}
When $k\in\eN$, we consider the following norm on $\swS(\eR^N)$:
\begin{equation} \label{eq_def_norm_Sob}
	\| \varphi \|_{H^k}^2=\int_{\eR^N}\overline{\varphi}(x)[1-(2\pi)^{-2}\Delta]^k\varphi(x)\,dx
\end{equation}
The \defe{Sobolev space}{Sobolev space} $H^k_2(\eR^N)$\nomenclature{$H^k_2(\eR^N)$}{Sobolev space} is the completed of $\swS$ for this norm.

\begin{proposition}
	These Sobolev spaces are Hilbert spaces
\end{proposition}

\begin{proof}
	No proof
\end{proof}

In order to define Sobolev spaces $H^k$ with $k<0$, we have to find a definition for $[-\Delta+1]^{-l}$. We define
\[
	\swS^{(l)}=\{ [1-(2\pi)^{-2}\Delta]^l\varphi\tq \varphi\in\swS \}
\]

\begin{lemma}
	For each $\psi\in\swS^{(l)}$, there exists one and only one $\varphi\in\swS$ such that $(-\Delta+1)^l\varphi=\psi$.
\end{lemma}

This unique function $\varphi$ is naturally denoted by $(-\Delta+1)^{-l}$

\begin{proof}
	We give the proof with $l=1$, the other are induction. When $\psi\in\swS^{(l)}$, existence is by definition true and only unicity is non trivial. Let $\varphi_1$ and $\varphi_2$ in $\swS$ such that
	\[
		[1-(2\pi)^{-2}\Delta]\varphi_1=[1-(2\pi)^{-2}\Delta]\varphi_2,
	\]
	the function $f=\varphi_1-\varphi_2$ fulfils $(-\Delta+1)f=0$ and thus
	\[
		\int_{\eR^N}\overline{ f }(x)[1-(2\pi)^{-2}\Delta]f(x)\,dx=0.
	\]
	Since $f\to 0$ at infinity rapidly, an integration by part of the term containing $\Delta$ leads, up to some constants, to
	\[
		\int \overline{ f }f-\int \overline{ f }\Delta f=\int | f |^2+\int | \nabla f |^2=0.
	\]
	This proves that $f=0$.
\end{proof}

Now, the norm \eqref{eq_def_norm_Sob} can be used to define the Sobolev space $H^{-l}$. Elements of $H^k$ ($k<0$) which are not functions are distributions. When $m\ge0$, formulas  \eqref{subeq_prop_Four} give
\begin{equation}  \label{eq_umdpi_spi}
	\left( F[1-(2\pi)^{-2}\Delta]^m\psi \right)(p)=\left( (1+p^2)^m\hat\psi \right)(p).
\end{equation}

\begin{proposition}
	When $\psi\in\swS^{(m)}$, equality  \eqref{eq_umdpi_spi} holds even for $m<0$.
\end{proposition}


Let us point out that $m$ keep integer; the general real case will be treated later.

\begin{proof}
	Let $m=-k<0$; from definition of the space $\swS^{(m)}$, the function $\varphi=[1-(2\pi)^{-2}\Delta]^{-k}\psi$ exists; we have
	\begin{equation}
		\hat\psi=\left( F[1-(2\pi)^{-2}\Delta]^k\varphi \right)(p)
		=(p^2+1)^k\hat\varphi(p),
	\end{equation}
	therefore $\hat\varphi(p)=(p^2+1)^{-k}\hat\psi(p)$. Replacing $\varphi$ by its definition,
	\begin{equation}
		\left( F[1-(2\pi)^{-2}\Delta]^{-k}\psi \right)(p)=(p^2+1)^{-k}\hat\psi(p).
	\end{equation}


\end{proof}

\begin{proposition}
	Let $\varphi\in\swS$. There exists a $\psi\in\swS$ such that
	\[
		\varphi=[1-(2\pi)^{-2}\Delta]^l\psi
	\]

\end{proposition}

\begin{proof}
	Let us prove it with $l=1$; other cases are obtained by iteration. We consider the function $\psi$ defined by the condition
	\[
		\hat\psi(p)=(p^2+1)^{-1}(F\varphi)(p).
	\]
	For this function we have $[1-(2\pi)^{-2}\Delta]\psi=\varphi$
\end{proof}

The space $\hat H^s(\eR^N)$ is the completed of $\swS$ for the norm
\begin{equation}
	\| \varphi \|^2_{\hat H^s}=\int_{\eR^N}(p^2+1)^2| \varphi(p) |^2\,dx
\end{equation}
where $s$ is any positive real.


\begin{theorem}
	For each $\varphi\in\swS$ and $k\in\eN$, we have
	\[
		\| F\varphi \|_{\hat H^k}=\| \varphi \|_{H^k},
	\]
	in other words, the Fourier transform in $\swS$ is an isometry $\dpt{F}{ H^k }{ \hat H^k }$.

\end{theorem}


\begin{proof}
	Using Parseval and equality \eqref{eq_umdpi_spi},
	\begin{equation}
		\| \varphi \|_{H^k}^2=\int_{\eR^N}\overline{ \varphi }(x)[1-(2\pi)^{-2}\Delta]^k\varphi(x)\,dx
		=\int \overline{ F\varphi(p) }(p^2+1)^k(F\varphi)(p)\,dp\\
		=\| \varphi \|_{\hat H^k}^2.
	\end{equation}
\end{proof}
The space $\swS$ is dense in $H^k$ and $F$ is a bounded operator on $\swS$ (because it is isometric). Therefore it can be extended to an unique isometric homomorphism $\dpt{ F }{ H^k }{ \hat H^k }$ which is evidently called \defe{Fourier transform}{Fourier transform}.


In the same way, $F^{-1}$ is extended to an inverse of $F$ and finally,
\[
	\dpt{ F }{ H^k(\eR^N) }{ \hat H^k(\eR^N) }
\]
is  an isometric isomorphism. For each $s\in\eR$, we define
\begin{equation}
	\| \varphi \|_{H^s}:=\| F\varphi \|_{\hat H^s},
\end{equation}
and the completed of $\swS$ for this norm is the \emph{Sobolev space} $H^s(\eR^N)$.
