% This is part of Giulietta
% Copyright (c) 2013-2015, 2019-2022, 2024-2025
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.

Here are the results which relate Lie groups and Lie algebras.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Invariant vector fields}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{definition}[\cite{MonCerveau}]	\label{DEFooDNARooBCKCkf}
	Let \( G\) be a Lie group. A vector field \(X \colon G\to TG  \) is \defe{left invariant}{left invariant vector field} if for every \( g,h\in G\) we have
	\begin{equation}
		(dL_g)_hX_h=X_{gh}.
	\end{equation}
\end{definition}

\begin{proposition}[\cite{MonCerveau}]	\label{PROPooNAKSooYajsZZ}
	Let \( G\) be a Lie group. Let \( g\in G\). The map
	\begin{equation}
		dL_g \colon TG\to TG
	\end{equation}
	is smooth.

	More precisely, if \( X\in T_hG\), then \( dL_gX\) stands for \( (dL_g)_hX\).
	%TODOooEKIHooBWoagZ. Prouver ça.
\end{proposition}


\begin{proposition}[\cite{BIBooZOGHooGGcZAU,MonCerveau}]	\label{PROPooYSIYooYptWWo}
	Every left invariant vector field\footnote{Definition \ref{DEFooDNARooBCKCkf}.} on a smooth Lie group is smooth.
\end{proposition}

\begin{proof}
	In two parts.
	\begin{subproof}
		\spitem[In a neighbourhood of \( e\)]
		%-----------------------------------------------------------
		We consider a local chart \(\varphi_{\alpha} \colon U_{\alpha}\to G  \) around \( e\). Using proposition \ref{LEMooQYETooZsTFMg} we consider a neighbourhood \( V\) of \( e\) in \( G\) such that \( V=V^{-1}\) and \( VV\subset\varphi_{\alpha}(U_{\alpha})\).

		We consider the map
		\begin{equation}
			\begin{aligned}
				r_i\colon \varphi_{\alpha}(U_{\alpha}) & \to  \eR                                           \\
				g                                      & \mapsto \pr_i\big( \varphi_{\alpha}^{-1}(g) \big).
			\end{aligned}
		\end{equation}
		We pose \( V=\varphi(U_{\alpha}) \) and
		\begin{equation}
			\begin{aligned}
				f\colon V\times V & \to \eR           \\
				(a,b)             & \mapsto r_i(a,b).
			\end{aligned}
		\end{equation}
		Notice that \( f=r_i\circ m=\pr_i\circ\varphi_{\alpha}^{-1}\circ m\) which is smooth because each of \( \pr_i\), \( \varphi_{\alpha}^{-1}\) and \( m\) are continuous. We will show that
		\begin{equation}
			a\mapsto X_a(r_i)
		\end{equation}
		is smooth, so that proposition \ref{PROPooYGHAooWOXbRu} will conclude that \( X\) is smooth. Let \( a,b\in V\). We have
		\begin{equation}
			X_a(r_i)=\big( (dL_a)_eX_e \big)(r_i)=X_e\big( r_i\circ L_a \big).
		\end{equation}
		There exists \( v_k\in \eR\) such that \( X_e=\sum_kv_k\partial_k\). We continue the computation; let \( y=\varphi_{\alpha}^{-1}(e)\). We have
		\begin{subequations}
			\begin{align}
				X_e(r_i\circ L_a) & =\sum_kv_k\frac{d}{dt} \left[ (r_i\circ L_a)\big( \varphi_{\alpha}(y+te_k) \big)  \right]_{t=0} \\
				                  & =\sum_kv_k\frac{d}{dt} \left[ r_i\big( a\varphi_{\alpha}(y+te_k) \big)  \right]_{t=0}           \\
				                  & =\sum_kv_k\frac{d}{dt} \left[ f(a,\varphi_{\alpha}(y+te_k))  \right]_{t=0}.
			\end{align}
		\end{subequations}
		At this point we remember that the product manifold chart \(\sigma_{\alpha\alpha} \colon U_{\alpha}\times U_{\alpha}\to G\times G  \) makes \( f\circ\sigma_{\alpha\alpha}\) smooth because \( f\) is smooth. Let \( x=\varphi^{-1}(a)\). We continue :
		\begin{subequations}
			\begin{align}
				X_e(r_i\circ L_a) & =\sum_kv_k\frac{d}{dt} \left[ f(a,\varphi_{\alpha}(y+te_k))  \right]_{t=0}                              \\
				                  & = \sum_kv_k\frac{d}{dt} \left[ f\big( \varphi_{\alpha}(x),\varphi_{\alpha}(y+te_k) \big)  \right]_{t=0} \\
				                  & =\sum_kv_k\frac{d}{dt} \left[ (f\circ\sigma_{\alpha\alpha})(x,y+te_k)  \right]_{t=0}                    \\
				                  & =\sum_kv_k\partial_k(f\circ\sigma_{\alpha\alpha})(x,y).
			\end{align}
		\end{subequations}
		Up to now we have proved that
		\begin{equation}
			X_a(r_i)=\sum_kv_k\partial_k(f\circ\sigma_{\alpha\alpha})\big( \varphi^{-1}(a),y \big).
		\end{equation}
		Now we consider the smooth map
		\begin{equation}
			\begin{aligned}
				\phi\colon G & \to U_{\alpha}\times U_{\alpha}                 \\
				g            & \mapsto \big( \varphi_{\alpha}^{-1}(g),y \big).
			\end{aligned}
		\end{equation}
		The map \( \partial_k(f\circ\sigma_{\alpha\alpha})\circ \phi\) is smooth and then
		\begin{equation}
			X_a(r_i)=\sum_kv_k\partial_k(f\circ\sigma_{\alpha\alpha})\circ\phi(a)
		\end{equation}
		is a smooth function of \( a\).

		We finished to prove that \( X\) is smooth on a neighbourhood of \( e\) in \( G\).

		\spitem[Elsewhere]
		%-----------------------------------------------------------
		Let now \( g\in G\). We have to prove that \( X\) is smooth on a neighbourhood of \( g\). Let \( U\) be a neighbourhood of \( e\) on which \( X\) is smooth. To avoid confusion we denote by \( Y\) the restriction of \( X\) to \( U\). The map
		\begin{equation}
			\begin{aligned}
				X\colon L_gU & \to TG         \\
				gh           & \mapsto X_{gh}
			\end{aligned}
		\end{equation}
		can be written under the form
		\begin{equation}
			X=dL_g\circ Y\circ L_{g^{-1}}.
		\end{equation}
		This is smooth because \( dL_g\) is smooth (proposition \ref{PROPooNAKSooYajsZZ}), \( Y\) is smooth and \( L_{g^{-1}}\) is smooth.
	\end{subproof}
\end{proof}


\begin{lemmaDef}        \label{DEFooSSDYooOwjHso}
	Let \( G\) be a smooth Lie group and \( X\in T_eG\). The vector field \( X^L\) defined by
	\begin{equation}
		X^L_g=dL_gX
	\end{equation}
	is smooth. This is the \defe{left invariant}{left invariant vector field} vector field associated with the vector \( X\in T_eG\).
\end{lemmaDef}

\begin{proof}
	Every invariant vector field is smooth by proposition \ref{PROPooYSIYooYptWWo}.
\end{proof}

\begin{definition}
	Let \( G\) be a group. The \defe{left translation}{left translation} by \( g\) on \( G\) is the map
	\begin{equation}
		\begin{aligned}
			L_g\colon G & \to G       \\
			h           & \mapsto gh.
		\end{aligned}
	\end{equation}
	The \defe{right translation}{right translation} by \( g\) on \( G\) is the map
	\begin{equation}
		\begin{aligned}
			R_g\colon G & \to G       \\
			h           & \mapsto hg.
		\end{aligned}
	\end{equation}
\end{definition}

\begin{definition}[\cite{BIBooUGWHooPbodCu}]        \label{DEFooYHKXooVoJalX}
	If $G$ is a Lie group, a vector field $X\in\Gamma^{\infty}(TG)$ is \defe{left invariant}{left invariant!vector field} if
	\begin{equation}
		(dL_g) X= X,
	\end{equation}
	which means that for every \( g,h\in G\),
	\begin{equation}
		(dL_h)_gX_g=X_{hg}.
	\end{equation}
	In the same way, the vector field \( Y\) is \defe{right invariant}{right!invariant!vector field} if
	\begin{equation}
		(dR_g)Y=Y.
	\end{equation}
	\index{invariant vector field}
\end{definition}

\begin{propositionDef}      \label{PROPooLEIAooTnnYRw}
	Let \( G\) be a Lie group and \( X\in T_eG\).
	\begin{enumerate}
		\item
		      The vector field \( X^L\) defined by
		      \begin{equation}        \label{DEFooYPUIooAzcdjP}
			      X^L_g=(dL_g)_eX.
		      \end{equation}
		      is left-invariant.
		\item
		      The vector field \( X^L\) defined by
		      \begin{equation}
			      X^R_g=(dR_g)_eX.
		      \end{equation}
		      is right-invariant.
	\end{enumerate}
	They are called the left and right-invariant vector fields \defe{associated with}{left-invariant vector field}\index{right-invariant vector field!} \( X\).
\end{propositionDef}

\begin{propositionDef}      \label{DEFooKDCPooZOJsMD}
	Let \( G\) be a smooth Lie group. If \( X,Y\in T_eG\) we define the bracket\footnote{On the right, this is the bracket of vector fields defined in \ref{DEFooHOTOooRaPwyo}.}
	\begin{equation}
		[X,Y] = [X^L,Y^L]_e.
	\end{equation}
	The set \( T_eG\) with this bracket is a Lie algebra. This is the \defe{Lie algebra of the Lie group}{Lie algebra of a Lie group} \( G\). It will usually be denoted by \( \lG\).

	The topology on \( \lG=T_eG\) is the usual one of the tangent spaces, definition \ref{PROPooHJOXooMGANfd}.
\end{propositionDef}

\begin{proof}
	We know from proposition \ref{PROPooEJBWooSbvypo} that \( T_eG\) is a vector space. We have to define a Lie bracket on it. For that we use the left-invariant vector field. Let \( X\in T_eG\) and \( g\in M\) we define
	\begin{equation}
		X^L_g=dL_gX
	\end{equation}
	where \( L_g\colon G\to G\) is the left translation: \( L_g(h)=gh\). If \( X,Y\in T_eG\) we define
	\begin{equation}
		[X,Y]=[X^L,Y^L]_e
	\end{equation}
	where the bracket on the right hand side is the commutator of vector field defined in \ref{DEFooHOTOooRaPwyo}. It defines a Lie algebra structure by the proposition \ref{PROPooSWQSooSEfTuX}.
\end{proof}

In order to make the notations clear, let us write the formula explicitly. If \( X,Y\in T_eG\) are given by \( X=\alpha'(0)\) and \( Y=\beta'(0)\) we have
\begin{subequations}        \label{SUBEQSooHKWMooQbeStl}
	\begin{align}
		(XY)f & =X(Y(f))                                               \\
		      & =\Dsdd{ (Yf)\big( \alpha(t) \big) }{t}{0}              \\
		      & =\Dsdd{ Y_{\alpha(t)}(f) }{t}{0}                       \\
		      & =\Dsdd{ Y^L_{\alpha(t)}(f) }{t}{0}                     \\
		      & =\DDsdd{ f\big( \alpha(t)\beta(u) \big) }{t}{0}{s}{0}.
	\end{align}
\end{subequations}


\begin{lemma}[\cite{BIBooFLEXooPgvAlz}]       \label{LEMooWTNRooCjlYMJ}
	Let \( G\) be a Lie group and \( X_1,\ldots, X_k\) be linearly independent vectors in its Lie algebra \( \lG\). For every \( g\in G\), the vectors\footnote{Left invariant vector field, definition \ref{DEFooYHKXooVoJalX}.} \( X_i^L(g)\) are linearly independent in \( T_gG\).
\end{lemma}

\begin{proof}
	Let \( \lambda_i\) be reals such that \( \sum_{i=1}^k\lambda_iX_i^L(g)=0\); in other terms,
	\begin{equation}
		0=(dL_g)_e\big( \sum_i\lambda_iX_i \big).
	\end{equation}
	We apply \( (dL_{g^{-1}})_e\) on both side: \( 0=\sum_i\lambda_iX_i\). By hypothesis, \( \lambda_i=0\) for every \( i\). This proves that the vectors \( X^L_i(g)\) are linearly independent.
\end{proof}

\begin{theorem}[\cite{BIBooUGWHooPbodCu}]
	The map \( \varphi\colon X\mapsto X^L\) where \( X^L_g=(dL_g)_eX\) is a bijection from \( T_eG\) to the set of left-invariant vector fields.
\end{theorem}

\begin{proof}
	Two parts.
	\begin{subproof}
		\spitem[Surjective]
		Let \( X\) be a left-invariant vector field. We have \( X=(X_e)^L\) because
		\begin{equation}
			(X_e)^L_g=(dL_g)X_e=X_g.
		\end{equation}
		The first equality is the definition of the left-invariant associated vector field (equation \eqref{DEFooYPUIooAzcdjP} applied to \( X_e\)) and the second equality is the fact that \( X\) is left-invariant. Thus \( X\) is the left-invariant vector field associated with \( X_e\).
		\spitem[Injective]
		Let \( X,Y\in T_eG\) be such that \( X^L=Y^L\). In particular \( X^L_e=Y^L_e\), which means \( X=Y\).
	\end{subproof}
\end{proof}

\begin{proposition}[\cite{BIBooUGWHooPbodCu, MonCerveau}]
	Let \( G\) be a Lie group. The map
	\begin{equation}
		\begin{aligned}
			\varphi\colon G\times \lG & \to TG        \\
			(g,X)                     & \mapsto X^L_g
		\end{aligned}
	\end{equation}
	is a bijection.

	Moreover for each \( g\in G\), the map
	\begin{equation}
		\begin{aligned}
			\varphi_g\colon \lG & \to T_gG      \\
			X                   & \mapsto X^L_g
		\end{aligned}
	\end{equation}
	is a vector space isomorphism.
\end{proposition}

\begin{proof}
	Several points.
	\begin{subproof}
		\spitem[\( \varphi\) is surjective]
		Let \( X\in TG\); there is some \( g\in G\) such that \( X\in T_gG\). Since \( X=(dL_g)_e(dL_{g^{-1}})_gX\) we have
		\begin{equation}
			X=(dL_{g^{-1}}X)^L_g=\varphi(g,dL_{g^{-1}}X).
		\end{equation}
		\spitem[\( \varphi\) is injective]
		If \( \varphi(g,X)=\varphi(h,Y)\), we have \( X_g^L=Y^L_h\), so that \( g=h\). The equality  \( X_g^L=Y_g^L\) means \( (dL_g)_eX=(dL_g)_eY\). Applying \( (dL_{g^{-1}})_g\) on both sides we get \( X=Y\).
		\spitem[\( \varphi_g\) is bijective]
		These are the same verifications.
		\spitem[\( \varphi_g\) is linear]
		The map \( \varphi_g\) is nothing else than \( (dL_g)_e\), so it is linear.
	\end{subproof}
\end{proof}


\begin{proposition}[\cite{MonCerveau}]      \label{PROPooWWXKooWEBpMf}
	Let \( G\) be a Lie group and \( \lG\) its Lie algebra. The map
	\begin{equation}
		\begin{aligned}
			L\colon \lG & \to \Gamma(TG) \\
			X           & \mapsto X^L
		\end{aligned}
	\end{equation}
	is linear.
\end{proposition}


\begin{proposition}[\cite{MonCerveau}]	\label{PROPooPYVRooFtRGaj}
	Let \( G\) be a smooth Lie group. Let \( X,Y\in \lG\). We have
	\begin{equation}
		[X^L,Y^L]=[X,Y]^L.
	\end{equation}
	%TODOooZDRBooYSzEjQ. Prouver ça.
	% et vérifie au passage que PROPooWWXKooWEBpMf est prouvée.
	% Et aussi PROPooLEIAooTnnYRw
\end{proposition}


%+++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Product and Leibniz rules}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++


\begin{proposition}[\cite{MonCerveau}]	\label{PROPooPPJJooBQgHMd}
	Let \( G\) be a smooth Lie group. We denote by \(m \colon G\times G\to G  \) the multiplication. Let \( (a,b)\in G\times G\) and \( X\in T_{(a,b)}(G\times G)\). We consider the vector space isomorphism\footnote{From proposition \ref{PROPooPSELooDDwFru}.} \(\mu \colon T_{(a,b)}(G\times G)\to T_aG\times T_bG  \)
	We have
	\begin{equation}
		dm_{(a,b)}X=(dR_b)_a(X_a)+(dL_a)_b(Y_b)
	\end{equation}
	where \( X_a\) and \( X_b\) are defined by \( \mu(X)=(X_a,X_b)\).
\end{proposition}

\begin{proof}
	Let \(f \colon G\times G\to \eR  \) be a smooth function. We consider a path \(\gamma \colon \eR\to G\times G  \) such that \( X=\gamma'(0)\) and we use the proposition \ref{PROPooFNVKooVxPulA} :
	\begin{equation}
		dm_{(a,b)X}(f)=\nabla_{\gamma_1}(f\circ m)_1+\nabla_{\gamma_2}(f\circ m)_2.
	\end{equation}
	By definition \ref{NORMooPEHNooAiyUqc}, \( (f\circ m)_A(g)=f(gb)=(f\circ R_b)(g)\), and similarly for \( (f\circ m)_2\). We have
	\begin{subequations}
		\begin{align}
			(f\circ m)_1 & =f\circ R_b  \\
			(f\circ m)_2 & =f\circ L_a.
		\end{align}
	\end{subequations}
	According to the relation \eqref{EQooYNFOooMqKQuQ}, \( \nabla_{\gamma_1}=X_a\) and \( \nabla_{\gamma_2}=X_b\), so that
	\begin{equation}
		dm_{(a,b)X}(f)=X_a(f\circ m)_1+X_b(f\circ m)_2.
	\end{equation}
	We get the result using proposition \ref{PROPooMYSMooQnRQyx} which, in our case, provides \( X_a(f\circ R_b)=(dR_b)_a(X_a)f\).
\end{proof}


\begin{proposition}[\cite{BIBooFLEXooPgvAlz}]	\label{PROPooVMKQooRRztYF}
	Let \( G\) be a smooth Lie group. Let \(\gamma_i \colon \eR\to G  \) be smooth maps. If
	\begin{equation}
		\gamma(t)=\gamma_1(t)\gamma_2(t),
	\end{equation}
	then we have
	\begin{equation}
		\gamma'(t)=dL_{\gamma_1(t)}\big(\gamma_2'(t)\big)+dR_{\gamma_2(t)}\big(\gamma'_1(t)\big).
	\end{equation}
	%TODOooNDIUooBcmpiR. Prouver ça.
	% et aussi PROPooXCJXooYdoAqz
\end{proposition}

\begin{proposition}[\cite{BIBooFLEXooPgvAlz}]	\label{PROPooXCJXooYdoAqz}
	Let \( G\) be a smooth Lie group. We denote by \(m \colon G\times G\to G  \) the group product. If \( X_a\in T_aG\) and \( X_b\in T_bG\), then
	\begin{equation}
		dm_{(a,b)}(X_a,X_b)=(dR_b)_a(X_a)+(dL_a)_b(Y_b).
	\end{equation}
	%TODOooULRXooRMXMMV. Prouver ça.
\end{proposition}

In order to prove that, we have to use \ref{PROPooJIFTooGboJoI}.

\begin{proposition}[\cite{MonCerveau}]	\label{PROPooWKWLooOOrOZs}
	Let \( G\) be a smooth Lie group with multiplication \( m\). Let \(\gamma_i \colon \eR\to G  \) be smooth maps. We have
	\begin{equation}
		\frac{d}{dt} \left[ m\big( \gamma_1(t),\gamma_2(t) \big)  \right]_{t=0}=(dR_{\gamma_2(0)})_{\gamma_1(0)}\gamma_1'(0)+(dL_{\gamma_1(0)})_{\gamma_2(0)}\gamma_2'(0)
	\end{equation}
	in \( T_{\gamma_1(0)\gamma_2(0)}G\).
	%TODOooIGZOooJPSlhr. Prouver ça.
\end{proposition}


%+++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Local isomorphisms}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++


\begin{theorem} \label{tho:loc_isom}
	Two Lie groups are locally isomorphic if and only if their Lie algebras are isomorphic.
	%TODOooGAVAooRRgFXG
\end{theorem}

\begin{theorem}		\label{ThoSubGpSubAlg}		\label{tho:gp_alg}
	If $G$ is a Lie group, then
	\begin{enumerate}
		\item\label{ThoSubGpSubAlgi} if $\lH$ is the Lie algebra of a Lie subgroup $H$ of $G$, then it is a subalgebra of $\lG$,
		\item Any subalgebra of $\lG$ is the Lie algebra of one and only one connected Lie subgroup of $G$.
	\end{enumerate}

	\begin{probleme}
		À mon avis, il faut dire ``connexe et simplement connexe'', et non juste ``connexe''.
	\end{probleme}

\end{theorem}
\begin{proof}

	\subdem{First item}
	Let $\dpt{i}{H}{G}$ be the identity map; it is a homomorphism from $H$ to $G$, thus $di_e$ is a homomorphism from $\lH$ to $\lG$. Conclusion: $\lH$ is a subalgebra of $\lG$.

	\subdem{Characterization for $\lH$}
	Before to go on with the second point, we derive an important characterization of $\lH$:
	\begin{equation}\label{eq:path_alg}
		\lH=\{X\in\lG:\text{the map } t\to\exp tX\text{ is a path in $H$}\}.
	\end{equation}
	For that, consider $\dpt{\exp_H}{\lH}{H}$ and $\dpt{\exp_G}{\lG}{G}$; from unicity of the exponential, for any $X\in\lH$, $\exp_HX=\exp_GX$, so that one can simply write ``$\exp$''\ instead of ``$\exp_h$''\ or ``$\exp_G$''.

	Now, if $X\in\lH$, the map $t\to\exp tX$ is a curve in $H$. But it is not immediately clear that such a curve in $H$ is automatically build from a vector in $\lH$ rather than in $\lG$.  More precisely, consider a $X\in\lG$ such that $t\to\exp tX$ is a path (continuous curve) in H. By lemma~\ref{lem:var_cont_diff}, the map $t\to\exp tX$ is differentiable and thus by derivation, $X\in\lH$.
	The characterisation \eqref{eq:path_alg} is proved.

	Thus $\lH$ is a Lie subalgebra of $\lG$.

	\subdem{Second item}
	For the second part, we consider $\lH$ any subalgebra of $\lG$ and $H$, the smallest subgroup of $G$ which contains $\exp\lH$. We also consider a basis $\{X_1,\ldots,X_n\}$ of $\lG$ such that $\{X_{r+1},\ldots,X_n\}$ is a basis of $\lH$.

	By corollary~\ref{cor:/24}, the set of linear combinations of elements of the form $X(M)$ with $M=(0,\ldots,0,m_{r+1},\ldots,m_r)$ form a subalgebra of $U(\lG)$. If $X=x_1X_1+\cdots+x_nX_n$, we define $|X|=(x_1^2+\cdots+x_n^2)^{1/2}$ ($x_i\in\eR$).

	Let us consider a $\delta>0$ such that $\exp$ is a diffeomorphism (normal neighbourhood) from $B_{\delta}=\{X\in\lG:|X|<\delta\}$ to a neighbourhood $N_e$ of $e\in G$ and such that $\forall x,y,xy\in N_e$,
	\begin{equation}\label{eq:coord_xy}
		(xy)_k=\sum_{M,N}C^{[k]}_{MN}x^My^N
	\end{equation}
	holds\footnote{The validity of this second condition is assured during the proof of theorem~\ref{tho:loc_isom} which is not given here.}. We note $V=\exp(\lH\cap B_{\delta})\subset N_e$. The map
	\[
		\exp(x_{r+1}X_{r+1}+\cdots+x_nX_n)\to(x_{r+1},\ldots,x_n)
	\]
	is a coordinate system on $V$ for which $V$ is a connected manifold. But $\lH\cap B_{\delta}$ is a submanifold of $B_{\delta}$, then $V$ is a submanifold of $N_e$ and consequently of~$G$.

	Let $x$, $y\in V$ such that $xy\in N_e$ (this exist: $x=y=e$); the canonical coordinates of $xy$ are given by \eqref{eq:coord_xy}. Since $x_k=y_k=0$ for $1\leq k\leq r$, $(xy)_k=0$ for the same $k$ because for $(xy)_k$ to be non zero, one need $m_1=\ldots=m_r=n_1=\ldots=n_r=0$ -- otherwise, $x^M$ or $y^N$ is zero. Now we looks at $C^{[k]}_{MN}$ for such a $k$ (say $k=1$ to fix ideas): $[k]=(\delta_{11},\ldots,\delta_{1k})=(1,0,\ldots,0)$ and by definition of the $C$'s,
	\[
		X(M)X(N)=\sum_PC_{MN}^PX(P).
	\]
	But we had seen that the set of the $X(A)$ with $A=(0,\ldots,0,a_{r+1},\ldots,a_n)$ form a subalgebra of $U(\lG)$. Then, only terms with $P=(0,\ldots,0,p_{r+1},\ldots,p_n)$ are present in the sum; in particular, $C_{MN}^{[k]}=0$ for $k=1,\ldots,r$. Thus $VV\cap N_e\subset V$.

	The next step is to consider $\mV$, the set of all the subset of $H$ whose contains a neighbourhood of $e$ in $V$. We can check that this fulfils the six axioms of a topological group\index{topological!group}:

	\begin{enumerate}
		\item The intersection of two elements of $\mV$ is in $\mV$;
		\item the intersection of all the elements of $\mV$ is $\{e\}$;
		\item any subset of $H$ which contains a set of $\mV$ is in $\mV$;
		\item If $\mU\in\mV$, there exists a $\mU_1\in\mV$ such that $\mU_1\mU_1\subset\mU$ because $VV\cap N_e\subset V$;
		\item if $\mU\in\mV$, then $\mU^{-1}\in\mV$ because the inverse map is differentiable and transforms a neighbourhood of $e$ into a neighbourhood of $e$;
		\item if $\mU\in\mV$ and $h\in H$, then $h\mU h^{-1}\in\mV$.
	\end{enumerate}

	To see this last item, we denote by $\log$ the inverse map of $\dpt{\exp}{B_{\delta}}{N_e}$. By definition of $V$, it sends $V$ on $\lH\cap B_{\delta}$. If $X\in\lG$, there exists one and only one $X'\in\lG$ such that $he^{tX}h^{-1}=e^{tX'}$ for any $t\in\eR$. Indeed we know that $he^{X}h^{-1}=e^{\Ad_hX}$, then $X'$ must satisfy $e^{tX'}=e^{\Ad_htX}$. If it is true for any $t$, then, by derivation, $X'=\Ad_hX$.

	The map $X\to X'$ is an automorphism of $\lG$ which sent $\lH$ on itself. So one can find a $\delta_1$ with $0<\delta_1<\delta$ such that
	\[
		h\exp({B_{\delta_1}\cap\lH})h^{-1}\subset V.
	\]
	Indeed, $he^{\lH} h^{-1}\subset\lH$, so that taking $\delta_1<\delta$, we get the strict inclusion. We can choose $\delta_1$ even smaller to satisfy $he^{B_{\delta_1}}h^{-1}\subset N_e$. Since the map $X\to\log(he^{X}h^{-1})$ from $B_{\delta_1\cap\lH}$ to $B_{\delta}\cap\lH$ is regular, the image of $B_{\delta_1}\cap\lH$ is a neighbourhood of $0$ in $\lH$. Thus $he^{B_{\delta_1}\cap\lH}h^{-1}$ is a neighbourhood of $e$ in $V$. Finally, $h\mU h^{-1}\in\mV$ and the last axiom of a topological group is checked.

	This is important because there exists a topology on $H$ such that $H$ becomes a topological group and $\mV$ is a family of neighbourhood of $e$ in $H$. In particular, $V$ is a neighbourhood of $e$ in $H$.

	For any $z\in G$, we define the map $\dpt{\phi_z}{zN_e}{B_{\delta}}$ by
	\begin{equation}
		\phi_z(ze^{x_1X_1+\cdots+x_nX_n})=(x_1,\ldots,x_n),
	\end{equation}
	and we denote by $\varphi_z$ the restriction of $\phi_z$ to $zV$. If $z\in H$, then $\varphi_z$ sends the neighbourhood $zV$ of $z$ in $H$ to the open set $B_{\delta}\cap\lH$ in $\eR^{n-r}$. Indeed, an element of $zV$ is a $ze^Z$ with $Z\in\lH\cap B_{\delta}$ which is sent by $\varphi_z$ to an element of $\lH\cap B_{\delta}$. (we just have to identify $x_1X_1+\cdots+x_nX_n$ with $(x_1,\ldots,x_n)$).

	Moreover, if $z_1,z_2\in H$, the map $\varphi_{z_1}\circ\varphi_{z_2}^{-1}$ is the restriction to an open subset of $\lH$ of $\phi_{z_1}\circ\phi_{z_2}$. Then $\varphi_{z_1}\circ\varphi_{z_2}^{-1}$ is differentiable. Conclusion: $(H,\varphi_z: z\in H)$ is a differentiable manifold.

	Recall that the definition of $\lH$ was to be a subalgebra of $\lG$; therefore $V=e^{\lH\cap B_{\delta}}$ is a submanifold of $G$. But the left translations are diffeomorphism of $H$ and $H$ is the smallest subgroup of $G$ containing $e^{\lH}$. Thus $H$ is a manifold on which the multiplication is diffeomorphic and consequently, $H$ is a Lie subgroup of $G$.

	Rest to prove that the Lie algebra of $H$ is $\lH$ and the unicity part of the theorem.

	We know that $\dim H=\dim\lH$ and moreover for $i>r$, the map $t\to\exp tX_i$ is a curve in $H$. Now, the fact that $\lH$ is the set of $X\in\lG$ such that $t\to\exp tX$ is a path in $H$ show that $X_i\in\lH$. Then the Lie algebra of $H$ is $\lH$ and $H$ is a connected group because it is generated by $\exp\lH$ which is a connected neighbourhood of $e$ in $H$.

	We turn our attention to the unicity part. Let $H_1$ be a connected Lie subgroup of $G$ such that $T_eH_1=\lH$. Since $\exp_{\lH}X=\exp_{\lH_1}X$, $H=H_1$ as set. But $\exp$ is a differentiable diffeomorphism from a neighbourhood of $0$ in $\lH$ to a neighbourhood of $e$ in $H$ and $H_1$, so as Lie groups, $H$ and $H_1$ are the same.

	Let us consider an element $X\in\lG$ such that $\exp tX\in H$ for every $t\in\eR$, and the map $\dpt{\varphi}{\eR}{G}$, $\varphi(t)=\exp tX$. This is continuous, then there exists a connected neighbourhood $\mU$ of $0$ in $\eR$ such that $\varphi(\mU)\subset V$. Then $\varphi(\mU)\subset H\cap V$ and the connectedness of $\varphi(\mU)$ makes $\varphi(\mU)\subset\exp\mU_h$. But $\exp\mU_h$ is an arbitrary small neighbourhood of $e$ in $H$; the conclusion is that $\varphi$ is a continuous map from $\eR$ into $H$. Indeed, we had chosen $X$ such that $\exp tX\in H$.

	Moreover, we know that
	\[
		e^{(t_0+\epsilon)X}=e^{t_0X}e^{\epsilon X},
	\]
	but $\exp \epsilon X$ can be as close to $e$ as we want (this proves the continuity at $t_0$). Then $\varphi$ is a path in $H$.

	In definitive, we had shown that $\exp tX\in H$ implies that $t\to\exp tX$ is a path. Now equation \eqref{eq:path_alg} gives the result.
\end{proof}

\begin{corollary}
	Let $G$ be a Lie group and $H_1$, $H_2$, two subgroups both having a finite number of connected components (each for his own topology). If $H_1=H_2$ as sets, then $H_1=H_2$ as Lie groups.
\end{corollary}

\begin{proof}
	The proposition shows that $H_1$ and $H_2$ have same Lie algebra. But any Lie subalgebra of $\lG$ is the Lie algebra of exactly one connected subgroup of $G$ (theorem~\ref{tho:gp_alg}). Then as Lie groups, ${H_1}_0={H_2}_0$. Since $H_1$ and $H_2$ are topological groups, the equality of they topology on one connected component gives the equality everywhere (because translations are differentiable).
\end{proof}

\label{pg:ex_topo_Lie}
Consider the group $T=S^1\times S^1$ and the continuous map $\dpt{\gamma}{\eR}{T}$ given by
\[
	\gamma(t)=(e^{it},e^{i\alpha t})
\]
with a certain irrational $\alpha$ in such a manner that $\gamma$ is injective and $\Gamma=\gamma(\eR)$ is dense in $T$.

The subset $\Gamma$ is not closed because his complementary in $T$ is not open: any neighbourhood of element $p\in T$ which don't lie in $\Gamma$ contains some elements of $\Gamma$. We will show that the inclusion map $\dpt{\iota}{\Gamma}{T}$ is continuous. An open subset of $T$ is somethings like
\[
	\mO=(e^{iU},e^{iV})
\]
where $U,V$ are open subsets of $\eR$. It is clear that
\[
	\iota^{-1}(\mO)=\{ \gamma(t)\tq t\in U+2k\pi,\alpha t\in V+2m\pi \},
\]
but the set of elements $t$ of $\eR$ which satisfies it is clearly open. Then $\Gamma$ has at least the induced topology from $T$ (as shown in proposition~\ref{prop:topo_sub_manif}). In fact, the own topology of $\Gamma$ is \emph{more} than the induced: the open subsets of $\Gamma$ whose are just some small segments clearly doesn't appear in the induced topology. Thus the present case is an example (and not a counter-example) of theorem~\ref{tho:H_ferme}.

This example show the importance of the condition for a topological subspace to have \emph{exactly} the induced topology. If not, any Lie subgroup were a topological Lie subgroup because a submanifold has at least the induced topology. We will go further with this example after the proof.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Matrix Lie group and its algebra}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\label{SECooTSAJooNtjgMD}

In this section we deal with Lie groups made from matrices, that is subgroups of \( \GL(n, \eC)\) (typically \( \SO(n)\) or \( \SU(n)\)) and their Lie algebra. We will denote the identity either by \( e\) or by \( \mtu\).

\begin{normaltext}      \label{NORMooHZGKooJEiamo}
	It is time to reread the remark \ref{REMooJQFHooQuoZxt}. In this section, when \( \gamma\) is a path in the matrix group \( G\), we denote by \( \gamma'(0)\) the ``usual'' derivative of \( \gamma\): that is the component-wise derivative; not the differential operator.

	We denote by \( D_{\gamma}\) the differential operator
	\begin{equation}
		\begin{aligned}
			D_{\gamma}\colon  C^{\infty}(G) & \to \eR                                        \\
			f                               & \mapsto \Dsdd{ f\big( \gamma(t) \big) }{t}{0}.
		\end{aligned}
	\end{equation}

	We aim to study the link between \( D_{\gamma}\) and \( \gamma'(0)\).

	From the Lie group of matrix \( G\) we can build (at least) two Lie algebras\footnote{Definition \ref{DEFooVBPKooGxlDBn}.}:
	\begin{itemize}
		\item The usual Lie algebra of the group: \( T_eG\) with the definition \ref{DEFooKDCPooZOJsMD}. As set, this is
		      \begin{equation}
			      T_eG=\{ D_{\gamma}\tq \gamma(0)=e \}
		      \end{equation}
		      with the implicit that \( \gamma\) is a smooth path in \( G\).
		\item
		      The set of ``usual'' derivatives of the paths in \( G\):
		      \begin{equation}
			      G'=\{ \gamma'(0)\tq \gamma(0)=e \}.
		      \end{equation}
		      This is a set of matrices on which we can use the bracket \( [X,Y]=XY-YX\) (matrix product). We will see the following facts.
		      \begin{itemize}
			      \item
			            The set \( G'\) is a Lie algebra in proposition \ref{PROPooUKITooLnEKZW},
			      \item
			            The Lie algebras \( G'\) and \( T_eG\) are isomorphic as Lie algebras in theorem \ref{THOooWQGMooHyjRtx} for the case \( G=\GL(n,\eC)\)
			      \item
			            When \( H\) is a Lie subgroup of \( \GL(n,\eC)\), the Lie algebras \( H'\) and \( T_eH\) are isomorphic as Lie algebras in proposition \ref{PROPooSQHLooGQAykc} for the Lie subgroups of \( \GL(n,\eC)\).
		      \end{itemize}
	\end{itemize}
\end{normaltext}

\begin{lemma}[\cite{MonCerveau}]
	Let \( G\) be a matrix Lie group, et \( g\in G\) and \( X\in G'\). Then \( gXg^{-1}\in G'\).
\end{lemma}

\begin{proof}
	Let \( x\colon \eR\to G\) be a smooth path such that \( X=x'(0)\). Then we the derivative of the path given by the matrix product
	\begin{equation}
		t\mapsto gx(t)g^{-1}
	\end{equation}
	is \( gXg^{-1}\).
\end{proof}

\begin{lemma}[\cite{MonCerveau}]        \label{LEMooHQUYooSoiKbI}
	Let \( G\) be a matrix Lie group. Then \( G'\) is a vector space on \( \eR\).
\end{lemma}

\begin{proof}
	Let \( X,Y\in G'\) be the derivatives of the paths \( x\) and \( y\). If we set \( \varphi_1(t)=x(t)y(t)\) we have
	\begin{equation}
		\varphi_1'(0)=x'(0)y(0)+x(0)y'(0).
	\end{equation}
	Since \( x(0)=y(0)=e\) we have \( \varphi'(0)=X+Y\), so that \( X+Y\in G'\).

	For the product by a scalar, let the path \( \varphi_2(t)=x(\lambda t)\). The component-wise derivative
	\begin{equation}
		\varphi_2'(0)=\lambda x'(0)=\lambda X,
	\end{equation}
	so that \( \lambda X\in G'\).
\end{proof}

\begin{proposition}     \label{PROPooUKITooLnEKZW}
	Let \( G\) be a matrix Lie group. The vector space \( G'\) is a Lie algebra for the matrix commutator.
\end{proposition}

\begin{proof}
	We already know that \( G'\) is a real vector space by lemma \ref{LEMooHQUYooSoiKbI}. The fact that \( (X,Y)\mapsto XY-YX\) satisfies the axioms of a Lie algebra is easy to check. The only point is to show that if \( X,Y\in G'\), then \( [X,Y]=XY-YX\in G'\).

	Let
	\begin{equation}        \label{EQooJDTLooGWsDiq}
		\varphi(t)=x(t)Yx(-t).
	\end{equation}
	This is for sure a path in the full matrix vector space, and this is derivable because \( x\) is derivable while the matrix product is linear. So the derivative \( \varphi'(0)\) is still a matrix. The question is: why \( \varphi'(0)\in G'\) ?

	By lemma \ref{LEMooHQUYooSoiKbI}, for each \( t\) we have
	\begin{equation}
		\frac{ \varphi(t)-\varphi(0) }{ t }\in G'.
	\end{equation}
	Now, \( G'\) is a vector subspace of \( \eM(n,\eC)\) which is finite dimensional; is is thus closed and the limit belongs to \( G'\).

	Is is now a simple computation to show that \( \varphi'(0)=[X,Y]\).
\end{proof}

\begin{normaltext}
	The following theorem is a Giulietta's masterpiece in the following sense:
	\begin{itemize}
		\item It is fundamental because the Lie algebra isomorphism between \( T_eGL(n,\eR)\) and the matrices is used everywhere one says «The Lie algebra of $\SO(3)$ is the set of skew-symmetric traceless matrices».
		\item
		      Either I'm idiot, either I never seen that theorem even stated (let alone being proved)\footnote{There is in fact a third possibility:  this theorem is a classic one but cannot be found \emph{on internet}.}.
		\item
		      I think that the fundamental misunderstanding\footnote{Once again, either I'm idiot either everybody is wrong but me\ldots well \ldots} is that in the context of Lie groups, people \emph{define} \( [X,Y]\) as being \( \ad(X)Y\) while \( \ad\) is defined as the ``second differential'' of \( \AD(g)h=ghg^{-1}\). In that case, obviously we get \( [X,Y]=XY-YX\) with the matrix product. This way fails to make the link with the commutator of vector fields as defined by \ref{DEFooHOTOooRaPwyo}.
		\item
		      So you must read this proof with much care and write me if you see any mistake or unclear point.
	\end{itemize}
\end{normaltext}
So here it is with the notations explained in \ref{NORMooHZGKooJEiamo}.

\begin{theorem}     \label{THOooWQGMooHyjRtx}
	Let \( G=\GL(n,\eC)\) be the group of invertible matrices. The map
	\begin{equation}
		\begin{aligned}
			\phi\colon G' & \to T_eG           \\
			\gamma'(0)    & \mapsto D_{\gamma}
		\end{aligned}
	\end{equation}
	is
	\begin{enumerate}
		\item
		      well defined,
		\item
		      bijective,
		\item
		      linear,
		\item
		      a Lie algebra isomorphism.
	\end{enumerate}
\end{theorem}

\begin{proof}
	Several points to be proved.
	\begin{subproof}
		\spitem[\( \phi\) is well defined]
		Let \( \alpha\) and \( \beta\) be paths in \( G\) such that \( \alpha'(0)=\beta'(0)\) and let \( f\colon G\to \eR\) be a smooth function. We have to prove that \( D_{\alpha}(f)=D_{\beta}(f)\).

		We consider a chart \( \varphi\colon \mU\to \mO\) where \( \mU\) is a neighbourhood of \( 0\) in \( \eR^m\) and \( \mO\) is a neighbourhood of \( e\) in \( \GL(n,\eC)\). We suppose that \( \varphi(0)=e\). We set \( \tilde f=f\circ \varphi\), \( \tilde \alpha=\varphi^{-1}\circ \alpha\) and \( \tilde \beta=\varphi^{-1}\circ\beta\). We have
		\begin{subequations}
			\begin{align}
				D_{\alpha}(f) & =\Dsdd{ f\big( \alpha(t) \big) }{t}{0}                                                                 \\
				              & =\Dsdd{ \tilde f\big( \tilde \alpha(t) \big) }{t}{0}                                                   \\
				              & =\sum_{i=1}^m\frac{ \partial \tilde f }{ \partial x_i }\big( \tilde \alpha(0) \big)\tilde \alpha_i(0).
			\end{align}
		\end{subequations}
		Since \( \tilde \alpha(0)=\tilde \beta(0)\) we still have to prove that \( \tilde \alpha_i'(0)=\tilde \beta_i'(0)\). As you remember, \( \tilde \alpha\) is a map from \( \eR\) to \( \eR^m\), so that the following derivative is quite usual:
		\begin{subequations}
			\begin{align}
				\tilde \alpha'(0) & =\Dsdd{ (\varphi^{-1}\circ \alpha)(t) }{t}{0}    \\
				                  & =d\varphi^{-1}_{\alpha(0)}\big( \alpha'(0) \big) \\
				                  & =d\varphi^{-1}_{\beta(0)}\big( \beta'(0) \big).
			\end{align}
		\end{subequations}
		Thus the map \( \phi\) is well defined.
		\spitem[\( \phi\) is linear]
		This is from the linearity of the derivation.
		\spitem[\( \phi\) is injective]
		If \( \phi(\alpha')=\phi(\beta')\), then \( D_{\alpha}(f)=D_{\beta}(f)\) for every function \( f\). In that case,
		\begin{equation}
			\sum_{i=1}^m\frac{ \partial \tilde f }{ \partial x_i }(e)\tilde \alpha_i'(0)=\sum_{i=1}^m\frac{ \partial \tilde f }{ \partial x_i }(e)\tilde \beta_i'(0).
		\end{equation}
		That equation must be satisfied for every function. Taking the projection on the components, we get \( \tilde \alpha_i'(0)=\tilde b_i'(0)\), which means \( \alpha'(0)=\beta'(0)\) because \( \varphi^{-1}\) is bijective.
		\spitem[\( \phi\) is surjective]
		Every element of \( T_eG\) is of the form \( D_{\alpha}\) for some path \( \alpha\), so \( \phi\) is surjective.
		\spitem[\( \phi\) is a Lie algebra isomorphism]
		Let \( X,Y\in G'\) being the derivative of the paths \( \alpha\) and \( \beta\). We have to prove that
		\begin{equation}
			[\phi(X),\phi(Y)]=\phi[X,Y].
		\end{equation}
		If \( t\) is small enough, the paths
		\begin{subequations}
			\begin{align}
				\alpha(t)=\mtu+tX \\
				\beta(t)=\mtu+tY  \\
			\end{align}
		\end{subequations}
		are good ones because \( \det(\mtu)\neq 0\), so that the determinant of \( \mtu+tX\) remains different from zero when \( t\) is small, whatever \( X\) is. So \( \alpha\) and \( \beta\) are paths in \( \GL(n,\eC)\). Using the general definition in differential geometry,
		\begin{subequations}        \label{SUBEQSooCYRDooFOdLrn}
			\begin{align}
				[\phi(X),\phi(Y)]f & =[\phi(X)^L,\phi(Y)^L]_ef                                                                             \\
				                   & =\phi(X)^L_e\big( \phi(Y)^L(f) \big)-\phi(Y)^L_e\big( \phi(X)^L(f) \big) \label{SUBEQooOPUAooZYsZlX}.
			\end{align}
		\end{subequations}
		We focus on the first term:
		\begin{subequations}        \label{SUBEQooTUNFooFkDmuP}
			\begin{align}
				\phi(X)^L\big( \phi(Y)^L(f) \big) & =\Dsdd{ \phi(Y)^L_{\phi(X)^L_e(t)}(f) }{t}{0}                                                  \\
				                                  & =\DDsdd{ f\big( (\mtu+tX)(\mtu+sY) \big) }{t}{0}{s}{0}                                         \\
				                                  & =\DDsdd{ f(\mtu+tX+sY+tsXY) }{t}{0}{s}{0}                                                      \\
				                                  & =\Dsdd{ df_{\mtu+tX}\big( (\mtu+tX)Y \big) }{t}{0} \label{SUBEQooLHPBooTnXiZd}                 \\
				                                  & =\Dsdd{ df_{\mtu+tX}(Y) }{t}{0}+\Dsdd{ df_{\mtu+tX}(tXY) }{t}{0}   \label{SUBEQooMXJJooBFTLsM}
			\end{align}
		\end{subequations}
		where we have used the linearity of \( df_{\mtu+tX}\) and where \( XY\) stands for the matrix product. In the expression \eqref{SUBEQooLHPBooTnXiZd}, the symbol \( df\) stands for the differential of \( f\) as function from \( \eM(n,\eC)\) (as vector space), not for the differential of \( f\) on \( G\) as manifold. This is why we are allowed to put an expression as the matrix \( Y\) as argument of \( df_{\mtu+tX}\) while \( Y\) is not an element of \( T_{\mtu+tX}G\).

		The expression \eqref{SUBEQooMXJJooBFTLsM} is still made of two terms. The second one is
		\begin{equation}
			\Dsdd{ df_{\mtu+tX}(tXY) }{t}{0}=\Dsdd{ tdf_{\mtu+tX}(XY) }{t}{0}=df_{\mtu}(XY)
		\end{equation}
		where we used the Leibniz rule\footnote{In general, notice that \( \Dsdd{ tf(t) }{t}{0}=f(0)\)}.

		The first term in \eqref{SUBEQooMXJJooBFTLsM} is computed as
		\begin{equation}
			\Dsdd{ df_{\mtu+tX}(Y) }{t}{0}=\DDsdd{ f(\mtu+tX+sY) }{t}{0}{s}{0}.
		\end{equation}
		We set
		\begin{equation}
			\begin{aligned}
				\gamma\colon \eR^2 & \to G               \\
				(t,s)              & \mapsto \mtu+tX+sY,
			\end{aligned}
		\end{equation}
		so that
		\begin{subequations}
			\begin{align}
				\Dsdd{ df_{\mtu+tX}(Y) }{t}{0} & =\DDsdd{ f(\mtu+tX+sY) }{t}{0}{s}{0}                               \\
				                               & =\DDsdd{ (\tilde f\circ\varphi^{-1}\circ\gamma)(t,s) }{t}{0}{s}{0} \\
				                               & =\DDsdd{ g(t,s) }{t}{0}{s}{0}
			\end{align}
		\end{subequations}
		where the function \( g=\tilde f\circ\varphi^{-1}\circ \gamma\) is a smooth function from \( \eR^2\) to \( \eR\).

		The expression \eqref{SUBEQooTUNFooFkDmuP} is now
		\begin{equation}
			\phi(X)^L\big( \phi(Y)^L(f) \big)=\DDsdd{ g(t,s) }{t}{0}{s}{0}+df_{\mtu}(XY).
		\end{equation}
		The commutator we have to compute, with the same computations is
		\begin{equation}
			[\phi(X),\phi(Y)]f=\DDsdd{ g(t,s) }{t}{0}{s}{0}+df_{\mtu}(XY)-\DDsdd{ g(s,t) }{t}{0}{s}{0}-df_{\mtu}(YX).
		\end{equation}
		The function \( g\) being \(  C^{\infty}\), the derivative commute and the corresponding termes annihilate each other and we are left with
		\begin{equation}
			[\phi(X),\phi(Y)]f=df_{\mtu}(XY)-df_{\mtu}(YX)=df_{\mtu}(XY-YX)
		\end{equation}
		where we used the linearity of the differential.

		In the other sense,
		\begin{equation}
			\phi[X,Y]f=\Dsdd{ f(\mtu+tXY-tYX) }{t}{0}=df_{\mtu}\big( [X,Y] \big)
		\end{equation}
		where, once again, \( df\) stands for the ``usual'' differential.
	\end{subproof}
\end{proof}

Ok. This is proved for \( G=\GL(n,\eC)\), the full matrix group. What about subgroups ? Here is the result.

\begin{proposition}[\cite{MonCerveau}]      \label{PROPooSQHLooGQAykc}
	Let \( H\) be a closed Lie subgroup of \( \GL(n,\eC)\). With the same notations as above, the map
	\begin{equation}
		\begin{aligned}
			\phi\colon H' & \to T_eH           \\
			\gamma'(0)    & \mapsto D_{\gamma}
		\end{aligned}
	\end{equation}
	is a Lie algebra isomorphism.
\end{proposition}

\begin{proof}
	We have to prove that
	\begin{equation}        \label{EQooRLBBooYgHhtH}
		\phi[X,Y]f=[\phi(X),\phi(Y)]f
	\end{equation}
	for every \( X,Y\in H'\) and \( f\in  C^{\infty}(H)\). For that, we will see the left and right hand sides of \eqref{EQooRLBBooYgHhtH} in \( G=\GL(n,\eC)\), and use the already proved result, theorem \ref{THOooWQGMooHyjRtx}.

	If \( X,Y\in H'\) we know from proposition \ref{PROPooUKITooLnEKZW} that \( [X,Y]\in H'\). Thus there exists a path \( \gamma\colon \eR\to H\) such that \( [X,Y]=\gamma'(0)\). We consider the extension\footnote{The proposition \ref{PROPooOTZQooIfboXV} can be used since \( H\) is a submanifold of \( G\) by \ref{PROPooFXZJooCOFXZX}.} \( \tilde f\colon W\to \eR\) of \( f\) such that \( \tilde f=f\) on \( H\) and \( W\) is an open set around \( e\) in \( \GL(n,\eC)\). For the sake of making things complicated we also define \( \tilde \gamma=\iota\circ \gamma\) where \( \iota\colon H\to \GL(n,\eC)\) is the inclusion. With all that we have
	\begin{equation}
		\phi[X,Y]f=\Dsdd{ f\big( \gamma(t) \big) }{t}{0}=\Dsdd{ \tilde f\big( \tilde \gamma(t) \big) }{t}{0}=\clubsuit.
	\end{equation}
	At this point, notice that \( [X,Y]\in \GL(n,\eC)'\) and \( [X,Y]=\tilde \gamma'(0)\), so that if we consider the map \( \tilde \phi\colon \GL(n,\eC)\to T_e\GL(n,\eC)\) we also have
	\begin{equation}
		\clubsuit=\Dsdd{ \tilde f\big( \tilde \gamma(t) \big) }{t}{0}=\tilde \phi[X,Y]\tilde f=\big[ \tilde \phi(X),\tilde \phi(Y) \big]\tilde f
	\end{equation}
	where we used the result \ref{THOooWQGMooHyjRtx} on \( \GL(n,\eC)\).

	We still have to prove that \( \tilde \phi(X)\tilde \phi(Y)\tilde f=\phi(X)\phi(Y)f\). Using, among others the formula \ref{SUBEQSooHKWMooQbeStl} adapted to \( \tilde \phi(X)\) instead of \( X\):
	\begin{subequations}
		\begin{align}
			\tilde \phi(X)\tilde \phi(Y)\tilde f & =\Dsdd{ \big( \tilde \phi(Y)^L\tilde f \big)\big( \alpha(t) \big) }{t}{0} \\
			                                     & =\Dsdd{ \tilde \phi(Y)^L_{\alpha(t)}\tilde f }{t}{0}                      \\
			                                     & =\DDsdd{ \tilde f\big( \alpha(t)\beta(u) \big) }{t}{0}{s}{0}.
		\end{align}
	\end{subequations}
	At this point, notice that \( \alpha(t)\) and \( \beta(u)\) are elements in \( H\) which is a group, so \( \tilde f\big( \alpha(t)\beta(u) \big)=f\big( \alpha(t)\beta(u) \big)\). Thus
	\begin{subequations}
		\begin{align}
			\tilde \phi(X)\tilde \phi(Y)\tilde f & =\DDsdd{ \tilde f\big( \alpha(t)\beta(u) \big) }{t}{0}{s}{0} \\
			                                     & =\DDsdd{ f\big( \alpha(t)\beta(u) \big) }{t}{0}{s}{0}        \\
			                                     & =\phi(X)\phi(y)f.
		\end{align}
	\end{subequations}
\end{proof}

\begin{lemma}[\cite{MonCerveau}]
	Let \( G\) be a Lie group of matrices and \( X\in T_eG\) such that
	\begin{equation}
		df_e(X)=0
	\end{equation}
	for every smooth function \( f\colon G\to \eR\). Then \( X=0\).
\end{lemma}

\begin{proof}
	We consider the functions \( \pr_{ij}\colon G\to \eR\) defined by \( \pr_{ij}(A)=A_{ij}\). If \( g\colon \eR\to G\) is a path, for every \( t\) we have \( \pr_{ij}g(t)=g(t)_{ij}\) and then
	\begin{equation}
		\Dsdd{ \pr_{ij}g(t) }{t}{0}=g'(0)_{ij}.
	\end{equation}
	Then we build
	\begin{equation}
		\begin{aligned}
			f\colon G & \to \eR                         \\
			A         & \mapsto \pr_{11}(A)\pr_{ij}(A).
		\end{aligned}
	\end{equation}
	If \( g\colon \eR\to G\) is a path such that \( g(0)=e\) and \( g'(0)=X\), then we have
	\begin{subequations}
		\begin{align}
			\Dsdd{ f\big( g(t) \big) }{t}{0} & =\Dsdd{ \pr_{11}\big( g(t) \big)\pr_{ij}\big( g(t) \big) }{t}{0}                 \\
			                                 & =\pr_{11}g(0)\Dsdd{ \pr_{ij}g(t) }{t}{0}+\Dsdd{ \pr_{11}g(t) }{t}{0}\pr_{ij}g(0) \\
			                                 & =X_{ij}+\delta_{ij}X_{11}                                                        \\
			                                 & =X_{ij}+\delta_{ij}X_{11}.
		\end{align}
	\end{subequations}
	We know that this is zero for every choice of \( ij\):
	\begin{equation}
		X_{ij}+\delta_{ij}X_{11}=0
	\end{equation}
	In particular with \( i=j=1\) we have \( 2X_{11}=0\), so that \( X_{11}=0\). Then we are left with \( X_{ij}=0\) for every \( ij\).
\end{proof}

\section{Fundamental vector field}\label{sec:fond_vec}
%++++++++++++++++++++++++++++++++++++

\begin{definition}
	If $\yG$ is the Lie algebra\footnote{Lie algebra of a Lie group, definition \ref{DEFooKDCPooZOJsMD}.} of a Lie group $G$ acting on a manifold $M$ (the action of $g$ on $x$ being denoted by $x\cdot g$), the \defe{fundamental vector field}{fundamental!vector field} associated with $A\in\yG$ is given by
	\begin{equation}			\label{EqDefChmpFond}
		A^*_x=\Dsdd{ x\cdot e^{-tA} }{t}{0}.
	\end{equation}
\end{definition}

If the action of $G$ is transitive, the fundamental vectors at point $x\in M$ form a basis of $T_xM$. More precisely, we have the

\begin{lemma}
	For any $v\in T_xM$, there exists a $A\in\yG$ such that $v=A^*_x$, in other terms
	\[
		\Span\{ A^*_{x}\tq A\in\yG \}=T_{x}M.
	\]
	\label{LemFundSpansTan}
\end{lemma}

\begin{proof}
	The vector $v$ is given by a path $v(t)$ in $M$. Since the action is transitive, one can write $v(t)=x\cdot c(t)$ for a certain path $c$ in $G$ which fulfills $c(0)=e$. We have to show that $v$ depends only on $c'(0)\in\yG$. We consider
	\begin{equation}  \label{eq_def_RGM}
		\begin{aligned}
			R\colon G\times M & \to M       \\
			R(g,x)            & = x\cdot g,
		\end{aligned}
	\end{equation}
	so
	\begin{equation}\label{eq:v_Rc}
		v=\Dsdd{ R(c(t),x) }{t}{0}=dR_{(e,x)}\big[  (d_tc(t),x)+(c(0),x)   \big].
	\end{equation}

\end{proof}

\begin{lemma}\label{lem:As_Bs_A_B}
	If $A$, $B\in\yG$ are such that $A^*=B^*$, and if the action is effective, then $A=B$.
\end{lemma}

\begin{proof}
	We consider once again the map \eqref{eq_def_RGM} and we look at
	\[
		v=\Dsdd{ R(c(t),x) }{t}{0}
		=(dR)_{(e,x)}\Dsdd{ (c(t),x) }{t}{0},
	\]
	keeping in mind that $c(t)=e^{-tA}$. In order to treat this expression, we define
	\begin{subequations}
		\begin{align}
			\dpt{R_1}{G}{M},\quad  R_1(h) & =R(h,x), \\
			\dpt{R_2}{M}{M},\quad  R_2(y) & =R(g,y).
		\end{align}
	\end{subequations}
	So
	\[
		v=dR_1(X)+dR_2(0)=dR_1c'(0)
	\]
	and the assumption $A^*_x=B^*_x$ becomes $dR_1 A=dR_1 B$. This makes, for small enough $t$,
	\begin{equation}
		R_1(e^{tA}e^{-tB})=x\cdot e^{tA}e^{-tB}=x;
	\end{equation}
	if the action is effective, it imposes $A=B$.
\end{proof}

\begin{lemma}
	If we consider the action of a matrix group, $R_g$ acts on the fundamental field by
	\[
		dR_g(A^*_{\xi})=\big( \Ad(g^{-1})A \big)^*_{\xi\cdot g}.
	\]
	\label{lem:dRgAstar}
\end{lemma}

\begin{proof}
	Just notice that $e^{-t\Ad(g^{-1})A}=\AD_{g^{-1}}(e^{-tA})=g^{-1} e^{-tA}g$, thus
	\begin{equation}
		\big( \Ad(g^{-1})A \big)^*_{\xi\cdot g}=\Dsdd{ \xi\cdot ge^{-t\Ad(g^{-1})A} }{t}{0}=dR_g(A^*_{\xi}).
	\end{equation}
\end{proof}


%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Exponential map}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Integral curve}
%---------------------------------------------------------------------------------------------------------------------------

The integral curve of a vector field on a manifold is given by definition \ref{PROPooJACTooXBSxfE}. Here we are dealing with special manifolds: Lie groupe. From definition \ref{DEFooYHKXooVoJalX} we know that one can create vector fields (invariant) on \( G\) from an element of \( T_eG\).

We want to prove that the vector space of left invariant vector fields is isomorphic to the tangent vector space \( T_eG\) to \( G\) at identity. If \( X\in T_eG\), we introduce the left invariant vector field \( X^L=dLX\), more explicitly:
\begin{equation}
	X^L_g=\Dsdd{ gX(t) }{t}{0}.
\end{equation}
Then we consider \( \alpha_X\colon I\to G\) the integral curve of maximal length to \( X^L\) through \( X_e\). Here, \( I\) is the interval on which \( \alpha_X\) is defined. This is the solution of
\begin{subequations}        \label{SUBEQSooBJUVooEeOVVA}
	\begin{numcases}{}
		\Dsdd{ \alpha_X(t_0+t) }{t}{0}=X_{\alpha_X(t_0)}\\
		\alpha_X(0)=e.
	\end{numcases}
\end{subequations}
Existence and unicity by proposition \ref{PROPooJACTooXBSxfE}. What we write \( \alpha_X\) here is what is written \( \Phi_e^X\) there. Si as far as the notations are concerned,
\begin{equation}
	\alpha_X=\Phi_e^X.
\end{equation}

\begin{proposition}     \label{PROPooWEYCooCvyHNr}
	Let \( X\in T_eG\). The integral curve of \( X^L\) is defined on \( \eR\) and for every \( s,t\in\eR\),
	\begin{equation}
		\alpha_X(s+t)=\alpha_X(s)\alpha_X(t).
	\end{equation}
\end{proposition}

\begin{proof}
	Let \( \alpha\) be any integral curve for \( X^L\) and \( y\in G\). If we put \( \alpha_1(t)=y\alpha(t)\), we have
	\begin{equation}
		\Dsdd{ \alpha_1(t) }{t}{0}=X^L_y,
	\end{equation}
	so that \( \alpha_1\) is an integral curve for \( X^L\) through the point \( y\).

	Let now \( I\) be the maximal domain of \( \alpha_X\), and \( t_1\in I\). If we set \( x_1=\alpha_X(t_1)\), the path
	\begin{equation}
		\alpha_1(t)=x_1\alpha_X(t)
	\end{equation}
	is an integral curve of \( X^L\) through \( x_1\) and has the same maximal definition domain \( I\). On the other hand, the maximal integral curve starting at \( e\) being \( \alpha_X\), the maximal integral curve starting at \( \alpha_X(t_1)\) is
	\begin{equation}
		\alpha_2\colon t\mapsto \alpha_X(t+t_1).
	\end{equation}
	Its domain is \( I-t_1\), but since it starts at \( x_1\), it has to be the same as \( \alpha_1\), then \( I\subset I-t_1\) which proves that \( I=\eR\).

	For each \( s\) and \( t\) in \( \eR\), the maximal integral curve starting at \( \alpha_X(s)\) can be written as
	\begin{equation}
		c(t)=\alpha_X(s)\alpha_X(t)
	\end{equation}
	as well as
	\begin{equation}
		d(t)=\alpha_X(s+t),
	\end{equation}
	so again by unicity, \( \alpha_X(s+t)=\alpha_X(s)\alpha_X(t)\).
\end{proof}

\begin{lemma}[\cite{MonCerveau}]        \label{LEMooNZCJooSltfLg}
	Let \( G\) be a Lie group and \( X\in\lH\). For every \( u\in \eR\) we have
	\begin{equation}        \label{EQooMNQLooHNDpJS}
		\Phi_e^{(uX)^L}(t)=\Phi_e^{X^L}(tu).
	\end{equation}
\end{lemma}

\begin{proof}
	First observation: proposition \ref{PROPooWEYCooCvyHNr} ensures that the flow exists for every \( u\), so that the left and right hand sides of \eqref{EQooMNQLooHNDpJS} makes sense for every \( u\in \eR\).

	Let \( u\in \eR\). We define
	\begin{equation}
		\begin{aligned}
			\gamma\colon \eR & \to G                    \\
			t                & \mapsto \Phi_e^{X^L}(tu)
		\end{aligned}
	\end{equation}
	and we prove that this is the integral curve of \( (uX)^L\) by checking the two conditions of proposition \ref{PROPooJACTooXBSxfE}. The first condition is easy:
	\begin{equation}
		\gamma(0)=\Phi_e^{X^L}(0)=e.
	\end{equation}
	The second condition to be checked is
	\begin{equation}
		\gamma'(t_0)=(uX)^L_{\gamma(t_0)}.
	\end{equation}
	We have
	\begin{subequations}
		\begin{align}
			\gamma'(t_0) & =u(\Phi^{X^L}_e)'(t_0u)      & \text{lem. \ref{LEMooMHSQooQyTZCg}}   \\
			             & =u(X^L)_{\Phi_e^{X^L}(t_0u)}                                         \\
			             & =u(X^L)_{\gamma(t_0)}                                                \\
			             & =(uX)^L_{\gamma(t_0)}        & \text{prop. \ref{PROPooWWXKooWEBpMf}}
		\end{align}
	\end{subequations}
\end{proof}

\begin{proposition} \label{PROPooUXFQooIwimav}
	The flow\footnote{Definition \ref{PROPooJACTooXBSxfE}.} of a smooth left-invariant vector field \( X\) is given by
	\begin{equation}
		\Phi(t,g)=g\Phi(t,e).
	\end{equation}
\end{proposition}

\begin{proof}
	In few steps.
	\begin{subproof}
		\spitem[Left invariance]
		% -------------------------------------------------------------------------------------------- 

		The left invariance means that $(dL_g)_hX_h=X_{gh}$ for every \( h\in G\). We write that condition with \( h=\Phi_e(t_0)\):
		\begin{equation}        \label{EQooPGWKooWNKslJ}
			(dL_g)_{\Phi_e(t_0)}X_{\Phi_e(t_0)}(f)=X_{g\Phi_e(t_0)}(f).
		\end{equation}
		for every smooth function \( f\colon M\to \eR\).
		\spitem[The path]
		% -------------------------------------------------------------------------------------------- 
		In order to prove that \( \Phi_g(t)=\Phi_e(t)\) we consider the path
		\begin{equation}
			\begin{aligned}
				\gamma\colon I & \to M              \\
				t              & \mapsto g\Phi_e(t)
			\end{aligned}
		\end{equation}
		and we prove that it satisfy the properties to be the integral curve of \( X\) at \( g\), that is the two conditions of definition \ref{PROPooJACTooXBSxfE}.
		\spitem[First condition]
		% -------------------------------------------------------------------------------------------- 
		This is the easy one: \( \gamma(0)=g\Phi_e(0)=ge=g\).
		\spitem[Second condition]
		% -------------------------------------------------------------------------------------------- 
		We apply \( \gamma'(0)\) to a function \( f\):
		\begin{subequations}
			\begin{align}
				\gamma'(0)f & =\Dsdd{ (f\circ \gamma)(t) }{t}{t_0}                                                                                     \\
				            & =\Dsdd{ f\big( g\Phi_e(t) \big) }{t}{t_0}                                                                                \\
				            & =\Dsdd{ (f\circ L_g)\big( \Phi_e(t) \big) }{t}{t_0}                                                                      \\
				            & =(dL_g)_{\Phi_e(t_0)}\big( \Phi_e'(t_0) \big)f                             & \text{proposition \ref{PROPooALATooGgcVQV}} \\
				            & =(dL_g)_{\Phi_e(t_0)}X_{\Phi_e(t_0)}(f)        \label{SUBEQooOMDOooFZaCLp}                                               \\
				            & =X_{g\Phi_e(t_0)}(f)                                                       & \text{by \eqref{EQooPGWKooWNKslJ}}          \\
				            & =X_{\gamma(t_0)}(f).
			\end{align}
		\end{subequations}
		Justifications.
		\begin{itemize}
			\item For \eqref{SUBEQooOMDOooFZaCLp}, by definition of an integral curve, \( \Phi'_e(t_0)=X_{\Phi_e(t_0)}\)
		\end{itemize}
	\end{subproof}
\end{proof}


%---------------------------------------------------------------------------------------------------------------------------
\subsection{Integral curve and exponential}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}[Exponential map]     \label{DEFooOLLZooMHRgsz}
	If \( G\) is a Lie group with algebra \( \lG\), we define the \defe{exponential}{exponential from a Lie algebra} is the map
	\begin{equation}\label{EqdefExpoLieTgFGp}
		\begin{aligned}
			\exp\colon \lG & \to G                   \\
			X              & \mapsto \Phi^{X^L}_e(1)
		\end{aligned}
	\end{equation}
	where \( \Phi\) is the flow defined in \ref{PROPooJACTooXBSxfE} and \( X^L\) is the left-invariant vector field defined in \ref{PROPooLEIAooTnnYRw}.
\end{definition}

\begin{normaltext}
	This definition works on Lie groups thanks to the group structure that allows to build a natural vector field \( X^L\) from the data of a single vector \( X\). On general manifolds, one has not a notion of exponential. However, if one has a Riemannian manifold, one consider the geodesic.

	In the case of groups for which the Killing form defines a scalar product, the notion of exponential associated with the Riemannian structure propagated from the Killing form coincides with the definition \eqref{EqdefExpoLieTgFGp}.
\end{normaltext}


%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Flow and exponential}
%---------------------------------------------------------------------------------------------------------------------------

\begin{lemma}       \label{LEMooEQFHooRjUAin}
	We have
	\begin{enumerate}
		\item
		      \( \exp(0)=e\).
		\item \label{ITEMooTQHIooFLaOnX}
		      \( \exp(X)^{-1}=\exp(-X)\).
	\end{enumerate}
	%TODOooZWOVooPqavON. Prouver ça.
\end{lemma}


\begin{lemma}[\cite{MonCerveau}]        \label{LEMooGKDKooFTsDSr}
	Let \( G\) be a Lie group, \( \lG\) its Lie algebra. Let \( t\in \eR\) and \( X\in\lG\). We have
	\begin{equation}
		\exp(tX)=\Phi_e^{X^L}(t).
	\end{equation}
	In other words, \( t\mapsto \exp(tX)\) is an integral curve of \( X\).
\end{lemma}

\begin{proof}
	Computation:
	\begin{subequations}
		\begin{align}
			\exp(tX) & =\Phi_e^{(tX^L)}(1) & \text{definition}                    \\
			         & =\Phi_e^{X^L}(t)    & \text{lem. \ref{LEMooNZCJooSltfLg}}.
		\end{align}
	\end{subequations}
\end{proof}

\begin{proposition}[\cite{BIBooFLEXooPgvAlz}]       \label{PROPooMIMZooAwxvkB}
	Let \( G\) be a smooth Lie group. The exponential map \( \exp\colon \lG\to G\) is smooth.
\end{proposition}

\begin{proof}
	We consider the product manifold\footnote{See the proposition \ref{PROPooJVSQooGvNqIx} for the manifold structure on the vector space \( \lG\) and the definition \ref{DEFooYOLXooDPrnHa} for the product of manifolds.} \( M=G\times \lG\) and the vector field \( Y_{(g,X)}=(X^L_g,0)\), and the map
	\begin{equation}
		\begin{aligned}
			\Phi\colon \eR\times G\times \lG & \to G\times \lG         \\
			(t,g,X)                          & \mapsto (g e^{tX}, X) .
		\end{aligned}
	\end{equation}
	We prove that \( \Phi\) is the flow\footnote{Definition \ref{PROPooJACTooXBSxfE}.} of the vector field \( Y\). Since \( \exp(0)=e\) (lemma \ref{LEMooEQFHooRjUAin}), we have \( \Phi(0,g,X)=(g,X)\). For the second condition, we use the lemma \ref{LEMooTONEooFiysTA}:
	\begin{subequations}
		\begin{align}
			\Dsdd{ \Phi_{(g,X)}(t) }{t}{0} & =\Dsdd{ \big( g\exp(tX),X \big) }{t}{0}                \\
			                               & =\Big( \Dsdd{ g\exp(tX) }{t}{0},\Dsdd{ X }{t}{0} \Big) \\
			                               & =(X^L_g,0)                                             \\
			                               & =Y_{(g,X)}.
		\end{align}
	\end{subequations}
	Since the vector field \( Y\) is smooth, the proposition \ref{PROPooQVQAooJVdwOa} says that \( \Phi\) is smooth.

	Let
	\begin{equation}
		\begin{aligned}
			\alpha\colon \lG & \to G\times \lG                            \\
			X                & \mapsto \Phi(1,e,X)=\big( \exp(X),X \big).
		\end{aligned}
	\end{equation}
	As restriction of \( \Phi\), the map \( \alpha\) is smooth.

	The projection map
	\begin{equation}
		\begin{aligned}
			\pi_1\colon G\times \lG & \to G     \\
			(g,X)                   & \mapsto g
		\end{aligned}
	\end{equation}
	is smooth from the proposition \ref{PROPooCHVLooVFScOl}\ref{ITEMooRFFAooRSeBPl}. As composition, the map
	\begin{equation}
		\exp=\pi_1\circ\alpha
	\end{equation}
	is smooth.
\end{proof}

\begin{lemma}           \label{LEMooKSTKooNCnxzB}
	If \( \varphi\colon G\to H\) is a smooth Lie group morphism, then
	\begin{equation}
		d\varphi_e(X)^L=d\varphi(X^L).
	\end{equation}
	More explicitly, for every \( g\in G\) we have
	\begin{equation}
		d\varphi_e(X)^L_{\varphi(g)}=d\varphi_gX^L_g.
	\end{equation}
\end{lemma}

\begin{proof}
	Let \( h\in H\). We compute the vector field \( d\varphi_e(X)^L\) at \( h\):
	\begin{subequations}
		\begin{align}
			d\varphi_e(X)^L_h & =(dL_h)_e\big( d\varphi_e(X) \big)                                                     \\
			                  & =\Dsdd{ (L_h\circ\varphi)\big( \exp(tX) \big) }{t}{0}                                  \\
			                  & =\Dsdd{ \varphi\big( \varphi^{-1}(h) e^{tX} \big) }{t}{0}  \label{SUBEQooEWJUooMNJdHj} \\
			                  & =d\varphi_{\varphi^{-1}(h)}\Dsdd{ L_{\varphi^{-1}(h)} e^{tX} }{t}{0}                   \\
			                  & =d\varphi_{\varphi^{-1}(h)}\big( dL_{\varphi^{-1}(h)} \big)_eX                         \\
			                  & =d\varphi_{\varphi^{-1}(h)}X^L_{\varphi^{-1}(h)}.
		\end{align}
	\end{subequations}
	Justifications.
	\begin{itemize}
		\item For \eqref{SUBEQooEWJUooMNJdHj}. Since \( \varphi\) is a group morphism, \( h\varphi(g)=\varphi\big( \varphi^{-1}(h)g \big)\).
	\end{itemize}
\end{proof}

\begin{lemma}[\cite{BIBooFLEXooPgvAlz}]     \label{LEMooHQYMooJjdKkG}
	Let \( G\) be a Lie group and \( \lG\) be its Lie algebra. We have
	\begin{equation}
		(d\exp)_0\circ j=\id
	\end{equation}
	where \( j\) is given by\footnote{See also the proposition \ref{PROPooJVSQooGvNqIx}.}
	\begin{equation}
		\begin{aligned}
			j\colon \lG & \to T_0\lG                 \\
			X           & \mapsto \Dsdd{ tX }{t}{0}.
		\end{aligned}
	\end{equation}
\end{lemma}

\begin{proof}
	Let \( \gamma(t)=tX\), so that \( j(X)=\gamma'(0)\). We have
	\begin{subequations}
		\begin{align}
			(d\exp)_0j(X) & =(d\exp)_0\gamma'(0)                                                            \\
			              & =\Dsdd{ \exp\big( \gamma(t) \big) }{t}{0}                                       \\
			              & =\Dsdd{ \exp(tX) }{t}{0}                                                        \\
			              & =\Dsdd{ \Phi_e^{X^L}(t) }{t}{0}           & \text{lem. \ref{LEMooGKDKooFTsDSr}} \\
			              & =X^L_e                                                                          \\
			              & =X.
		\end{align}
	\end{subequations}
\end{proof}


\begin{proposition}[\cite{BIBooFLEXooPgvAlz,Lie}]       \label{PROPooKYNDooVAEzFw}
	Let $G$, $H$ be two Lie groups with algebras\footnote{Lie algebra of a Lie group, definition \ref{DEFooKDCPooZOJsMD}.} $\mG$ and $\mH$. Let $\dpt{\phi}{G}{H}$ be a group morphism which is differentiable at $e\in G$. Then for every $X\in\lG$, the following formula holds:
	\begin{equation}
		\phi(\exp X)=\exp(d\phi_eX).
	\end{equation}
\end{proposition}

\begin{proof}
	Let \( x\in\lG\) and define
	\begin{equation}
		\begin{aligned}
			\phi_X\colon \eR & \to H                            \\
			t                & \mapsto (\varphi\circ \exp)(tX).
		\end{aligned}
	\end{equation}
	We prove that this is an integral curve of \( d\varphi(X^L)\). Using lemma \ref{LEMooGKDKooFTsDSr} and the fact that \( \varphi\) is a group morphism (\( \varphi(e)=e\)), we have the first condition:
	\begin{equation}
		\phi_X(0)=(\varphi\circ\exp)(0)=\varphi(e)=e.
	\end{equation}
	The second condition to be checked is, for every \( t_0\) in a neighborhood of \( 0\in \eR\),
	\begin{equation}
		\Dsdd{ \phi_X(t) }{t}{t_0}=d\varphi(X^L)_{\phi_X(t_0)}.
	\end{equation}
	To prove that, we write \( h=\phi_X(t_0)\). We have
	\begin{subequations}
		\begin{align}
			\Dsdd{ \phi_X(t) }{t}{t_0} & =\Dsdd{ \varphi\big( \exp(tX) \big) }{t}{t_0}                                                                                                                \\
			                           & =d\varphi_{\exp(t_0X)}\Dsdd{  \exp(tX) }{t}{t_0}                                                                                                             \\
			                           & =d\varphi_{\exp(t_0X)}\Dsdd{ \Phi_e^{X^L}(t) }{t}{t_0}                                                                 & \text{lem. \ref{LEMooGKDKooFTsDSr}} \\
			                           & =d\varphi_{\exp(t_0X)}X^{L}_{\exp(t_0X)}       \label{SUBEQooDKLLooSMJbVf}                                                                                   \\
			                           & =d\varphi_{\varphi^{-1}\big( \phi_X(t_0) \big)}X^L_{\varphi^{-1}\big( \phi_X(t_0) \big)}   \label{SUBEQooPKFUooNwMkeC}                                       \\
			                           & =d\varphi_e(X)^L_{\phi_X(t_0)}     \text{lem. \ref{LEMooKSTKooNCnxzB}}
		\end{align}
	\end{subequations}
	Justifications.
	\begin{itemize}
		\item For \eqref{SUBEQooDKLLooSMJbVf}. From the definition of the flow,
		      \begin{equation}
			      \Dsdd{ \Phi_e^{X^L}(t) }{t}{t_0}=X^{L}_{\Phi^{X^L}_e(t_0)}=X^L_{\exp(t_0X)}.
		      \end{equation}
		\item
		      By definition of \( \phi_X\), \( \exp(t_0X)=\varphi^{-1}\big( \phi_X(t_0) \big)\).
	\end{itemize}
	We proved that \( \phi_X\) is an integral curve of \( d\varphi(X)\). But lemma \ref{LEMooGKDKooFTsDSr} says that the integral curve of \( d\varphi(X)\) is \( t\mapsto \exp\big( td\varphi(X) \big)\). We deduce that these two curves are equal, and that, for every \( t\) we have
	\begin{equation}
		\varphi\big( \exp(tX) \big)=\exp\big( d\varphi_e(tX) \big).
	\end{equation}
\end{proof}

%-------------------------------------------------------
\subsection{Properties of the exponential}
%----------------------------------------------------


\begin{proposition}[\cite{MonCerveau}]	\label{PROPooPEFPooFvpxTe}
	Let \(  G\) be a smooth Lie group.
	\begin{enumerate}
		\item		\label{ITEMooKSGJooHdaZcR}
		      If \( X\) is a smooth vector field, then \( \alpha_X=\Phi_e^X \).
		\item		\label{ITEMooAFTTooHpaeJi}
		      If \( X\in \lG\), then \( \exp(X)=\Phi_e^{X^L}(1)\).
		\item	\label{ITEMooXRHDooTlrTYA}
		      If \( X\in\lG\), then \( \exp(tX)=\Phi_e^{X^L}(t)\)
	\end{enumerate}
\end{proposition}

\begin{proof}
	Several parts.
	\begin{subproof}
		\spitem[For \ref{ITEMooKSGJooHdaZcR}]
		%-----------------------------------------------------------
		The differential equation \eqref{SUBEQSooBJUVooEeOVVA} is the same as the one of proposition \ref{PROPooJACTooXBSxfE} (which proves unicity).
		\spitem[For \ref{ITEMooAFTTooHpaeJi}]
		%-----------------------------------------------------------
		It is the definition \ref{DEFooOLLZooMHRgsz}.
		\spitem[For \ref{ITEMooXRHDooTlrTYA}]
		%-----------------------------------------------------------
		It is lemma \ref{LEMooGKDKooFTsDSr}.
	\end{subproof}
\end{proof}


The following proposition is a generalization of \ref{PROPooKDKDooCUpGzE}.
\begin{proposition}     \label{PROPooNRVJooEDCpOI}
	If \( X\in \lG\) and \( s,t\in \eR\) we have
	\begin{equation}
		e^{sX} e^{tX}= e^{(s+t)X}.
	\end{equation}
\end{proposition}

\begin{proof}
	A computation using all the previous properties :
	\begin{subequations}
		\begin{align}
			\exp(sX)\exp(tX) & =\Phi_e^{X^L}(s)\Phi_e^{X^L}(t) & \text{prop. \ref{PROPooPEFPooFvpxTe}\ref{ITEMooXRHDooTlrTYA}} \\
			                 & =\alpha_{X^L}(s)\alpha_{X^L}(t) & \text{prop. \ref{PROPooPEFPooFvpxTe}\ref{ITEMooKSGJooHdaZcR}} \\
			                 & =\alpha_{X^L}(s+t)              & \text{prop. \ref{PROPooWEYCooCvyHNr}}
		\end{align}
	\end{subequations}
\end{proof}

\begin{lemma}       \label{LEMooRPHVooAtZJnz}
	Let \( G\) be a Lie group with algebra \( \lG\). If \( n\in \eN\) we have
	\begin{equation}
		\exp(X)^n=\exp(nX).
	\end{equation}
\end{lemma}

\begin{proof}
	Apply \( n\) times the proposition \ref{PROPooNRVJooEDCpOI}.
\end{proof}

\begin{proposition}[\cite{MonCerveau}]	\label{PROPooFJNEooKUhJUl}
	Let \( G\) be a smooth Lie group. Let \( X_1,\ldots,X_n\in \lG\). If
	\begin{equation}
		\gamma(t)=\exp(tX_1)\ldots \exp(tX_n),
	\end{equation}
	then
	\begin{equation}
		\gamma'(0)=\sum_iX_i.
	\end{equation}
	%TODOooIZWAooHmIBux. Prouver ça.
	% C'est sans doute déjà fait, mais il faut vérifier que celles-ci ont déjà une preuve : 
	% - PROPooNRVJooEDCpOI
\end{proposition}


\begin{lemma}       \label{LEMooLMTZooCvunSl}
	Let \( G\) be a Lie group and \( X\in G\). We have
	\begin{equation}        \label{EQooNBENooPXLENs}
		X^R_g=\Dsdd{  \exp(tX)g }{t}{0}
	\end{equation}
	and
	\begin{equation}
		X^L_g=\Dsdd{  g\exp(tX) }{t}{0}
	\end{equation}
\end{lemma}


%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Invariant vector and derivation}
%---------------------------------------------------------------------------------------------------------------------------

\begin{proof}
	We prove the one about \( X^R\); the other one is similar. We have
	\begin{subequations}
		\begin{align}
			\Dsdd{ \exp(tX)g }{t}{0} & =\Dsdd{ R_g\big( \exp(tX) \big) }{t}{0}                                      \\
			                         & =(dR_g)_e\Dsdd{ \exp(tX) }{t}{0}        & \text{by \eqref{EQooVLUIooAbGZEi}} \\
			                         & =(dR_g)_eX.
		\end{align}
	\end{subequations}
\end{proof}

\begin{normaltext}      \label{NORMooSATDooIhwXXr}
	We will often write the relation \eqref{EQooNBENooPXLENs} under the form
	\begin{equation}
		X^R_g(t)= e^{tX}g.
	\end{equation}
	This is a way to implies that \( t\mapsto  e^{tX}g\) is a path for the vector \( X^R_g\). It is a common abuse of notation to write the vector and a path representing the vector with the same symbol.
\end{normaltext}


You may want to know how the exponential can be used to write some formulas linking left-invariant vector field and derivation of functions. Here you are.

\begin{normaltext}
	Let \( X\in \lG\), \( g\in G\) and \( u\in \eR\). Let \( f\colon G\to \eR\) be a smooth function. Using the abuse of notation described in \ref{NORMooSATDooIhwXXr} and the proposition \ref{PROPooNRVJooEDCpOI},
	\begin{subequations}
		\begin{align}
			(X^Lf)(g e^{uX}) & =\Dsdd{ f\big( X^L_{g e^{uX}}(t) \big) }{t}{0} \\
			                 & =\Dsdd{ f\big( g e^{uX} e^{tX} \big) }{t}{0}   \\
			                 & =\Dsdd{ f\big( g e^{(t+u)X)} \big)}{t}{0}      \\
			                 & =\Dsdd{ f(g e^{tX}) }{t}{u}.
		\end{align}
	\end{subequations}
	The formula
	\begin{equation}
		(X^Lf)(g e^{uX})=\Dsdd{ f(g e^{tX}) }{t}{u}
	\end{equation}
	means that \( X^L\) derives \( f\) in the direction of the path \(  e^{tX}\) at right.
\end{normaltext}

\begin{normaltext}
	By the way, we recall that, if \( f\) is a function and \( X\) a vector field, \( (Xf)\) is a new function, given by
	\begin{equation}
		(Xf)(a)=X_a(f).
	\end{equation}
	In that sense we can write combinations like \( XYf\) or \( (X^2+X)f\) where \( X\) and \( Y\) are vector fields.
\end{normaltext}

\begin{proposition}[\cite{BIBooPBAMooNcYhCM}]       \label{PROPooKSIDooVIFkiM}
	Let \( G\) be a Lie group with Lie algebra \( \lG\). We consider \( X,Y\in \lG\) and a smooth function \( f\colon G\to \eR\). We have\quext{My source \cite{BIBooPBAMooNcYhCM} seems to write \( (X^R)^n(Y^R)^m\) instead of \( (X^R)^n(Y^L)^m\). Let me know where I'm wrong.}
	\begin{equation}
		\big( (X^R)^n(Y^L)^mf \big)( e^{sX} e^{tY})=\frac{ d^n }{ du^n }\frac{ d^m }{ dv^m }\Big( f( e^{uX} e^{vY}) \Big)_{\substack{u=s\\v=t}}.
	\end{equation}
\end{proposition}

\begin{proof}
	We have to do a proof by induction on \( (n,m)\). We start with \( (n,m)=(0,0)\) and we prove the steps \( (n,m)\to (n+1,m)\) and \( (n,m)\to (n,m+1)\).

	\begin{subproof}
		\spitem[\( (0,0)\)]
		With \( (n,m)=(0,0)\) we are okay.
		\spitem[\( (n+1,m)\)]
		We have
		\begin{equation}
			\Big( (X^R)^{n+1}(Y^L)^mf \Big)( e^{sX} e^{tY})=\big( (X^R)(X^R)^n(Y^L)^mf \big)( e^{sX} e^{tY}).
		\end{equation}
		We will apply the induction hypothesis on the function \( (X^R)^n(Y^L)^mf\), but in a first time we just apply the vector field \( X^R\) to the function \( (X^R)^n(Y^L)^m\) and we evaluate at \(  e^{sX} e^{tY}\). Here is a couple of computations:
		\begin{subequations}
			\begin{align}
				\Big( (X^R)(X^R)^n(Y^L)^mf \Big)( e^{sX} e^{tY}) & =\Dsdd{  \Big( (X^R)^n(Y^L)^mf \Big)\big( X^R_{ e^{sX} e^{tY}}(u) \big)  }{u}{0} \\
				                                                 & =\Dsdd{  \Big( (X^R)^n(Y^L)^mf \Big)(  e^{uX} e^{sX} e^{tY} )  }{u}{0}           \\
				                                                 & =\Dsdd{  \Big( (X^R)^n(Y^L)^mf \Big)( e^{uX} e^{tY})  }{u}{s}.
			\end{align}
		\end{subequations}
		At this point we use the induction hypothesis:
		\begin{subequations}
			\begin{align}
				\Dsdd{  \Big( (X^R)^n(Y^L)^mf \Big)( e^{uX} e^{tY})  }{u}{s} & =\frac{ d }{ du }\left( \frac{ d^n }{ dw^n }\frac{ d^m }{ dv^m }\big( f( e^{wX} e^{vY}) \big)_{\substack{w=u \\v=t}}  \right)_{u=s}\\
				                                                             & =\frac{ d^{n+1} }{ dw^{n+1} }\frac{ d^m }{ dv^m }\left( f( e^{wX} e^{vY}) \right)_{\substack{w=s             \\v=t}}.
			\end{align}
		\end{subequations}
		\spitem[\( (n,m+1)\)]
		Same kind of computations.
	\end{subproof}
\end{proof}


%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Exponential as smooth diffeomorphism}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


\begin{proposition}[\cite{BIBooJOSEooGOmqoQ}]     \label{PROPooYFZZooLUOuOj}
	Let \( G\) be a smooth Lie group. There exists a neighbourhood \( U\) of \( 0\) in \( \lG\) and a neighbourhood \( V\) of \( e\) in \( G\) such that
	\begin{equation}
		\exp\colon U\to V
	\end{equation}
	is a \(  C^{\infty}\)-diffeomorphism\footnote{\( \exp\) is \(  C^{\infty}\), invertible and he inverse is \(  C^{\infty}\) as well.}.
\end{proposition}

\begin{proof}
	Proposition \ref{PROPooMIMZooAwxvkB} shows that the exponential is smooth. On the other hand, lemma \ref{LEMooHQYMooJjdKkG} says that the differential is invertible. The local inversion theorem \ref{THOooDWEXooMClWVi} makes \( \exp\) a local \(  C^{\infty}\)-diffeomorphism.
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Exponential as analytic diffeomorphism}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++


\begin{proposition}       \label{PROPooTRPRooJVAYwF}
	Let \( G\) be an analytic Lie group. The exponential map \( \exp\colon \lG\to G\) is analytic.
\end{proposition}

\begin{theorem}     \label{THOooFMFLooCnLJPr}
	Let \( G\) be an analytic Lie group. There exists a neighbourhood \( U\) of \( 0\) in \( \lG\) and a neighbourhood \( V\) of \( e\) in \( G\) such that
	\begin{equation}
		\exp\colon U\to V
	\end{equation}
	is an analytic diffeomorphism\footnote{\( \exp\) is analytic, invertible and its inverse is analytic too.}.
	% TODOooQVZJooQeMwAM Prouver ceci. 
\end{theorem}

The proof uses:
\begin{enumerate}
	\item
	      \(\exp \colon \lG\to G  \) is analytic,
	      %TODOooJFFLooUdhYCE.
	\item
	      The local inversion theorem \ref{THOooSZHVooKSEmuI}.
\end{enumerate}


%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Analytic Lie group, Taylor formula}
%---------------------------------------------------------------------------------------------------------------------------

In this subsection we study the analytic functions over an analytic Lie group.

\begin{lemma}[\cite{BIBooPBAMooNcYhCM}]     \label{LEMooPILVooHQbtAH}
	Let \( G\) be an analytic Lie group. We consider an analytic function \( f\colon G\to \eR\), an element \( X\in \lG\), a basis \( \{ X_i \}\) of \( \lG\) and \( g\in G\). There exists an absolutely converging power series \( P\) such that
	\begin{equation}
		f(g e^{x_1X_1+\ldots +x_nX_n})=P(x_1,\ldots, x_n).
	\end{equation}
\end{lemma}

\begin{proof}
	First we make the proof for \( g=e\).

	We consider a basis \( \{ e_i \}\) of \( \lG\). Let \( U\) be a neighbourhood of \( 0\) in \( \lG\) and \( V\) a neighbourhood of \( e\) in \( G\) such that \( \exp\colon U\to V\) is an analytic diffeomorphism\footnote{By theorem \ref{THOooFMFLooCnLJPr}.}.

	We consider \( U'\), the open set in \( \eR^n\) which correspond to \( U\) via the basis \( \{ e_i \}\). The map
	\begin{equation}
		\begin{aligned}
			\varphi\colon U'  & \to V                              \\
			(x_1,\ldots, x_n) & \mapsto \exp(x_1e_1+\ldots+x_ne_n)
		\end{aligned}
	\end{equation}
	is analytic chart of \( V\).

	The fact that \( f\) is analytic means that the composition of \( f\) with the charts are analytic. In our case, the map \( \tilde f =f\circ\varphi\) is analytic from \( U'\subset \eR^n\) to \( \eR\). Thus there exists an absolutely converging power series \( P\) such that
	\begin{equation}
		\tilde f(x_1,\ldots, x_n)=P(x_1,\ldots, x_n).
	\end{equation}
	We conclude:
	\begin{equation}
		f\big( \exp(x_1e_1+\ldots +x_ne_n) \big)=f\big( \varphi(x_1,\ldots, x_n) \big)=P(x_1,\ldots, x_n).
	\end{equation}

	If \( g\) is not \( e\), we consider the neighbourhood \( gV\) and the map
	\begin{equation}
		\begin{aligned}
			\varphi\colon U   & \to gV                               \\
			(x_1,\ldots, x_n) & \mapsto g\exp(x_1e_1+\ldots +x_ne_n)
		\end{aligned}
	\end{equation}
	is a chart, so that
	\begin{equation}
		f(g e^{x_1e_1+\ldots +x_ne_n})=\tilde f(x_1,\ldots, x_n)
	\end{equation}
	which is a power series.
\end{proof}

\begin{proposition}[Taylor formula\cite{BIBooPBAMooNcYhCM}]     \label{PROPooIYWQooZJtKiu}
	Let \( G\) be an analytic Lie group. We suppose that \( f\colon G\to \eR\) is an analytic functions. For \( g\in G\) and \( X\in \lG\) we have
	\begin{equation}
		f(g e^{X})=\sum_{k=0}^{\infty}\frac{1}{ n! }\big( (X^R)^nf \big)(g).
	\end{equation}
\end{proposition}

\begin{proof}
	We know from proposition \ref{LEMooPILVooHQbtAH} that \( f(g e^{X})=P(x_1,\ldots, x_n)\) for some power series \( P\). We consider a neighbourhood \( U\) of \( 0\) in \( \lG\) and \( V\) of \( g\) in \( G\) such that
	\begin{equation}
		\begin{aligned}
			\varphi\colon U & \to V           \\
			X               & \mapsto  ge^{X}
		\end{aligned}
	\end{equation}
	is an analytic diffeomorphism (i.e. an analytic chart for \( G\) around \( g\)). Let \( X\in U\) and \( \delta\) such that \( tX\in U\) for all \( t\in \mathopen] -\delta , \delta \mathclose[\). Notice that \( \delta>1\). Now, \( X\) being fixed, the value of \( P(tx_1,\ldots, tx_n)\) is an absolutely convergent power series of \( t\). We have
	\begin{equation}
		f(g e^{tX})=P(tx_1,\ldots, tx_n)=\sum_{k=0}^{\infty}\frac{ a_m }{ m! }t^m
	\end{equation}
	for some constants \( a_m\in \eR\).

	But considering the function
	\begin{equation}
		\begin{aligned}
			r\colon \eR & \to \eR              \\
			t           & \mapsto f(g e^{tX}),
		\end{aligned}
	\end{equation}
	there is an unicity of its power series expansion; thus \( a_m\) is the \( m\)-th derivative of \( r\) at \( t=0\).

	But we also know from proposition \ref{PROPooKSIDooVIFkiM} that
	\begin{equation}
		\big( (X^L)^mf \big)(g e^{tX})=\frac{ d^m }{ du^m }\big( f(g e^{uX}) \big)_{u=t};
	\end{equation}
	taking that at \( t=0\) we have
	\begin{equation}
		a_m=\big( (X^L)^mf \big)(g)
	\end{equation}
	and the Taylor formula
	\begin{equation}
		f(g e^{tX})=\sum_{k=0}^{\infty}\frac{1}{ k! }\frac{ d^k }{ du^k }\big( f(g e^{uX}) \big)_{u=0}t^m.
	\end{equation}
	Finally taking \( t=1\) (recall that \( \delta>1\), so it is valid):
	\begin{equation}
		f(g e^{X})=\sum_{k=0}^{\infty}\frac{1}{ k! }\frac{1}{ k! }\big( (X^L)^kf \big)(g).
	\end{equation}
\end{proof}

\begin{definition}[normal neighbourhood]    \label{DEFooEUTBooVqlEGM}
	Let $M$ be a differentiable manifold. If $V$ is a neighbourhood of zero in $T_pM$ on which the exponential $\dpt{\exp_p}{T_pM}{M}$ is a diffeomorphism, then $\exp_pV$ is  \defe{normal neighbourhood}{normal!neighbourhood} of $p$.
\end{definition}


\begin{lemma}       \label{LEMooWKFIooRHsrFX}
	Let \( G\) be an analytic Lie group with algebra \( \lG\). We consider a basis \( \{ e_i \}_{i=1,\ldots, n}\) of \( \lG\) and the functions
	\begin{equation}
		\begin{aligned}
			f_i\colon U                & \to \eR     \\
			\exp(x_1e_1+\ldots+x_ne_n) & \mapsto x_i
		\end{aligned}
	\end{equation}
	defined on a normal neighbourhood\footnote{Definition \ref{DEFooEUTBooVqlEGM}.} \( U\) of \( e\).

	If \( X,Y\in \lG\) satisfy
	\begin{equation}
		Xf_i=Yf_i
	\end{equation}
	for every \( i\), then \( X=Y\).
\end{lemma}

\begin{proof}
	If \( X=\sum_kX_ke_k\) we have
	\begin{equation}
		X(f_i)=\Dsdd{ f_i( e^{tX}) }{t}{0}=\Dsdd{ f_i\big(  e^{t\sum_kX_ke_k} \big) }{t}{0}=\Dsdd{ tX_i }{t}{0}=X_i.
	\end{equation}
\end{proof}

\begin{lemma}[\cite{MonCerveau}]        \label{LEMooDHXPooGOmNYT}
	Let \( G\) be a Lie group. Let smooth paths \( \gamma\colon \eR\to G\) and \( \sigma\colon \eR\to G\) satisfying \( \gamma(0)=\sigma(0)=e\). If \( \nabla_{\gamma}=\nabla_{\sigma}\), then there exists a smooth map \( \alpha\colon \eR\to G \) such that
	\begin{subequations}
		\begin{numcases}{}
			\sigma(t)=\alpha(t)\gamma(t)\\
			\alpha(0)=e\\
			\alpha'(0)=0
		\end{numcases}
	\end{subequations}
\end{lemma}


\begin{lemma}[\cite{MonCerveau}]        \label{LEMooGMMNooVlDkNm}
	Let \( G\) be an analytic Lie group with Lie algebra \( \lG\). Let \( X,Y\in \lG\).
	\begin{enumerate}
		\item
		      We have the formula
		      \begin{equation}        \label{EQooDCUJooYDDZHD}
			      [X,Y]=\Dsdd{ \exp\big( \sqrt{ t }X \big)\exp\big( \sqrt{ t }Y \big)\exp\big( -\sqrt{ t }X \big)\exp\big( -\sqrt{ t }Y \big) }{t}{0},
		      \end{equation}
		\item
		      There exists a smooth map \( \alpha\colon \eR\to G\) such that \( \alpha(0)=e\), \( \alpha'(0)=0\) and
		      \begin{equation}
			      \exp\big( t[X,Y] \big)=\alpha(t)\exp\big( \sqrt{ t }X \big)\exp\big( \sqrt{ t }Y \big)\exp(-\sqrt{ t }X)\exp(-\sqrt{ t }Y)
		      \end{equation}
		      % Utiliser le lemme LEMooDHXPooGOmNYT
	\end{enumerate}
	% En vérité je suis quasiment certain que ce résultat est déjà quelque part.
\end{lemma}

\begin{lemma}[\cite{BIBooPBAMooNcYhCM}]     \label{LEMooMJBRooMOuJpa}
	Let \( G\) be an analytic Lie group with Lie algebra \( \lG\). For \( X,Y\in \lG\) we have:
	\begin{enumerate}
		\item       \label{ITEMooHVOIooKDrUSw}
		      \( \exp(tX)\exp(tY)=\exp\big( t(X+Y)+\frac{ t^2 }{2}[X,Y]+t^2\alpha(t) \big)\),
		\item       \label{ITEMooWIQIooHphJcP}
		      \( \exp\big( t(X+Y) \big)=\exp(tX)\exp(tY)\exp(t\alpha(t))\)
	\end{enumerate}
	In both formulas, \( \alpha\) is a function \( \alpha\colon \eR\to \lG\) satisfying \( \lim_{t\to 0} \alpha(t)=0\).
\end{lemma}

\begin{proof}
	Several steps.
	\begin{subproof}
		\spitem[A good function]

		Let \( \{ e_i \}_{i=1,\ldots, n}\) be a basis of \( \lG\). We consider a neighbourhood \( U\) of \( 0\) in \( \lG\) and \( V\) of \( e\) in \( G\) such that \( \exp\colon U\to V\) is an analytic diffeomorphism. On that \( U\) we consider the function
		\begin{equation}
			\begin{aligned}
				f\colon U                   & \to \eR     \\
				\exp(x_1e_1+\ldots +x_ne_n) & \mapsto x_i
			\end{aligned}
		\end{equation}
		for some fixed \( i\). This function is analytic and satisfies \( f(e)=0\).
		\spitem[Some Taylor expansions]
		Using proposition \ref{PROPooKSIDooVIFkiM} we have
		\begin{equation}
			\big( (X^R)^n(X^L)^mf \big)( e^{sX} e^{tY})=\frac{ d^n }{ du^n }\frac{ d^m }{ dv^m }\big( f( e^{uX} e^{vY}) \big)_{\substack{u=s\\v=t}}.
		\end{equation}
		Considering the function \( q(s,t)=f( e^{sX} e^{tY})\), we have the Taylor expansion
		\begin{equation}        \label{EQooNBOIooRxlZmP}
			f( e^{sX} e^{tY})=q(s,t)=\sum_{m,n\geq 0}\frac{ s^n }{ n! }\frac{ t^m }{ m! }\big( (X^R)^n(Y^L)^mf \big)(e)=\sum_{m,n\geq 0}\frac{ s^n }{ n! }\frac{ t^m }{ m! }\big( X^nY^mf \big)(e).
		\end{equation}
		Here the second equality is due to the fact that \( (X^Lf)(e)=(X^Rf)(e)=X(f)\).

		\spitem[The function \( Z\)]

		On the other hand, when \( t\) is small enough, the element \(  e^{tX} e^{tY}\) belongs to a normal neighbourhood of \( e\), so that there exists an element \( Z(t)\in \lG\) satisfying
		\begin{equation}
			e^{tX} e^{tY}= e^{Z(t)}.
		\end{equation}
		The element \( Z(t)\) is given by
		\begin{equation}
			Z(t)=\exp^{-1}\big(  e^{tX} e^{tY} \big).
		\end{equation}
		Since the exponential is an analytic diffeomorphism\footnote{Theorem \ref{THOooFMFLooCnLJPr}.} (the inverse is analytic), \( Z\) is an analytic function around \( t=0\). Thus there exists a function \( \alpha\colon \eR\to \lG\) such that
		\begin{equation}        \label{EQooRPGGooXtZzFy}
			Z(t)=tZ_1+t^2Z_2+t^2\alpha(t)
		\end{equation}
		and \( \lim_{t\to 0} \alpha(t)=0\). Notice that \( Z(0)=0\), which explain the absence of constant term in \eqref{EQooRPGGooXtZzFy}.

		\spitem[A formula for \( f\big(  e^{Z(t)} \big)\)]

		We pose \( Z_1=\sum_ka_{1k}e_k\), \( Z_2=\sum_ka_{2k}e_k\) and \( \alpha(t)=\sum_k\sigma_k(t)e_k\), so that
		\begin{equation}
			Z(t)=\sum_k\big( ta_{1k}+t^2a_{2k}+t^2\alpha_k(t) \big)e_k.
		\end{equation}
		Applying \( f\) we have
		\begin{equation}
			f\big(  e^{Z(t)} \big)=ta_{1i}+t^2a_{2i}+t^2\alpha_i(t)=f\big(  e^{tZ_1+t^2Z_2} \big)+t^2\alpha_i(t).
		\end{equation}

		\spitem[Some more Taylor expansions]

		We use the Taylor expansion of proposition \ref{PROPooIYWQooZJtKiu} with \( g=e\) and \( X=Z(t)\):
		\begin{equation}        \label{EQooSFKOooDAavVy}
			f( e^{Z(t)})=\sum_k\frac{1}{ k! }\big( [tZ^L_1+t^2Z_2^L]^kf \big)(e)+t^2\alpha_i(t).
		\end{equation}
		Once again we can drop the \( L\) exponent since \( (X^Lf)(e)=X(f)\). We collect out of \eqref{EQooSFKOooDAavVy} the terms with \( t\) and \( t^2\):
		\begin{equation}        \label{EQooEYUSooTDntym}
			f( e^{tX} e^{tY})=f( e^{Z(t)})=tZ_1(f)+t^2 Z_2 +\frac{ t^2 }{2}Z_1^2 +t^2\beta(t)
		\end{equation}
		with \( \lim_{t\to 0} \beta(t)=0\).

		\spitem[Comparison]

		The formulas \eqref{EQooNBOIooRxlZmP} with \( s=t\) and \eqref{EQooEYUSooTDntym} are Taylor expansions of the same quantity. They are equal; we copy them here:
		\begin{equation}
			\sum_{m,n}\frac{ t^{m+n} }{ m!n! }\big( (X^R)^n(Y^L)^mf \big)(e)=tZ_1(f)+t^2 Z_2 +\frac{ t^2 }{2}Z_1^2 +t^2\beta(t)
		\end{equation}
		On the left hand side, the terms with \( t\) and \( t^2\) are obtained when \( (n,m)\) is among the possibilities $(0,1)$, $(1,0)$, $(2,0)$, $(0,2)$, and $(1,1)$. Collecting we have on the left
		\begin{equation}
			(X+Y)f+XYf+\frac{ 1 }{2}X^2f+\frac{ 1 }{2}Y^2f
		\end{equation}
		where we used the fact that \( \big( (X^R)^2f \big)(e)=X(Xf)=X^2f\).

		Using lemma \ref{LEMooWKFIooRHsrFX} we have \( Z_1f=(X+Y)f\), so that \( Z_1=X+Y\) and then
		\begin{equation}
			\frac{ 1 }{2}[X,Y]=Z_2.
		\end{equation}
	\end{subproof}
	At this point we proved that
	\begin{equation}
		e^{tX} e^{tY}= e^{t(X+Y)+\frac{ t^2 }{2}[X,Y]+t^2\alpha(t)}.
	\end{equation}
	This is \ref{ITEMooHVOIooKDrUSw}.

	For point \ref{ITEMooWIQIooHphJcP}, we are searching for a function \( \beta\) such that
	\begin{equation}
		e^{tX} e^{tY} e^{t\beta(t)}= e^{t(X+Y)}.
	\end{equation}
	We replace in the left-hand side the value of \(  e^{tX} e^{tY}\) given by the point \ref{ITEMooHVOIooKDrUSw} (this is the reason why we write \( \beta\) instead of \( \alpha\)) and we isolate \(  e^{t\beta(t)}\):
	\begin{equation}        \label{EQooLTMBooVIChyC}
		e^{t\beta(t)}= e^{t(X+Y)} e^{-t(X+Y)-t^2[X,Y]/2-t^2\alpha(t)}.
	\end{equation}
	So now our aim is to show that the right-hand side of \eqref{EQooLTMBooVIChyC} can be written as only one exponential with an argument of the form \( t\beta(t)\) satisfying \( \beta(t)\to 0\). For that, we use \ref{ITEMooHVOIooKDrUSw} once again with \( X+Y\) instead of \( X\) and \( -(X+Y)-t[X,Y]/2-t\alpha(t)\) instead of \( Y\). What we get is
	\begin{subequations}
		\begin{align}
			e^{t\beta(t)} & =\exp\big( t(-t[X,Y]/3-t\alpha(t))+\frac{ t^2 }{2}\big[ X+Y,-(X+Y)-t[X,Y]/2-t\alpha(t) \big] \big)                        \\
			              & =\exp\big( -\frac{ t^2 }{2}[X,Y]  -t^2\alpha(t)-\frac{ t^3 }{ 4 }\big[ X+Y,[X,Y] \big]-\frac{ t^3 }{ 2 }\alpha(t)  \big).
		\end{align}
	\end{subequations}
	We are done with \ref{ITEMooWIQIooHphJcP}.
\end{proof}


%-------------------------------------------------------
\subsection{Product of Lie group and its Lie algebra}
%----------------------------------------------------

\begin{lemma}[\cite{MonCerveau}]	\label{LEMooTNXEooUBpJFv}
	The vector space isomorphism
	\begin{equation}
		\mu \colon T_{(e,e)}(G\times H)\to T_eG\times T_eH=\lG\times \lH.
	\end{equation}
	of proposition \ref{PROPooPSELooDDwFru} satisfy
	\begin{equation}		\label{EQooOLTGooPIczEJ}
		\exp\big( \mu^{-1}(X,Y) \big)=\big( \exp(X),\exp(Y) \big).
	\end{equation}
\end{lemma}

\begin{proof}
	We let
	\begin{equation}
		\begin{aligned}
			\phi\colon \eR & \to G\times H                         \\
			t              & \mapsto \big( \exp(tX),\exp(tY) \big)
		\end{aligned}
	\end{equation}
	and we prove that this is the integral curve of \( \mu^{-1}(X,Y)\). More precisely we prove that
	\begin{equation}
		\phi(t)=\Phi_e^{\mu^{-1}(X,Y)^L}(t)
	\end{equation}
	where \( \Phi\) is defined in \ref{PROPooJACTooXBSxfE}. For that we check the two conditions :
	\begin{enumerate}
		\item
		      \( \phi(0)=(e,e)\) (the neutral in \( G\times H\)),
		\item
		      \( \frac{d}{dt} \left[ \phi(t)  \right]_{t=t_0}=\mu^{-1}(X,Y)^L_{\phi(t_0)}\).
	\end{enumerate}
	The first condition is immediate. The second one is more fun. We have :
	\begin{subequations}	\label{EQooNEUVooIzLeWx}
		\begin{align}
			\frac{d}{dt} \left[ \phi(t)  \right]_{t=t_0} & =\frac{d}{dt} \left[ \big( \exp(tX),\exp(tY) \big)  \right]_{t=t_0}                                                                        \\
			                                             & =\frac{d}{dt} \left[ \exp\big( (t+t_0)X \big),\exp\big( (t+t_0)Y \big)  \right]_{t=0}                                                      \\
			                                             & =\frac{d}{dt} \left[ \exp(t_0X)\exp(tX),\exp(t_0Y)\exp(tY)  \right]_{t=0}                          & \text{prop. \ref{PROPooNRVJooEDCpOI}} \\
			                                             & =\frac{d}{dt} \left[ \big( \exp(t_0X),\exp(t_0Y) \big)\big( \exp(tX),\exp(tY) \big)  \right]_{t=0}                                         \\
			                                             & =\frac{d}{dt} \left[ \phi(t_0)\phi(t)  \right]_{t=0}                                                                                       \\
			                                             & =dL_{\phi(t_0)}\frac{d}{dt} \left[ \phi(t)  \right]_{t=0}.
		\end{align}
	\end{subequations}

	Let \( \gamma_1(t)=\exp(tX)\), \( \gamma_2(t)=\exp(tY)\). We have \( \nabla_{\phi}=\mu^{-1}(\nabla_{\gamma_1},\nabla_{\gamma_2})\). But \( \nabla_{\gamma_1}=X\) and \( \nabla_{\gamma_2}=Y\), so that
	\begin{equation}
		\frac{d}{dt} \left[ \phi(t)  \right]_{t=0}=\mu^{-1}(X,Y).
	\end{equation}
	We continue the equalities \eqref{EQooNEUVooIzLeWx} :
	\begin{equation}
		\frac{d}{dt} \left[ \phi(t)  \right]_{t=t_0}=dL_{\phi(t_0)}\mu^{-1}(X,Y)=\mu^{-1}(X,Y)^{L}_{\phi(t_0)}.
	\end{equation}
	It is now proven that \( \phi(t)=\Phi_e^{\mu^{-1}(X,Y)^L}(t)\). Now the definition \eqref{EqdefExpoLieTgFGp} of the exponential reads
	\begin{equation}
		\phi(1)=\exp\big( \mu^{-1}(X,Y) \big),
	\end{equation}
	which is exactly \eqref{PROPooPSELooDDwFru}.
\end{proof}

\begin{proposition}[\cite{MonCerveau}]	  \label{PROPooFWGKooFgUZMZ}
	Let \( G\) and \( H \) be smooth Lie groups with Lie algebras \( \lG\) and \( \lH\). The Lie algebra\footnote{The Lie algebra of a Lie group is its tangent space at the neutral, definition \ref{DEFooKDCPooZOJsMD}. The group \( G\times H\) is a Lie group by proposition \ref{PROPooKITOooTcsIiu}.} of \( G\times H\) is isomorphic to \( \lG\oplus\lH\)\footnote{The Lie algebra structure on \( \lG\times \lH\) is defined in \ref{DEFooNBHXooMZdXGt}.}.
\end{proposition}

\begin{proof}

	We divide in few parts.
	\begin{subproof}

		\spitem[Some manipulations with \( \mu\)]
		%-----------------------------------------------------------

		We prove that \( \mu\) is a Lie algebra isomorphism. We denote by \( \gamma_{X,Y}\) the path of lemma \ref{LEMooGMMNooVlDkNm}:
		\begin{equation}		\label{EQooZGXEooGPqpMf}
			\gamma_{X,Y}(t)=\exp(\sqrt{ t }X)\exp(\sqrt{t}Y)\exp(-\sqrt{ t }X)\exp(-\sqrt{ t }Y).
		\end{equation}
		It satisfies \( [X,Y]=\nabla_{\gamma_{X,Y}}\).

		Let \( X=\mu^{-1}(X_1,X_2)\). Using lemma \ref{LEMooTNXEooUBpJFv} we have
		\begin{subequations}
			\begin{align}
				\exp(\sqrt{t}X) & =\exp\big( \mu^{-1}\big( \sqrt{t}X_1,\sqrt{t}X_2 \big) \big) \\
				                & =\big( \exp(\sqrt{t}X_1),\exp(\sqrt{t}X_2) \big).
			\end{align}
		\end{subequations}
		Computing the products of \eqref{EQooZGXEooGPqpMf} we get
		\begin{equation}
			\gamma_{\mu^{-1}(X_1,X_2),\mu^{-1}(Y_1,Y_2)}=\big( \gamma_{X_1,Y_1},\gamma_{X_2,Y_2} \big).
		\end{equation}
		In other words,
		\begin{equation}		\label{EQooBKMHooCYBLlA}
			\big[  \mu^{-1}(X_1,X_2),\mu^{-1}(Y_1,Y_2)  \big]=\nabla_{\sigma}
		\end{equation}
		where
		\begin{equation}
			\sigma(t)=\big( \gamma_{X_1,Y_1}(t),\gamma_{X_2,Y_2}(t) \big),
		\end{equation}
		and then, taking \( \mu\) of both sides of \eqref{EQooBKMHooCYBLlA} :
		\begin{equation}		\label{EQooSETHooGusRwa}
			\mu\big[  \mu^{-1}(X_1,X_2),\mu^{-1}(Y_1,Y_2)  \big]=\big( \nabla_{\gamma_{X_1,Y_1}},\nabla_{\gamma_{X_2,Y_2}} \big)=\big( [X_1,Y_1],[X_2,Y_2] \big).
		\end{equation}

		\spitem[Lie algebra isomorphism]
		%-----------------------------------------------------------

		Now we prove that \( \mu\) is a Lie algebra isomorphism. Let \( A,B\in T_{(e,e)}(G\times H)\). There exists \( X_1,Y_1\in T_eG\) and \( X_2,Y_2\in T_eH\) such that \( A=\mu^{-1}(X_1,X_2)\) and \( B=\mu^{-1}(Y_1,Y_2)\).

		We have
		\begin{subequations}
			\begin{align}
				\mu[A,B] & =\mu\big[   \mu^{-1}(X_1,X_2),\mu^{-1}(Y_1,Y_2) \big]                                       \\
				         & = \big( [X_1,Y_1],[X_2,Y_2] \big)                     & \text{eq. \eqref{EQooSETHooGusRwa}} \\
				         & = \big[  (X_1,X_2),(Y_1,Y_2) \big]                                                          \\
				         & =\big[  \mu(A),\mu(B) \big],
			\end{align}
		\end{subequations}
		which shows that \( \mu\) is a Lie algebra morphism. Since we know that \( \mu\) is a bijection, it is an isomorphism.
	\end{subproof}
\end{proof}
