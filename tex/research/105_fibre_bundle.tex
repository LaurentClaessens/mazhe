% This is part of (almost) Everything I know in mathematics
% Copyright (c) 2013-2014, 2020, 2023-2024
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.

\section{Vector bundle}
%++++++++++++++++++++++

\begin{definition}[\cite{MonCerveau,BIBooZBHSooLbtepQ}]		\label{DEFooFRPLooTxMUzg}
	Let \( M\) be a smooth manifold with charts \( \{ \varphi_{\alpha} \colon I_{\alpha}\to M   \}_{\alpha\in \tau}\). A \( k\)-dimensional \defe{vector bundle}{vector bundle} on \( M\) is the given of
	\begin{enumerate}
		\item		\label{ITEMooIVKKooNEfxVi}
		      A vector space \( V_x\) for each \( x\in M\).

		      Formally, we suppose that the vector space \( V_x\) has the form \( V_x=\{ (x,v)\tq v\in W_x \}\) for some vector space \( W_x\). The reason is that we want the union \( E=\bigcup_{x\in M}V_x\) to be disjoint.
		\item
		      For each chart \(\varphi_{\alpha} \colon U_{\alpha}\to M  \), a map
		      \begin{equation}
			      \sigma_{\alpha} \colon U_{\alpha}\times \eR^k\to \bigcup_{x\in \varphi_{\alpha}(U_{\alpha})}V_x.
		      \end{equation}
	\end{enumerate}

	With the following conditions.
	\begin{enumerate}[label=(\alph*)]
		\item	\label{ITEMooVIYBooMXFaKb}
		      The maps \( \sigma_{\alpha}\) give a manifold structure on \( E\).
		\item	\label{ITEMooXHOBooERubro}
		      The projection
		      \begin{equation}
			      \begin{aligned}
				      \pi\colon E & \to M     \\
				      (x,v)       & \mapsto x
			      \end{aligned}
		      \end{equation}
		      is smooth for the differential structure of \( E\) given by the atlas \( \{ \sigma_{\alpha} \}_{\alpha\in\tau}\).
		\item		\label{ITEMooXJIVooVJTorK}
		      For every \( s\in U_{\alpha}\) and \( v\in \eR^k\) we have \( \sigma_{\alpha}(s,v)\in V_{\varphi_{\alpha}(s)}\).
		\item \label{ITEMooOBCMooOCqoQo}
		      For each \( s\in U_{\alpha}\), the map
		      \begin{equation}
			      \begin{aligned}
				      \tau_{\alpha,s}\colon \eR^k & \to V_{\varphi_{\alpha}(s)}  \\
				      v                           & \mapsto \sigma_{\alpha}(s,v)
			      \end{aligned}
		      \end{equation}
		      is a vector space isomorphism (linear bijection).
		\item		\label{ITEMooPNLXooLQWGqc}
		      The map \(g_{\alpha\beta} \colon U_{\alpha}\cap U_{\beta}\to \Fun(\eR^k,\eR^k)  \) defined by
		      \begin{equation}
			      (\sigma_{\alpha}^{-1}\circ \sigma_{\beta})(s,v)=\big( s,g_{\alpha\beta}(s)v \big)
		      \end{equation}
		      belongs to \( C^{\infty}\big( U_{\alpha}\cap U_{\beta},\GL(\eR,k) \big)\).
	\end{enumerate}
	Most of the time, we will denote the whole vector bundle only by the couple \( (E,\pi)\).

	The maps \( g_{\alpha\beta}\) are the \defe{transition functions}{transition function}.
\end{definition}

\begin{definition}		\label{DEFooDSKKooEFgmPU}
	Let \( E_1\), \( E_2\) be two vector bundles over the same manifold \( M\). A map \(f \colon E_1\to E_2  \) is a \defe{vector bundle isomorphism}{vector bundle isomorphism} if
	\begin{enumerate}
		\item
		      \( f\) is a manifold smooth diffeomorphism.
		\item
		      \( \pi_1\circ f=\pi_2\)
		\item
		      \( f\big( \pi_1^{-1}(x) \big)=\pi_2^{-1}(x)\) for every \( x\in M\).
		\item
		      The restriction \(f \colon \pi_1^{-1}(x)\to \pi_2^{-1}(x)   \) is a vector space isomorphism.
	\end{enumerate}
\end{definition}


\begin{proposition}		\label{PROPooJZLEooYFgjnY}
	Let \( V\) be a \( k\)-dimensional vector space. Let \(f \colon \eR^k\to V  \) be an isomorphism and \( M\), a manifold. We define
	\begin{equation}
		V_x=\{ (x,v)\tq v\in V \}
	\end{equation}
	and
	\begin{equation}
		\begin{aligned}
			\sigma_{\alpha}\colon U_{\alpha}\times \eR^k & \to \bigcup_{x\in \varphi_{\alpha}(U_{\alpha})} \\
			(s,v)                                        & \mapsto \big( \varphi_{\alpha}(s),f(v) \big).
		\end{aligned}
	\end{equation}
	We have:
	\begin{enumerate}
		\item		\label{ITEMooYHUVooXUSryK}
		      This is a vector bundle structure.
		\item		\label{ITEMooCZLRooIJjQUn}
		      If \( f\) and \( g\) are two isomorphisms between \( \eR^k\) and \( V\), the corresponding vector bundle are isomorphic\footnote{Definition \ref{DEFooDSKKooEFgmPU}}.
	\end{enumerate}
\end{proposition}

\begin{proof}
	For \ref{ITEMooYHUVooXUSryK}, this is a long verification\quext{Make it, write it and send me your proof, so that I can add it here.}.
	%TODOooNKRPooHQgEtj

	We prove \ref{ITEMooCZLRooIJjQUn}. We name \( E_1\) the vector bundle created by \( f\) and \( E_2\) the one created by \( g\). We define
	\begin{equation}
		\begin{aligned}
			h\colon E_1 & \to E_2                                   \\
			(x,v)       & \mapsto \big( x,(f\circ g^{-1})(v) \big).
		\end{aligned}
	\end{equation}
	It satisfies \( \pi_1\circ h=\pi_2\) because \( \pi_i(x,v)=x\) for every \( v\). The map \( h\) is a bijection because \( f\) and \( g\) are bijections. Since \( f\) and \( g\) are linear, the restriction map \(h \colon V_x\to V_x  \) is a vector space isomorphism.

	We prove that \( h\) is a manifold isomorphism: \( h\) and \( h^{-1}\) have to be smooth.
	\begin{subproof}
		\spitem[\( h\) is smooth]
		%-----------------------------------------------------------
		In order to say that \(h \colon E_1\to E_2  \) is smooth, we have to check that
		\begin{equation}
			\sigma_{f,\alpha}^{-1}\circ h\circ \sigma_{g,\beta} \colon  U_{\alpha}\cap U_{\beta}\times \eR^k  \to U_{\alpha}\cap U_{\beta}\times \eR^k
		\end{equation}
		is smooth. We have
		\begin{subequations}
			\begin{align}
				\sigma_{f,\alpha}^{-1}\circ h\circ\sigma_{g,\beta}(s,v) & = (\sigma_{f,\alpha}\circ h)\big( \varphi_{\beta}(s),g(v) \big)                       \\
				                                                        & =\sigma_{f,\alpha}^{-1}\Big( \varphi_{\beta}(s),(f\circ g^{-1})\big( g(v) \big) \Big) \\
				                                                        & =\sigma_{f,\alpha}^{-1}\big( \varphi_{\beta}(s),f(v) \big)                            \\
				                                                        & = \big( (\varphi_{\alpha}^{-1}\circ \varphi_{\beta})(s),v \big).
			\end{align}
		\end{subequations}
		The last expression is smooth with respect to \( (s,v)\).
		\spitem[\( h^{-1}\) is smooth]
		%-----------------------------------------------------------
		The verification is the same for \( \sigma_{g,\alpha}^{-1}\circ h^{-1}\circ\sigma_{g,\beta}\).
	\end{subproof}
\end{proof}

\subsection{Transition functions}
%--------------------------------

\begin{proposition}
	Let \( (E,\pi)\) be a vector bundle. The transition functions satisfy
	\begin{equation}\label{eq:g_compat}
		g_{\alpha\beta}\circ g_{\alpha\gamma}\circ g_{\gamma\alpha}=\mtu.
	\end{equation}
\end{proposition}

\subsection{Inverse construction}\label{subsec:inv_g}
%-------------------------------------------

Let us consider a manifold $M$, an open covering $\{\mU_{\alpha}:\alpha\in I\}$ and some functions $\dpt{g\bab}{\mU\bab}{GL(r,\eK)}$ which fulfill relations \eqref{eq:g_compat}. We will build a vector bundle $E\stackrel{p}{\longrightarrow}M$ whose transition functions are the $g_{\alpha\beta}$'s. Let $\tilde{E}$ be the disjoint union
\[
	\tilde{E}=\bigsqcup_{\alpha\in I}\mU_{\alpha}\times\eK^r,
\]
i.e. triples of the form $(x,v,\alpha)\in M\times\eK^r\times I$ with the condition that $x\in\mU_{\alpha}$. We define an equivalence relation on $\tilde{E}$ by $(x,v,\alpha)\sim(y,w,\beta)$ if and only if $x=y$ and $w=g\bab(x)v$. Next, we define $E=\tilde{E}/\sim$ and $\dpt{\omega}{\tilde{E}}{E}$, the canonical projection. The projection $\dpt{p}{E}{M}$ is naturally defined by $p([x,v,\alpha])=x$. The chart diffeomorphism is $\dpt{\varphi_{\alpha}}{\mU_{\alpha}\times\eK^r}{p^{-1}(\mU_{\alpha})}$,
\[
	\varphi_{\alpha}(x,v)=\omega(x,v,\alpha).
\]
Now we have to prove that $E$ endowed with the $\varphi_{\alpha}$'s is a vector bundle.

First we prove that $\varphi_{\alpha}$ is surjective. For this we remark that a general element in $p^{-1}(\mU_{\alpha})$ can be written under the form $\omega(x,v,\alpha)$ with $x\in\mU\bab$. But
\begin{equation}
	\begin{split}
		\varphi_{\alpha}(x,g\bab(x)w)&=\omega(x,g\bab(x)w,\alpha)\\
		&=\omega(x,g_{\alpha\beta}(x)g\bab(x)w,\beta)\\
		&=\omega(x,w\beta),
	\end{split}
\end{equation}
then $\varphi_{\alpha}$ is surjective. Now we suppose $\varphi_{\alpha}(x,v)=\varphi_{\alpha}(y,w)$. Then $\omega(x,v,\alpha)=\omega(y,w,\alpha)$ and $x=y$, $w=g_{\alpha\alpha}v$ which immediately gives $v=w$. Then $\varphi_{\alpha}$ is injective.

Finally, we have
\begin{equation}
	(\varphi\alpha\circ\varphi_{\beta}^{-1})(\omega(x,v,\alpha))=\varphi_{\alpha}(x,g_{\alpha\beta}(x)v)
	=\omega(x,g_{\alpha\beta}(x)v,\alpha),
\end{equation}
which proves that the maps $g$ are the transition functions of the vector bundle $E$.

\subsection{Equivalence of vector bundle}
%----------------------------------------

Let $E\stackrel{p}{\longrightarrow}M$ and $F\stackrel{p'}{\longrightarrow}M$ be two vector bundles on $M$. They are \defe{equivalent}{equivalence!of vector bundle} if there exists a smooth diffeomorphism $\dpt{f}{E}{F}$ such that

\begin{itemize}
	\item $p'\circ f=p$,
	\item $\dpt{f|_{E_x}}{E_x}{F_x}$ is a vector space isomorphism.
\end{itemize}

Let $E$ and $F$ be two equivalent vector bundles, $\{\mU_{\alpha}\tq \alpha\in I\}$, an open covering which trivialize $E$ and $F$ in the same time and $\phi^E_{\alpha}$, $\phi^F_{\alpha}$ the corresponding trivializations. A map $\dpt{f}{E}{F}$ reads ``in the trivialization''\ as $\dpt{\phi^F_{\alpha}\circ f|_{p^{-1}(\mu_{\alpha})}\circ\phi^E{}^{-1}_{\alpha}}{\mU_{\alpha}\times\eK^r}{\mU_{\alpha}\times\eK^r}$ and defines a map $\dpt{\lambda_{\alpha}}{\mU_{\alpha}}{GL(r,\eK)}$ by
\begin{equation}
	(\phi^F_{\alpha}\circ f|_{p^{-1}(\mu_{\alpha})}\circ\phi^E{}^{-1}_{\alpha})(x,v)=(x,\lambda_{\alpha}(x)v).
\end{equation}
If we denote by $g^E$ the transition functions for $E$ (and $g^F$ for $F$),
\[
	\phi^F_{\alpha}\circ\phi^F_{\beta}{}^{-1}= (\phi^F_{\alpha}\circ f\circ\phi_{\alpha}^E{}^{-1})\circ
	(\phi^E_{\alpha}\circ\phi^E_{\beta}{}^{-1})\circ
	(\phi^E_{\beta}\circ f^{-1}\circ\phi_{\beta}^E{}^{-1}),
\]
so that
\begin{equation}\label{eq:g_l_g_l}
	g\bab^F(x)=\lambda_{\alpha}(x) g^E\bab(x)\lambda(x)^{-1}.
\end{equation}

Once again we have an inverse construction. We consider a vector bundle $E$ on $M$ with transition functions $g^E$ and some maps $\dpt{\lambda_{\alpha}}{\mU_{\alpha}}{GL(r,\eK)}$; then we define $g^F\bab(x)$ by equation \eqref{eq:g_l_g_l}.

From subsection~\ref{subsec:inv_g}, one can construct a vector bundle $F$ on $M$ whose transition functions are these $g^F$. With the trivializations $\phi^F$ of $F$, one can define $\dpt{f}{E}{F}$ by
\[
	(\phi^F_{\alpha}\circ f\circ\phi^E_{\alpha}{}^{-1})(x,v)=(x,\lambda_{\alpha}(x)v).
\]

When a basis space $B$ is given, we denote by $\Vect(B)$ the set of isomorphism classes of vector bundles over $B$. In the complex case, we denote it by $\Vect_{\eC}(B)$.

\begin{proposition}
	Any vector bundle over $\eR^n$ is trivial.
\end{proposition}

\begin{proof}
	Let $\dpt{p}{F}{M}$ be a vector bundle on $M=\eR^n$ and $\{\mU_{\alpha}\}$ be covering of $\eR^n$ by local trivializations. Now consider a partition of unity\index{partition of unity} related to the covering $\mU_{\alpha}$: a set of functions $\dpt{f_{\alpha}}{M}{\eR}$ such that
	\begin{itemize}
		\item $f_{\alpha}>0$,
		\item $\forall x\in M$, one can find a neighbourhood of $x$ in which only a \emph{finite} number of $f_{\alpha}$ is non zero,
		\item $\forall x\in M$, $\sum_{\alpha} f_{\alpha}(x)=1$.
		\item $f_{\alpha}=0$ outside of $\mU_{\alpha}$.
	\end{itemize}
	Using that partition of unity, we build the trivialization function $\dpt{f}{F}{\eR^n\times V}$ by $f(l)=(x,\sum_{\alpha} f_{\alpha}(x)\phi_{\alpha x}(l))$.
\end{proof}

The following two propositions have some importance in K-theory.
\begin{proposition}		\label{PropEoplusEprimetriv}
	Let $\pi\colon E\to B$ be a complex vector bundle over a basis compact, Hausdorff, connected basis $B$. Then there exists a vector bundle $E'$ such that $E\oplus E'$ is trivial.
\end{proposition}

\begin{proposition}		\label{PropmapfEEsun}
	Let $f\colon A\to B$ be a map between the topological spaces $A$ and $B$, and consider a vector bundle $\pi\colon E\to B$. Then there exists one and only one vector bundle $\pi'\colon E'\to A$ and a map $f'\colon E'\to E$ such that $f'|_{E'_x}\colon E'_x\to E_{f(x)}$ is an isomorphism. The vector bundle $E'$ is unique up to isomorphism.
\end{proposition}
Proofs can be found in \cite{VB_and_K}. Let us denote by $f^*(E)$ the function given by proposition~\ref{PropmapfEEsun}. It satisfies the following properties
\begin{equation}		\label{EqPropfstarEVect}
	\begin{split}
		(fg)^*(E)		&=g^*\big( f^*(E) \big)\\
		\id^*(E)		&=E\\
		f^*(E_1\oplus E_2)	&=f^*(E_1)\oplus f^*(E_2)\\
		f^*(E_1\otimes E_2)	&=f^*(E_1)\otimes f^*(E_2).
	\end{split}
\end{equation}



\subsection{Sections of vector bundle}
%-------------------------------------

\begin{definition}		\label{DEFooULPGooZeVheH}
	A \defe{section}{section!of vector bundle} of the vector bundle $p\colon E\to M$ is a smooth map $\dpt{s}{M}{E}$ such that $p\circ s=\id|_M$. The set of all the sections is denoted by $\Gamma^{\infty}(M)$ or simply $\Gamma(E)$.\nomenclature{$\Gamma(E)$}{Space of sections of the vector bundle $E$}
\end{definition}

\begin{proposition}		\label{PROPooMCJWooNAqmIQ}
	Let \( E= \big(  \{ V_x \}_{x\in M},  \{ \sigma_{\alpha} \}  \big)\) be a vector bundle. We consider a set of sections \(e_i \colon M\to E  \) such that for each \( x\in M\), the set \( \{ e_i(x) \}\) is a basis of \( V_x\).

	For every \( v\in \Gamma^{\infty}(E)\), there exist smooth functions \( v_i\in C^{\infty}(M)\) such that
	\begin{equation}
		v(x)=\sum_iv_i(x)e_i(x)
	\end{equation}
	for every \( x\in M\).
\end{proposition}

If $(\mU_{\alpha},\phi_{\alpha})$ is a local trivialization, one can describe the section $s$ by a function $\dpt{s_{\alpha}}{\mU_{\alpha}}{V}$ defined by $\phi_{\alpha}(s(x))=(x,s_{\alpha}(x))$, or equivalently by
\[
	s(x)=\phi_{\alpha}^{-1}(x,s_{\alpha}(x)).
\]
As usual when we define such a local quantity, we have to ask ourself how are related $s_{\alpha}$ and $s_{\beta}$ on $\mU_{\alpha}\cap\mU_{\beta}$. The best is $s_{\alpha}=s_{\beta}$, but most of the time it is not. Here, we compute
\[
	\phi_{\beta}\circ\phi_{\alpha}^{-1}\circ\phi_{\alpha}(s(s))=(x,g_{\alpha\beta}(x)s_{\alpha}(x)),
\]
which is obviously also equal to $(x,s_{\beta}(x))$. Then
\begin{equation}\label{eq:tr_sec}
	s_{\beta}(x)=g_{\alpha\beta}(x)s_{\alpha}(x)
\end{equation}
without summation.

%-------------------------------------------------------
\subsection{Tensor product}
%----------------------------------------------------

\begin{propositionDef}[\cite{MonCerveau,BIBooPQXJooItBJGZ}]		\label{DEFooCSDZooJuzGuE}
	Let \( M \) be a smooth manifold. We consider two vector bundles\footnote{Definition \ref{DEFooFRPLooTxMUzg}.} \( V_x^{(i)}\), \( \sigma_{\alpha}^{(i)}  \colon U_{\alpha}\times \eR^{k_i}\to \bigcup_{x\in M}V_x^{(i)} \) with transition functions \(g_{\alpha\beta}^{(i)} \colon U_{\alpha}\cap U_{\beta}\to \GL(\eR,k)  \).

	Let \(r \colon \eR^{k_1}\otimes \eR^{k_2}\to \eR^{k_1k_2}  \) be a vector space isomorphism\footnote{For the dimension, see the proposition \ref{PROPooTHDPooWgjUwk}.}.

	We consider the following :
	\begin{enumerate}
		\item
		      \( V_x=V_x^{(1)}\otimes V_x^{(2)}\),
		\item
		      \( T=\bigcup_{x\in M}V_x\)
		\item For each \( \alpha\) we define
		      \begin{equation}		\label{EQooXHURooBpOMlU}
			      \begin{aligned}
				      \sigma_{\alpha}\colon U_{\alpha}\times \eR^{k_1k_2} & \to T                                                                                   \\
				      \big( s, r(\sum_{ij}a_{ij} v_i\otimes w_j) \big)    & \mapsto \sum_{ij}a_{ij}\sigma_{\alpha}^{(1)}(s,v_i)\otimes \sigma_{\alpha}^{(2)}(s,w_j)
			      \end{aligned}
		      \end{equation}
		      for every \( s\in U_{\alpha}\), \( v_i\in \eR^{k_1}\) and \( w_j\in \eR^{k_2}\).
	\end{enumerate}

	We have:
	\begin{enumerate}
		\item
		      The set	\( T\) with the charts \( \sigma_{\alpha} \) is a smooth vector bundle of dimension \( k_1k_2\) over \( M\).
		\item
		      The vector bundle does not depend on the choice of the isomorphism \( r\) in the sense that two vector bundles build from two different isomorphisms \( r_1\) and \( r_2\) are equivalent.
		      %TODOooTXYEooCxyiwi Je dois définir la notion d'équivalence, et le prouver.
		      % C'est la définition DEFooDSKKooEFgmPU
	\end{enumerate}
\end{propositionDef}

\begin{proof}
	Since the spaces \( V^{(i)}_x\) are distinct, the spaces \( V_x=V_x^{(1)}\otimes V_x^{(2)}\) are distinct.
	We have to check the conditions of definition \ref{DEFooFRPLooTxMUzg}.
	\begin{subproof}
		\spitem[Condition \ref{ITEMooVIYBooMXFaKb}]
		%-----------------------------------------------------------
		We have to check the conditions of definition \ref{DEFooVMWRooGQYJwl}.
		\begin{subproof}
			\spitem[Condition \ref{ITEMooUOXXooAzRrAk}]
			%-----------------------------------------------------------
			A generic element of \( T\) has the form
			\begin{equation}
				\xi=\sum_{ij}a_{ij} v_i\otimes w_j=\sum_{ij} (a_{ij}v_i)\otimes w_j
			\end{equation}
			with \( v_i\in V_x^{(1)}\) and \( w_j\in V_x^{(2)}\) for some \( x\in M\). There exists a \( \alpha\) such that \( x\in \varphi_{\alpha}(U_{\alpha})\). Let \( s\in U_{\alpha}\) such that \( x=\varphi_{\alpha}(s)\). There exist vectors \( v'_{ij}\in \eR^{k_1}\) such that
			\begin{equation}
				a_{ij}v_i=\sigma_{\alpha}^{1}(s,v'_{ij}),
			\end{equation}
			and \( w'_j\in \eR^{k_2}\) such that \( w_j=\sigma_{\alpha}^{2}(s,w'_j)\). Now we have
			\begin{subequations}
				\begin{align}
					\sigma_{\alpha}\big( s,r(\sum_{ij}v'_{ij}\otimes w'_j) \big) & =\sum_{ij}\sigma_{\alpha}^{(1)}(s,v'_{ij})\otimes \sigma_{\alpha}^{(2)}(s,w'_j) \\
					                                                             & = \sum_{ij}a_{ij}v_i\otimes w_j                                                 \\
					                                                             & =\xi.
				\end{align}
			\end{subequations}
			This proves that \( \xi\) belongs to \( \sigma_{\alpha}(U_{\alpha}\times \eR^{k_1k_2})\).
			\spitem[Condition \ref{ITEMooQHIYooBISPjL}]
			%-----------------------------------------------------------
			We have to prove that
			\begin{equation}
				\sigma_{\alpha}^{-1}\big( \sigma_{\alpha}(U_{\alpha}\times \eR^{k_1k_2})\cap  \sigma_{\beta}(U_{\beta}\times \eR^{k_1k_2}) \big)
			\end{equation}
			is open in \( U_{\alpha}\times \eR^{k_1k_2}\).

			First we prove that
			\begin{equation}		\label{EQooNWFCooWcxQxa}
				\sigma_{\alpha}(U_{\alpha}\times \eR^{k_1k_2})\cap \sigma_{\beta}(U_{\beta}\times \eR^{k_1k_2})=\bigcup_{x\in \varphi_{\alpha}(U_{\alpha})\cap \varphi_{\beta}(U_{\beta})}V_x^{(1)}\otimes V_x^{(2)}.
			\end{equation}
			\begin{subproof}
				\spitem[First inclusion]
				%-----------------------------------------------------------
				Let \( \xi\in \sigma_{\alpha}(U_{\alpha}\times \eR^{k_1k_2})\cap \sigma_{\beta}(U_{\beta}\times \eR^{k_1k_2})\). There exists \( s\in U_{\alpha}\) and \( v\in \eR^{k_1k_2}\) such that, using the condition \ref{DEFooFRPLooTxMUzg}\ref{ITEMooXJIVooVJTorK},
				\begin{equation}
					\xi=\sigma_{\alpha}(s,v)\in V_{\varphi_{\alpha}(s)}=V_{\varphi_{\alpha}(s)}^{(1)}\otimes V_{\varphi_{\alpha}(s)}^{(2)}.
				\end{equation}
				In the same way, there exists \( t\in U_{\beta}\) and \( w\in \eR^{k_1k_2}\) such that
				\begin{equation}
					\xi=\sigma_{\beta}(t,w)\in V_{\varphi_{\beta}(t)}=V_{\varphi_{\beta}(t)}^{(1)}\otimes V_{\varphi_{\beta}(t)}^{(2)}.
				\end{equation}
				We deduce that \( \varphi_{\alpha}(s)=\varphi_{\beta}(t)\), which is, by the way, \( \pi(\xi)\). Thus, setting \( x=\varphi_{\alpha}(s)\) we have
				\begin{equation}
					\xi\in V_x^{(1)}\otimes V_{x}^{(2)}.
				\end{equation}
				\spitem[Second inclusion]
				%-----------------------------------------------------------
				Let \( \xi\in V_x^{(1)}\otimes V_x^{(2)}\) with \( x\in \varphi_{\alpha}(U_{\alpha})\cap \varphi_{\beta}(U_{\beta})\). We can write \( \xi=\sum_{ij}a_{ij}v_i\otimes w_j\) with \( v_i\in V_x^{(1)}\) and \( w_j\in V_x^{(2)}\). Since the map \(\sigma_{\alpha}^{(1)} \colon U_{\alpha}\times \eR^{k_1}\to \bigcup_{x\in M}V_x^{(1)}  \) is a chart, there exist \( v'_i\in \eR^{k_1}\) such that
				\begin{equation}
					v_i=\sigma_{\alpha}^{(1)}\big( \varphi_{\alpha}^{-1}(x),v'_i \big).
				\end{equation}
				In the same way, there exists \( w'_{ij}\in \eR^{k_2}\) such that
				\begin{equation}
					a_{ij}w_j=\sigma_{\alpha}^{(2)}\big( \varphi_{\alpha}^{-1}(x),w'_{ij} \big).
				\end{equation}
				Few computations:
				\begin{subequations}
					\begin{align}
						\xi & =\sum_{ij}a_{ij}v_i\otimes w_j                                                                                                                     \\
						    & =\sum_{ij}v_i\otimes (a_{ij}w_j)                                                                                                                   \\
						    & =\sum_{ij}\sigma_{\alpha}^{(1)}\big( \varphi_{\alpha}^{-1}(x),v'_i \big)\otimes \sigma_{\alpha}^{(2)}\big( \varphi_{\alpha}^{-1}(x), w'_{ij} \big) \\
						    & =\sigma_{\alpha}\Big( \varphi_{\alpha}^{-1}(x),r\big( \sum_{ij}v'_i\otimes w'_{ij} \big) \Big)                                                     \\
						    & \in \sigma_{\alpha}(U_{\alpha}\times \eR^{k_1k_2}).
					\end{align}
				\end{subequations}
				In the same way we see that \( \xi\in \sigma_{\beta}(U_{\beta}\times \eR^{k_1k_2})\). Equation \eqref{EQooNWFCooWcxQxa} is proven.
			\end{subproof}
			Now let \( A\) be a part of \( U_{\alpha}\). We prove that
			\begin{equation}		\label{EQooJCUAooYxMMvC}
				\sigma_{\alpha}^{-1}\big( \bigcup_{x\in \varphi_{\alpha}(A)}V_x^{(1)}\otimes V_x^{(2)} \big)=A\times \eR^{k_1k_2}.
			\end{equation}
			\begin{subproof}
				\spitem[First inclusion]
				%-----------------------------------------------------------
				Let \( \xi\in V_x^{(1)}\otimes V_x^{(2)}\) and let \( s\in U_{\alpha}\) be such that \( x=\varphi_{\alpha}(s)\). We have \( \xi=\sum_{ij}a_{ij} v_i\otimes w_j\) with \( v_i= \sigma_{\alpha}^{(1)}(s,v'_i)\) and \( a_{ij}w_j=\sigma_{\alpha}^{(2)}(s,w'_{ij})\). Now we have
				\begin{subequations}
					\begin{align}
						\xi & =\sum_{ij}\sigma_{\alpha}^{(1)}(s,v'_i)\otimes \sigma_{\alpha}^{(2)}(s,w_{ij}') \\
						    & =\sigma_{\alpha}\big( s,r(\sum_{ij}v'_i\otimes w'_{ij}) \big)                   \\
						    & \in \sigma_{\alpha}\big( \varphi_{\alpha}^{-1}(x),\eR^{k_1k_2} \big).
					\end{align}
				\end{subequations}
				\spitem[Second inclusion]
				%-----------------------------------------------------------
				Let \( (s,\omega)\in A\times \eR^{k_1k_2}\). We have to prove that \( \sigma_{\alpha}(s,\omega)\in \bigcup_{x\in \varphi_{\alpha}(A)}V_x^{(1)}\otimes V_x^{(2)}\). For that, notice that \( \omega\in \eR^{k_1k_2}\) can be written as \( \omega=r\big( \sum_{ij}a_{ij}v_i\otimes w_j \big)\) for some \( v_i\in \eR^{k_1}\) and \( w_j\in \eR^{k_2}\). Now compute
				\begin{equation}
					\sigma_{\alpha}(s,\omega)=\sum_{ij}a_{ij}\sigma_{\alpha}^{(1)}(s,v_i)\otimes \sigma_{\alpha}^{(2))}(s,w_j).
				\end{equation}
				Since \( \sigma_{\alpha}^{(1)}(s,v_i)\in V_{\varphi_{\alpha}(s)}\) and \( \sigma_{\alpha}^{(2)}(s,w_j)\in V_{\varphi_{\alpha}(s)}^{(2)}\) we found that
				\begin{equation}
					\sigma_{\alpha}(s,\omega)\in V_{\varphi_{\alpha}(s)}^{(1)}\otimes V_{\varphi_{\alpha}(s)}^{(2)}
				\end{equation}
				The equality \eqref{EQooJCUAooYxMMvC} is proved.
			\end{subproof}

			Recall what we have in equations \eqref{EQooNWFCooWcxQxa} and \eqref{EQooJCUAooYxMMvC} :
			\begin{subequations}
				\begin{align}
					\sigma_{\alpha}(U_{\alpha}\times \eR^{k_1k_2}) & \cap \sigma_{\beta}(U_{\beta}\times \eR^{k_1k_2})                                                                                                                                                  \\
					                                               & =\bigcup_{x\in \varphi_{\alpha}(U_{\alpha})\cap \varphi_{\beta}(U_{\beta})}V_x^{(1)}\otimes V_x^{(2)}                                                                                              \\
					                                               & = \Big( \bigcup_{x\in \varphi_{\alpha}(U_{\alpha})}V_x^{(1)}\otimes V_x^{(2)} \Big)\cap\Big( \bigcup_{x\in \varphi_{\beta}(U_{\beta})}V_x^{(1)}\otimes V_x^{(2)}  \Big)		\label{SUBEQooPFDVooPuzjYl}
				\end{align}
			\end{subequations}
			and
			\begin{equation}		\label{EQooSYTEooEfyxPi}
				\sigma_{\alpha}^{-1}\big( \bigcup_{x\in \varphi_{\alpha}(A)}V_x^{(1)}\otimes V_x^{(2)} \big)    =A\times \eR^{k_1k_2}.
			\end{equation}
			The map \( \sigma_{\alpha}^{-1}\) is injective, so that we can use proposition \ref{PROPooBXVSooZXmwKC}. Now we make the final computation:
			\begin{subequations}
				\begin{align}
					 & \sigma_{\alpha}^{-1}\big( \sigma_{\alpha}(U_{\alpha}\times \eR^{k_1k_2})  \big)                                                                                                                                                                                    \\
					 & = \sigma_{\alpha}^{-1}\Big(  \bigcup_{x\in \varphi_{\alpha}(U_{\alpha})}V_x^{(1)}\otimes V_x^{(2)}  \Big) \cap   \sigma_{\alpha}^{-1}\Big(  \bigcup_{x\in \varphi_{\beta}(U_{\beta})}V_x^{(1)}\otimes V_x^{(2)}  \Big) & \text{by eq. \eqref{SUBEQooPFDVooPuzjYl}} \\
					 & = \big( U_{\alpha}\times \eR^{k_1k_2} \big) \cap \big( U_{\beta}\times \eR^{k_1k_2} \big)                                                                                                                              & \text{by eq. \eqref{EQooSYTEooEfyxPi}}    \\
					 & =\big( U_{\alpha}\cap U_{\beta}\big)\times \eR^{k_1k_2}.
				\end{align}
			\end{subequations}
			We know that \( \big( U_{\alpha}\cap U_{\beta}\big)\times \eR^{k_1k_2}\) is open since \( \varphi_{\alpha}\) and \( \varphi_{\beta}\) are charts of \( M\).
			\spitem[Condition \ref{ITEMooHICSooDrPwuV}]
			%-----------------------------------------------------------
			We have to prove that
			\begin{equation}
				\sigma_{\beta}^{-1}\circ\sigma_{\alpha}  \colon  \sigma_{\alpha}^{-1}\Big( \sigma_{\alpha}(U_{\alpha}\times \eR^{k_1k_2})\cap \sigma_{\beta}(U_{\beta}\times \eR^{k_1k_2}) \Big)      \to  U_{\beta}\times \eR^{k_1k_2}
			\end{equation}
			is smooth.

			\begin{subproof}
				\spitem[First step]
				%-----------------------------------------------------------

				We have :
				\begin{equation}		\label{EQooNROCooARFfPa}
					(\sigma_{\beta}^{-1}\circ \sigma_{\alpha})\Big( s,r\big( \sum_{ij}a_{ij}v_i\otimes w_j \big)\Big)
					=\sigma_{\beta}^{-1}\Big( \sum_{ij}a_{ij}\sigma_{\alpha}^{(1)}(s,v_i)\otimes \sigma_{\alpha}^{(2)}(s,w_j) \Big).
				\end{equation}

				\spitem[Notation \( A_1\) and \( A_2\)]
				%-----------------------------------------------------------
				Small point about the notations. When we have a map \(A \colon U_{\alpha}\times \eR^{k_1}\to U_{\beta}\times \eR^{k_2}  \), we write \( A_1(s,v)\) the \( U_{\beta}\) component of \( A(s,v)\) and \( A_2(s,v)\) the component in \( \eR^k_2\).

				With that notation we have
				\begin{equation}		\label{EQooSBLDooRxPKQR}
					(\sigma_{\beta}^{(1)-1}\circ\sigma_{\alpha}^{(1)})_1(s,v)=(\varphi_{\beta}^{-1}\circ \varphi_{\alpha})(s).
				\end{equation}
				Indeed, by definition \ref{DEFooFRPLooTxMUzg}\ref{ITEMooOBCMooOCqoQo}, we have \( \sigma_{\alpha}^{(1)}(s,v)\in V_{\varphi_{\alpha}(s)}^{(1)}\), and by the same point,
				\begin{equation}
					\sigma_{\beta}^{(1)-1}\big( V_{\varphi_{\alpha}(s)} \big)=\big( (\varphi_{\beta}^{-1}\circ\varphi_{\alpha})(s), \eR^{k_1} \big).
				\end{equation}
				The first component is \( (\varphi_{\beta}^{-1}\circ \varphi_{\alpha})(s)\) as expected.

				\spitem[Next step]
				%-----------------------------------------------------------
				We continue \eqref{EQooNROCooARFfPa} by proving
				\begin{equation}		\label{EQooGVGEooRbGZUd}
					\begin{aligned}[]
						 & \sigma_{\beta}^{-1}\Big( \sum_{ij}a_{ij}\sigma_{\alpha}^{(1)}(s,v_i)\otimes \sigma_{\alpha}^{(2)}(s,w_j) \Big)                                  \\
						 & \quad = \Big( (\varphi_{\beta}^{-1}\circ\varphi_{\alpha})(s),r\big( \sum_{ij}a_{ij}(\sigma_{\beta}^{(1)-1}\circ \sigma_{\alpha}^{(1)})_2(s,v_i)
						\otimes
						(\sigma_{\beta}^{(2)-1}\circ\sigma_{\alpha}^{(2)})_2(s,w_j)
						\big) \Big).
					\end{aligned}
				\end{equation}

				Notice that, setting \( x=(\varphi_{\beta}^{-1}\circ\varphi_{\alpha})(s)\), the equation \eqref{EQooSBLDooRxPKQR} says that \(   (\sigma_{\beta}^{(1)-1}\circ\sigma_{\alpha}^{(1)})_1(s,v_i)  =x   \), so that
				\begin{equation}		\label{EQooZEBYooXtCaUP}
					\big( x,  (\sigma_{\beta}^{(1)-1}\circ\sigma_{\alpha}^{(1)})_2(s,v_i) \big) = (\sigma_{\beta}^{(1)-1}\circ\sigma_{\alpha}^{(1)})(s,v_i).
				\end{equation}

				Now we prove \eqref{EQooGVGEooRbGZUd} by applying \( \sigma_{\beta}\) to the right hand side :
				\begin{subequations}
					\begin{align}
						                                                                                            & \sigma_{\beta}  \Big( x,r\big( \sum_{ij}a_{ij}(\sigma_{\beta}^{(1)-1}\circ \sigma_{\alpha}^{(1)})_2(s,v_i)
						\otimes
						(\sigma_{\beta}^{(2)-1}\circ\sigma_{\alpha}^{(2)})_2(s,w_j)
						\big) \Big)                                                                                                                                                                                              \\
						                                                                                            & \quad  = \sum_{ij}a_{ij}
						\sigma_{\beta}^{(1)}\big( x,  (\sigma_{\beta}^{(1)-1}\circ\sigma_{\alpha}^{(1)})_2(s,v_i) \big)
						\otimes
						\sigma_{\beta}^{(2)}\big( x,  (\sigma_{\beta}^{(2)-1}\circ\sigma_{\alpha}^{(2)})_2(s,w_i) \big)                                                                                                          \\
						                                                                                            & \quad  = \sum_{ij}a_{ij}
						\sigma_{\beta}^{(1)}\big(   (\sigma_{\beta}^{(1)-1}\circ\sigma_{\alpha}^{(1)})(s,v_i) \big)
						\otimes
						\sigma_{\beta}^{(2)}\big(   (\sigma_{\beta}^{(2)-1}\circ\sigma_{\alpha}^{(2)})(s,w_i) \big) & \text{eq. \eqref{EQooZEBYooXtCaUP}}                                                                        \\
						                                                                                            & \quad = \sum_{ij}a_{ij}\sigma_{\alpha}^{(1)}(s,v_i)\otimes \sigma_{\alpha}^{(2)}(s,w_j).
					\end{align}
				\end{subequations}
				\spitem[Conclusion]
				%-----------------------------------------------------------
				We have
				\begin{subequations}		\label{SUBEQSooRYKSooBkBmaF}
					\begin{align}
						 & (\sigma_{\beta}^{-1}\circ\sigma_{\alpha})\Big( s,r\big( \sum_{ij}a_{ij}v_i\otimes w_j \big) \Big)                                                                                                                               \\
						 & \quad =\sigma_{\beta}^{-1}\Big( \sum_{ij}a_{ij}   \sigma_{\alpha}^{(1)}(s,v_i)\otimes \sigma_{\alpha}^{(2)}(s,w_j)  \Big)                                                                                                       \\
						 & \quad = \Big( (\varphi_{\beta}^{-1}\circ\varphi_{\alpha})(s),r\big[  \sum_{ij}a_{ij}(\sigma_{\beta}^{(2)-1}\circ\sigma_{\alpha}^{(1)})_2(s,v_i)\otimes (\sigma_{\beta}^{(1)-1}\circ\sigma_{\alpha}^{(2)})_2(s,w_j) \big] \Big).
					\end{align}
				\end{subequations}
				Since the maps \( \varphi_{\alpha}\), \( \varphi_{\beta}\) are charts of \( M\), the composition \( \varphi_{\beta}^{-1}\circ\varphi_{\alpha}\) is smooth. The same way, the maps \( \sigma_{\alpha}^{(i)}\) and \( \sigma_{\beta}^{(i)} \) are charts of \( \bigcup_{x\in M}V_x^{(i)}\), the composition \( \sigma_{\beta}^{(i)-1}\circ \sigma_{\alpha}^(i)\) is smooth.
			\end{subproof}
		\end{subproof}
		\spitem[Condition \ref{ITEMooXHOBooERubro}]
		%-----------------------------------------------------------
		We have to prove that\footnote{Here we use the fact that the spaces \( V_x^{(i)}\) have the form \( \{ (x,v)\tq v\in W_x^{(i)} \}\), so that when we write \( v_i\otimes w_j\), we could have written \( (x,v_i)\otimes (x,w_j)\). Just keep in mind that the base point \( x\) is contained in the vector \( v_i\) in the following formula.}
		\begin{equation}
			\begin{aligned}
				\pi\colon \bigcup_{x\in M}V_x^{(1)}\otimes V_x^{(2)} & \to M     \\
				\sum_{ij}a_{ij}v_i\otimes w_j                        & \mapsto x
			\end{aligned}
		\end{equation}
		is smooth. In other words, for each \( \alpha\) and \( \beta\), the map
		\begin{equation}
			\varphi_{\beta}^{-1}\circ \pi\circ \sigma_{\alpha} \colon U_{\alpha}\to U_{\beta}
		\end{equation}
		must be smooth. We have
		\begin{subequations}
			\begin{align}
				(\varphi_{\beta}^{-1}\circ\pi\circ\sigma_{\alpha}) & \big( s,r(\sum_{ij}a_{ij}v_i\otimes w_j) \big)                                                                                                                        \\
				                                                   & =(\varphi_{\beta}^{-1}\circ\pi)\Big( \underbrace{\sum_{ij}a_{ij}\sigma_{\alpha}^{(1)}(s,v_i)\otimes \sigma_{\alpha}^{(2)}(s,w_j)}_{\in V_{\varphi_{\alpha}(s)}} \Big) \\
				                                                   & =(\varphi_{\beta}^{-1}\circ\varphi_{\alpha})(s).
			\end{align}
		\end{subequations}
		So we have
		\begin{equation}
			(\varphi_{\beta}^{-1}\circ\pi\circ\sigma_{\alpha})(s,\xi)=(\varphi_{\beta}^{-1}\circ\varphi_{\alpha})(s),
		\end{equation}
		which leads us to \( \varphi_{\beta}^{-1}\circ\pi\circ\sigma_{\alpha}=\varphi_{\beta}^{-1}\circ\varphi_{\alpha}\circ\pr\) where \(\pr \colon \eR^n\times \eR^{k_1k_2}\to \eR^n  \) is the projection. Since \( \pr\) is smooth and \( \varphi_{\beta}^{-1}\circ\varphi_{\alpha}\) is smooth, we conclude that \( \varphi_{\beta}^{-1}\circ\pi\circ\sigma_{\alpha}\) is smooth.
		\spitem[Condition \ref{ITEMooXJIVooVJTorK}]
		%-----------------------------------------------------------
		Since \( \sigma_{\alpha}^{(i)}\) is a chart for the vector bundle \( \bigcup_{x\in M}V_x^{(i)}\) we have \( \sigma_{\alpha}^{i}(s,v)\in V_{\varphi_{\alpha}(s)}\). Thus for right hand side of \eqref{EQooXHURooBpOMlU} is an element of \( V_{\varphi_{\alpha}(s)}^{(1)}\otimes V_{\varphi_{\alpha}(s)}^{(2)}=V_{\varphi_{\alpha}(s)}\).
		\spitem[Condition \ref{ITEMooOBCMooOCqoQo}]
		%-----------------------------------------------------------
		We fix \( s\in U_{\alpha}\). We have to prove that the map
		\begin{equation}
			\begin{aligned}
				\tau_{\alpha,s}\colon \eR^{k_1k_2} & \to V_{\varphi_{\alpha}(s)}    \\
				\xi                                & \mapsto \sigma_{\alpha}(s,\xi)
			\end{aligned}
		\end{equation}
		is a linear bijection. If \( \xi=r\big( \sum_{ij}a_{ij}v_i\otimes w_j \big)\),
		\begin{equation}
			\tau_{\alpha,s}(\xi)=\sum_{ij}a_{ij}\sigma_{\alpha}^{(1)}(s,v_i)\otimes \sigma_{\alpha}^{(2)}(s,w_j).
		\end{equation}
		\begin{subproof}
			\spitem[Linear]
			%-----------------------------------------------------------
			For the linearity, for \( \lambda\in \eR\) we have
			\begin{subequations}
				\begin{align}
					\tau_{\alpha,s}(\lambda\xi) & =\tau_{\alpha,s}\Big( r\big( \sum_{ij}a_{ij}(\lambda v_i)\otimes w_j \big) \Big)         \\
					                            & =\sum_{ij}a_{ij}\sigma_{\alpha}^{(1)}(s,\lambda v_i)\otimes \sigma_{\alpha}^{(2)}(s,w_j) \\
					                            & =\lambda\sum_{ij}\sigma_{\alpha}^{(1)}(s,v_i)\otimes \sigma_{\alpha}^{(2)}(s,w_j)        \\
					                            & =\lambda\tau_{\alpha,s}(\xi)
				\end{align}
			\end{subequations}
			because \( \sigma_{\alpha}^{(1)}(s,\lambda v_i)=\lambda\sigma_{\alpha}^{(1)}(s,v_i)\). The same kind of computations hold to prove that \( \tau_{\alpha,s}(\xi_1+\xi_2)=\tau_{\sigma,s}(\xi_1)+\tau_{\alpha,s}(\xi_2)\).
			\spitem[Injective]
			%-----------------------------------------------------------
			Suppose \( \tau_{\alpha,s}(\xi)=0\). Let \( \{e_i\}\) be a basis of \( V\) and \( \{e'_j\}\) be a basis of \( W\). By proposition \ref{PROPooTHDPooWgjUwk}\ref{ITEMooQCILooUncdGl}, the set \( \{e_i\otimes e'_j\}\) is a basis of \( V\otimes W\). We write \( \xi=r\big( \sum_{ij}a_{ij}e_i\otimes e'_j \big)\), so that
			\begin{equation}		\label{EQooVGWPooTRDuJW}
				\sum_{ij}a_{ij}\sigma_{\alpha}^{(1)}(s,e_i)\otimes \sigma_{\alpha}^{(2)}(s,e'_j)=0.
			\end{equation}
			Since \( v\mapsto \sigma_{\alpha}^{(i)}(s,v)\) is a linear bijection, the set \( \{ \sigma_{\alpha}^{(i)}(s,v) \}\) is a basis of \( V_{\varphi_{\alpha}(s)}^{(i)}\). We conclude that the set
			\begin{equation}
				\{ \sigma_{\alpha}^{(1)}(s,e_i)\otimes \sigma_{\alpha}^{(2)}(s,e'_j) \}
			\end{equation}
			is a basis of \( V_{\varphi_{\alpha}(s)}=V_{\varphi_{\alpha}(s)}^{(1)}\otimes V_{\varphi_{\alpha}(s)}^{(2)}\). Thus equation \eqref{EQooVGWPooTRDuJW} implies that \( a_{ij}=0\) for every \( i,j\). We conclude that \( \xi=0\) and that \( \tau_{\alpha,s}\) is injective.

			\spitem[Surjective]
			%-----------------------------------------------------------
			The set \(			\{ \sigma_{\alpha}^{(1)}(s,e_i)\otimes \sigma_{\alpha}^{(2)}(s,e'_j) \}  \) is a basis and is in the image of \( \tau_{\alpha,s}\) which is linear. Thus \( \tau_{\alpha,s}\) is surjective.
		\end{subproof}
		\spitem[Condition \ref{ITEMooPNLXooLQWGqc}]
		%-----------------------------------------------------------
		Two points to be proven.
		\begin{subproof}
			\spitem[\( g_{\alpha\beta}(s)\in \GL(\eR,k_1k_2)\)]
			%-----------------------------------------------------------
			The condition
			\begin{equation}
				(\sigma_{\alpha}^{-1}\circ\sigma_{\beta})(s,v)=\big( s,g_{\alpha\beta}(s)v \big)
			\end{equation}
			for every \( v\in \eR^{k_1k_2}\) says
			\begin{equation}
				g_{\alpha\beta}(s)v=(\tau_{\alpha,s}^{-1}\circ\tau_{\alpha,s})(v).
			\end{equation}
			Thus \( g_{\alpha\beta}(s)\) is linear and invertible. This means that for every \( s\), the map \( g_{\alpha\beta}(s)\) belongs to \(\GL(\eR, k_1k_2)\).
			\spitem[\( g_{\alpha\beta}\) is smooth]
			%-----------------------------------------------------------
			We are going to prove that
			\begin{equation}\label{EQooAUMXooCoqPTO}
				g_{\alpha\beta}(s)=r\circ\big( g_{\alpha\beta}^{(1)}(s)\otimes g_{\alpha\beta}^{(2)}(s) \big)\circ r^{-1}.
			\end{equation}
			Let \( \{ e_i \}_{i\in I}\) be a basis of \( \eR^k_1\) and \( \{ e'_j \}_{j\in J}\) be a basis of \( \eR^{k_2}\). We consider \( v=r(e_i\otimes e'_j)\) and we compute
			\begin{subequations}		\label{EQSooUIMFooMBbBvp}
				\begin{align}
					\sigma_{\alpha}\Big( s,  r\circ\big( g_{\alpha\beta}^{(1)}(s)\otimes g_{\alpha\beta}^{(2)}(s) \big)\circ r^{-1}v \Big)
					 & =\sigma_{\alpha}\Big(  s, r\circ\big( g_{\alpha\beta}^{(1)}(s)\otimes g_{\alpha\beta}^{(2)}(s) \big)(e_i\otimes e'_j)   \Big)                                                          \\
					 & =\sigma_{\alpha}\Big( s,r\big( g_{\alpha\beta}^{(1)}(s)e_i\otimes g_{\alpha\beta}^{(2)}(s)e'_j \big) \Big)                                                                             \\
					 & = \sigma_{\alpha}^{(1)}\big( s,g_{\alpha\beta}^{(1)}(s)e_i \big)\otimes \sigma_{\alpha}^{(2)}\big( s,g_{\alpha\beta}^{(2)}e'_j \big)                                                   \\
					 & = \sigma_{\beta}^{(1)}(s,e_i)\otimes \sigma_{\beta}^{(2)}(s,e'_j)                                                                    & \text{cf. justif.}  \label{SUBEQooSZDEooLQBGoQ} \\
					 & =\sigma_{\beta}\big( s,r(e_i\otimes e'_j) \big)                                                                                                                                        \\
					 & =\sigma_{\beta}\big( s,r(v) \big).
				\end{align}
			\end{subequations}
			Justifications.
			\begin{itemize}
				\item
				      For \eqref{SUBEQooSZDEooLQBGoQ}. We have \( \big( s,g_{\alpha\beta}^{(1)}(s)e_i \big)=\big( \sigma_{\alpha}^{(1)-1}\circ \sigma_{\beta} \big)(s,e_i)\), and similar for \( e'_j\).
			\end{itemize}
			Putting \( \sigma_{\alpha}\) on the right hand side the equalities \eqref{EQSooUIMFooMBbBvp} show that
			\begin{equation}
				(\sigma_{\alpha}^{-1}\circ \sigma_{\beta})\big( s,r(v) \big)=\Big( s,r\circ\big( g_{\alpha\beta}^{(1)}(s)\otimes g_{\alpha\beta}^{(2)}(s) \big)r^{-1}v \Big).
			\end{equation}
			The left hand side can be expressed in terms og \( g_{\alpha\beta}(s)\). We have
			\begin{equation}
				\big( g_{\alpha\beta}(s)\circ r \big)(e_i\otimes e'_j)=r\circ \big( g_{\alpha\beta}^{(1)}(s)\otimes g_{\alpha\beta}^{(2)}(s) \big)(e_i\otimes e'_j).
			\end{equation}
			Since the operators \( g_{\alpha\beta}(s)\circ r\) and \( r\circ\big(   g_{\alpha\beta}^{(1)}(s)\otimes g_{\alpha\beta}^{(2)}(s) \big)\) are linear and since the elements \( e_i\otimes e'_j\) form a basis we have the operator equality
			\begin{equation}
				g_{\alpha\beta}(s)\circ r=r\circ \big( g_{\alpha\beta}^{(1)}(s)\otimes g_{\alpha\beta}^{(2)}(s) \big),
			\end{equation}
			which is the announced equality \eqref{EQooAUMXooCoqPTO}.
			\spitem[Conclusion]
			%-----------------------------------------------------------
			The maps \( g_{\alpha\beta}^(1)\) and \( g_{\alpha\beta}^{(2)}\) are smooths by hypothesis. By proposition \ref{PROPooLANVooKPiLuu}, the tensor product is smooth. The maps \( r\) and \( r^{-1}\) are linear on finite dimensional vector spaces; they are smooth too.
		\end{subproof}
	\end{subproof}
\end{proof}

\begin{proposition}[\cite{MonCerveau}]		\label{PROPooEYSWooOeQNyX}
	The tensor product\footnote{Definition \ref{DEFooCSDZooJuzGuE}.} of vector bundles is associative : if \( E_1\), \( E_2\) and \( E_3\) are vector bundles, then
	\begin{equation}
		(E_1\otimes E_2)\otimes E_3=E_1\otimes (E_2\otimes E_3).
	\end{equation}
	%TODOooTXYEooCxyiwi Je dois définir la notion d'équivalence, et le prouver.
\end{proposition}


%+++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Tensor bundle}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{definition}
	Let \( (k,l)\) be integers. The \defe{\( k,l\)-tensor bundle}{tensor bundle} is
	\begin{equation}
		\bigotimes^{k,l}(TM)=(TM)^{\otimes k}\otimes (T^*M)^{\otimes l}.
	\end{equation}
	A \defe{\( (k,l)\)-tensor field}{tensor field} is a smooth section of \( \bigotimes^{k,l}(TM)\).
\end{definition}

\begin{proposition}		\label{PROPooIMOJooKzEDXA}
	The set \( TM\) becomes a vector bundle with the charts
	\begin{equation}
		\begin{aligned}
			\sigma_{\alpha}\colon U_{\alpha}\times \eR^n & \to TM                                                              \\
			(s,v)                                        & \mapsto  \frac{d}{dt} \left[ \varphi_{\alpha}(s+tv)  \right]_{t=0}.
		\end{aligned}
	\end{equation}
\end{proposition}

\noproof


%-------------------------------------------------------
\subsection{Dual basis}
%----------------------------------------------------


The proposition \ref{PROPooAAAXooKAMsfK} says that the vectors
\begin{equation}
	\partial_i=\frac{d}{dt} \left[ \varphi_{\alpha}(s_0+te_i)  \right]_{t=0}
\end{equation}
form a basis of \( T_pM\) where \( p=\varphi_{\alpha}(s_0)\). We denote by \( \{ \partial_{i}^* \}\) the dual basis.

\begin{normaltext}
	When \( I=(i_1,\ldots,i_k)\) is a multiindex, we write
	\begin{equation}
		\partial^*_{\wedge I}=\partial_{i_1}\wedge\ldots\wedge\partial_{i_k}.
	\end{equation}
\end{normaltext}

\begin{normaltext}
	The object \( \partial^*_{\wedge I}\) is build from the elements of the basis \( \partial_i^*\) which is the dual of the basis
	\begin{equation}
		\partial_i=\frac{d}{dt} \left[ \varphi_{\alpha}(s+te_i)  \right]_{t=0}.
	\end{equation}
	Thus \( \partial^*_{\wedge I}\) is a function of \( s\).
\end{normaltext}

\begin{lemma}[\cite{MonCerveau}]		\label{LEMooKCBSooPjEwEl}
	Let \( (U,\varphi)\) be a chart of a smooth manifold. We have the local expression
	\begin{equation}
		\partial^*_i=df_i
	\end{equation}
	where \( f_i\) is the function
	\begin{equation}
		\begin{aligned}
			f_i\colon M & \to \eR                    \\
			q           & \mapsto \varphi^{-1}(q)_i.
		\end{aligned}
	\end{equation}
\end{lemma}

\begin{proof}
	Let \( q=\varphi(x)\in M\). At \( q\) we have \( \partial_j=\frac{d}{dt} \left[ \varphi(x+te_j)  \right]_{t=0}\) and, using the definition \( f_i=\proj_i\circ\varphi^{-1}\), we have
	\begin{subequations}
		\begin{align}
			df_i(\partial_j) & =\frac{d}{dt} \left[ f_i\big( \varphi(x+te_j) \big)  \right]_{t=0}                 \\
			                 & =\frac{d}{dt} \left[ (\proj_i\circ\varphi^{-1}\circ\varphi)(x+te_j)  \right]_{t=0} \\
			                 & =\frac{d}{dt} \left[ \proj_i(x+te_j)  \right]_{t=0}                                \\
			                 & =\frac{d}{dt} \left[ x_i+t\delta_{ij}  \right]_{t=0}                               \\
			                 & =\delta_{ij},
		\end{align}
	\end{subequations}
	which proves that \( df_i=\partial^*_i\).
\end{proof}

\begin{lemma}[\cite{MonCerveau}]  \label{LEMooGEFSooVlPLOs}
	Let \( f\) be a smooth function over the manifold \( M\). We consider a chart \( (U,\varphi)\). The differential of \( f\) is
	\begin{equation}
		df=\sum_i(\partial_if)\partial^*_i.
	\end{equation}
\end{lemma}

\begin{proof}
	Let \( X\) be the vector \( X=\sum_i\partial_i\). Since \( \{ \partial^*_i \}\) is the dual basis, we express the components of \( X\) under the form \( X_i=\partial_i^*(X)\). Now, by definition,
	\begin{equation}
		df(X)=X(f)=\sum_iX_i\partial_if=\sum_i(\partial_if)\partial_i^*(X).
	\end{equation}
	Since it is valid for every vector \( X\), we have the equality.
\end{proof}

\begin{lemma}		\label{LEMooIAASooDnnhRA}
	The map
	\begin{equation}
		\partial^*_{\wedge I}\colon U_{\alpha} \to \Wedge^k(T^*M)
	\end{equation}
	is smooth and satisfy
	\begin{equation}
		\partial_{\wedge I}^*(s)\in\Wedge^k\big( T^*_{\varphi_{\alpha}(s)}M \big).
	\end{equation}
\end{lemma}

\begin{normaltext}		\label{NORMooDQEZooHaJPoa}
	Let \(\varphi_{\alpha} \colon U_{\alpha}\to M  \) be a chart. We introduce two maps to make the link between the real world and the manifold world. One for the forms :
	\begin{equation}
		\begin{aligned}
			\tau_{\alpha,s}\colon \Wedge^k(\eR^n)^* & \to \Wedge^kT^*_{\varphi_{\alpha}(s)}M                \\
			\sum_{I\in C_k}\omega_Ie^*_{\wedge I}   & \mapsto \sum_{I\in C_k}\omega_I\partial^*_{\wedge I}.
		\end{aligned}
	\end{equation}
	An one for the vectors:
	\begin{equation}
		\begin{aligned}
			\tau_{\alpha,s}\colon \eR^n & \to T_{\varphi_{\alpha}(s)}M \\
			v                           & \mapsto \sum_iv_i\partial_i.
		\end{aligned}
	\end{equation}
	These two maps have the same name «\( \tau_{\alpha,s}\)», but their arguments are different enough not to cause confusion.
\end{normaltext}


\begin{propositionDef}[Exterior bundle]		\label{DEFooZELVooFfosEn}
	Let \( M\) be a \( n\)-dimensional manifold. We write\footnote{This provides a basis of \( \Wedge^kT^*m\), see proposition \ref{PROPooUGLOooTULnDK}.}
	\begin{equation}
		C_k=\{ (i_1,\ldots,i_k)\tq 1\leq i_1<\ldots <i_k\leq n \}.
	\end{equation}
	The set \( \Wedge^kT^*M\) is a vector bundle with the charts
	\begin{equation}		\label{EQooOMWMooKKWhqf}
		\begin{aligned}
			\sigma_{\alpha}\colon U_{\alpha}\times \Wedge^k(\eR^n)^* & \to \Wedge^kT^*M                                                                       \\
			(s,\sum_{I\in C_k}\omega_Ie^*_{\wedge I})                & \mapsto \Big( \varphi_{\alpha}(s),  \sum_{I\in C_k}\omega_I\partial^*_{\wedge I}\Big).
		\end{aligned}
	\end{equation}
	In other words,
	\begin{equation}
		\sigma_{\alpha}(s,\omega')=\big( \varphi_{\alpha}(s),\tau_{\alpha,s}(\omega') \big).
	\end{equation}
	Two notes.
	\begin{enumerate}
		\item
		      There is an hidden choice of isomorphism between \( \eR^m\) and \( \Wedge^k\eR^n\) with \( m=\binom{ n }{ k }\).
		\item
		      The vector space \( V_{\varphi_{\alpha}(s)}\) is the set of elements of the form \( \big( \varphi_{\alpha}(s),\omega \big)\) with \( \omega\in \Wedge^kT^*_{\varphi_{\alpha}(s)}M\). The purpose of that is to make explicit the fact that all the vector spaces \( V_x\) are distinct. See the point \ref{ITEMooIVKKooNEfxVi} of the definition \ref{DEFooFRPLooTxMUzg} of a vector bundle.
	\end{enumerate}
\end{propositionDef}

\noproof


%+++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Differential form}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{definition}		\label{DEFooBRSSooWOgoov}
	A \defe{\( k\)-differential-form}{differential form} is a section of \( \Wedge^kT^*M\). We denote by \( \Omega^k(M)\) the set of \( k\)-differential forms.

	When the context is clear, we could simply say "\( k\)-form" instead of \( k\)-differential form.
\end{definition}

\begin{normaltext}
	Formally, a \( k\)-differential form \( \omega\) is a smooth map
	\begin{equation}
		\omega \colon M\to M\times \Wedge^kT^*M
	\end{equation}
	where the \( M\)-component of \( \omega\) is the identity.

	We will, however, often make the abuse of notation and drop that \( M\)-component.
\end{normaltext}

\begin{propositionDef}		\label{PROPooQOUXooZfFHNb}
	If \( \omega\in \Omega^k(M)\) and \( \eta\in \Omega^l(M)\) we define \( \omega\wedge \eta\) pointwise by
	\begin{equation}
		(\omega\wedge \eta)_p=\omega_p\wedge \eta_p
	\end{equation}
	where the exterior product is defined by \ref{DEFooCTSPooZRIufr}.

	We have \( \omega\wedge\eta\in\Omega^{k+l}(M)\).
\end{propositionDef}

\begin{lemma}[\cite{MonCerveau}]		\label{LEMooUVRQooVZDKir}
	If \( f\) is a function and \( \omega\) is a \( k\)-differential form we have
	\begin{equation}		\label{EQooYHCKooNLgJWG}
		f\wedge \omega=f\omega.
	\end{equation}
	where, on the left hand side, \( f\) is seen as a \( 0\)-differential form while, on the right hand side this is the pointwise product.
\end{lemma}

\begin{proof}
	We compute the left-hand side of \eqref{EQooYHCKooNLgJWG} at \( x\in M\). From definition \ref{PROPooQOUXooZfFHNb},
	\begin{equation}
		(f\wedge \omega)_x=f(x)\wedge \omega_x.
	\end{equation}
	Now we are reduced to check \( (\lambda\otimes \omega)=\lambda\omega\) for \( \lambda\in \eR\) and \( \omega\in \Wedge^k(V^*)\) for some vector space \( V\). Using the definitions \ref{DEFooCTSPooZRIufr} and \ref{DEFooHAKAooIfbsEy},
	\begin{subequations}
		\begin{align}
			\lambda\wedge \omega & =\frac{ (0+k)! }{ 0!k! }\Alt(\lambda\otimes \omega)                    \\
			                     & =\Alt(\lambda\otimes \omega)                                           \\
			                     & =\frac{1}{ k!}\sum_{\pi\in S_k}(-1)^{\pi}(\lambda\otimes\omega)^{\pi}.
		\end{align}
	\end{subequations}
	Each term in the sum is subject to the relation \( (\lambda\otimes \omega)(v_1,\ldots,v_k)=\lambda\omega(v_1,\ldots,v_k)\).
\end{proof}

\begin{proposition}		\label{PROPooNOGKooQedJba}
	Let \( \omega\in \Omega^k(M)\). There exist functions \( \omega_I\in C^{\infty}(M)\) for each
	\begin{equation}
		I\in C_k=\{ (i_1,\ldots,i_k)\tq 1\leq i_1<\ldots <i_k\leq n \}
	\end{equation}
	such that
	\begin{equation}
		\omega_x=\sum_{I\in C_k}\omega_I(x)\partial^*_{\wedge I}.
	\end{equation}
	Note: even if we don't write it explicitly, \( \partial^*_i\) is a vector field, and then a function of \( x\).
\end{proposition}

\noproof


\begin{proposition}			\label{PROPooHTKMooVzYQdW}
	We consider a \( k\)-form \( \omega\in \Omega^k(M)\) and smooth vector fields \( X_1,\ldots,X_k\). The map
	\begin{equation}
		\begin{aligned}
			\omega(X_1,\ldots,X_k)\colon M & \to \eR                                            \\
			x                              & \mapsto \omega_x\big( (X_1)_x,\ldots,(X_k)_x \big)
		\end{aligned}
	\end{equation}
	is smooth.
\end{proposition}

\begin{proof}

	We have to prove that \( \omega(X_1,\ldots,X_k)\circ \varphi_{\alpha}\) is smooth as function from \( U_{\alpha}\) to \( \eR\). Using proposition \ref{PROPooNOGKooQedJba}, we have smooth functions \( \omega_I\in C^{\infty(M,\eR)}\) such that
	\begin{equation}
		\omega_x=\sum_{i\in C_k}\omega_I(x)\partial^*_{\wedge I}.
	\end{equation}

	From proposition \ref{PROPooXURIooYPytwa}, there exist smooth functions \( X_{ij}\in C^{\infty(M)}\) such that
	\begin{equation}
		X_i(x)=\sum_jX_{ij}(x)\partial_j.
	\end{equation}


	We have
	\begin{subequations}
		\begin{align}
			\omega(X_1,\ldots,X_k)\varphi_{\alpha}(s) & =\sum_{I\in C_k}(\omega_I\circ\varphi_{\alpha})(s)\partial_{\wedge I}^*\Big( (X_1\circ\varphi_{\alpha})(s),\ldots,(X_k\circ \varphi_{\alpha})(s) \Big)                                               \\
			                                          & =\sum_I(\omega_I\circ\varphi_{\alpha})(s)(\partial^*_{i_1}\wedge\ldots\partial_{i_k}^*)  \Big( (X_1\circ\varphi_{\alpha})(s),\ldots,(X_k\circ \varphi_{\alpha})(s) \Big).		\label{SUBEQooKPRLooFzreMJ}
		\end{align}
	\end{subequations}
	The function \( \omega_I\circ\varphi_{\alpha}\) is smooth. The rest of \eqref{SUBEQooKPRLooFzreMJ} are sum of products of elements of the form\footnote{We write the dependence of \( \partial_i^*\) in \( x=\varphi_{\alpha}(s)\).}
	\begin{subequations}
		\begin{align}
			\partial_{i_m}^*(x)\Big( (X_l\circ\varphi_{\alpha})(s) \Big) & = \partial^*_{i_m}(x)\sum_{j=1}^n(X_{lj\circ\varphi_{\alpha}})(s)\partial_j(x) \\
			                                                             & = \sum_j (X_{lj}\circ \varphi_{\alpha})(s)\delta_{j,i_m}                       \\
			                                                             & = (X_{l,i_m}\circ\varphi_{\alpha})(s).
		\end{align}
	\end{subequations}
	The last line is a smooth function of \( s\) since \( X_{ij}\) are smooth. The proposition \ref{PROPooCWPAooKDnwHR} about sum and product of smooth functions makes \( \omega(X_1,\ldots,X_k)\) smooth.
\end{proof}


\begin{lemma}		\label{LEMooMEZCooGXpOOa}
	Let \( v\in \eR^n\). The maps of \ref{NORMooDQEZooHaJPoa} satisfy
	\begin{enumerate}
		\item		\label{ITEMooZSFDooAuUnPd}
		      \begin{equation}
			      \tau_s(e^*_i)\big( \tau_s(v) \big)=e_i^*(v)=v_i.
		      \end{equation}
		\item		\label{ITEMooSVEFooBKhHnc}
		      For every miltiindex \( I=(i_1,\ldots,i_k)\) and \( X_j\in T_{\varphi_{\alpha}(s)}M\), we have
		      \begin{equation}
			      \tau_{\alpha,s}(e^*_{\wedge I})(X_1,\ldots,X_k)=e^*_{\wedge I}\big( \tau_{\alpha,s}^{-1}(X_1),\ldots,\tau_{\alpha,s}^{-1}(X_k) \big).
		      \end{equation}
		      \item\label{ITEMooQUZCooGcJrLe}
		      For every \( \omega'\in \Wedge^k(\eR^n)^*\) and \( X_i\in T_{\varphi_{\alpha}(s)M}\) we have
		      \begin{equation}
			      \tau_{\alpha,s}(\omega')(X_1,\ldots,X_k)=\omega'\big( \tau_{\alpha,s}^{-1}(X_1),\ldots,\tau_{\alpha,s}^{-1}(X_k) \big).
		      \end{equation}
	\end{enumerate}
\end{lemma}

\begin{proof}
	Each point is a generalisation of the previous one.
	\begin{subproof}
		\spitem[For \ref{ITEMooZSFDooAuUnPd}]
		%-----------------------------------------------------------
		We have \( e^*_i\in \Wedge^k\eR^n\) with \( k=1\); we can apply \( \tau_s\) to it. We have
		\begin{equation}
			\tau_s(e^*_i)\big( \tau_s(v) \big)=\partial_i^*\big( \sum_jv_j\partial_j \big)=\sum_jv_j\delta_{ij}=v_i=e^*_i(v).
		\end{equation}
		\spitem[For \ref{ITEMooSVEFooBKhHnc}]
		%-----------------------------------------------------------
		Let \( X_j\in T_{\varphi_{\alpha}(s)}M\). Thanks to proposition \ref{PROPooAAAXooKAMsfK}, we write \( X_j=\sum_lX_{jl}\partial_l\). Applying \( \partial^*_m\) we have
		\begin{equation}		\label{EQooBGWWooXQqAdc}
			\partial_m^*(X_j)=\sum_lX_{jl}\delta_{ml}=X_{jm}.
		\end{equation}
		Now we can compute. On the one hand,
		\begin{subequations}
			\begin{align}
				\tau_{\alpha,s}(e^*_{\wedge I})(X_1,\ldots,X_k) & = \partial^*_{\wedge I}(X_1,\ldots,X_k)                                                                                                              \\
				                                                & =(\partial_{i_1}^*\wedge \ldots \wedge \partial_{i_k}^*)(X_1,\ldots,X_k)                                                                             \\
				                                                & =k!\Alt(\partial^*_{i_1}\otimes \ldots\otimes \partial_{i_k}^*)(X_1,\ldots,X_k)                               & \text{lem. \ref{LEMooZJJLooFGuguy}.} \\
				                                                & = \sum_{\pi\in S_k}(-1)^{\pi}(\partial_{i_1}^*\otimes \ldots \partial_{i_k}^*)(X_{\pi(1)},\ldots, X_{\pi(k)}) & \text{def. \ref{DEFooHAKAooIfbsEy}}  \\
				                                                & = \sum_{\pi\in S_k}(-1)^{\pi} \partial_{i_1}^*(X_{\pi(1)})\ldots \partial_{i_k}(X_{\pi(k)})                                                          \\
				                                                & = \sum_{\pi\in S_k}(-1)^{\pi}X_{i_1\pi(1)}\ldots X_{i_k\pi(k)}                                                & \text{by \eqref{EQooBGWWooXQqAdc}.}
			\end{align}
		\end{subequations}
		On the other hand we can make the same calculation\quext{I did not. Check and send me a message saying if it works or not.} for \( e^*_{\wedge I}\big( \tau^{-1}_{\alpha,s}(X_1),\ldots,\tau_{\alpha,s}^{-1}(X_k) \big)\) using the fact that
		\begin{equation}
			e^*_i\big( \tau_{\alpha,s}(X_j) \big)=e^*_i\big( \sum_lX_{jl}e_l \big)=X_{ji}.
		\end{equation}
		\spitem[For \ref{ITEMooQUZCooGcJrLe}]
		%-----------------------------------------------------------
		Using the linearity of \( \tau_{\alpha,s}\) and point \ref{ITEMooSVEFooBKhHnc}.
	\end{subproof}
\end{proof}

\begin{lemma}		\label{LEMooOLSHooZNRoZs}
	Let \( \omega\in \Omega^k(M)\). There exists a smooth \(\omega' \colon U_{\alpha}\to \Wedge^k(\eR^n)^*  \) such that
	\begin{equation}
		\omega_{\varphi_{\alpha}(s)}=\Big( \varphi_{\alpha}(s),\tau_{\alpha,s}\big( \omega'(s) \big) \Big).
	\end{equation}
\end{lemma}

\begin{proof}
	Saying that the map \(\omega \colon M\to M\times \Wedge^kT^*M  \) is smooth means that the map \( f=\sigma_{\beta}^{-1}\circ \omega\circ\varphi_{\alpha}\) is smooth as map from \( U_{\alpha}\) to \( U_{\beta}\). In particular with \( \beta=\alpha\) we are looking at \( f(s)=(\sigma_{\alpha}^{-1}\circ \omega\circ \varphi_{\alpha})(s)\):
	\begin{subequations}
		\begin{align}
			f(s) & = \sigma_{\alpha}^{-1}\big( (\omega\circ \varphi_{\alpha})(s) \big) \\
			     & = \sigma_{\alpha}^{-1}\big( \varphi_{\alpha}(s),\xi(s) \big)        \\
			     & = \big( s,\omega'(s) \big)
		\end{align}
	\end{subequations}
	for some \( \xi(s)\in \Wedge^k(T^*_{\varphi_{\alpha}(s)})\) and \( \omega'(s)\in \Wedge^k(\eR^n)^*\). Since \( f\) is smooth, the map
	\begin{equation}
		\omega' \colon U_{\alpha}\to \Wedge^k(\eR^n)^*
	\end{equation}
	is smooth. From the definition of \( f\),
	\begin{equation}
		(\omega\circ \varphi_{\alpha})(s)=(\sigma_{\alpha}\circ f)(s)=\sigma_{\alpha}\big( s,\omega'(s) \big)=\Big( \varphi_{\alpha}(s),\tau_{\alpha,s}\big( \omega'(s) \big) \Big).
	\end{equation}
	We proved that
	\begin{equation}		\label{EQooMAINooBKsaex}
		(\omega\circ \varphi_{\alpha})(s)=\Big( \varphi_{\alpha}(s),\tau_{\alpha,s}\big( \omega'(s) \big) \Big).
	\end{equation}
\end{proof}

\begin{proposition}		\label{PROPooFWEQooIqTFSa}
	If \(\omega \colon U_{\alpha}\to \Wedge^k(\eR^n)^*  \) is smooth, then the map
	\begin{equation}
		\begin{aligned}
			f\colon U_{\alpha} & \to \Wedge^k\big( T^*_{\varphi_{\alpha}(s)}M \big) \\
			s                  & \mapsto \tau_{\alpha,s}\big( \omega(s) \big)
		\end{aligned}
	\end{equation}
	is smooth.
\end{proposition}

\begin{proof}
	Proposition \ref{PROPooDXTOooKYDOiI} says that there exist smooth functions \(\omega_I \colon U_{\alpha}\to \eR  \) such that
	\begin{equation}
		\omega(s)=\sum_{I\in C_k}\omega_I(s)e^*_{\lambda I}.
	\end{equation}
	Thus
	\begin{equation}
		\tau_{\alpha,s}\big( \omega(s) \big)=\sum_{I\in C_k}\omega_I(s)\partial^*_{\wedge I}.
	\end{equation}
	The functions \( \omega_I\) are smooth as well as \( \partial_{\wedge I}^*\) (lemma \ref{LEMooIAASooDnnhRA}).
\end{proof}

The following definition is in the same spirit of definition \ref{DEFooFWIHooJiTnwM}.
\begin{definition}		\label{DEFooZMQNooRNhWXk}
	Let \( \omega'\in \Wedge^k(\eR^n)^*\), \( p=\varphi_{\alpha}(s)\in M\) and \( X\in T_pM\). We define \( i_X(\omega)\) by
	\begin{equation}
		i_X(\omega)(X_1,\ldots,X_{k-1})=\omega(X,X_1,\ldots,X_{k-1}).
	\end{equation}

	Let \( X\) be a smooth vector field and \( \omega\) a smooth \( k\)-differential form. We defin \( i_X(\omega)\) for each \( p\in M\) by
	\begin{equation}
		i_X(\omega)_p=i_{X_p}(\omega_p).
	\end{equation}
\end{definition}

\begin{proposition}		\label{PROPooLCFAooLrbqeh}
	Let \( \omega'\in \Wedge^k(\eR^n)^*\), \( v\in \eR^n\) and \( p=\varphi_{\alpha}(s)\in M\). We have
	\begin{equation}
		\tau_{\alpha,s}\big( i_{v}(\omega') \big)=i_{\tau_{\alpha,s}(v)}\big( \tau_{\alpha,s}(\omega') \big).
	\end{equation}
\end{proposition}

\begin{proof}
	Using lemma \ref{LEMooMEZCooGXpOOa}\ref{ITEMooQUZCooGcJrLe} twice (once in each direction) we have
	\begin{subequations}
		\begin{align}
			i_v(\omega')(X_1,\ldots,X_{k-1}) & =i_v(\omega')\big( \tau_{\alpha,s}^{-1}(X_1),\ldots,\tau_{\alpha,s}^{-1}(X_{k_1}) \big)                                   \\
			                                 & =\omega'\big( v,\tau_{\alpha,s}^{-1}(X_1),\ldots,\tau_{\alpha,s}^{-1}(X_{k-1}) \big)                                      \\
			                                 & =\omega'\big( \tau_{\alpha,s}^{-1}\tau_{\alpha,s}(v),\tau_{\alpha,s}^{-1}(X_1),\ldots,\tau_{\alpha,s}^{-1}(X_{k-1}) \big) \\
			                                 & =(\tau_{\alpha,s}\omega')\big( \tau_{\alpha,s}(v),X_1,\ldots,X_{k-1} \big)                                                \\
			                                 & =i_{\tau_{\alpha,s}(v)}\big( \tau_{\alpha,s}(\omega') \big)(X_1,\ldots,X_{k-1}).
		\end{align}
	\end{subequations}
\end{proof}

\begin{lemma}[\cite{MonCerveau}]		\label{LEMooEKYDooKkgZJB}
	Let \(v \colon U_{\alpha}\to \eR^n  \) and \(\omega \colon U_{\alpha}\to \Wedge^k(\eR^n)^*  \) be smooth. Then the map
	\begin{equation}
		\begin{aligned}
			r\colon U_{\alpha} & \to \Wedge^{k-1}(\eR^n)^* \\
			s                  & \mapsto i_{v(s)}\omega(s)
		\end{aligned}
	\end{equation}
	is smooth.
\end{lemma}

\begin{proof}
	Notice that \( \Wedge^{k-1}(\eR^n)^*\) is a part of \( \End\Big( (\eR^n)^{k-1},\eR \Big)\), thus we can consider
	\begin{equation}
		r \colon U_{\alpha}\to \End\big( (\eR^n)^{k-1},\eR \big).
	\end{equation}
	If \( \omega(s)=\sum_{I=(i_1,\ldots,i_k)}(s)e^*_{\otimes I}\), proposition \ref{LEMooOBUVooBHpDZX} gives
	\begin{equation}
		r(s)=\sum_{J=(j_1,\ldots,j_{k-1})}\omega'_J(s)e^*_{\otimes J}
	\end{equation}
	with
	\begin{equation}
		\omega'_J=\sum_i\omega_{iJ}(s)v(s)_i.
	\end{equation}
	Thus we write
	\begin{equation}		\label{EQooQKQHooGXUzHY}
		r(s)=\sum_J\sum_i\omega_{iJ}(s)v(s)_ie^*_{\otimes J}.
	\end{equation}
	The map \( s\mapsto \omega_{iJ(s)}\) is smooth as well as \( s\mapsto v(s)_i\). The whole expression \eqref{EQooQKQHooGXUzHY} is smooth.
\end{proof}

\begin{propositionDef}[\cite{MonCerveau}]		\label{PROPooTBFLooVCqycE}
	Let \( X\) be a smooth vector field and \( \omega\) a smooth \( k\)-differential form. Then the map
	\begin{equation}
		i_X(\omega) \colon M\to \Wedge^k(T^*M)
	\end{equation}
	is smooth and is then a \( k\)-differential form.
\end{propositionDef}

\begin{proof}
	Let \( p=\varphi_{\alpha}(s)\in M\). We have, for some \( \omega'(s)\in \Wedge^k(\eR^n)^*\),
	\begin{subequations}
		\begin{align}
			\big( i_X(\omega) \big)_p & = i_{X_p}(\omega_p)                                                                                       \\
			                          & =i_{X_p} \tau_{\alpha,s}\big( \omega'(s) \big)                                                            \\
			                          & =\tau_{\alpha,s}\Big( i_{\tau_{\alpha,s}^{-1}}(X_p)\omega' \Big) & \text{prop. \ref{PROPooLCFAooLrbqeh}.}
		\end{align}
	\end{subequations}
	Since \( \tau_{\alpha,s}\) is smooth by proposition \ref{PROPooFWEQooIqTFSa}, it remains to prove that the map
	\begin{equation}
		\begin{aligned}
			r\colon U_{\alpha} & \to \Wedge^{k-1}(\eR^n)^*                                           \\
			s                  & \mapsto i_{\tau_{\alpha,s}^{-1}(X_{\varphi_{\alpha}(s)})}\omega'(s)
		\end{aligned}
	\end{equation}
	is smooth. Since \( X\) is a smooth vector field, proposition \ref{PROPooXURIooYPytwa} says that we can write
	\begin{equation}
		X_{\varphi_{\alpha}(s)}=\sum_{i=1}^nX_i\big( \varphi_{\alpha}(s) \big)\partial_i
	\end{equation}
	for some smooth functions \(X_i \colon M\to \eR  \). With these notations we have
	\begin{equation}
		\tau_{\alpha,s}^{-1}(X_{\varphi_{\alpha}(s)})=\sum_i(X_i\circ \varphi_{\alpha,s})(s)e_i.
	\end{equation}
	The latter is smooth with respect to \( s\).
\end{proof}


%-------------------------------------------------------
\subsection{Interior product}
%----------------------------------------------------

In the algebraic setting (without regularity and manifolds), the interior product we introduced in definition \ref{DEFooFWIHooJiTnwM}, and we already had the Leibnitz rule in proposition \ref{PROPooYCRXooSOsqCb}. Recall: the we denote by \( \Omega^k(M)\) the space of \( k\)-differential forms on the smooth manifold \( M\). These are the sections of \( \Wedge^k(T^*M)\), see definition \ref{DEFooBRSSooWOgoov}.

\begin{proposition}[\cite{BIBooJMRFooTAhhcg}]		\label{PROPooIQIUooTDNJdB}
	Let \( X\) be a smooth vector field. Let \( \omega\in \Omega^k(M)\) and \( \eta\in \Omega^l(M)\) be \( k\) and \( l\) differential forms.

	Then we have
	\begin{equation}
		i_X(\omega\wedge \eta)=i_X(\omega)\wedge \eta+(-1)^k\omega\wedge i_X(\eta).
	\end{equation}
\end{proposition}

\begin{proof}
	For each \( p\in M\) we have
	\begin{subequations}
		\begin{align}
			\Big( i_X(\omega\wedge \eta) \Big)_p & = i_{X_p}(\omega_p\wedge \eta_p)                                                                                         \\
			                                     & = i_{X_p}(\omega_p)\wedge\eta_p+(-1)^k\omega_p\wedge(i_{X_p}\eta)                & \text{prop. \ref{PROPooYCRXooSOsqCb}} \\
			                                     & = \Big( i_X(\omega)\wedge \eta \Big)_p+(-1)^k\Big( \omega\wedge i_X\eta \Big)_p.
		\end{align}
	\end{subequations}
\end{proof}


%-------------------------------------------------------
\subsection{Exterior derivative}
%----------------------------------------------------

\begin{proposition}[exterior derivative\cite{MonCerveau,BIBooANSPooJQsBvY}]		\label{PROPooTXFRooMtaVrU}
	There exists a unique map \(d \colon \Omega^k(M)\to \Omega^{k+1}(M)  \) such that
	\begin{enumerate}
		\item		\label{ITEMooPQYCooHMjgIR}
		      \( d\) is \( \eR\)-linear :  \( d(\lambda \omega)=\lambda d\omega\) and \( d(\omega+\eta)=d\omega+d\eta\) for every \( \lambda\in \eR\) and \( \omega,\eta\in \Omega^k(M)\).
		\item		\label{ITEMooRKJRooWwHUiS}
		      If \( f\in\Omega^0(M)=C^{\infty}(M)\), then \( df\) is the usual differential of \( f\).
		\item	\label{ITEMooBBFLooWpZJuT}
		      Leibniz rule : if \( \omega\in \Omega^k(M)\), we have \( d(\omega\wedge \eta)=(d\omega)\wedge\eta=(-1)^k\omega\wedge d\eta\)
		\item		\label{ITEMooJXMFooHFTFYi}
		      \( d(d\omega)=0\).
	\end{enumerate}
\end{proposition}

\begin{proof}
	First unicity, then existence.
	\begin{proofpart}
		Unicity
	\end{proofpart}
	We initiate by proving the unicity by showing that \( d\) has a fixed form in a chart. Let \( (U,\varphi)\) be a chart. From \ref{PROPooNOGKooQedJba} a generic differential form reads \( \omega_x=\sum_I\omega_I(x)\partial^*_{\wedge I}\).

	\begin{subproof}
		\spitem[\( d(\partial^*_{\wedge I})=0\)]
		%-----------------------------------------------------------
		Let \( I=(i_1,\ldots,i_k)\) and compute \( d(\partial^*_{\wedge I})\). We denote \( \omega=\partial^*_{i_1}\wedge\ldots\wedge\partial^*_{i_{k-1}}\) :
		\begin{subequations}
			\begin{align}
				d(\partial^*_{\wedge I}) & = d\big( \omega\wedge \partial^*_{i_{k}} \big)                                                                                    \\
				                         & = (d\omega)\wedge\partial^*_{i_{k}}+(-1)^{k-1}\omega\wedge d(\partial^*_{i_{k}}) & \text{by item \ref{ITEMooBBFLooWpZJuT}.}       \\
				                         & = d(\partial^*_{i_1}\wedge \ldots\partial^*_{i_{k-1}})\wedge\partial^*_{i_k}     & \text{see bellow}. \label{SUBEQooOWTHooIZcNWw}
			\end{align}
		\end{subequations}
		Justification for \eqref{SUBEQooOWTHooIZcNWw}. From lemma \ref{LEMooKCBSooPjEwEl}, \( \partial^*_{i_{k}}=df_{i_k}\), so that item \ref{ITEMooJXMFooHFTFYi} gives \( d(\partial^*_{i_{k+1}})=d(df_i)=0\).

		By recursion we have \( d(\partial^*_{\wedge I})=0\).
		\spitem[Computation of \( d(f\partial^*_{\wedge I})\)]
		%-----------------------------------------------------------
		From lemma \ref{LEMooUVRQooVZDKir} we use the wedge product \(  f\partial^*_{\wedge I}=f\wedge \partial^*_{\wedge I} \) and we can use the Leibniz formula of item \ref{ITEMooBBFLooWpZJuT} :
		\begin{equation}
			d(f\partial^*_{\wedge I})=d(f\wedge\partial^*_{\wedge I})=df\wedge \partial^*_{\wedge I}+f\wedge \underbrace{d(\partial^*_{\wedge I})}_{=0}=df\wedge\partial^*_{\wedge I}.
		\end{equation}
		\spitem[The general case]
		%-----------------------------------------------------------
		A general differential \( k\)-form \( \omega\) is given by proposition \ref{PROPooNOGKooQedJba} which is a real linear combination of elements of the form \( f\partial^*_{\wedge I}\).
		\begin{equation}		\label{EQooMGAVooCndFmv}
			d\omega=d\big( \sum_Ia_I\partial^*_{\wedge I} \big)=\sum_Ida_I\wedge \partial^*_{\wedge I}.
		\end{equation}
		\spitem[Unicity]
		%-----------------------------------------------------------
		If a map \( d\) satisfying all the conditions exists, it has to be of the form
		\begin{equation}
			d\big( \sum_Ia_I\partial^*_{\wedge I} \big)=\sum_Ida_I\wedge \partial^*_{\wedge I}
		\end{equation}
		on each coordinate patch. This proves the unicity.
	\end{subproof}
	\begin{proofpart}
		Local existence
	\end{proofpart}
	For each chart \( (U_{\alpha}, \varphi_{\alpha})\) we define the operators
	\begin{equation}
		\begin{aligned}
			d_{\alpha} \colon \Omega^k\big( \varphi_{\alpha}(U_{\alpha}) \big) & \to \Omega^{k+1}\big( \varphi_{\alpha}(U_{\alpha}) \big) \\
			\sum_Ia_I\partial^*_{\wedge I}                                     & \mapsto \sum_Ida_I\wedge\partial^*_{\wedge I},
		\end{aligned}
	\end{equation}
	and we prove that they satisfy the conditions.
	\begin{subproof}
		\spitem[Property \ref{ITEMooPQYCooHMjgIR}]
		%-----------------------------------------------------------
		We have
		\begin{equation}
			d(\lambda \omega)  =\big( \sum_I(\lambda a_I)\partial^*_{\wedge I} \big)
			=\sum_Id(\lambda a_I)\wedge\partial^*_{\wedge I}
			=\lambda\sum_Ida_I\wedge \partial^*_{\wedge I}.
		\end{equation}
		Same kind of computations for \( d(\omega+\eta)=d\omega+d\eta\).
		\spitem[Property \ref{ITEMooRKJRooWwHUiS}]
		%-----------------------------------------------------------
		If \( \omega\) is a \( 0\)-form, the expression \eqref{EQooMGAVooCndFmv} has no sum over \( I\) and reduces to \( \omega=f\).
		\spitem[Property \ref{ITEMooBBFLooWpZJuT}]
		%-----------------------------------------------------------
		Let \( \omega=\sum_{I\in C_k}a_I\partial^*_{\wedge I}\) and \( \eta=\sum_{J\in C_l}b_J\partial^*_{\wedge J}\). Since the wedge product is linear we can group the sums:
		\begin{equation}
			\omega\wedge \eta=\sum_I\sum_Ja_Ib_J\partial^*_{\wedge I}\wedge \partial^*_{\wedge J}.
		\end{equation}
		Using the product rule for usual differential, we have
		\begin{subequations}
			\begin{align}
				d_{\alpha}(\omega\wedge\eta) & =\sum_{I,J}d(a_Ib_J)\wedge(\partial^*_{\wedge I}\wedge \partial^*_{\wedge J})                                                                                                                               \\
				                             & =\sum_{I,J}b_J(da_I)\wedge(\partial^*_{\wedge I}\wedge \partial^*_{\wedge J})+\sum_{I,J}(a_Idb_J)\wedge(\partial^*_{\wedge I}\wedge \partial^*_{\wedge J})                                                  \\
				                             & =\sum_{I,J}(da_I\wedge \partial^*_{\wedge I})\wedge(b_J\partial^*_{\wedge J})+\sum_{I,J}a_I(-1)^k\partial^*_{\wedge I}\wedge db_J\wedge\partial^*_{\wedge J} & \text{cf. bellow}		\label{SUBEQooFXOAooCziZnU} \\
				                             & = d\omega\wedge\eta+(-1)^k\omega\wedge d\eta.
			\end{align}
		\end{subequations}
		For \eqref{SUBEQooFXOAooCziZnU}. In the first sum, the function \( b_J\) commutes with the operation \( \wedge\). In the second sum, the differential form \( db_J\) commutes with the wedge products giving a minus sign. This explains the \( (-1)^k\).
		\spitem[\( d(df)=0\)]
		%-----------------------------------------------------------
		Let \(f \colon M\to \eR  \) be a smooth function. Using lemma \ref{LEMooGEFSooVlPLOs}, we compute \( d_{\alpha}(df)\) :
		\begin{equation}
			d_{\alpha}(df)=\sum_i\sum_j(\partial_j\partial_if)\partial^*_j\wedge\partial^*_i.
		\end{equation}
		Since \( \partial_i\partial_if\) is symmetric with respect to \( i,j\) and \( \partial^*_j\wedge\partial^*_i\) is anti-symmetric with respect to \( i,j\), the sum is zero.
		\spitem[Property \ref{ITEMooJXMFooHFTFYi}]
		%-----------------------------------------------------------
		Let \( \omega=\sum_Ia_I\partial^*_{\wedge I}\). First we have
		\begin{equation}
			d_{\alpha}\omega=\sum_Ida_I\wedge\partial^*_{\wedge I}.
		\end{equation}
		Then
		\begin{equation}
			d_{\alpha}(d_{\alpha\omega})=\sum_I\underbrace{d(da_I)}_{=0}\wedge\partial^*_{\wedge I}-\sum_Ida_I\wedge \underbrace{d(\partial^*_{\wedge I})}_{=0}.
		\end{equation}
	\end{subproof}
	\begin{proofpart}
		Global existence
	\end{proofpart}
	By the unicity part, we have \( d_{\alpha}=d_{\beta}\) on the part \( \varphi_{\alpha}(U_{\alpha})\cap\varphi_{\beta}(U_{\beta})\). Thus the local formula
	\begin{equation}
		d\big( \sum_Ia_I\partial^*_{\wedge I} \big)  =\sum_Ida_I\wedge\partial^*_{\wedge I}
	\end{equation}
	globally defines \( d\).
\end{proof}


%-------------------------------------------------------
\subsection{Pull back}
%----------------------------------------------------

\begin{proposition}[\cite{BIBooJMRFooTAhhcg}]		\label{PROPooLEYOooJfPtmB}
	Let \( M\) and \( N\) be smooth manifolds. Let \(s \colon M\to N  \) be a smooth map. We consider charts \(\varphi \colon U\to M  \) and \(\psi \colon V\to N  \) where \( U\) and \( V\) are small enough to have
	\begin{equation}
		s\big( \varphi(U) \big)\subset \psi(V).
	\end{equation}
	If \( f\in C^{\infty}(N)\) we define
	We define \( s^*f\) by
	\begin{equation}
		(s^*f)(p)=(f\circ s)(p)
	\end{equation}
	for each \( p\in M\). If \( \omega\in \Omega^k(N)\) we define
	\begin{equation}		\label{EQooCQBJooQpJYUf}
		(s^*\omega)_p(X_1,\ldots,X_k)  = \omega_{s(p)}\big( ds_p(X_1),\ldots,ds_p(X_k) \big)
	\end{equation}
	for each \( p\in M\) and \( X_i\in T_pM\).

	With these definitions, we have
	\begin{equation}
		s^* \colon C^{\infty}(N)\to C^{\infty}(M)
	\end{equation}
	and
	\begin{equation}
		s^* \colon \Omega^k(N)\to \Omega^k(M).
	\end{equation}
\end{proposition}

\begin{proposition}		\label{PROPooHUDYooLCAYZW}
	Let \( s\in C^{\infty(M,N)}\), let \( g\in C^{\infty}(N)\). We consider
	\begin{enumerate}
		\item
		      A field of basis \( \{ e_i \}\) of \( TM\),
		\item
		      The dual field of basis \( \{ \alpha_i \}\) of \( T^*M\); that means that for each \( x\), the basis \( \{ (\alpha_i)_x \}\) of \( T^*_xM\) is the dual of the basis \( \{ (e_i)_x \}\) of \( T_xM\),
		\item
		      A field of basis \( \{ e'_i \}\) of \( TN\),
		\item
		      The dual basis \( \{ \beta_i \}\) of \( T^*N\).
	\end{enumerate}

	We have\footnote{As a side note, the fact that \( \det(ds)\) is smooth is the proposition \ref{PROPooYPLLooZaQEMx}.}
	\begin{equation}	\label{EQooWODAooMroYCO}
		s^*\big( g\beta_1\wedge\ldots\wedge \beta_n \big)=(s^*g)\big( \det(ds) \big)\alpha_1\wedge\ldots\wedge \alpha_n.
	\end{equation}
	where \( \det(ds)\) is the determinant of the matrix \( ds\) for the basis \( \{ e_i \}\) and \( \{ e'_i \}\).
\end{proposition}

\begin{proof}
	Let \( x\in M\). We apply the left hand side of \eqref{EQooWODAooMroYCO} to the field of basis \( \{ e_i \}\) :
	\begin{subequations}
		\begin{align}
			\Big( s^*(g\beta_1\wedge \ldots \wedge\beta_n) \Big)_x & (e_1,\ldots,e_n)                                                       \nonumber                                                     \\
			                                                       & =(g\beta_1\wedge \ldots\wedge \beta_n)_{s(x)}\big( ds_xe_1,\ldots,ds_xe_n \big)       & \text{def. \eqref{EQooCQBJooQpJYUf}}         \\
			                                                       & = (g\circ s)(x)(\beta_1\wedge\ldots \beta_n)_{s(x)}(ds_xe_1,\ldots,ds_xe_n)                                                          \\
			                                                       & = (s^*g)(x)\det\big( \beta_i(ds_xe_j) \big)                                           & \text{cf.justif.}		\label{SUBEQooVLMLooHPxZFR} \\
			                                                       & = (s^*g)(x)\det\Big( \beta_i\big( \sum_k(ds_x)_{kj}e'_k \big) \Big)                                                                  \\
			                                                       & = (s^*g)(x)\det\Big(  \sum_k(ds_x)_{kj}\underbrace{\beta_i(e'_k)}_{=\delta{ik}} \Big)                                                \\
			                                                       & = (s^*g)(x)\det(ds_x).
		\end{align}
	\end{subequations}
	Justifications.
	\begin{itemize}
		\item
		      For \eqref{SUBEQooVLMLooHPxZFR}. We used the proposition \ref{PROPooRRSZooJXOApq}. Formally we should write \( (\beta_i)_{s(x)}\) and \( (e_j)_x\), but we drop the indices.
	\end{itemize}
	Now we apply the right hand side at \( x\in M\) to \( (e_1,\ldots,e_n)\). Using again proposition \ref{PROPooRRSZooJXOApq}, we have
	\begin{equation}
		(\alpha_1\wedge\ldots\wedge \alpha_n)(e_1,\ldots,e_n)=\det\big( \alpha_i(e_j) \big)=\det(\delta_{ij})=1,
	\end{equation}
	thus
	\begin{equation}
		(s^*g)(x)\det(ds_x)(\alpha_1\wedge\ldots\wedge \alpha_n)(e_1,\ldots,e_n)=(s^*g)(x)\det(ds_x).
	\end{equation}

	By linearity, the equality still holds pointwise on a general element of \(  (T_xM)^n\).
\end{proof}


\section{Vector valued differential forms}	\label{SecVectValFiffFor}
%+++++++++++++++++++++++++++++++++++++++++++

Let $E$ be a vector bundle over $M$. A \defe{$E$-valued $p$-form}{vector-valued differential form}\index{differential!form!vector-valued} is a section
\[
	e\in\Gamma\big( E\otimes\Wedge^pT^*M \big).
\]
We denote by $\Omega(M,E)=\Gamma\big( E\otimes\Wedge^pT^*M \big)$\nomenclature[D]{$\Omega(M,E)$}{the set of $E$-valued differential forms} the set of $E$-valued differential forms. An element of $\Omega^1(M,E)=\Gamma\big( E\otimes\Wedge T^*M\big)$ always reads  $\sum_is_i\otimes\omega_i$ for some sections $s_i$ and usual differential forms $\omega_i$.

A form of $\Omega^p(M,E)$ can be seen as a fiber morphism $\underbrace{TM\otimes\cdots\otimes TM}_{p\text{ times}}\to E$ by associating
\[
	s\otimes\omega(X_1,\cdots,X_p)=s(x)\omega(X_1,\cdots,X_p)\in E_x
\]
to the element $(s\otimes \omega)\in\Omega^p(M,E)$. There exists a wedge product between vector-valued forms. If $e\in\Omega^p(M,E_1)$ and $f\in\Omega^q(M,E_2)$, then we define $e\wedge f\in\Omega^{p+q}(M,E_1\otimes E_2)$ by
\begin{equation}	\label{EqDefwedgevecor}
	(e\wedge f)(v_1,\cdots,v_{p+q})=\frac{1}{ p!q! }\sum_{\pi\in S_{p+q}}(-1)^{\pi} e(v_{\pi(1)},\cdots v_{\pi(p)})\otimes f(v_{\pi(p+1)},\cdots,v_{\pi(p+q)})\in E_1\otimes E_2.
\end{equation}
where $(-1)^{\pi}$ stands for the sign of the permutation $\pi$. For example when $e$, $f\in \Omega^1(M,E)$, we have
\[
	(e\wedge f)(X,Y)=e(X)\otimes f(Y)-e(Y)\otimes f(X)\in E\otimes E.
\]

When $M$ is a differentiable manifold, the \defe{fundamental $1$-form}{fundamental!$1$-form} is the element $\theta\in\Omega(M,TM)$ such that
\[
	\iota(X)\theta=X
\]
for every $X\in \Gamma(TM)$.

\subsection{A digression:  \texorpdfstring{$T_Y\yG$}{TYG} and \texorpdfstring{$\yG$}{G}}\label{subsec:digress}
%+++++++++++++++++++++++++++++++++++++++++++

We define two product: $G\times\yG\to TG$ and $\yG\times\yG\to\yG$. If $g\in G$ and $X\in\yG$, we put
\begin{subequations}
	\begin{equation} \label{eq_gXdefa}
		gX=\dsdd{ge^{tX}}{t}{0},
	\end{equation}
	and if $X$, $Y\in\yG$,
	\begin{equation}\label{eq:yGyGb}
		XY=\DDsdd{e^{tX}e^{uY}}{t}{0}{u}{0}.
	\end{equation}
\end{subequations}
We naturally define the product of a $\yG$-valued $1$-form $A$ by an element $g\in G$ by $(gA)v=gA(v)$.

Note that $gX$ does not belong to $\yG$ but to $T_{g}G$. Fortunately, in the expressions which we will meet, there will  always be a $g^{-1}$ to save the situation.

Let us give some precisions about derivatives as \eqref{eq:yGyGb}. We consider the expression
\[
	\frac{d}{du}\left( \left.\frac{d}{dt} c_u(t)\right|_{t=0}\right)_{u=0},
\]
which will be more simply written as:
\begin{equation}\label{eq:2307e1}
	\DDsdd{ c_u(t) }{u}{0}{t}{0}
\end{equation}
with $c_u(t)\in G$ for all $u,t$; $c_u(0)=e$ for all $u$ and $c_0'(0)=Y\in\yG$ where the prime stands for the derivative with respect of $t$. So $\dsdd{c_u(t)}{t}{0}\in\yG$ for each $u$ and \eqref{eq:2307e1} belongs to $T_Y\yG$. But we know that $\yG$ is a vector space, then $T_Y\yG\simeq\yG$, the isomorphism being given by the following idea: if $\{\partial_i\}$ is a basis of $\yG$ and $\{e_i\}$ the corresponding basis of $T_Y\yG$, we define the action of $A^ie_i\in T_Y\yG$ on $\dpt{f}{G}{\eR}$ by $(A^ie_i)f:=A^i\partial_if$.

\begin{lemma}
	Seen as an equality in $\yG$, for $\dpt{f}{G}{\eR}$ we have:
	\begin{equation}
		\DDsdd{c_u(t)}{u}{0}{t}{0}f=\DDsdd{f(c_u(t))}{u}{0}{t}{0}.
	\end{equation}
\end{lemma}

\begin{proof}
	Let us consider $X_u=X_u^i\partial_i=c_u'(0)$ and $X_0=Y$. We naturally have
	\begin{align}
		X_uf & =\dsdd{f(c_u(t))}{t}{0}, & \text{ and } &  & \dsdd{X_u}{u}{0}\in T_Y\yG.
	\end{align}
	Now, we consider a function $\dpt{h}{\yG}{\eR}$ and compute:
	\[
		\Dsdd{X_u}{u}{0}h=\Dsdd{h(X_u)}{u}{0}
		=\dsdd{ h(\Dsdd{c_u(t)}{t}{0}) }{u}{0}.
	\]
	If $\{\partial_i\}$ is a basis of $\yG$ and $\{e_i\}$, the corresponding one of $T_Y\yG$, thus
	\begin{equation}
		\Dsdd{X_u}{u}{0}h=\left.\dsd{h}{e_i}\right|_Y\DDsdd{c^i_u(t)}{u}{0}{t}{0}.
	\end{equation}
	So, we can write
	\[
		\Dsdd{X_u}{u}{0}=\DDsdd{c^i_u(t)}{u}{0}{t}{0}\left.\dsd{}{e_i}\right|_Y,
	\]
	and, as element of $\yG$, we consider
	\[
		\Dsdd{X_u}{u}{0}=\DDsdd{ c^i_u(t) }{u}{0}{t}{0}\partial_i|_e.
	\]
	Now, we can compute the action of $\dsdd{X_u}{u}{0}$ on a function $\dpt{f}{G}{\eR}$ as
	\begin{equation}
		\begin{split}
			\Dsdd{X_u}{u}{0}f&=\DDsdd{c^i_u(t)}{u}{0}{t}{0}\left.\dsd{f}{x^i}\right|_e\\
			&=\Dsdd{ \left.\dsd{f}{x^i}\right|_e\dsdd{c^i_u(t)}{t}{0}  }{u}{0}\\
			&=\Dsdd{ \dsdd{f(c_u(t))}{t}{0} }{u}{0}.
		\end{split}
	\end{equation}
	\begin{probleme}
		Je ne sais pas pourquoi tout d'un coup la dernière équation était commentée, et donc la phrase n'était pas finie.
	\end{probleme}

\end{proof}

Let us now see a great consequence of the definition \eqref{eq:yGyGb}
\begin{proposition} \label{prop:XY_YX}
	The formula
	\begin{equation}
		XY-YX=[X,Y].
	\end{equation}
	links the formal product inside the Lie algebra and the Lie bracket.
\end{proposition}

\begin{proof}
	From this, we can precise our definition of $XY$ when $X$, $Y\in\yG$. The product $XY$ acts on $\dpt{f}{G}{\eR}$ by
	\[
		(XY)f=\DDsdd{f(e^{tX}e^{uY})}{t}{0}{u}{0}.
	\]
	We can get a more geometric interpretation of this. We know how to build a left invariant vector field $\tilde Y$ from any $Y\in\yG$: for each $g\in G$ we just have to define
	\[
		\tY_g(f)=\Dsdd{f(gY(s))}{s}{0}.
	\]
	%
	First remark: $\tY_g$ is precisely the object that previously named ``$gY$''. In order to construct the basis blocks of the formula $XY-YX=[X,Y]$, we turn our attention to $\tX_e\tY$. It is clear that $\tY(f)$ is a function from $G$ to $\eR$, so we can apply $\tX_e$ on it. If $X_t$ is a path which gives the vector $\tX_e$ (for example: $X_t=e^{tX}$), we have
	\begin{equation}
		\tX_e(\tY(f))=\Dsdd{\tY(f)_{X_t}}{t}{0}\\
		=\DDsdd{f(X_tY(u))}{u}{0}{t}{0}\\
		=\DDsdd{f(e^{tX}e^{uY})}{u}{0}{t}{0}.
	\end{equation}
	Thus we have: $XY=\tX_e\tY$, but it is clear that $[\tX,\tY]_e=\tX_e\tY-\tY_e\tX$. The claim reads now: $[\tX,\tY]_e=[X,Y]$. We can actually take it as de \emph{definition} of $[X,Y]$. It is done in \cite{Helgason}. The link with the definition in terms of successive derivations of $\AD_g(x)=gxg^{-1}$ is not trivial but it can be done.
\end{proof}



Now, we can give a powerful definition of the wedge for two $\yG$-valued $1$-forms. If $A$, $B\in\Omega^1(M,\yG)$ and $v$, $w\in\cvec(M)$, we define
\begin{equation}
	(A\wedge B)(v,w)=A(v)B(w)-A(w)B(v).
\end{equation}
For $A^2$, we find back the usual definition:
\[
	(A\wedge A)(v,w)=A(v)A(w)-A(w)A(v)=[A(v),A(w)].
\]
%
One can see that for any section $\dpt{\salpha}{\mU_{\alpha}}{P}$, we have
\begin{equation}\label{eq:1907r2}
	\salpha^*(A\wedge A)=(\salpha^*A)\wedge(\salpha^*A).
\end{equation}


\begin{lemma}
	If $A$ and $B$ are two $\yG$-valued $1$-forms, one can make  ``simplifications'' as
	\begin{equation}
		(Ag)\wedge(g^{-1} B)=A\wedge B.
	\end{equation}
	\label{lem:simplif}
\end{lemma}

\begin{proof}
	We just have to prove that for $A$, $B\in\yG$, $(Ag)(g^{-1} B)=AB$ with definitions \eqref{eq_gXdefa} and \eqref{eq:yGyGb}. Remark that $Ag=\Dsdd{e^{sA}g}{s}{0}$, so
	\[
		e^{tAg}=\exp(t\dsdd{e^{sA}g}{s}{0})=\exp(\dsdd{e^{stA}g}{s}{0})=e^{tA}g.
	\]
	Therefore
	\[
		(Ag)(g^{-1} B)=\DDsdd{  e^{tAg}e^{ug^{-1} B}  }{t}{0}{u}{0}=\DDsdd{  e^{tA}gg^{-1} e^{uB}  }{t}{0}{u}{0}=AB.
	\]
\end{proof}

\begin{lemma}
	\begin{equation}
		F_{\beta}=dA_{\beta}+A_{\beta}^2.
	\end{equation}
\end{lemma}

\begin{proof}
	This is  a direct consequence of \eqref{eq:1907r2} and $[\sbeta^*,d]=0$.
\end{proof}

\section{Lie algebra valued differential forms}	\label{SecLiaAlgformval}
%+++++++++++++++++++++++++++++++++++++++++++++++++

An important particular case of vector valued forms is given by Lie algebra valued forms. That case appears for example in the connection theory over principal bundle\footnote{So in Maxwell and other gauge field theories.}. If $\omega$ and $\eta$ are elements of $\Omega^1(M,\mG)$ for some Lie algebra $\mG$, we define
\[
	(\omega\wedge\eta)(X,Y)=\omega(X)\otimes\eta(Y)-\omega(Y)\otimes\eta(X).
\]
Combining with the Lie bracket, we define\nomenclature[D]{$[\omega\wedge\eta]$}{Combination of the wedge product and the Lie bracket in the case of Lie algebra-valued forms}
\begin{equation}	\label{EqDefomegawedgebeta}
	[\omega\wedge\eta](X,Y):=[\omega(X),\eta(Y)]-[\omega(Y),\eta(X)].
\end{equation}
Using the proposition~\ref{prop:XY_YX}, we often implicitly transforms the tensor product into a product \eqref{eq:yGyGb} and put
\begin{equation}	\label{EqAbuswesgeomom}
	(\omega\wedge\omega)(X,Y)=[\omega(X),\omega(Y)].
\end{equation}
Let us point out the fact that that kind of formula only holds for a ``wedge square'', but not for a general product $\omega\wedge\eta$. Remark that for $\omega\in\Omega^1(M,\mG)$ and $\beta\in\Omega^2(M,\mG)$, a simple computation of definition \eqref{EqDefwedgevecor} yields
\begin{equation}	\label{EqomwedgebetaXYZ}
	(\omega\wedge\beta)(X,Y,Z)=\omega(X)\otimes\beta(Y,Z)-\omega(Y)\otimes\beta(X,Z)+\omega(Z)\otimes\beta(X,Y),
\end{equation}
so that, using the same trick as for equation \eqref{EqAbuswesgeomom}, we find
\[
	(\omega\wedge\beta-\beta\wedge\omega)(X,Y,Z)=[\omega(X),\beta(Y,Z)]-[\omega(Y),\beta(X,Z)]+[\omega(Z),\beta(X,Y)].
\]
But that expression is exactly what we find by exchanging the tensor product by Lie bracket in expression \eqref{EqomwedgebetaXYZ}. So we define
\begin{equation}	\label{EqDefCrochwedgedeux}
	[\omega\wedge\beta]=\omega\wedge\beta-\beta\wedge\omega
\end{equation}
when $\omega\in\Omega^1(M,\mG)$ and $\beta\in\Omega^2(M,\mG)$. The reader should remark that this is what one would expect from generalisation of definition \eqref{EqDefomegawedgebeta}.
\section{Principal bundle}
%+++++++++++++++++++++++++

Let $M$ be a manifold and $G$, a Lie group whose unit is denoted by $e$. A $G$-\defe{principal bundle}{principal!bundle}\index{bundle!principal} on $M$ is a smooth manifold $P$, a smooth map $\dpt{\pi}{P}{M}$ and a right action of $G$ on $P$ denoted by $\xi\cdot g$ with $g\in G$ and $\xi\in P$ such that

\begin{itemize}
	\item $\pi(\xi\cdot g)=\pi(\xi)$,
	\item $\forall \xi\in\pi^{-1}(x)$, $\pi^{-1}(x)=\{\xi\cdot g\tq g\in G\}\simeq G$,
	\item $\forall x\in M$, there exists a neighbourhood $\mU_{\alpha}$ of $x$ in $M$, a diffeomorphism $\dpt{\phi_{\alpha}}{\pi^{-1}(\mU_{\alpha})}{\mU_{\alpha}\times G}$ and a diffeomorphism $\dpt{\phi_{\alpha x}}{P}{G}$ such that

	      \begin{itemize}
		      \item $\phi_{\alpha}(\xi)=(x,\phi_{\alpha x}(\xi))$,
		      \item $\phi_{\alpha x}(\xi\cdot g)=\phi_{\alpha x}(\xi)\cdot g$.
	      \end{itemize}
\end{itemize}
The group $G$ is often called the \defe{structure group}{structure!group}. We suppose that the action is effective. We will sometimes use the notation $P(G,M)$ to precise that $P$ is a principal bundle over $M$ with structure group $G$.

\begin{lemma}\label{lem:phixh}
	The map $\phi_{\alpha}^{-1}$ fulfills
	\[
		\phi\alpha^{-1}(x,h)\cdot g=\phi_{\alpha}^{-1}(x,hg).
	\]
\end{lemma}

\begin{proof}

	From the definition of a principal bundle, any $\xi\in P$ can be written under the form $\xi=\phi_{\alpha}^{-1}(x,\phi_{\alpha x}(\xi))$ with $\phi_x$ satisfying $\phi_x(\xi\cdot h)=\phi_x(\xi)h$ for a certain function $\dpt{\phi_x}{P}{G}$.  We consider in particular $\xi=\phi_{\alpha}^{-1}(x,h)\cdot g$. Then $\xi\cdot g^{-1}=\phi_{\alpha}^{-1}(x,h)$. But $\xi\cdot g^{-1}=\phi_{\alpha}^{-1}(x,\phi_{\alpha x}(\xi)g^{-1})$, then $h=\phi{\alpha_x}(\xi)g^{-1}$ and $\phi_{\alpha x}(\xi)=hg$. So we have
	\[
		\xi=\phi_{\alpha}^{-1}(x,h)\cdot g=\phi_{\alpha}^{-1}(x,\phi_{\alpha x}(\xi))=\phi_{\alpha}^{-1}(x,hg).
	\]

\end{proof}

Let
\[
	R=\{ (x,y)\in P\times P\tq x=y\cdot g\,\textrm{ for a certain $g\in G$}  \}.
\]

\begin{proposition}
	The function $\dpt{u}{R}{G}$ defined by the condition
	\[
		p\cdot u(p,q)=q.
	\]
	is differentiable.
\end{proposition}

\begin{proof}
	Let $\mU$ be an open subset of $M$ and $\dpt{\sigma}{\mU}{P}$, a section. We consider a differentiable map $\dpt{\rho}{\pi^{-1}(\mU)}{G}$ such that $\rho(\xi\cdot g)=\rho(\xi)\cdot g$ and $\rho(\sigma(x))=e$. Such a map is given by
	\[
		\rho(\xi)=\phi_x(\sigma(x))^{-1}\phi_x(\xi)
	\]
	where $x=\pi(\xi)$. We naturally define $R_{\mU}=R\cap( \pi^{-1}(\mU)\times\pi^{-1}(\mU) )$ and we pick $(\xi,\eta)\in R_{\mU}$. Let $s\in G$ be the one such that $\xi\cdot s=\eta$, so that $\rho(\xi)\cdot s=\rho(\eta)$. Then the restriction of $u$ to $R_{\mU}$ is given by $u(\xi,\eta)=\rho(\xi)^{-1}\rho(\eta)$ which makes $u|_{\mU}$ differentiable. Since this reasoning can be made on every chart open $\mU$, $u$ is differentiable everywhere on $P$.
\end{proof}

The following is a corollary of Leibnitz rule, proposition~\ref{Leibnitz}.
\begin{corollary}  \label{cor_PrincLeib}
	If $P$ is a $G$-principal bundle and $v$, $a$ are curves in $P$ and $G$ respectively, we can consider the curve $u(t)=v(t)a(t)$. We have:
	\[
		\dsdd{u(t)}{t}{0}=\dsdd{v(t)a(0)}{t}{0}+\dsdd{v(0)a(t)}{t}{0}.
	\]
\end{corollary}
The proof is direct. This result is often written as
\begin{equation}
	\dot{u}_t=\dot{v}_ta_t+v_t\dot{a}_t.
\end{equation}
A main application is
\begin{equation}\label{eq:rdotht}
	\Dsdd{ r\cdot h(t) }{t}{0}=\Dsdd{r\cdot e^{th'(0)}}{t}{0}.
\end{equation}

\subsection{Transition functions}
%--------------------------------


Let $(\mU_{\alpha},\phi_{\alpha})$ be a local trivialization of $P$. This induces transition functions $\dpt{g\bab}{\mU_{\alpha}\cap\mU_{\beta}}{G}$ defined by
\begin{equation}
	\begin{aligned}
		\phi_{\alpha}\circ\phi_{\beta}^{-1}\colon \mU_{\alpha}\cap\mU_{\beta}\times G & \to \mU_{\alpha}\cap\mU_{\beta}\times G       \\
		(x,a)                                                                         & \mapsto (x,g\bab(x)a).\label{eq:transi_princ}
	\end{aligned}
\end{equation}
Clearly, $g_{\alpha\alpha}=e$ and $g\bab g_{\alpha\beta}=e$ on $\mU_{\alpha}\cap\mU_{\beta}$. Then the triviality
\[
	\phi_{\alpha}\circ\phi_{\beta}^{-1}\circ\phi_{\beta}\circ\phi\bgamma^{-1}\circ\phi\bgamma\circ\phi_{\alpha}^{-1}=\id
\]
implies the compatibility conditions
\begin{equation}
	g\bab g_{\beta\gamma} g_{\gamma\alpha}=e
\end{equation}
on $\mU_{\alpha}\cap\mU_{\beta}\cap\mU\bgamma$.

There is an inverse construction. Let $\{\mU_{\alpha}\tq\alpha\in I\}$ be an open covering of $M$ and $\dpt{g\bab}{\mU_{\alpha}\cap\mU_{\beta}}{G}$ a family of functions such that $g_{\alpha\alpha}=e$, $g\bab g_{\alpha\beta}=e$ on $\mU_{\alpha}\cap\mU_{\beta}$ and $g\bab g_{\beta\gamma}g_{\gamma\alpha}=e$ on $\mU_{\alpha}\cap\mU_{\beta}\cap\mU\bgamma$. Then the following construction gives a $G$-principal bundle whose transition functions are the $g\bab$'s.

\begin{itemize}
	\item $\tilde{P}=\bigsqcup_{\alpha\in I}\mU_{\alpha}\times G$  (disjoint union),
	\item if $(x,a)\in\mU_{\alpha}\times G$ and $(y,b)\in\mU_{\beta}\times G$, then $(x,a)\sim(y,b)$ if and only if $x=y$ and $b=g\bab(x)a$,
	\item $\dpt{\pi}{\tilde{P}}{M}$ is defined by $\pi[(x,a)]=x$ where $[(x,a)]$ is the class of $(x,a)$ for~$\sim$,
	\item the action is defined by $[(x,a)]\cdot g=[(x,ag)]$.
\end{itemize}

\begin{theorem}
	Let $G$ be a Lie group; $M$, a differentiable manifold; $\{\mU_{\alpha}\}_{\alpha\in I}$, an open covering of $M$ and some functions $\dpt{\varphi\bab}{\mU_{\alpha}\cap\mU_{\beta}}{G}$ such that $\varphi\bab(x)=\varphi_{\alpha\gamma}(x)\varphi_{\gamma\beta}(x)$. Then there exists a principal bundle $P$ whose transition functions are the $\varphi_{\alpha}$'s for the covering $\{\mU_{\alpha}\}_{\alpha\in I}$.
\end{theorem}

\begin{proof}
	We consider the topological space
	\begin{equation}
		E=\bigcup_{\alpha\in I}(G\times\mU_{\alpha}\times I)
	\end{equation}
	where we put the discrete topology on $I$. Each $G\times\mU_{\alpha}\times\{\alpha\}$ is a manifold. Thus $E$ has a structure of differentiable manifold induced from the one of $G\times M$. We consider on $E$ the equivalence relation given by the following subset of $E\times E$:
	\[
		R=\left\{\big(  (g,x,\alpha),(h,y,\beta)\big)\in E\times E\tq y=x\text{ and }  h=\varphi_{\alpha\beta}(x)g \right\}.
	\]
	We will show that $P=E/R$ has a structure of principal bundle. We begin by defining an action of $G$ on $P$ by
	\[
		[ (g,x,\alpha)\cdot h ]=[ (gh,x,\alpha) ].
	\]
	In order to see that this definition is correct, let us consider $[g',x,\beta]=[g,x,\alpha]$. From the definition of the equivalence class, $g'=\varphi_{\alpha\beta}(x)g$. Then $[(g',x,\beta)]\cdot h=[(\varphi_{\alpha\beta}(g)gh,x,\beta)]$, and the form of $R$ shows that this is well $[(gh,x,\alpha)]$. Since the map $(g,h)\to gh$ is differentiable on $G$, the so defined action is a differentiable action of $G$ on $P$ and $G$ is a transformation group on $P$\quext{Faut voir comment ça correspond à la définition de l'autre texte.}.

	If $[(g,x,\alpha)]=[(gh,x,\alpha)]$, then $gh=\varphi_{\alpha\alpha}g=g$ and $h=e$. So the action is effective.

	Now we consider the quotient $P/G$. A typical element is
	\[
		\overline{ (s,x,i) }=\{ [s,x,i]\cdot g\tq g\in G \}.
	\]
	The projection $\dpt{\pi}{P}{M}$, $[(s,x,\alpha)]\to x$ is well defined and we can consider $\dpt{\varphi}{P/G}{M}$, $\varphi\overline{(s,x,\alpha)}=x$. It provides a bijection between $P/G$ and $M$. So we can identify $P/G$ and $M$. Now we are going to show that $P$ endowed with the projection $\dpt{\pi}{P}{X}$ is a principal bundle.

	We consider the map
	\begin{equation}
		\begin{aligned}
			h_{\alpha} \colon G\times\mU_{\alpha} & \to P\
			(g,x)                                 & \mapsto \omega(g,x,\alpha)
		\end{aligned}
	\end{equation}
	%
	where $\dpt{\omega}{E}{P=E/R}$ is the canonical projection. Since
	\[
		(\pi\circ h_{\alpha})(g,x)=(\pi\circ\omega)(g,x,\alpha)=\pi[(g,x,\alpha)]=x,
	\]
	the map $h_{\alpha}$ actually is $\dpt{h_{\alpha}}{G\times\mU_{\alpha}}{\pi^{-1}(\mU_{\alpha})}$. In order to see that $h_{\alpha}$ is surjective on $\pi^{-1}(\mU_{\alpha})$, let us take a general element of $\pi^{-1}(\mU_{\alpha})$ under the form $\omega(g,x,\beta)$ with $x\in\mU_{\alpha}\cap\mU_{\beta}$. Then $(g,x,\beta)\in[ (\varphi\bab(x)g,x,\alpha) ]$ and therefore $\omega(g,x,\beta)=h_{\alpha}(\varphi\bab(x)g,x)$. For the injectivity, remark that $\omega(g,x,\beta)=\omega(h,y,\alpha)$ implies $x=y$ and $h=\varphi_{\beta\beta}(x)g=g$. In particular, $h_{\alpha}(g,x)=h_{\alpha}(h,y)$ implies $x=y$ and $g=h$.

	Now we will prove that the inverse of $h_{\alpha}$ is continuous. For this we consider an open set $\Omega\subset G\times\mU_{\alpha}$ and we have to show that $h_{\alpha}(\Omega)$ is open in $\pi^{-1}(\mU_{\alpha})$.

	We recall the \defe{quotient topology}{topology!quotient}: if $A$ is a topological space with an equivalence relation $\sim$ and the canonical projection $\dpt{\varphi}{A}{A/\sim}$, then $V\subset A/\sim$ is open if and only if $\varphi^{-1}(V)\subset A$ is open. So in our case, we have to check the openness of $V=\omega^{-1}( h_{\alpha}(\Omega) )$ in $E$. We consider the open covering
	\[
		\{ G\times\mU_{\alpha}\times\{\alpha\} \}_{\alpha\in I}
	\]
	of $E$ and we will show that the intersection of $V$ with any of these open set is open. We have to show that
	$\omega^{-1}\big(  h_{\alpha}(\Omega)\cap (G\times\mU_{\alpha}\times\{\beta\})  \big)$ is open for any $\beta\in I$. For this, we define a map $\dpt{\alpha}{G\times(\mU_{\alpha}\cap\mU_{\beta})\times\{\beta\}}{G\times\mU_{\alpha}}$ by
	\begin{equation}
		\alpha_{\beta}(g,x,\beta)=(\varphi\bab(x)g,x)
	\end{equation}
	which is continuous. The set $(h_{\alpha}\circ\alpha_{\beta})^{-1}(h_{\alpha}(\Omega))=\alpha^{-1}_{\beta}(\Omega)$ is open because $h_{\alpha}\circ\alpha_{\beta}$ is the restriction of $\omega$ to $G\times (\mU_{\alpha}\cap\mU_{\beta})\times\{\beta\}$. Then $h_{\alpha}$ is an homeomorphism from $G\times\mU_{\alpha}$ tp $\pi^{-1}(\mU_{\alpha})$. Since it is build from differentiable functions, it is moreover a diffeomorphism.

	So we have a chart system $\{ (h_{\alpha},\mU_{\alpha}) \}_{\alpha\in I}$ where $h_{\alpha}$ fulfils the ``good'' properties with respect to $\pi$. It remains to be proved that the $\varphi\bab$'s are the transition functions and that $\pi^{-1}(\pi(\xi))=\xi\cdot G$ for every $\xi\in P$. We begin by the latter. For $\xi=[(g,x,\alpha)]$, $\pi(\xi)=x$ and we have to study the set
	\[
		\pi^{-1}(x)=\{ [(h,x,\beta)]\tq h\in G,\beta\in I \}.
	\]
	Clearly, $[(h,x,\beta)]\cdot G\subset\pi^{-1}(x)$. The fact that there is nothing else than $[(h,x,\beta)]\cdot G$ in $\pi^{-1}(x)$ is seen by
	\[
		[h,x,\beta]=[\varphi\bab(x)g,x,\alpha]\in[(h,x,\alpha)]\cdot G.
	\]

	In order to check the change of charts, let us consider $g'=h_{\beta,x}^{-1}\circ h_{\alpha,x}(g)$ where
	\begin{equation}
		h_{\alpha,x}(g)=h_{\alpha}(g,x)=\omega(g,x,\alpha).
	\end{equation}
	The fact that $h_{\beta}(g',x)=g_{\alpha}(g,x)$ concludes the proof. To see this fact, remark that $h_{\beta,x}(h^{-1}_{\beta,x}\circ h_{\alpha,x}(g))=h_{\alpha,x}(g)$, so that $h_{\alpha}(g',x)=h_{\alpha}(g,x)$ implies $\omega(g',x,\beta)=\omega(g,x,\alpha)$ which proves that $g'=\varphi\bab(g)$.
\end{proof}

The \defe{trivial bundle}{trivial!principal bundle} is simply $P=M\times G$ and $\pi(x,g)=x$ with the action $(x,a)\cdot g=(x,ag)$.

\subsection{Morphisms and such\texorpdfstring{\ldots}{...}}
%----------------------------------

An \defe{homomorphism}{homomorphism!of principal bundle} between $P(G,M)$ and $P'(G',M')$ is a differentiable map $\dpt{h}{P}{P'}$ such that $\forall \xi\in P,g\in G$,
\begin{equation}\label{eq:def_princ_homo}
	h(\xi\cdot g)=h(\xi)\cdot h_G(g)
\end{equation}
where $\dpt{h_G}{G}{G'}$ is a Lie group homomorphism. From the definition, $h$ maps a fiber to only one fiber, but it is not specially surjective on any fiber. So $h$ induces a homomorphism $\dpt{h_M}{M}{M'}$ such that $\pi'\circ h=h_M\circ\pi$.

An \defe{isomorphism}{isomorphism!of principal bundle} is a homomorphism $\dpt{g}{P(G,M)}{P'(G',M')}$ such that

\begin{itemize}
	\item $h_P$ is a diffeomorphism $P\to P'$,
	\item $h_G$ is a Lie group homomorphism $G\to G'$, and
	\item $h_M$ is a diffeomorphism $M\to M'$.
\end{itemize}

A principal bundle is \defe{trivial}{trivial!principal bundle} if one can find an isomorphism $\dpt{h}{G\times M}{P}$ such that $\pi\circ h=\id\circ\pr_2$, i.e. the following diagram commutes:
\begin{equation}\label{diag:princ_triv}
	\xymatrix{ G\times M \ar[d]_{\pr_2} \ar[r]^h & P\ar[d]^{\pi} \\M \ar[r] _{\id}&M}
\end{equation}
We say that $P$ is \defe{locally trivial}{locally!trivial!principal bundle} if for every $x\in M$, there exists an open neighbourhood $\mU$ in $M$ such that $\pi^{-1}(\mU)$ endowed with the induced structure of principal bundle is trivial.

\subsection{Frame bundle: first}\label{pg:frame_bundle}
%--------------------------------

In the ideas, the building of a vector bundle is just to put a vector space on each point of the base manifold. A principal bundle is to put something on which a group acts on each point. If you have a vector bundle on a manifold, you can consider, on each point $x\in M$, the set of all the basis of the fiber $E_x$ over $x$. The group $GL(r,\eK)$ naturally acts on this set which becomes a candidate to be a $GL(r,\eK)$-principal bundle.

More formally, we consider a vector bundle $\dptvb{F}{p}{M}$, and for each $x$, the set of the basis of the vector space $F_x=p^{-1}(x)$. We define
\[
	P=\bigcup_{x\in M}(\textrm{basis of $F_x$}).
\]
We naturally consider the projection $\dpt{\pi}{P}{M}$, $\pi(b_x)=x$ if $b_x$ is a basis of $F_x$.

Let $\dpt{\phi^F_{\alpha}}{p^{-1}(\mU_{\alpha})}{\mU_{\alpha}\times\eK^r}$ be a local trivialization of $F$, and $\{\overline{e}_1,\ldots,\overline{e}_r\}$, the canonical basis of $\eK^r$. We naturally define
\[
	\ovS_{\alpha i}(x)=\phi^F_{\alpha}{}^{-1}(x,\overline{e}_i).
\]
The set $\{\ovS_{\alpha 1}(x),\ldots,\ovS_{\alpha r}(x)\}$ is a ``reference''{} basis of $F_x$ with respect to the trivialization $\phi_{\alpha}$. If we choose another basis $\{\ovv_1,\ldots\ovv_r\}$ of $F_x$, we can find a matrix $A\in GL(r,\eK)$ such that $\ovv_k=A^l_k\ovS_{\alpha l}(x)$. This gives a bijection
\begin{equation}
	\begin{aligned}
		\phi_{\alpha}^P\colon \pi^{-1}(\mU_{\alpha}) & \to \mU_{\alpha}\times GL(r,\eK) \\
		(\ovv_1,\ldots,\ovv_r)                       & \mapsto (x,A).
	\end{aligned}
\end{equation}
One can give to $P$ a $GL(r,\eK)$-principal bundle structure such that the $\phi_{\alpha}^P$ are diffeomorphism.

Let $(\mU_{\alpha},\phi_{\alpha}^F)$ be a local trivialization of  $F$ and $\dpt{g\bab^F}{\mU_{\alpha} \cap\mU_{\beta}}{GL(r,\eK)}$. In this case, $(\mU_{\alpha},\phi_{\alpha}^P)$ is a trivialization of $P$ whose transition function is $g\bab^P=g\bab^F$. Indeed
\[
	\phi_{\alpha}^P\circ\phi_{\beta}^P{}^{-1}(x,A)=\phi_{\alpha}^P(\{\ovv_1,\ldots,\ovv_r\})
\]
where $\ovv_s=(\phi^F_{\beta})^{-1}(x,A^l_s\overline{e}_l)$. In order to see it, recall that $\ovv_s=A^l_s\ovS_{\alpha l}(x)$ and that $\phi_{\alpha}^F{}^{-1}(x,\overline{e}_s)=\ovS_{\alpha s}(x)$. Then
\[
	\ovv_s=(\phi_{\beta}^F)^{-1}(x,A^l_s\overline{e}_l)=A^l_s\ovS_{\alpha s}(x).
\]
On the other hand, from the definition of $\phi_{\beta}^P$, the basis $(\phi_{\beta}^P)^{-1}(x,A)$ is the one obtained by applying $A$ on $S$. With all this,
\begin{equation}
	\begin{split}
		\phi_{\alpha}^P\circ(\phi_{\beta}^P)^{-1}(x,A)&=\phi_{\alpha}^P\{  (\phi_{\beta}^F)^{-1}(x,A^l_s\overline{e}_l)\}_{s=1,\ldots r}\\
		&=\phi_{\alpha}^P\{(\phi_{\alpha}^F)^{-1}\circ(\phi_{\alpha}^E\circ\phi_{\beta}^F{}^{-1})(x,A^l_s\overline{e}_l)  \}_{s=1,\ldots r}\\
		&=\phi_{\alpha}^P\{  (\phi^E_{\alpha})^{-1}(x,g\bab^F(x)^s_iA^l_s\overline{e}_l   ) \}_{i=1,\ldots r}\\
		&=(x,g^F\bab(x)A).
	\end{split}
\end{equation}
The last product $g^F\bab(x)A$ is a matricial product.

\subsection{Frame bundle: second} \label{subsec_frbundle}
%------------------------------

\subsubsection{Basis}\label{subsubsecframebundle}
%////////////////////////////////////////////////

If $M$ is a $m$-dimensional manifold, a \defe{frame}{basis!of $T_xM$} of $T_xM$ is an isomorphism $\dpt{b}{\eR^m}{T_xM}$. In our purpose, we will always deal with (pseudo)Riemannian manifold. So, the tangents spaces $T_xM$ comes with a metric, and we ask a frame to be isometric. In other words, we ask $b$ to be an isometry from $(\eR^m,\cdot)$ to $(T_xM,g_x)$, where the dot denotes the (pseudo)euclidian product on $\eR^m$. Such a frame is given by a base point $x$ of $M$ and a matrix $S$ in $\SO(g_x)$:
\begin{equation}
	\label{r1504e1}b(v)=(Sv)^i(\partial_i)_x,
\end{equation}
if the vector $v$ is written as $v=v^i\oui$ in the canonical orthogonal frame $\{\oui\}$ of $\eR^m$ and $\SO(g_x)$ is the set of the $m\times m$ matrix $A$ such that $A^tg_xA=g_x$.

This frame intuitively corresponds to the basis of $T_xM$ (see as a ``true''\ vector space) that we would have written by $\{Se_i\}_x$ if $e_i=\dsd{}{x^i}$. In order to follow this idea, we will effectively denote by $\baz{S}{x}$ the map $\dpt{b}{\eR^m}{T_xM}$ given by \eqref{r1504e1}.

We will often write the frame $b$ as $\baz{b}{x}$, making no differences in notation between the $b$ of $\SO(M)$ and the $b$ of $\SO(g_x)$ which implement it.

\begin{remark}
	One has to distinguish a \emph{frame} and a \emph{basis}: a basis is only a free and generating set while a frame can be interpreted as an ordered basis.
\end{remark}


\subsubsection{Construction}
%////////////////////////////

We just saw how to build a frame bundle over a manifold. One can get another expression of the frame bundle when we express a basis of $T_xM$ by means of an isomorphism between $\eR^n$ and $T_xM$. If $M$ is a $n$-dimensional manifold, a \defe{frame}{frame} at $x$ is an ordered basis
\[
	b=(\overline{ b }_1,\ldots,\overline{ b }_n)
\]
of $T_xM$. It is clear that any frame defines an isomorphism (linear bijective map)
\begin{equation}
	\begin{aligned}
		\tilde{b}\colon\eR^n & \to T_xM                 \\
		e_i                  & \mapsto \overline{ e_i }
	\end{aligned}
\end{equation}
where $\{e_i\}$ is the canonical basis of $\eR^n$. It is also clear that any isomorphism gives rise to a frame. Then we see a frame of $M$ at $x$ as an isomorphism $\dpt{\tilde{b}}{\eR^n}{T_xM}$. Let $B(M)_x$ be the of all the frames of $M$ at $x$; we define
\[
	B(M)=\bigcup_{x\in M}B(M)_x.
\]
For all $b\in B(M)_x$, we define $p_B(b)=x$ and the action $B(M)\times GL(n,\eR)\to B(M)$ by $b\cdot g=(\overline{ b }'_1,\ldots,\overline{ b }'_n)$ where
\begin{equation}
	\overline{ b }'_j=\overline{ b }_i\bghd{g}{i}{j}.
\end{equation}
It is easy to see that $\dpt{\widetilde{b\cdot g}=\tilde{b}\circ g}{\eR^n}{T_xM}$. So we can give to
\begin{equation}
	\xymatrix{
		GL(n,\eR)  \ar@{~>}[r] & B(M) \ar[d]^{p_B}\\& M
	}
\end{equation}
a structure of principal bundle\footnote{Much more details and proofs are given in \cite{Naber}.}. If $(\mU_{\alpha},\varphi_{\alpha})$ is a local coordinate chart on $M$, we define
\begin{equation}
	\begin{aligned}
		\tilde{\varphi} \colon p_B^{-1}(\mU_{\alpha}) & \to \varphi_{\alpha}(\mU_{\alpha})\times GL(n,\eR)\
		b                                             & \mapsto (\varphi_{\alpha}(x),A(b))
	\end{aligned}
\end{equation}
where $A(b)\in GL(n,\eR)$ is defined by the condition $\overline{ b }_j=\bghd{A}{j}{i}\partial_i|_x$. The matrix $A(b)$ is the one which transforms the canonical basis (in the trivialization $\varphi_{\alpha}$) into $b\in B(M)_x$. That's for the principal bundle structure.

The manifold structure of $B(M)$ is given by $\dpt{\Phi_{\alpha}}{p_B^{-1}(\mU_{\alpha})}{\mU_{\alpha}\times GL(\eR)}$,
\begin{equation}
	\begin{split}
		\Phi(b)&=(\varphi_{\alpha}^{-1}\times \id|_{GL(n,\eR)})\circ\tilde{\varphi}(b)\\
		&=(x,A(b))\\
		&=(p_B(b),A(b)).
	\end{split}
\end{equation}
It fulfils $A(b\cdot g)=A(b)\cdot g$. A section $\dpt{s}{\mU_{\alpha}}{B(M)}$ is sometimes called a \defe{moving frame}{moving frame}\index{frame!moving} over $\mU_{\alpha}$.

Frame bundle over $\eR^2$ is given as example in page \pageref{Pg_exempleRdeux}
%
% \subsection{Space-time}\label{subsec:space_time}
% %----------------------
%
%
% We say that the basis $\{\gb_0,\ldots,\gb_3\}$ of $T_xM$ is oriented, time oriented and orthonormal if $g(\gb_i,\gb_j)=\eta_{ij}$ (pointwise) and if $\gb_0$ is time-like and future directed. All this is devoted to build the frame bundle
%
%
% \[
% \xymatrix{
%     \Lpf  \ar@{~>}[r] & L(M) \ar[d]^{p_L} \\
%     &M.
%   }
% \]
%
% From discussion in \autoref{subsec:sym_nature}, we know that, in physics, the relevant group is \emph{not} the Lorentz group $\Lpf$, but $\SLdc$ . So we want to build a $\SLdc$-principal bundle which ``fit''{} as deeply as possible the bundle $L(M)$. It is done with a \defe{spin structure}{spin!structure} which is a principal bundle
%
% \[
% \xymatrix{
%     \SLdc  \ar@{~>}[r] & S(M) \ar[d]^{p_S} \\
%     &M.
%   }
% \]
% with a map $\dpt{\lambda}{S(M)}{L(M)}$ such that $p_L\circ\lambda=p_S$ and $\lambda(\xi\cdot g)=\lambda(\xi)\cdot\mSpin(g)$. See \autoref{sec:spin_str} and \autoref{sec:incl_Lorentz}.

\subsection{Sections of principal bundle}
%----------------------------------------

A \defe{section}{section!of principal bundle} of a $G$-principal bundle is a smooth map $\dpt{s}{M}{P}$ such that $s(x)\in\pi^{-1}(x)$ for any $x\in M$. A trivialization $\phi_{\alpha}^P$ $P$ on $\mU_{\alpha}$ defines a section of $P$ over $\mU_{\alpha}$ by
\[
	\sigma_{\alpha}(x)=(\phi_{\alpha}^P)^{-1}(x,e)
\]
where $e$ is the neutral of the group. In the inverse sense, we have the following:

\begin{proposition}
	If $\dpt{\sigma_{\alpha}}{\mU_{\alpha}}{P}$ is local section of $P$ over $\mU_{\alpha}\subset M$, then the definition $\phi_{\alpha}^P(\xi)=(x,a)$ if $\xi=\sigma_{\alpha}(x)\cdot a$ is a local trivialization.
\end{proposition}

\begin{proof}
	The function $\phi_{\alpha}^P$ is well defined because $\xi\in\pi^{-1}(\mU_{\alpha})$ implies the existence of a $x\in\mU_{\alpha}$ such that $\xi\in\pi^{-1}(x)=\{\xi\cdot g\}\simeq G$. For this $x$, there exists a $g\in G$ such that $\xi=\sigma_{\alpha}(x)\cdot g$.

	Now we prove that the couple $(x,a)$ is unique in the sense that $s_{\alpha}(x)\cdot a=\sigma_{\alpha}(y)\cdot b$ implies $(x,a)=(y,b)$. The left hand side belongs to $\pi^{-1}(x)$ while the right one belongs to $\pi^{-1}(y)$. Then $x=y$. The condition $\pi^{-1}(x)\simeq G$ imposes the unicity of the $g$ making $\xi=\eta\cdot g$ for each couple, $\xi,\eta\in\pi^{-1}(x)$.
\end{proof}

If $\sigma$ and $\sigma'$ are two sections of the same principal bundle $P$, then there exists a differentiable map $\dpt{f}{M}{G}$ such that $\sigma'(x)=\sigma(x)\cdot f(x)$. So all the sections can be deduced from only one and multiplication by such a $f$.

\begin{theorem}
	If $\dpt{\pi}{P(G,M)}{M}$ is a principal bundle, then the four following propositions are equivalent:
	\begin{enumerate}
		\item\label{enuymai} $P$ is trivial,
		\item\label{enuymaii} $P$ has a global section,
		\item\label{enuymaiii} there exists a differentiable map $\dpt{\gamma}{P}{G}$ such that $\gamma(\xi\cdot g)=g^{-1}\gamma(\xi)$ for all $\xi\in P$ and $g\in G$,
		\item\label{enuymaiv} there exists a differentiable map $\dpt{\rho}{P}{G}$ such that $\rho(\xi\cdot g)=\rho(\xi)g$.
	\end{enumerate}
	\label{ThoYPrincBTrivSect}
\end{theorem}

\begin{proof}
	\subdem{\ref{enuymai}$\Rightarrow$~\ref{enuymaii}}
	The diagram \eqref{diag:princ_triv} commutes and
	\begin{equation}
		\begin{aligned}
			\tau \colon M & \to G\times M\
			x             & \mapsto (e,x)
		\end{aligned}
	\end{equation}
	is a local section of $G\times M$. From it we build the following global section of $P$:
	\begin{equation}
		\begin{aligned}
			\sigma \colon M & \to P\
			x               & \mapsto h(e,x).
		\end{aligned}
	\end{equation}
	This is injective because $\pi\circ h=\pr_2$ and differentiable because this is a composition of $\xdp{x}{(e,x)}$ and $\xdp{(g,x)}{h(g,x)}$.
	\subdem{\ref{enuymaii}$\Rightarrow$~\ref{enuymai}}
	The principal bundle $P$ admits a global section $\dpt{\sigma}{M}{P}$. From it, we can build the differentiable map
	\begin{equation}
		\begin{aligned}
			h \colon G\times M & \to P\
			(g,x)              & \mapsto \sigma(x)\cdot g
		\end{aligned}
	\end{equation}
	which satisfies $h(gh,x)=h(g,x)\cdot h$ and $\pi\circ(g,x)=x$. First we show that $h$ is a fiber homomorphism and an isomorphism between $P$ and $G\times M$ so that $P$ is trivial. For this remark that
	\[
		g(gh,x)=g(g,x)\cdot h=\sigma(x)\cdot gh,
	\]
	hence equation \eqref{eq:def_princ_homo} reduces to $h( (g,x)\cdot h )=h(g,x)\cdot h_G(h)$ which is true with $h_G=\id$. Moreover $\dpt{h}{G\times M}{P}$ is bijective because $\sigma(\pi(\xi))$ belongs to the fiber of $\xi\in P$, therefore there is one and only one $\gamma(\xi)=u(\xi,\sigma(\pi(\xi)))$ such that $\xi\cdot\gamma(\xi)=(\sigma\circ\pi)\xi$. The inverse map is
	\begin{equation}
		\begin{aligned}
			\theta \colon P & \to G\times M\
			\xi             & \mapsto (\gamma(\xi),\pi(\xi))
		\end{aligned}
	\end{equation}
	which is differentiable because $\gamma$ and $\pi$ are. So far we see that $h$ and $h^{-1}$ are differentiable. Then $h$ is an isomorphism between $P$ and $G\times M$.

	\subdem{\ref{enuymaii}$\Rightarrow$~\ref{enuymaiii}}
	Let $\sigma$ be the global section and define
	\begin{equation}
		\begin{aligned}
			\gamma \colon P & \to G\
			\xi             & \mapsto u(\xi,(\sigma\circ\pi)\xi)
		\end{aligned}
	\end{equation}
	where $\dpt{u}{R}{G}$ is the map defined by the condition $\xi\cdot(\xi,\eta)=\eta$. The map $\gamma$ is differentiable and we have to prove that $\gamma(\xi\cdot g)=g^{-1}\gamma(\xi)$. Since $\xi\cdot \gamma(\xi)=\sigma\circ\pi(\xi)$,
	\[
		\gamma(\xi\cdot g)=u(\xi\cdot g,(\sigma\circ\pi)(\xi\cdot g))=u(\xi\cdot g,(\sigma\circ\pi)(\xi)).
	\]
	But $(\xi\cdot g)(g^{-1}\gamma(\xi))=\xi\cdot\gamma(\xi)=x$. So $\gamma(\xi\cdot g)=u(\xi\cdot g,x)$. Thus $\gamma(\xi\cdot g)=g^{-1}\gamma(\xi)$.

	\subdem{\ref{enuymaiii}$\Rightarrow$~\ref{enuymaii}}
	The given map $\gamma$ fulfils $\xi\cdot g\gamma(\xi\cdot g)=\xi\cdot(\xi)$, so
	\begin{equation}
		\begin{aligned}
			\varphi \colon P & \to P\
			\xi              & \mapsto \xi\cdot(\xi)
		\end{aligned}
	\end{equation}
	is just function of the class of $\xi$, thus we have a section $\dpt{\sigma'}{P/G}{P}$, but we know that $P/G$ and $M$ are isomorphic.

	\subdem{\ref{enuymaiii}$\Rightarrow$~\ref{enuymaiv}}
	Let us define $\dpt{\rho}{P}{G}$ by $\rho=J\circ\gamma$ with $J(g)=g^{-1}$, thus $\rho(\xi)=\gamma(\xi)^{-1}$ and
	\[
		\rho(\xi\cdot g)=\gamma(\xi\cdot g)^{-1}=(g^{-1}\gamma(\xi))^{-1}=\gamma(\xi)^{-1} g=\rho(\xi)g.
	\]
	\subdem{\ref{enuymaiv}$\Rightarrow$~\ref{enuymaiii}} The proof is just the same with $\rho=J\circ\rho$.
\end{proof}

\begin{definition}
	A section $\psi\in\Gamma(P,TP)$ is \defe{$G$-equivariant}{equivariant!vector field on principal bundle} when
	\[
		d\tau_{g}\psi(\xi)=\psi(\xi\cdot g).
	\]
	\label{DefEqVectPrinc}
\end{definition}
Be careful: this \emph{does not} define equivariant sections of the principal bundle.
\subsection{Equivalence of principal bundle}
%-------------------------------------------

Two principal bundles $\dpt{\pi}{P}{M}$ and $\dpt{\pi'}{P'}{M}$ are \defe{equivalent}{equivalence!of principal bundle} if there exists a diffeomorphism $\dpt{\varphi}{P}{P'}$ such that

\begin{itemize}
	\item  $\pi'\circ\varphi=\pi$
	\item $\varphi(\xi\cdot g)=\varphi(\xi)\cdot g$.
\end{itemize}

If $\{\mU_{\alpha}\}_{\alpha\in I}$ is an open covering of $M$ on which we have trivializations $\phi_{\alpha}$ of $P$ and $\psi_{\alpha}$ of $P'$, the diffeomorphism $\varphi$ induces some functions $\dpt{\lambda}{\mU_{\alpha}}{G}$ by setting
\[
	(\phi_{\alpha}\circ\varphi^{-1}\circ\psi_{\alpha}^{-1})(x,a)=(x,\lambda_{\alpha}(x)a).
\]
This definition works because from the definitions of principal bundle and equivalence, one sees that $(\phi_{\alpha}\circ\varphi^{-1}\circ\psi_{\alpha}^{-1})(x,\cdot)=(x,\cdot)$.

\subsubsection{Transition functions}
%///////////////////////////////////

We have some transition functions for $P$ and $P'$ given by equations
\[
	\begin{aligned}
		(\phi_{\alpha}\circ\phi_{\beta}^{-1})(x,g) & =(x,g\bab(x)g)   \\
		(\psi_{\alpha}\circ\psi_{\beta}^{-1})(x,g) & =(x,g'\bab(x)g).
	\end{aligned}
\]
Now, we want to know what is $g'\bab$ in function of $g\bab$. First remark that $(\psi_{\alpha}\circ\varphi\circ\phi_{\alpha}^{-1})(x,a)=(x,\lambda_{\alpha}(x)^{-1})a$, and next, compute
\begin{equation}
	\begin{split}
		(x,g\bab(x)a)a&=(\psi_{\alpha}\circ\varphi\circ\phi_{\beta}^{-1}\circ\phi_{\beta}\circ\varphi^{-1}\circ\psi_{\beta}^{-1})(x,a)\\
		&=(\psi_{\alpha}\circ\varphi\circ\phi_{\beta}^{-1})(x,\lambda_{\beta}(x)a)\\
		&=(\psi_{\alpha}\circ\varphi\circ\phi_{\alpha}^{-1}\circ\phi_{\alpha}\circ\phi_{\beta}^{-1})(x,\lambda_{\beta}(x)a)\\
		&=(x,\lambda_{\alpha}(x)^{-1} g\bab(x)\lambda_{\beta}(x)a).
	\end{split}
\end{equation}
Then
\begin{equation}
	g\bab(x)=\lambda_{\alpha}(x)^{-1} g\bab(x)\lambda_{\beta}.
\end{equation}
One can show that if two principal bundle have transition functions whose fulfill this condition, they are equivalent. A $G$-principal bundle is \defe{trivial}{trivial!principal bundle} if it is equivalent to the one given by $\dpt{\pi_1}{M\times G}{M}$.

\subsection{Reduction of the structural group}
%---------------------------------------------

We say that a principal bundle $P(G,M)$ is \defe{reducible}{reducible!principal bundle} when there exists a principal bundle $P'(H,M)$ such that

\begin{itemize}
	\item $H$ is a subgroup of $G$,
	\item there exists an homeomorphism $\dpt{h}{P'}{P}$ such that $\dpt{h_G}{H}{G}$ is an injective homomorphism.
\end{itemize}

In this case we say that $G$ is reducible to $H$ and that $P'$ is a reduced principal bundle.

\begin{theorem}
	If $P$ is a principal bundle over $M$, the structural group $G$ is reducible to the Lie subgroup $H$ if and only if there exists an open covering $\{ \mU_i \}_{i\in I}$ of $M$ and transition functions $\varphi_{ij}$ taking their values in $H$.
\end{theorem}
\begin{proof}
	No proof.
\end{proof}
The following comes from \cite{Dieu4}. Let us consider the principal bundle
\begin{equation}
	\xymatrix{%
		G \ar@{~>}[r]		&	P\ar[d]^{\pi_P}\\
		&	M
	}
\end{equation}
and $H$, a closed subgroup of $G$. We denote by $j\colon H\to G$ the inclusion map. The principal bundle
\begin{equation}
	\xymatrix{%
		H \ar@{~>}[r]		&	Q\ar[d]^{\pi_Q}\\
		&	M
	}
\end{equation}
is a \defe{reduction}{reduction of a principal bundle} of $P$ to the group $H$ if there exists a map $u\colon Q\to P$ such that $\pi_P\circ u=\pi_Q$ and $u(\xi\cdot h)=u(\xi)\cdot j(h)$. In this case, $u$ is an embedding\quext{plongement} of $Q$ in $P$ and the image is a closed submanifold of $P$.

Let $M$ be a $n$-dimensional manifold and $B(M)$ be its frame bundle. This is a $\GL(n,\eR)$-principal bundle. If $G$ is a closed subgroup\footnote{Typically $\SO(p,q)$ or $\SO_0(p,q)$.} of $\GL(n,\eR)$, a \defe{$G$-structure}{$G$-structure} is a reduction of $B(M)$ to $G$.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Density}
%---------------------------------------------------------------------------------------------------------------------------

A \defe{density}{density} on a $d$-dimensional manifold $M$ is a section of the principal bundle whose fiber $P_x$ over $x\in M$ is the space of homogeneous non vanishing maps
\begin{equation}
	\rho\colon \Wedge^dT_xM\to \eR^*_+
\end{equation}
such that $\rho(\lambda v)=| \lambda |\rho(v)$ for every $\lambda\in\eR$ and $v\in\Wedge^d T_xM$.


\section{Associated bundle}  \index{bundle!associated}
%++++++++++++++++++++++++++

Let $\dpt{\pi}{P}{M}$ be a $G$-principal bundle and $\dpt{\rho}{G}{GL(V)}$, a representation of $G$ on a vector space $V$ (on $\eK=\eR$ or $\eC$) of dimension $r$.

The associated bundle $\dptvb{E=P\times_{\rho} V}{p}{M}$ is defined as following. On $P\times V$, we consider the equivalence relation
\[
	(\xi,v)\sim(\xi\cdot g,\rho(g^{-1})v)
\]
for $g\in G$, $\xi\in P$ and $v\in V$. Then we define

\begin{itemize}
	\item $E=P\times_{\rho} V:=P\times V/\sim$,
	\item $p[(\xi,v)]=\pi(\xi)$
\end{itemize}
where $[(\xi,v)]$ is the class of $(\xi,v)$ in $P\times V$.

If $\phi^P_{\alpha}(\xi)=(\pi(\xi),a(\xi))$ is a  trivialization of $P$ on $\mU_{\alpha}$, then
\begin{equation}\label{eq:triv_P_E}
	\phi^E[(\xi,v)]=(\pi(\xi),\rho(a)v)
\end{equation}
is a trivialization of $E$.

In order to see that it is a good definition, let us consider $(\eta,w)\sim(\xi,v)$. It immediately gives the existence of a $g\in G$ such that $\eta=\xi\cdot g$ and $w=\rho(g^{-1})v$. Then $\phi^E[ (\xi\cdot g,\rho(g^{-1})v) ]=( \pi(\xi\cdot g),\rho(b)\rho(g^{-1})v )$.  From the definition of $\phi^E$, the vector $b$ is given by $\phi^P(\xi\cdot g)=( \pi(\xi\cdot g),b )$, and the definition of a principal bundle gives $b=\phi_{\pi(\xi)}(\xi\cdot g)=\phi_{\pi(\xi)}(\xi)\cdot g=ag$. The fact that $\rho$ is a homomorphism makes $\rho(ag)\rho(g^{-1})=\rho(a)v$ and $\phi^E$ is well defined.

Let $G$ be a Lie group, $\rho$ a representation of $G$ on $V$ and $M$, a manifold. We consider $\dptvb{P=M\times G}{\pr_1}{M}$, the trivial $G$-principal bundle on $M$. Then $\dptvb{E=P\times_{\rho}V}{p}{M}$ is \defe{trivial}{trivial!principal bundle}, i.e. we can build a $\dpt{\varphi}{P\times_{\rho} V}{M\times V}$ such that $\pr_1\circ\varphi=p$. It is rather easy: we define
\[
	\varphi\big[ \big((x,g),v\big) \big]=(x,\rho(g)v).
\]
It is easy to see that $(\pr_1\circ\varphi)[ (x,g),v ]=x$ and $p[(x,g),v]=\pr_1(x,g)=x$.

\subsection{Transition functions}
%--------------------------------

\begin{proposition}
	Let $(\mU_{\alpha},\phi_{\alpha}^P)$ be a trivialization of $\dptvb{P}{\pi}{M}$ whose transition functions are $\dpt{g\bab}{\mU_{\alpha}\cap\mU_{\beta}}{G}$. Then $(\mU_{\alpha},\phi^E_{\alpha})$ given by \eqref{eq:triv_P_E} is a local trivialization of $\dptvb{E}{p}{M}$ whose transition functions $\dpt{g\bab^E}{\mU_{\alpha}\cap\mU_{\beta}}{GL(\dim V,\eK)}$ are given by
	\[
		g\bab^E(x)=\rho(g\bab^P(x)).
	\]

\end{proposition}

\begin{proof}
	If we write $a:=\phi^E_{_{\beta} x}(\pi^{-1}(x))$, we have $\phi_{\beta}^P(\pi^{-1}(x))=(x,a)$ and $\phi_{\alpha}^E\circ(\phi_{\beta}^E)^{-1}(x,v)=\phi^E_{\alpha}[ (\pi^{-1}(x),\rho(a)^{-1} v) ]$. So,
	\begin{equation}
		\begin{split}
			\phi_{\alpha}^E[ (\pi^{-1}(x),\rho(a)^{-1} v) ]&=\Big(x,
			\rho\big(\phi_{\alpha x}(\pi^{-1}(x))\big)\rho\big(\phi_{\beta x}(\pi^{-1}(x))\big)^{-1} v   \Big)\\
			&=\Big(   x,\rho\big(\phi_{\alpha x}( \pi^{-1}(x) )\phi_{\beta x}( \pi^{-1}(x) )        \big)    \Big).
		\end{split}
	\end{equation}
	Then
	\begin{equation}
		g\bab^E=\rho\Big(  \phi_{\alpha x}( \pi^{-1}(x) )\phi_{\beta x}\big( \pi^{-1}(x) \big)  \Big)\\
		=\rho(g^P\bab(x)).
	\end{equation}

\end{proof}

\subsection{Sections on associated bundle}  \label{sec_fnequiv}
%-----------------------------------------

\subsubsection{Equivariant functions}

We consider a bundle $\dptvb{E=P\times_{\rho} V}{p}{M}$ associated with the principal bundle $\dptvb{P}{\pi}{M}$ and a section $\dpt{\psi}{M}{E}$.
\[
	\xymatrix{ P \ar[rd]_{\displaystyle\pi^P} &&
		E=P\times_{\rho} V \ar[ld]^{\displaystyle\pi^E} \\ & M }
\]
A \defe{section}{section!of an associated bundle} of $E$ is a map $\dpt{\psi}{M}{E}$ such that $\pi^E\circ\psi=id_M$. We define the function $\dpt{\hpsi}{P}{V}$ by
\begin{equation}\label{eq:equiv_psi}
	\psi(\pi(\xi))=[\xi,\hpsi(\xi)].
\end{equation}
Let us see the condition under which this equation well defines $\hpsi$. First, remark that a $\psi$ defined by this equation is a section because $p[\xi,v]=\pi(\xi)$, so that $(p\circ\psi)(\pi(\xi))=\pi(\xi)$. Now, consider a $\eta$ such that $\pi(\eta)=\pi(\xi)$. Then there exists a $g\in G$ for which $\eta\cdot g=\xi$. For any $g$ and for this one in particular,
\[
	\psi(\pi(\eta))=[\eta,\hpsi(\eta)]=[\eta\cdot g,\rho(g^{-1})\hpsi(\eta)].
\]
Then equation \eqref{eq:equiv_psi} defines $\hpsi$ from $\psi$ if and only if
\begin{equation}\label{eq:equiv_psi_b}
	\hpsi(\xi\cdot g)=\rho(g^{-1})\hpsi(\xi).
\end{equation}
This condition is called the \defe{equivariance}{equivariant} of $\hpsi$. Reciprocally, any equivariant function $\hpsi$ defines a section of $E=P\times_{\rho} V$.

If $\eta=\xi\cdot g=\chi\cdot k$, one define a sum
\begin{equation}\label{eq:def:som_E}
	[\xi,v]+[\chi,w]=[\eta,\rho(g)v+\rho(k)w].
\end{equation}
If $\dpt{\psi,\eta}{M}{E}$ are two sections defined by the equivariant functions $\dpt{\hpsi,\hat\eta}{P}{V}$, then the section $\psi+\eta$ is defined by the equivariant function $\hat\psi+\hat \eta$.

\subsubsection{For the endomorphism of sections of \texorpdfstring{$E$}{E}}\label{equivendo}
%////////////////////////////////////////////////////

Let us now make a step backward, and take $A$ in $\End{\Gamma(E)}$. We will now see that $A$ defines (and is defined by) an equivariant function $\dpt{\hat A}{P}{\End{V}}$. Let $\dpt{\psi}{M}{E}$ be in $\Gamma(E)$. If $\psi(x)=[\xi,v]$, we define the new section $A\psi$ by
\[
	(A\psi)(x)=[\xi,\hat A(\xi)v]=[\xi,\hat A(\xi)\hat\psi(\xi)].
\]
In order for $A\psi$ to be well defined, the function $\hat A$ must satisfy
\begin{equation}
	\hat A(\xi\cdot g)=\rho(g^{-1})\hat A(\xi)\rho(g)                 \label{equivA}
\end{equation}
for all $g$ in $G$.

\subsubsection{Local expressions}
%////////////////////////////////

We consider a local trivialization $\dpt{\phi^P_{\alpha}}{\pi^{-1}(\mU_{\alpha})}{\mU_{\alpha}\times G}$ of $P$ on $\mU_{\alpha}$ and the corresponding section $\dpt{\sigma_{\alpha}}{\mU_{\alpha}}{P}$ given by
\[
	\sigma_{\alpha}(x)=(\phi^P_{\alpha})^{-1}(x,e).
\]
We saw at page \pageref{eq:triv_P_E} that a trivialization of $P$ gives a trivialization of the associated bundle $E=P\times_{\rho} V$; the definition is
\begin{equation}
	\phi^E_{\alpha}[(\xi,v)]=( \pi(\xi),\rho(a)v )
\end{equation}
if $\phi_{\alpha}^P(\xi)=(\pi(\xi),a)$. With $\xi=\sigma_{\alpha}(x)$, we find
\begin{equation}
	\phi^E_{\alpha}[(\sigma_{\alpha}(x),v)]=(  \pi(\sigma_{\alpha}(x)),\rho(a)v  )
	=(x,v).
\end{equation}

The section $\psi$ can also be seen with respect to the ``reference''{} sections $\sigma_{\alpha}$ by means of the definition
\begin{equation}\label{eq:def:psisa}
	\psi(x)=[\sigma_{\alpha}(x),\psisa(x)]
\end{equation}
for a function $\dpt{\psisa}{M}{V}$.

\begin{lemma}
	Let $\dpt{\psi}{M}{E}$ be a section and $\dpt{\hpsi}{P}{V}$, the corresponding equivariant function. Then
	\[
		\psisa(x)=\hpsi(\sigma_{\alpha}(x)).
	\]
\end{lemma}

\begin{proof}
	By definition, $\psi(x)=\psi(\pi(\xi))=[\xi,\hpsi(\xi)]$.  Thus if we consider in particular $\xi=\sigma_{\alpha}(x)$,
	\begin{equation}
		\phi^E_{\alpha}(\psi(x))=\phi^E_{\alpha}[\xi,\hpsi(\xi)]
		=\phi^E_{\alpha}[s_{\alpha}(x),\hpsi(\sigma_{\alpha}(x))]
		=(x,\hpsi(\sigma_{\alpha}(x))).
	\end{equation}

\end{proof}

Let us anticipate. A \defe{spinor}{spinor} is a section of an associated bundle $E=P\times_{\rho} V$ where $P$ is a Lorentz-principal bundle, $V=\eC^2$ and $\rho$ is the spinor representation of Lorentz on $\eC^2$. So a spinor $\dpt{\psi}{M}{E}$ is \emph{locally} described by a function $\dpt{\psi\bsa}{M}{\eC^2}$. The latter is the one that we are used to handle in physics. In this picture, the transformation law of $\psi$ under a Lorentz transformation comes naturally.

Let $\{e_i\}$ be a basis of V; we consider some ``reference'' sections $\gamai$ of the associated bundle $E=P\times_{\rho} V$ defined by
\begin{equation}\label{eq:def:gamai}
	\gamai(x)=[\phi_{\alpha}^{-1}(x,e),e_i].
\end{equation}
A general section $\dpt{\psi}{M}{E}$ is defined by an equivariant function $\dpt{\hpsi}{P}{V}$ which can be written as $\hpsi(\xi)=a^i(\xi)e_i$. If $\eta=\phi_{\alpha}^{-1}(x,e)$ and $\xi=\eta\cdot g(\xi)$,
\begin{equation}
	\psi(x)=[\xi,a^ie_i]
	=a^i[\eta,\rho(g)e_i]
	=a^i(\xi)\bghd{\rho(g(\xi))}{i}{j}[\eta,e_j]
	=c^j(\xi)\gamaj(x).
\end{equation}
Since the left hand side of this equation just depends on $x$, the functions $c^j$ must actually not depend on the choice of $\xi\in\pi^{-1}(x)$. So we have $\dpt{c^j}{M}{\eR}$. Indeed, if we choose $\chi\in\pi^{-1}(x)$,
\[
	\psi(x)=c^j(\xi)\gamaj(x)
	\stackrel{!}{=}[\xi,a^{i}(\chi)e_i]
	=\ldots
	=c^j(\chi)\gamaj(x),
\]
so that $c^j(\xi)=c^j(\chi)$. So any section $\dpt{\psi}{M}{E}$ can be decomposed (over the open set $\mU_{\alpha}$) as
\begin{equation}
	\psi(x)=s_{\alpha}^i(x)\gamai(x).
\end{equation}


\subsection{Associated and vector bundle}
%----------------------------------------

\subsubsection{General construction}
%///////////////////////////////////

We are going to see that a vector bundle is an associated bundle. For this, we consider a vector bundle $\dpt{p}{F}{M}$ with a fiber $F_x=V$ of dimension $m$. Let $G=GL(V)$, $P$ be the trivial principal bundle $P=M\times G$ and $\rho$ be the definition representation of $G$ on $V$. We set $E=P\times_{\rho} V$. Our aim is to put a vector bundle structure on $E$ which is equivalent to the one of $F$. The bijection $\dpt{b}{F}{E}$ will clearly be
\begin{equation}
	b(\phi^{-1}(x,v))=[(x,e),v].
\end{equation}
We define the projection $\dpt{q}{E}{M}$ by
\[
	q[(x,g),w]=x
\]
and we have to show that  $q^{-1}(x)=\{  [(x,g),w]\tq g\in G \textrm{ and } w\in V  \}$ is a vector space isomorphic to $V$. The following definitions define a vector space structure:
\begin{itemize}
	\item multiplication by a scalar: $\lambda[(x,g),v]=[(x,g),\lambda v]$,
	\item addition: $[(x,g),v]+[(x,h),w]=[(x,e),\rho(g)v+\rho(h)w]$.
\end{itemize}
As local trivialization map, we consider
\begin{equation}
	\begin{aligned}
		\chi\colon q^{-1}(\mU) & \to \mU\times V      \\
		[(x,g),v]              & \mapsto(x,\rho(g)v).
	\end{aligned}
\end{equation}
With this structure, the bijection $b$ is an equivalence because $b|_{F_x}$ is a vector space isomorphism and $q\circ b=p$.

\subsection{Equivariant functions for a vector field}	\label{equivvec}
%----------------------------------------------------

In order to define in the same way an equivariant function for a vector field $X\in\cvec(M)$, we need to see $TM$ as an associated bundle.

\begin{proposition}
	If $M$ is a $n$ dimensional manifold, we have the following isomorphism:
	\[
		\SO(M)\times_{\rhoM}\eR^m\simeq TM
	\]
	where $\dpt{\rhoM}{\SO(m)\times\eR^m}{\eR^m}$ is defined by $\rhoM(A)v=Av$.
\end{proposition}
\begin{proof}
	Recall that an element $b\in \SO(M)_x$ is a map $\dpt{b}{\eR^m}{T_xM}$. The isomorphism is no difficult. It is $\dpt{\psi}{\SO(M)\times_{\rhoM}\eR^m}{TM}$ defined by
	\[\psi[b,v]=b(v).\]
	It prove no difficult to see that $\psi$ is well defined, injective and surjective.
\end{proof}

Now, let us consider $X\in\cvec(M)$. We can see it as an element of $\Gamma(\SO(M)\times_{\rhoM}\eR^m)$, and define an equivariant function $\dpt{\hX}{\SO(M)}{\eR^m}$.

Let us make it more explicit. A vector field $Y\in\cvec(M)$ is, for each $x$ in $M$, the data of a tangent vector $Y_x\in T_xM$. Hence the formula $b(v)=Y_x$ defines an element $[b,v]$ in $\SO(M)\times_{\rhoM}\eR^m$, and $Y$ defines a section $\tilde{Y}(x)=[b(x),v(x)]$ of $\SO(M)\times_{\rhoM}\eR^m$. The associated equivariant function is given by $\hY(b)=v$ if $b(v)=Y_x$. In other words, the equivariant function $\dpt{\hY}{\SO(M)}{\eR^m}$ associated with the vector field $Y\in\cvec(M)$ is given by
\begin{equation}\label{r1404e1}
	\hY(b)=b^{-1}(Y_x),
\end{equation}
where $x=\pi(b)$.


\subsection{Gauge transformations}
%---------------------------------

A \defe{gauge transformation}{gauge!transformation!of principal bundle} of the $G$-principal bundle $\dpt{\pi}{P}{M}$ is a diffeomorphism $\dpt{\varphi}{P}{P}$ such that

\begin{itemize}
	\item $\pi\circ\varphi=\pi$,
	\item  $\varphi(\xi\cdot g)=\varphi(\xi)\cdot g$.
\end{itemize}

When we consider some local sections on $\dpt{\sigma_{\alpha}}{\mU_{\alpha}}{P}$, we can describe a gauge transformation with a function $\dpt{\tilde{\varphi}_{\alpha}}{M}{G}$ by requiring
\[
	\varphi(\sigma_{\alpha}(x))=\sigma_{\alpha}(x)\cdot\tilde{\varphi}_{\alpha}(x).
\]
This formula defines $\varphi$ from $\tilde{\varphi}$ as well as $\tilde{\varphi}$ from $\varphi$.

The group of gauge transformations\index{gauge!transformation!of section of associated bundle} has a natural action on the space of sections given by
\begin{subequations}
	\begin{align}
		(\varphi\cdot\psi)(x)           & =[\varphi(\xi),v].
		\intertext{if $\psi(x)=[\xi,v]=[\xi,\hat{\psi}(\xi)]$. This law can also be seen on the equivariant function $\hpsi$ which defines $\psi$. The rule is}
		\widehat{\varphi\cdot\psi}(\xi) & =\hpsi(\varphi^{-1}(\xi)).
	\end{align}
\end{subequations}
Indeed, in the same way as before we find $(\varphi\cdot\psi)(x)=[\xi,\widehat{\varphi\cdot\psi}(x)]\stackrel{!}{=}[\varphi(\xi),v]=[\varphi(\xi),\hpsi(\xi)]$. Taking $\xi\to\varphi^{-1}(\xi)$ as representative, $(\varphi\cdot\psi)(x)=[\xi,\hpsi\circ\varphi^{-1}(\xi)]$.
