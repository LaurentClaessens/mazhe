\section{Some symplectic and Poisson geometry}\label{sec:symple}
%--------------------------------------------

\subsection{Symplectic manifold}
%-------------------------------

A \defe{symplectic structure}{symplectic!vector space} on a vector space $V$ is a skew-symmetric, nondegenerate bilinear $2$-form $\dpt{\Omega}{V\times V}{\eR}$. We define the \defe{symplectic group}{symplectic!group} $\SP(\Omega)$\nomenclature{$\SP(V,\Omega)$}{Symplectic group} as the group of linear operators $\dpt{A}{V}{V}$ such that $\Omega(Au,Av)=\Omega(u,v)$ for every $u$, $v\in V$. It is easy to see that elements of $\SP(V)$ satisfy
\begin{equation} \label{EqPropodefMtrsym}
	A^t\Omega A=\Omega.
\end{equation}
The Lie algebra of $\SP(\Omega)$ is denoted by $\gsp(\Omega)$\nomenclature{$\mfsp$}{Symplectic algebra}. Taking the derivative of equation \eqref{EqPropodefMtrsym} with respect to $A$, one finds the following condition for $B\in\gsp(\Omega)$:
\begin{equation}
	\Omega B+B^{t}\Omega=0.
\end{equation}

If $W$ is a subspace of the symplectic vector space $V$, the \defe{symplectic complement}{symplectic!complement} is
\begin{equation}
	W^{\omega}=\{ x\in V\tq \omega(x,y)=0\;\forall y\in W \}.
\end{equation}
We say that $W$ is a \defe{Lagrangian}{Lagrangian!subspace} of $V$ when $W=W^{\omega}$. Typically, when one consider the canonical structure $\Omega(p_{i},q_{j})=\delta_{ij}$ on $\eR^{2n}$, the spaces $\Span\{ p_{i}\tq i=1,\ldots, n \}$ and $\Span\{ q_{i}\tq i=1,\cdots,n \}$ are Lagrangian.

A \defe{symplectic manifold}{symplectic!manifold} is the data of a smooth manifold $M$ and a symplectic structure $\omega_{x}$ on each tangent space $T_{x}M$. The map $x\mapsto \omega_{x}$ is required to be a smooth section of the $2$-tensor bundle.

\begin{definition}
	A \defe{symplectic Lie algebra}{symplectic!Lie algebra} is a Lie algebra $\mfs$ endowed with a symplectic structure $\omega$  such that $\forall x$, $y$, $z\in\mfs$,
	\begin{equation}   \label{EqDefAlgSymple}
		\omega([x,y],z)+\omega([y,z],x)+\omega([z,x],y)=0.
	\end{equation}
	\label{DefSympleAlg}
\end{definition}
\subsection{Poisson manifold}
%-----------------------------

Let $M$ be a smooth manifold. A \defe{Poisson structure}{Poisson structure}, or a \emph{Poisson bracket} on $M$ is a map $\{ .,. \}\colon  C^{\infty}(M)\times C^{\infty}(M)\to  C^{\infty}(M)$ such that
\begin{enumerate}
	\item $\big(  C^{\infty}(M), \{ .,. \} \big)$ is a Lie algebra,
	\item for each $f\in C^{\infty}(M)$, the map $\{ f,. \}$ is a derivation of the algebra $ C^{\infty}(M)$:
	      \[
		      \{ f,gh \}=\{ f,g \}h+g\{ f,h \}.
	      \]
\end{enumerate}

\subsection{Hamiltonian action}\label{app:ham_act}
%///////////////////////////////////

Let $(M_1,\omega_1)$ and $(M_2,\omega_2)$ be symplectic manifolds. A \defe{symplectomorphism}{symplectomorphism} from $M_1$ to $M_2$ is a diffeomorphism $\varphi\colon M_1\to M_2$ such that $\varphi^*\omega_2=\omega_1$.

For any function $f\in C^{\infty}(M)$, we define the \defe{Hamiltonian field}{Hamiltonian!field} $X_f\in\cvec(M)$ associated with $f$ by
\begin{equation}   \label{EqDefHamVect}
	i(X_f)\omega=df.
\end{equation}
Existence of such a $X_f$ for each $f$ is assured because $\omega$ is nondegenerate.  A symplectic structure induces a Poisson bracket by defining\index{Poisson structure!on symplectic manifold}
\begin{equation}\label{eq:def_Poisson}
	\{f,g\}=-\omega(X_f,X_g)=-X_g(f)=X_f(g).
\end{equation}
In local coordinates, one can write $\omega=\frac{1}{2}\omega_{ij}dx^i\wedge dx^j$ and $X_f=\omega^{ij}\partial_if\partial_j$, where $(\omega^{ij})$ is the inverse matrix of $(\omega_{ij})$. The Poisson tensor defined by
\begin{equation}  \label{EqPoisson}
	\{f,g\}=P^{kl}\partial_kf\partial_lg,
\end{equation}
is nothing else than $P=\omega^{-1}$.

\begin{theorem}\label{tho:equiv_Poisson}
	If $\varphi\colon M\to M'$ is a diffeomorphism between two Poisson manifolds $(M,P)$ and $(M',P')$, then the following are equivalent:
	\begin{enumerate}
		\item $\varphi_*(X_{f\circ\varphi})=X'_f$,
		      \item\label{ite_equivii} $\{u\circ\varphi,v\circ\varphi\}=\{u,v\}'\circ\varphi$,
		\item $\varphi_*P=P'$,
	\end{enumerate}
	If moreover the Poisson structures $P$ and $P'$ come from symplectic forms $\omega$ and $\omega'$, $\varphi^*\omega'=\omega$.
\end{theorem}

\begin{definition}
	Let $\dpt{\tau}{G\times M}{M}$ be a symplectic action of a Lie group $G$ on $M$ (i.e. $\dpt{\tau_g}{M}{M}$ is a symplectic transformation of $M$ for each $g\in G$). That action is \defe{Hamiltonian}{Hamiltonian!action} if, for every $X\in\mG$, there exists a map $\lambda_X\in C^{\infty}(M,\eC)$ such that
	\begin{subequations}\label{eq:act_ham}
		\begin{align}
			i(X^*)\omega            & =d\lambda_X,\label{1s17d}        \\
			\{\lambda_X,\lambda_Y\} & =\lambda_{[X,Y]}\label{eq:hamil}
		\end{align}
	\end{subequations}
	where $X^*$ is the fundamental vector field associated with the vector $X$.
\end{definition}

\begin{definition}
	The map $\dpt{\lambda}{\mG}{\Cinf(M)}$ which satisfies \eqref{eq:act_ham} is the \defe{dual}{momentum map!dual} momentum map while the \defe{momentum map}{momentum map} is $\dpt{J}{M}{\mG^*}$ defined by
	\begin{equation} \label{eq:defmomm ap}
		\lambda_X(x)=\langle J(x),X\rangle
	\end{equation}
	for all $X\in\mG$.
	\label{def:app_mom_mom_duale}
\end{definition}
Using the musical isomorphism (see~\ref{subsec_musique}), equation \eqref{1s17d} can be written as $(d\lambda_X)^{\sharp}=X^*$ or $d\lambda_X=(X^*)^{\flat}$.

Since $i(X_{\lambda_Y})\omega=d\lambda_Y=i(Y^*)\omega$, we have:
\begin{equation} \label{eq_XlambdaYs}
	X_{\lambda_Y}=Y^*.
\end{equation}
The \defe{symplectic gradient}{symplectic!gradient} is
\[
	\sgrad u=(du)^{\sharp}.
\]

\begin{remark}
	If the action only fulfils \eqref{1s17d}, it is said to be \defe{weakly Hamiltonian}{Hamiltonian!action!weak}. But one can find some literature in which the first condition is called a \emph{Hamiltonian action} and the second, a \emph{strongly Hamiltonian} one.
\end{remark}

\begin{remark}
	Be careful with some choices of signs. We made at least three choices: the definition of $\lambda_X$ in \eqref{1s17d} can get a minus sign; the definition of the Poisson bracket \eqref{eq:def_Poisson} is modulo a sign; and the definition of the fundamental fields that we take is
	\begin{equation}   \label{EqDefFondsiTHZ}
		X^*_{x}=\Dsdd{ \tau_{ e^{-tX}}x }{t}{0}.
	\end{equation}
	It can be written without the minus sign in the exponential. Each of these choice is free, by condition \eqref{eq:hamil} is not! If one make  ``wrong'' choices, this can become
	\begin{equation}
		\{\lambda_X,\lambda_Y\}=-\lambda_{[X,Y]},
	\end{equation}
	with all the consequences in the computations. For example, if one defines $X^*_x=\dsdd{\tau_{\exp tX}x}{t}{0}$, one finds an extra minus sign in equations \eqref{EqlamHal}, \eqref{EqlamEal} and \eqref{EqlamFal}.
\end{remark}

\subsection{Coadjoint orbits}		\label{sub:coadjoint}
%///////////////////////////////

Let $G$ be a Lie group and $\mG$ its Lie algebra.  We know that $G$ acts on the dual $\mG^*$ by
\begin{equation}    \label{EqDefActCoadj}
	g\cdot \xi=\xi\circ \Ad(g^{-1})=\Ad(g)^*\xi
\end{equation}
for $g\in G$ and $\xi\in\mG^*$. The second equality defines the \defe{coadjoint action}{coadjoint!action} $\Ad^*\colon G\times\mG^*\to \mG^*$. In other words, for all $X\in\mG$,
\[
	(g\cdot \xi)(X)=\langle \xi,\Ad(g^{-1})X\rangle=\langle \Ad(g)^*(\xi),X\rangle.
\]
This representation is also called the \defe{\wikipedia{en}{Dual_representation}{contragredient} representation}{contragredient representation}.
In this context, the notion of fundamental fields is given bu $X^*_{\xi}=\xi\circ\ad(X)$. Let $\theta_{\xi}=\{g\cdot \xi|g\in G\}$, the orbit of $\xi$ in $\mG^*$. It can be shown that
\begin{equation}\label{eq_omega_Gs}
	\tilde\omega_x(X^*_x,Y^*_x)=\langle x,[X,Y]\rangle
\end{equation}
defines a symplectic form on $\theta_{\xi}$\nomenclature{$\theta_{\xi}$}{Coadjoint orbit of $\xi$}, the coadjoint orbit of $\xi$.

\begin{proposition}
	The coadjoint action is Hamiltonian.
\end{proposition}

\begin{proposition}
	The diffeomorphism
	\begin{equation}
		\begin{aligned}
			\varphi(g)\colon \theta_{\xi} & \to \theta_{\xi}   \\
			\xi                           & \mapsto g\cdot \xi
		\end{aligned}
	\end{equation}
	fulfils
	\[
		\big(\varphi(g)^*\omega\big)_{\xi}(X^*_{\xi},Y^*_{\xi})=\omega_{\xi}(X^*_{\xi},Y^*_{\xi}).
	\]
\end{proposition}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Example of adjoint and coadjoint orbit}
%---------------------------------------------------------------------------------------------------------------------------

Let us consider the following subgroup of $\SL(2,\eR)$
\begin{equation}
	\eS=\{ \begin{pmatrix}
		a & n      \\
		0 & a^{-1}
	\end{pmatrix}\text{where }a>0\text{ and } n\in\eR\}.
\end{equation}
The Lie algebra is
\begin{equation}
	\lS=\{ \begin{pmatrix}
		x & y  \\
		0 & -x
	\end{pmatrix}\text{where }x,y\in\eR\}.
\end{equation}
The following is a basis of $\lS$:
\begin{equation}
	\begin{aligned}[]
		H=\begin{pmatrix}
			  1 & 0  \\
			  0 & -1
		  \end{pmatrix} &  & E & =\begin{pmatrix}
			                          0 & 1 \\
			                          0 & 0
		                          \end{pmatrix}
	\end{aligned}
\end{equation}
and the commutation relation is $[H,E]=2E$. Since we are in a matrix group, the adjoint action is given by $\Ad(g)X=gXg^{-1}$ and we can compute
\begin{equation}
	\Ad(a,n)(x,y)=\begin{pmatrix}
		x & ay^2-2nax \\
		0 & -x
	\end{pmatrix}
	=
	xH+(a^2y-2nax)E
\end{equation}
Thus the adjoint orbits are the straight lines.

For the coadjoint orbits, consider an element $\xi=\xi_HH^*+\xi_EE^*\in\lS^*$. We have
\begin{equation}
	\begin{aligned}[]
		\langle \Ad^*(g^{-1})\xi, X_0\rangle & =\langle \xi, \Ad(g)X\rangle  \\
		                                     & =(\xi_H-2na\xi_E)x+a^2\xi_Ey.
	\end{aligned}
\end{equation}
If we write $\xi=(\xi_H,\xi_E)$ we have
\begin{equation}
	\Ad^*(a,n)^{-1}(\xi_H,\xi_E)=\begin{pmatrix}
		1 & -2na \\
		0 & a^2
	\end{pmatrix}\begin{pmatrix}
		\xi_H \\
		\xi_E
	\end{pmatrix}.
\end{equation}
This is the orbit of $\xi$. Notice that $H^*$ is fix while $E^*\mapsto -2na H^*+a^2E^*$, so that $E^*$ has a quite large orbit. If $\xi_2\neq 0$, then $\dim\Ad^*(\eS)\xi=2$. If $\xi_E=0$, then the orbit is one single point. Thus we have three kind orbits in the plane $(H^*,E^*)$:
\begin{enumerate}

	\item
	      the upper half plane is one two dimensional orbit,
	\item
	      each of the point on the $\xi_E=0$ is an orbit,
	\item
	      the lower half plane is a second two dimensional orbit.
\end{enumerate}
These orbits are very different from the adjoint orbits.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{A second example}
%---------------------------------------------------------------------------------------------------------------------------

Let $\lG=\SL(2,\eR)$ and the basis $\{ H,E,F \}$ with the relations
\begin{equation}
	\begin{aligned}[]
		[H,E] & =2E  \\
		[H,F] & =-2F \\
		[E,F] & =H.
	\end{aligned}
\end{equation}
The Killing form is given by the matrix
\begin{equation}
	\beta=\begin{pmatrix}
		8 & 0 & 0 \\
		0 & 0 & 4 \\
		0 & 4 & 0
	\end{pmatrix}.
\end{equation}
It is nondegenerate and its signature is $+,+,-$.

\begin{lemma}
	If the Killing form $\beta$ is nondegenerate, the map
	\begin{equation}
		\begin{aligned}
			\flat\colon \lG & \to \lG^*   \\
			X^{\flat}(y)    & =\beta(X,Y)
		\end{aligned}
	\end{equation}
	is a linear $\Ad$-equivariant\index{equivariant} isomorphism, that is
	\begin{equation}
		\Ad^*(g)(X^{\flat})=\big( \Ad(g)X \big)^{\flat}.
	\end{equation}
\end{lemma}

\begin{proof}
	We have
	\begin{equation}
		\begin{aligned}[]
			\langle \Ad^*(g)X^{\flat}, Y\rangle & =\beta\big( X,\Ad(g^{-1})Y \big) \\
			                                    & =\beta\big( \Ad(g)X,Y \big)      \\
			                                    & =\big( \Ad(g)X \big)^{\flat}Y.
		\end{aligned}
	\end{equation}
\end{proof}
In that case, the $\flat$ map intertwines the actions and the adjoint orbits are the same as the coadjoint orbits.


\subsection{Kostant theorem}
%--------------------------

Let $G$ act transitively on $M$ and on $\mG^*$ by the coadjoint action \eqref{EqDefActCoadj}. We suppose this action to be Hamiltonian. One can prove that $J$ is \defe{equivariant}{equivariant!momentum map}:
\begin{equation}
	J(g\cdot x)=g\cdot J(x)
\end{equation}
where the first dot is the action on $M$ and the second one, the action on $\mG^*$. The momentum map of $M$ and $\mG^*$ are related by $\lambda_X^M=\lambda_X^{\mG^*}\circ J$. Since $G$ is transitive on $M$, for any $x\in M$, we have $M=G\cdot x$ for any $x$ in $M$, so
\[
	J(M)=G\cdot J(x).
\]
We conclude that $J(M)$ is only one orbit in $\mG^*$.

\begin{proposition}
	Let $\mO$ be the coadjoint orbit of a connected Lie group $G$. Then $\mO$ is canonically endowed by a $\Ad^*(G)$-equivariant symplectic structure given by
	\begin{equation}		\label{EqKKSsymple}
		\omega^{\mO}_{\xi}(X^*,Y^*)=\langle \xi, [x,Y]\rangle
	\end{equation}
	where $X^*$ stands for the fundamental vector. Here the equivariance means
	\begin{equation}
		\Ad^*(g)\omega^{\mO}=\omega^{\mO}
	\end{equation}
	for every $g\in G$.
\end{proposition}

\begin{proof}
	No proof.
\end{proof}
The formula \eqref{EqKKSsymple} is \emph{Kirillov-Kostant-Souriau}. Notice that this proposition shows that the coadjoint orbits are always even dimensional.


If $\xi\in\mG^*$, we know a symplectic structure on its orbit $\theta_{\xi}$:
\begin{equation}
	\omega_{\eta}^{\theta}(X^*_{\eta},Y^*_{\eta})=\eta([X,Y])
\end{equation}
for all $\eta\in\theta_{\xi}$. We have
\begin{equation}
	\begin{split}
		(J^*\omega^{\theta})_x(X^{*M},Y^{*M})&=\omega_{J(x)}^{\theta}(X^*,Y^*)\\
		&=J(x)[X,Y]\\
		&=\lambda^M_{[X,Y]}(x)\\
		&=\{ \lambda_X^M,\lambda_Y^M \}(x),
	\end{split}
\end{equation}
and if $M$ is symplectic, it also fulfils $\omega_x^M(X^{*M},Y^{*M})=\{ \lambda_X^M,\lambda_Y^M \}(x)$, so that
\begin{equation}
	J^*\omega^{\theta}=\omega^M.
\end{equation}

\begin{theorem}[Kostant theorem]
	Let $(M,\omega)$ be a symplectic manifold on which the connected Lie group $G$ has a transitive Hamiltonian action. Then the momentum map $\dpt{J}{M}{\mG^*}$ takes his values in only one orbit $\theta$ and $J$ is a covering\quext{revêtement, en français.} of $G$ in $\mG^*$.
\end{theorem}

\begin{proof}
	Let us fix a $x\in M$, we pose $\xi=J(x)$ and define $G_x$, the stabilizer of $x$ in $G$.  Formula $\psi(g)=g\cdot x$ defines a bijection $\psi\colon G/G_{x}\to M$.  So we identify $M=G/G_x$. In the same way, $\theta_{\xi}=G/G_{\xi}$. So we can write $J(x)=G_{\xi}$ and
	\[
		J(g\cdot G_x)=g\cdot J(x)=g\cdot G_{\xi}.
	\]
	Since $g\cdot \xi=g\cdot J(x)=J(g\cdot x)=J(x)=\xi$, we have $G_x\subset G_{\xi}$. The nondegenerateness of $\omega^M$ and $\omega^{\theta}$ makes $J$ nondegenerate because $\omega^M=J^*\omega^{\theta}$. Then $dJ$ is injective and $J$ is an immersion.

	We conclude that $\mG_x=\mG_{\xi}$ which proves that $G_{\xi}/G_x$ is discrete and finally that $J$ is a covering.

\end{proof}
\subsection{Central extension}
%--------------------------

Let $\mG$ be a Lie algebra. A \defe{Chevalley coboundary}{chevalley!coboundary} is a $2$-form which reads $\delta\xi$ for a certain $\xi\in\mG^*$ with $\delta$ defined by
\begin{equation}  \label{EqDefChevCoycl}
	(\delta\xi)(A,B)=-\xi([A,B]).
\end{equation}
Let $\Omega$ be a $2$-cocycle. If it is not a coboundary, we add an element $C$ in $\mG$ and we consider $\mG'=\mG\oplus\eR C$ with the Lie algebra structure
\begin{equation}
	[A+s,B+t]_{\mG'}=[A,B]_{\mG}+\Omega(A,B)C.
\end{equation}
This is the \defe{central extension}{central!extension} of $\mG$ with respect to the $2$-cocycle $\Omega$. The terminology comes from the fact that the extension $\eR C$ belongs to the center of $\mG'$. The point is that $\Omega$ is a coboundary in $\mG'$ because
\begin{equation}
	\begin{split}
		(\delta C^*)(A,B)=C^*[A,B]_{\mG'}
		=C^*\big( [A,B]_{\mG}+\Omega(A,B)C \big)
		=\Omega(A,B),
	\end{split}
\end{equation}
so that $\Omega=\delta C^*$.

Now we suppose that the group $G$ acts on a manifold $M$. We define the action of the extended group $G'=G\otimes e^{\eR C}$ by saying that the ``new'' part does not act: $(g,s)\cdot x=g\cdot x$. Fundamental fields remains unchanged:
\begin{equation}  \label{eq:XseqXss}
	(X,s)^*=X^*.
\end{equation}
If the action of $G$ on $M$ is weakly Hamiltonian, we have functions $\dpt{ \mu_x}{M}{\eC}$ such that $i(X^*)\omega=d\mu_X$. These functions fulfil $X^*=\{ \mu_X,\,. \}$. We define
\begin{equation} \label{eq:lamXsmuXs}
	\lambda_{X,s}=\mu_X+s.
\end{equation}

\begin{proposition}
	The action of $G'$ is (strongly) Hamiltonian for these functions.
\end{proposition}

\begin{proof}

	From equation \eqref{eq:XseqXss}, we have $\{ \mu_X,. \}=\{ \mu_{X,s},. \}$ hence
	\begin{equation}
		\{ \lambda_{(X,s)},\lambda_{(Y,t)} \}=\{ \mu_X,\mu_Y \}
		=\mu_{[X,Y]}+C_{X,Y}
	\end{equation}
	for certain constants $C_{XY}$ which satisfy the property $d\big( \{ \mu_X,\mu_Y \}-\mu_{[X,Y]} \big)=0$.
	Therefore
	\begin{equation}
		\{ \lambda_{(X,s)},\lambda_{(Y,t)} \}=\lambda_{[X,Y],C_{X,Y}}
		=\lambda_{[(X,s),(Y,t)]}.
	\end{equation}

\end{proof}

The sense of the whole construction is the following. When the action $G$ is weakly Hamiltonian on $M$, we have functions $\mu_X$ which define $\Omega$ by
\[
	\{ \mu_X,\mu_Y \}=\mu_{[X,Y]}+\Omega(X,Y).
\]
In this case, the corresponding group extension has a strongly Hamiltonian action with momentum maps given by \eqref{eq:lamXsmuXs}.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Constrained system}

%----------------------------------------------------------------------------------------------------------------------------
\subsection{Holonomic constraints}

References are \cite{ms_book,Schomblond_Hamcontra}. An \defe{holonomic constraint}{holonomic constraint} appears when one force a particle to move for an example on a circle. More formally let $Q$ be the configuration space; an holonomic constraint is a submanifold $N\subset Q$, or more generally an integrable subbundle of $TQ$. From the inclusion $TN\subset TN$, the Lagrangian restricts to $L_N\colon TN\to \eR$.

We assume that $L_N$ is a regular Lagrangian (see definition on page \pageref{PgDefRegular}) and that $N$ is given by an equation of the form $N=\varphi^{-1}(0)$ for a certain section $\varphi\colon Q\to E^*$ of the dual of a vector bundle over $Q$. The variational principle is given by
\begin{equation}
	\delta\int L_N(q,\dot q)dt=0
\end{equation}
where the function $q$ is constrained by $\varphi\big( q(t) \big)=0$ for every $t$. We enforce that condition by the Lagrange multiplier method:
\begin{equation}
	\delta\int\Big(    L\big( q(t),\dot q(t) \big)-\big\langle \lambda\big( q(t),t \big), \varphi\big(q(t))\big\rangle      \Big)dt
\end{equation}
where $\lambda$ is a function of $(q,t)$ with values in $E$. The $\delta$ denotes a variation on the curves $q$ in $Q$ and $\lambda$ in $E$. In local coordinates, the Euler-Lagrange equations read
\begin{align}
	\frac{ d }{ dt }\left(    \frac{ \partial L }{ \partial \dot q^i }  \right) & =\frac{ \partial L }{ \partial q^i }-\lambda\frac{ \partial \varphi_a }{ \partial q^i }, & \varphi_a=0.
\end{align}
So the Euler-Lagrange equations for $L_N$ on $N$ are the sames as the one of $L$ on $Q$, with the constraint $\varphi=0$.

%----------------------------------------------------------------------------------------------------------------------------
\subsection{Primary constraints}

The action is given by
\[
	S(q)=\int_{t_1}^{t_2}L(q,\dot q)dt,
\]
and we require the action to be stationary with respect to variations $\delta q$ vanishing on $t_1$ and $t_2$. The Euler-Lagrange equations are given by $\frac{ \delta S }{ \delta q }=\frac{ \partial L }{ \partial q }-\frac{ d }{ dt }\left( \frac{ \partial L }{ \partial \dot q } \right)=0$ or, in coordinates,
\[
	0=\frac{ \partial L }{ \partial q^k }-\dot q^l\frac{ \partial L }{ \partial q^l\partial q^k }-\ddot q^l\frac{ \partial L }{ \partial \dot q^l\partial \dot q^k }.
\]
when the Hessian matrix is invertible, i.e. when
\[
	\det\left( \frac{ \partial L }{ \partial \dot q^l\partial \dot q^k } \right)\neq 0,
\]
one can solve these equations in an algebraic way for the accelerations $\ddot q$ in functions of the positions $q$ and the velocities $\dot q$. When that determinant is vanishing, some of the Euler-Lagrange equations are simple relations between components of $q$ and components of $\dot q$, so that the solutions include some arbitrary functions of time.

\subsubsection{Example: Maxwell}
%///////////////////////////////

The action is
\[
	S(A)=-\frac{ 1 }{ 4 }\int F_{\mu\nu}F^{\mu\nu}d^4x
\]
with $F_{\mu\nu}=\partial_{\mu}A_{\nu}-\partial_{\nu}A_{\mu}$. That actions has a gauge invariance
\[
	A_{\mu}\mapsto A'_{\mu}=A_{\mu}+\partial_{\mu}f
\]
for any function $f$. The equations of motion are $\partial_{\nu}F^{\mu\nu}=0$, in particular the equation $\nabla\times{\bB}=\partial_t{\bE}=0$ provides the $\ddot A_k$ in terms of the $A_l$ and $\dot A_{\mu}$. Indeed the Hessian
\[
	\frac{ \partial^2L}{ \partial \dot A_{\alpha}\partial\dot A_{\beta} }=-4\big( g^{0\beta}g^{\alpha 0}+g^{\alpha\beta} \big)=
	\begin{pmatrix}
		0 \\&1\\&&1\\&&&1
	\end{pmatrix},
\]
has vanishing determinant.

%----------------------------------------------------------------------------------------------------------------------------
\subsection{Passage to Hamiltonian formalism}

The very principle is to define the momentums $p_k=\frac{ \partial L }{ \partial \dot q^k }$, so that
\[
	\frac{ \partial p_k }{ \partial \dot q^l }=\frac{ \partial^2L }{ \partial \dot q^l\partial \dot q^k },
\]
so that the vanishing determinant condition makes that it is not possible to solve the velocities $\dot q^k=\dot q^k(q,p)$. That means that the momentums are not independent: there exists relations
\begin{equation}
	\phi_m(p,q)=0
\end{equation}
for $m=1,\ldots,M$. These relations are the \defe{primary constraints}{primary constraints}: they do not rely on the equations of motion. In other terms, we have
\[
	\phi_m\big( q,p(q,\dot q) \big)=0
\]
identically, and not only on the solutions.

In the Maxwell example, we pose the momentums $\pi^{\alpha}=\frac{ \partial L }{ \partial \dot A_{\alpha} }=F^{0\alpha}$. Notice that $\pi^0+F^{00}=0$ and that the remaining is $\pi^k=E^k$ (the electric field).

If one suppose the rank of the Hessian to be constant, the constraints $\phi_m(q,p)=0$ define a submanifold of the phase space. This is the \emph{primary constraint surface}.

Suppose that the primary constraints can be divided into one set of independent constraints $\phi_m$, $m=1,\ldots,M'$ with the rank of $\frac{ \partial \phi_{m'} }{ \partial X }$ being $M'$ ($X=(q,p)$) and some dependent constraints $\phi_{\bar m}$ such that vanishing of all the $\phi_{m'}$ implies the vanishing of all the $\phi_{\bar m}$.

In that case, we have two important results.
\begin{theorem}
	If a function $G$ vanishes on the constraint surface $\phi_m=0$, then there exists functions $g^m$ such that $G=g^m\phi_m$.
\end{theorem}

\begin{theorem}
	If $\lambda^k\delta q^k+\mu^k\delta p_k=0$ for every variations $\delta q^k$ and $\delta p_k$ tangent to the constraint surface, then
	\begin{align}
		\lambda_k & =u^m\frac{ \partial \phi_m }{ \partial q^k } \\
		\mu^k     & =u^m\frac{ \partial \phi_m }{ \partial p_k }
	\end{align}
	for some functions $u^m$.
\end{theorem}
The tangent assumption means that
\[
	\delta\phi_m=\frac{ \partial \phi_m }{ \partial q^k }\delta q^k+\frac{ \partial \phi_m }{ \partial p_k }\delta p_k=0.
\]
Now the Hamilton equations with $\phi_m=0$ are provided by the action
\begin{equation}		\label{EaHamSqpuint}
	S(q,p,u)=\int_{t_1}^{t_2}\big( p_k\dot q^k-H-u^m\phi_m \big)dt
\end{equation}
where the functions $u^m$ are Lagrange multipliers. The equations of motion for $p$ and $u$ provide expressions $p_k=P_k(q,\dot q)$ and $u^m=U^m(q,\dot q)$ in a purely algebraic way, so that one has a reduced action
\[
	S_L(q)=S(q,P,U)
\]
which satisfies
\[
	\frac{ \delta S_L }{ \delta q^k }=\frac{ \delta S }{ \delta q^k },
\]
so that the variational principle for $q$ are the same with $S_L$ as with the original $S$.

One can show that the equations of motion of the action \eqref{EaHamSqpuint} read
\begin{equation}		\label{EqdotFCrochet}
	\dot F=[F,H]+u^m[F,\phi_m]
\end{equation}
for any function $F=F(q,p)$.

%----------------------------------------------------------------------------------------------------------------------------
\subsection{Secondary constraints}

For consistency, one can impose that the constraints are preserved in time: $\dot\phi_m=0$. Using the evolution equation \eqref{EqdotFCrochet} on the function $\phi_m$, one finds, for each $m$,
\[
	\dot\phi_m=[\phi_m,H]+u^n[\phi_m,\phi_n]
\]
which are relations between $q$ and $p$. In the case where that relation is independent of the $\phi_m$, one has a \defe{secondary constraint}{secondary constraint} $X(p,q)=0$ which has to be preserved with the time, so that
\[
	[X,H]+u^n[X,\phi_n]=0.
\]
Once again, this is a relation between $p$ and $q$.

\section{Lie groupoids and algebroids}
%++++++++++++++++++++++++++++++++++++
The reference for this section are \cite{WeinGroupoids,WeinGpoidsSymple}.

Let $M$ be a manifold and $\cA$, a vector bundle over $M$. Let $[.,.]$ be a Lie algebra structure on $\cA$. Then $\cA$ becomes a \defe{Lie algebroid}{Lie!algebroid} when we endow it by a homomorphism $\rho\colon \cA\to TM$ such that
\begin{enumerate}
	\item\label{DefAloidItemi} it induces a Lie algebra homomorphism on the sections, i.e. a $\rho\colon \Gamma(M,\cA)\to \Gamma(TM)$ such that $\rho[\psi,\varphi]=[\rho(\psi),\rho(\varphi)]$,
	\item for all $f\in C^{\infty}(M)$ and $\psi,\varphi\in\Gamma(M,\cA)$,
	      \begin{equation}  \label{DefAlgoidCondc}
		      [f\psi,\varphi]=f[\psi,\varphi]=f[\psi,\varphi]-\big( \rho(\varphi)f \big)\psi.
	      \end{equation}

\end{enumerate}
The map $\rho$ is the \defe{anchor}{anchor}. In order to be more precise for item~\ref{DefAloidItemi}, the anchor function $\rho\colon \cA\to TM$ induces the homomorphism  $\rho'\colon \Gamma(\cA)\to \Gamma(TM)$ by formula
\begin{equation}  \label{EqInduitAncra}
	\rho'(\psi)(x)=\rho(\psi(x)).
\end{equation}
We will omit the prime and simply write $\rho$ for both functions.

The algebroid $\cA$ admit standard coordinates\label{PgStandCoord} $(q,\lambda)$ where $q$ are coordinates on $M$ and $\lambda$ some coordinates on the fibres (whose are vector spaces). These coordinates depends on a choice of a local base $\xi$ of sections of $\cA$: the set of sections $\{\xi_{i}(x)\}$ is a basis of the fibre $\cA_{x}$ for each $x\in M$. IN terms of these coordinates, the Lie algebra structure of $\cA$ reads
\[
	[\xi_{i},\xi_{j}]=c_{ijk}\xi_{k}
\]
where the $c_{ijk}\in C^{\infty}(M)$ are the \emph{structure constant}. In the same way, the anchor is given in terms of functions $a_{ij}\in C^{\infty}(M)$ by
\[
	\rho(\xi_{i})=a_{ij}\frac{ \partial }{ \partial q_{j} }.
\]

\subsection{Example: tangent bundle \texorpdfstring{$TM$}{TM}}
%---------------------------------------------------------------

If we consider $\cA=TM$, the anchor is $\rho=\id$. Then formula \eqref{EqInduitAncra} is $\rho(\psi)(x)=\psi(x)$, and the condition \eqref{DefAlgoidCondc}, with more familiar notations, reduces to
\[
	[fX,Y]=f[X,Y]-(Yf)X.
\]

\subsection{Example: a Lie algebra}
%-----------------------------------

Any Lie algebra $\mG$ can be seen as an algebroid on a manifold $M=\{ p \}$ is a manifold containing only one point. In this case, any path in $M$ is constant and the tangent space $TM$ reduces to only the zero vector. The identically vanishing map $\rho\colon \mG\to TM$ is an anchor.

\subsection{Example: gauge algebroid}
%-------------------------------------

We consider the following principal bundle:
\[
	\xymatrix{
		G \ar@{~>}[r] & P\ar[d]^{\displaystyle \pi}\\ &M
	}
\]
Let's begin to give a structure of vector bundle on the quotient $TP/G$. What is clear is that $TP$ is a vector bundle $p\colon TP\to M$. The action of $G$ on $TP$ is
\[
	X_{\xi}\cdot g=d\tau_{g}X_{\xi}
\]
where $\tau\colon P\to P$ is the action. So the quotient $TP/G$ is taken with respect to the equivalence $X_{\xi}\sim d\tau_{g}X_{\xi}$. Notice that $X_{\xi}\in T_{\xi}P$ and $d\tau_{g}X_{\xi}\in T_{\xi\cdot g}P$; in fact in each class $[X_{\xi}]$, there is one and only one vector at each point of the fibre of $\xi$.

The differential $d\pi$ of the projection passes to quotient: $d\pi(X_{\xi})=d\pi(X_{\xi}\cdot g)$. It follows that the next definition is correct:
\begin{equation}
	\begin{aligned}
		d\pi\colon TP/G & \to TM                           \\
		d\pi[X_{\xi}]   & = d\pi X_{\xi}\in T_{\pi(\xi)}M.
	\end{aligned}
\end{equation}

Now let us study the sections $\psi\colon M\to TP/G$.

\begin{lemma}
	The sections of $TP/G$ are the $G$-equivariant vector fields on $P$\index{equivariant!vector field on principal bundle}. (see definition~\ref{DefEqVectPrinc}.)
\end{lemma}

\begin{proof}
	We consider the map $L\colon \Gamma(M,TP/G)\to \Gamma(P,TP)$,
	\[
		(L\psi)(\xi)=\psi(\pi(\xi))|_{\xi}
	\]
	where, when $q\in TP/G$, the symbol $q|_{\xi}$ denotes the element of $T_{\xi} P$ which belongs to $q$. In particular, $[X_{\xi}]|_{\xi}=X_{\xi}$. The section $L\psi$ is $G$-equivariant, i.e.
	\begin{equation}
		d\tau_{g}(L\psi)(\xi)=(L\psi)(\xi\cdot g).
	\end{equation}
	Indeed, $d\tau_{g}X_{\xi}\in [X_{\xi}]$, thus
	\[
		d\tau_{g}\big[ \psi(\pi\xi) \big]|_{\xi}\in [\psi(\pi\xi)]\cap T_{\xi\cdot g}P,
	\]
	and there is only one element which is $\big[ \psi(\pi\xi) \big]|_{\xi\cdot g}=(L\psi)(\xi\cdot g)$.
\end{proof}

Now, taking $d\pi$ as anchor, this construction gives an algebroid structure to $TP/G$. In order to prove that we have to prove that
\[
	[f\psi,\varphi]=f[\psi,\varphi]-\big( \rho(\varphi)f \big)\psi
\]
for any choice of sections $\psi,\varphi\colon M\to TP/G$ and of function $f\colon M\to \eR$. Here we have
\begin{equation}
	\begin{aligned}
		\rho\colon \Gamma(M,TP/G) & \to \Gamma(M,TM)          \\
		\rho(\psi)(x)             & =d\pi\big( \psi(x) \big).
	\end{aligned}
\end{equation}
The first think to be remarked is that a good choice of local section $a\colon M\to P$ and vector fields $X$, $Y\in\Gamma(P,TP)$ on $P$, one can express $\psi$ and $\varphi$ under the form
\begin{equation}  \label{EqXcorrapsi}
	\psi(x)=\big[ (X\circ a)(x) \big],\qquad \varphi(x)=\big[ (Y\circ a)(x) \big]
\end{equation}
with the same $a$. On $TP/G$, we put the Lie bracket inherited from the one of $TP$:
\begin{equation}
	[\psi,\varphi](x)=\Big[ [X,Y]\circ a(x) \Big].
\end{equation}
If $X$ corresponds to $\psi$ by \eqref{EqXcorrapsi}, we have
\begin{align*}
	(f\psi)(x) & =\Big[ f(x)(X\circ a)(x) \Big]                          \\
	           & =\Big[ \big( (f\circ\psi)X \big)\big( a(x) \big) \Big],
\end{align*}
thus $(f\circ \pi)X$ corresponds to $f\psi$ in the sense of
\[
	\Big( (f\circ \pi)X \Big)(\xi)=f(\pi\xi)X(\xi).
\]
Then we have
\begin{align*}
	[f\psi,\varphi](x) & =\Big[ \big[ (f\circ\pi)X,Y \big]\circ a(x) \Big]                     \\
	                   & =\Big[ \big( (f\circ\pi)[X,Y]-Y(f\circ\pi)X \big)\circ a(x) \Big]     \\
	                   & =\big[ f(x)[X,Y]\circ a(x) \big]-\big[ Y(f\circ\pi)X\circ a(x) \big].
\end{align*}
What lies in the bracket of the second term reads better under the form:
\[
	\big( Y(f\circ\pi)X \big)\circ a(x)=Y_{a(x)}(f\circ\pi)X_{a(x)}.
\]
We want this thing to be equal to
\begin{align*}
	\Big( \big( \rho(\varphi)f \big)\psi \Big)(x) & =\big( \rho(\varphi)(x)f \big)\psi(x)                     \\
	                                              & =d\pi\big( \varphi(x) \big)f\big[ (X\circ a)(x) \big]     \\
	                                              & =d\pi\big[ (Y\circ a)(x) \big]f\big[ (X\circ a)(x) \big].
\end{align*}
In the latter expression, $(Y\circ a)(x)\in T_{a(x)}P$ while  $d\pi\big[ (Y\circ a)(x)\Big]\in T_{x}M$. Since $d\pi\colon TP\to TM$ fulfils $d\pi(X_{\xi}\cdot g)=d\pi X_{\xi}$, the differential of $\pi$ passes to the classes (this is the reason for which we chose it a anchor) and
\[
	d\pi[(Y\circ a)(x)]=d\pi(Y\circ a)\in TM.
\]
It remains to be proved that
\[
	\Big[ \big( Y(f\circ\pi)X \big)\circ a(x) \Big]=\big( d\pi(Y\circ a)(x) \big)f\big[ (X\circ a)(x) \big],
\]
which is true because
\begin{align*}
	Y_{a(x)}(f\circ\pi) & =(Y\circ a)(x)               \\
	                    & =(df\circ d\pi)(Y\circ a)(x) \\
	                    & =d\pi(Y\circ a)(x)f.
\end{align*}

\subsection{Poisson structure}
%------------------------------

Let us describe a Poisson structure on the dual $\cA^*$. For this, we put a Poisson bracket\index{Poisson structure!on dual algebroid} on each $\cA^*_{x}$, $x\in M$. Since the bracket only depends on differential, we just have to define it on affine functions on the fibres. Two remarks: firstly, the functions which are constant on fibres can be seen as functions on $M$ and second, linear functions can be seen as sections of $\cA$ because a linear function on a vector space is equivalent to the data of a single vector. So let $f,g\colon M\to \eR$ be two functions and $\psi,\varphi\colon M\to \cA$ be sections. The bracket on $ C^{\infty}(\cA^*)$ is defined as
\begin{equation}
	\{ f,g \}=0,\quad \{ f,\psi \}=\rho(\psi)f,\quad\{ \psi,\varphi \}=[\psi,\varphi].
\end{equation}

\section{Lagrangian formalism}
%+++++++++++++++++++++++++++++

Let $\cA$ be a Lie algebroid on a manifold $M$ and a function $L\colon \cA\to \eR$ which we will call \defe{Lagrangian}{Lagrangian}. The \defe{Legendre mapping}{legendre mapping} is the fibre derivative $FL\colon \cA\to \cA^*$\nomenclature{$FL$}{Legendre mapping, fibre derivative of the Lagrangian $L$} given by
\begin{equation}
	FL(a)\in\cA^*_{\pi(a)},\quad FL(a)(b)=dL_{a}(b).
\end{equation}
More precisely, the differential of $L$ at $a\in \cA$ is a map from $T_{a}\cA$. In order to define $FL(a)\in\cA^*$, we begin to consider the restriction $L|_{a}$ of $L$ to the fibre of $a$. The differential of $L|_{a}\colon \cA_{\pi(a)}\to \eR$ is
\[
	(dL|_{a})_{a}\colon T_{a}\cA_{\pi(a)}\to \eR,
\]
but the fibre $\cA_{\pi(a)}$ is a vector space which can therefore be identified with its dual space. Then we have
\[
	(dL|_{a})_{a}\in\cA^*_{\pi(a)}\subset\cA^*.
\]

When one has a Lagrangian on $\cA$, one define the \defe{action}{action!associated with Lagrangian} as the function $A\colon \cA\to \eR$,
\begin{equation}
	A(v)=\langle FL(v),\,v\rangle,
\end{equation}
i.e. the action of $FL(v)\in\cA^*_{\pi(v)}$ on $v\in\cA_{\pi(v)}$. The \defe{energy}{energy!associated with a Lagrangian} is the function
\[
	E=A-L.
\]
The Lagrangian $L$ is a \defe{regular Lagrangian}{regular!Lagrangian} if $FL$ is a local diffeomorphism. In this case, one can bring the Poisson structure of $\cA^*$ on $\cA$. The resulting Poisson structure on $\cA$ is the \defe{Lagrange-Poisson structure}{Lagrange-Poisson structure}\index{Poisson structure!on algebroid}. For this, we have to define $\{ \xi,\eta \}$ when $\xi$, $\eta\in C^{\infty}(\cA)$. The natural definition is
\begin{equation}
	\{ \xi,\eta \}_{\cA}:=\{ FL(\xi),FL(\eta) \}_{\cA^*}
\end{equation}
with the following definition of $FL(\xi)\in  C^{\infty}(\cA^*)$:
\begin{equation}
	FL(\xi)(\omega)=\xi(FL^{-1}(\omega)).
\end{equation}
The latter definition says that when $\omega\in\cA^*_{\pi(a)}$ the element $FL^{-1}(\omega)$ is the element $a$ such that $(dL|_{a})_{a}=\omega$ (this is an equality in $\cA^*_{\pi(a)}$).

Since we have a Poisson structure, we can consider the Hamiltonian field (see definition \eqref{EqDefHamVect}) corresponding to the energy function $E\colon \cA\to \eR$. This is a vector field on $\cA$. This field is the \defe{Lagrangian vector field}{Lagrangian!vector field}

In standard coordinates (see page \pageref{PgStandCoord}), the Lagrangian is a function $(q,\lambda)\mapsto L(q,\lambda)$. In order to build $FL$, we first restrict $F$ to a fibre; so $L$ becomes a function $\lambda\mapsto L(q_{0},\lambda)$ and thus the derivatives which appear in $FL$ are
\[
	\mu_{i}=\frac{ \partial L }{ \partial\lambda_{i} }.
\]
Now we try to express the Poisson structure on $\cA$ in the standard coordinates. Fist, $q_{i}$ is a  function on $\cA$ which associates to one point the component $i$ of its projection. If $\omega$ and $\eta$ both belong to $\cA^*_{x}$, the elements $FL^{-1}(\omega)$ and $FL^{-1}(\eta)$ both belongs to the same fibre $\cA_{x}$. Thus $FL(q_{i})$ is a function that is constant on the fibres. So
\[
	\{ q_{i},q_{j} \}=0.
\]





%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\section{Groupoids}
%
%%%%%%%%%%%%%%%%%%%%%%%%

A set $\Gamma$ is a \defe{groupoid}{groupoid} when we consider some maps
\begin{itemize}
	\item $\alpha,\beta\colon \Gamma\to \Gamma_{0}\subset\Gamma$,
	\item $m\colon \Gamma_{2}\to \Gamma$ where $\Gamma_{2}=\{ (x,y)\in\Gamma\times\Gamma\tq \beta(y)=\alpha(x)) \}$,
	\item $i\colon \Gamma\to \Gamma$
\end{itemize}
such that
\begin{enumerate}
	\item $m(x,m(y,z))$ is defined if and only if $m(m(x,y),z)$ is defined, and in this case, they are equal,
	\item $m(\beta(x),x)=m(x,\alpha(x))=x$,
	\item $m(x,i(x))$ and $m(i(x),x)$ are defined to be respectively equal to $\beta(x)$ and $\alpha(x)$.
\end{enumerate}
Notice that the fact for $m(x,y)$ to be defined means that $\alpha(x)=\beta(x)$. As notations and terminology, we adopt the following conventions. The map $i$ is the \emph{inversion}, $m$ is the \emph{multiplication} and is denoted by a dot: $m(x,y)=x\cdot y$. We also write $i(x)=i^{-1}$.

The first hypothesis is called \emph{associativity}.

\begin{lemma}
	$\forall\,x\in\Gamma$, we have

	\begin{subequations}
		\begin{align}
			\alpha(\beta(x)) & =\beta(x)   \\
			\beta(\alpha(x)) & =\alpha(x).
		\end{align}
	\end{subequations}
\end{lemma}

\begin{proof}
	From definition of a groupoid, $\beta(x)\cdot x=x$, so $\alpha(\beta(x))=\beta(x)$. The other statement comes in the same way.

	Notice that the conclusion does not come from the equality $\beta(x)\cdot x=x$, but only from the existence of the product $\beta(x)\cdot x$.
\end{proof}

\begin{lemma}
	If $(x,y)\in\Gamma_{2}$, we have
	\begin{subequations}
		\begin{align}
			\beta(x\cdot y)  & =\beta(x)  \\
			\alpha(x\cdot y) & =\alpha(y)
		\end{align}
	\end{subequations}

\end{lemma}

\begin{proof}
	Since $(x,y)\in \Gamma_{2}$, one can write $x\cdot y$. Using $x=\beta(x)\cdot x$, and associativity we find:
	\[
		x\cdot y=\big( \beta(x)\cdot x \big)\cdot y=\beta(x)\cdot(x\cdot y).
	\]
	Existence of the last product implies $\alpha(\beta(x))=\beta(x\cdot x)$. Using the equality $\alpha(\beta(x))=\beta(x)$, we find the second relation. The first one is proven by the same:
	\[
		x\cdot y=x\cdot \big( y\cdot\alpha(y) \big)=(x\cdot y)\cdot \alpha(x).
	\]

\end{proof}

\begin{lemma}
	For all $x\in\Gamma$, we have
	\begin{subequations}
		\begin{align}
			\alpha(\alpha(x)) & =\alpha(x) \\
			\beta(\beta(x))   & =\beta(x).
		\end{align}
	\end{subequations}
\end{lemma}

\begin{proof}
	Using formula $x\cdot\alpha(x)=x$ in itself, and using associativity,
	\[
		(x\cdot\alpha(x))\cdot\alpha(x)=x\cdot\big( \alpha(x)\cdot\alpha(x) \big)=x.
	\]
	The existence of the product $\alpha(x)\cdot\alpha(x)$ and the fact that $\beta\circ\alpha=\alpha$ give the result.
\end{proof}

\begin{lemma}
	Let us mention the following other properties:
	\begin{align}
		\alpha(x^{-1})          & =\beta(x)  & \beta(x^{-1})         & =\alpha(x) \\
		\alpha(x)\cdot\alpha(x) & =\alpha(x) & \beta(x)\cdot\beta(x) & =\beta(x)
	\end{align}
	the \emph{simplification} rule:
	\begin{align}
		x\cdot y_{1}=x\cdot y_{2} & \Rightarrow y_{1}=y_{2} \\
		x_1\cdot y=x_{2}\cdot y   & \Rightarrow x_1-x_2,
	\end{align}
	and the corollary
	\begin{equation}
		(x^{-1})^{-1}=x.
	\end{equation}

\end{lemma}
\begin{proof}
	No proof.
\end{proof}

\begin{proposition}
	The set $\Gamma_0$ is the set of fixed points of $\alpha$ and $\beta$.
\end{proposition}

\begin{proof}
	We proof that $\Gamma_0=\{ x\in\Gamma\tq \alpha(x)=x \}$; the same is true for $\beta$. The definition of $\Gamma_0$ is to be the image of $\alpha$. Let $x\in\Gamma_0$: there exists a $y\in\Gamma$ such that $x=\alpha(y)$. So $\alpha(x)=\alpha(\alpha(y))=\alpha(y)=x$.

	For the reciprocal, let $x=\alpha(x)$. Then $x\in \Gamma_0$ because $x$ belongs to the image of $\alpha$ --- for instance, the image of itself.
\end{proof}

\subsection{Example: when \texorpdfstring{$\Gamma_0=\{ e \}$ }{G=e}}
%---------------------------------------------------------------------

Let us prove that in the case when $\Gamma_0$ reduces to only one point $\{ e \}$, the groupoid $\Gamma$ is a group whose unit is $e$.

First, remark that for all $x\in\Gamma$, we have $\alpha(x)=\beta(x)=e$, so that $\Gamma_2=\Gamma$ and the multiplication is everywhere defined. Associativity is not a problem. The map $x\mapsto i(x)$ is the inverse because $x\cdot i(x)=\beta(x)=e$ and $i(x)\cdot x=\alpha(x)=e$. We also have $x\cdot e=e\cdot x=x$ because $e=\alpha(x)$ and $x\cdot \alpha(x)=x$.

\subsection{Example: the null  groupoid}
%----------------------------------------

A \defe{null groupoid}{null!groupoid} is a groupoid in which $\Gamma_0=\Gamma$. In this case, since $\Gamma_0$ is the set of fix points of $\alpha$ and $\beta$, we have
\[
	\alpha=\beta=\id.
\]
In order for $x\cdot y$ to exist, we need $\beta(y)=\alpha(x)$, which in the case of the null groupoid gives $x=y$. So the only products that are defined are
\[
	x\cdot x=x.
\]

\subsection{The case \texorpdfstring{$\alpha=\beta$}{a=b}}
%----------------------------------------------------------

The case $\alpha=\beta$ regroup the two preceding cases. We will prove that for each $u\in\Gamma_0$, the set $\alpha^{-1}(u)$ is a group with $u$ as unit. Indeed let $x$, $y\in\alpha^{-1}(u)$; it is clear that $x\cdot y$ exists because $\beta(y)=\alpha(y)=x=\alpha(x)$. So the product is defined everywhere. Proof of the fact that $u$ is the unit is easy:
\begin{align*}
	x\cdot u=x=x\cdot\alpha(x)=x \\
	u\cdot x=\beta(x)\cdot x=x,
\end{align*}
and
\begin{align*}
	x\cdot i(x)=\beta(x)=u \\
	i(x)\cdot x=\alpha(x)=u.
\end{align*}

\subsection{An example on a vector bundle}
%-----------------------------------------

We consider a vector bundle $\pi\colon E\to M$ and
\[
	\Gamma_0=\{ o_{x}\tq x\in M \},
\]
the set of the zero of each fibre. As groupoid law, we choose the addition in the fibres: when $\pi(v)=\pi(w)$, we define $v\cdot w=v+w$, and as map $\alpha=\beta$, we naturally choose
\[
	\alpha(v)=\beta(v)=o_{x}
\]
if $v\in E_{x}$. In this case, $\alpha^{-1}(o)$ is the fibre of $o$ which is a group for the addition.


\subsection{Orbits}
%------------------

Let $\Gamma$ be a groupoid and $u\in\Gamma_0$. The \defe{isotropy group}{isotropy!group}\index{group!isotropy} of $u$ is
\[
	\Gamma_{u}=\alpha^{-1}(u)\cap\beta^{-1}(u)
\]
In order to prove that it is a group, remark that if $x$, $y\in\Gamma_{u}$,
\[
	\alpha(x)=\alpha(y)=\beta(x)=\beta(y)=u,
\]
in particular, $x\cdot y$ exists and $\Gamma_{u}$ has a law. It is easy to prove that $u$ is th unit.

Notice that $\beta(\alpha^{-1}(x))=\alpha(\beta^{-1}(x))$. Indeed if $y\in\beta(\alpha^{-1}(x))$, there exists a $z$ such that $y=\beta(z)$ and $\alpha(z)=x$. We have to find a $z'$ such that $y=\alpha(z')$ and $\beta(z')=x$. The element $z'=\beta(z)$ works.

The set $\beta(\alpha^{-1}(x)=\alpha(\beta^{-1}(x))$ is the \defe{orbit}{orbit in a groupoid} of $\Gamma$ through $x$.

\begin{proposition}
	The set of orbits of $\Gamma$ is a partition of $\Gamma_0$.
\end{proposition}

\begin{proof}
	The proof is as easy as I want not to give you.
\end{proof}

\subsection{Morphism}
%--------------------

If $\Gamma$ and $\Gamma'$ are two groupoids, the map $f\colon \Gamma\to \Gamma'$ is a \defe{morphism}{morphism!of groupoid} if for each existing product $x\cdot y$ in $\Gamma$, we have
\[
	f(x)\cdot f(y)=f(x\cdot y).
\]
We see that automatically
\[
	\beta'(f(x))\cdot f(x)=f(x)=f(\beta(x)\cdot x)=f(\beta(x))\cdot f(x);
\]
so that the simplification rule gives
\begin{subequations}
	\begin{align}
		\beta'\circ f  & =f\circ\beta   \\
		\alpha'\circ f & =f\circ\alpha.
	\end{align}
\end{subequations}

\section{Lie groupoid}
%+++++++++++++++++++++

A \defe{Lie groupoid}{Lie!groupoid} is a (maybe non Hausdorff) manifold endowed with a groupoid structure such that
\begin{enumerate}
	\item the set $\Gamma_0$ is a Hausdorff manifold,
	\item the maps $\alpha$ and $\beta$ are differentiable submersions,
	\item the multiplication $m\colon \Gamma_2\to \Gamma$ is differentiable,
	\item the inversion $x\to x^{-1}$ is a diffeomorphism.
\end{enumerate}
