% This is part of (almost) Everything I know in mathematics
% Copyright (c) 2013-2014
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.

\section{Deformation by action of group}    \label{SecDefAction}        %\label{sec:framedef}
%----------------------------------------

The procedure of deformation by group action is described in \cite{TrsStProd}. Let $G$ be a Lie group. We suppose to know a subset $A^G$ of $\Fun(G,\eC)$  such that
\begin{enumerate}
\item $A^G$ is invariant under the left regular representation of $G$ on itself,
\item $A^G$ is provided with a $G$-invariant product $\stG$\nomenclature{$\stG$}{Star product on $G$} such that $(A^G,\stG)$ is an associative algebra. The $G$-invariance means that $\forall a,b\in A^G$,
\[
    (L^*_ga)\stG(L^*_gb)=L^*_g(a\stG b).
\]
\end{enumerate}

Notice that we do not impose any regularity condition on this product. The reason is that the deformation by group action is a formal procedure which allows to guess a product on a manifold. The ``true'' work to prove convergences and invariances has to be done on the level of the deformed manifold.

Now, let $X$ be a manifold endowed with a right action  $\dpt{\tau}{G\times X}{X}$ of $G$.  For $u\in\Fun(X)$, $x\in X$ and $g\in G$, we consider $\alpha^x(u)\in\Fun(G)$ and $\alpha_g(u)\in\Fun(X)$ defined by
\begin{equation}        \label{EqDefalphaxu}
   \alpha^x(u)(g)=\alpha_g(u)(x)=u(\tau_{g^{-1}}(x)),
\end{equation}
and the following functional space on $X$:
\[
   A^X=\{u\in\Fun(X)|\alpha^x(u)\in A^G\,\forall x\in X\}.
\]
For example, the $A^X$ corresponding to $A^G=\Fun(G)$ is the whole $\Fun(X)$.  For $u$, $v\in A^X$, we define $\dpt{\stX}{A^X\times A^X}{\Fun(X)}$\nomenclature{$\stX$}{Star product on $X$}
\begin{equation}\label{eq:def_stG}
   (u\stX v)(x)=\big(\alpha^x(u)\stG \alpha^x(v)\big)(e)
\end{equation}
where $e$ is the identity of $G$.

%\label{lem:dist_alpha}

\begin{theorem}
The product \eqref{eq:def_stG} obtained by action of the group $G$ on the manifold $X$ fulfils the following properties:
\begin{enumerate}
\item\label{itemthostG} The operation $\alpha^x$ intertwines the products $\star^X$ and $\star^G$:
\[
   \alpha^x(u\stX v)=(\alpha^xu)\stG(\alpha^xv).
\]

\item $A^X$ is stable under $\stX$,
\item $(A^X,\stX)$ is an associative algebra.
\end{enumerate}
\end{theorem}

% Attention : dans le texte, je dit des ``first'', ``second'' et ``third'' point. Donc en cas de changement de num√©rotation, je dois adapter le texte.

\begin{proof}
First remark that $\alpha^{\tau_{g^{-1}}(x)}u=L^*_g\alpha^xu$ because
\[
(\alpha^{\tau_{g^{-1}}(x)}u)(h)=u\big(\tau_{(gh)^{-1}}(x)\big)=(\alpha^xu)(gh)
=\big(L^*_g\alpha^xu\big)(h),
\]
It follows that
\begin{equation}
\begin{split}
\alpha^x(u\stX v)(g)&=(u\stX v)(\tau_{g^{-1}}(x))
                    =(\alpha^{\tau_{g^{-1}}(x)}u\stG\alpha^{\tau_{g^{-1}}(x)}v) (e)\\
            &=\left[ L^*_g(\alpha^xu\stG\alpha^xv) \right](e)
            =(\alpha^xu\stG\alpha^xv)(g).
\end{split}
\end{equation}
The first point is proved.

Using the first point, we see that $\alpha^{\tau_{g^{-1}}(x)}u$ belongs to $A^G$ because $\alpha^xu\in G^G$ and $A^G$ is stable under $L_g$. So we have the second point.  For the third one,
\[
\begin{split}
[(u\stX v)\stX w](x)&=\big(\alpha^x(u\stX v)\stG\alpha^x(w)\big)(e)\\
                    &=\big((\alpha^xu\stG\alpha^xv)\stG\alpha^x(w)\big)(e).
\end{split}
\]
The conclusion follows from associativity of $\star^G$.
\end{proof}

Let us summarize what was done up to now. When $G$ acts on $X$, and when we have a ``good'' product on $A^G\subset\Fun(G)$, we are able to build an associative product on $A^X\subset\Fun(X)$. The space $A^X$ is defined by $A$ and the action. So a deformation of a group gives rise to a deformation of any manifold on which the group acts. This is why we call it an ``universal``\ deformation. That universal construction is the motivation to deform groups.

\begin{lemma}
A function $u$ belongs to $A^{X}$ if and only if there exists one $y$ such that $\alpha^y(u)\in A^G$ in each $g$-orbit in $X$.
        \label{LemUnPtParOrbite}
\end{lemma}

\begin{proof}
The necessary condition is direct because, when $u\in A^X$, the function $\alpha^x(u)$ belongs to $A^G$ for every $x$. For the sufficient condition, suppose $\alpha^y(u)\in A^{G}$, then $\alpha^{g\cdot y}(u)=L_{g^{-1}}^*(\alpha^yu)\in A^{G}$ for all $g$ because $A^{G}$ is left invariant. If it holds for a $y$ in each $G$-orbit, then $\alpha^xu\in A^{G}$ for all $x\in X$.
\end{proof}

The content of this lemma is that if one wants to check if a given function $u$ belongs to $A^{X}$, one only has to check is $\alpha^yu\in A^{G}$ for one $y$ in each $G$-orbit.


The functions $\alpha^x(u)$ are not ``gentle'' functions, even when $u$ is. Let us give two examples of pathology that can occur in $\alpha^x(u)$ without to be present in $u$. Firstly,  if the action is the identity, the support of $\alpha^x(u)$ is the whole $G$ which can be non compact. So, even when $u$ is compactly supported, there are no guarantee with respect to the support of $\alpha^x(u)$.

Secondly, the function $\alpha^x(u)$ is of course bounded; but the derivatives are not specially such. Indeed, in order to fix ideas, suppose that the group $G$ is a two parameter group and that the manifold $X$ is a two dimensional manifold. In this case, one can write
\begin{equation}        \label{EqDefziDefA}
  f(a,l)=\alpha^x(u)(a,l)=u\big( z_1(a,l),z_2(a,l) \big)
\end{equation}
where $x$ is a parameter in the functions $z_i$. Depending on the action, the function $z$ can be very odd. In particular, the derivatives
\[
  (\partial_af)(a,l)=(\partial_1u)(z_1,z_2)(\partial_az_1)(a,l)+(\partial_2u)(z_1,z_2)(\partial_az_2)(a,l)
\]
in which $\partial_az_i$ can be divergent. Even worse, the degree of the divergence can increase with the degree of the derivation. Two examples of such a hill behaviour are given in section~\ref{SecEplolUnter}.


\section{A first analysis question}
%++++++++++++++++++++++++++++++++++

The big work will be done in section~\ref{sec:unifsl},

\subsection{A simple toy model}
%-----------------------------

We consider the multiplicative action of $\eR_0$ (i.e. $\eR$ minus zero) on $\eR$ and the induced one on $C(\eR)$:

\begin{equation}
(r\cdot f)(x)=f(rx).
\end{equation}
We are searching for the functions $f\in C(\eR)$ such that the map $\dpt{\phi_f}{\eR}{C(\eR)}$, $\phi_f(r)x=f(rx)$ is continuous. For, we consider the topology on $C(\eR)$ given by a choice of a fundamental sequence of compact sets $(K_m)$ and the open sets
\[
  \mO=\{ g\in C(\eR)\tq \sup_{x\in K_m}| f_0(x)-g(x) |<\varepsilon \}.
\]
for any choice of $f_0$ and $\varepsilon$. We want a $f$ such that $\phi_f^{-1}(\mO)$ is open in $\eR_0$. We have
\begin{equation}
\phi^{-1}_f=\{ z\in\eR_0\tq \sup_{x\in K_m}| f_0(x)-f(zx) |<\varepsilon \}.
\end{equation}
Let us prove that $f(x)=e^x$ makes $\phi_f^{-1}(\mO)=\phi_{\exp}^{-1}(\mO)$ open. Let $z_0\in \phi^{-1}_{\exp}$, i.e.
\[
  \sum_{x\in K_m}| f_0(x)-e^{z_0x} |<\varepsilon.
\]
It just a little game to see that, by choosing $| \delta |$ small enough, we have $z_0+\delta\in\phi_{\exp}^{-1}$.

The important point to remark is that the chosen topology will accept\quext{Est-ce le bon mot ?} all functions which are uniformly continuous on all compact. In particular, it will admit $f(x)=e^{x^2}$. This is \emph{not} the same topology as the one used by Rieffel.

\subsection{The case of interest}
%--------------------------------

Let us now address a problem. Let $R=AN\subset SL(2,\eR)$ and the coadjoint action\index{coadjoint!action} of $R$ on the dual of its Lie algebra $R\times\sR^*\to\sR^*$:
\begin{equation}
(r\cdot \xi)X=\big( \Ad^*(r)\xi \big)(X)=\xi\big( \Ad(r^{-1})X \big).
\end{equation}
for $X\in\sR$, $\xi\in\sR^*$ and $r\in R$. We consider the following decomposition of $R$:
\begin{equation}  \label{eq:defeaeal}
(a,l)=
\begin{pmatrix}
e^a & e^al\\
0 & e^{-a}
\end{pmatrix}
\end{equation}
which induces the group law
\begin{equation}
  (a,l)(a',l')=(a+a',l'+e^{-2a'}l)
\end{equation}
and the inverse
\begin{equation}
  (a,l)^{-1}=(-a,-e^{2a}l).
\end{equation}
Among other relations, we point out $(a,0)=e^{aH}$, $(0,l)=e^{lE}$, $\mtu=(0,0)$ and $(a,l)=(a,0)(0,l)$.

Let us compute explicitly the action of $r=(a,l)$ on $\xi=y_H H^*+y_EE^*$. For this, we consider $X=x_H H+x_EE$ and we compute
\begin{equation}
\begin{split}
  (r\cdot \xi)X&=[(a,l)\cdot (y_HH^*+y_EE^*)](x_HH+x_EE)\\
		&=(y_HH^*+y_EE^*)(\Ad(a,l)^{-1} (x_HH+x_EE) )\\
		&=(y_HH^*+y_EE^*)(x_HH+e^{-2a}(x_E+2e^{2a}lx_H)ZE)\\
		&=(y_H+2y_El)x_H+y_E e^{-2a}x_E.
\end{split}
\end{equation}
So
\begin{equation}
  r\cdot \xi=(y_H+2y_El)H^*+y_Ee^{-2a}E^*.
\end{equation}
From a matrix point of view, the matrix of $(a,l)$ on the basis
$\begin{pmatrix}
H^*\\
E^*
\end{pmatrix}
$, we have
\[
  r=(a,l)\leadsto
\begin{pmatrix}
1&2l\\0&e^{-2a}
\end{pmatrix}.
\]
In particular, the determinant of this matrix is non zero (so the action of $R$ on $\sR^*$ is always bijective), the space spanned by $H^*$ is fixed\footnote{\emph{each} point of this space is fixed.}, and the sign of the $E^*$ component doesn't changes under the action. Then the action has three orbits in $\sR^*$: two half plane of dimension $2$ and one linear subspace of dimension $1$.


\subsection{Smooth vectors of the action}
%----------------------------------------

For $u\in \Fun(\sR^*)$, the actions we are looking at is

\[
  \alpha^{\xi}(u)(r)=\alpha_r(u)\xi=u(\alpha_{r^{-1}}(\xi))
\]
and we consider the map
		\begin{equation}
		\begin{aligned}
			f_u \colon R &\to \Fun\sR^*\
			r&\mapsto u(\alpha_{r^{-1}}(\xi)).
		\end{aligned}
	\end{equation}

 The question is: for which $u\in\Fun(\sR)$, this map is smooth? As first question, we have to precise the sense of a smooth map from $R$ into $\Fun(\sR^*)$. The derivative of $\dpt{f_u}{R}{\Fun(\sR^*)}$ is defined by means of the map $\dpt{\tilde f=f\circ\varphi}{\eR^2}{\Fun\sR^*}$ where $\dpt{\varphi}{\eR^2}{R}$ is the chart \eqref{eq:defeaeal}. We naturally forget the tilde. The quantity which have to be defined is


\[
 f_u'(x)=\lim_{\varepsilon\to 0}\frac{f_u(x+\varepsilon)-f_u(x)}{\varepsilon}.
\]
It is natural to apply it to a $\xi\in\sR^*$ and define

\begin{equation}
f'_u(\xi):=\lim_{\varepsilon\to 0}\frac{f_u(X+\varepsilon)\xi-f_u(x)\xi}{\varepsilon}
	=\lim_{\varepsilon\to 0}\frac{u\big( \alpha_{(x+\varepsilon)^{-1}}(\xi) \big)-u\big( \alpha_{x^{-1}}(\xi) \big)}{\varepsilon}.
\end{equation}



\subsection{Oscillatory definition on \texorpdfstring{$\SL(2,R)$}{SL2R}}  \label{subsec:Oscdefsl}
%---------------------------------------------

The integral we have to study now is
\[
  \int_{R\times R} F(x_1,x_2) e^{2iS(x_0,x_1,x_2)}dx_1dx_2.
\]
Where $x_i=(a_i,l_i)$. As usual, we begin to suppose that $F$ has compact support so that integral makes sense and integration by part does not produce boundary term.

We consider the phase function as
\begin{equation}
S(x_0,x_1,x_2)=l_2\sinh(a_0-a_1)+l_0\sinh(a_1-a_2)+l_1\sinh(a_2-a_0).
\end{equation}
We have
\begin{subequations}
\begin{align}
\partial_{a_1}S&=-l_2\cosh(a_0-a_1)+l_0\cosh(a_1-a_2)\\
\partial^2_{a_1}S&=l_2\sinh(a_0-a_1)+l_0\sinh(a_1-a_2)\\
\partial_{a_2}S&=-l_0\cosh(a_1-a_2)+l_1\cosh(a_2-a_0)\\
\partial^2_{a_2}S&=l_0\sinh(a_1-a_2)+l_1\sinh(a_2-a_0)\\
\partial_{l_1}S&=\sinh(a_2-a_0)\\
\partial_{l_2}S&=\sinh(a_0-a_1)
\end{align}
\end{subequations}
It is easy to compute that, for each $t$ in $\{a_1, a_2, l_1, l_2\}$
\[
  \int (\partial_t^2 F)e^{iS}=\int F[i\partial_t^2S-(\partial_tS)^2]e^{iS}
\]
that we write under the form
\begin{equation}
\int (\Delta F)e^{iS}=\int FLe^{iS}
\end{equation}
with
\[
  L=\sum_t [i\partial^2_t S-(\partial_t S)^2].
\]
Let us write it for $F'=F/(1-L)$:
\[
  \int (1-\Delta)\left( \frac{F}{1-L} \right)e^{iS}=\int Fe^{iS}.
\]
Making an induction, one sees that
\begin{equation}
\int Fe^{iS}=\int [(1-\Delta)\circ M_K]^kF e^{iS}
\end{equation}
where $M_K F=F/(1-L)$ and $K=1/(1-L)$.

Let us suppose that $F$ is a polynomial with respect to $\sinh(a_i)$ and $\cosh(a_i)$. We write $P_{a,b}$, a polynomial of degree $a$ in $\cosh(a_1)$, $\sinh(a_1)$ and of degree $b$ in $\cosh(a_2)$, $\sinh(a_2)$. For example,
\[
  P_{a,b}=\cosh(a_1)^{a}\sinh(a_2)^{b-1}\cosh(a_2).
\]
We will use any abuse of notation as
\[
  \partial_{a_1}(P_{a,b})=P_{a,b}
\]
or $P_{1,7}+P_{4,2}=P_{4,7}$ and so on. We have $L=iP_{1,1}+P_{2,2}$ with real coefficients. One can see that
\begin{equation}
\begin{split}
  \Delta\left( K\frac{P_{a,b}}{P_{c,d}} \right)&=K^3\left( \frac{P_{a+4,b+4}}{P_{c,d}} \right)\\
                                               &\quad+
       K^2\left( \frac{P_{a+2,b+2}}{P_{c,d}} +\frac{P_{a+c+2,b+d+2}}{P_{2c,2d}}+\frac{P_{a+2c+2,b+2d+2}}{P_{3c,3d}} \right)\\
                                               &\quad+
    K\left( \frac{P_{a+2c,b+2d}}{P_{3c,3d}}+\frac{P_{a+5c,b+5d}}{P_{6c,6d}} \right)
\end{split}
\end{equation}
which is for all terms two degrees lower than $\frac{P_{a,b}}{P_{c,d}}$.

So by virtue of operator $[(1-\Delta)\circ M_K]^k$, we can get
\begin{equation}
\int F  e^{iS}=\int \frac{P_{a,b}}{P_{c,d}} e^{iS}
\end{equation}
with $c-a$ and $d-b$ as large as we want.

\subsubsection{First example}
%///////////////////////////////

Let us perform the computation to prove the integrability of $F=\cosh(a_1-a_2)$. First,
\begin{equation}  \label{eq:umDelfracch}
  [(1-\Delta)\circ M_K]\cosh(a_1-a_2)=\frac{\cosh(a_1-a_2)}{1-L}-\Delta\left( \frac{\cosh(a_1-a_2)}{1-L} \right).
\end{equation}
As far as the first term is concerned, we write
\[
  \left\|  \frac{\cosh(a_1-a_2)}{1-L}  \right\|\leq \frac{\| \cosh(a_1-a_2) \|}{\| 1-L \|}.
\]
We find an upper bound of it by forgetting the imaginary part of $L$ and the three first terms of
\[
  \real(1-L)=1+[\partial_{a_1}S]^2+[\partial_{a_2}S]^2+\sinh^2(a_2-a_0)+\sinh^2(a_0-a_1).
\]
Then
\[
  \left\| \frac{\cosh(a_1-a_2)}{1-L}\right\|\leq \frac{\cosh(a_1-a_2)}{\sinh^2(a_2-a_0)+\sinh^2(a_0-a_1)}.
\]
If one looks at it on the line $a_1=a_2=x$, then one finds $\cosh(x)/2\sinh(2x)$ whose limit is $1/2$. So we have to take a second iteration of operator $[(1-\Delta)\circ M_K]$. So let us continue computation \eqref{eq:umDelfracch}.

Since $\nabla F=0$, we find $\Delta F=2\cosh(a_1-a_2)$ and
\begin{equation}
\begin{split}
\Delta\left( \frac{\cosh(a_1-a_2)}{1-L} \right)&=\Delta K \cosh(a_1-a_2)+2K\cosh(a_1-a_2)\\
                                               &=\cosh(a_1-a_2)(\Delta K+2K).
\end{split}
\end{equation}
Simple computation shows that
\begin{equation}
\begin{split}
[(1-\Delta)\circ M_K]^2\cosh(a_1-a_2)&=\cosh(a_1-a_2)(3K^2-K\Delta K)\\
		&\quad-\Delta(\cosh(a_1-a_2)(3K^2-K\Delta K)).
\end{split}
\end{equation}

\begin{lemma}
If the function $F$ becomes larger than any exponential, the integral $\int F e^{iS}$ makes no sense.
\end{lemma}

\begin{proof}
The definition of $\int F e^{iS}$ is given by iteration of operator $[(1-\Delta)\circ M_K]$, but
\begin{equation}
\begin{split}
\int F e^{iS}&=\int [(1-\Delta)\circ M_K]F e^{iS}\\
		&=\int M_KF e^{iS}-\int \Delta\left( \frac{F}{1_L} \right) e^{iS}
\end{split}
\end{equation}
where the function $KF$ in the first integral has same fundamental property as~$F$.
\end{proof}

\subsubsection{Functional spaces}
%////////////////////////////////

From theory developed in~\ref{SecDefAction}, we have to study the set
\[
  A^{\sR^*}=\{ u\in\Fun(\sR^*)\tq \alpha^{\xi}\in A^R\,\forall \xi\in\sR^* \}
\]
where, by definition, $(\alpha^{\xi}u)(r)=u(r^{-1}\cdot\xi)$. From our previous work in~\ref{subsec:Oscdefsl}, we define $A^R$ as the space of functions $\dpt{f}{R}{\eC}$ for which there exists a $m$, $n\in\eN$ such that
\begin{equation}  \label{eq:alpxial}
  (\alpha^{\xi}u)(a,l)^{-1}=u(y_H+2y_El,y_Ee^{-2a}).
\end{equation}

In order the map $(a,l)^{-1}\to u(y_H+2y_El,y_Ee^{-2a})$ to belongs to $A^R$, we need
\begin{equation}
   | u(x_H,x_E) |< | x_E |^n| x_H |^m.
\end{equation}
The point is the fact that $a$ comes in \eqref{eq:alpxial} in an exponential.

\section{Method improvement}
%+++++++++++++++++++++++++++

\subsection{Change of point of view for the integral}
%----------------------------------------------------


The product of two functions $u$, $v\in\Fun(R)$ reads
\begin{equation}
(u\star^R v)(x)=\int_{R\times R} K(x,y,z)u(y)v(z)\,dy\,dz
\end{equation}
where

\begin{itemize}
\item $K$ is left invariant,
\item the measure on $R$ is left invariant,
\item the action $R\times\eA\to\eA$ is the regular right action: $\alpha_g(u)x=u(xg)$.
\end{itemize}
Using these properties, we can transform the integral:
\[
  \begin{aligned}
(u\star^R v)(x)&=\int K(x,y,z)u(y)v(z)\,dy\,dz\\
		&=\int K(e,x^{-1}y,x^{-1}z)u(y)v(z)\,dy\,dz		&\textrm{invariance of $K$}\\
		&=\int K(e,\eta,\zeta)u(x\eta)v(x\zeta)\,d\eta\,d\zeta	&\textrm{measure invariance}\\
		&=\int K(e,\eta,\zeta) (R^*_{\eta}u)(x) (R^*_{\zeta}v)(x)\,d\eta\,d\zeta
\end{aligned}
\]
Then one can write
\begin{equation}  \label{eq:intadefinir}
\begin{split}
u\star^R v=\int_{R\times R} K(e,\eta,\zeta)R^*_{\eta}u R^*_{\zeta}v\,d\eta\,d\zeta
\end{split}
\end{equation}
as a $\eA$-valued integral of a function $R\times R\to\eA$. The problem now is to find a subset $\eA\subset\Fun(R)$ in which it is possible to give a sense to integral \eqref{eq:intadefinir}.

\subsection{Adapted vector field and by part integration}
%--------------------------------------------------------

In~\ref{subsec:Oscdefsl}, we used derivation $\partial_{a_1},\ldots$ to define the oscillatory integral. It was meaningful in the case of the additive action of $\eR^n$ in~\ref{subsec:actionrn} and more generally in the case of Rieffel \cite{Rieffel}. However, these vector fields on $R$ are not natural vector fields in this sense that it ``fits'' no structure. In particular, it does not take account of the action. More natural vector fields are the invariant vector fields for the action:
\begin{equation}
   (\tilde X\cdot u)(x)=\Dsdd{ \alpha_{e^{tX}}u }{t}{0}(x)=\Dsdd{ u(xe^{tX}) }{t}{0}.
\end{equation}
The middle expression shows that $\tilde X$ is a derivation of the action. Let us compute the corresponding by part integration formula.
\begin{equation}
\begin{split}
\int (\tilde X\cdot u)v&=\dsdd{\int (\alpha_{e^{tX}}u)(x)v(x)\,dx }{t}{0}\\
		&=\dsdd{ \int u(xe^{tX})v(x)\,dx }{t}{0}.
\end{split}
\end{equation}
Now the non right invariance of the measure is painful because we want to effect a change of variable $y=xe^{tX}$. We introduce the \defe{modular function}{modular!function} $\Delta$ by
\begin{equation}
  d(xg)=\Delta(g,x)\,dx.
\end{equation}
So $x=ye^{-tX}$ implies $dx=\Delta(e^{-tX},y)\,dy$ and the integral becomes
\begin{equation} \label{eq:euler}
\begin{split}
\int (\tilde X\cdot u)v&=\dsdd{ \int u(y)v(ye^{-tX})\Delta(e^{-tX},y)\,dy }{t}{0}\\
		&=\int u(y)(-\tilde X)v(y)\,dy+\int u(y) v(y)\Dsdd{ \Delta(e^{-tX},y)\,dy }{t}{0}
\end{split}
\end{equation}
and we finally write
\begin{equation}
\int (\tilde X\cdot u)v=-\int u\tilde X\cdot v+\int uv\mu_X
\end{equation}
where $\mu_X$ is defined as the last derivative. Note that in the whole computation, we would had written $\int\frac{d}{dt}$ instead of $\int\frac{d}{dt}$. Then there are in fact no inversion problem.


\subsection{New way to express the problem}
%------------------------------------------

We are now able to give a better statement of our analysis problem. Let $\eA$ be a topological algebra (presently, a subspace of $\Fun(R)$) and a map $F\in C^{\infty}(R\times R,\eA)$, presently
\begin{equation} \label{eq:Fchxun}
F(x,y)=\cosh(x_1-y_1)\alpha_x u\alpha_yv.
\end{equation}
The purpose is to give a sense to
\begin{equation}
\int e^{i\sigma(x,y)}F(x,y)\,dx\,dy
\end{equation}
as element in $\eA$.

\begin{remark}
In order the function \eqref{eq:Fchxun} to be smooth, one needs in particular $u$ and $v$ to be smooth vector of the action.
\end{remark}

We denote by $\tilde X^{(1)}F$ the action of $\tilde X$ on the first variable of $F$. Then
\begin{equation}
\begin{split}
\int \tilde X^{(1)}F e^{i\sigma}&=-\int F\tilde X\cdot(e^{i\sigma})+\int F\mu^{(1)}_Xe^{i\sigma}\\
		&=-i\int F(\tilde X^{(1)}\cdot \sigma)e^{i\sigma}+\int F\mu_X^{(1)}e^{i\sigma}\\
		&=\int [\mu_X^{(1)}-i\tilde X^{(1)}\cdot \sigma]Fe^{i\sigma}
\end{split}
\end{equation}
where
\begin{equation}
  (\tilde X^{(1)}\cdot \sigma)(x,y)=\Dsdd{ \sigma(xe^{tX},y) }{t}{0}.
\end{equation}

When $u$, $v\in\eA$, we look at
		\begin{equation}
		\begin{aligned}
			\Phi \colon R\times R &\to \eA\\
			(x,y)&\mapsto K(e,x,y)(\alpha_xu)(\alpha_yv)e^{i\sigma(x,y)}
		\end{aligned}
	\end{equation}
 and we ask ourself if the integral
\[
  \int_{R\times R}\Phi
\]
exists or not.

\subsection{Topology choice}
%---------------------------

In order to define a Fr√©chet space, we want to put seminorms on $\eA$ in such a way that the action is isometric for each seminorm. For example, if $K$ is a compact set in $R$,
\[
  p_K(u)=\sup_{x\in K}| u(x) |
\]
doesn't works because
\[
  p_K(\alpha_gu)=\sup_{x\in K}| u(xg) | =-p_{gK}(u)\neq p_K(u).
\]

We now suppose that $\eA$ is a Banach algebra for the supremum norm and we are searching for a topological structure on the subspace $\eA^{\infty}$. So we can try the following seminorm:
\begin{equation}
   p'_X(u)=\| X\cdot u \|_{\eA},
\end{equation}
but it does not work because
\begin{equation}
\begin{split}
  (X\cdot \alpha_gu)(x)&=\Dsdd{ (\alpha_gu)(xe^{tX}) }{t}{0}\\
		&=\Dsdd{ u(xe^{tX}g) }{t}{0}\\
		&=\Dsdd{ (\alpha_{e^{tX}g}u)(x) }{t}{0}\\
		&=\Dsdd{ (\alpha_{g\AD(g^{-1})e^{tX}}u)(x) }{t}{0}\\
		&=\Dsdd{ (\alpha_{ge^{t\Ad(g^{-1})X}}u)(x) }{t}{0}\\
		&=\alpha_g\Ad(g^{-1})\cdot u.
\end{split}
\end{equation}
Then
\[
  p'_X(\alpha_gu)=\| \alpha_g\Ad(g^{-1})X\cdot u \|_{\eA},
\]
but the action is isometric with respect to $\| . \|_{\eA}$ because it is a supremum norm. It leads to
\[
  p'_X(\alpha_gu)=p_{\Ad(g^{-1})X}u
\]
and there are no reason for $\| \Ad(g^{-1})X\cdot u \|_{\eA}$ to be equal to $\| X\cdot u \|_{\eA}$.

Semi-norms in which the action is isometric are given by
\begin{equation}
  p_X(y)=\sup_{g\in R}\| X\cdot \alpha_g(u) \|_{\eA}.
\end{equation}
We put on $\eA^{\infty}$ the topology of these seminorms when $X\in\mU(\eR)$, the enveloping algebra of $\eR$, see~\ref{subsec:env_alg}. This is the quotient of the tensor algebra $T(\eR)$ by relation $X\otimes Y-Y\otimes X\sim [X,Y]$.

It is immediate to see that $\eA^{\infty}$ is Hausdorff with this topology by taking $X=1\in\mU(\eR)$:
\[
  p_1(w)=\sum_{g\in R}\| \alpha_g(w) \|_{\eA},
\]
but
\begin{equation}
   \| \alpha_g w \|_{\eA}=\sum_{x\in R}| \alpha_g w(x) |_{\eC}
		=\sup_{x\in R}| w(xg) |_{\eC}
\end{equation}
which is zero only if $w$ is identically zero.



\subsection{Convergence condition}
%--------------------------------

Our strategy is to transform the integral over $R\times R$ into an integral over $\eR^2\times\eR^2$ and to reduce the problem to a simple application of Rieffel's method described in \cite{Rieffel}.

Let $\alpha$ be the regular right action of $R$ on $\Fun(R)$ and the integral
\begin{equation}
\iint_{R\times R}\cosh(a_1-a_2)\alpha_{x_1}(u)\alpha_{x_2}(v)e^{i[\sinh(a_1)l_2]-\sinh(a_2)l_1}
\end{equation}
in which we perform the change of variable $\xi_j=\sinh(a_j)$, $da_j=\frac{ d\xi_j }{ \sqrt{1+\xi_j^2} }$. The phase becomes $\xi_jl_2-\xi_2l_1=\omega(p_1,p_2)$ where $\omega$ is the usual symplectic form. Since $\cosh(a_1-a_2)=\sqrt{1+\xi_1^2}\sqrt{1+\xi_2^2}$, the integral to be computed  is
\[
  \int_{\eR}\int_{\eR^2}\frac{ \sqrt{1+\xi_1^2}\sqrt{1+\xi_2^2}-\xi_1\xi_1  }{ \sqrt{1+\xi_1^2} \sqrt{1+\xi_2^2}  }e^{i\omega(p_1,p_2)} \tilde\alpha_{p_1}(u)\tilde\alpha_{p_2}(v)
\]
where
\begin{equation}
  \big( \tilde\alpha_p(u) \big)(x,y)=\big( R^*_{(\arcsinh\xi,l)}u \big)(x,y)=u( x+\arcsinh\xi,l+e^{-2\arcsinh\xi}y ).
\end{equation}
This is not a bounded operator on $ C^{\infty}(R)$.
It is easy to see that the fraction is a bounded function and that all the derivatives are also bounded by studying the function $\beta(\xi)=\xi/\sqrt{1+\xi^2}$.

Let us see more precisely $\tilde\alpha(u)$:
\begin{equation}
\begin{split}
(\tilde\alpha_py)(x,y)&=u\big( (x,y)(\arcsinh\xi,l) \big)\\
		&=u\big( x+\arcsinh\xi,l+e^{-2\arcsinh\xi}y \big)\\
		&=u\big( x+\arcsinh\xi,l+y(\sqrt{\xi^2+1}-\xi)^2 \big).
\end{split}
\end{equation}
Then
\begin{equation}
\partial_{\xi}(\tilde\alpha_pu)(x,y)=(\partial_xu)(\ldots)\frac{1}{ \sqrt{ 1+\xi^2 }}+y(\partial_yu)(\ldots)2(\sqrt{\xi^2-1})(\frac{ \xi }{ \sqrt{\xi^2+1}-2 })
\end{equation}
The conclusion is that
\begin{equation}
\begin{split}
\partial_{\xi}(\tilde\alpha_pu)(x,y)&=\tilde\alpha_p(\partial_xu)(x,y)f_1(\xi)\\
		&+\tilde\alpha_p(y\partial_yu)(x,y)f_2(\xi).
  \end{split}
\end{equation}
where $f_1$ and $f_2$ are bounded functions with all derivative bounded, i.e. functions in the space of Rieffel. In the same way,
\begin{equation}
(\partial_l\tilde\alpha u)(x,y)=\tilde\alpha_p(\partial_yu).
\end{equation}
If we put $X=\partial_x$, $Y=y\partial_y$ and $Z=\partial_y$

We are studying the integral
\[
  \int_{\eR^2\times\eR^2} B(\xi_1,\xi_2)\tilde\alpha_{p_1}(u)\tilde\alpha_{p_2}(v)e^{i\omega(p_1,p_2)}\,dp_1\,dp_2.
\]
Since the phase function has the same form as the one of Rieffel, the condition that we have to impose on $u$ and $v$ must be such that $\tilde\alpha_p(u)$ fulfils Rieffel's condition, namely $\partial_{\xi}(\tilde\alpha u)$, $\partial_l(\tilde\alpha u)$ and so on must be bounded. This leads us to only consider functions $u$ on $R$ such that $\partial_x^ku$ and $y^n\partial^m_yu$ are bounded for all $k$ and $m\geq n$.


Let us now more precisely the Fr√©chet algebra issues. For $u$, $v\in\Fun(R)$, we pose
\[
\begin{aligned}
   u\star^R v&=\int_{R\times R} \cosh(a_1-a_2)\alpha_{x_1}(u)\alpha_{x_2}(v)e^{[\cdots]}\,dx_1\,dx_2\\
	&=\int_{\eR^2\times\eR^2}B(\xi_1,\xi_2)\tilde\alpha_{p_1}(u)\tilde\alpha_{p_2}(v)e^{i\omega(p_1,p_2)}\,dp_1\,dp_2.
\end{aligned}
\]
We want the function $\dpt{ F }{ \eR^2\times\eR\sp 2 }{ \Fun(R) }$ given by
\[
  F(p_1,p_2)=\tilde\alpha_{p_1}(u)\tilde\alpha_{p_2}(v)
\]

We put the following seminorms on $ C^{\infty}(R)$:
\begin{equation}
\| u \|_k=\sup_{(a,l)\in R}| l^ku(a,l) |;
\end{equation}
this is an increasing family. We say that $A$ is the set of $ C^{\infty}(R)$ functions which are bounded for each of these seminorms. It is Fr√©chet because
\[
\begin{split}
\| uv \|_k&=\sup | l^ku(a,l)v(a,l) |\\
		&\leq \sup| l^ku(a,l) |\sup| l^kv(a,l) |\\
		&=\| u \|_k\| v \|_k.
\end{split}
\]

We have
\begin{equation}
\begin{split}
(\partial_X u)(x,y)&=\Dsdd{ \big( \tilde\alpha_{tX}(u) \big)(x,y) }{t}{0}\\
		&=\Dsdd{ u\big( x+\arcsinh(tX_x), tX_y+e^{-2\arcsinh tX_x}y \big) }{t}{0}\\
		&=\partial_x u+(\partial_yu)\Dsdd{ yX_y+e^{-2\arcsinh tX_x}y }{t}{0}\\
		&=\partial_xu+X_y(\partial_yu)-2 y(\partial_yu).
\end{split}
\end{equation}

\subsection{Some inequalities in  \texorpdfstring{$C^{\infty}(R)$}{CR}}
%--------------------------------------------------

\begin{lemma}
For each $u\in A^{\infty}$, we have

\begin{enumerate}
\item $\| u \|_{jk}\leq \| u \|_{(j+1)k}$,
\item $\| \partial_tu \|_{jk}\leq c_k\| u \|_{j(k+1)}$,
\item $\| yu \|_{jk}\leq \| u \|_{(j+1)k}$,
\end{enumerate}
where $t$ denotes $x$ or $y$, and $yu$ denotes the function $(x,y)\mapsto yu(x,y)$.  In particular
\begin{equation}
\| y\partial_yu \|_{jk}\leq c_k\| u \|_{(j+1)(k+1)}
\end{equation}

\end{lemma}

\begin{proof}
The first claim is immediate. For the second, remark that each term in $\| u \|_{j(k+1)}$ has a corresponding term in $\| \partial_tu \|_{jk}$ with a different coefficient. For example, the term $\sup_{i\leq j}\| \partial_x^2u \|_i$ in $\| \partial_xu \|_{jk}$ corresponds to $\frac{ 1 }{2}\sup_{i\leq j}\| \partial_x^2u \|_i$ in $\| u \|_{j(k+1)}$. These coefficients are depend only on $k$ and can be majored by a constant $c_k$. This proves the second inequality.

For the next inequality, computes
\begin{equation}
\begin{split}
  \| yu \|_{jk}&=\sup_{i\leq j}\sum_{|\mu|\leq k}\frac{1}{ \mu }\| \partial_{\mu}(yu) \|_i\\
		&\leq \sup_{i\leq j}\sum_{\mu}\frac{1}{ \mu }\| y\partial_{\mu} \|_i\\
		&=\sup_{i \leq j}\sum_{\mu}\frac{1}{ \mu }\| \partial_{\mu}u \|_{i+1}.
\end{split}
\end{equation}
The set on which the supremum is taken for $\| u \|_{(j+1)k}$ has the extra term $\sum_{\mu}\frac{1}{ \mu }\| \partial_{\mu}\|_0$. Then $\| yu \|_{jk}\leq \| u \|_{(j+1)k}$.

\end{proof}

\begin{proposition}
For each $X\in V$ and $u\in C^{\infty}(R)$, we have
\begin{equation}
\| \tilde\alpha_Xu \|_{jk}\leq c_{kX}\| u \|_{(j+1)(k+1)}
\end{equation}
where $c_{kX}$ is a constant which only depend on $X$ and $k$.
\end{proposition}

\begin{proof}
From definitions,
\begin{equation}
\begin{split}
(\tilde\alpha_Xu)(x,y)&=\Dsdd{ \tilde\alpha_{tX}u(x,y) }{t}{0}\\
		&=X_{\xi}(\partial_xu)(x,y)+[X_l-2X_{\xi}y](\partial_yu)(x,y).
\end{split}
\end{equation}
Then, using the lemma,
\begin{equation}
\begin{split}
\| \tilde\alpha_Xu \|_{jk}&\leq | X_{\xi} |\| \partial_xu \|_{jk}+| X_l |\| \partial_yu \|_{jk}+2| X_{\xi} |\| y\partial_yu \|_{jk}\\
			&\leq c_k\| u \|_{(j+1)(k+1)}.
\end{split}
\end{equation}

\end{proof}


\begin{proposition}
Let $u\in A^{\infty}$ then $F_u\in C_u(V,A^{\infty})$ defined by
\[
  F_u(p)=\tilde\alpha_p(u).
\]
is a smooth vector for the action $\tau$ of $V$ on $C_u(V,A^{\infty})$ by translation:
\[
  (\tau_rF)(p)=\tilde\alpha_{p+r}(u).
\]

\end{proposition}

\begin{proof}
Let
		\begin{equation}
		\begin{aligned}
			 f  \colon V &\to C_u(V,A^{\infty})\\
			r&\mapsto \tau_rF_u.
		\end{aligned}
	\end{equation}
and
		\begin{equation}
		\begin{aligned}
			 g  \colon V &\to A A^{\infty}\\
			r&\mapsto \tilde\alpha_r(u).
		\end{aligned}
	\end{equation}
The map $g$ is smooth by definition of $A^{\infty}$. One can write
\begin{equation}
(\tau_rF_u)(p)=\tilde\alpha_{p+r}(u)
		=g(p+r)
		=(g\circ (+r))(p),
\end{equation}
so that
\[
  f=g\circ(+),
\]
where $\dpt{ (+) }{ V }{ \Trans V }$ is the map which to $v\in V$ assign the translation by $v$. When we write $g\circ(+)$, we identify $\Trans V$ with $V$ itself. So by $f=g\circ(+)$, we mean the chain
\[
  V  \stackrel{(+)}{\to}  \Trans V\stackrel{\id}{\to} V\stackrel{g}{\to}C_u(C,A^{\infty}).
\]
This is a composition of smooth maps.


\end{proof}


\subsection{Compactly supported function}
%---------------------------------------

When $u\in C_c^{\infty}(R)$, $F_u$ is bounded:
\[
  \| F_u(p) \|_{jk}=\| \tilde\alpha_p(u) \|=\sup_{i\leq j}\sum _{\mu\leq k}\frac{1}{ \mu! }\| \partial_{\mu}(\tilde\alpha_p(u)) \|_i
\]
which is bounded because $u$ is compact supported.

\begin{proposition}
The smooth compact supported functions on $R$ are smooth vectors of the action $\tilde\alpha$.
\end{proposition}

\begin{proof}
We are looking at
\[
 f(r)=\tilde\alpha_r(u)=u\big( \alpha(x,r),\beta(x,r) \big)
\]
for certain functions $\alpha$ and $\beta$. Let us, for an induction argument a map $\dpt{ g }{ V }{  C^{\infty}(R) }$,
\begin{equation} \label{eq_formfind}
  g(r)(x,y)=a\big( \gamma(x,y),\delta(y,r) \big)
\end{equation}
where $a$ is smooth and compactly supported and $\gamma$ and $\delta$ are smooth but not special compactly supported and neither bounded. We suppose however that $\gamma$ and $\delta$ are bounded on every bounded set. We have
\begin{equation}
\begin{split}
  (\partial_Xg)(r)(x,y)&=\Dsdd{ g(r+tX)(x,y) }{t}{0}\\
		&=\Dsdd{ a\big( \gamma(x,r+tX),\delta(y,r+tX) \big) }{t}{0}\\
		&=(\partial_xa)\big( \gamma(x,r),\delta(y,r) \big)
           \big( X_{\xi}(\partial_{\xi}\gamma)(x,r)+X_l(\partial_l\gamma)(x,r)   \big)\\
		&\quad+(\partial_ya)\big( \gamma(x,r),\delta(y,r) \big)\big( X_{\xi}(\partial_{\xi}\delta)(y,r)+X_l(\partial_l\delta)(y,r) \big).
\end{split}
\end{equation}
The functions $(\partial_x a)$ and $\partial_ya$ are compact supported and the whole expression is bounded. Then the element $(\partial_Xg)(r)$ is a sum and product of functions of the type of $g$ itself. By induction, any derivative of $f$ will be of the same type.

We have now to prove that $\dpt{ g }{ V }{  C^{\infty}(R) }$ is continuous. Let $\mO$ be an open subset of $ C^{\infty}(R)$:
\[
  \mO=\{ h\in C^{\infty}(R)\tq \sup_{(x,y)\in R}| y^jh(x,y)  |\leq\varepsilon\,\forall j\geq j_0 \}.
\]
Let $g(r)\in\mO$. We want to prove that $g(r+\varepsilon')$ belongs to $\mO$ too when $\varepsilon'$ is small enough. From continuity, taking a suitable $t\in V$, we can get
\[
   \left| y^ja\big( \gamma(x,r),\delta(y,r) \big)-y^ja\big( \gamma(x,r+t),\delta(y,r+t) \big) \right|\leq\varepsilon'
\]
Then
\begin{equation}
\begin{split}
\sup_{(x,y)\in R}\Big|  y^ja\big( \gamma(x,r+t),\delta(y,r+t) \big)   \Big|&=
	\sup_{(x,y)\in R}\Big|   y^ja\big( \gamma(x,r+t),\delta(y,r+t) \big)\\
		&\qquad-y^ja\big( \gamma(x,r),\delta(y,r) \big)\\
		&\qquad+ y^ja\big( \gamma(x,r),\delta(y,r) \big) \Big|\\
		&\leq \sup_{(x,y)\in R}\Big|  y^ja\big( \gamma(x,r+t),\delta(y,r+t) \big)\\
		&\qquad  - y^ja\big( \gamma(x,r),\delta(y,r)  \Big|\\
		&\qquad + \sup_{(x,y)\in R}\Big|   y^ja\big( \gamma(x,r),\delta(y,r)  \Big|\\
		&\leq\varepsilon'+\varepsilon.
\end{split}
\end{equation}
We conclude that a map of the form \eqref{eq_formfind}  is continuous and the induction proves that any compact supported smooth function on $R$ is a smooth vector for the action $\tilde\alpha$.


\end{proof}


%%%%%%%%%%%%%%%%%%%%%%%%%%
%
   \section{The construction}
%
%%%%%%%%%%%%%%%%%%%%%%%%

We consider the Fr√©chet algebra $A= C^{\infty}_{XYZ}(R)$, the space of smooth function which are bounded for the following seminorms:
\begin{equation}
\| u \|_j=\sup_{(x,y)\in R}| y^j u(x,y) |.
\end{equation}
We consider the action $\tilde\alpha$ of $V=\eR^2$ on $A$ defined by
\begin{equation}
\tilde\alpha_{(\xi,l)}(u)(x,y)=u\big( x+\arcsinh\xi,l+e^{-2\arcsinh\xi}y \big)
\end{equation}


\begin{lemma}
This action is intern on $A$, i.e. for all $p\in V$ and $u\in A$, $\tilde\alpha_p(u)\in A$.
\end{lemma}

\begin{proof}
We have to prove that, for each $j$, the quantity
\[
  \| \tilde\alpha_p(u) \|_j=\sup_{(x,y)}| y^ju(x+C,B+Ay) |
\]
is bounded for arbitrary constants\footnote{In fact, $A$ and $B$ are related but it doesn't matter here.} $A$, $B$, $C\in\eR$ with $A\neq 0$. We can completely forget $C$ because of the $\sup$ on $x$, but we have to take care about $A$ and $B$ because $y$ appears one time under the form $Ay+B$ and one under the form $y^j$. So we have to perform the change of variable $z=Ay+B$ in the $\sup$:
\begin{equation}
\begin{split}
 \| \tilde\alpha_p(u) \|_j	&=\sup_{(x,z)}\left|   \Big( \frac{ z-B }{ A } \Big)^ju(x,z)    \right|
				=\Big| \frac{1}{ A }  \Big|^j\sup_{(x,z)}| (z-B)^ju(x,z) |\\
				&=\Big| \frac{1}{ A }  \Big|^j\sup_{(x,z)}| [z^j-jBz^{j-1}\pm\cdots]u(x,z) |\\
				&\leq\Big| \frac{1}{ A }  \Big|^j\left[  \sup_{(x,z)}| z^ju |-Bj\sup_{(x,z)}| z^{j-1}u |\pm\cdots  \right]\\
				&=\Big| \frac{1}{ A }  \Big|^j\big[  \| u \|_j-Bj\| u \|_{j-1}\pm\cdots   \big]
\end{split}
\end{equation}
where each term is finite because $u\in C^{\infty}_{XYZ}(R)$.

\end{proof}

Now we consider $A^{\infty}$, the Fr√©chet algebra of smooth vectors of the action $\tilde\alpha$ endowed with the seminorms
 \begin{equation}
\| u \|_{jk}=\sum_{i\leq j}\sum_{| \alpha |\leq k}\frac{1}{ \alpha! }\| \partial_{\alpha}u \|_i
\end{equation}
where
\[
  \partial_Xu=\Dsdd{ \tilde\alpha_{tX}(u) }{t}{0}.
\]

\begin{lemma}
Let suppose that the map $\dpt{ \tilde \alpha }{ A }{ A }$ is continuous for each $p\in V$. If $u\in A^{\infty}$, then $\partial_Xu\in A^{\infty}$.
\end{lemma}

\begin{proof}
Let $\dpt{ g }{ V }{ A }$ given by $g(r)=\tilde\alpha_r(\partial_Xu)$. Our purpose is to prove that $g$ is smooth. The derivative $\partial_Yg$ is given by
\[
 \begin{split}
	(\partial_Yg)(r)&=\Dsdd{ g(r+tY) }{t}{0}
			=\Dsdd{ \tilde\alpha_{r+tY} \Dsdd{ \tilde\alpha_{sX}u }{s}{0} }{t}{0}\\
			&=\DDsdd{ \tilde\alpha_{r+tY+sX}u }{t}{0}{s}{0}
			=(\partial_{XY}f)(r)
\end{split}
\]
where $f$ is smooth because it is the function $f(p)=\tilde\alpha_pu$. The continuity of $\tilde\alpha_p$ we used when we inverted $\tilde\alpha_{r+tY}$ and $d/ds$.

\end{proof}

\subsection{The problem with Rieffel}
%------------------------------------


Let $\eA$ be a $C^*$-algebra on which $R$ has a strongly continuous action $\tilde\alpha$. The integral that we consider is
\[
  \int_{\eR^2\times\eR^2}e^{i\omega(p,q)}B(p,q)\tilde\alpha_p(a)\tilde\alpha_q(b)\,dp\,dq
\]
where $a\in\eA$. The theorem of convergence of oscillatory integrals says that

\begin{theorem}
Let $F\in C^{\infty}(\eR^N,\eA)$ such that there exists a $m\in\eR$ with property that for all multi-index $\alpha$, there exists a $C_{\alpha}$ such that
\begin{equation} \label{eq_def_symb_m}
  | \partial^{\alpha}_{\eta}F(\eta) |\leq C_{\alpha}(1+| \eta |)^{m-| \alpha |},
\end{equation}
then the integral
\[
  \int_{\eR^N\times\eR^N} e^{ip\cdot q}F(p,q)\,dp\,dq
\]
makes sense.

\end{theorem}
When $F$ checks condition \eqref{eq_def_symb_m}, we say that $F\in\swS(\eR^N,\eA)$.

\begin{definition}
We say that $a\in\eA$ is a \defe{symbolic vector}{symbolic vector} of order $m$ is the map $x\mapsto\tilde\alpha_x(a)$ belongs to $\swS^m(\eR^2,\eA)$.
\end{definition}
We denote by $\eA^{(m)}$ the set of all symbolic vectors of order $m$ on $\eA$. The question is to know if $A^{\infty}:=\bigcup_{m\in\eR}\eA^{(m)}$ is at least dense in $\eA$.

Let us consider the case $\eA=C_0(R)$: the functions which decrease to zero at infinity with the right regular action
\[
  (\alpha_ra)(r')=a(r'r).
\]
Since the group law is
\[
  (a,l)(a',l')=(a+a',l+e^{-2a'}l),
\]
we find
\begin{equation}
\big( \tilde\alpha_{(\xi,l)}a \big)(x,y)=a\big( x+\arcsinh\xi,l+e^{-2\arcsinh\xi}y \big).
\end{equation}
When we want to perform $\int Fe^{i\omega}$ with methods from Rieffel, we are led to integrate derivatives and among others, we have to integrate over $(\xi,l)$ the expression
\begin{equation}
\begin{split}
\partial_{\xi}\big(\tilde\alpha_{(\xi,l)}a\big)(x,y)&=\partial_{\xi}a\big( x+\arcsinh\xi,l+e^{-2\arcsinh\xi}y \big)\\
		&=\frac{1}{ \sqrt{1+\xi^2} }(\partial_xa)( x+\arcsinh\xi,l+e^{-2\arcsinh\xi}y )\\
		&\quad +2y\left( \frac{ -\xi }{ \sqrt{\xi^1-1} } \right)\big(\sqrt{\xi^2+1}-\xi\big)\times\\
		&\qquad\times(\partial_ya)( x+\arcsinh\xi,l+e^{-2\arcsinh\xi}y )\\
		&=\tilde\alpha(\partial_xa)(x,y)f_1(\xi)+y\tilde\alpha_p(\partial_ya)(x,y)f_2(\xi).
\end{split}
\end{equation}
Since we want to integrate it with respect to $p$ as function $R\to \eA$, we have to regroup the dependence in $x$ and $y$ in order to show some bound in the supremum norm. Using formula
\[
  e^{-2\arcsinh x}=\big( \sqrt{x^2+1}-x \big)^2,
\]
we find $\tilde\alpha_{(\xi,l)}y=l+y(\sqrt{\xi^2}-x)^2$ and then
\begin{subequations}
\begin{align}
\partial_{\xi}\big( \tilde\alpha_{(\xi,l)}a \big)(x,y)&=(\partial_xa)( x+\arcsinh\xi,l+e^{-2\arcsinh\xi}y )f_1(\xi)\\
	&\quad+( \partial_ya)(x+\arcsinh\xi,l+e^{-2\arcsinh\xi}y)\times\\
	&\qquad\times 2y\big( \sqrt{\xi^2+1}-\xi \big)\left( \frac{ 1 }{2}\frac{ 2\xi }{ \sqrt{\xi^2+1} }-1 \right)\\
	&=\frac{ -2 }{ \sqrt{\xi^2+1} }\Big[  \tilde\alpha_{(\xi,l)}(\partial_ya)\big( \tilde\alpha_{(\xi,l)}y\big)-\tilde\alpha_p(\partial_ya) l  \Big]
\end{align}
\end{subequations}
Using the fact that $\tilde\alpha$ is a representation,
\[
\begin{split}
\partial_{\xi}(\tilde\alpha_{(\xi,l)}a)&=\tilde\alpha(\partial_xa)f_1(\xi)\\
		&\quad -\frac{ 2 }{ \sqrt{\xi^2+1} }\Big[ \tilde\alpha_p(y\partial_ya)-\tilde\alpha_p(\partial_ya)l\Big]
  \end{split}
\]
whatever the (semi)norms in $\eA$ are, one cannot hope a better upper bound that something like
\[
 \begin{split}
  | \partial_{\xi}\tilde\alpha_pa |&\leq | f_1(\xi) |\| \tilde\alpha(\partial_xa) \|_k+| f_2(\xi) |\| \tilde\alpha_p(y\partial_ya) \|_k-| l | |f_2(\xi) |\| \tilde\alpha\partial_ya \|_k
\end{split}
\]
The presence of the $l$ factor dooms any attempt to perform the integral with Rieffel methods.

\[
  \mathcal{FIN}
\]
