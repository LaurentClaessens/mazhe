% This is part of (almost) Everything I know in mathematics and physics
% Copyright (c) 2013-2014,2017-2018, 2020-2021
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.

\subsection{Cartan criterion}
%----------------------------

Let us recall a result: $\dD\lG=\lG^1$, $[\dD\lG,\dD\lG]\subset\lG^2$; then $\dD^k\lG\subset\lG^k$. Thus if $\lG$ is nilpotent, it is solvable. On the other hand, by the Engel theorem~\ref{tho:Engel}, $\dD\lG$ is nilpotent if and only if all the $\ad_{\dD\lG}x$ are nilpotent for $x\in\dD\lG$.


\begin{theorem}[Cartan criterion]
Let $\lG$ be a subalgebra of $\gl(V)$. We suppose that $\tr(xy)=0$ $\forall x\in\dD\lG, y\in\lG$. Then $\lG$ is solvable.
\end{theorem}

\begin{proof}
It is sufficient to prove that $\dD\lG$ is nilpotent indeed if we write $\dD^k\lG\subset\lG^k$ with $\dD\lG$ instead of $\lG$, $\dD^{k+1}\lG\subset(\dD\lG)^k$. If $\dD\lG$ is nilpotent, $(\dD\lG)^n=0$ and $\dD^{n+1}\lG=0$ so that $\lG$ is solvable.

Let us consider $x\in\dD\lG$. We have to prove that it is ad-nilpotent (see the Engel theorem~\ref{tho:Engel}). Let $A=\dD\lG$, $B=\lG$ and $M=\{x\in\gl(V)\tq [x\lG]\subset\dD\lG\}$. By definition of $\dD\lG$, $\lG\subset M$. The lemma~\ref{lem:M_nil} will conclude that $x\in\dD\lG$ is nilpotent if $\tr(xy)=0$ for any $y\in M$. Here we just have this equality for $y\in\lG$.

A typical generator of $\dD\lG$ is $[x,y]$ with $x$, $y\in\lG$. Take a $z\in M$; by the formula $\tr([x,y]z)=\tr(x[y,z])$, the trace that we have to check is
\begin{equation}
  \tr([x,y]z)=\tr(x[y,z])
             =\tr([y,z]x).
\end{equation}
But with $z\in M$, $[y,z]\in\dD\lG$, then $\tr([x,y]z)=\tr([y,z]x)=0$. Thus we are in the situation of the lemma.
\end{proof}


\begin{corollary}\label{cor:ad_g_sol}
A Lie algebra $\lG$ for which $\tr(\ad x\circ\ad y)=0$ for all $x\in\dD\lG$, $y\in\lG$ is solvable.
\end{corollary}

\begin{proof}
We consider $\lH=\ad\lG$; this is a subalgebra of $\gl(V)$ such that $a\in\dD\lH$ and $b\in\lH$ imply $\tr(ab)=0$. In order to see it, remark that $a\in\dD\lH$ can be written as $a=[\ad x,\ad y]=\ad[x,y]$ for certain $x$, $y\in\lG$. Then $\tr(ab)=\tr(\ad[x,y]\ad z)$ with $x$, $y$, $z\in\lG$; this is zero from the hypothesis. Then $\lH=\ad\lG$ is solvable.

It is also known that $\ker(\ad)=\mZ(\lG)$ is also solvable. Now we consider $\lM$ a complementary of $\mZ(\lG)$ in $\lG$: $\lG=\mZ\oplus\lM$. The Lie algebra $\ad(\lM)$ is solvable and the homomorphism $\dpt{\phi}{\ad\lM}{\lM}$ defined by $\phi(\ad x)=x$ is well defined. From the first item of the proposition~\ref{prop:trois_resoluble}, $\lM$ is solvable. With obvious notations, an element of $\dD\lM$ can be written as $[m,m']$ (because $\mZ(\lG)$ don't contribute to $\dD\lG$). Then $\dD\lG=\dD\lM$, so that $\lG$ is as much solvable than $\lM$.
\end{proof}


\begin{lemma}
The radical of a Lie algebra is non zero if and only if it has at least non zero abelian ideal.
\label{lem:ss_ideal}
\end{lemma}

\begin{proof}
The radical of $\lG$ is its unique maximal solvable ideal. An eventually non empty abelian ideal should be in the radical.

Let us now consider that the radical is non zero, and consider the derived series of $\Rad\lG$. Since $\Rad\lG$ is solvable, we can consider $n$, the minimal integer such that $\dD^n\Rad\lG=0$. Then $\dD^{n-1}\Rad\lG$ is a non zero abelian ideal.
\end{proof}


\begin{theorem}     \label{ThoRadicalEquivSS}
A Lie algebra is semisimple if and only if its radical is zero.
\end{theorem}

\begin{proof}
\subdem{Direct sense}
We suppose $\Rad\lG=0$ and we consider $S$, the radical of the Killing form:
\[
   S=\{X\in\lG\tq B(X,Y)=0\,\forall Y\in\lG\}.
\]
By definition, for any $X\in S$ and $Y\in\lG$, $\tr(\ad X\circ\ad Y)=0$. The Cartan criterion makes $\ad S$ solvable and the corollary~\ref{cor:ad_g_sol} makes $S$ solvable.

Now, the $ad$-invariance of the Killing form turns $S$ into an ideal, so that $S\subset\Rad(\lG)$ because any solvable ideal is contained in $\Rad\lG$. From the assumptions, $\Rad S=0$, then $S\subset\Rad\lG=0$. This shows that the Killing form is nondegenerate.

\subdem{Inverse sense}
We suppose $S=0$ and we will show that any abelian ideal of $\lG$ is in $S$. In this case, if $A$ is a solvable ideal with $\dD^nA=0$, then $\dD^{n-1}A$ is an abelian ideal, so that $\dD^{n-1}A=0$. By induction, $A=0$.

Let $I$ be an abelian ideal of $\lG$, $X\in I$ and $Y\in\lG$. Then $\ad X\circ\ad Y$ is nilpotent because for $Z\in\lG$,
\begin{equation}
  (\ad X\ad Y\ad X\ad Y)Z=(\ad X\ad Y)\underbrace{( [X,[Y,Z]] )}_{=X_1\in I}
                         =(\ad X)\underbrace{[Y,X_1]}_{=X_2\in I}
             =(\ad X)X_2
             =0.
\end{equation}
Then $0=\tr(\ad X\ad Y)=B(X,Y)$ and $X\in S$, so that $I\subset S=0$.

\end{proof}

\subsection{More about radical}
%-------------------------------

If $\lG$ is a Lie algebra whose radical is $\lR$, we say that a subalgebra $\lS$ of $\lG$ is a \defe{Levi subalgebra}{levi subalgebra} if $\lG=\lR\oplus\lS$.

Any Lie algebra posses a Levi subalgebra\quext{Reference needed.}.

\begin{lemma}
If $\lA$ is an ideal in a Lie algebra $\lG$, then
\[
  \Rad\lA=(\Rad\lR)\cap\lA.
\]
\label{lem:rad_ideal}
\end{lemma}

Before to begin the proof, let us recall that lemma~\ref{lem:pre_trois_resoluble} gives us an isomorphism $\dpt{\psi}{(\lA+\lB)/\lA}{\lB/(\lA\cap\lB)}$ when $\lA$ and $\lB$ are ideals in $\lG$.

\begin{proof}[Proof of the lemma]
If $\lR$ is the radical of $\lG$, then the radical of $\lG/\lR$ is zero, so that $\lR/\lR$ is semisimple. Let $\lA$ be an ideal in $\lG$, then $(\lA+\lR)/\lR$ is an ideal in the semisimple Lie algebra $\lG\lR$, so that it is also semisimple. From the isomorphism, $\lA/(\lA\cap\lR)$ is also semisimple and $\lA\cap\lR$ must contains the radical of $\lA$. Indeed if a solvable ideal of $\lA$ where not in $\lA\cap\lR$, then this should give rise to a non zero solvable ideal in $\lA/(\lA\cap\lR)$ although the latter is semisimple. Then $\lA\cap\lR=\Rad\lA$.
\end{proof}

\begin{proposition}
If $A$ is a compact group of automorphisms of the Lie algebra $\lG$, then there exists a Levi subalgebra of $\lG$ which is invariant under $A$.
\end{proposition}

\begin{proof}
Let $\lR$ be the radical of $\lG$; we will split our proof into two cases following $[\lR,\lR]=0$ or not.
\subdem{The radical is abelian}
In this first case we consider an induction with respect to the dimension of $\lG$. We consider $\olG=\lG/\lRlR$ and $\olR=\lR/\lRlR$: these are algebras with one less dimension that $\lG$ and $\lR$. We denote by $\dpt{\pi}{\lG}{\olG}$ the natural projection.

We begin to prove that $\olR$ is the radical of $\olG$. It is clear from the Lie algebra structure on a quotient that $\olR$ is an ideal because $\lR$ is. It is also clear that $\olR$ is solvable. We just have to see that $\olR$ is maximal in $\olG$. For this, suppose that $\olR\cup\oX$ is a solvable ideal in $\olG$. Then it is easy to see that $\lR\cup X$ is an ideal in $\lG$. Taking commutators in $\olR\cup\oX$, we always finish in $\overline{0}\in\olG$, i.e. in $\lRlR$. Taking again some commutators, we finish on $0\in\lG$ because $\lR$ is solvable. This contradict the maximality of $\lR$.

Since $A$ is made up of automorphisms, it leaves $\lR$ invariant, so that it also acts on $\olG$ as an automorphism group: $a\oX=\overline{aX}$ for $a\in A$ and $X\in\lG$. From the induction assumption, we can find a Levi subalgebra $\olS$ in $\olG$: $\olS\oplus\olR=\olG$. In this case, the radical of $\pi^{-1}(\olS)$ is $\lRlR$. Indeed in the one hand, $\olR\cap\olS=0$, so that $\pi^{-1}(\olR\cap\olS)=\lRlR$. In the other hand $\pi^{-1}(\olR\cap\olS)=\pi^{-1}(\olR)\cap\pi^{-1}(\olS)=\lR\cap\pi^{-1}(\olS)$. The lemma~\ref{lem:rad_ideal} conclude that $\Rad\pi^{-1}(\olS)=\lRlR$.

Now $A$ is a compact group of automorphism which leaves invariant $\pi^{-1}(\olS)$, so we have a Levi subalgebra $\lS$ of $\pi^{-1}(\olS)$ invariant under $A$. We will see that this is in fact a Levi subalgebra of the whole $\lG$, i.e. we have to prove that $\lS\oplus\lR=\lG$. From the definition of $\lS$,
\[
   \lS\oplus\lRlR=\pi^{-1}(\olS),
\]
and by definition of $\olS$,
\[
   \olS\oplus\frac{\lR}{\lRlR}=\olG.
\]
Then
\begin{equation}
  \lG=\pi^{-1}(\olS)\oplus\lR+\lRlR
     =\lS\oplus\lRlR\oplus\lR+\lRlR
     =\lS\oplus\lR.
\end{equation}

We can now pass to the second case: $\lRlR=0$.
\subdem{The radical is not abelian}
Let $\lS_0$ and $\lS$ be Levi subalgebras of $\lG$. For $X\in\lS_0$, we write
\[
   X=f(X)+X_{\lS}
\]
with respect to the decomposition $\lG=\lS\oplus\lR$. This defines a linear map $\dpt{f}{\lS_0}{\lR}$. For any $X$, $Y\in\lS_0$, $[X_{\lS},X_{\lS}]=[X,Y]-[X,f(y)]-[f(X),Y]$ because $\lR$ is abelian. Since\quext{C'est pas clair pourquoi on a \c a.}, $[X_{\lS},X_{\lS}]=[X,Y]_{\lS}$,
\begin{equation}\label{eq:f_presque_isom}
f([X,Y])=[X,f(Y)]-[f(X),Y].
\end{equation}
Now let us consider a map $\dpt{f}{\lS_0}{\lR}$ which satisfy this equation. Then the map $X\to X-f(X)$ is an isomorphism between $\lS_0$ and his image which is a Levi subalgebra of $\lG$. Indeed
\begin{equation}
\begin{split}
[X,Y]&\to[X,Y]-f([X,Y])\\
     &=[X,Y]-[X,f(Y)]-[f(X),Y]\\
     &=[X-f(X),Y-f(Y)].
\end{split}
\end{equation}
Now we consider $V$, the space of all the linear maps $\lS_0\to\lR$ which fulfil the condition \eqref{eq:f_presque_isom}. We have a bijection between $V$ and the Levi subalgebras of $\lG$: for any Levi subalgebra we associate the map $f\in V$ given by $X=f(X)+X_{\lS}$.

So our proof can be reduced to find a fixed point of $V$ under the action of $A$. In order to do that, we will see that $A$ is a group of \emph{affine} transformations on $V$. Consider a $\alpha\in A$ and $f_0$, $f_0^{\alpha}$, $f^{\alpha}$ be the elements of $V$ corresponding to $\lS_0$, $\lS$ and $\alpha(\lS)$. We take a $X\in\lS_0$ and we denote by $\oalpha(X)$ the $\lS_0$-component of $\alpha(X)$ with respect to the decomposition $\lG=\lR\oplus\lS_0$:
\[
   \alpha(X)=\oalpha(X)+\beta(X).
\]
This also defines $\dpt{\beta}{\lG}{\lR}$ and $-\beta(X)$ is the $\lR$-component of $\oalpha(X)$ with respect to $\lG=\lR\oplus\alpha(\lS_0)$. Since $f_0^{\alpha}$ just correspond to this decomposition, $f_0^{\alpha}(\oalpha(X))=-\beta(X)$, so that
\begin{equation}
\begin{split}
\oalpha(X)&=f_0^{\alpha}(\oalpha(X))+\alpha(X)\\
          &=f_0^{\alpha}(\oalpha(X))+\alpha(f(X))-\alpha(f(X))+\alpha(X).
\end{split}
\end{equation}
Since $X-f(X)\in\lS$, $\alpha(X)-\alpha(f(X))\in\alpha(\lS)$, then $f_0^{\alpha}(\oalpha(X))+\alpha(X)$ is the $\lR$-component of $\oalpha(X)$ with respect to $\lG=\lR\oplus\alpha(\lS)$. Then
\[
   f_0^{\alpha}(\oalpha(X))+\alpha(f(X))=f^{\alpha}(\oalpha(X))=f^{\alpha}(\oalpha(X)).
\]
Since $X$ was taken arbitrary, $f^{\alpha}=f^{\alpha}_0+\alpha\circ f\circ\oalpha^{-1}$. Then the map $V\to V$, $f\to f^{\alpha}$ is an affine transformation with translation equals to $f_0^{\alpha}$ and linear part being $f\to\alpha\circ f\circ\oalpha$.

A general result shows that a compact group of affine transformations on a vector space has a fixed point.

\end{proof}

An other result that will be used:
\begin{lemma}		\label{lem:Killing_ss_descent}
If $G$ is a semisimple Lie group and $H$ a semisimple subgroup of $G$, the restrictions on $H$ of the Killing form of $G$ is nondegenerate.
\end{lemma}
%TODO: a proof.

\subsection{Lorentz algebra}
%---------------------------

\begin{lemma}[\cite{Schomblond_em}]     \label{LemCommsopqAlg}
The matrices of $\so(p,q)$ satisfy the definition relation
\begin{equation}
    M^t\eta+\eta M=0,
\end{equation}
and if $M^{ab}$ is the ``rotation'' in the place of directions $a$ and $b$ (i.e. a trigonometric or an hyperbolic rotation following that $a$ and $b$ are of the same type or not), then the action on $\eR^{(p,q)}$ is given by $(x')^{\mu}=(M^{ab})^{\mu}_{\nu}x^{\nu}$ with
\begin{equation}
    (M^{ab})^{\mu}_{\nu}=\eta^{a\mu}\delta^b_{\nu}-\eta^{b\mu}\delta^a_{\nu}.
\end{equation}
The commutation relations are given by
\begin{equation}
    [M^{ab},M^{cd}]=-\eta^{ac}M^{bd}+\eta^{ad}M^{bc}+\eta^{bc}M^{ad}-\eta^{bd}M^{ac}.
\end{equation}
Notice that $M^{ab}=-M^{ba}$.
\end{lemma}

There is an other physical reason (which is in fact the same, but differently presented) justifying the study of the Clifford algebra. The quantum field theory need representation of the Lorentz algebra\footnote{When one think to real infinitesimal rotation matrices, the presence of $i$ seems not natural, but one redefines $J\to iJ$ for formalism reasons.}\index{lorentz!algebra}
\[
 [J^{\mu\nu},J^{\rho\sigma}]=i(\eta^{\nu\rho}J^{\mu\sigma}-\eta^{\mu\rho}J^{\nu\sigma}
 -\eta^{\nu\sigma}J^{\mu\rho}+\eta^{\mu\sigma}J^{\nu\rho}).
\]
Dirac had a trick to find such $J$ matrices from a representation of the Clifford algebra. If we have $n\times n$ matrices $\gamma_{\mu}$ such that
\[
    \gamma^{\mu}\gamma^{\nu}+\gamma^{\nu}\gamma^{\mu}=2\eta^{\mu\nu}\mtu_{n\times n},
\]
a $n$-dimensional representation of the Lorenz algebra is obtained by
\[
    S^{\mu\nu}=\frac{i}{4}\left[\gamma^{\mu},\gamma^{\nu}\right].
\]

By a simple redefinition $J=iM$, one obtains
\begin{equation}            \label{EqJJietaJcomm}
    [J,J]=i\eta J
\end{equation}
instead of $[M,M]=\eta M$, and the matrices $J$ are Hermitian. Here $\eta$ is the matrix 
\begin{equation}
\eta=diag(\underbrace{+,\ldots,+}_{p \text{times}},\underbrace{-,\ldots,-}_{\text{$q$ times}}). 
\end{equation}
As convention, we say that a direction corresponding to a \emph{positive} entry in the metric is a \emph{time} direction, while the spatial directions are negative. That corresponds to the convention of page \pageref{PgDefsGenre} to say that a \emph{time-like} vector has positive norm.

\section{Clifford algebra}
%++++++++++++++++++++++++++

\subsection{Definition and universal problem}
%------------------------------------------------------


\begin{theorem}\index{Clifford!algebra!Universal property of}
Let $E$ be an unital associative algebra and $\dpt{j}{V}{E}$ a linear map such that
\begin{equation}
    j(v)\cdot j(v)=q(v)1.        \label{102r1}
\end{equation}
Then we have an unique extension of $j$ to a homomorphism $\dpt{\tilde\jmath}{\Cliff(V,q)}{E}$. Moreover, $\Cliff(V,q)$ is the unique associative algebra which have this property for all such~$E$.
\[
\xymatrix{
    \Cliff(V,q) \ar@{^{(}->}[d]_{\displaystyle i} \ar[rd]^{\displaystyle\tilde{j}} &  \\
    V \ar[r]_{\displaystyle j} & D
  }
\]
\label{tho_Cliffunif}
\end{theorem}
This theorem can be seen as a definition of $\Cliff(V,q)$.

\begin{proof}
The proof shall belongs two parts: the first one will show how to extend $j$ and why it is unique, and the second one will prove the unicity of $\Cliff(V,q)$.

We begin by define the extension of $j$. First note that any linear map $\dpt{f}{V}{E}$ can be extended to an algebra homomorphism $\dpt{\overline{f}}{T(V)}{E}$ in only one way. Indeed, the homomorphism condition require that $\overline{f}(v\otimes w)=f(v)\cdot f(w)$.  The whole map $\overline{f}$ is then well defined by the data of $f$ alone.

As far as the map $j$ is concerned, we have the relation \eqref{102r1} which says that $\overline{j}(\mI)=0$. Indeed,
\begin{equation}
 \ovj(v\otimes v-q(v)\cdot(1))=\ovj(v)\cdot\ovj(v)-q(v)\ovj(1)
                              =j(v)\cdot j(v)-q(v)1
                              =0.
\end{equation}
Thus $\dpt{\ovj}{T(V)}{E}$ is a class map for $\mI$, and we can descent $\ovj$ from $T(V)$ to $\Cliff(V,q)$, We define
$\dpt{\tilde\jmath}{\Cliff(V,q)}{E}$ by
\begin{equation}
         \tilde\jmath[x]=\ovj(x)
\end{equation}
where $[x]$ is the class of $x$. That's for the existence part.

The unicity is clear: $f_1=f_2$ on $V$ implies that $\overline{f_1}=\overline{f_2}$ on $T(V)$. Thus $\tilde{f_1}=\tilde{f_2}$ on $\Cliff(V,q)$.

We turn now our attention to the unicity of $\Cliff(C,q)$. Let $D$ be an unital associative algebra such that
\begin{enumerate}
\item $V\subset D$,
\item For any unital associative algebra $E$ and for any $\dpt{f}{D}{E}$ such that $f(v)\cdot f(v)=-q(v)1$, there exists only one homomorphic map $\dpt{\tilde{f}}{D}{E}$ which extend $f$.
\end{enumerate}
We should find a homomorphic map $\dpt{\tilde{k}}{D}{\Cliff(V,q)}$. Let $i$ be the canonical injection $\dpt{i}{V}{D}$. Clearly, we have a homomorphism $V\rightarrow i(V)$. Now, as a space $E$, we can take $\Cliff(V,q)$; $i$ can be seen as a linear map $\dpt{i}{V}{\Cliff(V,q)}$ such that $i(v)\cdot i(v)=q(v)1$. The assumptions say that $i$ can be extended (in only one way) to a homomorphic map $\dpt{\tilde{i}}{D}{\Cliff(V,q)}$.

The Clifford algebra is thus unique up to a homomorphism.

\end{proof}

What we proved is the following: if for any $E$ and for any $\dpt{j}{V}{E}$ such that $j(v)\cdot j(v)=q(v)1$, there exist an unique $\dpt{\tilde{j}}{D}{E}$ which extend $j$, then $D=\Cliff(V,q)$ up to a homomorphism. One ays that $\Cliff(V,q)$ solve an \defe{universal problem}{universal!problem}.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Representations of the algebra \texorpdfstring{$\gsu(2)=\so(3)$}{su2so3}}
%---------------------------------------------------------------------------------------------------------------------------
\label{subsecPJmtqrG}

If one knows a load of theory, it is possible to determine the irreducible representations of \( \so(3)\) in a very short way; This will be done in example~\ref{ExHESKimc}. We are now going to determine the irreducible representations of \( \so(3)\) in a quite explicit way.

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Ladder operators}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

The algebra $\gsu(2)$ is the real algebra generated by the matrices of the form
$
\begin{pmatrix}
\alpha  &\beta\\
-\beta^*&-\alpha
\end{pmatrix}
$ with $\alpha$, $\beta\in\eC$. A convenient basis is given by
\begin{align}       \label{EqGenssudeux}
u_1&=\frac{ 1 }{2}
\begin{pmatrix}
  i &   0   \\
  0 &   -i
\end{pmatrix},
&u_2&=
\frac{ 1 }{2}
\begin{pmatrix}
  0 &   1   \\
  -1    &   0
\end{pmatrix},
&u_3&=\frac{ 1 }{2}
\begin{pmatrix}
  0 &   i   \\
  i &   0
\end{pmatrix}.
\end{align}
That algebra satisfies the commutation relations
\begin{equation}
    [u_i,u_j]=\epsilon_{ijk}u_k.
\end{equation}
The trick to build finite dimensional representations\index{representation!of $\gsu(2)$} of that algebra is common (see \cite{MQSenechal} for example). The first step is to perform a change of basis $J_k=iu_k$ that brings the algebra under the form (see section~\ref{SubSecTheGroupSotrois} to understand why)
\begin{equation}        \label{EqAlgsuiepsijk}
    [J_i,J_j]=i\epsilon_{ijk}J_k.
\end{equation}
We are going to construct all the finite dimensional irreducible representations of the algebra \eqref{EqAlgsuiepsijk}. The key point of that new basis is that one can define the \defe{ladder operators}{ladder operators}
\begin{equation}
    J_{\pm}=J_1\pm iJ_2
\end{equation}
that have the property that
\begin{equation}
    [J_3,J_{\pm}]=\pm J_{\pm}.
\end{equation}
Notice that for every $i$, we have $(J_i)^*=J_i$, so that $(L^{\pm})^*=L^{\mp}$. An other important property is that, defining $J^2=J_1^2+J_2^2+J_3^2$, we have
\begin{equation}
    [J_i,J^2]=0,
\end{equation}
which show that $J^2$ is a Casimir operator, and is thus by Schur's lemma a multiple of identity. Notice that we are using an abuse of notation between $J_i$ as element of $\gsu(2)$ and $J_i$ as the operator that represent $J_i$. In the first case, products like $J_iJ_j$ make no sense\footnote{In fact, one has to understand these products as elements of the universal enveloping algebra. What we are building is a reprensentation of that algebra, which, obviously, restricts to a representation of the algebra. When we use the Schur's lemma, in fact we invoke it in $\mU\big(\so(3)\big)$}, but it makes sense as operator composition.

The subalgebra $\{ J^2,J_3 \}$ being abelian, we can simultaneously diagonalise $J^2$ and $J_3$. Let $| m,\sigma \rangle $ be an orthonormal basis of the eigenspace of $J_3$ associated with the eigenvalue $m$. The index $\sigma$ is for a possible degenerateness to be studied later.  We have
\[
    J_3| m,\sigma \rangle =m| m,\sigma \rangle .
\]
Using the commutation relations between $J_3$ and the ladder operators, we have
\begin{equation}        \label{EqJtroisJpmmplusun}
    J_3J_{\pm}| m,\sigma \rangle =\big( \pm J_{\pm}+J_{\pm}J_3 \big)| m,\sigma \rangle =(m\pm 1)J_{\pm}| m,\sigma \rangle .
\end{equation}
Thus $J_{\pm}| m,\sigma \rangle $ is an eigenvector of $J_3$ with the eigenvalue $m\pm 1$, which means that $J_{\pm}| m,\sigma \rangle $ is a linear combination of the vectors $| m\pm 1,\sigma \rangle $ with different values of $\sigma$. This is the reason of the name of the \emph{ladder} operators: they raise and lower the eigenvalue of $J_3$.

We can now prove that one has to drop the index $\sigma$ because eigenvalues of $J_3$ cannot be degenerated. For, compute
\begin{equation}        \label{JpJmJcarrerelation}
    J_+J_-=(J_1+iJ_2)(J_1-iJ_2)=J^2-J_3^2+i[J_2,J_1]=J^2-J_3^2+J_3,
\end{equation}
so that
\[
    J_+J_-| m,\sigma \rangle =(\alpha-m^2+m)| m,\sigma \rangle
\]
where $\alpha$ is defined by $J^2=\alpha\mtu$. That proves that the space generated by $| m,\sigma \rangle $ and the action of $J_3$, $J_+$ and $J_-$ is invariant under the representation, while one cannot obtain $\ket{m,\sigma'}$ by action of $J_{\pm}$ on $\ket{m,\sigma}$. Since we are looking for \emph{irreducible} representations, that space must actually be all the representation space. That rules out the possibility to have two different vectors $| m,\sigma_1 \rangle $ and $| m,\sigma_2 \rangle $.

The explicit matrix form of $J_{\pm}$ are:
\begin{align}
J_{+}&=
\begin{pmatrix}
0   &   0   &   0   &0  &\hdots\\
1   &   0   &   0   &0  &\hdots\\
0   &   1   &   0   &0  &\hdots\\
0   &   0   &   1   &0  &\hdots\\
\vdots  &   \vdots  &   \vdots  &\vdots &\ddots
\end{pmatrix},
&J_{-}&=
\begin{pmatrix}
0   &   1   &   0   &0  &\hdots\\
0   &   0   &   1   &0  &\hdots\\
0   &   0   &   0   &0  &\hdots\\
0   &   0   &   0   &1  &\hdots\\
\vdots  &   \vdots  &   \vdots  &\vdots &\ddots
\end{pmatrix},
\end{align}
Since we are searching for finite dimensional representations, there exists a maximal eigenvalue of $J_3$. Let us denote by $j$ that maximal eigenvalue and by $| j \rangle$ the corresponding eigenvector. The relation \eqref{EqJtroisJpmmplusun} shows that if $J_+| j \rangle\neq 0$, then $J_+| j \rangle$ is an eigenvector for $J_3$ with eigenvalue $j+1$, which contradicts maximality. Then we have $J_+| j \rangle=0$.

Since we know the action of $J_3$ and $J_+$ on $| j \rangle$, it is convenient to write $J^2$ in terms of these two operators. This is done in the same way as probing equation \eqref{JpJmJcarrerelation}:
\begin{equation}
    J^2=J_3^2+J_3+J_-J_+,
\end{equation}
so that
\begin{equation}        \label{EqJcarrejjplusun}
    J^2| j \rangle=j(j+1)| j \rangle.
\end{equation}
We know that $J^2=\alpha\mtu$ and that $\alpha$ is a characteristic of the representation. What equation \eqref{EqJcarrejjplusun} tells us is that the maximal eigenvalue of $J_3$ is related to $\alpha$ by $j(j+1)=\alpha$.

We are now able to determine the proportionality constant of relation $J_{\pm}| m \rangle\propto| m\pm 1 \rangle$. Since $(J_-)^*=J_+$, we have
\begin{equation}    \label{EqnormeJmoinm}
    \| J_-| m \rangle \|^2=\langle m| J_+J_- | m \rangle = j(j+1)-m^2+m.
\end{equation}
Then one has
\begin{subequations}
    \begin{align}
        J_-| m \rangle  &=\sqrt{j(j+1)-m(m-1)}| m-1 \rangle,    \label{EqJmoinsmanglemmointun}      \\
        J_+| m \rangle  &=\sqrt{j(j+1)-m(m+1)}| m+1 \rangle.
    \end{align}
\end{subequations}
As expected, $J_-| -j \rangle=0$ and $J_+| j \rangle=0$. Notice that we avoid the possibility $J_-| m \rangle=-\sqrt{\cdots}| m-1 \rangle$ by a simple redefinition $| m-1 \rangle\to -| m-1 \rangle$.

Equation \eqref{EqnormeJmoinm} shows that the norm of $| m \rangle$ becomes negative for $m<-j$ and $m>j+1$. We conclude that the minimal eigenvalue of $J_3$ is $-j$. Since $| j \rangle$ has to be reached from $| -j \rangle$ by action of $J_+$, the difference $j-(-j)$ must be an integer. Thus $j\in\eN/2$. The number $j$ is the \defe{spin}{spin!of representation of $\so(3)$} of the representation.

Let us give the explicit example with spin one half.
When $j=\frac{ 1 }{2}$, the vector space is generated by the vectors $| 1/2 \rangle$ and $| -1/2 \rangle$, and the operators are given by
\begin{align}
    J_3&=\frac{ 1 }{2}
\begin{pmatrix}
  1 &   0   \\
  0 &   -1
\end{pmatrix},
&J_-&=
\begin{pmatrix}
  0 &   0   \\
  1 &   0
\end{pmatrix},
&J_+&=
\begin{pmatrix}
  0 &   1   \\
  0 &   0
\end{pmatrix},
\end{align}
from which we deduce
\begin{align*}
J_1&=\frac{ 1 }{2}
\begin{pmatrix}
  0 &   1   \\
  1 &   0
\end{pmatrix},
&J_2&=
\begin{pmatrix}
  0 &   -i  \\
  i &   0
\end{pmatrix}.
\end{align*}
Notice that we have $J_i=\frac{ 1 }{2}\sigma_i$ with the \defe{Pauli matrices}{pauli matrices},
\begin{align}
\sigma_1&=
\begin{pmatrix}
  0 &   1   \\
  1 &   0
\end{pmatrix},
&\sigma_2&=
\begin{pmatrix}
  0 &   -i  \\
  i &   0
\end{pmatrix},
&\sigma_3&=
\begin{pmatrix}
  1 &   0   \\
  0 &   -1
\end{pmatrix}.
\end{align}
These matrices fulfil the relation
\begin{equation}
    \sigma_i\sigma_j=\delta_{ij}+i\epsilon_{ijk}\sigma_k.
\end{equation}

%---------------------------------------------------------------------------------------------------------------------------
\subsubsection{Weight vectors}  \label{subSubSecweightsotrois}
%---------------------------------------------------------------------------------------------------------------------------

The algebra $\so(3)$ does not contain abelian subalgebra of dimension bigger than one, so a Cartan subalgebra is generated by $J_3$. The unique (up to dilatation) element of $\hH^*$ is thus given by $\alpha(J_3)=1$. The relation $[J_z,J_{\pm}]$ provides the root spaces:
\begin{equation}
    \begin{aligned}
        \so(3)_1    &=\{ J_+ \}\\
        \so(3)_{-1} &=\{ J_- \},
    \end{aligned}
\end{equation}
thus $\lN^{\pm}$ is generated by $J_{\pm}$.


%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Cartan subalgebras in complex Lie algebras}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\label{SecCartaninComplex}
About Cartan algebra, one can read \cite{Dragan,Berndt,Hochschild,SamelsonNotesLieAlg}.

In this section $\lG$ will always denotes a complex finite dimensional Lie algebra.

\begin{definition}\label{PgDefCentralisateur}
    When \( \lH\) is a subalgebra of \( \lG\), the \defe{centralizer}{centralizer} of \( \lH\) is the set\nomenclature[G]{$\mZ(\lH)$}{the centralizer of \( \lH\)}
    \begin{equation}
        \mZ(\lH)=\{x\in\lG\tq [x,\lH]\subset\lH\}.
    \end{equation}
    More generally if $\lG$ is a Lie algebra and if $\lA$, $\lB$ are two subset of $\lG$, the centraliser of $\lA$ in $\lB$ is
    \begin{equation}
        \mZ_{\lB}(\lA)=\{X\in\lB\tq [X,\lA]=0\}.
    \end{equation}
    If $\lA$ is a subalgebra of $\lG$, its \defe{normalizer}{normalizer} is
    \begin{equation}
        \lN_{\lA}=\{X\in\lG\tq [X,\lA]\subset\lA\}.
    \end{equation}
    One can check that $\lA$ is an ideal in $\lN_{\lA}$.
\end{definition}

\begin{definition}      \label{DEFooUNWJooVsBZgJ}
A subalgebra $\lH$ of a Lie algebra $\lG$ is a \defe{Cartan subalgebra}{Cartan!subalgebra} if it is nilpotent and if it is its own centralizer: $[x,\lH]\subset\lH$ implies $x\in\lH$.
\end{definition}

Our first task is to show that every Lie algebra has a Cartan algebra.

\begin{lemma}[Primary decomposition theorem]
    Let \( V\) be a complex vector space and \( A\colon V\to V\) be linear map. Then we have the direct sum decomposition
    \begin{equation}        \label{EqPrimDecomTho}
        V=\bigoplus_{\lambda\in\eC}V_{\lambda}(A)
    \end{equation}
    where \( V_{\lambda}(A)=\{ v\tq (A-\lambda\mtu)^nv=0\text{ for some } n\in\eN \} \)
\end{lemma}
This is the result that restricts ourself to \emph{complex} Lie algebras when proving that Cartan subalgebras exist. Notice that the sum in \eqref{EqPrimDecomTho} is reduced to the eigenvalues of \( A\) since \( \lG_{\lambda}(A)=0\) when \( \lambda\) is not an eigenvalue. Indeed if \( \big( A-\lambda\mtu \big)^nY=0\) then \( (A-\lambda\mtu)^{n-1}Y\) is an eigenvector for \( A\) with eigenvalue \( \lambda\).

For any \( \lambda\in\eC\) and \( X\in\lG\) we consider the space
\begin{equation}
    \lG_{\lambda}(X)=\{ Y\in\lG\tq \big( \ad(X)-\lambda\mtu \big)^nY=0\text{ for some } n \}.
\end{equation}
The primary decomposition theorem implies the decomposition
\begin{equation}        \label{EqDecomplGpRimDecombijk}
    \lG=\bigoplus_{\lambda}\lG_{\lambda}(X)
\end{equation}
for each \( X\in\lG\).

A small useful formula: if \( u\) is a derivation of the Lie bracket and if \( [X,Y]\) is any bracket, then
\begin{equation}\label{EqWGujmeF}
    (u-\lambda\mtu)[X,Y]=\big[ (u-\lambda\mtu)X,Y \big]+[X,uY].
\end{equation}

\begin{lemma}   \label{LemVZzSnUW}
    For each \( X\in\lG\) and \( \lambda,\mu\in\eC\) we have
    \begin{equation}
        \big[ \lG_{\lambda}(X),\lG_{\mu}(X) \big]\subset\lG_{\lambda+\mu}(X).
    \end{equation}
\end{lemma}

\begin{proof}
    Let \( X_{\lambda}\in\lG_{\lambda}(X)\) and \( X_{\mu}\in\lG_{\mu}(X)\). Using the fact that \( \ad(X)\) is a derivation we have
    \begin{equation}
        \ad(X)[X_{\lambda},X_{\mu}]-(\lambda+\mu)[X_{\lambda},X_{\mu}]=\Big[ \big( \ad(X)-\mu\mtu \big)X_{\lambda},X_{\mu} \Big]+\Big[ X_{\lambda},\big( \ad(X)+\mu\mtu \big)X_{\mu} \Big]
    \end{equation}
    Let us show by induction the following equality for all \( n\):
    \begin{equation}    \label{EqPIzsRhb}
        \big( \ad(X)-(\lambda+\mu)\mtu \big)^n[X_{\lambda},X_{\mu}]=\sum_{i=0}^{\infty}\binom{ n }{ i }\Big[ \big( \ad(X)-\lambda\mtu \big)^iX_{\lambda},\big( \ad(X)-\mu\mtu \big)^{n-i}X_{\mu} \Big].
    \end{equation}
    In order to prove that, it is sufficient to apply \( \big( \ad(X)-(\lambda+\mu)\mtu \big)\) to that equality and use the fact that \( \ad(X)\) is a derivation of the Lie bracket. Then apply formula \eqref{EqWGujmeF}.

The expression \eqref{EqPIzsRhb} vanishes when \( n\) is large enough.
\end{proof}

We say that \( X\) is \defe{regular}{regular} if \( \dim\lG_0(X)\) is the smallest with respect to the others \( \dim\lG_0(Y)\).

The following proposition shows that every complex Lie algebra has a Cartan Lie subalgebra.
\begin{proposition}
    If $X$ is regular in \( \lG\) then the subalgebra \( \lG_0(X)\) is Cartan.
\end{proposition}

\begin{proof}
    Since \( X\in\lG_0(X)\) we have \( \ad(X)\lG_{\lambda}(X)\subset\lG_{\lambda}(X)\). Thus we see \( \ad(X)\) as a linear operator on \( \lG_{\lambda}(X)\). The operator \( \ad(X)|_{\lG_{\lambda}(X)}\) is nonsingular\footnote{it means that \( \ad(Y)\) is invertible.} when \( \lambda\neq 0\). Indeed all the eigenvalues of \( \ad(X)\) on \( \lG_{\lambda}(X)\) are equal to \( \lambda\) because
    \begin{equation}
        \big( \ad(X)-\mu\mtu \big)Y=0
    \end{equation}
    implies \( Y\in\lG_{\mu}(X)\). If \( Y\in\lG_{\lambda}(X)\) it only occurs when \( \mu=\lambda\) since the sum \eqref{EqPrimDecomTho} is direct.

    For each eigenvalue \( \lambda\) we have a neighborhood \( \mU_{\lambda}\) of $X$ in \( \lG_0(X)\) such that for all \( Y\in\mU_{\lambda}\), \( \ad(Y)\) is nonsingular on \( \lG_{\lambda}(X)\). We consider \( \mU=\bigcap_{\lambda}\mU_{\lambda}\) which is a non empty open set since the intersection is taken over the eigenvalues of \( \ad(X)\) that are in finite numbers.

    Let us prove that the restriction to \( \lG_0(X)\) of the linear operator \( \ad(Y)\) is nilpotent for each \( Y\in\mU\). First we have
    \begin{equation}        \label{EqLgzsubsetlzY}
        \lG_0(Y)\subseteq\lG_0(X)
    \end{equation}
    because by construction \( \ad(Y)\) cannot be nilpotent on the other spaces \( \lG_{\lambda}(X)\). But by hypothesis the element \( X\) is regular, thus the inclusion \eqref{EqLgzsubsetlzY} cannot be strict. Thus \( \lG_0(X)\subset\lG_0(Y)\) which means that \( \ad(Y)\) is nilpotent on \( \lG_0(X)\).

    Now the fact for \( \ad(Y)\) to be nilpotent means the vanishing of a polynomial determined by the coefficients of the matrix of \( \ad(Y)\). Since this polynomial vanishes on the open set \( \mU\), it vanishes identically, so that \( \ad(Y)\) is nilpotent on \( \lG_0(X)\). It results that \( \lG_0(X)\) is a \( \ad\)-nilpotent algebra and the Engel's theorem~\ref{tho:Engel} concludes that \( \lG_0(X)\) is nilpotent.

    We still have to prove that \( \lG_0(X)\) is its own centralizer. Since \( \lG_0(X)\) is a subalgebra we have the inclusion
    \begin{equation}
        \lG_0(X)\subseteq\mZ\big( \lG_0(X) \big).
    \end{equation}
    Let \( Z\in\mZ\big( \lG_0(X) \big)\). For each \( Y\in\lG_0(X)\) we have \( [Z,Y]\in\lG_0(X)\). In particular with \( Y=X\) we have \( \ad(X)Z\in\lG_0(X)\). Thus
    \begin{equation}
        \ad(X)^nZ=\ad(X)^{n-1}\underbrace{\ad(X)Z}_{\in\lG_0(X)}
    \end{equation}
    and there exists a \( n\) such that \( \ad(X)^{n-1}\ad(X)Z=0\).
\end{proof}

If \( \lG\) is a Lie algebra, the group of \defe{inner automorphism}{inner!automorphism} is the subgroup of \( \Aut(\lG)\) generated by the elements of the form \(  e^{\ad(X)}\) with \( X\in\lG\). This definition is motivated in the context of matrix groups by the fact that when \( g= e^{Y}\in G\) and \( X\in\lG\) we have
\begin{equation}
    gXg^{-1}= e^{\ad(Y)}X.
\end{equation}
\begin{example}
    If
    \begin{equation}
        \begin{aligned}[]
            g=\begin{pmatrix}
                \cos(t)    &   \sin(t)    &   0    \\
                -\sin(t)    &   \cos(t)    &   0    \\
                0    &   0    &   1
            \end{pmatrix},&&X=\begin{pmatrix}
                0    &   a    &   b    \\
                -a    &   0    &   0    \\
                -b    &   0    &   0
            \end{pmatrix},
        \end{aligned}
    \end{equation}
    then one checks that \( g= e^{Y}\) with
    \begin{equation}
        Y=\begin{pmatrix}
              0  &  t     &   0    \\
            -t    &   0    &   0    \\
            0    &   0    &   0
        \end{pmatrix}
    \end{equation}
    and
    \begin{equation}
        gXg^{-1}= e^{\ad(Y)}X=\begin{pmatrix}
            0    &   a    &   b\cos(t)    \\
            -a    &   0    &   -b\sin(t)    \\
            -b\cos(t)    &   b\sin(t)    &   0
        \end{pmatrix}.
    \end{equation}
\end{example}

\begin{theorem}
    The group of inner automorphisms of \( \lG\) acts transitively on the set of Cartan subalgebras.
\end{theorem}

For a proof, see \cite{SerreSSAlgebres}. In particular they have all the same dimension and the definition of the \defe{rank}{rank!of a complex Lie algebra} as the dimension of its Cartan algebra make sense. In \cite{SerreSSAlgebres} we have a more abstract definition of the rank, see page III-2.

\begin{proposition}     \label{PropCartanLzXtjs}
    If \( \lH\) is a Cartan subalgebra of the complex Lie algebra \( \lG\), there exists a regular element \( X\in\lG\) such that \( \lH=\lG_0(X)\).
\end{proposition}

For a proof, see \cite{SerreSSAlgebres}.

\begin{proposition}\label{prop:Cartan_max_nil}
A Cartan subalgebra is a maximal nilpotent subalgebra.
\end{proposition}

\begin{proof}
Let $\lH$ be a Cartan subalgebra of $\lG$ and $\lN$, a nilpotent algebra which contains $\lH$. Let $\{X_1,\ldots,X_n\}$ be a basis of $\lG$ chosen in such a way that the $p$ first vectors form a basis of $\lH$ while the $r$ first, a basis of $\lN$ ($r>p$ of course). As notational convention, the subscript $i,j$ are related to $\lH$ and $u,t$ to $\lN\ominus\lH$.

Let us first suppose $\dim\lN=\dim\lH+1$ and let $X_u$ be the basis vector of $\lN$ which is not in $\lH$. Since $\lH$ is Cartan, we can find $X_i\in\lH$ such that $Y=[X_u,X_i]\notin\lH$. Then $Y$ has a $X_u$-component and this contradict the fact that $\ad X_i$ is nilpotent.

The next case is $\lN=\lH\oplus X_u\oplus X_t$. In this case we can find a $X_i\in\lH$ such that $Y=[X_u,X_i]\notin\lH$. The fact to be nilpotent makes that $Y$ has no $X_u$-component, so that it has a $X_t$-component. Now it is clear that for any $X_j\in\lH$, $[Y,X_j]$ still has no $X_u$-component (because $(\ad X_i\circ\ad X_j)$ has to be nilpotent), but has also no $X_t$-component. Then for any $X\in\lH$, $[Y,X]\in\lH$ with $Y\notin\lH$. There is a contradiction.

Now the step to the general case is easy: if $\dim\lN=\dim\lH+m$, we  consider $X_1,\ldots,X_m\in\lH$ and $A=(\ad X_1\circ\ad X_m)X_u$. This is not in $\lH$ although $[A,X]\in\lH$ for any $X\in\lH$.
\end{proof}


\begin{proposition}
    If \( \lG\) is a semisimple Lie algebra, a subalgebra \( \lH\) is Cartan if and only if the two following conditions are satisfied:
    \begin{enumerate}
        \item
            \( \lH\) is a maximal abelian subalgebra
        \item
            the endomorphism \( \ad(H)\) is diagonalizable for every \( H\in\lH\).
    \end{enumerate}
\end{proposition}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Root spaces in semisimple complex Lie algebras}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\label{SecRootcomplexss}
In this section we particularize ourself to complex semisimple Lie algebras. A very good reference about complex semisimple algebras including the reconstruction \emph{via} the Cartan matrix and Chevalley-Weyl basis is \cite{SerreSSAlgebres}.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Introduction and notations}
%---------------------------------------------------------------------------------------------------------------------------

Real and complex Lia algebras deserve quite different treatment with root space. We review here the main steps in both cases, emphasising the differences. We restrict ourself to semisimple Lie algebras. See \cite{Wisser}.

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Complex Lie algebras}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

If \( \lG\) is a complex semisimple Lie algebra, we choose a Cartan subalgebra \( \lH\) and the root spaces are given by
\begin{equation}
    \lG_{\alpha}=\{ X\in\lG\tq [H,X]=\alpha(H)X \forall H\in\lH \}.
\end{equation}
The dimension of \( \lH\) is the rank of \( \lG\). Then the root space decomposition reads
\begin{equation}
    \lG=\lH\oplus\bigoplus_{\alpha\in\Phi}\lG_{\alpha}
\end{equation}
where \( \Phi\) is the set of roots.

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Real Lie algebras}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

If \( \lG\) is a real semisimple Lie algebra we consider a Cartan involution and the Cartan decomposition \( \lG=\lK\oplus\lP\). Then we choose a maximally abelian subalgebra \( \lA\) in \( \lP\) and we define
\begin{equation}
    \lG_{\lambda}=\{ X\in\lG\tq [J,X]=\alpha(J)X \forall J\in\lA \}.
\end{equation}
The rank of \( \lG\) is the dimension of \( \lA\). The root space decomposition then reads
\begin{equation}
    \lG=\lG_0\oplus\bigoplus_{\lambda\in\Sigma}\lG_{\lambda}
\end{equation}
where \( \Sigma\) is the set of \( \lambda\in\lA^*\) such that \( \lambda\neq 0\) and \( \lG_{\lambda}\neq 0\).

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Notations}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\label{SubsecNotationRootsDel}

We summarize the notations that will be used later. Let \( \lH\) be a Cartan algebra in the complex semisimple Lie algebra \( \lG\). An element \( \alpha\in\lH^*\) is a root if the space
\begin{equation}
    \lG_{\alpha}=\{ X\in\lG\tq \ad(H)X=\alpha(H)x,\forall H\in\lH \}
\end{equation}
is non empty.

\begin{enumerate}
    \item
        \( \Phi\) is the set of all the roots. We consider an ordering notion on \( \Phi\) and \( \Phi^+=\Pi\) is the set of positive roots.
    \item
        An element in \( \Phi^+\) is simple if it cannot be written as the sum of two positive roots.
    \item
        \( \Delta\) is the set of simple roots\footnote{The symbol \( \Delta\) has not a fixed signification in the literature. As example, in \cite{Cornwell} the symbol \( \Delta\) is the set of roots while in \cite{SternLieAlgebra} it denotes the set of simple roots.}. The simple roots are denoted by \( \{ \alpha_1,\ldots,\alpha_l \}\).
\end{enumerate}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Root spaces}
%---------------------------------------------------------------------------------------------------------------------------

We are considering a complex semisimple Lie algebra \( \lG\) with a Cartan subalgebra \( \lH\).

\begin{definition}      \label{DefRootSpace}
    For each \( \alpha\in\lH^*\) we define
    \begin{equation}            \label{eq:lG_alpha_nss}
        \lG_{\alpha}=\{  x\in\lG\tq\forall h\in\lH, \big(\ad h-\alpha(h)\big)^nx=0\text{ for some }n\in\eN    \}.
    \end{equation}
    If \( \lG_{\alpha}\) is not reduced to \( 0\), we say that \( \alpha\) is a \defe{root}{root} and \( \lG_{\alpha}\) is a \defe{root space}{root!space}.
\end{definition}
Corollary~\ref{CorCoolWrlGbalpha} will provide an easier formula for the root spaces when the algebra \( \lG\) is complex and semisimple.
\begin{theorem}     \label{TholGCartalphaplusbeta}
Let $\lG$ be a complex Lie algebra with Cartan subalgebra $\lH$. If $\alpha,\beta\in\lG^*$ then
\begin{enumerate}
    \item   \label{ItemTholGCartalphaplusbetai}
    $[\lG_{\alpha},\lG_{\beta}]=\lG_{\alpha+\beta}$,
\item $\lG_0=\lH$.
\end{enumerate}
\label{prop:deux_racine}
\end{theorem}

\begin{proof}
For $z\in\lH$ and $x$, $y\in\lG$ we have
\begin{equation}
\big( \ad z-(\alpha+\beta)(z) \big)[x,y]=[ (\ad z-\alpha(z))x,y ]+[ x,(\ad z-\beta(z))y ].
\end{equation}
Using the same induction as in the proof of lemma~\ref{LemVZzSnUW} we show that
\begin{equation}
\big( \ad z-(\alpha+\beta)(z) \big)^n[x,y]=\sum_k \binom{k}{n}
\left[
(\ad z-\alpha(z))^k(x),(\ad z-\beta(z))^{n-k}(y)
\right].
\end{equation}
This formula shows that $[\lG_{\alpha},\lG_{\beta}]\subset\lG_{\alpha+\beta}$. Indeed let $x\in\lG_{\alpha}$, $y\in\lG_{\beta}$ and $n$ be large enough,
\begin{equation}
    \left( \ad z-(\alpha+\beta)(z) \right)^n[x,y]=0.
\end{equation}

    Now we turn our attention to the second part. Let us apply the Lie theorem~\ref{tho:Lie_Vu} to the action of \( \lG\) on the quotient \( \lG_0/\lH\). There exists \( [X_0]\in\lG_0/\lH\) such that \( h[X_0]=\lambda(h)[X_0]\) where the bracket stand for the class. Since \( \lH\) is nilpotent on \( \lG_0\) we have \( \lambda=0\) identically. Looking outside the class, the existence of a non vanishing \( [X_0]\in\lG/\lH\) such that \( h[X_0]=0\) means that there exists \( X_0\in\lG_0\setminus\lH\) such that \( [h,X_0]\in\lH\) for every \( h\in\lH\). This contradicts the fact that \( \lH\) is its own centralizer.
\end{proof}

\begin{proposition}
    The complex Lie algebra decomposes into the root spaces as
    \begin{equation}
        \lG=\bigoplus_{\alpha\in\lH^*}\lG_{\alpha}.
    \end{equation}
\end{proposition}

\begin{proof}
    Let \( H\in\lH\). We consider the primary decomposition \eqref{EqDecomplGpRimDecombijk} with respect to the operator \( \ad(H)\):
    \begin{equation}
        \lG=\bigoplus_{\lambda}\lG_{\lambda}(H).
    \end{equation}
    If \( H'\in\lH\) the operator \( \ad(H')\) acts the space \( \lG_{\lambda}(H)\) because \( H'\in\lG_0(H)\) so that
    \begin{equation}
        [H',\lG_{\lambda}(H)]\subset\lG_{\lambda}(H).
    \end{equation}
    Thus we can write the primary decomposition of \( \lG_{\lambda}(H)\) with respect to the operator \( \ad(H')\) knowing that
    \begin{equation}
        \big( \lG_{\lambda}(H) \big)_{\mu}(H')=\{ X\in\lG_{\lambda}(H)\tq\big( \ad(H')-\mu \big)^nX=0 \}=\lG_{\lambda}(H)\cap\lG_{\mu}(H').
    \end{equation}
    What we get is the decomposition
    \begin{equation}
        \lG=\bigoplus_{\lambda}\bigoplus_{\mu}\lG_{\lambda}(H)\cap\lG_{\mu}(H').
    \end{equation}
    We continue the decomposition with \( H'',H''',\ldots\) until each \( \ad(H)\) with \( H\in\lH\) has only one eigenvalue on each of the summand of the decomposition
    \begin{equation}
        \lG=\bigoplus_{\lambda_1,\ldots,\lambda_l}\lG_{\lambda_1}(H_1)\cap\ldots\cap\lG_{\lambda_l}(H_l).
    \end{equation}
    For each \( l\)-uple \( (\lambda_1,\ldots,\lambda_l)\), the eigenvalue of \( H_i\) on \( \lG_{\lambda_1}\cap\ldots\cap\lG_{\lambda_l}\) is \( \lambda_i\). Thus we can see \( \lambda\) as a \( 1\)-form on \( \lH\) and write
    \begin{equation}        \label{EqdirectumlGRoots}
        \lG=\bigoplus_{\lambda}\lG_{\lambda}
    \end{equation}
    with
    \begin{equation}
        \lG_{\lambda}=\{ X\in\lG\tq\big( \ad(H)-\lambda(H) \big)^nX=0 \}.
    \end{equation}
\end{proof}

\begin{corollary}\label{cor:Bxy_zero}
    If $X_{\alpha}\in\lG_{\alpha}$ and $X_{\beta}\in\lG_{\beta}$ with $\alpha+\beta\neq 0$, then $B(X_{\alpha},X_{\beta})=0$.
\end{corollary}

\begin{proof}
    From the second point of proposition~\ref{prop:deux_racine}, we have $\dpt{\ad X_{\alpha}\circ\ad X_{\beta}}{\lG_{\mu}}{\lG_{\mu+\alpha+\beta}}$. If $\alpha+\beta\neq 0$, the fact that the sum \eqref{EqdirectumlGRoots} is direct makes the trace of $\ad X_{\alpha}\circ\ad X_{\beta}$ zero.
\end{proof}


Since \( \lG\) is semisimple, the restriction of the Killing form on \( \lH\) is nondegenerate\footnote{Because the Killing form is zero on each space \( \lG_{\alpha}\) with \( \alpha\neq 0\).}. Thus we can introduce, for each linear function $\phi\colon \lH\to \eC$, the unique element $t_{\phi}\in\lH$ such that
\begin{equation}
    \phi(h)=B(t_{\phi},h)
\end{equation}
for every $h\in\lH$. \nomenclature[G]{\( t_{\alpha}\)}{a basis of \( \lH\)} This element is nothing else that the dual \( \phi^*\) with respect to the Killing form. Indeed
\begin{equation}
    t_{\phi}^*(h)=B(t_{\phi},h)=\phi(h),
\end{equation}
so that \( t_{\phi}^*=\phi\). Incidentally, this proves that when \( \phi\) runs over a basis of \( \lH^*\), the vector \( t_{\phi}\) runs over a basis of \( \lH\). The space $\lH^*$ is endowed with an inner product defined by\nomenclature{$(\alpha,\beta)$}{Inner product on the dual $\lH^*$ of a Cartan algebra}\nomenclature[G]{\( (\alpha,\beta)\)}{inner product on the dual \( \lH^*\).}
\begin{equation}        \label{EqDefInnprHestrar}
    (\alpha,\beta) = B(t_{\alpha},t_{\beta})=\beta(t_{\alpha})=\alpha(t_{\beta}).
\end{equation}

\begin{lemma}       \label{LemXYBXYtalpha}\label{Propoxalphaymoinaalpha}
    If \( X\in\lG_{\alpha}\) and \( Y\in\lG_{-\alpha}\), then
    \begin{equation}
        [X,Y]=B(X,Y)t_{\alpha}.
    \end{equation}
\end{lemma}

\begin{proof}
    By theorem~\ref{TholGCartalphaplusbeta}\ref{ItemTholGCartalphaplusbetai}, $[X,Y]\in\lG_0=\lH$. Now we consider $h\in\lH$ and the invariance formula \eqref{eq:Killing_invariant}. We find:
    \begin{equation}
        B\big( h,[X,Y] \big)=-B\big( [X,h],Y \big)=\alpha(h)B(X,Y)=B(h,t_{\alpha})B(X,Y)=B\big(h,B(X,Y)t_{\alpha}\big).
    \end{equation}
    The lemma is proven since it is true for any $h\in\lH$ and $B$ is nondegenerate on $\lH$.
\end{proof}

The elements \( t_{\alpha}\) allow to introduce an inner product on \( \lH^*\) and hence on the roots by defining
\begin{equation}
    (\alpha,\beta)=B(t_{\alpha},t_{\beta}).
\end{equation}

\begin{lemma}       \label{Leminnerabequaaggb}
    If \( \alpha\) and \( \beta\) are roots we have the formula
    \begin{equation}
        (\alpha,\beta)=\sum_{\gamma\in\Phi}(\dim\lG_{\gamma})(\alpha,\gamma)(\beta,\gamma).
    \end{equation}
\end{lemma}

\begin{proof}
    We consider for \( \lG\) a basis in which all the elements are part of one of the root spaces and we look at the endomorphism \( \ad(t_{\alpha})\) of \( \lG\). This is diagonal and has zeros on the entries corresponding to \( \lH\). The other entries on the diagonal are of the form \( \gamma(t_{\alpha})\). Thus
    \begin{equation}
        B(t_{\alpha},t_{\beta})=\sum_{\gamma\in\Phi}(\dim\lG_{\gamma})\gamma(t_{\alpha})\gamma(t_{\beta}).
    \end{equation}
    Thus we have \( (\alpha,\beta)=B(t_{\alpha},t_{\beta})=\sum_{\gamma\in\Phi}(\dim\lG_{\gamma})(\alpha,\gamma)(\beta,\gamma)\).
\end{proof}

\begin{proposition}[\cite{Cornwell}]     \label{PropScalrooTsQ}
    Let \( \alpha\) and \( \beta\) be roots. We have
    \begin{enumerate}
        \item
            \( (\alpha,\beta)\in\eQ\),
        \item
            \( (\alpha,\alpha)\geq 0\).
    \end{enumerate}
\end{proposition}

\begin{proof}
    Let \( \alpha,\beta\in\Phi\) and consider the space
    \begin{equation}
        V=\bigoplus_{m\in\eZ}\lG_{\beta+m\alpha}.
    \end{equation}
    If \( X_{\alpha}\in\lG_{\alpha}\) and \( X_{-\alpha}\in\lG_{-\alpha}\) with \( [X_{\alpha},X_{-\alpha}]=t_{\alpha}\) we have, for all \( v\in V\),
    \begin{subequations}
        \begin{align}
            [X_{\alpha},v]&\in V\\
            [X_{-\alpha},v]&\in V\\
            [t_{\alpha},v]&\in V.
        \end{align}
    \end{subequations}
    Thus we can consider the restrictions to \( V\) of the operators \( \ad(X_{\alpha})\), \( \ad(X_{-\alpha})\) and \( \ad(t_{\alpha})\). Since \( \ad\) is an homomorphism we have, as operator on \( V\),
    \begin{equation}
        \ad(t_{\alpha})=\big[ \ad(X_{\alpha}),\ad(X_{-\alpha}) \big],
    \end{equation}
    and then \( \tr\big( \ad(t_{\alpha})|_V \big)=0\).

    Let us compute that trace on the basis \( \{ v_k^{(i)} \}\) where \( v_k^{(i)}\in\lG_{\beta+k\alpha}\). Since
    \begin{equation}
        \ad(t_{\alpha})v_k^{(i)}=(\beta+k\alpha)(t_{\alpha})v_k^{(i)}
    \end{equation}
    we have
    \begin{subequations}
        \begin{align}
            0&=\tr\big( \ad(t_{\alpha})|_V \big)\\
            &=\sum_{k\in\eZ}\dim\lG_{\beta+k\alpha}(\beta+k\alpha)(t_{\alpha})\\
            &=\sum_{k\in\eZ}\dim_{\beta+k\alpha}\big( (\alpha,\beta)+(\alpha,\alpha) \big)
        \end{align}
    \end{subequations}
    and
    \begin{equation}        \label{EqunderbAabmaaB}
        \underbrace{\left( \sum_{k\in\eZ}\dim\lG_{\beta+k\alpha} \right)}_{A\in\eN}(\alpha,\beta)=-(\alpha,\alpha)\underbrace{\left( \sum_{k\in\eZ}k\dim\lG_{\beta+k\alpha} \right)}_{B\in\eZ}.
    \end{equation}
    If \( (\alpha,\alpha)=0\) then we have \( (\beta,\alpha)=0\) for every \( \beta\in\Phi\), hence \( B(t_{\alpha},t_{\beta})=0\) which contradicts non degeneracy of the Killing form. We conclude that \( (\alpha,\alpha)\neq 0\). By the formula of lemma~\ref{Leminnerabequaaggb} we get
    \begin{equation}
        (\alpha,\alpha)=\sum_{\beta\in\Phi}\dim\lG_{\beta}(\alpha,\beta)^2.
    \end{equation}
    Replacing in that formula the value of \( (\alpha,\beta)\) taken from formula \eqref{EqunderbAabmaaB} we found
    \begin{equation}
        (\alpha,\alpha)=\sum_{\beta\in\Phi}\dim\lG_{\beta}\frac{ B^2 }{ A^2 }(\alpha,\alpha)^2
    \end{equation}
    and then \( (\alpha,\alpha)\in\eQ^+\). The fact that \( (\alpha,\beta)\) is rational follows.

    Notice that the sign of \( B\) is not guaranteed because it's not sure because we do not know whether there are more positive or negative terms in the sum of the right hand side of \eqref{EqunderbAabmaaB}.
\end{proof}

\begin{proposition}
    Let \( \alpha\) be a root of the complex semisimple Lie algebra \( \lG\). Then
    \begin{enumerate}
        \item
            \( \dim\lG_{\alpha}=1\),
        \item
            the only integer multiple of \( \alpha\) to be roots are \( \pm\alpha\).
    \end{enumerate}
\end{proposition}

\begin{proof}
    Let \( X_{\alpha}\in\lG_{\alpha}\) and consider the vector space
    \begin{equation}
        V=\eC t_{\alpha}\oplus\eC X_{\alpha}\oplus\bigoplus_{m<0}\lG_{m\alpha}.
    \end{equation}
    Let \( y\in\lG_{-\alpha}\) be chosen in such a way that \( [X_{\alpha},y]=t_{\alpha}\); by lemma~\ref{LemXYBXYtalpha} this is only a matter of normalization. The space \( V\) is invariant under \( \ad(X_{\alpha})\) and \( \ad(y)\). Indeed
    \begin{enumerate}
        \item
            \( \ad(X_{\alpha})t_{\alpha}=-\alpha(t_{\alpha})X_{\alpha}\in\eC X_{\alpha}\);
        \item
            \( \ad(X_{\alpha})X_{\alpha}=0\);
        \item
            \( \ad(X_{\alpha})\lG_{m\alpha}\subset\lG_{(m+1)\alpha}\); if \( m<-1\), \( (m+1)<0\), while if \( m=-1\) we know that the commutator \( [X_{\alpha},\lG_{-\alpha}]\) is included in \( \eC t_{\alpha}\in V\);
        \item
            \( \ad(y)t_{\alpha}\in\lG_{-\alpha}\)
        \item
            \( \ad(y)X_{\alpha}=-t_{\alpha}\) by definition;
        \item
            \( \ad(y)\lG_{m\alpha}\subset\lG_{(m-1)\alpha}\).
    \end{enumerate}
    Since \( \ad\colon \lG\to \GL(\lG)\) is an homomorphism (lemma~\ref{LemadhomomadXadYadXY}) we have
    \begin{equation}
        \big[ \ad(X_{\alpha}),\ad(y) \big]=\ad(t_{\alpha})
    \end{equation}
    and then \( \tr\big( \ad(t_{\alpha}) \big)=0\) because the trace of a commutator is zero\footnote{From the cyclic invariance of the trace.}. Since \( V\) is an invariant subspace, the trace of \( \ad(t_{\alpha})\) restricted to \( V\) is also vanishing. Let us compute that trace on the basis \( \{ X_{\alpha},t_{\alpha},X^i_{m\alpha} \}_{m<0}\) where \( i\) takes as many values as the dimension of \( \lG_{m\alpha}\).

    We have \( \ad(t_{\alpha})X_{-\alpha}=-\alpha(t_{\alpha})X_{-\alpha}\), \( \ad(t_{\alpha})t_{\alpha}=0\) and \( \ad(t_{\alpha})X^i_{m\alpha}=m\alpha(t_{\alpha})X_{m\alpha}\), thus the trace is
    \begin{equation}    \label{Eqzequalmulsumnotinfty}
        0=\alpha(t_{\alpha})\Big( -1+\sum_{m=1}^{\infty}m\dim\lG_{m_{\alpha}} \Big).
    \end{equation}
    Notice that the sum is in fact finite since the dimension of \( \lG\) is finite. We know that \( \alpha(t_{\alpha})=B(t_{\alpha},t_{\alpha})\neq 0\), so that equation \eqref{Eqzequalmulsumnotinfty} is only possible with \( \dim\lG_{\alpha}=1\) and \( \dim\lG_{m\alpha}=0\) for \( m\neq 1\).
\end{proof}

A very similar proof can be found in \cite{Cornwell}, page 827.


\begin{corollary}       \label{CorCoolWrlGbalpha}
    In the case of semisimple complex Lie algebra,

    \begin{enumerate}
        \item
            the root spaces are given by
            \begin{equation}        \label{EqExpWeightSemiSimple}
                \lG_{\alpha}=\{ X\in\lG\tq\forall h\in\lH, [h,X]=\alpha(h)X \};
            \end{equation}
        \item
            for every $ x_{\alpha}\in\lG_{\alpha}$, and for every $h\in\lH$, we have
            \begin{equation}
                [h, x_{\alpha}]=\alpha(h) x_{\alpha}.
            \end{equation}
    \end{enumerate}
\end{corollary}

\begin{proof}
    Let \( X\in\lG_{\alpha}\), we have
    \begin{equation}
        \big( \ad(h)-\alpha(h) \big)^nX=0,
    \end{equation}
    so
    \begin{equation}    \label{EqadhalphahnnmuvX}
        \big( \ad(h)-\alpha(h) \big) \underbrace{\big( \ad(h)-\alpha(h) \big)^{n-1} X}_v=0.
    \end{equation}
    In particular the vector \( v= \big( \ad(h)-\alpha(h) \big)^{n-1} X\) belongs to \( \lG_{\alpha}\). Since the latter space has dimension one, the vector \( v\) is a multiple of \( X\) and consequently equation \eqref{EqadhalphahnnmuvX} shows that
    \begin{equation}
        \big( \ad(h)-\alpha(h) \big)v=\big( \ad(h)-\alpha(h) \big)X=0.
    \end{equation}

    The second point is only an other way to write the same.
\end{proof}

\begin{lemma}       \label{LemHzesialphaHz}
    If \( H\) is an element of \( \lH\) with \( \alpha(H)=0\) for every root, then \( H=0\)
\end{lemma}

\begin{proof}
    Consider the decompositions (not unique) \( H=\sum_{\alpha\in\Phi}a_{\alpha} t_{\alpha}\) and \( H'=\sum_{\beta\in\phi}a'_{\beta}t_{\beta}\). Then
    \begin{subequations}
        \begin{align}
            B(H,H')&=\sum_{\alpha,\beta}a_{\alpha}a_{\beta}'B(t_{\alpha},t_{\beta})\\
            &=\sum_{\alpha,\beta}a'_{\beta}\beta(a_{\alpha},t_{\alpha})\\
            &=\sum_{\beta}a'_{\beta}\beta(H)\\
            &=0.
        \end{align}
    \end{subequations}
    Such an element is thus Killing-orthogonal to the whole space \( \lH\) but we already know the \( \lH\) is orthogonal to each space \( \lG_{\alpha}\) (\( \alpha\neq 0\)). By non degeneracy of the Killing form we must have \( H=0\).
\end{proof}

\begin{proposition}
    The set of roots of a complex semisimple Lie algebra spans the dual space \( \lH^*\).
\end{proposition}

\begin{proof}
    Consider a basis \( \{ H_i \}\) of \( \lH\) with \( \{ H_0,\ldots,H_m \}=\Span(\Phi)\) and \( \{ H_{m+1},\ldots,H_r \}\) be outside of \( \Span\Phi\). A root reads \( \alpha=\sum_{k=0}^ma_kH_k^*\).
    Thus \( \alpha(H_{m+1})=0\), which implies that \( H_{m+1}=0\) by lemma~\ref{LemHzesialphaHz}.
\end{proof}

\begin{corollary}
    A Cartan algebra \( \lH\) of a complex semisimple Lie algebra is abelian.
\end{corollary}

\begin{proof}
    Let \( H',H''\in\lH\) and consider \( H=[H',H'']\), a root \( \alpha\) and \( X_{\alpha}\in\lG_{\alpha}\). On the one hand we have
    \begin{equation}
        \big[ [H',H''],X_{\alpha} \big]=-\alpha(H')[X_{\alpha},H']+\alpha(H')[X_{\alpha},H'']=0
    \end{equation}
    and on the other hand we have \( \big[ [H',H''],X_{\alpha} \big]=[H,X_{\alpha}]=\alpha(H)X_{\alpha}\). We deduce that \( \alpha(H)=0\) for every root and then that \( H=0\) by lemma~\ref{LemHzesialphaHz}.
\end{proof}

We denote by \( \Phi\) the set of roots. These are the elements \( \lambda\in\lH^*\) such that \( \lG_{\lambda}\) is non trivial. We suppose to have chosen a positivity notion on \( \lH^*\), so that we can speak of \( \Phi^+\), the set of \defe{positive roots}{positive root}.

A positive root is \defe{simple}{simple!root} is it cannot be written as the sum of two positive roots.

%---------------------------------------------------------------------------------------------------------------------------
                    \subsection{Generators}
%---------------------------------------------------------------------------------------------------------------------------

We are going to build the Chevalley basis of the complex semisimple Lie algebra \( \lG\). That will essentially be a choice of a basis vector in each of the root spaces. We are following the notations summarized in point~\ref{SubsecNotationRootsDel}.


Now, for each root $\alpha$, we pick $e_{\alpha}\in\lG_{\alpha}$. We will see that, up to renormalization, we can set the in nice commutation relations.

\begin{lemma}       \label{LemBalpahbetaef}
    If \( \alpha\) and \( \beta\) are roots such that \( \alpha+\beta\neq 0\), then
    \begin{equation}
        B(e_{\alpha},e_{\beta})=0.
    \end{equation}
    If \( f_{\alpha}\in\lG_{-\alpha}\) we also have \( B(e_{\alpha},f_{\alpha})\neq 0\).
\end{lemma}

\begin{proof}
    By definition \( B(e_{\alpha},e_{\beta})=\tr\big( \ad(e_{\alpha})\circ\ad(e_{\beta}) \big)\). If we apply \( \ad(e_{\alpha})\circ\ad(e_{\beta})\) to an element of \( e_{\gamma}\) (including \( \lG_0=\lH\)), we get an element of \( \lG_{\alpha+\beta+\gamma}\). Thus the trace defining the Killing form is zero and \( B(e_{\alpha},e_{\beta})=0\) when \( \alpha+\beta=0\).

    Since the Killing form is nondegenerate, we conclude that \( B(e_{\alpha},e_{-\alpha})\neq 0 \).
\end{proof}

\begin{corollary}       \label{CorrExistInverseRoot}
    Let \( \lG\) be a semisimple complex Lie algebra and \( \lH\) be a Cartan subalgebra of \( \lG\). Let \( \alpha\) be a root of \( \lG\) and \( \lH_{\alpha}=[\lG_{\alpha},\lG_{-\alpha}]\). There exist an unique \( H_{\alpha}\in\lH_{\alpha}\) such that \( \alpha(H_{\alpha})=2\).
\end{corollary}

\begin{proof}
    We have \( [e_{\alpha},f_{\alpha}]=B(e_{\alpha},f_{\alpha})t_{\alpha}\) and the lemma~\ref{LemBalpahbetaef} shows that the Killing form is non zero. Multiplying by a suitable number provides the result.
\end{proof}
The element \( H_{\alpha}\in\lH\) defined in this lemma is the \defe{inverse root}{inverse!root} of \( \alpha\).

\begin{lemma}       \label{Lemalphaakbetaknimport}
    Let \( \{ \beta_1,\ldots,\beta_l \}\) be a choice of elements in \( \lH^*\) such that the set \( \{ t_{\beta_1},\ldots,t_{\beta_l} \}\) is a basis of \( \lH\). Thus the roots can be decomposed as
    \begin{equation}
        \alpha=\sum_{k=1}^la_k\beta_k
    \end{equation}
    with \( a_k\in\eQ\).
\end{lemma}

\begin{proof}

    Let \( \alpha=\sum_{k=1}^la_k\beta_k\). We know that the vectors \( t_{\beta_i}\) form a basis of \( \lH\), so we have the decomposition \( t_{\alpha}=\sum_ka_kt_{\beta_k}\). Indeed
    \begin{equation}
        B\big( h,\sum_k a_kt_{\beta_k} \big)=\sum_ka_k B(h,t_{\beta_k})=\sum_ka_k\beta_k(h)=\alpha(h).
    \end{equation}
    For each \( k=1,2,\ldots,l\) we have
    \begin{equation}
        (\alpha_k, \alpha) =\sum_{j=1}^la_k(\alpha_k, \alpha_j).
    \end{equation}
    This is a system of linear equations for the \( l\) variables \( a_k\). Since the coefficients \( (\alpha_k,\alpha)\) and \( (\alpha_k,\alpha_j)\) are rational by proposition~\ref{PropScalrooTsQ}, the solutions are rational too.
\end{proof}

\begin{remark}
    The lemma~\ref{Lemalphaakbetaknimport} deals with a quite general basis of \( \lH\). We will see in the proposition~\ref{ThoposrootnjajnZ} that in the case of the basis of simple roots, the coefficients \( a_k\) are integers, either all positive or all negative.
\end{remark}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Subalgebra \texorpdfstring{$ \gsl(2)_i$}{SL2R} }
%---------------------------------------------------------------------------------------------------------------------------
\label{SubSecCopiedeSLdansGi}

For each nonzero root \( \alpha\in\lH^*\), we choose \( e_{\alpha}\in\lG_{\alpha}\) and \( f_{\alpha}\in\lG_{-\alpha}\) in such a way to have
\begin{equation}
    B(e_{\alpha},f_{\alpha})=\frac{ 2 }{ B(t_{\alpha},t_{\alpha}) },
\end{equation}
and then we pose
\begin{equation}
    h_{\alpha}=\frac{ 2 }{ B(t_{\alpha},t_{\alpha}) }t_{\alpha}.
\end{equation}
Notice that these choices are possible because the Killing form is non degenerated on \( \lH\).

% This proposition about gsl(2,R) was at position 198631779.
\begin{proposition}[\cite{SternLieAlgebra}] \label{PropWEzZYzC}
    For each root, the set $\{ e_{\alpha},f_{\alpha},h_{\alpha} \}$ generates an algebra isomorphic to $\gsl(2,\eR)$, i.e. they satisfy
    \begin{subequations}
        \begin{align}
            [h_{\alpha},e_{\alpha}]&=2e_{\alpha}\\
            [h_{\alpha},f_{\alpha}]&=-2f_{\alpha}\\
            [e_{\alpha},f_{\alpha}]&=h_{\alpha}\\
        \end{align}
    \end{subequations}
\end{proposition}

\begin{proof}
    Since \( \alpha(t_{\alpha})=B(t_{\alpha},t_{\alpha})\) we have \( \alpha(h_{\alpha})=2\). Now the computations are quite direct. The first is
    \begin{equation}
        [h_{\alpha},e_{\alpha}]=\alpha(h_{\alpha})e_{\alpha}=2e_{\alpha}.
    \end{equation}
    For the second,
    \begin{equation}
        [h_{\alpha},f_{\alpha}]=-\alpha(h_{\alpha})f_{\alpha}=-2f_{\alpha}.
    \end{equation}
    For the third, we know that \( [e_{\alpha},f_{\alpha}]\in\lH\); thus \( B\big( X,[e_{\alpha},f_{\alpha}] \big)=0\) whenever \( X\in\lG_{\lambda}\) with \( \lambda\neq 0\). Let \( h\in\lH\). Using the invariance of the Killing form,
    \begin{equation}
        B\big( h,[e_{\alpha},f_{\alpha}] \big)=B\big( [h,e_{\alpha}],f_{\alpha} \big)=\alpha(h)B(e_{\alpha},f_{\alpha})=B(t_{\alpha},t_{\alpha})B(e_{\alpha},f_{\alpha})=B\big( B(e_{\alpha},f_{\alpha})t_{\alpha},h \big).
    \end{equation}
    Thus
    \begin{equation}
        [e_{\alpha},f_{\alpha}]=B(e_{\alpha},f_{\alpha})f_{\alpha}=h_{\alpha}.
    \end{equation}
\end{proof}
Remark that we used the non degeneracy of the Killing form in a crucial way. The copy of \( \gsl(2,\eR)\) formed by \( \{ e_{\alpha},f_{\alpha},h_{\alpha} \}\) is denoted by $\gsl(2,\eR)_{\alpha}$.

\begin{proposition}
    In the universal enveloping algebra,
    \begin{equation}        \label{Eqhjfikplusun}
        [h_j,f_i^{k+1}]=-(k+1)\alpha_i(h_j)f_i^{k+1}
    \end{equation}
    as generalisation of the previous one.
\end{proposition}

\begin{proof}
    We use an induction over $k$. Since $\ad(h_j)$ is a derivation in $\mU(\lG)$, the induction hypothesis and the definition relation $[h,f_i]=-\alpha_i(h)f_i$ with $h=h_i$, we have
    \begin{equation}
        \begin{split}
            \ad(h_j)f^{k+1}_i   &=\big( \ad(h_j)f_i^k \big)f_i+f_i^k\ad(h_j)f_i.\\
                        &=-k\alpha+i(h_j)f_i^kf_i-\alpha_i(h_j)f^{k+1}_i\\
                        &=-(k+1)\alpha_i(h_j)f_i^{k+1}.
        \end{split}
    \end{equation}
\end{proof}

Now the Lie algebra \( \lG\) can be seen as a \( \gsl(2,\eR)\)-module. As an example, for each choice of \( \beta\in\Phi\), the algebra \( \gsl(2)_{\alpha}\) acts on the vector space
\begin{equation}
    V=\bigoplus_{k\in\eZ}\lG_{\beta+k\alpha}.
\end{equation}
The vector space \( \lG\) carries thus several representations of \( \gsl(2)\); this fact will be used in a crucial way during the proof of proposition~\ref{Proppqasbabaa}.
