% This is part of (almost) Everything I know in mathematics and physics
% Copyright (c) 2013-2014, 2019
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Representations of \texorpdfstring{$ \SL(2,\eR)$}{SL(2,R)} and \texorpdfstring{$ \SU(2)$}{SU(2)}}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

The representation $\pi_m$ of $\SL(2,\eC)$ restricts to $\SL(2,\eR)$.

\begin{lemma}
	The representation $\pi_m$ of $\SL(2,\eR)$ is irreducible.
\end{lemma}

\begin{proof}
	If $W$ is an invariant space under $\pi_m\big( \SL(2,\eR) \big)$, then is is invariant under the derived representation $\rho_m\big( \gsl(e,\eR) \big)$. The proof of proposition~\ref{ProprhomirredsldeuxC} still holds here, so that $W=\mP_m$.
\end{proof}

\begin{theorem}
	Let $\pi$ be an irreducible representation of $G=\SL(2,\eR)$ or $\SU(2)$ in a complex finite dimensional vector space $V$. Then $\pi$ is equivalent to one of the $\pi_m$.
\end{theorem}

\begin{proof}
	Let $\lG$ be the Lie algebra of $G$. One important property shared by $\SL(2,\eR)$ and $\SU(2)$ is that $G=\exp(\lG)$. It is clear that the representation $d\pi$ on $\gsl(2,\eR)$ extends $\eC$-linearly to a representation $\rho$ of $\gsl(2,\eC)$. Looking on the basis \eqref{EqGenssudeux}, one sees that in fact the same is true for $\gsu(2)$ which $\eC$-linearly extends to $\gsl(2,\eC)$.

	Let us prove that $\rho$ is irreducible. Let $W\neq\{ 0 \}$ be a subspace of $V$ invariant under $\rho(\lG)$. Then $W$ is invariant under $ e^{\rho(X)}=\pi( e^{X})$ for every $X\in\lG$. Since $\exp(\lG)=G$, the space $W$ is in fact invariant under $\pi(G)$, and is therefore equal to $V$.

	Since $\rho$ is irreducible, we have $\rho=\rho_m$ for a certain $m$. Thus there exists an intertwining operator $A\colon V\to \mP_m$ such that
	\[
		A\rho(X)=\rho_m(X)A
	\]
	for every $X\in\lG$. By linearity, for every $N\in\eN$, we have $A\rho\big( \sum_{k=1}^n X^k/k! \big)=\rho_m\big( \sum_{k=1}^n X^k/k! \big)A$, and at the limit, we have
	\begin{equation}
		A e^{\rho(X)}= e^{\rho_m(X)A}.
	\end{equation}
	From that we deduce that $A\pi( e^{X})=\pi_m( e^{X})A$ which means that
	\[
		A\pi(g)=\pi_m(g)A.
	\]
	That shows that $A$ intertwines $\pi$ and $\pi_m$, so that $\pi$ is equivalent to $\pi_m$.
\end{proof}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Representations of \texorpdfstring{$\so(2,d-1)$}{so2d}}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Here we deal with the representations of \( \so(2,d-1)\). For singleton theory as field theory, see the section~\ref{SecUKPhZVd} (you are welcome if you can fill that section which is for the moment almost empty).

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Verma module}
%---------------------------------------------------------------------------------------------------------------------------

One can find text about these representations in \cite{Ferrata,Dolan_son,SingString}, while we will mainly follow the developments of \cite{SingletonCompposites,HowMassless,Teschner}. We are going to study representations of the algebra $\so(2,d-1)$ which fulfills the commutation relations described in lemma~\ref{LemCommsopqAlg}:
\begin{equation}		\label{EqCommsodeuxdmoinsun}
	[M_{ab},M_{cd}]=-i\eta_{ac}M_{bd}+i\eta_{ad}M_{bc}+i\eta_{bc}M_{ad}-i\eta_{bd}M_{ac}.
\end{equation}
Notice that $M_{ab}=-M_{ba}$. As convention, the indices $a$, $b$,\ldots{} run over $\{ 0,0',1,2,\ldots d-1 \}$ while $r$, $s$, \ldots{} run over $\{ 1,2,\ldots,d-1 \}$. As on page \pageref{PgDefsGenre}, we choose the convention
\begin{equation}
	\eta =
	\begin{pmatrix}
		\mtu_{2\times 2}             \\
		 & -\mtu_{(d-1)\times (d-1)}
	\end{pmatrix}.
\end{equation}
Notice that this convention numerically holds for the matrix $\eta_{st}$ as well as for its inverse $\eta^{st}$.

The algebra separates into two parts: the compact and the non compact part. The maximal compact subalgebra is $\so(2)\oplus\so(d-1)$ which is generated by $E=M_{00'}$ and $J_{rs}=M_{rs}$. The non compact generators are $M_{0'r}$ and $M_{0r}$ that we rearrange into ladder operators
\begin{equation}
	L^{\pm}_r=M_{0r}\mp iM_{0'r}.
\end{equation}
Using commutation relations \eqref{EqCommsodeuxdmoinsun}, one computes the commutators in the new basis. For example
\[
	[E,L^{\pm}_r]=[M_{0'0},M_{0r}]\mp i[E_{0'0},M_{0'r}]=\pm M_{0r}-iM_{0'r}=\pm L^{\pm}_r.
\]
The table of $\so(2,d-1)$ in this basis is
\begin{subequations}		\label{SubEqsCommssodeuxd}
	\begin{align}
		[E,L^{\pm}_r]      & =\pm L^{\pm}_r                                                                 \\
		[J_{rs},L_t^{\pm}] & =-i(\delta_{rt}L_s^{\pm}-\delta_{st}L_r^{\pm})                                 \\
		[L_r^{-},L_s^+]    & =2(iJ_{rs}+\delta_{rs}E)                                                       \\
		[J_{rs},J_{tu}]    & =-i\delta_{ac}M_{bd}+i\delta_{ad}M_{bc}+i\delta_{bc}M_{ad}-i\delta_{bd}M_{ac}.
	\end{align}
\end{subequations}
The unitary properties are $(M_{rs})^{\dag}=M_{rs}$, $E^{\dag}=E$ and $(L^{\pm}_r)^{\dag}=L_r^{\mp}$. From these commutators, we deduce the following rules that will be always used
\begin{subequations}
	\begin{align}
		L^-_rL^+_s  & =L^+_sL^-_r+2(iJ_{rs}+\delta_{rs}E)               \\
		J_{rs}L^+_t & =L^+_tJ_{rs}-i(\delta_{rt}L^+_s-\delta_{st}L^+_r) \\
		EL^+_r      & =L^+_rE+L^+_r.
	\end{align}
\end{subequations}

The Cartan algebra of $\so(d)$ is given by the elements $A_p=M_{2p-1,2p}$ with $p=1,\ldots, r$ for $\so(2r)$ and $\so(2r+1)$.

The unitary irreducible representations of $\so(2,n)$ have the form $\mD(e_0,\bar\jmath)$. It is given by a basis vector $| e_0,\bar\jmath \rangle$ on which $E$ and $J_{rs}$ act by their respective representations (of $\so(n)$ and $\so(2)$). The \defe{energy}{energy!in the representations of $\so(2,d-1)$} of the vector $\ket{e,\overline{ m }}$ is its eigenvalue for the operator $E$, namely $e$:
\begin{equation}
	E\ket{e,\overline{ m }}=e\ket{e,\overline{ m }}.
\end{equation}
Using the commutators \eqref{SubEqsCommssodeuxd}, we find $L_r^{\pm}=(E\pm 1)L_r^{\pm}$, so that
\begin{equation}
	E L^{\pm}_r\ket{e,\overline{ m }} =(e\pm 1)\ket{e,\overline{ m }}.
\end{equation}
We see that the ladder operator $L_r^+$ raises the value of the energy of one unit, while the operator $L_r^-$ lower the energy of one unit. The vector $\ket{e_0,\bar\jmath}$ is the \defe{vacuum vector}{vacuum!vector}, it has the lowest energy in the sense that $L^{-}_r| e_0,\jmath \rangle=0$. A \defe{scalar representation}{scalar!representation} is a representation with $\bar\jmath=0$. They are, logically, denoted by $\mD(e_0)$ and its vacuum is $| e_0 \rangle$ which satisfies
\begin{align}		\label{Eqaldefketezerovac}
	J_{rs}| e_0 \rangle & = 0 & (E-e_0)| e_0 \rangle & =0 & L_r^{-}| e_0 \rangle & =0.
\end{align}
Then one build the generalised Verma module
\begin{equation}	\label{EqmVVermaldots}
	\mV(e_0,0)\equiv \big\{   L_{r_1}^+\ldots L_{r_n}^+| e_0 \rangle   \big\}_{n=0}^{\infty}.
\end{equation}
Notice that the Verma module is not automatically irreducible. We will soon build irreducible representations by taking quotient of the Verma module by its singular module.

In order to compute the norm of $L_s^+L_r^+\ket{e_0}$, we compute $L^-_rL^-_sL^+_sL^+_r\ket{e_0} =4\big(E+E^2+\delta_{rs}E^2+(J_{rs})^2\big)\ket{e_0}$. In order to get that result, we moved all the $L^-$ on the right using the commutation relation, and we taken into account the simplifications induced by the definition relations \eqref{Eqaldefketezerovac}. Now, using the relation $J_{rs}\ket{e_0}=0$, we have
\begin{equation}
	4\big(E+E^2+\delta_{rs}E^2\big)\ket{e_0}.
\end{equation} We also have
\begin{equation}
	(E-e_0)L^+_sL^+_s\ket{e_0}=0.
\end{equation}

\begin{proposition}
	The vectors $L^+_{r_1}\ldots L^+_{r_k}\ket{e_0}$ and $L^+_{t_1}\ldots L^+_{t_l}\ket{e_0}$ are orthogonal if $k\neq l$.
\end{proposition}
That proposition says that different layers are orthogonal\quext{À justifier en analysant qui est exactement $\lH$ et les racines simples, mais ça me semble ok.}

\begin{proof}
	We proceed by induction. We suppose that the result is proved for $k,l\geq n$, and we prove that
	\begin{equation}
		L^-_{t_1}\ldots L^-_{t_{n+1}}L^+_{r_1}\ldots L^+_{r_n}\ket{e_0}=0.
	\end{equation}
	First, remark that, using the commutation relations and the fact that $J_{rs}\ket{e_0}=0$ and $E\ket{e_0}=e_0\ket{e_0}$, the vectors
	\begin{subequations}		\label{SubEqsJELLket}
		\begin{align}
			J_{st}L^+_{r_1}\ldots L^+_{r_k}\ket{e_0} \\
			EL^+_{r_1}\ldots L^+_{r_k}\ket{e_0}
		\end{align}
	\end{subequations}
	are combinations of vectors of the form $L^+_{a_1}\ldots L^+_{a_k}\ket{e_0}$. Now, we have
	\begin{equation}
		L^-_{t_1}\ldots L^-_{t_{n+1}}L^+_{r_1}\ldots L^+_{r_n}\ket{e_0}= L^-_{t_1}\ldots L^-_{t_n}\big( L^+_{r_1}L^-_{t_{n+1}}+2i(J_{t_{n+1},r_1} + \delta_{t_{n+1},r_1}E ) \big)L^+_{r_2}\ldots L^+_{r_n}\ket{e_0}
	\end{equation}
	which decomposes in three terms. The first one is
	\begin{equation}
		L^-_{t_1}\ldots L^-_{t_n}L^+_{r_1}L^-_{t_{n+1}}L^+_{r_2}\ldots L^+_{r_n}\ket{e_0},
	\end{equation}
	and according to equations \eqref{SubEqsJELLket}, the two other terms reduce to zero. Continuing that way, the operator $L^-_{t_{n+1}}$ advance of one position at each step and finishes to kill himself on $\ket{e_0}$.
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Singular module}
%---------------------------------------------------------------------------------------------------------------------------

Let us compute the norm of the general vector $L^+_{r_1}\ldots L^+_{r_k}\ket{s_0,s}$. We have
\begin{equation}
	\begin{aligned}[]
		L^-_{r_k}\ldots L^-_{r_1}L^+_{r_1}\ldots L^+_{r_k}\ket{e_0,s}
		 & = L^-_{r_k}\ldots L^-_{r_2} (L^+_{r_1}L^-_{r_2}+2E) L^+_{r_2}\ldots L^+_{r_k}\ket{e_0,s} \\
		 & = L^-_{r_k}\ldots L^-_{r_2}L^+_{r_1}L^-_{r_2}L^+_{r_2}\ldots L^+_{r_k}\ket{e_0,s}        \\
		 & \quad +2(e_0+k-1)L^-_{r_k}\ldots L^-_{r_2} L^+_{r_2}\ldots L^+_{r_k}\ket{e_0,s}
	\end{aligned}
\end{equation}
Using again and again the commutation relations, we eliminate all the operators $L^+_r$ and we obtain a sum of terms of the form $(e_0+k-l)$. It will, obviously be positive for large enough $e_0$. Thus, unitarity of the representation is enforced for large values of $e_0$, and there exists a lower bound $E_0(s)$ such that negative norm states appears when $e_0<E_0(s)$. If $e_0=E_0(s)$, then these vectors have a vanishing norm.

Let us consider a limit representation: $e_0=E_0$; there are vectors of vanishing norm, but no vectors with negative norm. In that case, if $v\cdot v=0$, then $v\cdot w=0$ for every other vector $w$. Indeed, if $v\cdot w\neq 0$, we have
\begin{equation}
	(v-w)\cdot(v-w)=w\cdot w - v\cdot w-w\cdot v,
\end{equation}
which holds for every positive multiple $\lambda v$ and $\mu w$. Choosing a big $\lambda$ and a small $\mu$, the norm of $\lambda v-\mu w$ becomes negative. What we proved is
\begin{lemma}
	If the energy $e_0$ of a representation saturates the unitary condition, then a vector with vanishing norm is orthogonal to every other vectors. Moreover, the vectors with vanishing norm form an invariant subspace.
\end{lemma}
The second part is the fact that, if $A\in\lG$, and $\| \ket{\psi} \|=0$  then $\| A\ket{\psi} \|=0$, because it is the scalar product of $\ket{\psi}$ with the vector $A^{\dag}A\ket{\psi}$. The submodule made of vectors of zero norm is the \defe{singular submodule}{singular!submodule}, and is denoted by $\mS(e_0,s)$.

\begin{proposition}		\label{PropSinModRedSSIADesNuls}
	A module is reducible if and only if it possesses a vector $\ket{v}$ (different from $\ket{e_0,s}$) such that $L^-_r\ket{v}=0$ for every $r$. Such a vector is said to be \defe{null}{null vector}.
\end{proposition}

\begin{proof}
	Since the energy is bounded from bellow, applying several times the lowering operators $L^-_r$ on any vector ends up on zero. Thus, any submodule contains a vector $\ket{v}$ such that $L^-\ket{v}=0$ for every $r$. If that vector is not $\ket{e_0,s}$, then the submodule is a proper submodule.

	If $\ket{v}\neq\ket{e_0,s}$, then it is of the form $L^+_{\bar r}\ket{e_0,s}$ and its norm is given by
	\begin{equation}
		\| L^+_{\bar r}\ket{e_0,s} \|=\bra{e_0,s} L^-_{\bar r}L^+_{\bar r}\ket{e_0,s}=0
	\end{equation}
	because $L^-_{\bar r}L^+_{\bar r}\ket{e_0,s}=0$ by assumption.
\end{proof}
From the Verma module \eqref{EqmVVermaldots}, we thus extract the irreducible representation taking the quotient by the singular module:
\begin{equation}
	\mH(e_0) = \mV(e_0)/\mS(e_0).
\end{equation}

Most of time, we have only one extra vacuum, let $\ket{e'_0,s'}$, and in this case, the whole singular module is generated by vectors of the form
\begin{equation}
	L^+_{r_1}\ldots L^+_{r_k}\ket{e'_0,s'}.
\end{equation}
Let $\ket{e_0,s}$ be the vacuum with $s=(s_1,s_2,0,\ldots,0)$, corresponding to the Young diagram
\begin{equation}
	\input{auto/pictures_tex/Fig_AIFsOQO.pstricks}
	%	\input{image_Young_sssSing.pstricks}
\end{equation}
where the first line has $s_1$ boxes and the second one has $s_2$ boxes. Thanks to theorem~\ref{ThoOpqrepreTens}, it can be realized with the tensor
\begin{equation}
	v_{a_1,\ldots a_{s_2}b_1\ldots s_1}(e_0)
\end{equation}
which is separately symmetric in the indices $a$ and $b$, in the same time as being antisymmetric in the couples $a_i$, $b_i$ when $i\leq s_2$, for example,
\begin{equation}
	v_{a_1\ldots a_{s_2},b_1\ldots b_{s_1}} = -v_{b_1 a_1\ldots a_{s_2},b_2\ldots b_{s_1}}.
\end{equation}
In particular, if we symmetrise $v$ on $s_1+1$ indices, we always found zero. Moreover, all the traces vanishes. If $\eta$ is the metric of $O(D-1)$, we have for example
\begin{equation}
	\eta^{b_1b_2}v_{a_1\ldots a_{s_2},b_1,\ldots b_{s_2}}=0.
\end{equation}

The vectors of the first level are the ones of the form	$L^+_r\ket{e_0,s}$. As far as notations are concerned, we have
\begin{equation}
	L^+_rv_{a_1\ldots a_{s_2},b_1\ldots b_{s_2}}=(L^+_rv)_{a_1\ldots a_{s_2},b_1\ldots b_{s_2}}.
\end{equation}
Remark that the operators $\{ L_r^+ \}_{r=1,\ldots,D-1}$ carry a representation of $o(D-1)$, namely the vector representation. Thus, the states of the first level form the representation given by the tensor product of $(s_1,s_2,0,\ldots)$ and the vector representation. In order to see the irreducible components of that representation, we have to know what are the symmetry properties that we can give to the indices
\begin{equation}
	r,a_1,\ldots,a_{s_2},b_1,\ldots,b_{s_1}.
\end{equation}
There are three possibilities: we can contract the $r$ with one of the $a_i$ (by symmetry, all of these contractions are equivalent), or with one of the $b_i$, or add one box in the Young diagram. The latter possibility splits into three cases: the diagram $(s_1,s_2,0,\ldots)$ can be transformed in $(s_1+1,s_2,0,\ldots)$, $(s_1,s_2+1,0,\ldots)$ or $(s_1,s_2,1,0,\ldots)$. So we have $5$ irreducible component in the $o(D-1)$ representation carried by the level one.

The question that naturally arises is to know if one of these have a singular vacuum. In other words, if $\Pi_{\beta}$ are the projections to the irreducible components, do we have
\begin{equation}
	L^-_{t}\Pi_{\alpha}\big( L^+_rv_{\bar a,\bar b}(e_0) \big)=0
\end{equation}
for a certain $e_0$?

Notice that the contraction with the last $b_i$'s is not the same as the one with the firsts ones because of the symmetry properties with respect to the $a_i$'s. The first representation with cell cut is given by
\begin{equation}
	v^1_{\bar a,b_1\ldots b_{s_1-1}}	=\eta^{rt}L^+_r\big\{ v_{\bar a,b_1 \ldots b_{s_1-1}t}(e_0)
	+\frac{ s_2 }{ s_1-s_2+1 } v_{ca_1\ldots a_{s_2-1},b_1\ldots b_{s_1-1}a_{s_2}(e_0)}\big\},
\end{equation}
while the second representation with cell cut is easier:
\begin{equation}
	v^2_{a_1\ldots a_{s_{2}-1},\bar b}=\eta^{rt}L^+_rv_{ta_1\ldots a_{s_2-1},\bar b}(e_0).
\end{equation}
Now, the sport is to compute $L^-_qv^1_{\bar a,b_1\ldots b_{s_1-1}}$ and $L^-_q v^2_{a_1\ldots a_{s_{2}-1},\bar b}$.

\begin{probleme}
	Il y a du calcul non terminé, ici.
\end{probleme}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{The quotient for the scalar singleton}
%---------------------------------------------------------------------------------------------------------------------------

The value of the energy which saturates the unitary condition is $1$ when $s=\frac{1}{ 2 }$ and $\frac{ 1 }{2}$ when $s=0$. That is the reason why we consider the two special representations
\begin{equation}
	\begin{aligned}[]
		\rDi & =\mD(1,\frac{ 1 }{2}) &  & \rRac & =\mD(\frac{ 1 }{2},0).
	\end{aligned}
\end{equation}
We are now interested in the scalar case, the $Rac$.

We know that, when $\epsilon_0$ is the value of the energy which saturates the unitary condition $e_0\geq \frac{ d-3 }{ 2 }$ (in the scalar case, then
\begin{enumerate}
	\item the vectors $L^+_sL^+_s\ket{\epsilon_0}$ are singular vectors,
	\item the vectors $L^+_{r_1}\cdots L^+_{r_n}L^+_sL^+_s\ket{\epsilon_0}$ is orthogonal to all other states, it is a null vector.
\end{enumerate}
On the other hand, we know from proposition~\ref{PropSinModRedSSIADesNuls} that a module is reducible if and only if it has a vector $\ket{v}\neq\ket{e_0,s}$ such that $L^-_r\ket{v}=0$ for every $r$. Thus one constructs irreducible representations by taking the quotient of the Verma module by the singular module.

What is the dimension of the scalar singleton? We have to count how many different vectors we have in the Verma module $\mV(e_0,0)\equiv \big\{   L_{r_1}^+\ldots L_{r_n}^+| e_0 \rangle   \big\}_{n=0}^{\infty}$, and which \emph{are not} build over $L^+_sL^+_s\ket{e_0}$. In the case of $\SO(2,3)$, we have the generators $L^+_1$, $L^+_2$ and $L^+_3$ (which are commuting), so the only vectors that are left after removing the singular modules are the seven following ones: $L^+_1\ket{e_0}$, $L^+_2\ket{e_0}$,$L^+_3\ket{e_0}$, $L^+_1L^+_2\ket{e_0}$, $L^+_1L^+_3\ket{e_0}$,$L^+_2L^+_3\ket{e_0}$, and $L^+_1L^+_2L^+_3\ket{e_0}$. The scalar singleton representation is thus $7$ dimensional.
