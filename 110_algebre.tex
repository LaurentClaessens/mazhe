% This is part of (almost) Everything I know in mathematics and physics
% Copyright (c) 2013-2014,2016
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.

%%%%%%%%%%%%%%%%%%%%%%%%%%
%
   \section{Algebraic structures}
%
%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Algebraic structures}
%--------------------------------

A set with operations $(R,+,\cdot)$ is a \defe{ring}{ring} if 
\begin{itemize}
\item $(R,+)$ is an abelian group (we denote the neutral by $0$),
\item the multiplication $(R,\cdot)$ is unital and associative,
\item the multiplication is distributive with respect to addition.
\end{itemize}
A ring is not always a vector space because there are no multiplication by scalar.

A \defe{field}{field!algebraic structure} is a commutative ring whose nonzero elements form a group under multiplication.

An \defe{algebra}{algebra} is a vector space $\cA$ on $\eR$ or $\eC$ (or any field $\eK$) with an operation $\times\colon \cA\times\cA\to \cA$ such that
\begin{itemize}
\item $\times$ is distributive at left and right with respect to addition (vector structure),
\item for all $z,z'\in\cA$ and $A$, $B\in\cA$,
\[ 
  zA\times z'B=(zz')(A\times B).
\]
\end{itemize}
Most of time, the element $A\times B$ is just denoted by $AB$. In the case of Lie algebra, $X\times Y$ is $[X,Y]$. We will often treat with unital associative algebras on $\eC$; these algebras are in fact rings.


When $\cA$ is an algebra, the \defe{opposite}{opposite algebra} $\cA^0$\nomenclature{$\cA^0$}{Opposite algebra} is given by $\cA^0=\cA$ as sets, but multiplication in $\cA^0$ is
\[ 
  a^0b^0:=(ba)^0
\]
where the left hand side product is the one in $\cA^0$ while the right hand side one is the product in~$\cA$. A \defe{trace}{trace!over an algebra} aver an algebra is a linear form which satisfies the cyclic property $\tau(xy)=\tau(yx)$ for every elements $x$ and $y$ in the algebra.

\subsection{Morphisms and such}
%----------------------------

When $(E,\times)$ and $(F,\cdot)$ are two set with composition law and appropriate differential structure, a map $\varphi\colon E\to F$ is a
\begin{description}
\item[monomorphism] if $\ker\varphi=0$,
\item[epimorphism]  if $\varphi$ is surjective,
\item[homomorphism] if $\varphi(x\times y)=\varphi(x)\cdot\varphi(y)$,
\item[homeomorphism] if $\varphi$ and $\varphi^{-1}$ are continuous ($\varphi^{-1}$ needs to exist !).
\end{description}

If $(E,\times)$ and $(F,\cdot)$ are two sets with a composition law, a map $\dpt{\varphi}{E}{F}$ is a \defe{homomorphism}{homomorphism} if it satisfies
\[
     \varphi(x\times y)=\varphi(x)\cdot\varphi(y).
\]
It is a \defe{monomorphism}{monomorphism} when $\ker\varphi=0$ and an \defe{epimorphism}{epimorphism} if $\varphi(E)=F$.

If $M$ and $N$ are differentiable manifolds of respective dimension $m$ and $n$, a map $\dpt{f}{M}{M}$ is \defe{differentiable}{differentiable!map} if the coordinate associated map $\dpt{f_{\alpha i}}{\mU_{\alpha}}{\mU_i}$ is of class $\Cinf$ for any chart $\mU_{\alpha}$ of $M$ and $\mU_i$ of $N$.

The map $\dpt{f}{M}{N}$ is a \defe{diffeomorphism}{diffeomorphism} if $f$ is bijective and if $g$ and $g^{-1}$ are both differentiable. An \defe{homeomorphism}{homeomorphism} is a continuous map which has a continuous inverse.

\begin{remark}
Take care to not confuse \emph{homomorphism} and \emph{hom\underline{eo}morphism}. The first is only a map which respect an algebraic structure (a composition law) while the second also satisfies topological conditions: it must be continuous and open.
\end{remark}

%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Group ring}
%---------------------------------------------------------------------------------------------------------------------------

Let $G$ be a group and $R$, a ring. The set $R[G]$, called the \defe{group ring}{group ring} of $G$ is 
\begin{equation}
	R[G]=\{ \sum_{g\in G}a_gg \}
\end{equation}
where $a_g\in R$ is non vanishing only for a finite number of $g$. The set $R[G]$ becomes a group by combining the composition law of $G$ and $R$ in the following way:
\begin{equation}
	\Big( \sum_ga_gg \Big)\Big( \sum_hb_hh \Big)=\sum_{g,h}(a_gb_h)gh.
\end{equation}
One can show that this definition is the only one for which the property
\[ 
	(1g)(1h)=(1gh)
\]
holds when $R$ has an unit $1$.  If $R$ and $G$ are commutative, then $R[G]$ is commutative.

\section{Tensor products}
%+++++++++++++++++++++++++

%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Tensor product of vector spaces}
%---------------------------------------------------------------------------------------------------------------------------

When $V$ and $W$ are vector spaces, it is well known that the Cartesian product $V\times W$ is a vector space. A \defe{tensor product}{tensor product!of vector spaces} of $V$ and $W$ is a vector space $V\otimes W$ endowed with a bilinear map $\sigma\colon V\times W\to V\otimes W$ such that for every vector space $X$ and bilinear map $B\colon V\times W\to X$, there exists an unique linear map $\varphi\colon V\otimes W\to X$ such that $\varphi\circ\sigma=B$, i.e. the following diagram commutes:
\[ 
\xymatrix{%
   V\times W \ar[dr]_{B}\ar[rr]^{\sigma}		&	&V\otimes W\ar@{.>}[dl]^{\varphi}\\
 					&  X.
}	
\]
One can exhibit an explicit construction for the tensor product. Let $\{ v_{\alpha} \}$ and $\{ w_{\beta} \}$ be basis of $V$ and $W$ respectively and define $V\otimes W$ as the free vector space generated by the symbols $v_{\alpha}\otimes w_{\beta}$ endowed with the bilinear map $V\times W\to V\otimes W$,
\[ 
  \big( \sum_{\alpha} a_{\alpha} v_{\alpha},\sum_{\beta} b_{\beta}w_{\beta} \big)\mapsto\sum_{\alpha\beta} a_{\alpha}b_{\beta}\, v_{\alpha}\otimes w_{\beta}.
\]

One can form in that way tensor product of any \emph{finite} number of vector space. For the infinite product case, we make a direct limit, namely if $V_k$ are normed vector spaces, we choose unit vectors $v_k\in V_k$ and we define
\begin{equation}
\bigotimes_{k=1}^{\infty} V_k=\text{completion of }\left(\lim_{\rightarrow}\bigotimes_{k=1}^N V_k\right),
\end{equation}
the maps being $w_1\mapsto w_1\otimes v_2$, and so on\ldots

\begin{lemma}
If $V_i$ are finite dimensional vector spaces, there exists an isomorphism $\phi\colon (V_1\otimes V2)^*\to V_1^*\otimes V_2^*$. 
\end{lemma}
\begin{proof}
Indeed an element of $(V_1\otimes V_2)^*$ reads $F=F^{i\alpha}(e_i\otimes e_{\alpha})^*$ where $\{ e_i \}$ is a basis of $V_1$ and $\{ e_{\alpha} \}$ is a basis of $V_2$. Then we define
\[ 
  \phi(F)=F^{i\alpha}e_i^*\otimes e_{\alpha}^*.
\]
\end{proof}

\begin{lemma}
When $V_1$ and $V_2$ are finite dimensional, an inner product on $V_1\otimes V_2$ such that
\[ 
  \langle w_1\otimes w_2, z_1\otimes z_2\rangle =\langle w_1, z_1\rangle \langle w_2, z_2\rangle 
\]
exists and is unique.
\end{lemma}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Some conversions}
%---------------------------------------------------------------------------------------------------------------------------
\label{SUBSECooAASYooVHZEhz}

Let \( A,B\) be vector spaces and a bilinear map
\begin{equation}
    \psi\colon A\times B\to B.
\end{equation}
This can also be seem as a map \( \psi\colon A\otimes B\to B\). Here the tensor product is taken with respect to the base field \( \eR\).
We consider a basis \( \{ e_k \}\) of \( A\) and \( \{ f_{\alpha} \}\) of \( B\) and we define \( \psi_{k\alpha}\in B\) by \( \psi_{k\alpha}=\psi(e_k,f_\alpha)\). Thus if \( a=\sum_ka_ke_k\) and \( b=\sum_{\alpha}b_{\alpha}f_{\alpha}\) we have
\begin{equation}
    \psi(a,b)=\sum_{k\alpha}\psi_{k\alpha}a_kb_\alpha.
\end{equation}
  This induces a map 
\begin{equation}
    \varphi\colon B\to B\otimes A^*
\end{equation}
defined by
\begin{equation}
    \varphi(b)=\sum_{k\alpha}(\psi_{k\alpha}b_{\alpha})\otimes e_k^*.
\end{equation}
It can also be seen as a map \( \varphi(b)\colon A\to B\) by
\begin{equation}
    \varphi(b)a=\varphi(b)(A\otimes a)=\sum_{k\alpha} \big( (\psi_{k\alpha}b_{\alpha})\otimes e_{k}^*\big)(1\otimes a)=\sum_{k\alpha}\psi_{k\alpha}b_{\alpha}a_k=\psi(a,b).
\end{equation}
Here ``\( 1\)'' is the \( B\)-valued \( 1\)-form over \( B\) that is defined by \( 1(b)=b\).

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Contraction of tensors}
%---------------------------------------------------------------------------------------------------------------------------

Let \( (M,g)\) be a (pseudo)Riemannian manifold and \( X\in\Gamma(TM)\), \( \omega\in\Gamma(T^*M)\). We can consider the tensor product
\begin{equation}    
    X\otimes \omega\in \Gamma(TM)\otimes \Gamma(T^*M).
\end{equation}
\begin{definition}
    The \defe{contraction}{contraction!of a tensor} of \( X\otimes \omega\) is the function
    \begin{equation}    \label{EQooDODKooOxCzZP}
        C(X\otimes \omega)=\sum_{kj}(g^{-1})_{kj}\omega_jX_k
    \end{equation}
    where we have decomposed \( X=\sum_kX_k\partial_k\) and \( \omega=\sum_l\omega_ldx_l  \).
\end{definition}
The fact to have used the inverse of the metric allows to use the Einstein's summation convention : 
\begin{equation}
    C(X\otimes \omega)=\omega^iX_i=g^{ik}\omega_kX_i
\end{equation}
where \( g^{ik}=(g^{-1})_{ik}\).

%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Tensor product of groups}
%---------------------------------------------------------------------------------------------------------------------------

Let $A$ and $B$ be two abelian groups, we define the tensor product of $A$ and $B$ as the abelian group $A\otimes_{\eZ}B$ endowed with a map $A\times B\to A\otimes_{\eZ}B$ which is an homomorphism onto $A$ when $b\in B$ is fixed and an homomorphism onto $B$ when $a\in A$ is fixed, and such that for every morphism $A\times B\to C$ to an abelian group $C$, there exists a morphism $A\otimes_{\eZ}B\to C$ which makes the following diagram commute
\[ 
\xymatrix{%
   A\times B \ar[rr]\ar[dr]_{\displaystyle\forall}		&&	A\otimes_{\eZ}B\ar[ld]^{\displaystyle\exists !}\\
								& C.
}
\]

Let $R$ be a ring; $A$, a right $R$-module and $B$, a left $R$-module. We define
\begin{equation}		\label{EqdefAtensRB}
	A\otimes_RB=\frac{ A\otimes_{\eZ}B }{\text{subgroup generated by elements of the form $ar\otimes_{\eZ}b-a\otimes_{\eZ}rb$}}.
\end{equation}

\section{Modules over algebras}
%++++++++++++++++++++++++++++++

Some more details can be found in \cite{Landi}.


Let $\cA$ be an algebra on $\eC$. A vector space $\modE$ is a \defe{right module}{module!right} on $\cA$ if it carry a right representation of $\cA$. In other terms, if we have a right multiplication 
\begin{equation}
\begin{aligned}
 \modE\times\cA&\to \modE \\ 
  (\eta,a)&\mapsto \eta a 
\end{aligned}
\end{equation}
such that
\begin{subequations}
\begin{align}
  \eta(ab)&=(\eta a)b\\
\eta(a+b)&=\eta a+\eta b\\
(\eta+\xi)a&=\eta a+\xi a
\end{align}
\end{subequations}
for all $\eta,\xi\in\modE$ and $a$, $b\in\cA$. Let $\modE$ and $\modF$ be two right $\cA$-module. A \defe{morphism}{morphism!of right module} of $\modE$ on $\modF$ if a $\cA$-linear map $\rho\colon \modE\to \modF$ which fulfils $\rho(\eta a)=\rho(\eta)a$ for all $a\in\cA$ and $\eta\in\modE$. When $\modE$ is a right $\cA$-module, we have a left $\cA^0$-module $\modE^0$ defined by $a^0\eta a$. 

Let $\cA$ and $\cB$ be two algebras; the vector space $\modE$ is a $\cA$-$\cB$-\defe{bimodule}{bimodule} if $\modE$ is a left $\cA$-module, a right $\cB$-module and if the two actions commute: $(a\xi)b=a(\xi b)$ for every $\xi\in\modE$, $a\in\cA$ and $b\in cB$.

The algebra $\cA^e:=\cA\otimes_{\eC}\cA^0$\nomenclature{$\cA^e$}{Enveloping algebra} is the \defe{enveloping algebra}{enveloping algebra} of $\cA$. A $\cA$-bimodule can be seen as a right $\cA^e$-module with definition $\eta(a\otimes b^0)=b\eta a$.

Let $\Gamma$ be a directed set; a family $(e_t)_{t\in \Gamma}$ is \defe{generating}{generating family of a module} for the right module $\modE$ if any element of $\modE$ can be written under the form $\sum_{t\in \Gamma}e_ta_t$ with $a_t\in\cA$ with only a finite non zero terms in the sum. The family $(e_t)$ is \defe{free}{free!family in a module} if it is made of $\cA$-linearly independent elements. A family is a \defe{basis}{basis!of a module} when it is both free and generating. A module is of \defe{finite type}{module!finite type}\index{finite type module} if it possesses a generating family of finite cardinality. Notice that the decomposition is in general not unique.

Let us now consider the set $\cA^N=\eC^N\otimes_{\eC}\cA$\nomenclature[A]{$\cA^N=\eC^N\otimes_{\eC}\cA$}{A complex module over $\cA$}. An element of this space can be written under the form 
\[ 
  \eta=
\begin{pmatrix}
\eta_1\\\vdots\\\eta_N
\end{pmatrix}
\]
with $\eta_i\in\cA$. A module structure on $\cA^N$ is given by the map $(\eC^N\otimes_{\eC}\cA)\times\cA\to \eC^N\otimes_{\eC}\cA$,
\[ 
  \begin{pmatrix}
\eta_1\\\vdots\\\eta_n
\end{pmatrix}a=
\begin{pmatrix}
\eta_1 a\\\vdots\\\eta_N a
\end{pmatrix}.
\]
A basis of this module can be identified with the canonical basis of $\eC^N$ because
\[ 
  \begin{pmatrix}
\eta_1\\\vdots\\\eta_N
\end{pmatrix}=\eta_1
\begin{pmatrix}
1\\\vdots\\0
\end{pmatrix}+\ldots+
\eta_N\begin{pmatrix}
0\\\vdots\\1
\end{pmatrix}.
\]
Hence the module $\cA^N$ is free and of finite type. The inclusion map (inverse of $p$ in a certain sense) $\lambda\colon \modE\to \eC^N\otimes_{\eC}\cA$\label{PgdeflambdaMod} will also be sometimes used. A general element of $\cA^N$ reads $\sum_{j=1}^{N}e_j\otimes_{\eC}a_j$ where $a_j\in\cA$ and $\{ e_j \}$ is the canonical basis of $\eC^N$. If we pose $f_i=e_i\otimes_{\eC}1$, every element of $\cA^{N}$ is $\sum_{j}j_ja_j$, so that $\cA^N$ is a finitely generated module.


Since $p$ is a module homomorphism,
\[ 
  p\big( \sum_{j}f_ja_j \big)=\sum_j p(f_j)a_j
\]
with $f_j\in\cA^N$ and $a_j\in\cA$. We deduce that $\{ p(f_j) \}$ is a basis of the finitely generated module $p\cA^N$.

If $\modE$ is a $\cA$-bimodule, the \defe{center}{center!of a bimodule} of $\modE$ is the set
\begin{equation}
\mZ(\modE)=\{ \xi\in\modE\tq a\xi=\xi a,\;\forall a\in\cA,\,\xi\in\modE \}.
\end{equation}

\begin{proposition}
If we define the maps
\begin{equation}
\begin{aligned}
 j\colon \modE\otimes_{\cA}\Omega^1\cA&\to \modE\otimes_{\eC}\cA \\ 
   \xi\otimes_{\cA}\delta a&\mapsto \xi\otimes_{\eC}a-\xi a\otimes_{\eC}1 
\end{aligned}
\end{equation}
and
\begin{equation}
\begin{aligned}
 m\colon \modE\otimes_{\eC}\cA&\to \modE \\ 
   \xi\otimes_{\eC}&\mapsto \xi a, 
\end{aligned}
\end{equation}
the sequence
\[ 
\xymatrix{%
   0 \ar[r]		&	\modE\otimes_{\cA}\Omega^1\ar[r]^-j	&  \modE\otimes_{\eC}\cA\ar[r]^-m	&\modE\ar[r]	&0
}
\]
is exact
\end{proposition}

\begin{proof}
An element in the kernel of $m$ has the form $\xi\otimes_{\eC}ba-\xi b\otimes_{\eC}a$ which is the image by $j$ of $\xi\otimes_{\cA}(\delta b)a$. Indeed
\begin{align*}
j\big( \xi\otimes_{\cA}(\delta b)a \big)	&=j\big( \xi\otimes_{\cA}\delta(ba)-\xi\otimes_{\cA}b\delta a \big)\\
						&=\xi\otimes_{\eC}ba-\xi ba\otimes_{\eC}A-\xi b\otimes_{\eC}a+\xi ba\otimes_{\eC}1\\
						&=\xi_{\eC}ba-\xi b\otimes_{\eC} a.
\end{align*}
\end{proof}

\subsection{Endomorphism}
%------------------------

Let us prove that an endomorphism $A\in\End_{\cA}(\modE)$ is identified with a matrix $A\in\eM_{N\times N}(\cA)$ such that $A=Ap=pA=pAp$. The action of $A$ must satisfy
\[ 
  A\big( \sum_ip(f_i)a_i \big)=\sum_iA\big( p(f_i) \big)a_i,
\]
so that $A$ acts on the generating part $\{ p(f_i) \}$ of $\modE$. We pose 
\begin{equation}
  Ap(f_i)=\sum_kp(f_i)A_{ik}
\end{equation}
for some $A_{ik}\in\cA$. So we have
\begin{align*}
  Ap\big( \sum_ie_i\otimes_{\eC}a_i \big)&=\sum_i\sum_kp(f_i)A_{ik}a_i
				=\sum_ip(f_i)\sum_kA_{ik}a_i
				=p\Big( \sum_ie_i\otimes_{\eC}\big( \sum_kA_{ik}a_i \big) \Big).
\end{align*}
Using the notation $\xi=p\big( \sum_ie_i\otimes_{\eC}\xi^i \big)$ we have
\begin{equation}
A\xi=p\Big( \sum_ie_i\otimes_{\eC}(A\xi)_i \Big),
\end{equation}
that we note $pA\xi$ by abuse of notation. For the same reason of notations, the equation $\xi=p\big( \sum_ie_i\otimes_{\eC}\xi^i \big)$ is denoted by $\xi=p\xi$, thus we have
\[ 
  A=Ap=pA,
\]
where $A$ and $p$ have different meaning.


\subsection{Dimension of a module} \label{subsec_DimofModule}
%---------------------------------

There exists some free modules which admit several basis of different cardinality; for them, there are no way to define the notion of dimension. For a free module whose all basis have same cardinality, the latter is the \defe{dimension}{dimension!of a free module} of the module.

If $\modE$ is a module of finite type, there exists an integer $N$ and a surjective map $\rho\colon \cA^N\to \modE$. Indeed, the fact the $\modE$ is of finite type gives a generating part $\{ e_1,\ldots,e_N \}$. Then the definition
\[ 
  \rho
\begin{pmatrix}
a_1\\\vdots\\ a_N
\end{pmatrix}
=
\sum_{i=1}^N e_ia_i
\]
works. In general, it is not possible to extract a free part of this generating part. Let us see an example. Consider $ C^{\infty}(S^2)$, the algebra of smooth functions on the sphere and the Lie algebra $\cvec(S^2)$. The latter is a module of finite type on $ C^{\infty}(S^2)$ and a generating part is given by the three following vector fields :
\[ 
  Y_i(x)=\sum_{j,k=1}^3 \epsilon_{ijk}x_j\partial_k.
\]
These vectors are tangent vectors because scalar product $Y_i(x)\cdot x$ vanishes :
\[ 
  Y_i\cdot x =\sum_l (Y_i)_lx_l=\sum_{l,j}\epsilon_{ijl} x_jx_l=0.
\]
In order to prove that this set is generating, let us suppose that $Y_1$ is proportional to $Y_2$ and $Y_3$. If we impose $bY_3=Y_1$, we find, for each $k$ :
\[ 
  \epsilon_{1jk} x_j\partial_k=b\epsilon_{3jk}\partial_k,
\]
taking $k=1$, we find $x_2=0$. The same with $Y_1=aY_2$ leads to $x_3=0$. So the only candidate point where the set of $Y_i$ can fail to be generating is $x_1=\pm 1$, $x_2=x_3=0$. At this point, $Y_2=\pm\partial_3$ and $Y_3=\pm\partial_2$ whose are linearly independent. Hence the set of $Y_j$ is a generating part. It is not a free part (with respect to $ C^{\infty}(S^2)$) because
\[ 
  \sum_{j=1}^3 x_jY_j=0.
\]
We can however not find two vector fields $X_1$ and $X_2$ which form a global basis of $\cvec{S^2}$ because we would have $X_1-X_2\neq0$ everywhere on $S^2$.

\subsection{Tensor product of modules (first)}
%-------------------------------------

Let $\modE_1,\ldots,\modE_n$, and $\modF$, some modules on $\eC$. We denote by $L^n(\modE_1,\ldots,\modE_n;\modF)$ the module of $n$-multi-linear maps $f\colon \modE_1\times\ldots\times\modE_n\to \modF$. Let $\modM$ the free module generated by $n$-uples $(x_1,\ldots,x_n)$, $x_i\in\modE_i$; we denote by $\modN$ the submodule generated by elements of the form
\begin{subequations}
\begin{align}
(x_1,\ldots,x_i+x'_i,\ldots,x_n)&+(x_1,\ldots,x_i,\ldots,x_n)-(x_1,\ldots,x'_i,\ldots,x_n)\\
(x_1,\ldots,zx_i,\ldots,x_n)&-z(x_1,\ldots,x_n)
\end{align}
\end{subequations}
for all $x_i,x'_i\in\modE_i$ and $z\in\eC$.

We have a canonical injection $\modE_1\times\ldots\times\modE_n\to\modM$ and $\modM\to\modM/\modN$. We denote by $\varphi\colon \modE_1\times\ldots\times\modE_n\to \modM/\modN$ the composition of these two. This $\varphi$ is the \defe{tensor product}{tensor product!of modules} $\modE_1\otimes\ldots\otimes\modE_n$, and we write
\[ 
  \xi_1\otimes_{\eC}\xi_2=\varphi(\xi_1,\xi_2).
\]
The tensor product has an universal property.

\begin{proposition}
If $f\colon \modE_1\times\ldots\times\modE_n\to G$ is a $n$-multi-linear, there exists a map $f_*\colon \modM/\modN\to G$ such that the following diagram commutes :
\begin{equation}
\xymatrix{%
   \modE_1\times\ldots\times\modE_n \ar[r]^-{\varphi}\ar[dr]_{f}		&\modM/\modN\ar@{.>}[d]^{f_*}\\
   									&	G
}
\end{equation}
\end{proposition}

\begin{proof}
It is first clear that there exists a $f'\colon \modM\to G$ such that $i\circ f'=f$. This map takes the value $0$ on $\modN$ because $i^{-1}(\modN)=0$. So $f'$ can be factorised by $\modN$ to give $f_*$.
\end{proof}

\subsection{Tensor product of module (second)}
%---------------------------------------------

Let $\modE_1$ and $\modE_2$ be two $\cA$-bimodule. We consider $\modM$, the free $\cA$-bimodule generated by $\modE_1\times\modE_2$, i.e. the set of (formal) linear combinations of elements of the form
\[ 
  a(\xi_1,\xi_2)\text{ and }(\xi_1,\xi_2)a
\]
with $xi_i\in\mA$ and $a\in\mA$. We define the sub-module $\modN$ generated by elements of the form
\begin{subequations}
\begin{align}
i(\xi_1+\eta_1,\xi_2+\eta_2)-i(\xi_1,\xi_2)-i(\xi_1,\eta_2)-i(\eta_1,\xi_2)-i(\eta_1,\eta_2)\\
ai(\xi_1,\xi_2)\\
ai(\xi_1,\xi_2)-i(a\xi_1,\xi_2)\\
ai(\xi_1,\xi_2)-i(\xi_1,a\xi_2)\\
i(\xi_1,\xi_2)a-i(\xi_1,\xi_2a)\\
i(\xi_1,\xi_2)a-i(\xi_1a,\xi_2).
\end{align}
\end{subequations}
We define $\varphi\colon \modE_1\times\modE_2\to \modM/\modN$ as 
\[ 
  \varphi=\pi\circ i
\]
where $i$ is the inclusion of $\modE_1\times\modE_2$ in $\modM$. The definition $\xi_1\otimes_{\cA}\xi_2=\varphi(\xi_1,\xi_2)$ has an universal property.

\begin{proposition}
Let $G$ be a $\cA$-bimodule and a $\cA$-linear map $f\colon \modE_1\times\modE_2\to G$. Then there exists one and only one $\cA$-linear map $f_*\colon \modM/\modN\to G$ such that the diagram
\begin{equation}  \label{eq_diagprodtensunif}
\xymatrix{%
   \modE_1\times\modE_2 \ar[r]^-{\varphi}\ar[dr]_{f}		&	\modM/\modN\ar@{.>}[d]^{f_*}\\
   	&	G
}
\end{equation}
is commutative.
\end{proposition}

\begin{proof}
We first consider a map $f'\colon \modM\to G$ such that $f'\circ i=f$. From $\cA$-linearity of $f'$, we conclude that
\[ 
 \begin{split}
f'\big( ai(\xi_A,\xi_2)-i(a\xi_1,\xi_2) \big)&=a(f'\circ i)(\xi_1,\xi_2)-(f'\circ i)(a\xi_1,\xi_2)\\
		&=af(\xi_2,\xi_2)-f(a\xi_2,\xi_2)\\
		&=0.
\end{split} 
\]
So $f'(\modN)=0$, and we can consider the quotient map $f_*=f'/\modN$ which gives commutativity of diagram \eqref{eq_diagprodtensunif}. We still have to prove the unicity part. Let $g_*\colon \modM/\modN\to G$ be an other map which has the same commutativity property that $f_*$ :
\[ 
  f=f_*\circ \varphi=g_*\circ\varphi
\]
and $f_*(\modN)=g_*(\modN)=0$. A general element in $\modM/\modN$ has the form (of linear combination of) $\varphi(\xi_1,\xi_2)$, so we following computation concludes the proof :
\[ 
  f_*\varphi(\xi_1,\xi_2)-g_*\varphi(\xi_1,\xi_2)=f(\xi_1,\xi_2)-f(\xi_2,\xi_2)=0.
\]
\end{proof}

\subsection{Tensor product of modules (third)}
%---------------------------------------------

This definition of tensor mainly product comes from \cite{Jacobson_alg}.

We suppose the algebra $\cA$ to be unital and associative, so it is a ring. Note that $\eC$ is a ring too; so we will in the same time define $\otimes_{\eC}$ and $\otimes_{\cA}$. Let $\modE$ be a right $\cA$-module and $\modF$ a left $\cA$-module on the ring $R$, in particular, recall that $\modE$ and $\modF$ are vector spaces on $\eC$. For $\eta\in\modE$, $\xi\in\modF$, and $a\in R$, we have maps
\begin{equation}
\begin{aligned}
 \modE\times R&\to \modE \\ 
(\eta,a)&\mapsto \eta a, 
\end{aligned}
\end{equation} 
and
\begin{equation}
\begin{aligned}
 R\times\modF&\to \modF \\ 
(a,\xi)&\mapsto a\xi. 
\end{aligned}
\end{equation}

A \defe{balanced product}{balanced product} of $\modE$ and $\modF$ is an abelian group $(P,+)$ with a map $f\colon \modE\times\modF\to P$ such that 
\begin{subequations}
\begin{align}
  f(\eta+\eta')&=f(\eta,\xi)+f(\eta',\xi)\\
f(\eta,\xi+\xi')&=f(\eta,\xi)+f(\eta,\xi')\\
f(\eta a,\xi)&=f(\eta,a\xi).
\end{align}
\end{subequations}
This balanced product is denoted by $(P,f)$. The function $f$ must fulfil
\[ 
  f(0,\xi)=0=f(\eta,0)
\]
because $f(0,\xi)=f(0+0,\xi)=f(0,\xi)+f(0\xi)$. The same kind of reason leads to
\[ 
  f(-\eta,\xi)=-f(\eta,\xi)
\]
where the minus sign in the right hand side is in the sense of the inverse in the additive group $(P,+)$.

When $(P,f)$ and $(P,g)$ are two balanced products, a \defe{morphism}{morphism!of balanced product} is a group homomorphism $\varphi\colon P\to Q$ such that
\[ 
  g(\eta,\xi)=\varphi\big( f(\eta,\xi) \big).
\]

\begin{definition}
A \defe{tensor product}{tensor product!of modules} of $\modE$ and $\modF$ is a balanced product $(A,\otimes_R)$ such that for each balanced product $(P,f)$, there exists an unique morphism $(A,\otimes_R)\to(P,f)$ such that
\[ 
  \otimes_R(\eta,\xi)=f(\eta,\xi).
\]

\end{definition}
The element $\otimes_R(\eta,\xi)$ is often denoted by $\eta\otimes_R\xi$.

Unicity of tensor product is given by the following proposition.

\begin{proposition}
Let $(A,\otimes_1)$ and $(B,\otimes_2)$ be two tensor products of $\modE$ and $\modF$. There exists an unique isomorphism $\varphi\colon A\to B$ such that
\[ 
  \varphi\big( \otimes_1(\eta,\xi) \big)=\otimes_2(\eta,\xi).
\]

\end{proposition}

\begin{proof}
Since $(A,\otimes_1)$ is a tensor product and $(B,\otimes_2)$ is a balanced product, there exists an unique morphism $\varphi\colon (A,\otimes_1)\to (B,\otimes_2)$ such that
\[ 
  \varphi(\eta\otimes_1\xi)=\eta\otimes_2\xi.
\]
We have to prove that this morphism is an isomorphism. There also exists an unique morphism $\phi\colon (B,\otimes_2)\to (A,\otimes_1)$ such that
\[ 
  \phi(\eta\otimes_2\xi)=\eta\otimes_1\xi.
\]
Then
\[ 
   (\varphi\circ\phi)(\eta\otimes_2\xi)=\varphi(\eta\otimes_1\xi)=\eta\otimes_2\xi  
\]
and $\varphi$ is the inverse of $\phi$.
\end{proof}

\begin{proposition}
If $(A,\otimes)$ is a tensor product of $\modE$ and $\modF$, then the group $A$ is generated by products $\eta\otimes\xi$.
\end{proposition}

\begin{proof}
Let us suppose the existence of $\omega\in A$ which cannot be written under the form $\sum_i\eta_i\otimes\xi_i$. If $(P,f)$ is a balanced product, a morphism $\varphi\colon A\to P$ is not completely defined by the requirement $\varphi(\eta\otimes\xi)=f(\eta,\xi)$ because $\varphi(\omega)$ can take any value in $A$.

\end{proof} 

\subsection{Explicit building of tensor product}
%------------------------------------------------

We will now explicitly build a tensor product $\modE\otimes_R\modF$ that will be named \emph{the} tensor product. First we consider the abelian free group $M$ of basis $\modE\times\modF$, i.e. the set of formal sums
\[ 
  n_1(\eta_1,\xi_1)+\ldots+n_r(\eta_r,\xi_r)
\]
with $n_i\in\eZ$, $\eta_i\in\modE$ and $\xi_i\in\modF$. We put the usual addition and if $(\eta_i,\xi_i)\neq(\eta_j,\xi_j)$ for all $i\neq j$, this sum is zero only if $n_i=0$ for all $i$. In $M$, we consider the subgroup $N$ generated by
\begin{subequations}
\begin{align}
(\eta+\eta',\xi)&-(\eta,\xi)-(\eta',\xi)\\
(\eta,\xi+\xi')&-(\eta,\xi)-(\eta,\xi')\\
(\eta a,\xi)&-(\eta, a\xi)
\end{align}
\end{subequations}
with $\eta,\eta'\in\modE$, $\xi,\xi'\in\modF$ and $a\in R$. Now we define 
\begin{equation}
\modE\otimes_R\modF=M/N
\end{equation}
and 
\begin{equation}
\eta\otimes_R\xi=[(\eta,\xi)].
\end{equation}

\begin{proposition}
The group $(\modE\otimes_R\modF,\otimes_R)$ is a tensor product.
\end{proposition}

\begin{proof}
We begin by proving that $(\modE\otimes_R\modF,\otimes_R)$ is a balanced product. From definition of the equivalence defining the class $[(\eta,\xi)]$, we have
\[ 
 \begin{split}
  \otimes_R(\eta+\eta',\xi)&=\otimes_R(\eta,\xi)-\otimes_R(\eta',\xi)\\
		&=[(\eta+\eta',\xi)]-[(\eta,\xi)]-[(\eta',\xi)]\\
		&=[0].
\end{split} 
\]
and 
\[ 
  \otimes_R(\eta a,\xi)=[(\eta a,\xi)]=[(\eta,a\xi)]=\otimes_R(\eta, a\xi).
\]

Now let $(P,f)$ be a balanced product. Since $M$ is generated by elements of the form $(\eta,\xi)$, the prescription
\begin{equation}
\begin{aligned}
 \varphi\colon M&\to M \\ 
(\eta,\xi)&\mapsto f(\eta,\xi) 
\end{aligned}
\end{equation} 
completely defines $\varphi$. Now we try to defines something on $M/N$ from this $\varphi$. Let $K$ be the kernel of $\varphi$. Elements of the form
\[ 
 \begin{split}
(\eta+\eta',\xi)&-(\eta,\xi)-(\eta',\xi)\\
(\eta,\xi+\xi')&-(\eta,\xi)-(\eta,\xi')\\
(\eta,a,\xi)&-(\eta, a\xi)
\end{split} 
\]
belongs to $K$. Then $N\subset K$ and one has a well defined morphism 
\begin{equation}
\begin{aligned}
 M/N&\to P \\ 
[(\eta,\xi)]&\mapsto f(\eta,\xi).
\end{aligned}
\end{equation}
Uniqueness comes from the fact that elements of the form $[(\eta,\xi)]$ are generating $M/N$.

\end{proof}





\subsection{Unitary group}		\label{SubsecUnitGroup}
%-------------------------

Let $\modE=p\cA^N$ be an Hermitian finite projective module. The algebra of \defe{endomorphism}{endomorphism!of module} is\nomenclature[A]{$\End_{\cA}(\modE)$}{Algebra of endomorphism of the module $\modE$}
\[ 
  \End_{\cA}(\modE)=\{ T\colon \modE\to \modE\tq T(\eta a)=T(\eta)a \}.
\]
We naturally define the involution $*\colon \End_{\cA}(\modE)\to \End_{\cA}(\modE)$ defined by
\begin{equation}
\langle T^*\eta, \xi\rangle =\langle \eta, T\xi\rangle
\end{equation}
If $A\in\eM_{N\times N}(\cA)$ is an endomorphism of $\modE$, in particular for each $\xi\in\modE$, the element $A\xi$ must belongs to $\modE$, so that $pA\xi=A\xi$. That proves that $pA=A$. Since $\xi=p\xi$, we have moreover $pAp=Ap$. Finally
\[ 
  A=Ap=pA=pAp.
\]
So we have an isomorphism $\End_{\cA}(\modE)\simeq p\eM_{N\times N}(\cA)p$. An endomorphism $u$ is \defe{unitary}{unitary!endomorphism of module} if $u^*u=uu^*=1$. We denote by $U(\modE)$\nomenclature[A]{$U(\modE)$}{Space of unitary endomorphism of the module $\modE$} the space of unitary endomorphism of $\modE$.

As an example, let us take $M$, a differentiable manifold and $ C^{\infty}(M)$, the algebra of smooth functions over $M$. We want to study $U_N\big(  C^{\infty}(M) \big)=U\big(  C^{\infty}(M)^N \big)$. An element of that algebra is a $N\times N$ matrix whose entries are functions on $M$ or, equivalently, a function $u\colon M\to \eM_{N\times N}(\eC)$. The $1$ in the unitary condition $u^*u=uu^*=1$ has to be understood as the function on $M$ with $\mtu$ as constant value. So we have the isomorphism
\[ 
  U_N\big(  C^{\infty}(M) \big)\simeq C^{\infty}\big( M,U(N) \big)
\]
where $U(N)$ is the usual unitary group.


%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
					\section{Module over unital ring}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\label{SecModUnitalAnneau}

\begin{probleme}
This section is a mess. Several propositions have to be merged. We have to check that everything said in the algebra case hold in the ring case, and then change algebra to ring everywhere. The module over algebra part mainly comes from \cite{Landi}.
\end{probleme}

\subsection{Projective module of finite type on unital algebra}
%--------------------------------------------------------------

Let $\cA$ be an unital algebra.

\begin{proposition}		\label{PropEquivProjModule}
Let $\modE$ be a right $\cA$-module where $\cA$ is an unital algebra. The three following are equivalent:
\begin{enumerate}
\item If $\rho\colon \modF_1\to \modF_2$ is surjective homomorphism of right $\cA$-module, then every homomorphism $\lambda\colon \modE\to \modF_2$ can be lifted into a homomorphism $\tilde\lambda\colon \modE\to \modF_1$ which satisfies $\rho\circ\tilde\lambda=\lambda$. 
\begin{equation}  \label{eq_diag_proj_mod}
\xymatrix{%
            &\modF_1\ar@{>>}[d]^{\rho}\\
\modE \ar@{.>}[ur]^{\tilde\lambda}\ar[r]_{\lambda} &\modF_2
}
\end{equation}
That property is the \defe{lifting property}{lifting property!projective module}.

\item\label{ItemTroisCarecterisationProjectif} If $\rho\colon\modF_1\to \modE$ is a surjective morphism of module, there exists a module morphism $s\colon \modE\to \modF_1$ such that $\rho\circ s=\id|_{\modE}$. 
\[ 
    \xymatrix{ \modF_1 \ar[r]^{\rho} & \modE \ar@/^/@{.>}[l]^s }
\]

\item \label{prop_def_proj_module_iii}  There exists a free module $\modF$ which decomposes as a direct sum which one component is $\modE$:
\[ 
  \modF=\modE\oplus\modE'.
\]
In this case, $\modE'$ is also free.

\end{enumerate}
\label{prop_def_proj_module}
\end{proposition}

\begin{proof}
For a proof, see \cite{Landi} at page $59$.
\end{proof}

A right module which fulfils these properties is said to be \defe{projective}{projective!module}\index{module!projective}.

\subsection{Projective module of finite type on unital ring}
%------------------------------------------------------------

%
%	En termes de notations pour les modules, M devient \modE et N devient \modF.
%

Let $R$ be an unital ring, and $\modE$, $\modF$, \ldots be left modules over $R$. One says that $\modE$ is a \defe{projective module}{projective!module} if for every surjective module homomorphism $\lambda\colon \modF_2\to \modF_1$, there exists a lifting map $\tilde\lambda\colon \modE\to \modF_2$ such that the following diagram commutes:
\begin{equation}		\label{EqLiftPropProjModules}
\xymatrix{%
 					&  \modF_2 \ar@{->>}[d]^{\displaystyle\lambda}\\
   \modE \ar[r]\ar@{.>}[ru]^{\displaystyle\tilde\lambda}			&	\modF_1
}
\end{equation}
where the double arrow denotes the surjectivity. 

\begin{proposition}		\label{PropFGPRkP}
Every finitely generated projective module over the unital ring $R$ has the form 
\[ 
R^kP
\]
for some $k\in\eN$ and some idempotent matrix $P\in\eM_k(R)$. The choices of $k$ and $P$ are not unique.
\end{proposition}

\begin{proof}
We suppose that $\modE$ is projective and finitely generated by $\{ \xi_1,\ldots,\xi_k\}$. A module map $T\colon R^k\to R^k$ is given by a matrix $r$ defined by
\[ 
	T(0,\ldots,1,\ldots,0)=(r_{1j},\ldots,r_{kj})
\]
where, in the left hand side, the $1$ is on the $j$th position, and $T$ is the right matrix multiplication
\begin{equation}
	T(a_1,\ldots,a_k)=
\begin{pmatrix}
a_1&\ldots&a_k
\end{pmatrix}
\begin{pmatrix}
r_{11}	&	r_{21}	&\ldots	&r_{k1}\\
r_{12}	&	r_{22}	&\ldots	&r_{k2}\\
\vdots	&	\vdots	&	&\vdots\\
r_{k1}	&	r_{k2}	&\ldots	&r_{kk}
\end{pmatrix}.
\end{equation}

Item \ref{ItemTroisCarecterisationProjectif} of proposition \ref{PropEquivProjModule} assures the existence of a direct sum decomposition $R^k=\modE\oplus \modF$ of submodules of $R^k$, then, associated with the projection onto $\modE$, there is an idempotent matrix $P\in\eM_k(R)$ such that 
\begin{equation}		\label{EqMRkPdec}
	\modE\simeq R^kP.
\end{equation}
\end{proof}

The following proposition shows that every finitely generated projective module over $R$ come from that construction.
\begin{proposition}
A module $\modE$ is projective of finite type on $\cA$ if and only if there exists a matrix $p\in \eM_{N\times N}(\cA)$ such that
\begin{enumerate}
\item $p$ is idempotent: $p^2=p$,
\item $\modE=p\cA^N$.
\end{enumerate}

\end{proposition}

\begin{proof}

Since $\modE$ is projective as well as of finite type, we have a surjective map $\rho\colon \cA^N\to \modE$. Let us draw the diagram \eqref{eq_diag_proj_mod} in the particular case with $\modF_1=\cA^N$ and $\modF_2=\modE$: 
\begin{equation}
\xymatrix{%
						   		&	\cA^N\ar[d]^{\rho}\\
   \modE \ar[r]_{\lambda=\id}\ar@{.>}[ru]^{\tilde\lambda}	&	\modE
}
\end{equation}
Hence we have a map $\tilde\lambda\colon \modE\to \cA^N$ such that $\rho\circ\tilde\lambda=\id|_{\modE}$. The map $p=\tilde\lambda\circ\rho\colon \cA^N\to \cA^N$ fulfils $p^2=\id|_{\modE}$ and is therefore idempotent in $\End(\cA^N)$. It allows us to decompose $\cA^N$ as a sum of submodules
\[ 
  \cA^N=p\cA^N+(1-p)\cA^N.
\]
We know that $\rho$ and $\tilde\lambda$ are two isomorphism between $\modE$ and $p\cA^N$. We now prove that $\rho$ is bijective on $p\cA^N$. Surjectivity is clear; we have to prove that $\rho\colon p\cA^N\to \modE$ is injective. Let $\rho(pa)=\rho(pb)$ and apply $\tilde\lambda$ on both sides of this equality. Since $\tilde\lambda\rho=p$, we find $p^2a=p^2b$, en therefore $pa=pb$. Remark that this does not imply $a=b$.

For the inverse sense, we suppose a module $\modE$ on $\cA$ and a map $p\in M_{N\times N}(\cA)$ such that $p^2=p$ and $\modE=p\cA^N$. The module $\modE$ fulfils point \ref{prop_def_proj_module_iii} of proposition \ref{prop_def_proj_module} with
\[ 
  \cA^N=p\cA^N\oplus(1-p)\cA^N.
\]  
The fact that $\modE$ is of finite type is clear because $\cA^N$ is such.

\end{proof}
An element of $\modE$ can be seen as a $p$-invariant column vector with entry in $\cA$:
\[ 
  \xi=
\begin{pmatrix}
\xi_1\\\vdots\\\xi_N
\end{pmatrix}
\]
with $\xi_i\in\cA$ and $p\xi=\xi$. Remark that it does \emph{not} mean that $p\xi_i=\xi_i$ for each $i$: such a condition is in fact senseless.

A beautiful result that provides a concrete realisation of projective finite module is the following.

\begin{theorem}[Serre-Swan]
Let $M$ be a compact finite dimensional manifold. A $C^{\infty}(M)$-module $\modE$ is isomorphic to the space of sections $\Gamma(M,E)$ of a vector bundle $E\to M$ if and only if it is finite and projective.

In other words, to any projective finite module, we can associate a vector bundle whose sections give $\modE$.
\end{theorem}

\begin{proof}
No proof
\end{proof}

\begin{lemma}		\label{LemRklQkR}
If $R^kP\simeq \modE\simeq R^lQ$, then there are matrices $U\in\eM_{k\times l}(R)$ and $V\in\eM_{l\times k}(R)$ such that $UV=P$ and $VU=Q$.
\end{lemma}
\begin{proof}
No proof.
\end{proof}
This lemma says that if we perform two times the constructions which lead to decomposition \eqref{EqMRkPdec} with different choices, then the two results are in a certain sense equivalent.

Let $E\subseteq F$ be a $R$-submodule. The \defe{closure}{closure!of a submodule} of $E$ in $F$, denoted by $\Cl_F(E)$\nomenclature[A]{$\Cl_F(E)$}{Closure of the submodule $E$ in $F$}, or $\bar E$ when there are no confusion, is
\begin{equation}
	\Cl_F(E)=\{ f\in F\tq \varphi(f)=0,\,\forall \text{ module map }\varphi\colon F\to R\text{ such that }\varphi|_E=0 \}.
\end{equation}
We are not interested in the topology on $F$ that this definition provides.

The lemmas \ref{LemEprojEEEfproj} and \ref{LemFGenEEEsingleGen} will help to reduce numerous problems to singly generated modules.
\begin{lemma}		\label{LemEprojEEEfproj}
If $E$ is a finite projective module over $R$, then $E\oplus\ldots\oplus E$ is a finite projective module over $\eM_n(R)$. 

If $F$ is a submodule of $E$, then
\[ 
	\Cl_{E\oplus\ldots\oplus E}(F\oplus\ldots\oplus F)=\Cl_E(F)\oplus\ldots\oplus\Cl_E(F).
\]

\end{lemma}
\begin{proof}
No proof.
\end{proof}

\begin{lemma}		\label{LemFGenEEEsingleGen}
If $E$ is generated by $\{ e_1,\ldots, e_n \}$, then $E\oplus\ldots\oplus E$ is generated over $\eM_n(R)$ by the single element $(e_1,\ldots,e_n)$.
\end{lemma}
\begin{proof}
No proof.
\end{proof}


Now we suppose that we have a trace map $\varphi\colon R\to \eA$ where $\eA$ is a commutative ring (or any abelian group). If $S$ is a square matrix of elements in $R$, we define
\begin{equation}
	\varphi(S)=\sum_i\varphi(S_{ii}),
\end{equation}
and one checks that $\varphi(ST)=\varphi(TS)$, so that $\varphi$ is a trace over $\eM_k(R)$ for every $k$. Now, we define 
\begin{equation}			\label{EqPreDefDimModuleRA}
	\varphi(\modE)=\varphi(P)		
\end{equation}
where $P$ is defined by the condition $\modE=R^kP$. Lemma \ref{LemRklQkR} assures that this condition does not depend on the choice. 

\begin{definition}  \label{DefHDhfMGJ}
    The \defe{dimension function}{dimension!function} associated with the trace $\varphi$ is
    \begin{equation}\label{DefDimFunctModule}
    \begin{aligned}
        \dim_{\varphi}\colon \{ \text{isomorphism class of finitely generated projective modules} \} &\to \eA\\
        \modE&\mapsto \varphi(\modE).
    \end{aligned}
    \end{equation}
\end{definition}

\begin{lemma}
    It fulfills the condition
    \begin{equation}
        \dim_{\varphi}(\modE\oplus \modF)=\dim_{\varphi}(\modE)+\dim_{\varphi}(\modF).
    \end{equation}
\end{lemma}
We will show in section \ref{SecOverModVNalgDim} that the construction of the dimension function \eqref{DefDimFunctModule} extends to all modules over von~Neumann algebras. 

\begin{lemma}
If $H_1$ and $H_2$ are modules over the ring $R$, they are isomorphic if and only if $H_1\oplus\ldots\oplus H_1\simeq H_2\oplus\ldots\oplus H_2$ as module over $\eM_n(R)$.
\end{lemma}


%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Bialgebras and co-properties}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Bialgebras}
%---------------------------------------------------------------------------------------------------------------------------
Some generalities about bialgebras are taken from \cite{TimmernannInvitation}.

Let $\cA$ be an unital algebra and $r\in\cA\times\cA$. There exists a (non unique) decomposition $r=\sum_i\alpha_i\otimes\beta_i$ with $\alpha_i$, $\beta_i\in\cA$. There exists three ways to extend that in order to embed $r$ in $\cA\otimes\cA\otimes\cA$. We introduce the \defe{Sweedler notation}{sweedler notation} in order to distinguish them:
\begin{align*}
r_{12}&=\sum_i\alpha_i\otimes\beta_i\otimes 1\\
r_{13}&=\sum_i\alpha_i\otimes 1\otimes\beta_i\\
r_{23}&=\sum_i1\otimes\alpha_i\otimes\beta_i.
\end{align*}
One can define $r_{ij}$ in the same way in $\cA^{\otimes n}$. We denote by $\tau\colon \cA\otimes\cA\to \cA\otimes\cA$,
\[ 
  \tau(a\otimes b)=b\otimes a.
\]

If we denote by $\mu\colon \cA\otimes\cA\to \cA$ the algebra law in $\cA$, the unit $1$ defines (and is defined by) the map
\begin{equation}
\begin{aligned}
 \eta\colon \eK&\to \cA \\ 
   \eta(z)&= z1.
\end{aligned}
\end{equation}
The fact that $1$ is an unit is expressed by the equalities $1a=a1=a$ for all $a\in\cA$, or equivalently by the commutativity of the diagrams
\begin{align}		\label{EqDiagUnitHopf}
	\xymatrix{%
	\eK\otimes\cA \ar[r]^{\eta\otimes\id}\ar[rd]_{\psi}		&	\cA\otimes\cA\ar[d]^{\mu}\\
	   	&	\cA
	   }
&&
	\xymatrix{%
	\cA\otimes\eK \ar[r]^{\id\otimes\eta}\ar[rd]_{\psi}		&	\cA\otimes\cA\ar[d]^{\mu}\\
	   	&	\cA
	   }
\end{align}
where we indifferently denoted by $\psi$ the identification $\psi(z\otimes a)=za$ and $\psi(a)=1\otimes a$.

So an algebra can be defined as a vector space endowed with operations $\mu$ and $\eta$ such that the latter two diagrams commute. One define a \defe{coalgebra}{coalgebra} taking the dual of that construction. So a coalgebra is a vector space $\cA$ endowed with two linear maps
\begin{align*}
\epsilon&\colon \cA\to \eK,\\
\Delta&\colon \cA\to \cA\otimes_{\eK}\cA
\end{align*}
such that the following diagrams commute
\begin{align}	\label{EsDigcococo}
\xymatrix{%
&	 					\cA\otimes\cA\otimes\cA\\
\cA\otimes\cA \ar[ur]^{\Delta\otimes\id}&					&	\cA\otimes\cA\ar[ul]_{\id\otimes\Delta}\\
&						\cA\ar[ul]^{\Delta}\ar[ur]_{\Delta}
}
&&	% Début du second diagrame
\xymatrix{%
\eK\otimes\cA 		&	\cA\otimes\cA\ar[l]_{\epsilon\otimes\id}\\
&	\cA\ar[ul]^{\psi}\ar[u]_{\Delta}
   }
&&	% Début du troisième diagramme
\xymatrix{%
\cA\otimes\eK 		&	\cA\otimes\cA\ar[l]_{\id\otimes\epsilon}\\
&	\cA\ar[ul]^{\psi}\ar[u]_{\Delta}
   }\\
   (\id\otimes\Delta)\Delta=(\Delta\otimes \id)\Delta   &&   (\id\otimes\epsilon)\Delta=\id&&(\epsilon\otimes\id)\Delta=\id.
\end{align}
The first diagram expresses the \defe{coassociativity}{coassociativity} of $\Delta$ while the two last ones are the \defe{counit}{counit} definition for $\epsilon$. When these three diagrams commute, we say that $(\cA,\Delta,\epsilon)$ is a coalgebra.


Notice that, since the tensor product is defined by a quotient, we have $1\otimes za=z\otimes a$ for every $z\in\eC$ and $a\in\cA$. We also have $(\epsilon\otimes\id)(a\otimes b)=\epsilon(a)\otimes b=1\otimes\epsilon(a)b$.

\begin{definition}      \label{DefBialgebra}
    A \defe{bialgebra}{bialgebra} structure on $\cA$ is the data of $(\mu,\eta,\Delta,\epsilon)$ such as before (the six diagrams commute) and which fulfills the following compatibility conditions:
    \begin{align}       \label{EqSixBialgebraformdef}
    \Delta(hg)&=\Delta(h)\Delta(g)&			\epsilon(hg)&=\epsilon(h)\epsilon(g)\\
    \Delta(1)&=1\otimes 1		&		\epsilon(1)&=1
    \end{align}
    where in the last equality, the $1$ of the left hand side denotes the unit in $\cA$ while the $1$ in the right hand side is the unit in $\eK$. Such an operation $\Delta$ is said to be a \defe{coproduct}{coproduct} and such an operation $\epsilon$ is a \defe{counit}{counit}.
\end{definition}

It is interesting to write the formula \( \Delta(ab)=\Delta(a)\Delta(b)\) in a more abstract way. The product 
\begin{equation}
    (a\otimes b)(c\otimes d)=ac\otimes bd
\end{equation}
reads $(\mu\otimes\mu)(\id\otimes\sigma\otimes\id)(a\otimes b\otimes c\otimes d)$. Thus we consider
\begin{equation}        \label{EqDefmdeuxAAotAAmtAA}
    \begin{aligned}
        m_2\colon (A\otimes A)\otimes (A\otimes A)&\to A\otimes A \\
        m_2&=(\mu\otimes\mu)\circ(\id\otimes\sigma\otimes\id)
    \end{aligned}
\end{equation}
and we have the property
\begin{equation}        \label{EqDelMumdex}
    \Delta\circ\mu=m_2(\Delta\otimes\Delta).
\end{equation}


Among other interesting formulas, the identification \( A\otimes \eK=A\) allows us to write
\begin{equation}    \label{EqInterAmongOtheaaepsb}
    a=(\id\otimes\epsilon)\Delta(a)=\sum_i(\id\otimes \epsilon)(a_i\otimes b_i)=\sum_ia_i\epsilon(b_i).
\end{equation}

\begin{lemma}       \label{LemUnicityCounit}
    A coalgebra has at most one counit.
\end{lemma}

\begin{proof}
    Let \( \epsilon_1\) and \( \epsilon_2\) be counits of \( (A,\Delta)\). We have
    \begin{equation}
            \epsilon_1=\epsilon_1\circ(\id\otimes\epsilon_2)\Delta
            =(\epsilon_1\otimes\epsilon_2)\Delta
            =\epsilon_2(\epsilon_1\otimes\id)\Delta
            =\epsilon_2.
    \end{equation}
\end{proof}


%---------------------------------------------------------------------------------------------------------------------------
\subsection{Other co-properties}
%---------------------------------------------------------------------------------------------------------------------------
\label{subSecOtherCoPropoerties}

We usually denote by \( \sigma\) the flip operation:
\begin{equation}
    \begin{aligned}
        \sigma\colon \cA\otimes\cA&\to \cA\otimes\cA \\
        a\otimes b&\mapsto b\otimes a. 
    \end{aligned}
\end{equation}

As a general rule, one defines a ``coproperty'' by writing a property as a commutative diagram and then reversing all the arrows. A map \( \varphi\colon \cA\otimes\cA\to \cA\) is skew symmetric if the following diagram commutes:
\begin{equation}
    \xymatrix{%
    \cA\otimes\cA \ar[r]^-{\varphi}\ar[d]_{\sigma}        &   \cA\\
       \cA\otimes\cA \ar[r]_-{\varphi}   &   \cA\ar[u]_{-1}
       }
\end{equation}
Then one say that a map \( \phi\colon \cA\to \cA\otimes\cA\) is \defe{co-skew symmetric}{co-skew symmetric} if the diagram
\begin{equation}
    \xymatrix{%
    \cA\otimes\cA       &   \cA\ar[l]_-{\phi}\ar[d]^{-1}\\
    \cA\otimes\cA\ar[u]^{\sigma}   &     \cA\ar[l]^-{\phi}
    }
\end{equation}
commutes. In formula, it means that for every \( a\in\cA\), we have \( \phi(a)=\sigma\phi(-a)\) or
\begin{equation}        \label{EqDefCoSkewSym}
    (\sigma+\id)\circ\phi=0.
\end{equation}
A typical example of co-skew symmetric map is \( \phi(a)=1\otimes a-a\otimes 1\).

Let \( \xi\) be the cyclic permutation operator
\begin{equation}
    \begin{aligned}
        \xi\colon \cA\otimes\cA\otimes\cA&\to \cA\otimes\cA\otimes\cA \\
        a\otimes b\otimes c&\mapsto b\otimes c\otimes a.
    \end{aligned}
\end{equation}
A map \( \phi\colon \cA\otimes\cA\to \cA\) satisfies the \defe{Jacobi}{Jacobi} relation
\begin{equation}
    \varphi\big( a,\varphi(b,c) \big)=-\varphi\big( b,\varphi(c,a) \big)-\varphi\big( c,\varphi(a,b) \big)
\end{equation}
if the diagram 
\begin{equation}
    \xymatrix{%
    \cA\otimes\cA\otimes\cA\ar[r]^-{\id\otimes\varphi}\ar[d]_{-\xi-\xi^2}   &   \cA\otimes\cA\ar[r]^-{\varphi}      &   \cA\\
    \cA\otimes\cA\otimes\cA\ar[rr]_-{\id\otimes\varphi} &   &   \cA\otimes\cA\ar[u]_-{\varphi}
       }
\end{equation}
commutes. Thus one says that a map \( \phi\colon \cA\to \cA\otimes\cA\) satisfies the \defe{co-Jacobi}{co-Jacobi} relation if the diagram
\begin{equation}
    \xymatrix{%
    \cA\otimes\cA\otimes\cA     &       \cA\otimes\cA\ar[l]_-{\id\otimes\phi}       &       \cA\ar[l]_-{\phi}\ar[d]^-{\phi}\\
    \cA\otimes\cA\otimes\cA\ar[u]^-{-\xi-\xi^2}     &                               &       \cA\otimes\cA\ar[ll]^-{\id\otimes\phi}
    }
\end{equation}
commutes. In formula,
\begin{equation}        \label{EqDefCoJacobi}
    (\id+\xi+\xi^2)\circ(\id\otimes\phi)\circ\phi=0.
\end{equation}
