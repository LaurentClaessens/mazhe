% This is part of (almost) Everything I know in mathematics
% Copyright (c) 2013-2014
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
					\section{Position of submodules}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{proposition}
Let $M$ be a von~Neumann algebra (not specially with trace). Every finitely generated submodule of a finite generated projective module is projective.
\end{proposition}

\begin{proof}
Passing to the matrix algebra (lemmas \ref{LemEprojEEEfproj} and \ref{LemFGenEEEsingleGen}), one can assume that the module and the submodule are in fact singly generated.

A singly generated module over $ M$ has the form $E=MT\subseteq M$ for some element $T\in M$. We saw during the proof of proposition \ref{PropMTprojpourtoutT} that $MT\simeq MP$ where $P$ is the projection onto $\overline{ \Image(T) }$. The fact that $MP$ is a projective module was already argued on page \pageref{PgMPprojModule}.
\end{proof}

\begin{proposition}			\label{PropEfgpFssmodQuotProj}
If $E$ is a finite projective module over $M$ and $F$ is a submodule of $E$, then $E/\Cl_E(F)$ is projective.
\end{proposition}

\begin{proof}
Once again, using the matrix trick, one can suppose that $E$ is singly generated by an element $e$. A left module map $\varphi\colon E\to M$ such that $\varphi(F)=0$ is determined by the value of $\varphi(e)\in M$. The element $\varphi(e)$ is an operator on $\hH$ and we define $P_{\varphi}$ as the projection onto $\overline{ \Image\big( \varphi(e) \big) }$.

Now we define the module map
\begin{equation}
\begin{aligned}
\tilde{\varphi} \colon E&\to M \\ 
   \tilde{\varphi}(Te)&\mapsto TP_{\varphi}. 
\end{aligned}
\end{equation}
This is well defined. Indeed if $Se=0$, then $\varphi(Se)=S\varphi(e)=0$, which implies that $SP_{\varphi}=0$. For the same reason, $\ker(\varphi)=\ker(\tilde{\varphi})$. We define 
\begin{equation}
	Q=\bigvee_{\varphi}P_{\varphi},
\end{equation}
and 
\begin{equation}
\begin{aligned}
 \psi\colon E&\to M \\ 
   \psi(Te)&\mapsto TQ 
\end{aligned}
\end{equation}
which is well defined because $TQ=0$ if and only if $TP\varphi =0$ for every $\varphi$, since the operator $T$ is bounded\footnote{If $T$ is not bounded, it can get bigger and bigger on the range of $\varphi_k$ when $k$ goes to infinity, so that the limit of $T\bigvee_{\varphi\in\alpha}$ is not zero when $\alpha$ gets bigger.}.
\begin{probleme}
The explanation in the footnote is unclear; it has to be expressed in terms of nets.
\end{probleme}
By construction, $\ker(\psi)=\Cl_E(F)$, while $\Image(\psi)=MQ$, so that
\begin{equation}
	E/\ker(\psi)\simeq MQ,
\end{equation}
while the latter is projective.
\end{proof}

\begin{corollary}		\label{CorEfgpFssIsom}
When $E$ is a finite projective module and $F$ a submodule, we have an isomorphism
\[ 
	E=\Cl_E(F)\oplus E/\Cl_E(F)
\]
as direct sum of modules.
\end{corollary}

\begin{proof}
If $\xi\in E$, the class of $\xi$ in $E/\Cl_E(F)$ is
\begin{equation}
	[\xi]=\{ \xi+\eta\tq \eta\in\Cl_E(F) \}.
\end{equation}
Let us choose a representative $[\xi]_0$ in each of the classes\quext{This uses the famous axiom; it would be possible to do otherwise, isn't ?}. The following is the module isomorphism we are searching for
\begin{equation}
\begin{aligned}
 \psi\colon E&\to \Cl_E(F)\oplus E/\Cl_E(F) \\ 
   \xi&\mapsto  \eta\oplus [\xi]_0 
\end{aligned}
\end{equation}
where $\eta$ is the unique element of $\Cl_E(F)$ such that $[\xi]_0+\eta=\xi$.
\end{proof}

When $E$ is a finite projective module over $M$, we say that $\Cl_E(0)$ is the \defe{torsion submodule}{torsion!submodule} of $E$.

Let us see an example. Let 
\begin{equation}
	E=M/MT 
\end{equation}
with $T\geq 0$ and $\overline{ \Image(T) }=\hH$. We claim that the torsion submodule of $E$ is $E$ itself. A module map $\varphi\colon E\to M$ is a module map $M\to M$ composed with a projection, or in other words a module map $\varphi\colon M\to M$ such that $\varphi(T)=0$. Since $\varphi$ is a module map, its fulfils
\begin{equation}
	\varphi(S)=\varphi(S\mtu)=S\varphi(\mtu)=SX
\end{equation}
for a certain $X\in M$ such that $TX=0$. Thus we have $\overline{ \Image(X) }\subset\ker(T)$, but since $T\geq 0$ (in particular $T$ is self-adjoint) and $\overline{ \Image(T) }=\hH$, we have $\ker(T)=0$, and we conclude that $X=0$, so that $\varphi=0$. The question is to know if $E=M/MT$ has a finitely generated submodule or not. Let $P$ be a projective submodule of $M/MT$; by the lifting property \eqref{EqLiftPropProjModules} we have a map $\tilde \lambda$ such that the following commutes
\begin{equation}
\xymatrix{%
 									&  M \ar@{->>}[d]^{\displaystyle\lambda}\\
   P \ar[r]\ar@{.>}[ru]							& M/MT
}
\end{equation}
where the arrow from $P$ to $M/MT$ is injective. The image of $P$ by $\tilde\lambda$ is a submodule $MX$ that has to be injectively\quext{How to say the fact to be injective in English ? Does the word \emph{injectively} exist ?} projected in $M/MT$, so that $MX\cap MT=\emptyset$. Notice that it is not possible when $\hH$ is finite dimensional because $T$ is invertible (from the fact that the closure of its image is the whole space), so that $MT=M$.

Now we suppose that $X$ is positive. This is done without loss of generality because from polar decomposition, for every $X\in M$, there exists a positive $Y$ such that $MX=MY$.

Since $T$ is positive, we can consider the spectral theorem \ref{ThoSpectralTho} and the isomorphism
\begin{equation}
\begin{aligned}
 \theta\colon C^*(T,\cun)&\to C\big( \Spec(T) \big). 
\end{aligned}
\end{equation}
We define the following function on $\Spec(T)$
\begin{equation}
	f_{\epsilon}=
			\begin{cases}
					0				&\text{if $x<\epsilon$}\\
					\frac{ 1 }{ (\theta T)(x) }	&\text{if $x\geq\epsilon$,}
			\end{cases}
\end{equation}
and then one defines the operator $S_{\epsilon}=\theta^{-1}(f_{\epsilon})\in C^*(T,\cun)$. Let us prove that $P_{\epsilon}=S\epsilon T$ is a projection. We have $P_{\epsilon}^2=S_{\epsilon} TS_{\epsilon}T$. Take an orthonormal basis of $\hH$ of eigenvectors of $T$ and let's call $\lambda_i$ the eigenvalues: $Te_i=\lambda_ie_i$. If $\lambda_k<\epsilon$, then $S_{\epsilon}e_i=0$ and of course $S_{\epsilon}TS_{\epsilon}e_i=S_{\epsilon}e_i$. Otherwise, we have
\begin{equation}
	S_{\epsilon}TS_{\epsilon}e_i=\frac{1}{ \lambda_i }S_{\epsilon}T e_i =S_{\epsilon}e_i.
\end{equation}
That proves that $P_{\epsilon}^2=P_{\epsilon}$, and so that this is a projection. We obviously also have $P_{\epsilon}\to \mtu$ in $MT$.

Similarly one can define $Q$, the projection onto $\overline{ \Image(X) }$ and we have projections $Q_{\epsilon}\to Q$ with $Q_{\epsilon}=Y_{\epsilon} X$ for some $Y\epsilon\in M$ and $Q_{\epsilon}\in MX$. Now take $\epsilon_1$ and $\epsilon_2$ and look at the projection
\begin{equation}
	Q_{\epsilon_1}\vee P_{\epsilon_2}
\end{equation}
onto $\Image(Q_{\epsilon_1})\cap\Image(P_{\epsilon_2})$. The latter intersection is in fact $0$ because $A_{\epsilon_1}\vee P_{\epsilon_2}\in MQ_{\epsilon_1}\cap MP_{\epsilon_2}=MX\cap MT=0$. Using lemma \ref{LemDimSupDeuxProjs}, we get
\begin{equation}
	\dim\mtu\geq \dim(Q_{\epsilon_1}\vee P_{\epsilon_2})=\dim(Q_{\epsilon_1})+\dim(P_{\epsilon_2}).
\end{equation}
Recall that the trace used to define the dimension has to be normal, so that the dimension function is continuous in such a way that taking the limit $\epsilon_1\to 0$ and $\epsilon_2\to 0$ provides the expected result
\begin{equation}
	\dim(\mtu)\geq \dim(Q)+\dim(\mtu),
\end{equation}
from which one deduce that $\dim Q=0$ and therefore $X=0$. This finish the proof that the module $E=M/MT$ with a positive $T$ and $\overline{ \Image(T) }=\hH$ has no projective submodules.

\begin{proposition}
If $E$ is a finitely generated module over $M$, then the torsion submodule does not contains non zero projective finite submodules.
\end{proposition}

\begin{proof}
Later.
\end{proof}


\begin{lemma}			\label{LemFClosEF}
If $E$ is a finitely generated submodule of a finitely generated projective module $E$, then $F$ is projective and $F\simeq \Cl_E(F)$.
\end{lemma}

\begin{proof}
We assume as usual that $E$ and $F$ are singly generated. The singly generated projective module $E$ reads $E=MP$ while the general form of a singly generated submodule is $F=MT$ for a positive $T$ which vanishes on $P^{\perp}\hH$ and $\Image(T)\subseteq\Image(P)$. We already proved that $MT\simeq MQ$ where $Q$ is the projection over $\Image(T)$.

We have $\Cl_{MP}(MT)=MQ$ because of the direct sum decomposition $MP=MQ\oplus M(P-Q)$ from which we can build an homomorphism $MP\to M$ which vanishes on $MT$, namely the projection  because $MT\subseteq MQ$.
\begin{probleme}
I do not understand one single word about the latter justification $:($
\end{probleme}
\end{proof}

\begin{corollary}		\label{Corfgfgdilleqdim}
If $F$ is a finitely generated submodule of a finitely generated projective module $E$, then $\dim(F)\leq\dim(E)$.
\end{corollary}

\begin{proof}
By lemma \ref{LemFClosEF}, we have $\dim(F)\simeq\dim\big( \Cl_E(F) \big)$ while we know that $E=\Cl_E(F)\oplus E/\Cl_E(F)$. The latter makes that $\dim E$ is given by the trace of two projections:
\begin{equation}
	\dim E=\tr P_{\Cl_E(F)}+\tr P_{E/\Cl_E(F)}.
\end{equation}
\end{proof}

\begin{corollary}
If $E$ is a finitely projective module over a von~Neumann algebra with a trace, then $\dim(E)=\Dim(E)$. 
\end{corollary}

\begin{proof}
By very definition, $\Dim(E)\geq\dim(E)$ because $E$ itself belongs to the set on which the supremum is taken in the definition \eqref{DefDimAvecGrandD} of $\Dim$. The corollary \ref{Corfgfgdilleqdim} provides the opposite inequality.
\end{proof}

\begin{proposition}		\label{PropProjFiniDimCldim}
If $E$ is projective finitely generated and if $F\subseteq E$, then $\dim\big( \Cl_E(F) \big)=\Dim(F)$.
\end{proposition}

\begin{proof}
The case where $F$ is finitely generated is already done by lemma \ref{LemFClosEF}. For the general case, suppose that the proposition does not hold. In this case, the lemma \ref{LemFClosEF} yields
\begin{equation}
	\sup\{ \dim\big( \Cl_E(H) \big)\tq \text{$H$ is finite projective} \}<\dim\big( \Cl_E(F) \big).
\end{equation}
On the one hand, by corollary \ref{CorEfgpFssIsom}, the module $\Cl_E(H)$ is a direct summand of $\Cl_E(F)$ which is itself (by the same result) a direct summand of $E$. On the other hand, being a finitely generated module, it reads $E=M^nP$ for some projection $P$ by proposition \ref{PropFGPRkP}. Combining both, we have a projection $P_H\leq P$ such that $\Cl_E(H)=M^nP_H$.

Now the finitely generated projective submodules of $F$ form a directed system. For every finitely generated projective submodules $H_1$ and $H_2$ of $F$, there exists at least $H_3=H_1\oplus H_2$ which contains $H_1$ and $H_2$. Thus the set of $P_H$ is directed too and one can look at $\bigvee_HP_H$, the smalest projection whose range contains the range of all of the $P_H$.

We have $\bigvee_HP_H<P$ because if not, using normality of the trace,
\begin{equation}
	\dim\big( \bigvee_HP_H \big)=\sup_H\dim(P_H)<P.
\end{equation}
Now let $Q=P-\bigvee_HP_H$. If $F$ is some sunmodule of $E$, one has
\begin{equation}
\begin{split}
	F&=\bigcup\{ H\subseteq F\tq \text{$H$ is finitely generated} \}\\
	&=\bigcup\{ H\subseteq F\tq \text{$H$ is finitely generated and projective} \}
\end{split}
\end{equation}
because $H\subseteq F\subseteq E$ which is finitely generated projective. Such a $H$ has the form $M^nP_H$, sp $F\subseteq M^n\big( \bigvee_HP_H \big)$. Notice that this $F$ lies in the kernel of the non zero map
\begin{equation}
\begin{aligned}
 \Cl_E(F)=M^nP&\to M^nQ \\ 
   V&\mapsto VQ. 
\end{aligned}
\end{equation}
Indeed, since $\bigvee_HP_H<P$, we have $\big( \bigvee_HP_H \big)P=\bigvee_HP_H$, so that for every $T\in M^n$ we have $T\bigvee_HP_H\big( P-\bigvee_HP_H \big)=0$. By looking at the complement of $VQ$, one has a nonzero homomorphism $ \Cl_E(F)\to M$ which vanishes on $F$. That contradicts the definition of the closure.

\end{proof}

The three point in this demonstration that use the von~Neumann algebra blackground (and not only general module theory) are the following.
\begin{itemize}
\item First we used normality of the trace to commute the dimension with the suppremum,
\item and second, we used continuity of $\bigvee$ with respect to the dimension.
\end{itemize}

%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Summary}
%---------------------------------------------------------------------------------------------------------------------------

We have two dimension functions $\dim$ and $\Dim$ such that
\begin{enumerate}
\item $\dim E=\Dim E$ whenever $E$ is a finitely generated projective module,
\item for every finitely generated module $E$ and every submodule $F$, the module $E/\Cl_E(F)$ is finitely generated and projective,
\begin{probleme}
Check if one does not need the assumption that $E$ is projective too.
\end{probleme}
\item If $F\subseteq E$ and if $E$ is a finitely generated projective module, then $\Dim(F)=\Dim\big( \Cl_E(F) \big)$.
\end{enumerate}
From now we do no more use the ``von~Neumann algebra'' assumption. Instead we suppose to have a ring $R$ and two dimensions functions satisfying these three properties.

%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Properties of the dimension function}
%---------------------------------------------------------------------------------------------------------------------------

\begin{proposition}
If $E$ is the union of a directed system of submodules $E_{\alpha}$, then $\Dim(E)=\sup \Dim E_{\alpha}$.
\end{proposition}

\begin{proof}
A finitely generated projective submodule in $E$ is generated by $n$ elements, each of them being contained in some $E_{\alpha_1}$, $E_{\alpha_2},\ldots$ By definition of a directed set, the union of all the so defined $E_{\alpha_i}$ is contained in a $E_{\beta}$. Thus every finitely generated projective submodule in $E$ is of the form $E_{\beta}$.
\end{proof}

\begin{lemma}			\label{LemHinjectifHdimdim}
If one has a projective module map $\rho\colon H_1\to H_2$, then $\Dim(H_1)\geq\Dim(H_2)$.
\end{lemma}

\begin{proof}
Let $F$ be any projective module for which there exists an inclusion $\iota\colon F\to H_2$. That map can be lifted because $F$ is projective. So among all the submodules of $H_1$, there is the one which is the image of $F$ be the lifted map. That one of course contains $H_2$ itself. Thus $H_2$ is a submodule of $H_1$ and the supremum defining the dimension in $H_1$ is automatically bigger or equal to the one defining the dimension of $H_2$.
\end{proof}

\begin{proposition}
If
\begin{equation}
	\xymatrix{%
   0\ar[r] 	&E_0\ar[r]^{}	&E_1\ar[r]^{p}	&E_2 \ar[r]	&0	
}
\end{equation}
is a short exact sequence of modules, then $\dim(E_1)=\dim(E_0)+\dim(E_2)$.
\end{proposition}

\begin{proof}
Using last proposition, we can assume that all of $E_0$, $E_1$ and $E_2$ are finitely generated. Indeed when a module is not finitely generated, it is still the union of the directed system of all its finitely generated submodules.

Let $F$ be a finitely generated projective submodule of $E_2$, we have the exact sequence
\begin{equation}
	\xymatrix{%
   0\ar[r] 	&E_0\ar[r]	&p^{-1}(F)\ar[r]	&F \ar[r]	&0.
}
\end{equation}
The module $F$ being projective, we have $p^{-1}(F)\simeq F\oplus E_0$. We do not know if the dimension function is additive with respect to direct sum, but by definition of a supremum, we have the inequality $\Dim(E_0)+\Dim(F)\leq \Dim\big( p^{-1}(F) \big)$, and the chain
\begin{equation}
	\Dim(E_0)+\Dim(F)\leq \Dim\big( p^{-1}(F) \big)\leq\Dim(E_1)
\end{equation}
which in turn provides the inequalities
\begin{equation}
	\Dim(E_0)+\Dim(E_2)\leq\Dim(E_1).
\end{equation}
For the reverse inequality, let $F$ be a finitely generated projective submodule of $E_1$, and consider the following exact sequence of finitely generated projective module
\begin{equation}
	\xymatrix{%
   0\ar[r] 	&\Cl_F(F\cap E_0)\ar[r]	&F\ar[r]	&F/\Cl_F(F\cap E_0) \ar[r]	&0	
}
\end{equation}
The fact that $F/\Cl_F(F\cap E_0)$ is projective is proposition \ref{PropEfgpFssmodQuotProj}. Since $F/\Cl_F(F\cap E_0)$ is at most a subset of $F$ which is finitely generated, it has to be finitely generated too. We also know by corollary \ref{CorEfgpFssIsom} that $F$ splits into
\begin{equation}
	F\simeq \Cl_F(F\cap E_0)\oplus F/\Cl_F(F\cap E_0)
\end{equation}
which is a direct sum of finitely generated projective module, so that we can use the definition of dimension with traces (which sums up over direct sum) instead of the one with supremum. Thus we have
\begin{equation}
	\dim(E)=\dim\big( \Cl_F(F\cap E_0) \big)+\dim\big( F/\Cl_F(F\cap E_0) \big).
\end{equation}
The module $F$ being projective and finitely generated, proposition \ref{PropProjFiniDimCldim} allows us to replace $\dim\big( \Cl_F(F\cap E_0) \big)$ by $\Dim(F\cap E_0)$ and write
\begin{equation}
	\dim(E)=\Dim(F\cap E_0)+\Dim\big( F/\Cl_F(F\cap E_0) \big)\leq \Dim(E_0)+\Dim(F/(F\cap E_0))
\end{equation}
where we also used lemma \ref{LemHinjectifHdimdim}. Since $F/(F\cap E_0)$ is a quotient of $E_2$, we have $\Dim(F/(F\cap E_0))\leq\Dim(E_2)$, and taking the supremum over all suitable $F$, we find the result
\begin{equation}
	\dim(E_1)\leq \Dim(E_0)+\Dim(E_2).
\end{equation}
\end{proof}

\begin{proposition}
If $E$ is a finitely generated module and $F\subseteq E$, then $\Dim(F)=\Dim\big(\Cl_E(F)\big)$.
\end{proposition}
\begin{proof}
Hint: by the proposition, one can assume that $E$ is actually projective.
\end{proof}
\begin{probleme}
 That has to be completed.
\end{probleme}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
					\section{Decomposition of operators and representations}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Motivation}
%---------------------------------------------------------------------------------------------------------------------------

Let $G$ be a compact topological group and consider the space $L^2(G)$ (with respect to the Haar measure), and $M$ be the von~Neumann algebra generated by the left regular representation
\begin{equation}
	M=\{ U_g\tq g\in G \}''
\end{equation}
with $(U_gf)(f)=g(g^{-1} h)$. Each $U_g$ is an unitary operator in $H$. In this case, the commutant $M'$ turns out to be the von~Neumann algebra generated by the regular right representation.

\begin{probleme}
	The operator $R$ given by 
	\begin{equation}
		\big(R(f)\big)(x)=\frac{ f(x) }{ 2 }
	\end{equation}
	commutes with all the regular left representation, but is not part of the regular right representation. Do we impose unitarity conditions ?
\end{probleme}

When $\sigma\colon G\to \End(V)$ is a finite dimensional irreducible representation of the group $G$, the \defe{character}{character!of a representation} of $\sigma$ is the function $\chi_{\sigma}\colon G\to \eC$ defined by the formula
\begin{equation}
	\chi_{\sigma}(g)=\tr\big( \sigma(g) \big).
\end{equation}
The representation $\sigma$ thus defines the operator $P_{\sigma}$ on $H=L^2(G)$,
\begin{equation}
	(P_{\sigma})(f)=\frac{ \dim(\sigma) }{ \volume(G) }\int \chi_{\sigma}(g^{-1})(U_gf)\,dg.
\end{equation}

\begin{theorem}[Peter-Weyl]			\label{ThoPeterWeyl}\index{Peter-Weyl theorem}
	The operator $P_{\sigma}$ is a projection which belongs to $M\cap M'$ and for which the following hold
	\begin{enumerate}
		\item\label{ItemPeterWeyli} If $\sigma_1\nsimeq \sigma_2$, then $P_{\sigma_1}P_{\sigma_2}=0$,
		\item \label{ItemPeterWeylii} in the strong topology, $\sum_{\sigma}P_{\sigma}=\mtu$,
		\item the algebra $M\cap M'$ is generated by $\{ P_{\sigma} \}$ and each of the $P_{\sigma}$ is minimal in the center,
		\item $P_{\sigma}MP_{\sigma}$ is a factor on $H_{\sigma}$ and we have $(P_{\sigma}MP_{\sigma})'=P_{\sigma}M'P_{\sigma}$,
		\item $P_{\sigma}MP_{\sigma}$ is finite dimensional.
	\end{enumerate}
\end{theorem}

Notice that, because of point \ref{ItemPeterWeyli} and \ref{ItemPeterWeylii}, if $H_{\sigma}$ denotes the range of $P_{\sigma}$, then
\begin{equation}
	H=\bigoplus_{\sigma}H_{\sigma}.
\end{equation}

\begin{proof}
No proof.
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Conventions and definitions}
%---------------------------------------------------------------------------------------------------------------------------

From now, all Hilbert space will be separable and measure spaces $(X,\mu)$ will be as follows. The topological space $X$ will be an Hausdorff, secondly countable metrisable space and $\mu$ will be the completion of a Borel measure which is finite on compact sets on $X$. By \defe{completion}{completion!of a measure}, we mean that all subset of a null set are measurable of measure zero.

Now let $X$ be a set. A \defe{field of Hilbert space}{field!of Hilbert space} over $X$ is a set of Hilbert spaces $H_x$ for each $x\in X$. A \defe{section}{section!of field of Hilbert space} of the field is a function $V\colon C\to \bigsqcup_{x\in X}H_x$ such that $V(x)\in H_x$. We often write $V_x$ instead of $V(x)$. The set of sections is denoted by $\Gamma\{ H_x \}$.

Let $H$ be a (separable) Hilbert space. A \defe{direct integral decomposition}{direct!integral decomposition} of $H$ is
\begin{itemize}
	\item a measure space $(X,\mu)$,
	\item a field of Hilbert spaces over $X$,
	\item a function from $H$ to the space of sections of the field that we denote by $v_x$, the value at $x$ of the section associated with $v\in H$
\end{itemize}
such that
\begin{enumerate}
	\item for every $v$ and $w$ in $H$, the function $x\mapsto\langle v_x, w_x\rangle $ is integrable and
	\begin{equation}
		\int_X\langle v_x, w_x\rangle d\mu(x)=\langle v, w\rangle ,
	\end{equation}
	\item if $u$ is any section of the field such that $x\mapsto\langle u_x, w_x\rangle $ is integrable for all $w\in H$, then $u$ is almost everywhere equal to the section associated with a vector of $H$,
	\item the set of all decompositions of vectors in $H$ is maximal.
\end{enumerate}

\begin{probleme}
I do not understand the precise signification if the maximality, cf problem \ref{ProbMaximvE}.
\end{probleme}

Notice that the set of sections that are equal almost everywhere to sections obtained by decomposition of vectors in $H$ form a module over $L^{\infty}(X,\mu)$.


An technical fact that will be used in much of proofs is the following. 

\begin{lemma}		\label{LemdensHdensHx}
If $\{ v_1,v_2,\ldots \}\subseteq H$ has a dense span in $H$, then for almost every $x\in X$, the set $\Span\{ v_{1x},v_{2x},\ldots \}$ is dense in $H_x$.
\end{lemma}

%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Examples}
%---------------------------------------------------------------------------------------------------------------------------

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
					\subsubsection{First example}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////



Let $H_x$ with $x\in X$ be a field of Hilbert space over a countable set $X$. Then define $H=\bigoplus_{x\in X}H_x$. That Hilbert space decomposes by $(X,\mu)$ with $\mu$ being the counting measure, and to $v\in H$ corresponds a component $v_x$ in each $H_x$ that are taken as the section associated to the vector $v$.

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
					\subsubsection{Second example}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////


Let $(X,\mu)$ be the counting measure over the countable set $X$, and consider the Hilbert space $H=L^2(X,\mu)$. A decomposition of that Hilbert space is given as follows: first pose $H_x=\eC$ for each $x\in X$. Then, for each vector $v\in H$, we associate some choice of function $f$ in the equivalence class that defines $v$. Then we define the section associated with $v$ is $v_x=f(x)$.

Let us check that this construction fulfils the axioms of a direct integral decomposition of Hilbert space. First the function $x\mapsto \langle v_x, w_x\rangle $ has to be integrable. If $f$ is the function associated with $v$ and $g$ the one associated with $w$, we have $\langle v_x, w_x\rangle =f(x)\overline{ g(x) }$ which is integrable by Cauchy-Schwartz, and by the definition of the product in $L^2$, we have
\begin{equation}
	\langle v, w\rangle =\int_X f(x)\overline{ g(x) }\,d\mu(x).
\end{equation}
Second, suppose that $u$ is a section such that the map $x\mapsto u_x\overline{ f(x) }$ is integrable for every $f$ associated with a vector in $H$. The measured space $(X,\mu)$ being countable, $X$ is a union of finite measure sets $\{ X_i \}$ on each of them one can consider the characteristic function $1_i$. Then for every $i$, the function $x\mapsto u_x 1_i$ is measurable on $X_i$. That proves that $u$ is measurable. We conclude that it is square integrable and thus defines a function which is almost everywhere equal to the section associated with a vector $v\in L^2(X,\mu)$, namely the element of $L^2(X,\mu)$ which is the class of $u$.

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
					\subsubsection{Third example}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Let $H=L^2(X,\mu_1)\oplus L^2(X,\mu_2)$ and $\mu=\mu_1+\mu_2$ which is still a complete measure. By Radon-Nikod\'ym theorem \ref{ThoRadonNikodym}, there exists positive measurable functions $f_1$ and $f_2$ such that $\mu_i=f_i\mu$. We can decompose $H$ as the direct integral
\begin{equation}
	H_x=l^2\Big(    \{ x \}\cap\{ f_1>0 \}\sqcup \{ x \}\cap\{ f_2>0 \}  \Big).
\end{equation}
Depending on the $x$, the set $\{ x \}\cap\{ f_1>0 \}\sqcup \{ x \}\cap\{ f_2>0 \}$ has zero, one or two elements. Now if $v=(v_1,v_2)\in H$ with $v_!=[g_1]$ and $v_2=[g_2]$, we define the section associated with $v$ as
\begin{equation}
	v_x=\big( f_1(x)^{1/2}g_1(x),f_2(x)^{1/2}g_2(x) \big).
\end{equation}
As notation, if $f_1(x)=0$, we identify this with the element $f_2(x)^{1/2}g_2(x)$ instead of with $(0,f_2(x)^{1/2}g_2(x))$.

%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Decompositions of operators}
%---------------------------------------------------------------------------------------------------------------------------



Suppose that the separable Hilbert space $H$ is provided with a decomposition over $(X,\mu)$. A \defe{decomposition}{decomposition!of operator} of the operator $T\in \oB(H)$ is a family of bounded operators $T_x\colon H_x\to H_x$ such that for every $v\in H$, the condition
\begin{equation}		\label{EqCondTvDecompOps}
	(Tv)_x=T_xv_x
\end{equation}
holds for almost every $x\in X$. 

\begin{remark}
The conditions \ref{EqCondTvDecompOps} are in fact uncountably many conditions (one for each $v\in H$) each of them having the possibility to be wrong on a null set. One has thus to be prudent because an uncountable union of null set \emph{might} be a set of non zero measure.
\end{remark}


\begin{lemma}
The set of decomposable operators is a $*$-algebra.
\end{lemma}

\begin{proof}
If the operator $T$ is decomposable, the rule $(T^*)_x=(T_x)^*$ provides a decomposition of $T^*$.
\end{proof}

\begin{lemma}
Let $T$ be a decomposable operator. We have $T\geq 0$ if and only if $T_x\geq 0$ almost everywhere.
\end{lemma}

\begin{proof}
	In order to prove that $T$ is positive, we have to evaluate $\langle Tv, v\rangle $ from the decomposition of $T$ and $v$. We suppose that $T_x\geq 0$ for almost every $X\in X$ and we compute
	\begin{equation}
		\langle Tv, v\rangle =\int_X\langle (Tv)_x, v_x\rangle d\mu(x)=\int_X\langle T_xv_x, v_x\rangle d\mu(x)\geq 0.
	\end{equation}
	where we were allowed to change $(Tv)_x$ by $T_xv_x$ because the equality holds almost everywhere.

	For proving the contrary, let pick a dense, countable and rational vector subspace $H_0\subseteq H$, and assume that $T\geq 0$. If $v\in H$ and if $E\subseteq X$ is measurable, then by maximality of the Hilbert space decomposition there is some vector $v_E\in H$ such that
	\begin{equation}		\label{EqCondvEvx}
		(v_E)_x=
	\begin{cases}
		v_x&\text{if $x\in E$}\\
		0&\text{otherwise.}
	\end{cases}
	\end{equation}

	\begin{probleme}		\label{ProbMaximvE}
	I do not see why to use the maximality. Indeed, one considers the section 
	\begin{equation}		
		s_x=
	\begin{cases}
		v_x&\text{if $x\in E$}\\
		0&\text{otherwise.}
	\end{cases}
	\end{equation}
	By definition of decomposition of $v$, the integral
	\begin{equation}		\label{EqProbIntX}
		\int_X\langle v_x, w_x\rangle d\mu(x)
	\end{equation}
	exists for every $w\in H$. Now we have that
	\begin{equation}		\label{EqProbIntE}
		\int_X\langle s_x, w_x\rangle d\mu(x)= \int_E\langle v_x, w_x\rangle d\mu(x)
	\end{equation}
	whose existence is assured by existence of \eqref{EqProbIntX}, isn't ? 

	Existence of integral \eqref{EqProbIntE} assures the existence of a vector $v_E\in H$ such that $(v_E)_x=s_x$ almost everywhere. So we have the $v_E$ without maximality axiom. Do we really want the condition \eqref{EqCondvEvx} to hold everywhere and not only almost everywhere ? Since we only use it in integrals, I think that one does not care about a violation of condition \eqref{EqCondvEvx} on a null set.
	\end{probleme}

	We have that
	\begin{equation}
		\int_E\langle T_xv_x, v_x\rangle d\mu(x)=\int_X\langle T_xv_{Ex}, v_{Ex}\rangle =\langle Tv_E, v_E\rangle \geq 0
	\end{equation}
	because $T\geq 0$ by assumption. So we proved that $x\mapsto\langle T_xv_x, v_x\rangle $ is an integrable function on $X$ for which the integral over any subset is a positive real number. Then the function is real positive almost everywhere. Thus we have
	\begin{equation}
		\langle T_xv_x, v_x\rangle \geq 0
	\end{equation}
	almost everywhere. Therefore there exists a null set $N\subseteq X$ such that $\langle T_xv_x, v_x\rangle \geq 0$ for every $v\in H_0$ whenever $x\in X\setminus N$. If $x\in X\setminus N$, then $\Span\{ v_x\tq v\in H_0 \}$ is dense in $H_x$ because of lemma \ref{LemdensHdensHx}. Notice that $H_0$ is countable and there is one null set for each element of $H_0$ on which we are unsure of the sign of $\langle T_xv_x, v_x\rangle $.

	By enlarging the set $N$ we can assume that 
	\begin{equation}
		(a_1v_1+a_2v_2)=a_1(v_1)_x+a_2(v_2)_x
	\end{equation}
	for every $x\in X\setminus N$ and $a_i\in\eQ[i]$. Indeed the equalities are an equation for each $a_i\in\eQ[i]$ and $v_i\in H_0$. That is thus a countable set of equations; thus the set where the equations are not satisfied is a countable union of null sets.

	What we have now is that every vector in $H_x$ (with $xin X\setminus N$) can be written as a limit if vectors in $H_0$, and then $\langle T_xv_x, v\rangle \geq 0$, so that $T_x\geq 0$.

\end{proof}

\begin{lemma}
We have
\begin{equation} 
	\| T \|=\esssup\| T_x \|=\min\{ c\tq \| T_x \|\leq c\text{ almost everywhere} \}.
\end{equation}
\end{lemma}

\begin{proof}
	The inequality $\| T \|\leq\esssup\| T_x \|$ comes from the fact that
	\begin{equation}
		\| Tv \|=\int_X\langle T_xv_x, T_xv_x\rangle d\mu(x)
	\end{equation}
	which gives the bound. For the inverse inequality, remark that $\| T \|^2=\| T^*T \|$ and $(T^*T)_x=(T_x)^*T_x$ almost everywhere, so that one can replace $T$ by $T^*T$, or more simply we can assume that $T\geq 0$. Now consider the positive and self-adjoint operator $\| T \|\mtu-T$. The ``component'' operator is positive almost everywhere: $\| T \|\mtu=T_x\geq 0$ for almost every $x\in X$. We know that the maximum of the spectrum of $T_x$ is $\| T_x \|$, so that the number $\| TY \|-\| T_x \|$ is almost everywhere positive because it is an element of the spectrum of $\| T \|\mtu-T_x$ which is positive.
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Diagonal and decomposable operators}
%---------------------------------------------------------------------------------------------------------------------------



An operator $S$ is \defe{diagonal}{diagonal operator} if it is decomposable and if $S_x$ is multiple of identity for almost every $x\in X$.

As motivation, consider the example $H=\eC^{n_1+n_2}=\eC^{n_1}\oplus\eC^{n_2}$, the measure space being two points with the counting measure. A diagonal operator looks like
\begin{equation}
	\begin{pmatrix}
	  \lambda_1\mtu	&		\\ 
		&	\lambda_2\mtu	
	\end{pmatrix},
\end{equation}
while decomposable operators are
\begin{equation}
	\begin{pmatrix}
	 		 T_1	&		\\ 
			&	T_2	
	\end{pmatrix}.
\end{equation}
One sees that these two sets are mutually commutant. We will see in theorem \ref{ThoDecopDiagCommE} that this is a general fact that decomposable operators and diagonal operators are mutually commutant.

\begin{theorem}[Kaplansky density theorem]\index{Kaplansky density theorem}		\label{ThoKaplanskyDensity}
	If $A$ is a $*$-algebra of operators on $H$, then every strong limit of net in $A$ is a strong limit of a bounded net of elements in $A$. In other words, if $T=\lim_{\rightarrow}T_{\alpha}$, then there exist a net $S_{\beta}$ with $\| S_{\beta} \|\leq M$ (fixed $M$) such that $T=\lim_{\rightarrow}T_{\beta}$.
\end{theorem}

A complete proof is given in \cite{JonesVN}.

\begin{proof}[Sketch of proof]
	First, a convex subset of $\oB(\hH)$ is strongly closed if and only if it is weakly closed. So, using what is said on page \pageref{PgStarWeakRespecte} about the fact that weak topology is compatible with the involution, we know that if $T$ lies in the strong closure of $A$, and if $T=T^*$, then $T$ is the limit of a net of self-adjoint elements in $A$. That allows us to focus the proof of the theorem on self-adjoint elements of $A$.

	\begin{probleme}
	For me, the fact that this reasoning actually allows to restrict ourself to self-adjoint elements. But I suppose that it would become more clear when one understands the link between the statement here and the statement of Kaplansky's theorem in \cite{JonesVN}, page 32.
	\end{probleme}

	Consider the function $f(x)=2x/(1+x^2)$ that provides an homeomorphism from $[-1,1]$ to $[-1,1]$. Thus by continuous functional calculus, if $T=T^*$ and $\| T \|\leq 1$, we have $T=f(S)$ where $S=S^*$ and $S$ belongs to the norm closure of the algebra generated by $T$.

	Now if $T$ is the strong limit of the net $T_{\alpha}$ of self-adjoint operators, then $S$ is the strong limit of $S_{\alpha}$ with $S_{\alpha}\in A$ and $S^*_{\alpha}=S_{\alpha}$. Indeed one can prove that $S_{\alpha}\to S$ implies\footnote{In the weak topology, that implication is the continuous functional calculus, but in the strong topology (the one we are considering here), the validity of this assertion relies on the particular form of $f$.} $f(S_{\alpha})\to f(S)$.

	Since $\| f(S_{\alpha}) \|\leq 1$, thus $\| T \|\leq 1$.
\end{proof}



\begin{theorem}		\label{ThoDecopDiagCommE}
The algebra of decomposable and diagonal operators are mutually commutant.
\end{theorem}

\begin{proof}
	The fact that decomposable operators are in the commutant of diagonal operators and vice versa. The strategy to prove the theorem will be to first prove that decomposable and diagonal operators are von~Neumann algebras, and then show that every operator in the commutant of diagonal operators is decomposable. From there, the conclusion yields from the double commutant theorem.

	Suppose that $T$ is a strong limit of decomposable operators, i.e
	\begin{equation}
		T=\slim T_{\alpha}
	\end{equation}
	where $T_{\alpha}$ is decomposable and $\sup\{ | T_{\alpha} | \}<\infty$.
	 We want to show that $T$ is decomposable. For, let $H_0$ be a dense countable rational subspace of $H$. If $T$ is limit of a uniformly bounded \emph{net}, the fact that $H_0$ is countable makes that there is a \emph{sequence} of uniformly bounded decomposable operators $T_n$ such that $T_nv\to Tv$ for every $v\in H_0$.

	We have
	\begin{equation}
		\lim_{n\to\infty}\int_X \| T_{nx}v_x - (Tv)_x \|^2d\mu(x)=0
	\end{equation}
	for almost every $v\in H_0$. A general fact about $L^2$ spaces is that when a sequence goes to zero, then the functions (representative of the elements of $L^2$) themselves goes to zero on a subsequence. So for every given $v\in H_0$ there is a subsequence $\{ n_j \}$ such that
	\begin{equation}
		\| T_{n_jx}v_x-(Tv)_x \|\to 0
	\end{equation}
	for almost every $x\in X$. The subsequence might depends on the $v$, bu a diagonal argument provides a subsequence $\{ n_k \}$ of $\{ n_j \}$ such that for every $v\in H_0$,
	\begin{equation}
		\| T_{n_kx}v_x-(Tv)_x \|\to 0
	\end{equation}
	for almost every $x\in X$. These relations are a countable number of convergence almost everywhere. Then there exists a null set $N\subseteq X$ such that
	\begin{equation}		\label{EqTnkxTvxHorsN}
		\| T_{n_kx}v_x-(Tv)_x \|\to 0
	\end{equation}
	for every $v\in H_0$ and $x\in X\setminus N$. 

	By enlarging again the null set $N$, we define
	\begin{equation}
		H_{0x}=\{ v_x\tq v\in H_0 \}
	\end{equation}
	for $x\in X\setminus N$. This is a dense subspace of $H_x$ by lemma \ref{LemdensHdensHx}. Since the essential supremum of $\| T_{nx} \|$ is the norm of $T_n$, we have a ``double uniformly bounded'' relation
	\begin{equation}
		\sup_n\sup_x\| T_{nx} \|<\infty.
	\end{equation}
	Now for $x\in X\setminus N$ we define $T_x$ on $H_{0x}$ by
	\begin{equation}
		T_xv_x=\lim_{k\to\infty} T_{n_kx}v_x
	\end{equation}
	for each $v\in H_0$. That limit exists by construction. 

	\begin{probleme}
		I suppose that this definition together with property \eqref{EqTnkxTvxHorsN} means that for every $w\in H_0$ and every $x\in X\setminus N$,
		\begin{equation}			\label{EqSurHzeroTwTxwx}
			(Tw)_x-T_xw_x=0.
		\end{equation}
	\end{probleme}

	It extends by continuity from $H_{0x}$ to $H_x$. The resulting operator is bounded because the sequence $T_{n_kx}$ is uniformly bounded.
	 
	Now we enlarge once again the set $N$ by the null set appearing in the definition of the essential supremum we find that $T_x$ is bounded for every $x\in X\setminus N$. All the work make $\{ T_x \}_{x\in X}$ a candidate decomposition of $T$. 

	In order to check that this actually is a decomposition of $T$, we have to prove that $(Tv)_x=T_xv_v$ for every $v\in H$ and almost every $x\in X$. We will prove that property by proving that the integral
	\begin{equation}
		\int_X\| (Tv)_x-T_xv_x \|\,d\mu(x)
	\end{equation}
	vanishes. For that, we choose $w\in H_0$ such that $\| w-v \|\leq\epsilon$ and, by virtue of \eqref{EqSurHzeroTwTxwx}, we add $T_xw_x-(Tw)_w$ in the integrand:
	\begin{equation}
		\begin{split}
			\int_X\| (Tv)_x-T_xv_x \|^2\,d\mu(x)	&= \int_X\| (Tv)_x -(Tw)_x+T_xw_x -T_xv_x \|^2\,d\mu(x)\\
								&\leq 2\int_X\| (Tv)_x-(Tw)_x\|^2\,d\mu(x)+\int_X\| T_xw_x-T_xv_x\|^2\,d\mu(x)\\
								&=2\| T(v-w) \|^2+2\| \tilde T(v-w) \|^2\\
								&=2\| T \|\,\| v-w \|^2 + 2\| \tilde T \|\,\| v-w \|^2\\
								&\leq \text{constant}\cdot \epsilon
		\end{split}
	\end{equation}
	where the operator $\tilde T$ is defined by $(\tilde Tw)_x=T_xw_x$.


	Thus the set of decomposable operators is strongly closed, so that it is a von~Neumann algebra. The same argument holds to prove that diagonal operators form a von~Neumann algebra too. We want now to prove that the commutant of diagonal operators is the set of decomposable. For that, it is sufficient to prove that every operator in the commutant of diagonals is decomposable. Since a von~Neumann algebra is generated by its projections , we have only to prove that every projection in the commutant of the diagonal is decomposable.

	Let $P$ be such a projection and enlarge $H_0$ in order to have $PH_0\subset H_0$. That remains a countable set because such an enlargement is $H'_0=H_0+PH_0$ for example. We choose a null set $N\subseteq X$ such that if $x\in X\setminus N$ then
	\begin{equation}
		(a_1v_1+a_2v_2)_x=a_1v_{1x}+a_2v_{2x}
	\end{equation}
	for every $v_1$ and $v_2$ in $H_0$ and $a_i\in\eQ[i]$. The set $H_{0x}=\{ v_x\tq v\in H_0 \}$ is dense in $H_x$. For $f\in L^{\infty}(X,\mu)$, we define the multiplication operator
	\begin{equation}
		(M_fv)_x=f(x)v_x,
	\end{equation}
	which is, by definition, a diagonal operator. Let $v\in PH_0$ and $w\in P^{\perp}H_0$, we have
	\begin{equation}
		\int_Xf(x)\langle v_x, w_x\rangle \,d\mu(x)= \int_X\langle f(x) v_x, w_x\rangle \,d\mu(x)=\langle M_fv, w\rangle .
	\end{equation}
	Since $P$ is in the commutant of diagonals, it commutes with $M_f$, so that $M_fv\in PH$ while $w\in P^{\perp}H_0$ and the latter product is thus zero: $\langle M_fv, w\rangle =0$. That proves that $x\mapsto\langle v_x, w_x\rangle $ is a function that integrates to zero when multiplicated\quext{My spelling corrector does not know that word. Bad word or bad corrector ?} by any $L^{\infty}$ function. That means in turn that $\langle v_x, w_x\rangle =0$ almost everywhere. We enlarge $N$ in such a way that
	\begin{equation}		\label{EqPerpPHPperpH}
		\{ v_x\tq v\in PH_0 \}\perp\{ w_x\tq w\in P^{\perp}H_0 \}
	\end{equation}
	for every $x\in X\setminus N$. Of course, $PH_0\oplus P^{\perp}H_0=H_0$, so that the direct sum of the two spaces of \eqref{EqPerpPHPperpH} is $H_{0x}$. Taking the strong closure,
	\begin{equation}
		\overline{ \overline{ \{ v_x\tq v\in PH_0 \} } }\oplus\overline{ \overline{ \{w_x\tq w\in P^{\perp}H_0 \}} }=H_x
	\end{equation}
	where the double bar denotes the strong closure.
	%
	%	If someone knows ho to produce a double bar in a more intrinsically way that double \overline{  }, I am open to learn.
	% 
	Now, for $x\in C\setminus N$, define $P_x\colon H_x\to H_x$, the projection onto $\overline{ \overline{ \{ v_x\tq v\in PH_0 \} } }$. By the same reasoning as for $T$ before, we prove that $\{ P_x \}$ decomposes $P$.
\end{proof}

\begin{lemma}		\label{LemMabelAstrDense}
If $M$ is an abelian von~Neumann algebra on a separable Hilbert space $H$, then $M$ has a strongly dense $C^*$-algebra $A$
\end{lemma}

\begin{proof}
No proof.
\end{proof}

\begin{theorem}		\label{ThoVNableHDiag}
If $M$ is an abelian von~Neumann algebra on a (as usual separable) Hilbert space $H$, then there is a decompositon of $H$ such that $M$ is the set of diagonal operators.
\end{theorem}

\begin{proof}
	Pick a $A\subseteq M$ as in the lemma \ref{LemMabelAstrDense}, and add an unit is needed. Then we have $A\simeq C(X)$ for some metrisable compact space $X$ by the
	\href{http://en.wikipedia.org/wiki/Gelfand_isomorphism}{Gelfand theorem} (see \cite{Landsman}). We can write 
	\begin{equation}
		H=\bigoplus_{k=1}^{\infty}H_k
	\end{equation}
	where $H_k$ is invariant under the action of $A$ and has a cyclic vector. Indeed, pick a vector $v_1$ in $H$ and define $H_1=Av_1$, then pick $v_2$ in the complement and continue. We have an isomorphism $H_k\simeq L^2(X,\mu_k)$ where $\mu_k$ is some probability measure by $v_k\mapsto 1$ and $Tv_k\mapsto\hat T$ where the hat denotes the Gelfand isomorphism.

	\begin{probleme}
		That gives an element of $L^2(X,\mu_k)$ for each vector inside $H_k$. But I do not see the isomorphism. For example a simple step function belongs to $L^2(X,\mu_k)$ and corresponds to which element of $H_k$ ?

		The map
		\begin{equation}
			\begin{aligned}
			 \psi\colon Av_1&\to L^2(X,\mu) \\ 
			   Tv_1&\mapsto \hat T 
			\end{aligned}
			\end{equation}
		(whose image is included in $L^2(X,\mu)$ because $X$ is compact, so that every continuous function is square integrable with respect to a probability measure) is injective because two different continuous functions cannot belong to the same class in $L^2(X,\mu)$. 

		For me, surjectivity is not clear (and even wrong) because there exists many elements in $L^2(X,\mu)$ who have no continuous representative. Do we have to game with limits and exploit the fact that $A$ is strongly closed ?

		\end{probleme}
	So we can assume that $A=C(X)$ and $H=\bigoplus_kL^2(X,\mu)$. Let 
	\begin{equation}
		\mu=\sum_{k=1}^{\infty}2^{-k}\mu_k
	\end{equation}
	which is still a probability measure, and define $H_x=l^2(\eN,\mu_x)$ where $\mu_x$ is the measure on $\eN$ defined by
	\begin{equation}
		\mu_x\big( \{ k \} \big)=\frac{ d\mu_k }{ d\mu }(x)
	\end{equation}
	by the Radon-Niked\'ym theorem. For recall, $d\mu_k/d\mu$ is the function on $X$ defined by the fact that $d\mu_k=(d\mu_k/d\mu)d\mu$ in the sense that
	\begin{equation}
		\int_Xfd\mu_k=\int_Xf\frac{ d\mu_k }{ d\mu }d\mu
	\end{equation}
	for every functions $f$ on $X$. Now for each $\varphi=(\varphi_1,\varphi_2,\ldots)\in H$, we define $\varphi_x\in H_x$ by
	\begin{equation}
	\begin{aligned}
	 \varphi_x\colon \eN&\to \eC \\ 
	   k&\mapsto \varphi_k(x). 
	\end{aligned}
	\end{equation}
	One has to show that the so defined $\varphi_x$ is actually an element of $l^2(\eN,\mu_x)$, that is 
	\begin{equation}		\label{EqSumVpNK}
		\sum_k| \varphi_k(x) |^2\frac{ d\mu_k }{ d\mu }(x)
	\end{equation}
	has to be finite. For, we have the computation
	\begin{equation}		\label{EqIntXsumnormVarPhi}
	\begin{split}
		\int_X\sum_k| \varphi_k(x) |^2\frac{ d\mu_k }{ d\mu }(x)\,d\mu(x)	
			&=\sum_k\int_X| \varphi_k(x) |^2\frac{ d\mu_k }{ d\mu }(x)\,d\mu(x)\\
			& = \sum_k\int_X| \varphi_k |^2\,d\mu_k(x)\\
			& = \sum_k\| \varphi_j \|^2\\
			& = \| \varphi \|^2.		
	\end{split}
	\end{equation}
	where, in the first line we permuted the sum and the integral using the monotone convergence theorem. The fact that integral \eqref{EqIntXsumnormVarPhi} is finite proves that the function \eqref{EqSumVpNK} has finite values almost everywhere, or 
	\begin{equation}
		\| \varphi_x \|^2_{l^2(\eN,\mu_x)}<\infty
	\end{equation}
	almost everywhere. Let us redefine $\varphi_x$ as zero for the $x$ where the former definition gives $\| \varphi_x \|^2_{l^2(\eN,\mu_x)}$. This is a redefinition over a null set.

	One can check that this construction provides a decomposition of $H$ for which $M$ is the algebra of diagonal operators.

	\begin{probleme}
	To be done\ldots 
	\end{probleme}
\end{proof}

Let $M$ be an abelian von~Neumann algebra of operators on $H$ and suppose that there are two decompositions $\{ H_x \}$ and $\{ H_y \}$ of $H$ using $M$ by theorem \ref{ThoVNableHDiag}. Let now 
\begin{equation}
	M_2=
\left\{ 
\begin{pmatrix}
  T	&		\\ 
  	&	T	
\end{pmatrix}
 \right\}\tq T\in M
\end{equation}
That von~Neumann algebra decomposes $H\oplus H$ into $\{ H_x \}\oplus\{ H_y \}$. The matrix
\begin{equation}
	S=
\begin{pmatrix}
  0	&	1	\\ 
  1	&	0	
\end{pmatrix}
\end{equation}
is decomposable because it belongs to the commutant of $M_2$. Thus it provides an unitary isomorphism of $H$ that applies $H_x$ on $H_y$.

\begin{proposition}		\label{PropNprimexxNprime}
	If $N$ lies in the commutant of $M$, there are von~Neumann algebras $N_x\subseteq\oB(H_x)$ for almost every $x$ such that
	\begin{enumerate}
		\item $N_x=\{ T_x\tq T\in N \}''$,
		\item $(N_x)'=(N')_x$ almost everywhere.
	\end{enumerate}
\end{proposition}

\begin{proof}
No proof.
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Decompositions of representations}
%---------------------------------------------------------------------------------------------------------------------------



Let $A$ be a separable $C^*$-algebra and $\pi\colon A\to \oB(H)$ be a representation of $A$ on a separable Hilbert space. We do not assume that $\pi$ is faithful.

\begin{lemma}		\label{LemHDecPipixxpi}
If $H$ is provided with a decomposition $\{ H_x \}$ and if $\pi(A)$ consists of decomposable operators, then there are representations $\pi_x\colon A\to \oB(H_x)$ such that $\pi(a)_x=\pi_x(a)$.
\end{lemma}

\begin{proof}
No proof.
\end{proof}

\begin{theorem}		\label{ThoRepDecSepIrrep}
	If $\pi\colon A\to \oB(H)$ is any representation of a separable $C^*$-algebra, then there is a decomposition of $H$ such that $\pi(A)$ consists of decomposable operators. There also exists a decomposition $\{ \pi_x \}$ of $\pi$ such that each $\pi_x$ is irreducible.
\end{theorem}

That theorem says that every representation decomposes into irreducible.

\begin{proof}

	We do not prove the first part, and suppose then that $\{ \pi_x \}$ is a decomposition given by lemma \ref{LemHDecPipixxpi}, so that $\pi_x(a)=\pi(a)_x$.

	Let $M$ be a maximal (Zorn's lemma) abelian von~Neumann subalgebra of $\big( \pi(A) \big)'$, and decompose $H$ so that $M$ is the algebra of diagonal operators. Now we consider $N$, the von~Neumann algebra generated by $M$ and $\pi(A)$. An element in $N'$ belongs to $\pi(A)'$ and commutes with $M$ which is maximal. Thus $N'=M$. 

	By the property of the decomposition $\pi_x$, an element of $\pi_x(A)'$ has to commute with all $M$, so that
	\begin{equation}
		\pi_x(A)'=(N_x)'=(N')_x=M_x=\eC\mtu,
	\end{equation}
	and by Schur's lemma, the representation $\pi_x$ is irreducible almost everywhere.
\end{proof}

As an example, take $A=C^*(F_2)$ where $F_2$ is the free group with two generators and $A$ is formed by taking all the linear combination and then the closure as $C^*$-algebra. One can show that
\begin{enumerate}
	\item There are two decompositions of the regular representation $\pi$ of $A$ on $H=l^2(F_2)$ that we denote by $\{ H_x \}$ and $\{ H_y \}$. These decompositions are \emph{a priori} built on different measured spaces.
	\item All the representations in $\{ \pi_x \}\sqcup\{ \pi'_y \}$ are irreducible and mutually inequivalent.
\end{enumerate}
So the decomposition in irreducible representations is not unique at all, in contrast to the group representation case. The point is that the regular representation of $C^*(F_2)$ is a factor, while the following theorem only assures unicity of decomposition into factors.

\begin{theorem}
	Let $\pi\colon A\to \oB(H)$ be a representation of the $C^*$-algebra $A$. There is an essentially unique decomposition of $H$ such that 
	\begin{enumerate}
		\item the representation $\pi(A)$ consists of decomposable operators,
		\item the representations $\pi_x$ are factors representations for almost every $x$.

		By ``essentially unique'', one means that if 
		\begin{align}
			\big( X,\mu,\{ H_x \}, H\to\Gamma\{ H_x \} \big)&\text{and}&\big( X',\mu',\{ H'_x \}, H\to\Gamma\{ H'_x \} \big)
		\end{align}
		are two decompositions, there exists a map $X\to X'$ which is almost everywhere an equivalence of measurable spaces. That is it maps $\mu$ to a measure which is mutually absolutely continuous with $\mu'$, and an unitary isomorphism $H_x\to H'_x$ defined for almost every $X$ which maps $v_x$ to $v'_x$ where $v'_x$ is the decomposition of $v$ with respect to the decomposition $\{ H'_x \}$.
	\end{enumerate}
\end{theorem}

\begin{proof}
	Let us prove the existence part of the theorem For we proceed as in the proof of theorem \ref{ThoRepDecSepIrrep}, but we take $M=\pi(A)''\cap\pi(A)'$, this is the center of the von~Neumann algebra generated by $\pi(A)$. Using proposition \ref{PropNprimexxNprime}, we find
	\begin{equation}
		\pi_x(A)''\cap\pi_x(A)'=\big( \pi(A)''\cap\pi(A)' \big)_x=\eC\mtu.
	\end{equation}
	That shows that $\pi_x(A)$ is a factor.
\end{proof}

A $C^*$-algebra is \defe{liminal}{liminal $C^*$-algebra } if for every irreducible representation $\pi\colon A\to \oB(H)$, we have $\pi(A)=\oK(H)$, the space of compact operators on $H$.

\begin{theorem}
If $G$ is a semisimple Lie group, then $C^*(G)$ is liminal.
\end{theorem}
\begin{proof}
No proof.
\end{proof}

\begin{theorem}
If $A$ is a liminal $C^*$-algebra, then every factor representation is of type I.
\end{theorem}

\begin{theorem}
	If $\pi$ is any representation of a liminal $C^*$-algebra on a separable Hilbert space, then there is a decomposition of $H$ such that 
	\begin{enumerate}
		\item the space $H_x$ carries a representation which is a factor of type I,
		\item $H_x=H_{\pi_x}\otimes L_x$ where $H_{\pi_x}$ is an irreducible representation of $A$, all mutually inequivalent and $L_x$ is some Hilbert space which says the ``multiplicity'' of the representation $\pi_x$ inside $\pi$.
	\end{enumerate}
	That decomposition is essentially unique.
\end{theorem}

\begin{proof}
No proof.
\end{proof}

\begin{lemma}
Every irreducible representation of $A_1\otimes A_2$ with both $A_i$ being liminal is a tensor product of irreducible representations of $A_1$ and $A_2$.
\end{lemma}

Now take an unimodular group $G$ such that $C^*(G)$ is liminal. One knows that the von~Neumann algebras generated by the left and right regular representations are mutually commutant. We consider the bi-regular representation $G\times G$ on $L^2(G)$. The commutant of that representation is equal to the center of the von~Neumann algebra generated by the two regular representation and is in particular abelian.

Using the lemma, the space $ L^2(G)$ decomposes into representations $H_{\pi\tau}=H_{\pi}\otimes H_{\tau}$ of $G\times G$ where $\pi$ and $\tau$ are irreducible representations. From the unimodular assumption, the symmetry $f(g)\to f(g^{-1})$ is an isometry that intertwines left and right regular representations. Notice that a function can be seen as a vector on $L^2(G)$ as well as as an operator over $L^2(G)$ by the convolution. Thus we turn $H_{\pi\tau}$ into a $*$-algebra by the multiplication $H_{\pi\tau}\otimes H_{\pi\tau}\tau H_{\pi\tau}$.

We denote by $\hat G$\nomenclature{$\hat G$}{Set of irreducible representations of the group $G$} the set of irreducible representations of $G$

\begin{theorem}
	Let $G$ be an unimodular locally compact liminal group. There is an unique measure on $\hat G$, the \defe{Plancherel measure}{plancherel measure}, denoted by $\mu$ such that for every $f\in L^1(G)\cap L^2(G)$ (as vector in $L^2(G)$ or as operator by involution),
	\begin{equation}
		\| f \|^2_{L^2(G)}=\int_{\hat G}\| \pi(f) \|^2_{HS}\,d\mu(\pi)
	\end{equation}
	where $\| . \|_{HS}$ denotes the Hilbert-Schmidt operator norm. Moreover we have
	\begin{equation}
		\pi(f)=\int_G f(g)\pi(g)\,dg.
	\end{equation}
\end{theorem}

That theorem has to be compared to the Fourier theory for abelian groups like $\eR$ or $S^1$, in particular the \href{http://en.wikipedia.org/wiki/Parseval's_identity}{Parseval equality}. This has also to be compared with the following theorem.

\begin{theorem}[Peter-Weyl]
If $G$ is a compact group, then
\begin{equation}
	\| f \|_{L^2(G)}^2=\sum_{\hat G}\frac{ \dim(\pi) }{ \volume(G) }\| \pi(f) \|^2_{HS}
\end{equation}
where the ration $\dim(\pi)/\volume(G)$ is the Plancherel measure made explicit in the compact case.
\end{theorem}


%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
					\section{Index theory}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


One speaks about index and subfactors in \cite{JonesVN,ConnesNCG,JonesSunder}.

%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Introduction}
%---------------------------------------------------------------------------------------------------------------------------



Let $M$ be a type $II_1$ factor, which, thus, possesses an unique normal, tracial, normalized faithful state. We can assign a dimension to every modules over $M$ by theorem \ref{ThoPropDimiM}. In particular, $M$ being an algebra of operators on the Hilbert space $\hH$, the space $\hH$ is a $M$-module and we can consider the number
\begin{equation}
	\dim_M(\hH).
\end{equation}
Following the cases, that can be any number in $]0,\infty[$. Indeed, taking any $v\in\hH$, we have the $M$-module map 
\begin{equation}
\begin{aligned}
 \rho\colon M&\to \hH \\ 
   T&\mapsto Tv ,
\end{aligned}
\end{equation}
so that by lemma \ref{LemHinjectifHdimdim}, we have
\begin{equation}
	\dim_M(\hH)\geq\dim_MM.
\end{equation}
But we saw on page \pageref{subsubsecExemDimMMMod} that $\dim_MM=\tr(\mtu)$, see definition \eqref{EqPreDefDimModuleRA} and bellow. We deduce that $\dim_M\hH\geq \tr(\mtu)$, which can be any non vanishing positive real number.

Let $N\subseteq M\subseteq \oB(\hH)$ be a subfactor, i.e. that $N$ is a factor in $\oB(\hH)$ and $N\subseteq M$. For the same reason as before, $\dim_N(\hH)\in]0,\infty[$. We consider the ratio
\begin{equation}
	[M:N]=\frac{ \dim_N(\hH) }{ \dim_M(\hH) }
\end{equation}
that is called the \defe{index}{index}\nomenclature{$[M:N]$}{The index of two modules}.

The theorem that we are intend to prove is the following.
\begin{theorem}[Jones]
If $[M:N]<4$, then $[M:N]=4\cos^2(\pi/n)$ for some $n<2$.
\end{theorem}

\begin{proof}
No proof.
\end{proof}

\begin{center}
\begin{tabular}{ccr}
	$n$		&	$4\cos^2(\pi/n)$\\
\hline
	$2$		&	$0$\\
	$3$		&	$1$\\
	$4$		&	$2$\\
	$5$		&	$2.618$		& the golden ratio\\
	$6$		&	$3$\\
	\vdots		&	\vdots	
\end{tabular}
\end{center}
In the dots, we have an increasing sequence of numbers bigger than $3$ that converges to $4$.

%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Example}
%---------------------------------------------------------------------------------------------------------------------------


Let $G$ be a discrete group with infinite conjugacy classes and $H$, a subgroup which has infinite conjugacy classes for its own right. Consider $M=M(G)\subseteq\oB\big(l^2(G))$ and $N=M(H)\subseteq\oB\big( l^2(H) \big)$. By simple inclusion of $H$ in $G$, we have $M(H)\subseteq\oB\big( l^2(G) \big)$ too.

As defined in subsection \ref{sssOnePartCaseMG}, the von~Neumann algebra $M(H)$ is generated by the operators $\mU_h$ with $h\in H$. We already proved in proposition \ref{ProplDeuxGFGP}\label{PglDeuxGFGPutiliseIci} that $l^2(G)$ is a finitely generated projective module over $M(G)$, so that one can address the question of $\dim_{M(G)}\big( l^2(G) \big)$ using the decomposition given by corollary \ref{CorEfgpFssIsom}:
\begin{equation}
	l^2(G)=\Cl_{l^2(G)}\big( M(G) \big)\oplus l^2(G)/M(G).
\end{equation}
On the one hand, by proposition \ref{PropDimClEgalDim}, we have $\dim\Big( \Cl_{l^2(G)}\big( M(G) \big) \Big)=\dim\big( M(G) \big)$, and on the other hand, one can prove that $l^2(G)/M(G)$ is a torsion, so that
\begin{equation}		\label{EqdimmGlDeuxGbig}
	\dim_{M(G)}\big( l^2(G) \big)=\dim_{M(G)}\big( M(G) \big)=1
\end{equation}
when a correct choice of normalisation is done.

\begin{probleme}
Is it correct that the latter dimension is in fact the trace of $\mtu$ on $M(G)$ which has to be normalised ?
\end{probleme}

Let us now consider $g_1,\ldots,g_n$ be representatives of the classes of $G/H$ and look at the decomposition
\begin{equation}
	l^2(G)=l^2(Hg_1)\oplus\ldots\oplus l^2(Hg_n).
\end{equation}
Since $l^2(Hg_i)$ is a submodule of $l^2(H)$, each of $\dim_n\big( l^2(G) \big)$ lies in the same case as equation \eqref{EqdimmGlDeuxGbig}, so that
\begin{equation}
	\dim_N\big( l^2(G) \big)=n.
\end{equation}
Thus $[M:N]=n$.

One can explicitly construct examples of index for every real bigger than $4$. 

Let $M\subseteq\oB(\hH)$ be a von~Neumann algebra and form $M^{(\infty)}\subseteq\oB(\hH\oplus\ldots\oplus\hH\oplus\ldots)$,
\begin{equation}
	M^{(\infty)}=\big\{  (T,T,\ldots)\tq T\in M  \big\}.
\end{equation}
Since $M^{(\infty)}$ does not contains more information than $M$ itself, we want to be able to say that they are the same von~Neumann algebra. The interest of ultraweak topology described in subsection \ref{subSecUltraWtopol} is that if we consider both $M$ and $M^{(\infty)}$ with the ultraweak topology, then they are homeomorphic in a natural way. 


%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Isomorphisms of abstract von~Neumann algebras}
%---------------------------------------------------------------------------------------------------------------------------

If $M\subseteq\oB(\hH)$ is an ultraweakly closed subspace (what a von~Neumann algebra always is), then the Hahn-Banach theorem applies and in particular, every von~Neumann algebra is the dual of a space.

A positive linear map $\Phi$ between von~Neumann algebras is \defe{normal}{normal!map between von~Neumann algebras} if
\begin{equation}
	\Phi(\bigvee_{\alpha}P_{\alpha})=\bigvee_{\alpha}\Phi(P_{\alpha})
\end{equation}
for every increasing net of projections. A net of projections being said \defe{increasing}{increasing!net of projections} when $\alpha>\beta$ implies $P_{\alpha}>P_{\beta}$. An example of a normal map is the trace of a type $II_1$ factor.

\begin{theorem}		\label{ThoDixLinVNanormifffuwc}
A positive linear functional on a von~Neumann algebra is normal if and only if it us ultraweakly continuous.
\end{theorem}
A proof can be found in \cite{DixDecompBk}.

\begin{probleme}
It is the right citationm, isn't ?
\end{probleme}

\begin{theorem}				\label{ThoPhiEquivuwcvna}
Let $\Phi\colon M\to \oB(\hH)$ be a $*$-homomorphism from a von~Neumann algebra into $\oB(\hH)$. The the following are equivalent:
\begin{enumerate}
\item\label{ItemPhiEquivuwcvnai} $\Phi$ is ultraweakly continuous,
\item\label{ItemPhiEquivuwcvnaii}  $\Phi$ is normal,
\item\label{ItemPhiEquivuwcvnaiii}  $\Phi(M)$ is a von~Neumann algebra.
\end{enumerate}
\end{theorem}
Notice that we do not suppose $M$ to be a von~Neumann algebra acting on the Hilbert space $\hH$.

\begin{proof}
The implication \ref{ItemPhiEquivuwcvnaiii} $\Rightarrow$ \ref{ItemPhiEquivuwcvnaii} is proved by using the theorem \ref{ThoDixLinVNanormifffuwc}. The implication \ref{ItemPhiEquivuwcvnaii} $\Rightarrow$ \ref{ItemPhiEquivuwcvnai} is only the fact that ultraweak continuity is defined in terms of linear functionals.

The difficult part is to prove that \ref{ItemPhiEquivuwcvnai} implies \ref{ItemPhiEquivuwcvnaiii}. Since $\Phi(M)$ is a $*$-algebra, proving that it is strongly closed proves that it is a von~Neumann algebra. So, let us suppose $T$ to be in the strong closure of $\Phi(M)$. By Kaplansky density theorem \ref{ThoKaplanskyDensity}, there exists a net $T_{\alpha}\in\Phi(M)$ with $\sup\| T_{\alpha} \|<\infty$ and
\begin{equation}
	T=\slim T_{\alpha}=\slim \Phi(S_{\alpha})
\end{equation}
for some $S_{\alpha}$. Since $\Phi$ is isometric, the set $\{ S_{\alpha} \}$ is uniformly bounded: $\| S_{\alpha} \|<\infty$. Thus, using the Banach-Alaogu theorem \ref{ThoBanachAlaoglu}, and taking a subnet, we can assume that there is a $S\in M$ such that
\begin{equation}
	S=\uwlim S_{\alpha}.
\end{equation}
Since $\Phi$ is ultraweakly continuous by assumption, we have $\Phi(S)=\uwlim\Phi(S_{\alpha})$. Since the limit $T=\slim T_{\alpha}$ exists, the same exists in the weak topology (and is equal), thus $T=\Phi(S)$, which proves that $\Phi(M)$ is strongly closed.
\end{proof}

So if a von~Neumann algebra is algebraically realised as two different algebras of operators on two different Hilbert spaces, the two realisations are homeomorphic. For short, we say that $*$-isomorphisms of von~Neumann algebras correspond to weakly continuous maps between realisations of them.

Remark that a map $\Phi$ which fulfils the theorem \ref{ThoPhiEquivuwcvna} is automatically isometric because $\| T \|$ is the spectral radius of $| T |$ while the spectral radius (which is a purely algebraic notion) does not change when we consider $T$ as an operator acting on one Hilbert space or an other. So, the map $\Phi$ preserves the $C^*$-algebra structure.

Let $M$ be a finite factor. We denote by $L^2(M)$\nomenclature{$L^2(M)$}{Hilbert space of the standard form for a finite factor}\label{PgLdM} the completion of $M$ in the norm derived  from the inner product
\begin{equation}
	\langle T_1, T_2\rangle =\tau(T_1T_2^*).
\end{equation}
This is the GNS construction applied to the tracial state $\tau$. The \defe{standard form}{standard!form of a von~Neumann algebra} of the finite factor $M$ is the realisation of $M$ as left multiplication operators on $L^2(M)$. The image is a von~Neumann algebra because the representation is normal and faithful. 


%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Index of finite subfactors}
%---------------------------------------------------------------------------------------------------------------------------

We say that the vector $v\in L^2(M)$ is \defe{bounded}{bounded!element of $L^2(M)$} by the positive real $K$ if for every projection $P\in M$, the condition
\begin{equation}
	\| Pv \|^2_{L^2(M)}\leq K\tau(P).
\end{equation}

\begin{lemma}
An element $v\in L^2(M)$ belongs to $M$ if and only if it is bounded.
\end{lemma}
\begin{proof}
No proof.
\end{proof}

We consider the map
\begin{equation}
\begin{aligned}
 J\colon L^2(M)&\to L^2(M) \\ 
   T&\mapsto T^*. 
\end{aligned}
\end{equation}
\emph{A priori}, that is only defined on $M$, but it is an isometry because
\begin{equation}
	\| T \|=\tr(TT^*)=\tr(T^*T)=\| T^* \|.
\end{equation}
So it extends to the completion $L^2(M)$.

\begin{lemma}
We have
\begin{equation}
	M'=JMJ
\end{equation}
in the standard form.
\end{lemma}
Notice that operators in $JMJ$ are operators of right multiplication on $M$ because $(JTJ)S=JT(S^*)=J(TS^*)=ST^*$ while the elements of $M$ are left multiplications, so that it is clear that $JMJ\subseteq M'$.

\begin{proof}
No proof.
\end{proof}

Let $M_0$ be a subfactor of a finite factor $M_1$. We define the \defe{index}{index}\nomenclature{$[M_1:M_0]$}{Index of a subfactor.}
\begin{equation}
	[M_1:M_0]=\dim_{M_0}\big( L^2(M_1) \big).
\end{equation}

\begin{theorem}
One has
\begin{equation}
	[M_1:M_0]=\dim_{M_0}(M_1).
\end{equation}
and moreover
\begin{equation}
	[M_1:M_0]=\frac{ \dim_{M_0}(\hH) }{   \dim_{M_1}(\hH) }
\end{equation}
 if $M_1$ is represented on the Hilbert space $\hH$.
\end{theorem}
\begin{proof}
No proof.
\end{proof}

Suppose given $M_1$ and a finite subfactor $M_0$ and suppose $[M_1:M_0]<\infty$. Since $M_0$ is a subfactor of $M_1$, we can see $M_0'$ as subset of $\oB\big( L^2(M_1) \big)$. If $M_1'$ is not finite, then there is a part of $L^2(M_1)$ which is identified with $L^2(M_1)$ as $M_0$-module. That part has obviously the same dimension as the whole $L^2(M_1)$ (because the module structure is the same). Thus in this case, $L^2(M_1)$ contains infinitely many submodules with all the same dimension, so that $\dim_{M_0}\big( L^2(M_1) \big)=\infty$, which contradicts the assumption. We deduce that
\begin{equation}
	M_0'\subseteq\oB\big( L^2(M_1) \big)
\end{equation}
is a finite von~Neumann algebra. We consider 
\begin{equation}
	P_1\colon L^2(M_1)\to L^2(M_1)
\end{equation}
be the orthogonal projection onto $L^2(M_0)\subseteq L^2(M_1)$. 


\begin{lemma}		\label{LemTMunPTTPiffTMzero}
If $T\in M_1$, then $TP_1=P_1T$ if and only if $T\in M_0$.
\end{lemma}

\begin{proof}
It $T\in M_0$, we have
\begin{equation}		\label{EqTPPTPTProj}
	TP_1=P_1TP_1.
\end{equation}
Taking the adjoint of that equation, $P_1T^*=P_1T^*P_1$, and using the relation \eqref{EqTPPTPTProj} for $T^*$, we find $P_1T^*=T^*P_1$ which holds for every $T\in M_0$. Thus we have
\begin{equation}
	TP_1=P_1T
\end{equation}
for every $T\in M_0$.

For the reverse sense, equality $TP_1=P_1T$ is an equality of operators on $M_1$. Let us apply it to $\mtu\in M_1$. Since $\mtu$ belongs to $M_0$ too (every von~Neumann algebra contains the unit), $P_1(\mtu)=\mtu$ and we stay with $T=P_1T$, so that $T\in M_0$. 
\end{proof}

Let now $M_2$ be a von~Neumann algebra generated by $M_1$ and $P_1$
\begin{equation}
	M_2=\{ M_1,P_1 \}''.
\end{equation}
The properties of $M_1$, $P_1$ and $M_2$ are summarized in the following theorem.
\begin{theorem}
	If $[M_1:M_0]<\infty$, then
\begin{enumerate}
\item $M_2$ is a finite factor, in particular it has a unique normal faithful trace $\tau$,
\item $[M_2:M_1]=[M_1:M_0]$,
\item $\tau(P_1)=[M_1:M_0]^{-1}$.
\end{enumerate}
\end{theorem}
\begin{proof}
No proof.
\end{proof}

The von~Neumann algebra $M_2$ was created from $M_0$ and $M_1$, while the theorem shows that $M_1$ has the same properties in $M_2$ than $M_0$ in $M_1$, so that one can redo the construction starting from $M_2$ and $M_1$ instead of $M_0$ and $M_1$ to build $M_3$ and $P_2$. The index does not change and the projection $P_2$ still has the same trace.

%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Subfactors}
%---------------------------------------------------------------------------------------------------------------------------

\begin{probleme}
Je pense qu' partir d'ici, j'ai invers $M_0$ et $M_1$ partout jusqu' la subsection \ref{SubSecPropSeqMO}.
\end{probleme}

Let $M_1\subseteq M_0$ be a subfactor of the finite factor $M_0$, and $P\colon L^2(M_0)\to L^2(M_0)$ be the projection onto $L^2(M_1)$. Notice that $L^2(M_1)\subseteq L^2(M_0)$ because the trace on $M_1$ is the restriction to the one of $M_0$ from unicity. Now we consider $\langle M_0, P\rangle $\nomenclature{$\langle M_0, P\rangle $}{The von~Neumann algebra generated by $M_0$ and $P$}, the von~Neumann algebra generated by $M_0$ and $P$.

\begin{lemma}		\label{LemPMNinclu}
We have $P(M_0)\subseteq M_1$.
\end{lemma}
\begin{proof}
No proof.
\end{proof}

\begin{proposition}		\label{PropPropMappMN}
The map
\begin{equation}
\begin{aligned}
p \colon M_0&\to M_1 \\ 
   T&\mapsto P(T). 
\end{aligned}
\end{equation}
satisfies
\begin{enumerate}
\item\label{ItemPropMappMNi} $p(T^*)=p(T)^*$,
\item\label{ItemPropMappMNii}$p(T^*T)\geq 0$,
\item\label{ItemPropMappMNiii} $p(T^*T)=0$ if and only if $T=0$,
\item\label{ItemPropMappMNiv} $p(S_1TS_2)=S_1p(T)S_2$ for every $S_1$ and $S_2$ in $M_1$.
\end{enumerate}
for every $T\in M_0$.
\end{proposition}

\begin{proof}
The point \ref{ItemPropMappMNi} is the fact that $M_1$ is closed under the involution. The point \ref{ItemPropMappMNii} comes form lemma \ref{LemPMNinclu} and the positivity property in $M_1$. For the point \ref{ItemPropMappMNiii}, remark that $\tr\big( p(T) \big)=\tr(T)$ because $p(\mtu)=\mtu$, while by unicity up to normalisation, the trace is determined by its value on~$\mtu$.
\end{proof}
 
A basic implication if \ref{ItemPropMappMNi} is that 
\begin{equation}
	PJ=JP.
\end{equation}


\begin{lemma}		\label{LemPTPpTPopLdeux}
If $T\in M_0$, then 
\begin{equation}
	PTP=p(T)P
\end{equation}
as operators on $L^2(M_0)$.
\end{lemma}

\begin{proof}
No proof.
\end{proof}

\begin{lemma}		\label{LemNMpPNcup}
If $M_1\subseteq M_0$ is a subfactor of the finite factor $M_0$ and if $P$ is the projection onto $L^2(M_1)$ (as operator in $L^2(M_0)$), then
\begin{equation}
	M_1=\{ M_0'\cup P \}',
\end{equation}
and
\begin{equation}
	M_1'=\{ M_0'\cup P \}''
\end{equation}
as consequence.
\end{lemma}

\begin{proof}
First, every element of $\{ M_0'\cup P \}'$ has to commute with $M_0'$ and then to belongs to $M_0''=M_0$. But we proved in lemma \ref{LemTMunPTTPiffTMzero} that when $T\in M_0$ and $TP=PT$, then $T\in M_1$. That proves that $\{ M_0'\cup P \}'=M_1$.
\end{proof}

As other consequence of lemma \ref{LemTMunPTTPiffTMzero}, we have that, when $T\in M_1$, the operator $PT\colon S\mapsto P(TS)\in L^2(M_0)$ is equal to the operator $S\colon \mapsto TP(S)$, in other words,
\begin{equation}		\label{EqPTSeqalTPS}
	P(TS)=TP(S)
\end{equation}
for every $T\in M_1$ and $S\in M_0$.

\begin{lemma}		\label{LemMOJNJequal}
We have
\begin{equation}		\label{EqLemMPJNJequal}
	\langle M_0, P\rangle =JM_1'J,
\end{equation}
and as consequence, $\langle M_0, P\rangle $ is a finite factor.
\end{lemma}

\begin{proof}
First note that the commutant of a factor is a factor, so that $M_1'$ is a factor and $JM_1'J$ is a factor because it is algebraically isomorphic to the factor $M_1'$. Thus the lemma proves that the left hand side of \eqref{EqLemMPJNJequal} is in particular a finite factor.

Let us now prove the equality \eqref{EqLemMPJNJequal}. One needs to show that $J\langle M_0, P\rangle J=M_1'$. The commutant of the left multiplication action is the right one, while the left action of $JTJ$ is the right action of $T$, so one has $JM_0J=M_0'$. Since $JPJ=P$, it is sufficient to show that
\begin{equation}
	\langle M_0', P\rangle =M_1'.
\end{equation}
The von~Neumann algebra generated by $M_0'$ and $P$ is $\{ M_0',P \}''$ that is equal to $M_1'$ by lemma \ref{LemNMpPNcup}.
\end{proof}
So $\langle M_0, P\rangle $ is a factor and it is finite when $M_1'$ is finite, which happens when $[M_0:M_1]<\infty$. Assuming that finiteness, we thus have a trace $\tr\colon \langle M_0, P\rangle \to \eC$ which extends the trace on $M_0$ (by uniqueness).

Notice that, as particular case of equation \eqref{EqLemMPJNJequal} when $M_1=M_0$, we have $P=\id$ and 
\begin{equation}
	M_0=JM_0'J.
\end{equation}
That gives us an action of $M_0'$ on $L^2(M_0)$ by
\begin{equation}		\label{EqScdotTTSJT}
	S\cdot T=(JSJ)T
\end{equation}
when $S\in M_0'$ and $T\in M_0$. 

\begin{proposition}		\label{PropdimMQhHQDIMMhH}
If $M_0$ is any finite factor acting on $\hH$ and if $Q\in M_0'$, then $Q\hH$ is invariant by $M_0$, and
\begin{equation}
	\dim_{M_0}(Q\hH)=\tr(Q)\dim_{M_0}(\hH)
\end{equation}
where $Q\hH$ is seen as module over $M_0$ (because of its invariance).
\end{proposition}

\begin{proof}
First, notice that a finite factor always has an unique trace. If $Q=0$ or $Q=\mtu$, the claim is obvious. Suppose now that $\tr(Q)=r/s$, that is a rational number.

In that case, we have
\begin{equation}		 \label{EqQhQhHHHeqMmod}
	\underbrace{Q\hH\oplus\ldots\oplus Q\hH}_{\text{$s$ times}} =\underbrace{\hH\oplus\ldots\oplus \hH}_{\text{$r$ times}} 
\end{equation}
\begin{probleme}
I can understad that in the setting of the fractional dimensions as described in subsection \ref{SubSecRationalRealDim}, but there, we have the assumption of no minimal projection.
\end{probleme}
First, notice that the trace of the identity over $Q\hH$ is the trace of $Q$ on $\hH$. Indeed, let $\{ v_i \}$ be an Hilbertian basis of $Q\hH$ and $\{ w_k \}$ be a one of $Q^{\perp}\hH$. Then
\begin{equation}	
	\tr(Q)=\sum_i\langle v_i, Qv_i\rangle +\sum_k\langle w_k, Qw_k\rangle =\sum_i\langle v_i, v_i\rangle =\tr(\mtu_{Q\hH}).
\end{equation}
Thus, by additivity, 
\begin{equation}
	\tr(\mtu_{Q\hH\oplus\ldots\oplus Q\hH})=s\tr(Q)=r.
\end{equation}
On the other hand, $\tr(\mtu_{\hH\oplus\ldots\oplus\hH})=r\tr(\mtu_{\hH})=r$. So the identity over these two $M_0$-modules are the same.
\begin{probleme}
Is that enough to deduce that these are isomorphic as $M_0$-modules ?
\end{probleme}
Taking the dimension of both sides of \eqref{EqQhQhHHHeqMmod}, we find $s\dim_{M_0}(Q\hH)=r\dim_{M_0}(\hH)$, which proves the statement in the case of $\tr(Q)\in\eQ$.

Now, the functions $\dim_{M_0}(Q\hH)$ and $\tr(Q)\dim_{M_0}(\hH)$ are increasing functions of $\tr(Q)$ that coincide on $\eQ$. Thus they are equal on $\eR$.

\end{proof}



\begin{proposition}		\label{ProptrPTMNtrT}
We have the formula
\begin{equation}		\label{EqClaimLemPTfracMNtrT}
	\tr(PT)=\frac{1}{ [M_0:M_1] }\tr(T)
\end{equation}
for every $T\in M_0$.
\end{proposition}


\begin{proof}
We have $\tr(PT)=\tr(PPT)=\tr(PTP)=\tr\big( p(T)P \big)$ because of lemma \ref{LemPTPpTPopLdeux}. It is sufficient to prove the claim \eqref{EqClaimLemPTfracMNtrT} for $T\in M_1$ because when $S\in M_0$, we would have $\tr(PS)=\tr\big( p(S)P \big)=\tr(S)/[M_0:M_1]$ because $p(S)\in M_1$. Let thus $T\in M_1$ and consider the map
\begin{equation}
	T\mapsto \tr(PT)
\end{equation}
where $PT$ is considered as operator on $L^2(M_0)$. Thanks to \eqref{EqPTSeqalTPS}, this is a (normal faithful) trace on $M_0$. So that must be a multiple of the trace on $M_0$, namely there exists a $\tau\in\eC$ such that $\tr(PT)=\tau\tr(T)$. Taking that equality with $T=\mtu$ shows that $\tau=\tr(P)$. Using proposition \ref{PropdimMQhHQDIMMhH}, we have thus
\begin{equation}
	\dim_{M_1}\big( P\cdot L^2(M_0) \big)=\tr(P)\dim_{M_0}\big( L^2(M_0) \big),
\end{equation}
but, as $M_0$-module, we have $P\cdot L^2(M_0)=L^2(M_1)$ by definition of $P$, so we have
\begin{equation}
	1=\tr(P)\cdot \dim_{M_1}\big( L^2(M_0) \big).
\end{equation}

\end{proof}


The set of expressions 
\begin{equation}
	T_0+\sum_{j=1}^nT_{j_1}PT_{j_2}
\end{equation}
with $T_0$, $T_{j_1}$ and $T_{j_2}$ in $M_0$ is a $*$-algebra. Indeed, in the multiplication of two such expressions, we get monomials of the form
\begin{equation}
	T_1\underbrace{PT_2 P}_{=p(T_2)P}T_3=\underbrace{T_1p(T_2)}_{\in M_0}PT_3.
\end{equation}
By the double commutant theorem, the von~Neumann algebra $\langle M_0, P\rangle $ is the strong closure of such expressions, and
\begin{equation}
	\tr(T_1PT_2)=\tr(PT_2T_1)=\frac{1}{ [M_0:M_1] }\tr(T_1T_2)
\end{equation}
by proposition \ref{ProptrPTMNtrT}. Thus we have an explicit formula for the trace on $\langle M_0, P\rangle $ from the trace over $M_0$.

\begin{lemma}		\label{lemPhHPNPfrac}
If $P\in M_1$, then we have
\begin{equation}
	\dim_{PM_1P}( P\hH)=\frac{1}{ \tr(P) }\dim_{M_1}(\hH),
\end{equation}
but $P\hH$ is no more a $M_1$-module.
\end{lemma}

\begin{proof}
Let $\modE$ be any $M_1$-module. Since $P\modE$ is a $PM_1P$-module, we can define $\dim^{(P)}(\modE)$ by
\begin{equation}
	\dim^{(P)}(\modE)=\dim_{PM_1P}(P\modE).
\end{equation}
That defines a dimension function on the $M_1$-modules, which is thus a multiple of the standard one. We know that, as $M_1$-module, $M_1P$ as dimension $\tr(P)$, so that the proportionality factor can be fixed on $M_1P$.

\begin{probleme}
	That proof is not complete.
\end{probleme}
\end{proof}

Let take $M_1=\eM_3(\eC)$ and $\hH=\eC^3$ as example. Each column of $a\in M_1$ is an element of $\eC^3$, so $M_1$ is three copies of $\hH$ and, as left module, we have $\hH\oplus\hH\oplus\hH=N$, and $\dim_{M_1}(\hH)=1/3$. Let
\[ 
	P=
\begin{pmatrix}
  1	&		&	\\ 
  	&	0	&	\\ 
 	&		& 0	  
\end{pmatrix}.
\]
We have $P\hH\simeq \eC$, and $PM_1P=\eC$ (the upper left element of the matrix). Thus if we have $\tr(P)=1/3$, we conclude by the lemma \ref{lemPhHPNPfrac} that $\dim_{PM_1P}(P\hH)=1$.

\begin{lemma}
We have
\begin{equation}
	\dim_{M_1}(\hH)\dim_{M_1'}(\hH)=1
\end{equation}
if $M_1$ and $M_1'$ are finite factors.
\end{lemma}

\begin{proof}
Let us first check for $\hH=L^2(M_1)$. The action of $M_1'$ on $L^2(M_1)$ is given by \eqref{EqScdotTTSJT}, so we have $\dim_{M_1'}\big( L^2(M_1) \big)=\dim_{JM_1J}\big( L^2(M_1) \big)$, so that the action of $M_1'$ on $L^2(M_1)$ is conjugate of the one of $M_1$. That proves the lemma in the case where $\hH=L^2(M_0)$.

\begin{probleme}
Pourquoi ? Cela est fait dans la proposition \ref{PropDimIIun}. Et je crois que du ct de cette proposition, on trouve pas mal de rponses  pas mal de questions ici.
\end{probleme}

\end{proof}

\begin{corollary}
We have
\begin{equation}
	[M_0:M_1]=[M_1':M_0']
\end{equation}
when $M_0\in\oB(\hH)$ is a factor of type $II_1$ and $M_1$ is a subfactor of $M_0$.
\end{corollary}
\begin{proof}
No proof.
\end{proof}

\begin{theorem}
We have
\begin{equation}
	[ \langle M_0, P\rangle :M_0 ]=[M_0:M_1]
\end{equation}
under the same assumptions.
\end{theorem}

\begin{proof}
If $\modE$ is any representation of $\langle M_0, P\rangle $, we have the formula
\begin{equation}	\label{EqlangleMOmodEME}
	[\langle M_0, P\rangle :M_0]=\frac{ \dim_{M_0}\modE }{ \dim_{\langle M_0, P\rangle }\modE }.
\end{equation}
We know by formula \eqref{EqDimMMprimeprodun} that 
\begin{equation}
	\Big( \dim_{\langle M_0, P\rangle }\modE \Big)\cdot \Big(  \dim_{\langle M_0, P\rangle '}\modE\Big)=1.
\end{equation}
On the other hand, since $\langle M_0, P\rangle =JM_1'J$ (lemma \ref{LemMOJNJequal}), we have
\begin{equation}
	\dim_{\langle M_0, P\rangle '}\modE=\dim_{JM_1J}\modE=\dim_{M_1}\modE=[M_0:M_1].
\end{equation}
Since formula \eqref{EqlangleMOmodEME} holds for every choice of $\modE$, we compute the right hand side in the case where $\modE=L^2(M_0)$. In that particular case, $\dim_{M_0}\modE=1$, and the claim follows.
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Example of index bigger than \texorpdfstring{$4$}{4}}
%---------------------------------------------------------------------------------------------------------------------------

Consider $R$, the hyperfinite factor of type $II_1$ given by\footnote{Recall that one needs a functional in order to define the infinite tensor product.}
\begin{equation}
	R=\bigotimes_1^{\infty}\big( \eM_2(\eC),\tr \big)
\end{equation}
It turns out that, for that factor, we have $R\simeq PRP$ for every projection $P\in R$. Choose isomorphism $\alpha\colon R\to PRP$ and $\beta\colon R\to P^{\perp}RP^{\perp}$, and form the algebra
\begin{equation}
	S=\{ \alpha(T)+\beta(T)\tq T\in R \}.
\end{equation}
That algebra is algebraically isomorphic to $R$, and the isomorphism is ultraweakly continuous, so that $S$ is a von~Neumann algebra. The index of $S$ in $R$ is given by
\begin{equation}
	[R:S]=\tr(P)^{-1}+\tr(P^{\perp})^{-1}
\end{equation}
where $\tr(P)$ can take any value between $0$ and $1$, and $\tr(P^{\perp})=1-\tr(P)$. The possible values of the index are then given by the range of the function
\begin{equation}
	f(x)=\frac{1}{ x }+\frac{1}{ 1-x }
\end{equation}
when $x$ runs over $[0,1]$. One easily checks that that range is $[4,\infty]$.


%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Properties of the sequence of \texorpdfstring{$M_i$}{Mi}, \texorpdfstring{$P_i$}{Pi}}		\label{SubSecPropSeqMO}
%---------------------------------------------------------------------------------------------------------------------------

Let $M_0$ be a subfactor of $M_1$. We define $[M_1:M_0]=\dim_{M_0}\big( L^2(M_1) \big)$. We define $P_1\colon  L^2(M_1)\to L^2(M_1)$, the projection onto $L^2(M_0)$. Then we consider the new factor
\begin{equation}
	M_2=\langle M_1, P_1\rangle.
\end{equation}
For that definition, we see $M_1$ as subalgebra of $\oB\big( L^2(M_1) \big)$. Now, $M_2$ is also a subalgebra of $\oB\big( L^2(M_2) \big)$, so that, defining $P_2\colon L^2(M_2)\to L^2(M_2)$ as the projection onto $L^2(M_1)$, allows to define 
\begin{equation}
	M_3=\langle M_2, P_2\rangle \subseteq\oB\big( L^2(M_2) \big).
\end{equation}
Using that construction again and again, we get a sequence
\begin{equation}
	M_0\subseteq M_1\subseteq M_2\subseteq\ldots
\end{equation}
of factors defined by $M_{n+1}=\langle M_n, P_n\rangle $ where $P_n\colon L^2(M_n)\to L^2(M_n)$ is the orthogonal projection onto $L^2(M_{n-1})$. One can prove that
\begin{equation}
	P_n(M_n)\subseteq M_{n-1}.
\end{equation}
We thus consider the maps
\begin{equation}
\begin{aligned}
 p_n\colon M_n&\to M_{n-1} \\ 
   p_n(T_n)&\mapsto P_n(T_n),
\end{aligned}
\end{equation}
and we have the sequence
\begin{equation}
\xymatrix{%
   P_{n-1}\in M_n \ar[r]^{p_n}	&	M_{n-1}\ar[r]^{p_{n-1}}	& M_{n-2}.
}	
\end{equation}

The following is the proposition 3.3.2 in \cite{JonesSunder}.

\begin{proposition}		\label{ProppropsindexMarkov}
We have
\begin{enumerate}
\item $[M_n:M_{n+1}]=\lambda^{-1}$ does not depend on $n$,
\item $\tr(P_n)=\lambda$,
\item $\tr(P_nT_n)=\lambda\tr(T_n)$ for every $T_n\in M_n$.
\end{enumerate}
\end{proposition}

The last property is the \defe{Markov property}{Markov property}.

\begin{proof}
No proof.
\end{proof}

\begin{lemma}		\label{LemPnPllamcun}
We have 
\begin{equation}
	p_n(P_{n-1})=\lambda\cun
\end{equation}
where $\lambda=\tr(P_n)$ does not depends on $n$ by the proposition \ref{ProppropsindexMarkov}.
\end{lemma}

\begin{proof}
Since the map $(S,T)\mapsto\tr(ST)$ is a nondegenerate bilinear functional on $M_{n-1}$, it is sufficient to prove that $\tr\big( Sp_n(P_{n-1}) \big)=\lambda\tr(S)$ for every $S\in M_{n-1}$. Using point \ref{ItemPropMappMNiv} of proposition \ref{PropPropMappMN}, we have $Sp_n(P_{n-1})=p_n(SP_{n-1})$, so that
\begin{equation}
	\tr\big( Sp_n(P_{n-1}) \big)=\tr(SP_{n-1})=\lambda\tr(S),
\end{equation}
where the last equality is the Markov property.
\end{proof}

\begin{proposition}		\label{PropAlgPPPKoi}
	The projections $P_i$ fulfil the algebra
	\begin{subequations}		\label{SubeqPnPalgPPI}
	\begin{align}
		P_nP_{n+1}P_n&=\lambda P_n		\label{EqLoiPPun}		\\
		P_nP_{n-1}P_n&=\lambda P_n		\label{EqLoiPPdeux}		\\
		P_nP_m&=P_mP_n				\label{EqLoiPPtrois}
	\end{align}
	\end{subequations}
	when $| n-m |\geq 2$.
\end{proposition}

\begin{proof}
	Let us prove the second one. Using lemma \ref{LemPnPllamcun}, we find
	\begin{equation}
		P_nP_{n-1}P_n=p_n(P_{n-1})P_n = \lambda P_n,
	\end{equation}
	which is the claim.
\end{proof}

\begin{corollary}
	The algebra generated by
	\begin{equation}
		\{ \mtu,P_1,\ldots, P_n\}
	\end{equation}
	is a finite dimensional $C^*$-algebra in which there exists an unique tracial state such that for every~$k$,
	\begin{equation}
		\tr(P_kT)=\lambda \tr(T)
	\end{equation}
	whenever $T$ belongs to the algebra generated by $\mS_{k-1}=\{ \mtu,P_1,\ldots,P_{k-1} \}$.
\end{corollary}

\begin{proof}[Sketch of the proof]
Let a \emph{reduced word} in $P_1$, \ldots, $P_k$ be a word which is as small as possible using the three rules \eqref{SubeqPnPalgPPI}. We prove by induction that such a reduced word contains $P_k$ at most once. For beginning, the only reduced word in $P_1$ is $P_1$ itself. 

Now, let a word containing twice $P_k$. What is between two successive occurrences of $P_k$ is a word of $\mS_{k-1}$. That word is reduced, and thus contains $P_{k-1}$ only once by induction hypothesis. From rule \eqref{EqLoiPPtrois}, the operator $P_k$ commutes with $\mS_{k-2}$, and then the rule \eqref{EqLoiPPdeux} reduces the word (because $P_{k-1}$ appears only once).


Now, a general reduced word of $\mS_k$ has only one $P_k$ and thus has the form $m_1 P_k m_2$ where $m_1$ and $m_2$ are reduces words of $\mS_{k-1}$. Of course, $m_1$ them self decomposes in $n_{1} P_{k-1} n_2$ where $n_i$ are reduces words of $\mS_{k-2}$, and the process continues.

Every reduced word in $\mS_9$ look like
\begin{equation}
	(P_5P_4P_3)(P_8P_7P_6P_5P_4)(P_9P_8P_7P_6).
\end{equation}
Some comments
\begin{itemize}
\item The sub words are made of consecutive projections. For example the sub word $(P_5P_3)$ can be rearranged as the two sub words $(P_3)(P_5)$ by rule \eqref{EqLoiPPtrois}.
\item The sub words begin by $P_5$, $P_8$ and $P_9$. Notice that $5<8<9$. It will always be like that. If not, a rearrangement is possible.
\end{itemize}
Now fix a $n$ and consider the set of all the reduced words of $\mS_n$; there are only finitely many of them which will be labelled as $W_i$. We look at the matrix whose element $ij$ is given by
\begin{equation}		\label{EqMtrWWtr}
	\tr(W_i^*W_j).
\end{equation}
Each of $W_i^*W_j$ is a long string of elements of $\mS_n$ and the cyclic property of the trace allows us to do
\begin{equation}
	\tr\big( (\ldots)(\ldots)(P_nP_{n-1}\ldots) \big)=\tr\big( (P_nP_{n-1}\ldots)(\ldots)(\ldots)  \big).
\end{equation}
Then, using the Markov property of proposition \ref{ProppropsindexMarkov}, we can extract $P_n$. That matrix is positive semidefinite because it is formed of scalar products. If not, that would means that the assumption $M_0\subseteq M_1$ is wrong.

\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
					\subsection{Some interesting functions}
%---------------------------------------------------------------------------------------------------------------------------

Consider the polynomials defined by the induction
\begin{subequations}
\begin{align}
	f_0(x)&=0	\\
	f_1(x)&=1	\\
	f_n(x)&=f_{n-1}(x)-xf_{n-2}(x).	
\end{align}
\end{subequations}
Since $f_n(0)=f_{n-1}(0)$, all these polynomials pass by the point $(0,1)$. By induction, one can see that
\begin{equation}
	f_n\left( \frac{1}{ 4\cos^2\theta } \right)=\frac{\sin(n\theta)}{2^{n-1}\cos^{n-1}(\theta)\sin(\theta)},
\end{equation}
so that	the smallest positive root of $f_n$ is 
\begin{equation}
	\frac{1}{ 4\cos^2\left( \frac{ \pi }{ n } \right) },
\end{equation}
and $f_n$ is negative on the interval between $1/4\cos^2(\pi/n)$ and $1/4\cos^2(\pi/(n-1))$.

Suppose $\lambda^{-1}=[M:M_0]$ and $\lambda>1/4$. Now, assume that 
\begin{equation}
	\lambda\neq \frac{1}{ 4\cos^{2}(\pi/n) }
\end{equation}
for any value of $n\in\eN$. In this case, we will found a negative diagonal entry of the matrix \eqref{EqMtrWWtr}, which is impossible because a semipositive definite matrix has no negative diagonal element.

Let 
\begin{equation}
	Q_k=\mtu-P_1\vee\ldots\vee P_k.
\end{equation}
From lemma \ref{LemFiniCSestVNa}, the operator $Q_k$ is in fact a projection in a finite dimensional algebra, and is thus a polynomial in the $P_i$'s.

\begin{lemma}
	We have
\begin{equation}		\label{EqQPQffQPQ}
	(Q_{k-1}P_kQ_{k-1})^2=\frac{ f_k(\lambda) }{ f_{k+1}(\lambda) }Q_{k-1}P+kQ_{k-1},
\end{equation}
and 
\begin{equation}
	Q_{k+1}=Q_k-\frac{ f_{k+1}(\lambda) }{ f_k(\lambda) }Q_{k-1}Q_{k-1},
\end{equation}
if $f_{k+1}(\lambda)$, \ldots, $f_1(\lambda)\neq0$.
\end{lemma}
Notice in particular that, up to a factor, the operator of equation \eqref{EqQPQffQPQ} is a projection.

\begin{proof}
No proof.
\end{proof}

\begin{corollary}
The operators $Q_{k-1}$, $P_k$ and $Q_{k+1}$ are projection, and the product is a positive operator.
\end{corollary}

That corollary shows that
\begin{equation}
	\frac{ f_k(\lambda) }{ f_{k+1}(\lambda) }>0.
\end{equation}
But a simple study of the polynomials shows that this ratio is in fact negative. We conclude that operator satisfying the algebra of proposition \eqref{PropAlgPPPKoi} are only possible when $\lambda=1/4\cos(\pi/n)$.
