% This is part of (almost) Everything I know in mathematics and physics
% Copyright (c) 2013-2014
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.

\section{Dirac operator on \texorpdfstring{$AdS_2$}{AdS2}}
%-------------------------------------

Why to compute Dirac operator on anti de Sitter spaces ? Let $M=AdS_2$ and $R=AN$ acts on $M$. Let $\mO$ be an open orbit of $R\times M\to M$. In the specific case of $AdS_2$, we have $R=\mO=R\cdot\mfo$. In larger dimensions, there is a $\SO(1,n)$ which causes that the orbit is not exactly the acting group. It is
\[ 
  \mO=\frac{ R }{ R\cap \SO(1,n) }.
\]

\subsection{Clifford algebra and spin group}
%/////////////////////////////////////


As definition, we retain
\begin{equation}
\begin{split}
  AdS_2&\equiv t^2+u^2-x^2=1\\
    &=\frac{ \SO(2,1) }{ \SO(1,1) }.
\end{split}
\end{equation}
Let $V=\eR^{1,1}$ and $e_0$, $e_1$ an orthonormal basis. We pose 
\begin{align*}
  f_0=\frac{ 1 }{2}(e_0+e_1)\quad g_0=\frac{ 1 }{2}(e_0-e_1)
\end{align*}
and we define $\tilde\rho$ by
\begin{subequations}
\begin{align}
  \tilde\rho(f_0)\alpha&=f_0\wedge\alpha\\
    \tilde\rho(g_0)\alpha&=-i(g_0)\alpha
\end{align}
\end{subequations}
where $\alpha\in\Lambda W$, $W$ being the space spanned by $f_0$. More explicitly we have :
\begin{subequations}
\begin{align}
  \tilde\rho (f_0)1&=f_0&\tilde\rho (f_0)f_0&=0\\
\tilde\rho (g_0)1&=0&\tilde\rho (g_0)f_0&=-\eta(f_0,g_0).
\end{align}
\end{subequations}
As element of $\Lambda W$, $f_0$ stands for $\eta(f_0,.)$. If we choose the basis
\[ 
  1=
\begin{pmatrix}
1\\0
\end{pmatrix},
\quad
f_0=
\begin{pmatrix}
0\\1
\end{pmatrix},
\]
 the matrices of $\tilde\rho$ are given by
\[ 
  \tilde\rho(e_0)=
\begin{pmatrix}
0&-1/2\\
1&0
\end{pmatrix},
\quad
\tilde\rho(e_1)=
\begin{pmatrix}
0&1/2\\
1&0
\end{pmatrix}.
\]
Up to a change of basis,
\[ 
  \gamma_0=
\begin{pmatrix}
0&1\\1&0
\end{pmatrix},
\quad
\gamma_1=
\begin{pmatrix}
0&-1\\1&0
\end{pmatrix}
\quad
\gamma_0\gamma_1=
\begin{pmatrix}
1&0\\0&-1
\end{pmatrix},
\]
and a general element of $Cl_{(1,1)}$ reads
\[ 
  x\gamma_0+y\gamma_1+u\eR+v\gamma_0\gamma_1=
\begin{pmatrix}
u+v&x-y\\
x+y&u-v
\end{pmatrix}.
\]
With the change of basis $e_1\to ie_1$, we write it under a more simple form :
\begin{equation}
Cl_{(1,1)}\leadsto 
\begin{pmatrix}
\alpha&\beta\\
\bar\beta&\bar\alpha
\end{pmatrix}
\end{equation}
with $\alpha,\beta\in\eC$. In particular, an element of $V$, i.e. a combination of $\gamma_0$ and $\gamma_1$ is
\begin{equation}
V\leadsto
\begin{pmatrix}
0&\xi\\
\overline{\xi}&0
\end{pmatrix}.
\end{equation}
Let
\[ 
  1=
\begin{pmatrix}
1&0\\0&1
\end{pmatrix},
\quad
a=
\begin{pmatrix}
i&0\\0&-i
\end{pmatrix},
\quad b=
\begin{pmatrix}
0&1\\1&0
\end{pmatrix},
\quad
c=
\begin{pmatrix}
0&i\\-i&0
\end{pmatrix}
\]
Let us now determine $\alpha$, the extension of $-\id|_V$ into an automorphism and $\tau$, the extension of $\id|_V$ into an anti-automorphism. We have $\alpha(b)=-b$, $\alpha(c)=-c$, $\tau(b)=b$ and $\tau(c)=c$. We find the others by virtue of relations $bc=-a$ and $b^2=1$. Finally
\begin{equation}
\begin{aligned}
  \alpha(1)&=1&\alpha(a)&=a\\
\alpha(b)&=-b&\alpha(c)&=-c
\end{aligned}
\end{equation}
and
\begin{equation}
\begin{aligned}
  \tau(1)&=1&\tau(a)&=-a\\
\tau(b)&=b&\tau(c)&=c.
\end{aligned}
\end{equation}

The condition for $s\in Cl_{(1,1)}$ to belongs to $\Gamma_{(1,1)}$ is that $\alpha(s)v s^{-1}\in V$ for all $v\in V$. If we consider $s=
\begin{pmatrix}
\alpha&\beta\\\bar\beta&\bar\alpha
\end{pmatrix}$,
we have
\[ 
  \alpha(s)=
\begin{pmatrix}
\alpha&-\beta\\-\bar\beta&\bar\alpha
\end{pmatrix},
\text{ and }
s^{-1}=\frac{1}{ | \alpha |^2-| \beta |^2 }
\begin{pmatrix}
\bar\alpha&-\beta\\-\bar\beta&\alpha
\end{pmatrix}.
\]
If we impose $\alpha(s)v s^{-1}$ to be of the form $\begin{pmatrix}
0&\eta\\\bar\eta&0
\end{pmatrix}$ for all $v$ of the form $\begin{pmatrix}
0&\xi\\\bar\xi&0
\end{pmatrix}$, we find $\real(\bar\alpha\beta\bar\xi)=0$ and the $\bar\alpha\beta=0$. So generators of $\Gamma_{(1,1)}$ are
\begin{equation}
\Gamma_{(1,1)}\leadsto
\begin{pmatrix}
\alpha&0\\0&\bar\alpha
\end{pmatrix},\quad
\begin{pmatrix}
0&\beta\\\bar\beta&0
\end{pmatrix}.
\end{equation}
Elements of $Spin_{(1,1)}$ are elements of $\Gamma_{(1,1)}^+$ such that $\tau(s)=s^{-1}$. So
\begin{equation}
Spin_{(1,1)}\leadsto
\begin{pmatrix}
\alpha&0\\0&\bar\alpha
\end{pmatrix},\text{ such that }| \alpha |^2=1.
\end{equation}
We recognize $Spin_{(1,1)}=U(1)$.

\begin{probleme}
This is wrong: in fact $\Spin(1,1)\neq U(1)$.
\end{probleme}

\subsection{Relation between \texorpdfstring{$SU(1,1)$}{SU(1,1)} and \texorpdfstring{$\SO(2,1)$}{SO(2,1)}}
%//////////////////////////////////

A general matrix of $SU(1,1)$ is
\[ 
  U=\begin{pmatrix}
\alpha&\beta\\\bar\beta&\bar\alpha
\end{pmatrix},
\quad
U^{-1}=\begin{pmatrix}
\bar\alpha&-\beta\\-\bar\beta&\alpha
\end{pmatrix}
\]
with $| \alpha |^2 - | \beta |^2=1$. They are matrices which fulfil $\det U=1$ and $U^+g=gU^{-1}$.  If we denote by $V$ the space of matrices of the form $(r,z)=\begin{pmatrix}
r&\bar z\\z&r
\end{pmatrix}$ with $r\in\eR$ and $z\in\eC$, we have a bijection $\psi\colon \eR^{1,1}\to V$ given by
\[ 
  \begin{pmatrix}
u\\t\\x
\end{pmatrix}\mapsto
\begin{pmatrix}
x&t-iu\\ t+iu&x
\end{pmatrix}.  
\]
It becomes an isometry if we pose $\| (r,z) \|=z\bar z-r^2=-\det(r,z)$. The group $SU(1,1)$ has an isometric action on $V$ given by
\[ 
  Uv=UvU^{\dag}.
\]
We immediately remark that $Uv=(-U)v$. We define
\begin{equation}
\begin{aligned}
 T\colon SU(1,1)&\to \SO(2,1) \\ 
T(U)\begin{pmatrix}
u\\t\\x
\end{pmatrix}&= \psi^{-1}\big( U\psi\begin{pmatrix}
u\\t\\x
\end{pmatrix}U^{\dag} \big). 
\end{aligned}
\end{equation}

Now we want to know when $T(U)=T(\tilde U)$. Using the fact that $U^{-1}=gU^{\dag}g$ in the condition $UvU^{\dag}=\tilde Uv\tilde U^{\dag}$, we find
\[ 
  VvV^{\dag}=v
\]
with $V=\tilde U^{-1}U$. Then imposing
\[ 
  \begin{pmatrix}
r&\bar z\\z&r
\end{pmatrix}=
\begin{pmatrix}
\alpha&\beta\\\bar\beta&\bar\alpha
\end{pmatrix}
\begin{pmatrix}
r&\bar z\\z&r
\end{pmatrix}
\begin{pmatrix}
\bar \alpha&\beta\\\bar\beta&\alpha
\end{pmatrix},
\]
we find $T(U)=T(\tilde U)\Leftrightarrow \tilde U=\pm U$. We have
\[ 
  T\begin{pmatrix}
i\\&-i
\end{pmatrix}
=
\begin{pmatrix}
-1\\&-1\\&&1
\end{pmatrix}.
\]
The map $T\colon SU(1,1)\to \SO(2,1)$ is a double covering.

We are now going to explicitly compute the map $T$. First :
\[ 
 \begin{split}
\begin{pmatrix}
\alpha&\beta\\
 \bar\beta&\bar \alpha
\end{pmatrix}
\begin{pmatrix}
r&\bar z\\
z&r
\end{pmatrix}
&
\begin{pmatrix}
\bar\alpha&\beta\\
\bar\beta&\alpha
\end{pmatrix}=\\
&\begin{pmatrix}
\bar\alpha(\alpha r+\beta z)+\bar\beta(\alpha\bar z+\beta r)& \beta(\alpha r+\beta z)+\alpha(\alpha\bar z+\beta r)\\
\bar\alpha(\bar\beta+\bar\alpha z)+\bar\beta(\bar\beta\bar z+\bar\alpha r)&\beta(\bar\beta r+\bar\alpha z)+\alpha(\bar\beta\bar z+\bar\alpha r)
\end{pmatrix}.
\end{split} 
\]
When we pose $z=0$ and $r=1$, i.e., when we look at $\begin{pmatrix}
0\\0\\1
\end{pmatrix}$, we find
\[ 
  \begin{pmatrix}
\bar\alpha\alpha+\bar\beta\beta&2\beta\alpha\\
2\bar\alpha\bar\beta& \beta\bar\beta+\alpha\bar\alpha
\end{pmatrix}
\]
which corresponds to $x=\bar\alpha\alpha$, $t-iu=2\alpha\beta$ and $t+iu=2\bar\alpha\bar\beta$. We conclude that
\[ 
  T\begin{pmatrix}
\alpha&\beta\\\bar\beta&\bar\alpha
\end{pmatrix}
=
\begin{pmatrix}
.&.&i(\alpha\beta-\bar\alpha\bar\beta)\\
.&.&\alpha\beta+\bar\alpha\bar\beta\\
.&.&\alpha\bar\alpha+\beta\bar\beta
\end{pmatrix}.
\]
Similar computations lead to
\begin{equation}
T\begin{pmatrix}
\alpha&\beta\\
\bar\beta&\bar\alpha
\end{pmatrix}
=
\begin{pmatrix}
\frac{ \bar\alpha^2+\alpha^2-\beta^2-\bar\beta^2 }{2} &     \frac{ i }{2}(\alpha^2-\bar\alpha^2+\beta^2-\bar\beta^2) &  i(\alpha\beta-\bar\alpha\bar\beta)\\
\frac{ i }{2}(\beta^2-\bar\beta^2+\bar\alpha^2-\alpha^2) &  \frac{ 1 }{2}(\alpha^2+\bar\alpha^2+\beta^2+\bar\beta^2) &  \alpha\beta+\bar\alpha\bar\beta\\
i(\bar\alpha\beta-\bar\beta\alpha)          &   \bar\alpha\beta+\bar\beta\alpha             &   \alpha\bar\alpha+\beta\bar\beta
\end{pmatrix}
\end{equation}

\subsection{Spin structure on \texorpdfstring{$AdS_2$}{AdS2}}
%/////////////////////////////////////////

We are going to build elements of the following spin structure:
\[
\xymatrix{ \Spin(1,1) \ar@{~>}[r]& SU{(1,1)} \ar[rr]^{\displaystyle\varphi} \ar[rd]_{\displaystyle\pi} && \SO(AdS_2) \ar[ld]^{\displaystyle p}&\SO(2,1) \ar@{~>}[l]  \\& & AdS_2 }
\]
First let $\{ e_t,e_u,e_x \}$ be a basis of $\eR^{1,1}$ with $e_t\in AdS_2$, $e_t\cdot e_t=e_u\cdot e_u=-e_x\cdot e_x=-1$. We suppose that $e_u$ and $e_x$ span tangent space at $e_t$. Let $T$ be a representation of $\SO(1,1)$ on $\eR^{2,1}$  which leaves $e_t$ unchanged: $T(A)e_t=e_t$ for all $A\in \SO(1,1)$. To each element $B\in \SO(AdS_2)$, one can associate an element of $B'\in \SO(AdS_2)$ such that $B$ has the form
\begin{equation} \label{eq_blaseAdS}
  B=\{ B'e_u,B'e_x \}_{B'e_t}.
\end{equation}
We define
\[ 
  p(B)=B'e_t.
\]
Now the action of $A\in \SO(1,1)$ on $B\in \SO(AdS_2)$ is defined, if $B$ has the form \eqref{eq_blaseAdS}, by
\begin{equation}
  B\cdot A=\{ T(A)B'e_u,T(A)B'e_x \}_{B'e_t}.
\end{equation}
The map $\varphi\colon SU(1,1)\to \SO(AdS_2)$ is given by
\begin{equation}
\big( \varphi(U) \big)'=(T\circ S)(U),
\end{equation}
and the projection $\pi\colon SU(1,1)\to AdS_2$, 
  $\pi=p\circ\varphi$.

The group $\Spin(1,1)$ must act on $SU(1,1)$; we define
\begin{equation}
U\cdot s=\varphi^{-1}\big( \varphi(U)\cdot \chi(s) \big).
\end{equation}
We have $\pi(U\cdot s)=\pi(U)$ because
\[ 
  \pi(U\cdot s)=p\big( \varphi(U)\cdot\chi(s) \big),
        =\big[ \varphi(U)\cdot \chi(s) \big]'e_t
        =\varphi(U)\circ T(\chi(s))e_t
        =\varphi(U)'e_t
        =\pi(U).
\]
We have used the fact that  $\chi(s)\in \SO(1,1)$ and that, therefore, $(T\circ\chi)(s)e_t=e_t$.


\subsection{Spinor bundle and connection}
%///////////////////////////////////////

We define $S=\Lambda W$ where $W$ is the (one dimensional) space spanned by $f_0$ and we define 
\begin{equation} \label{eq_mSSUrho}
  \mS= SU(1,1)\times_{\rho}S
\end{equation}
where $\rho\colon Spin_{(1,1)}\times\Lambda W\to \Lambda W$ is the representation of $Spin_{(1,1)}$ on $SU(1,1)$ given by
\begin{equation}
  \rho(s,\alpha)=\tilde\rho(s)\alpha.
\end{equation}
Recall that $\alpha$ is either a scalar either a multiple of $f_0$. The equivalence relation which arises in equation \eqref{eq_mSSUrho} is
\begin{equation}
  (U,\alpha)\sim(U\cdot s,\rho(s^{-1})\alpha).
\end{equation}
The projection is
\[ 
  \pi_{\mS}[(U,\alpha)]=\pi(U).
\]

For the connection on $\SO(AdS_2)$, we want that horizontal vector are tangent vectors to curves formed by parallel transport. In other word, a path 
\[
B(s)=\{ B'(s)e_u,B'(s)e_x \}_{B'(s)e_t}
\]
 has horizontal tangent vector if $B'(s)e_i$ ($i=u,x$) is a parallel transport of $B'(0)e_i$ along the curve $B'(s)e_e$ on $AdS_2$. Here, $B'(s)$ denotes the matrix of $\SO(2,1)$ associated with the basis $B(s)$ : the prime doesn't denotes a derivation. Let us define the $so(1,1)$ valued connection $1$-form which corresponds to this intuition. We consider $b_i(s)$ the parallel transported along the curve $B'(s)e_t$ of $B'(0)e_i$, and $A(s)$, the matrix of $\SO(1,1)$ such that $A(s)B'(s)e_i=b_i(s)$ ($i=u,x$). The definition is
\[ 
  \omega(\dot B)=\Dsdd{ A(s) }{s}{0}.
\]


\begin{proposition}
It is a connection $1$-form.
\end{proposition}

\begin{proof}
First we consider a fundamental vector field
\[ 
  X^*_B=\Dsdd{ B\cdot e^{-tX} }{t}{0}=\Dsdd{ \{ T( e^{-tX})B'e_u,T( e^{-tX})B'e_x \}_{B'e_t} }{t}{0}.
\]
The path in $AdS_2$ on which this path in $\SO(AdS_2)$ is build is constant: it is $B'e_t$. So the parallel transport is constant and the path $A(s)$ is given by
\[ 
  A(s)T( e^{-tX})B'e_u=B'e_u
\]
and $\omega(X^*_B)=X$.

It remains to be proved that for all $B\in \SO(AdS_2)$, $g\in \SO(1,1)$ and $X\in T_B\SO(AdS_2)$,
\begin{equation}
\omega\big( (dR_g)_BX \big)=\Ad(g^{-1})\omega_B(X).
\end{equation}
We give $X$ by the path 
\[ 
  X(s)=\{ B'(s)e_u,B'(s)e_x \}_{B'(s)e_t}.
\]
 The differential $dR_g$ gives rise to the new path
\[ 
  (dR_gX)(s)=\{ gB'(s)e_u,gB'(s)e_x \}_{B'(s)e_t}.
\]
Let $b_i(s)$ be the parallel transport of $B'(0)e_i$ ($i=u,x$) along the path $B'(s)e_t$. We have to compute $\omega_B(X)$ with $A(s)$ defined by $A(s)B'(s)e_i=b_i$. The parallel transport of $gB'(0)e_i$ is given by $gb_i$. Therefore $\omega(dR_gX)$ is given by the path $A^g(s)$ which satisfies $A^g(s)gB'(s)e_i=gA(s)B'(s)e_i$. So
\[ 
  A^g(s)=gA(s)g^{-1}
\]
and
\[ 
  \Dsdd{ A^g(s) }{s}{0}=\Ad(g)\omega(X).
\]

\end{proof}

\subsection{Clifford algebra \texorpdfstring{$(1,1)$}{(1,1)}}
%-------------------------------------

We consider the left invariant vector fields
\begin{subequations}
\begin{align}
  \tilde{e}_J(r_0)&=\Dsdd{ r_0 e^{-sJ} }{s}{0}=-r_0J\\
\tilde{e}_L(r_0)&=\Dsdd{ r_0 e^{-sL} }{s}{0}=-r_0L.
\end{align}
\end{subequations}
More precisely, we consider the vectors given by action of these matrices on the ``base point'' $\begin{pmatrix}
0\\1\\0
\end{pmatrix}$. Hence
\begin{align}
\tilde{e}_J(r_0)=-r_0\begin{pmatrix}
0\\0\\1
\end{pmatrix},\quad
\tilde{e}_L(r_0)=-r_0\begin{pmatrix}
1\\0\\0
\end{pmatrix}
\end{align}
and 
\[ 
  g=\begin{pmatrix}
1\\&-1
\end{pmatrix}.
\]
Remark that this metric is constant (it does not depend on $r_0$) because $r_0$ is an isometry. For this reason, we now turn our attention to Clifford algebra and spin group for $V=\eR^{1,1}$. Following matrices fulfill relation \eqref{3101r3}
\[ 
  \gamma_J=\begin{pmatrix}
0&1\\1&0
\end{pmatrix},\quad
\gamma_L=\begin{pmatrix}
0&-1\\1&0
\end{pmatrix}. 
\]
The complete Clifford algebra has the following matrices too :
\[ 
  1=\begin{pmatrix}
1&0\\0&1
\end{pmatrix},\quad
\gamma_{JL}=\begin{pmatrix}
-1\\&1
\end{pmatrix}.
\]
The Clifford algebra is nothing else than $GL(2,\eR)$, the set of all real $2\times 2$ matrices. From definitions, one can check that
\[ 
 \begin{aligned} 
\alpha(J)&=-J   &\tau(J)&=J\\
\alpha(L)&=-L   &\tau(L)&=L\\
\alpha(JL)&=JL  &\tau(JL)&=-JL\\
\alpha(1)&=1    &\tau(1)&=1
\end{aligned}
\]
Inverse and $\alpha$ of general element in $\Cl(1,1)$ are given by
\[ 
  \begin{pmatrix}
p&q\\r&s
\end{pmatrix}^{-1}=
\frac{1}{ ps-qr }\begin{pmatrix}
s&-q\\-r&p
\end{pmatrix},\quad
\alpha\begin{pmatrix}
p&q\\r&s
\end{pmatrix}=
\begin{pmatrix}
p&-q\\-r&s
\end{pmatrix}.
\]
A general element in $\eR^{1,1}$ is $\begin{pmatrix}
0&\alpha\\\beta&0
\end{pmatrix}$ with $\alpha,\beta\in\eR$, so the condition to belongs to $\Gamma(1,1)$ is that 
\[ 
  \frac{1}{ ps-qr }\begin{pmatrix}
p&-q\\-r&s
\end{pmatrix}
\begin{pmatrix}
0&\alpha\\\beta&0
\end{pmatrix}
\begin{pmatrix}
s&-q\\-r&p
\end{pmatrix}
\]
belongs to $\eR^{1,1}$ for all $\alpha$ and $\beta$. It requires, among others, that $qs\beta-rp\alpha=0$ for all $\alpha$ and $\beta$. Hence $qs=rp=0$, but the alternatives $p=r=0$ and $q=s=0$ are ruled out because we want the determinant $ps-qr$ to be non zero. Therefore, $\Gamma(1,1)$ is generated by
\[ 
  \Gamma(1,1)\leadsto
\begin{pmatrix}
p&0\\0&s
\end{pmatrix},\begin{pmatrix}
0&q\\r&0
\end{pmatrix}.
\]
The latter belongs to $\eR^{1,1}$, so
\[ 
  \Gamma^+(1,1)\leadsto\begin{pmatrix}
z+c&0\\0&z-c
\end{pmatrix}=z\mtu+c\gamma_{JL}.
\]
From 
\[ 
  \tau(z\mtu+c\gamma_{JL})=z\mtu-c\gamma_{JL},
\]
elements in $\Spin(1,1)$ are subject to the relation
\[ 
  \begin{pmatrix}
s&0\\0&p
\end{pmatrix}=
\frac{1}{ ps }\begin{pmatrix}
s&0\\0&p
\end{pmatrix}.
\]
As consequence, we find
\begin{equation}
\Spin(1,1)=\eR_0\leadsto
\begin{pmatrix}
1/p\\&p
\end{pmatrix}.
\end{equation}
 If we put (see decomposition \eqref{eq:expo_ANK})
\[ 
  A=\begin{pmatrix}
 e^{a}\\& e^{-a}
\end{pmatrix},
\]
we have $\Spin(1,1)=A\times\eZ_2$. Let us check that $\Spin(1,1)$ is a double covering of $\SO_0(1,1)$. We know that 
\[ 
  \SO(1,1)=\begin{pmatrix}
\cosh\xi&\sinh\xi\\\sinh\xi&\cosh\xi
\end{pmatrix}\times\eZ_2
\]
while $\SO_0(1,1)$ is 
\[ 
  \SO_0(1,1)=\begin{pmatrix}
\cosh\xi&\sinh\xi\\\sinh\xi&\cosh\xi
\end{pmatrix}=\eR.
\]
This structure of $\SO(1,1)$ comes from the fact (true for all $\SO(1,n)$) that $| \Lambda^0_0 |\geq1$ when $\Lambda$ is a Lorentz transformation. So $\mtu$ and $-\mtu$ cannot belong to the same connected component. Note that $\cosh\xi\geq 1$.
We see intuitively how to cover two times $\eR$ with $\eR_0$. Let us see how the map $\chi$ does that. From definition, $\chi(x)y=\alpha(x)yx^{-1}$, so it is easy to see that 
\[ 
  \chi(1)=\chi(-1)=\id|_{\eR^{1,1}}
\]

\subsection{Parallel transport}
%------------------------------

We have a connection on the frame bundle of $AdS_2$ and we wan to lift the vectors $\tilde{e}_J$ and $\tilde{e}_L$, i.e. we consider a point 
\[ 
  \xi_0=(r_0,v_1,v_2)\in \SO(AdS_2)
\]
where $v_1$ and $v_2$ form an orthonormal (in the sense of $g$) basis of $T_{r_0}AdS_2$. Then we have to find a path $s\to\xi(s)$ in $\SO(AdS_2)$ such that $\xi(0)=\xi_0$, $\omega(\xi'(0))=0$ and $dp\xi'(0)=\tilde{e}_a$. The latter condition allows us to compute $r(s)$ in the expression
\[ 
  \xi(s)=(r(s),v_1(s),v_2(s)),
\]
namely, $r(s)$ is the path of $\tilde{e}_a$. The condition to be horizontal imposes that vectors $v_i(s)$ are parallel transport of $v_i$ along $\tilde{e}_a$. So we have to compute the different $T_a(\tilde{e}_b)(s)$ which is the parallel transported of $\tilde{e}_b$ along the path of $\tilde{e}_a$ at a distance $s$; this is an element of $T_{\tilde{e}_a(s)}AdS_2$. It will be decomposed in the basis 
\[ 
 \begin{split}
  \tilde{e}_J\big( \tilde{e}_a(s) \big)&=-r_0 e^{-s a}J\\
\tilde{e}_L\big( \tilde{e}_a(s) \big)&=-r_0 e^{-sJ}L.
\end{split} 
\]
where we imply the action on the base point $\begin{pmatrix}
0\\1\\0
\end{pmatrix}$. For notational simplicity, from now we write $a(s)$ instead of $\tilde{e}_a(s)$. Various products are easy to compute; for example
\[ 
  \tilde{e}_J(J(s))\cdot\tilde{e}_L(J(s))
        =r_0 e^{-sJ}J\cdot r_0 e^{-sJ}L\\
        =J\cdot L\\
        =\begin{pmatrix}
0\\0\\1
\end{pmatrix}\cdot\begin{pmatrix}
1\\0\\0
\end{pmatrix}\\
        =0
\]
because $r_0 e^{-sJ}$ is an isometry.
In general :
\[ 
  \tilde{e}_a\big( c(s) \big)\cdot \tilde{e}_b\big( c(s) \big)=a\cdot b
\]
Now we pose in general
\[ 
  T_a(\tilde{e}_b)(s)=\alpha(s)\tilde{e}_b\big( a(s) \big)+\beta(s)\tilde{e}_L\big( a(s) \big),
\]
and we want to find the (real valued) functions $\alpha$ and $\beta$. Parallel transport fulfils two conditions: the norm and the angle with the path are constant. This leads us to two conditions :
\begin{subequations}
\begin{align}
  T_a\big( \tilde{e}_b(s) \big)\cdot T_a\big( \tilde{e}_b(s) \big)&=b\cdot b\\
 T_a\big( \tilde{e}_b(s) \big)\cdot \tilde{e}_a\big( a(s) \big)&=b\cdot a.
\end{align}
\end{subequations}
These equations extends to
\begin{subequations}
\begin{align}
  \beta(s)^2-\alpha(s)^2&=b\cdot b\\
\alpha(s)J\cdot a+\beta(s)L\cdot a&=b\cdot a.
\end{align}
\end{subequations}
There are four cases to be considered following that $a=J,L$ and $b=J,L$. The result is that
\begin{equation}
T_a\big(\tilde{e}_b \big)=\tilde{e}_b,
\end{equation}
in other terms, the vectors $\tilde{e}_J$ and $\tilde{e}_L$ are not only parallel vector fields, but each is parallel along the path of the other.

\subsection{Covariant derivative}
%--------------------------------

We will give the horizontal lift of $\tilde{e}_a$ at point
\[ 
  \xi(0)=\{ B_1^b\tilde{e}_b,B_2^c\tilde{e}_c \}_{r_0e_t}
\]
under the form of the path
\[ 
  \xi(s)=\{ B_1^b\tilde{e}_b\big( a(s) \big),B_2^c\tilde{e}_c\big( a(s) \big) \}_{\tilde{e}_a(s)}.
\]
We create a connection on the spinor bundle from the connexion via the formula
\[ 
  \widehat{\nabla_X^E\psi}(\xi)=\overline{ X }_{\xi}(\hat \psi).
\]
In our case, we take $\psi\colon M\to \mS$, or $\hat{\psi}\colon SU(1,1)\to \Lambda W$ such that
\[ 
  \hat{\psi}(U\cdot g)=\rho(g^{-1})\hat{\psi}(U).
\]
Since $\tilde\omega=\varphi^*\omega$, we have $\tilde\omega(X)=\omega(d\varphi X)$ and
\[ 
  \overline{ e }_a{}_{\xi_0}=\varphi^{-1}\big( \tilde{e}_a(s),\ldots \big).
\]
Therefore
\begin{equation}  \label{eq_whidpsinabla}
\widehat{\nabla_a\psi}(\xi_0)=\Dsdd{ (\hat{\psi}\circ\varphi^{-1})\{ B_i^c\tilde{e}_c\big( a(s) \big) \}_{\tilde{e}_a(s)} }{s}{0}
\end{equation}
where $\varphi$ is defined by
\[ 
  \varphi(U)=\{ U\tilde{e}_J,U\tilde{e}_L \}_{Ur_0e_t}.
\]
We have to find
\begin{equation}  \label{eq_varpBic}
  \varphi^{-1}\{ B_i^c\tilde{e}_c\big( a(s) \big) \}_{\tilde{e}_a}.
\end{equation}
Before to write down the inverse of $\varphi$, let us perform some computations.
\[ 
  J=\begin{pmatrix}
&0\\
0&0&1\\
&1
\end{pmatrix},\quad
L=\begin{pmatrix}
0&1&1\\
-1\\
1
\end{pmatrix},
\]
and as far as we only wants to compute derivatives, we can write the exponentials as
\begin{align} 
 e^{sJ}&=\mtu+sJ=\begin{pmatrix}
1\\
&1&s\\
&s&1
\end{pmatrix}\\
 e^{sL}&=\mtu+sL=\begin{pmatrix}
1&s&s\\
-s&1&0\\
s&0&1
\end{pmatrix}.
\end{align}
The path are given by
\begin{equation}
\tilde{e}_a(s)=r_0 e^{-sa}\begin{pmatrix}
0\\1\\0
\end{pmatrix},
\end{equation}
in particular
 \begin{align}
\tilde{e}_J(s)&=r_0\begin{pmatrix}
0\\1\\-s
\end{pmatrix},
&\tilde{e}_L(s)&=r_0\begin{pmatrix}
-s\\1\\0
\end{pmatrix}.
\end{align} 
For the various $\tilde{e}_b\big( a(s) \big)$, we have
\begin{equation}
\tilde{e}_b\big( a(s) \big)=\Dsdd{ a(s) e^{-tb} }{t}{0}\begin{pmatrix}
0\\1\\0
\end{pmatrix}\\
    =\Dsdd{ r_0 e^{-sa} e^{-tb} }{t}{0}\begin{pmatrix}
0\\1\\0
\end{pmatrix}\\
    =-r_0 e^{-sa}b\begin{pmatrix}
0\\1\\0
\end{pmatrix}.
\end{equation}
Results are
\begin{subequations}
\begin{align}
  \tilde{e}_J\big( J(s) \big)&=-r_0\begin{pmatrix}
0\\-s\\1
\end{pmatrix}
&
\tilde{e}_J\big( L(s) \big)&=-r_0\begin{pmatrix}
-s\\0\\1
\end{pmatrix}\\
\tilde{e}_L\big( J(s) \big)&=-r_0\begin{pmatrix}
1\\0\\0
\end{pmatrix}
&
\tilde{e}_L\big( L(s) \big)&=-r_0\begin{pmatrix}
1\\s\\-s
\end{pmatrix}.
\end{align}
\end{subequations}
We finally have to know that
\[ 
  B^c\tilde{e}_c\big( J(s) \big)=-r_0\begin{pmatrix}
B^L\\-sB^J\\B^J
\end{pmatrix},
\quad
B^c\tilde{e}_c\big( L(s) \big)=-r_0\begin{pmatrix}
-sB^J+B^L\\sB^L\\B^J-sB^L
\end{pmatrix}.
\]

Following equation \eqref{eq_varpBic}, in order to write down $\widehat{\nabla_a\psi}$, we have to find $U(s)\in SU(1,1)$ such that
\begin{enumerate}
\item $Ur_0e_t=\tilde{e}_a(s)$,
\item $U\tilde{e}_J=B^c_1\tilde{e}_c\big( a(s) \big)$,
\item $U\tilde{e}_L=B^c_2\tilde{e}_c\big( a(s) \big)$.
\end{enumerate}
If $\overline{ f }$ and $\overline{ g }$ are vectors, solutions in $U$ of equation $Ur_0\overline{ f }=r_0\overline{ g }$ are $U=\AD(r_0)B$ where $B$ fulfils $B\overline{ f }=\overline{ g }$. In the case of $a=J$, the three conditions successively give
\begin{subequations}
\begin{align}
U&=\AD(r_0)\begin{pmatrix}
.&0&.\\
.&1&.\\
.&-s&.
\end{pmatrix}\\
U&=\AD(r_0)\begin{pmatrix}
.&.&B_1^L\\
.&.&-sB_1^J\\
.&.&B_1^J
\end{pmatrix}\\
U&=\AD(r_0)\begin{pmatrix}
-B^L_2&.&.\\
sB_2^J&.&.\\
B_2^J&.&.
\end{pmatrix}.
\end{align}
\end{subequations}
Putting all together in equation \eqref{eq_whidpsinabla} we find
\begin{equation} \label{eq_nabJmoi}
\begin{split}
  \widehat{\nabla_J\psi}(\xi_0)&=\frac{ d }{ ds }\hat{\psi}\AD(r_0)
\begin{pmatrix}
-B_2^L  &   0   &   B_1^L\\
sB_2^J  &   1   &   -sB_1^J\\
B_2^J   &   -s  &   B_1^J
\end{pmatrix}\\
    &=d\hat{\psi}\AD(r_0)\begin{pmatrix}
0&0&0\\
B_2^J&0&-B_1^J\\
0&-1&0
\end{pmatrix}.
\end{split}
\end{equation}
The same with $L$ instead of $J$ leads to
\begin{equation} \label{eq_nabLmoi}
\widehat{\nabla_L \psi}(\xi_0)=d\hat{\psi}\AD(r_0)\begin{pmatrix}
-B_2^J&-1&B_1^J\\
B_2^L&0&B_1^L\\
-B_2^L&0&-B_1^L
\end{pmatrix}.
\end{equation}

However it should be shocking to get $3\times 3$ matrices in $SU(1,1)$ : we had abused between $\SO(2,1)$ and $SU(1,1)$.

\subsection{Another way to write a section (wrong way to do)}
%------------------------------------------------------------

The equivariant function $\hat{\psi}\colon SU(1,1)\to \Lambda W$ fulfills 
\[ 
  \hat{\psi}(U\cdot g)=\rho(g^{-1})\hat{\psi}(U)
\]
for all $g\in\Spin(1,1)$; in particular with $g=-\mtu$,
\begin{equation}
 \hat{\psi}(-U)=-\hat{\psi}(U).
\end{equation}
This gives the idea that it is not impossible to define $\hat{\psi}$ from its projection on $\SO(2,1)$ : we want to get $\tilde{\psi}\colon \SO(2,1)\to \Lambda W$ and define 
\[ 
  \hat{\psi}(U)=\tilde{\psi}\big( T(U) \big).
\]
More precisely, we parametrize $SU(1,1)$ by $\alpha$ and $\beta$ such that $| \alpha |^2-| \beta |^2=1$. Then we divide $SU(1,1)$ into two parts: $\alpha=x+iy$ is green when $x>0$ and when $x=0$, $y<0$; $\alpha$ is red when $x<0$ and when $x=0$, $y>0$. When $\alpha=0$, we classify following $\beta$ in the same way. The result is that $U$ is green if and only if $-U$ is red. For a map $\tilde{\psi}\colon \SO(2,1)\to \Lambda W$, we define
\begin{equation}
\hat{\psi}(U)=
\begin{cases}
\tilde{\psi}\big( T(U) \big)&\text{if $U$ is green}\\
-\tilde{\psi}\big(T(U)\big)&\text{if $U$ is red}
\end{cases}
\end{equation}
We define $T^{-1}\colon \SO(2,1)\to SU(1,1)$ as follows: $T^{-1}(A)$ is the green element of $SU(1,1)$ whose image by $T$ is $A$. In any cases we have
\[ 
\hat{\psi}\circ T^{-1}=\tilde{\psi}.  
\]
The meaning of equations \eqref{eq_nabJmoi} and \eqref{eq_nabLmoi} is that $\AD(r_0)$ is a matrix whose inverse image by $T$ should be given to $\hat{\psi}$; the difficulty is to know which of the two. When $U_0$ is green,
\[ 
 \begin{split}
\widehat{\nabla_a\psi}(U_0)&=\Dsdd{ (\hat{\psi}\circ T^{-1})  \AD(r_0)\Big( \cdots \Big)   }{s}{0} \\
        &=\Dsdd{ \tilde{\psi} \AD(r_0)\Big( \cdots \Big)}{s}{0},
\end{split} 
\]
while when $U_0$ is red,
\[ 
  \widehat{\nabla_a\psi}(U_0)=-\Dsdd{ \tilde{\psi}\AD(r_0)\Big( \cdots \Big) }{s}{0}.
\]
These two show that
\begin{equation}
\widetilde{\nabla_a\psi}\big( T(U_0) \big)=\Dsdd{   \tilde{\psi}\AD(r_0)\Big( \cdots \Big)    }{s}{0}
\end{equation}
All this is only proved in the interior of the green and red regions so that the path $U(s)$ keeps on only one region.

\subsection{Once again}  \label{pg_DiracADsdeux}
%-------------------------

We see $AdS_2$ as\footnote{Here, $G=SL(2,\eR)$} $\mO=\Ad(G)H$ and we consider a base point $o=\Ad(k_0)H$ with $G=SL(2,\eR)=ANK$. Let the principal bundle
\[ 
\xymatrix{%
   A \ar@{~>}[r]^{R}        &   G\ar[d]^{\pi}\\
    &   \mO
}
\]
with $A$ acting on $G$ by $(a,g)\mapsto ga$ and the projection
\begin{equation}
\pi(rk_0a)=\Ad(rk_0a)H.
\end{equation}
where $r\in R$ and $a\in A$. More precisely, the principal bundle we look at is
\begin{equation}
\xymatrix{%
   A \ar@{~>}[r]^{R}        &   \mU_G\ar[d]^{\pi}\\
    &   \mU
}
\end{equation}
where $\mU_G=Rk_0A$ and $\mU=\pi(\mU_G)=\Ad(Rk_0A)H=\Ad(Rk_0)H=\Ad(R)o$. The $\mU_G$ is so defined in order to be the $\pi^{-1}$ of an orbit $\mU=\Ad(R)o$.

We have a manifold isomorphism $R\simeq\mU$ given by
\[ 
  \phi\colon r\to \Ad(r)o.
\]
How to see a left invariant vector field on $R$ \emph{via} this identification ? 
\[ 
  d\phi\tilde X_r=d\phi\Dsdd{ r e^{tX} }{t}{0}
        =\Dsdd{ \Ad(r)\Ad( e^{tX})o }{t}{0}.
\]
This leads us to consider the following field for $X\in\sR$. We define $\xi_X(rk_0a)\in T_{rk_0a}\mU_G$,
\begin{equation}
  \xi_X(rk_0a)=\Dsdd{ r e^{tX}k_0a }{t}{0}.
\end{equation}
Let's see the projection :
\[ 
\begin{split}
d\pi_{rk_0a}\xi_X(rk_0a)&=\Dsdd{ \pi(r e^{tX}k_0a) }{t}{0}\\
        &=\Dsdd{ \Ad(r e^{tX}k_0a)H }{t}{0}\\
        &=\Dsdd{ \Ad(r e^{tX})o }{t}{0}.
\end{split} 
\]
This gives us the idea to define $X^{\sharp}\in T_{\Ad(rk_0a)H}\mU=T_{\pi(rk_0a)}\mU$ by
\begin{equation}
X^{\sharp}_{rk_0a}=\Dsdd{ \Ad(re^{tX})o }{t}{0},
\end{equation}
which is a good definition because $\pi(rk_0a)=\pi(r'k_0a')$ only when $r=r'$. We put the following connection on $\mU_G$ :
\begin{equation}
\alpha_{rk_0a}(\Sigma)=\left[     \big( dL_{rk_0a}^{-1} \big)_{rk_0a}\Sigma    \right]_{\sA}.
\end{equation}
We hope $\xi_X$ to be the horizontal lift\footnote{We will see in proposition \ref{prop_horliftXdiz} that it is not the case, but for the moment, we hope it.} of $X^{\sharp}$; by construction $d\pi\xi_X=X^{\sharp}$. We have
\[ 
 \begin{split}
\alpha_{rk_0a}(\xi_X)&=\left[ dL_{(rk_0a)^{-1}}\xi_X(rk_0a) \right]_{\sA}\\
        &=\Dsdd{ a^{-1}k_0^{-1}r^{-1}r e^{tX}k_0a }{t}{0}^{\sA}\\
        &=\Dsdd{ a^{-1}\AD(k_0^{-1}) e^{tX}a}{t}{0}^{\sA}\\
        &=\left[ \Ad(a^{-1}k_0^{-1})X \right]_{\sA}.
\end{split} 
\]
One can, by brute force computation\footnote{Or by remarking that $\sA$ is abelian.}, show that the difference $\Ad(ak_0)X-\Ad(k_0)X$ is skew-diagonal when
\[ 
  X=\begin{pmatrix}
a'&n\\0&-a'
\end{pmatrix},
\quad k_0=\begin{pmatrix}
\cos a&\sin a\\\sin a&\cos a
\end{pmatrix},
\quad
a=\begin{pmatrix}
a&0\\0&1/p
\end{pmatrix}.
\]
So $\Ad(a)$ does not change the $\sA$-component of $\Ad(k_0)X$. We conclude that
\begin{equation}
  \alpha(\xi_X)=\left[ \Ad(k_0^{-1})X \right]_{\sA}.
\end{equation}
When $X\in\sR$, we consider $\tilde X_g=(dL_g)_eX$;
\begin{equation}                         \label{eq_defXtilde}
  \tilde X_{rk_0a}=dL_{rk_0a}X,
\end{equation}
in particular, $\tilde X_r=\Dsdd{ r e^{tX} }{t}{0}$.
We denote by $\tau$ the action
\begin{equation}
\begin{aligned}
 \tau_g\colon\mO&\to \mO \\ 
\tau_g\Ad(r)H&= \Ad(gr)H 
\end{aligned}
\end{equation}
In particular
\[ 
 \begin{split}
d\pi_gdL_g Y&=\Dsdd{ \pi(g e^{tY}) }{t}{0}\\
        &=\Dsdd{ \ad(g e^{tY}H) }{t}{0}\\
        &=\Dsdd{ \tau_g\Ad( e^{tY})H }{t}{0}\\
        &=(d\tau_g)_Hd\pi_e Y,
\end{split} 
\]
thus
\begin{equation}
d\pi\circ dL = d\tau\circ d\pi.
\end{equation}
With definition \eqref{eq_defXtilde}, we have $\alpha(\tilde X)=X_{\sA}$ because
 \[ 
\alpha\big( dL_{rk_0a}X \big)=\left[ dL_{(rk_0a)^{-1}}dL_{rk_0a}X \right]_{\sA}
        =X_{\sA}.
\]
We are now able to find some horizontal lift. 
\begin{proposition}  \label{prop_horliftXdiz}
The horizontal lift of $X^{\sharp}$ is
\[
  \overline{ X^{\sharp} }=\xi_X-\widetilde{  [\Ad(k_0^{-1})X]_{\sA}  }.
\]

\end{proposition}

\begin{proof}
First, we have
\[ 
 \begin{split}
d\pi\overline{ X^{\sharp} }|_{rk_0a}&=d\pi\xi_X-d\pi(dL_{rk_0a})_e[\Ad(k_0^{-1})X]_{\sA}\\
                &=\Dsdd{ \Ad(r e^{tX}o) }{t}{0}-d\tau\,d\pi[\Ad(k_0^{-1})X]_{\sA}.
\end{split} 
\]
The first term is $X^{\sharp}$ while the second is zero because if $A\in\sA$, 
\[ 
 \begin{split}
d\pi A&=\Dsdd{ \pi( e^{tA}) }{t}{0}\\
        &=\Dsdd{ \Ad( e^{tA})H }{t}{0}\\
        &=0.
\end{split} 
\]
On the other hand,
\[ 
\alpha(\overline{ X^{\sharp} })=\alpha(\xi_X)-[\Ad(k_0)^{-1}X]_{\sA}=0.
\]
\end{proof}

Now we prove that the function $\overline{ X^{\sharp} }\cdot\hat{\psi}$ is equivariant, and therefore that the definition
\[ 
  \widehat{\nabla_{X^{\sharp}}\psi}=\overline{ X^{\sharp} }\cdot\hat{\psi}
\]
works. Using equivariance of $\hat{\psi}$, 
\begin{equation}
\begin{aligned}
  \overline{ X^{\sharp} }\cdot \hat{\psi}(ga_1)&=\Dsdd{ \hat{\psi}(\xi_X(t) }{t}{0}-\hat{\psi}\big( dL_{ga_1}[\Ad(k_0^{-1})X]_{\sA} \big)\\
        &=\Dsdd{ \hat{\psi}\big( r e^{tX}k_0aa_1 \big) }{t}{0}-\Dsdd{ \hat{\psi}\big( ga_1 e^{t[\Ad(k_0^{-1})X]_{\sA}} \big) }{t}{0}\\
        &=\Dsdd{ \rho(a_1)\hat{\psi}\big( r e^{tX}k_0a \big) }{t}{0}-\Dsdd{ \rho(a_1)\hat{\psi}\big( g e^{t[\Ad(k_0^{-1})X]_{\sA}} \big) }{t}{0},\\
        &=\rho(a_1)\hat{\psi}(\xi_X)-\Dsdd{ \rho(a_1)\hat{\psi}\big( \widetilde{[\Ad(k_0^{-1})X]_{\sA} }|_g \big) }{t}{0}\\
        &=\rho(a_1)\hat{\psi}(\xi_X)-\rho(a_1)\widetilde{ [\Ad(k_0^{-1})X]_{\sA}  }\hat{\psi}(g)\\
        &=\rho(a_1)(\overline{ X^{\sharp} }\cdot\hat{\psi})(g).
\end{aligned}
\end{equation}
for the third line, we used the fact that $\sA$ is abelian
\subsubsection{Clifford algebra for \texorpdfstring{$AdS_2$}{AdS2}}
%----------------------------------------------------------------

Our basis of $\sA\oplus\sN$ is
\[ 
  H=\begin{pmatrix}
1&0\\0&-1
\end{pmatrix}\quad\text{and}\quad
E=\begin{pmatrix}
0&1\\0&0
\end{pmatrix}
\]
and we choose
\[ 
  o=\Ad(k_0)H=\cos(2k_0)H+\sin(2k_0)(E+F).
\]
Since (at first order in $t$) $\Ad( e^{tH})o=\cos(2k_0)\mtu+\sin(2k_0)\big( E+2tE+F-2tF \big)$,
\[ 
  H^{\sharp}_{rk_0a}=2\sin(2k_0)\Ad(r)(E-F),
\]
and
\[ 
  E^{\sharp}_{rk_0a}=\Ad(r)\big( -2\cos(2k_0)E+\sin(2k_0)H \big).
\]
We have to compute the metric matrix for this basis; we know from equation \eqref{eq_KillAdinvariant}, the Killing form is $\Ad$-invariant and $(\mathfrak{sl}(2,\eR),B)\simeq(\eR^3,\eta_{21})$. So the $\Ad(r)$ disappears in the computation of $B(X^{\sharp},Y^{\sharp})$. We get
\[
\begin{split}
B(H^{\sharp},H^{\sharp})&=4\sin^2(2k_0)B(E-F,E-F)\\
        &=-32\sin^2(2k_0)\\
B(E^{\sharp},E^{\sharp})&=\sin^2(2k_0)B(H,H)\\
        &=8\sin^2(2k_0)\\
B(E^{\sharp},H^{\sharp})&=-4\sin(2k_0)\cos(2k_0)B(E,E-F)+2\sin^2(2k_0)B(H,E-F)\\
        &=16\sin^2(2k_0)\cos(2k_0).
\end{split}
\]
So the metric is in the basis $\{ H^{\sharp},E^{\sharp} \}$
\begin{equation}
g=
\begin{pmatrix}
-32\sin^2(2k_0) & 16\sin(2k_0)\cos(2k_0)\\
16\sin(2k_0)\cos(2k_0) & 8\sin^2(2k_0)
\end{pmatrix}.
\end{equation}
When we consider the orbit of $E+F$, we choose $o=E+F$, i.e. $\cos(2k_0)=0$, $\sin(2k_0)=1$ so that
\begin{equation}
H^{\sharp}_{rk_0a}=2\Ad(r)(E-F),\quad E^{\sharp}_{rk_0a}=\Ad(r)H,
\end{equation}
and
\[ 
  g=\begin{pmatrix}
-32&0\\0&8
\end{pmatrix};
\]
in the case of the orbit of $-(E+F)$, we get the same. The negative vector is $H^{\sharp}$ and the positive one is $E^{\sharp}$.

\subsubsection{Identification \texorpdfstring{$\sQ\leftrightarrow\Lambda W$}{QW}}
%////////////////////////////////////////////////////////////////////////////////

We want a linear bijection $\phi\colon \sQ\to \Lambda W$ such that
\[ 
  \rho(s)\phi(X)=\phi\big( \rho(s)X \big)
\]
where the left hand side action of $\Spin$ is the usual on $\Lambda W$ while the right hand side one remains to be defined. The implementation of this is easy: we can take any bijection between $\sQ$ and $\Lambda W$ and define
\begin{equation}
  \rho(s)X=\phi^{-1}\big( \rho(s)\phi(X) \big).
\end{equation}

Spinors on $AdS_2$ are given by equivariant functions $\hat{\psi}\colon \mU_G\to \Lambda W$ which are now replaced by $\tilde{\psi}\colon R\to \sQ\simeq\Lambda W$ by
\[ 
  \hat{\psi}(rk_0a)=\rho(a^{-1})\tilde{\psi}(r).
\]
So the set of sections of the spinor bundle over $\mU$ is
\[ 
  \Gamma_{\mU}\simeq  C^{\infty}(R,\Lambda W).
\]

\subsubsection{Covariant derivative}
%////////////////////////////////

The aim is now to compute 
\[ 
\begin{split}
   \widetilde{\nabla_{X^{\sharp}}\psi}(r)&=\widehat{\nabla_{X^{\sharp}}\psi}(rk_0)\\
        &=\overline{ X^{\sharp} }\cdot \hat{\psi}|_{rk_0}\\
        &=\big( \xi_X-\widetilde{ [\Ad(k_0^{-1})X]_{\sA}  } \big)\cdot\hat{\psi}|_{rk_0}\\
        &=\Dsdd{ \tilde{\psi}(r e^{tX}) }{t}{0}-\Dsdd{ \rho\big(  e^{t[\Ad(k_0^{-1})X]_{\sA}} \big) }{t}{0}\tilde{\psi}(r)\\
        &=\tilde X_r\tilde{\psi}(r)-d\rho_e\big( [\Ad(k_0^{-1})X]_{\sA} \big)\tilde{\psi}(r).
\end{split}  
\]
Our final formula for the covariant derivative is
\begin{equation}
  \widetilde{\nabla_{X^{\sharp}}\psi}(r)=\tilde X_r\tilde{\psi}-d\rho\big( [\Ad(k_0^{-1})X]_{\sA} \big)\tilde{\psi}.
\end{equation}
The Dirac operator will be a linear combination of vectors of the form
\[ 
  \tilde X+d\rho\big( [\Ad(k_0^{-1})X]_{\sA}  \big).  
\]
Notice that $\tilde X$ is left invariant and the second term is even independent of the point, so the whole is left invariant.
