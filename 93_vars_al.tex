% This is part of Mes notes de mathématique
% Copyright (c) 2011-2013,2015
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Les lois usuelles}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Loi de Bernoulli}
%---------------------------------------------------------------------------------------------------------------------------

Une expérience de Bernoulli consiste à tirer au hasard un \( 0\) ou un \( 1\) avec une probabilité \( p\) de tomber sur \( 1\) et \( 1-p\) de tomber sur zéro. Il s'agit donc d'une expérience qui réussit ou qui rate.

Le cas typique est une urne avec des boules indiscernables blanches ou noires. La probabilité \( p\) est la proportion de blanches dans l'urne (avec remise entre les tirages). Dans ce cas, nous avons l'espace de probabilité \( (\Omega,\tribA,P)\) où \( \Omega\) représente l'ensemble des boules, \( \tribA\) est l'ensemble des parties de \( \Omega\) et \( P\) est l'équiprobabilité sur \( \Omega\). Une variable aléatoire est une application
\begin{equation}
    \begin{aligned}
        X\colon \Omega&\to \{ 0,1 \} \\
        \omega&\mapsto \text{couleur de la boule \( \omega\)}.
    \end{aligned}
\end{equation}
Nous notons \( \dB(1,p)\) la loi de Bernoulli. Elle a une expression très simple :
\begin{subequations}
    \begin{align}
        \dB(0,1)\big( \{ 1 \} \big)&=p\\
        \dB(0,1)\big( \{ 0 \} \big)&=1-p
    \end{align}
\end{subequations}

Une variable aléatoire réelle est de \defe{Bernoulli}{Bernoulli} de paramètre \( p\) (\( 0<p<1\)) si
\begin{equation}
    X\colon \Omega\to \eR
\end{equation}
avec \( P(x=1)=p\) et \( P(X=0)=1-p\). En tant que mesure sur \( \eR\), nous avons
\begin{equation}
    P_X=p\delta_1+(1-p)\delta_0.
\end{equation}
Une fonction \( h\) qui réalise le supremum de la formule \eqref{EqDefintYfdmu} est par exemple une fonction en escalier qui vaut en \( x\) le plus petit entier plus grand ou égal à \( x\). L'espérance d'une loi de Bernoulli est alors
\begin{equation}
    E(x)=p.
\end{equation}
Étant donné que la variable aléatoire \( X\) prend seulement les valeurs \( 0\) et \( 1\), nous avons pour tout ensemble mesurable \( B\)
\begin{equation}
    P_{X^2}(B)=P(X^2\in B)=P(X\in B),
\end{equation}
et par conséquent \( P_{X^2}=P_X\) et \( E(X^2)=E(X)\). Nous trouvons donc la variance
\begin{equation}        \label{EqVarBern}
    \Var(X)=E(X^2)-E(X)^2=p-p^2=p(1-p).
\end{equation}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Loi binomiale}
%---------------------------------------------------------------------------------------------------------------------------

Une expérience binomiale consiste à répéter \( n\) expériences de Bernoulli de paramètre \( p\) et de compter le nombre de réussites. Une telle expérience peut être réalisée selon la procédure suivante.

Soit une urne contenant \( N\) boules dont une proportion \( p\) de \( 1\) et \( 1-p\) de \( 0\). Une expérience binomiale de paramètres \( n\) et \( p\) consistera à prendre \( n\) boules \emph{avec remise} et à compter le nombre de \( 1\) obtenus.

En termes d'espaces probabilisé, nous avons \( \Omega\) qui est l'ensemble des tuple de taille \( n\) à valeurs dans \( \{ 0,1 \}\), la tribu \( \tribA\) est l'ensemble des parties de \( \Omega\), et la probabilité \( P\) est l'équiprobabilité :
\begin{equation}
    P(\omega)=\frac{1}{ N^n }
\end{equation}
si il y a \( N\) boules dans l'urne. Nous construisons alors la variable aléatoire
\begin{equation}
    X(\omega)=\sum_{i=1}^n\omega_i
\end{equation}
où \( \omega\) est une suite de taille \( n\) de $0$ et de \( 1\).

Calculons \( P(X=k)\). Il s'agit de considérer tous les sous-ensembles de taille \( n\) de \( \Omega\) contenant exactement \( k\) fois \( 1\). Il y a \( {n\choose k}\) manière de décider lesquelles des \( n\) boules seront blanches. Ensuite, chaque boule blanche peut être choisie parmi les \( m\) boules disponibles, et chaque boule noire peut être choisie parmi les  \( (N-m)\) disponibles. Nous avons donc
\begin{equation}        \label{EqformunPxkBin}
    P(X=k)={n\choose k}\frac{ m^k(N-m)^{n-k} }{ N^k }.
\end{equation}
En effet la mesure de probabilité sur \( \Omega\) est la mesure de comptage renormalisée par le cardinal de \( \Omega\) qui vaut \( N^m\). Étant donné que \( p=m/N\), nous transformons facilement \eqref{EqformunPxkBin} en
\begin{equation}
    P(X=k)={n\choose k}p^k(1-p)^{n-k}.
\end{equation}

Une variable aléatoire de loi binomiale étant une somme de variables aléatoires de Bernoulli indépendantes, l'espérance\footnote{Valable même sans indépendance, proposition \ref{PropZBnsCgh}} et la variance\footnote{Lemme \ref{LemVarXpYsmindep}.} s'obtiennent en sommant les espérances et variances termes à terme  :
\begin{equation}    \label{EqDGbBgrv}
    E(X)=np
\end{equation}
et
\begin{equation}    \label{EqKLubWlh}
    \Var(X)=\sum_{i=1}^n\Var(X_i)=np(1-p)
\end{equation}
en vertu de \eqref{EqVarBern}.

La loi binomiale lorsque \( p=0.7\) et \( n=10\).       % attention : nombres codés en dur dans la figure

\begin{center}
   \input{Fig_YYECooQlnKtD.pstricks}
\end{center}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Loi multinomiale}
%---------------------------------------------------------------------------------------------------------------------------

La loi multinomiale \( \dM(n;k;p_1,\ldots, p_k)\) consiste à effectuer \( n\) épreuves d'une démarche aléatoire qui peut avoir \( k\) issues différentes avec probabilités \( p_1,\ldots, p_k\). Les variables aléatoires multinomiales sont \( N_i\) avec les contraintes
\begin{subequations}
    \begin{align}
        \sum_{i=1}^kN_i=n\\
        \sum_{i=1}^kp_i=1.
    \end{align}
\end{subequations}
La fonction de probabilité multinomiale est
\begin{equation}
    P(N_1=n_1,\ldots, N_k=n_k)=\frac{ n! }{ n_1!\ldots n_k! }p_1^{n_1}\ldots p_k^k.
\end{equation}
Chacune des \( N_i\) est une binomiale de probabilité \( p_i\).

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Loi géométrique}
%---------------------------------------------------------------------------------------------------------------------------

Soit \( (X_n)\) une suite indépendante et identiquement distribuée de lois de Bernoulli de paramètre \( p\). Alors la variable aléatoire
\begin{equation}
    Z=\inf\{ n\geq 1\tq X_n=1 \}
\end{equation}
est une loi géométrique de paramètre \( p\).

La loi géométrique compte donc le nombre d'expériences de Bernoulli à effectuer avant que le premier succès soit au rendez-vous. Nous avons
\begin{equation}
    P(Z=k)=P(X_k=1)P(X_1,\ldots,X_{k-1}=0)=p(1-p)^{k-1}
\end{equation}

La loi géométrique de paramètre \( p=0.2\).

\begin{center}
   \input{Fig_UIEHooSlbzIJ.pstricks}
\end{center}
Note : si \( p\) est trop grand, on ne voit vite plus rien parce que la probabilité d'attendre longtemps est vite très faible.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Loi de Poisson}
%---------------------------------------------------------------------------------------------------------------------------


Une variable aléatoire \( Z\) suit une \defe{loi de Poisson}{loi!de Poisson} de paramètre \( \lambda\), notée \( \dP(\lambda)\) si
\begin{equation}
    P(Z=k)= e^{-\lambda}\frac{ \lambda^k }{ k! }
\end{equation}
pour tout \( k\in\eN\).

La \wikipedia{fr}{Loi_de_Poisson}{loi de Poisson} est une loi de probabilité discrète qui décrit le comportement du nombre d'évènements se produisant dans un laps de temps fixé, si ces évènements se produisent avec une fréquence moyenne connue et indépendamment du temps écoulé depuis l'évènement précédent. 

Si un événement se produit en moyenne \( p\) fois par seconde, la probabilité d'observer l'événement \( k\) fois durant \( n\) secondes est donnée par \( P(Z=k)\) où \( Z\) est une loi de Poisson de paramètre \( \lambda=pn\).

\begin{theorem}[\wikipedia{fr}{Loi_de_Poisson}{wikipedia}]      \label{ThojDZjuj}
    L'espérance et la variance d'une variable aléatoire de Poisson sont \( \lambda\) :
    \begin{subequations}
        \begin{align}
            E(X)&=\lambda\\
            \Var(X)&=\lambda.
        \end{align}
    \end{subequations}
\end{theorem}

La loi de Poisson de paramètre \( \lambda=2\).

\begin{center}
   \input{Fig_UGCFooQoCihh.pstricks}
\end{center}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Loi exponentielle}
%---------------------------------------------------------------------------------------------------------------------------

La loi de exponentielle représente le temps qu'il faut attendre pour qu'une particule se désintègre si elle a en permanence une probabilité\quext{Étant donné que \( \lambda\) n'est pas limité à \( 1\), en réalité ce n'est pas une probabilité. Je suis preneur d'une bonne interprétation physique de ce paramètre.} \( \lambda dt\) de se désintégrer entre \( t\) et \( t+dt\). L'espérance est donc \( 1/\lambda\).

Il se passe donc en moyenne \( \lambda\) événements par seconde. La proposition \ref{PropGMntiy} nous montrera que le nombre d'événements se produisant en une seconde suit une loi de Poisson de paramètre \( \lambda\).

Plus formellement, la loi exponentielle de paramètre \( \lambda\), notée \( \dE(\lambda)\) est la loi de densité
\begin{equation}
    f_X\colon x\mapsto\begin{cases}
        \lambda e^{-\lambda x}    &   \text{si \( x\geq 0\)}\\
        0    &    \text{sinon}.
    \end{cases}
\end{equation}

Densité de la loi exponentielle de paramètre \( \lambda=2\).

\begin{center}
   \input{Fig_UMEBooVTMyfD.pstricks}
\end{center}

\begin{proposition} \label{PropTxGcWn}
    Si \( X\sim\dE(\lambda)\), alors la fonction de répartition de \( X\) est donnée par
    \begin{equation}
        F(x)=P(X\leq x)=\begin{cases}
            1- e^{-\lambda x}    &   \text{si \( x\geq 0\)}\\
            0    &    \text{sinon}.
    \end{cases}
    \end{equation}
    La fonction caractéristique est donnée par
    \begin{equation}
        E( e^{itX})=\frac{ \lambda }{ \lambda-it }.
    \end{equation}
    L'espérance et la variance sont données par
    \begin{equation}
        \begin{aligned}[]
            E(X)&=\frac{1}{ \lambda }\\
            \Var(X)&=\frac{1}{ \lambda^2 }.
        \end{aligned}
    \end{equation}
\end{proposition}

\begin{proof}    
    Pour la fonction caractéristique,
    \begin{subequations}
        \begin{align}
            E( e^{itX})&=\int_{-\infty}^{\infty} e^{it x}\lambda e^{-\lambda x}\mtu_{\mathopen[ 0 , \infty [}(x)dx\\
            &=\lambda\int_0^{\infty} e^{x(-\lambda+it)}dx\\
            &=\lim_{A\to\infty}\left[  \frac{  e^{x(-\lambda+it)} }{ it-\lambda } \right]_{x=0}^{x=A}\\
            &=\lim_{A\to \infty}\frac{  e^{A(it-\lambda)} }{ it-\lambda }-\frac{1}{ it-\lambda }.
        \end{align}
    \end{subequations}
    Le premier terme est nul parce que si on prend la norme,
    \begin{equation}
        \left| \frac{  e^{A(-\lambda+it)} }{ -\lambda+it } \right| =\frac{  e^{-\lambda A} }{ | it-\lambda | }\to 0.
    \end{equation}

    En ce qui concerne l'espérance nous faisons le calcul suivant :
    \begin{equation}
        E(X)=\int_{\eR}xf_X(x)dx=\lambda\int_{\eR^+}x e^{-\lambda x}dx=\frac{1}{ \lambda }.
    \end{equation}
    Pour la variance, nous utilisons la formule \eqref{EqtWqMGB}. Nous avons
    \begin{equation}
        E(X^2)=\int_{\eR}x^2f_X(x)=\int_0^{\infty}x^2\lambda e^{-\lambda x}=\frac{ 2 }{ \lambda^2 }.
    \end{equation}
    Donc \( \Var(X)=E(X^2)-E(X)^2=\frac{1}{ \lambda^2 }\).
\end{proof}

La loi exponentielle est une loi \defe{sans mémoire}{processus!sans mémoire}\index{loi!sans mémoire} en ce sens que
\begin{equation}
    P(X>x+y|X>y)=P(X>x).
\end{equation}
En effet nous utilisons la règle de la probabilité conditionnelle
\begin{equation}
    P(A|B)=\frac{ P(A\cap B) }{ P(B) }.
\end{equation}
Ici,
\begin{equation}
    P(X>x+y|X>y)=\frac{ P(X>x+y) }{ P(X>y) }= e^{-\lambda x}.
\end{equation}
La proposition suivante montre que la loi exponentielle est à peu près la seule à être sans mémoire. D'où son importance dans l'étude des machines dont les pièces ne subissent pas d'usure.

\begin{proposition} \label{PropREXaIBg}
    Soit \( X\), une variable aléatoire admettant une densité continue \( f\) par rapport à la mesure de Lebesgue. Si elle est sans mémoire, alors elle est exponentielle.
\end{proposition}

\begin{proof}
    Nous posons \( \varphi(x)=P(X\geq x)\). Cela est la fonction de répartition de \( X\) (à part que cette dernière est \( 1-\varphi(x)\) mais c'est pas grave), et est donnée par
    \begin{equation}
        \varphi(x)=1-\int_0^xf(t)dt.
    \end{equation}
    Cette dernière intégrale vérifie les hypothèses du théorème \ref{PropREXaIBg}, de telle sorte que \( \varphi\) soit une fonction dérivable et \( \varphi'(x)=f(x)\).
    
    D'autre part en utilisant la définition de la probabilité conditionnelle la propriété de ne pas avoir de mémoire donne
    \begin{equation}
        \varphi(x+y)=\varphi(x)\varphi(y)
    \end{equation}
    et de plus \( \varphi(0)=0\). Calculons la dérivée de \( \varphi\) :
    \begin{equation}
        \varphi'(x)=\lim_{\epsilon\to 0}\frac{ \varphi(x+\epsilon)-\varphi(x) }{ \epsilon }=\varphi(x)\lim_{\epsilon\to 0}\frac{ \varphi(\epsilon)-1 }{ \epsilon }=\varphi(x)\varphi'(0).
    \end{equation}
    Donc \( \varphi\) vérifie l'équation différentielle de l'exponentielle.
    
\end{proof}
\index{fonction!définie par une intégrale!utilisation}

\begin{example}
    Une machine a une durée de vie représentée par une variable aléatoire suivant une loi de Poisson de paramètre \( \lambda\). Soit \( T_y\) la variable aléatoire qui représente la temps de vie restant sachant que la machine a déjà vécu un temps \( y\). Nous voulons trouver la fonction de répartition de \( T_y\). Nous avons
    \begin{equation}
        P(T_y>x)=P(X>x+y|X>y)=P(X>x)= e^{-\lambda x}.
    \end{equation}
    Dans ce cas, la loi de \( T_y\) ne dépend pas de \( y\). Cela signifie que la machine ne vieilli pas et surtout que le modèle n'est pas réaliste.
\end{example}

\begin{proposition}
    Si \( X\sim\dE(\lambda)\) et \( Y\sim\dE(\mu)\) sont indépendantes, alors
    \begin{enumerate}
        \item
            \( P(X<Y)=\frac{ \lambda }{ \lambda+\mu }\)
        \item
            \( P(X>Y)=\frac{ \mu }{ \lambda+\mu }\)
        \item
            \( P(X=Y)=0\)
        \item
            \( \min(X,Y)\sim\dE(\lambda+\mu)\).
    \end{enumerate}
    De plus les variables aléatoires exponentielles ont une propriété d'absence de mémoire :
    \begin{equation}
        P(X>t+s|X>s)=P(X>t)= e^{-\lambda t}.
    \end{equation}
\end{proposition}

\begin{proof}
    Étant donné que \( X\) et \( Y\) sont indépendantes, la densité conjointe est le produit des densités (\ref{PropDensiteConjIndep}). Nous avons donc
    \begin{equation}
        P(X>Y)=\int_D\lambda e^{-\lambda x}\mu e^{-\mu y}dxdy
    \end{equation}
    où \( D\) est le domaine \( D=\{ (x,y)\in \eR^2\tq x,y>0, x>y \}\). Nous avons donc
    \begin{equation}
        P(X>Y)=\lambda\mu\int_0^{\infty}dx\int_0^xdy  e^{-\lambda x} e^{-\mu y}=\frac{ \mu }{ \lambda+\mu }.
    \end{equation}
    \begin{verbatim}
sage: var('a,b')
(a, b)
sage: f(x,y)=exp(-a*x)*exp(-b*y)
sage: assume(a>0)
sage: assume(b>0)
sage: a*b*f.integrate(y,0,x).integrate(x,0,oo)
(x, y) |--> a*b/(a^2 + a*b)
    \end{verbatim}
    
    Pour trouver la loi de \( \min(X,Y)\), nous écrivons
    \begin{subequations}
        \begin{align}
            P\big( \min(X,Y)>t \big)&=P(X>t,Y>t)\\
            &=P(X>t)P(Y>t)  &\text{par indépendance}\\
            &=\big( 1-F_X(t) \big)\big( 1-F_Y(t) \big)\\
            &= e^{-(\lambda+\mu)t}\mtu_{\mathopen[ 0 , \infty [}(t)\\
            &=1-F_Z(t)
        \end{align}
    \end{subequations}
    où \( Z\sim \dE(\lambda+\mu)\).
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Approximation de la binomiale par une Poisson}
%---------------------------------------------------------------------------------------------------------------------------

\begin{proposition}
    Soit \( (X_n)\) une suite de variables aléatoires avec \( X_n\sim\dB(n,p_n)\) telle que \( np_n\) converge vers une constante \( \lambda>0\). Alors \( X_n\stackrel{\hL}{\longrightarrow}\dP(\lambda)\).
\end{proposition}

\begin{proof}
    Commençons par écrire la loi binomiale sous une forme plus adaptée au passage à la limite :
    \begin{equation}
        P(X=k)={n\choose k}p^k(1-p)^{n_k}=\frac{ n(n-1)\ldots (n-k+1) }{ k! }p^k(1-p)^{n-k}.
    \end{equation}
    Le produit au numérateur contient \( k\) termes dans lesquels nous mettons \( n\) en évidence. Nous trouvons
    \begin{equation}
        P(X=k)=\frac{ (np)^k\left( 1-\frac{1}{ n } \right)\left( 1-\frac{ 2 }{ n } \right)\ldots\left( 1-\frac{ k-1 }{ n } \right) }{ k! }p^k(n-p)^{n-k}.
    \end{equation}
    Lorsque nous passons à la limite, tous les facteurs du type \( 1-l/n\) tendent vers \( 1\) ainsi que \( (1-p_n)^{-k}\). Les facteurs dont la limite n'est pas \( 1\) sont donc
    \begin{equation}
        P(X_n=k)\simeq\frac{ (np_n)^k }{ k! }(1-p_n)^k.
    \end{equation}
    Nous avons
    \begin{equation}
        \lim_{n\to \infty} (1-p_n)^n=\lim_{n\to \infty} \left( 1-\frac{ np_n }{ n } \right)^n= e^{-\lambda}.
    \end{equation}
    La thèse est alors obtenue en remettant les morceaux ensemble.
\end{proof}

\begin{example}
    Considérons un serveur informatique qui reçoit des requêtes. Toutes les \( \unit{10^{-3}}{\second}\) il reçoit une requête avec une probabilité \( p=0.05\). La variable aléatoire qui consiste à donner le nombre de requêtes effectivement effectuées en une seconde suit une loi binomiale \( \dP(1000,p)\).

    Déterminons la probabilité que le serveur reçoive \( 20\) requêtes en une seconde. Nous approximons \( \dB(1000,0.05)\) par \( \dP(50)\), et la réponse est
    \begin{equation}
        e^{-50}\frac{ 50^{20} }{ 20! }\simeq 7\cdot 10^{-7}.
    \end{equation}
\end{example}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Loi de Poisson et loi exponentielle}
%---------------------------------------------------------------------------------------------------------------------------
\label{subsecPoissonetexpo}

Soient \( X_1,\ldots,X_n\) des variables aléatoires réelles indépendantes de loi exponentielle de paramètre \( \lambda\). En utilisant le produit de convolution, nous pouvons trouver la fonction de densité de la somme (voir point \ref{subsecscnvommevariablsindep}). Commençons avec deux variables aléatoires \( X\) et \( Y\). Les densités sont
\begin{subequations}
    \begin{align}
        f_X(x)&=\mtu_{[x\geq 0]}\lambda e^{-\lambda x}\\
        f_Y(y)&=\mtu_{[y\geq 0]}\lambda e^{-\lambda y},
    \end{align}
\end{subequations}
et la densité conjointe est alors
\begin{subequations}
    \begin{align}
        f_{X+Y}(x)&=\int_{\eR}\mtu_{[x-t\geq 0]}\lambda e^{-\lambda(x-t)}\mtu_{[t\geq 0]}\lambda e^{-\lambda t}dt\\
        &=\lambda^2 e^{-\lambda x}\int_0^x1\,dt\\
        &=x\lambda^2 e^{-\lambda x}.
    \end{align}
\end{subequations}
Par récurrence si \( S=X_1+\ldots+X_n\) nous trouvons
\begin{equation}
    f_S(x)=x^{n-1}\lambda^n e^{-\lambda x}.
\end{equation}

\begin{proposition}[\cite{Suquet}]      \label{PropGMntiy}
Soit \( (T_k)_{k\in\eN}\) une suite de variables aléatoires indépendantes de loi \( \dE(\lambda)\). Nous considérons la variable aléatoire \( S_n=\sum_{i=1}^nX_i\) et pour chaque \( t\in\eR^+\) nous considérons
\begin{equation}
    N_t=\max\{ n\geq 1\tq \sum_{i=1}^nT_i\leq t \}.
\end{equation}
Alors \( N_t\sim\dP(\lambda t)\). 

\end{proposition}

\begin{proof}
Ce que nous devons calculer est
\begin{equation}
    P(N_t=k)=P(S_{n}\leq t\leq S_{n+1}).
\end{equation}
Nous introduisons la variable aléatoire \( V_{n=1}=(X_1,\ldots,X_{n+1})\) ainsi que l'ensemble
\begin{equation}
    A_{n+1}=\{ x\in\eR^{n+1}\tq x_1+\ldots+x_n\leq t\leq x_1+\ldots+x_n+x_{n+1} \}.
\end{equation}
Le problème est donc de calculer
\begin{equation}
    P(S_n\leq t\leq S_{n+1})=P(V_{n+1}\in A_{n+1}^+)=\int_{A_{n+1}^+}f_{n+1}(x)dx
\end{equation}
où \( A_{n+1}^+\) est la partie de $A_{n+1}$ dans laquelle \( x_i\geq 0\) pour tout \( i\) et \( f_{n+1}\) est la fonction de densité conjointe des variables aléatoires \( X_i\). Nous effectuons le changement de variables
\begin{subequations}
    \begin{align}
        s_k&=\sum_{i\leq k}x_i\\
        x_k&=s_k-s_{k-1}
    \end{align}
\end{subequations}
dont le déterminant vaut \( 1\). D'autre part par indépendance des variables aléatoires \( X_i\), la fonction de partition jointe \( f_{n+1}\) s'exprime sous la forme
\begin{subequations}
    \begin{align}
        f_{n+1}(x_1,\ldots,x_{n+1})&=f_{X_1}(x_1)\ldots f_{X_{n+1}}(x_{n+1})\\
        &=\lambda^{n+1} e^{-\lambda(x_1+\ldots+x_{n+1})}\\
        &=\lambda^{n+1} e^{-\lambda s_{n+1}}.
    \end{align}
\end{subequations}
En ce qui concerne les bornes de l'intégrale dans les variables \( s_i\), nous voulons que tous les \( x_i\) soient positifs, par conséquent \( s_1\geq 0\) et ensuite l'équation \( x_k=s_k-s_{k-1}\) demande \( s_k\geq s_{k-1}\). Les bornes sont donc données par l'ensemble
\begin{equation}
    0\leq s_1\leq s_2\leq\ldots\leq s_n\leq t\leq s_{n+1},
\end{equation}
c'est à dire \( B_n\times \mathopen] t , \infty \mathclose[\) où 
\begin{equation}
    B_n=\{ (s_1,\ldots,s_n)\tq 0\leq s_1\leq s_2\leq\ldots\leq s_n\leq t \}.
\end{equation}
Le théorème de Fubini nous permet de décomposer l'intégrale :
\begin{subequations}
    \begin{align}
        P(S_n\leq t\leq S_{n+1})&=\int_{B_n\times\mathopen] t , \infty \mathclose[}\lambda^{n+1} e^{-\lambda s_{n+1}}ds_1\ldots ds_{n+1}\\
        &=\lambda^{n+1}\left( \int_{B_n}ds_1\ldots ds_n \right)\underbrace{\left( \int_t^{\infty} e^{-\lambda s_{n+1}}ds_{n+1} \right)}_{=\lambda^{-1} e^{-\lambda t}}\\
        &=\lambda^n e^{-\lambda t}\Vol(B_n)
    \end{align}
\end{subequations}
où \( \Vol(B_n)\) est le volume de \( B_n\) qui reste à calculer. L'ensemble \( C^n=[0,t]^n\) se décompose en cellules disjointes (à ensemble de mesure nulle près) de la forme
\begin{equation}
    C_{\sigma}=\{ 0\leq s_{\sigma(1)}\leq s_{\sigma(2)}\leq\ldots\leq s_{\sigma(n)}\leq t \}
\end{equation}
pour chaque permutation \( \sigma\in S_n\). Il y a exactement \( n!\) telles cellules dans \( C^n\). Par conséquent
\begin{equation}
    t^n=\Vol(C^n)=n!\Vol(C_{\sigma})=n!\Vol(B_n)
\end{equation}
et \( \Vol(B_n)=\frac{ t^n }{ n! }\). Finalement nous avons
\begin{equation}
    P(n_t=n)=P(S_n\leq t\leq S_{n+1})=\frac{ (\lambda t)^n }{ n! } e^{-(\lambda t)}.
\end{equation}
    
\end{proof}
%---------------------------------------------------------------------------------------------------------------------------
\subsection{Loi normale}
%---------------------------------------------------------------------------------------------------------------------------

La loi normale de paramètres \( m\) et \( \sigma>0\), notée \( \dN(m,\sigma^2)\) est la loi donnée par la densité
\begin{equation}
    \gamma_{m,\sigma^2}(x)=\frac{1}{ \sigma\sqrt{2\pi} }\exp\left[ -\frac{ 1 }{2}\left( \frac{ x-m }{ \sigma } \right)^2 \right].
\end{equation}

\begin{proposition}
    Si la variable aléatoire réelle \( X\) suit une loi normale \( \dN(m,\sigma^2)\), alors nous avons \( E(X)=m\) et \( \Var(X)=\sigma^2\).
\end{proposition}

\begin{proof}
    L'espérance d'une variable aléatoire se calcule à partir de la formule \eqref{EqEspDensform}:
    \begin{subequations}
        \begin{align}
            E(X)&=\frac{1}{ \sigma\sqrt{2\pi} }\int_{\eR}x\exp\left[ -\frac{1}{ 2 }\left( \frac{ x-m }{ \sigma } \right)^2 \right]dx\\
            &=\frac{1}{ \sigma\sqrt{2\pi} }\sigma\int_{\eR}(\sigma u+m) e^{-u^2/2}
        \end{align}
    \end{subequations}
    où nous avons effectué le changement de variable \( u=(x-m)/\sigma\). Nous utilisons ensuite l'intégrale remarquable
    \begin{equation}
        \int_{\eR} e^{-u^2/2}du=\sqrt{2\pi}.
    \end{equation}

    En ce qui concerne la variance, nous avons le même genre de calculs.
\end{proof}

La \defe{loi normale réduite}{normale!loi réduite} est la densité
\begin{equation}
    \gamma(x)=\gamma_{0,1}(x)=\frac{1}{ \sqrt{2\pi} } e^{-x^2/2}.
\end{equation}
La variable aléatoire \( X\) suit la loi \( \dN(m,\sigma^2)\) si et seulement si la variable aléatoire $Z=\frac{ X-m }{ \sigma }$ suit la loi normale réduite \( \dN(0,1)\).

\begin{proposition}     \label{PropFnCaractNorm}
    La fonction caractéristique de la distribution normale \( \dN(m,\sigma^2)\) est
    \begin{equation}
        \Phi_{\dN(m,\sigma^2)}(t)=\exp\left( itm-\frac{ \sigma^2t^2 }{ 2 } \right).
    \end{equation}
\end{proposition}

\begin{proof}
    En suivant la formule \eqref{EqFnCaractfncadens}, l'intégrale à calculer est 
    \begin{equation}
        \Phi_{\dN(m,\sigma^2)}(t)=\frac{1}{ \sigma\sqrt{2\pi} }\int_{\eR} e^{itx} e^{-\frac{ 1 }{2}\left( \frac{ x-m }{ \sigma } \right)^2}dx.
    \end{equation}
    Nous reconnaissons une transformée de Fourier. Afin de la calculer sans encombres, nous passons par les fonctions intermédiaires suivantes :
    \begin{equation}
        \begin{aligned}[]
            g(x)&= e^{-\frac{ 1 }{2}x^2}\\
            h(x)&=g\left( \frac{ x }{ \sigma } \right)\\
            k(x)&=h(x-m).
        \end{aligned}
    \end{equation}
    La fonction caractéristique que nous cherchons est \( \frac{1}{ \sigma\sqrt{2\pi} }\hat k(t)\). Les formules liées à la transformée de Fourier nous donnent
    \begin{subequations}
        \begin{align}
            \hat k(t)&=\hat h(t) e^{itm}    \label{subeqhatktrTFinvitm}\\
            \hat h(t)&=\sigma\hat g(\sigma t)\\
            \hat g(t)&=\int_{\eR} e^{-itx} e^{-\frac{ 1 }{2}x^2}dx=\sqrt{2\pi} e^{-t^2/2}.
        \end{align}
    \end{subequations}
    Attention : l'intégrale à calculer est une transformée de Fourier \emph{inverse}, d'où la formule \eqref{subeqhatktrTFinvitm} qui a un signe de différence avec la formule usuelle. En recombinant toutes ces expressions nous trouvons
    \begin{equation}
        \Phi_{\dN(m,\sigma^2)}= e^{-\sigma^2t^2/2} e^{itm},
    \end{equation}
    ce qu'il nous fallait.
\end{proof}

\begin{example}
    Une espérance qui sert de temps en temps est celle de \( X= e^{\beta Z}\) lorsque \( Z\sim\dN(0,1)\). Elle se calcule en remarquant que \( x^2-2\beta x=(x-\beta)^2-\beta^2\), donc
    \begin{subequations}        \label{EqEspexpbetaZnorm}
        \begin{align}
            E( e^{\beta Z})&=\frac{1}{ 2\pi }\int_{\eR} e^{\beta x} e^{-x^2/2}dx\\
            &=\frac{1}{ \sqrt{2\pi} }\int_{\eR} e^{-\frac{ 1 }{2}(x-\beta)^2} e^{\beta^2/2}\\
            &=\frac{  e^{\beta^2/2} }{ \sqrt{2\pi} }\int_{ e^{-y^2/2}}dy\\
            &= e^{\beta^2/2}.
        \end{align}
    \end{subequations}
\end{example}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Vecteurs gaussiens}
%---------------------------------------------------------------------------------------------------------------------------

Source : \cite{ProbaDanielLi,GaussienYoann}.

\begin{definition}
    Un vecteur aléatoire \( X\colon \Omega\to \eR^d\) est un \defe{vecteur gaussien}{vecteur!gaussien}\index{loi!normale!vecteur gaussien} si toutes les combinaisons linéaires de ses composantes sont des variables aléatoires normales. En d'autres termes, \( X\) est un vecteur gaussien si pour tout vecteur \( u\), la variable aléatoire \( u\cdot X\) est gaussienne.
\end{definition}

Le vecteur moyenne d'un vecteur gaussien est \( E(X)=\big( E(X_1),\ldots, E(X_n) \big)\) et sa matrice de \defe{variance-covariance}{variance!vecteur gaussien} est la matrice\nomenclature[P]{\( K_X\)}{matrice de covariance d'un vecteur gaussien}
\begin{equation}
    K_X=\Var(X)=E\Big[ \big( X-E(X) \big)\otimes \big( X-E(X) \big) \Big]
\end{equation}
où l'opération \( \otimes\) est celle introduite dans la section \ref{SeOOpHsn}. Cela n'est rien d'autre que la matrice de covariance de la variable aléatoire \( X\colon \Omega\to \eR^d\).

\begin{lemma}
    Si les variables aléatoires réelles \( X_1,\ldots, X_n\) sont des variables aléatoires réelles gaussiennes indépendantes, alors le vecteur \( X=(X_1,\ldots, X_n)\) est un vecteur gaussien.
\end{lemma}

\begin{proof}
    Nous devons montrer que si \( X\) et \( Y\) sont des variables aléatoires gaussiennes indépendantes, alors \( X+Y\) est encore gaussienne. L'indépendance nous assure les égalités suivantes pour la fonction caractéristique :
    \begin{equation}
        \Phi_{X+Y}(t)=E\big(  e^{it(X-Y)} \big)=E\big(  e^{itX} \big)E\big(  e^{itY} \big).
    \end{equation}
    Dans le cas où \( X\) et \( Y\) sont gaussiens nous trouvons
    \begin{equation}
        \Phi_{X+Y}(t)=\exp\left( im_1t-\frac{ \sigma_1^2t^2 }{2} \right)\exp\left( im_2t-\frac{ \sigma_2^2t^2 }{2} \right)=\exp\left( i(m_1+m_2)t-\frac{ (\sigma_1^2+\sigma_2^2)t^2 }{2} \right).
    \end{equation}
    Étant donné que la loi d'une variable aléatoire est entièrement déterminée par sa fonction caractéristique (théorème \ref{ThonMxtTy}), nous déduisons que \( X+Y\) est une normale de moyenne \( m_1+m_2\) et de variance \( \sigma=\sigma_1^2+\sigma_2^2\).
\end{proof}

\begin{proposition} \label{Propfmzuol}
    La fonction caractéristique d'un vecteur gaussien est donnée par
    \begin{equation}
        \Phi_X(u)=\exp\left( iu\cdot E(X)- \frac{ 1 }{2} u\cdot K_Xu \right)
    \end{equation}
    où \( K_X\) est la matrice de covariance de \( X\).
\end{proposition}

\begin{proof}
    Nous considérons la variable aléatoire réelle gaussienne \( u\cdot X\). Son espérance \( m=E(u\cdot X)=u\cdot E(X)\). Nous commençons par établir la formule suivante :
    \begin{equation}
        u^tK_Xu=u\cdot K_Xu=E\Big[ \big( [X-E(X)]\cdot u \big)^2 \Big].
    \end{equation}
    Utilisant la linéarité de l'espérance,
    \begin{equation}
        \sum_{kl}E(A_{kl})u_ku_l=\sum_{kl}E(A_{kl}u_ku_l),
    \end{equation}
    nous trouvons
    \begin{subequations}
        \begin{align}
            K_X(u,u)&=E\Big( [X-E(X)]\otimes [X-E(X)] \Big)(u,u)\\
            &=E\Big( \big( [X-E(X)]\otimes [X-E(X)] \big)(u,u) \Big)\\
            &=E\Big( \big( [X-E(X)]\cdot u \big)\big( [X-E(X)]\cdot u \big) \Big)\\
            &=E\left( \big( [X-E(X)]\cdot u \big)^2 \right).
        \end{align}
    \end{subequations}
    Par la linéarité du produit scalaire et de l'espérance,
    \begin{equation}
        [X-E(X)]\cdot u=u\cdot X-E(u\cdot X),
    \end{equation}
    ce qui nous ramène à la variable aléatoire \( u\cdot X\). Nous avons alors
    \begin{subequations}
        \begin{align}
            K_X(u,u)=E\left[ \big( [X-E(X)]\cdot u \big)^2 \right]=\Var(u\cdot X).
        \end{align}
    \end{subequations}
    Nous avons donc obtenu une forme pour la variance de la variable aléatoire \( u\cdot X\). Étant donné que \( u\cdot X\) est gaussienne de moyenne \( m=u\cdot E(X)\) et de variance \( \sigma^2=K_X(u,u)\), nous avons
    \begin{equation}    \label{EqJJftOX}
        \Phi_{u\cdot X}(t)=\exp\big( itm-\frac{ 1 }{2}\sigma^2t^2 \big).
    \end{equation}
    Par ailleurs nous avons \( \Phi_X(u)=\Phi_{u\cdot X}(1)\) parce que
    \begin{equation}
        \Phi_X(u)=E\big(  e^{iu\cdot X} \big)=\Phi_{u\cdot X}(1).
    \end{equation}
    En utilisant la forme \eqref{EqJJftOX} pour \( \Phi_{u\cdot X}\) nous trouvons
    \begin{equation}
        \Phi_X(u)=\Phi_{u\cdot X}(1)=\exp\big( im-\frac{ 1 }{2}\sigma^2 \big)=\exp\Big( iE(u\cdot X)-\frac{ 1 }{2}u\cdot KXu \Big).
    \end{equation}
\end{proof}

\begin{theorem} \label{ThoPRkxPdQ}
    Soit \( X=(X_1,\ldots, X_d)\), un vecteur gaussien. Les composantes sont indépendantes si et seulement si elles sont non corrélées.
\end{theorem}

\begin{proof}
    Nous savons que les variables aléatoires indépendantes sont non corrélées. Nous devons donc surtout prouver le contraire. Le fait que les variables aléatoires \( X_i\) soient non corrélées signifie que la matrice de covariance est
    \begin{equation}
        K_X=\begin{pmatrix}
            \sigma_1^2    &       &   0    \\
                &   \ddots    &       \\
            0    &       &   \sigma_d^2
        \end{pmatrix}
    \end{equation}
    où \( \sigma_k^2=\Var(X_k)\). Notons \( m_k=E(X_k)\). Si \( u\in \eR^d\), nous avons en vertu de la proposition \ref{Propfmzuol} que
    \begin{subequations}
        \begin{align}
            \Phi_X(u)&=\exp\Big( i(u_1m_1+\ldots +u_dm_d)-\frac{ 1 }{2}(\sigma_1^2u_1^2+\ldots +\sigma_d^2u_d^2) \Big)\\
            &=\exp\big( iu_1m_1-\frac{ 1 }{2}\sigma_1^2u_1^2 \big)\ldots\exp\big( iu_dm_d-\frac{ 1 }{2}\sigma_d^2u_d^2 \big)\\
            &=\Phi_{X_1}(u_1)\ldots \Phi_{X_d}(u_d).
        \end{align}
    \end{subequations}
    Les variables aléatoires \( X_i\) sont donc indépendantes parce que la fonction caractéristique se factorise.
\end{proof}

\begin{example}
    Nous donnons à présent un exemple de deux variables aléatoires gaussiennes qui ne forment pas un vecteur gaussien. Pour ce faire nous devons chercher des variables aléatoires non indépendantes. Soit \( Y\sim \dN(0,1)\) et \( \epsilon\) une variable aléatoire (indépendante de \( Y\)) donnée par \( P(\epsilon=-1)=\frac{ 1 }{2}\), \( P(\epsilon=1)=\frac{ 1 }{2}\). Nous considérons le vecteur \( (Y,\epsilon Y)\).

    D'abord montrons que \( \epsilon Y\) est une variable aléatoire gaussienne. Soit \( A\) un borélien de \( \eR\). Nous avons
    \begin{equation}
        P(\epsilon Y\in A)=P(\epsilon=-1,Y\in A)+P(\epsilon=-1,-Y\in A).
    \end{equation}
    Par indépendance et par symétrie de \( Y\)\footnote{C'est à dire que \( P(Y\in A)=P(Y\in -A)=P(-Y\in A)\).} nous trouvons
    \begin{subequations}
        \begin{align}
            P(\epsilon Y\in A)&=P(\epsilon=1)P(Y\in A)+P(\epsilon=-1)P(-Y\in A)\\
            &=\frac{ 1 }{2}P(Y\in A)+\frac{ 1 }{2}P(-Y\in A)\\
            &=P(Y\in A).
        \end{align}
    \end{subequations}
    Nous avons donc \( Y\sim \epsilon Y\), et donc \( \epsilon Y\) est gaussienne.

    En ce qui concerne la covariance, nous savons que \( E(Y)=E(\epsilon)=0\), donc
    \begin{equation}
        \Cov(Y,\epsilon Y)=E(Y\cdot \epsilon Y)=E(\epsilon Y^2)=E(\epsilon)E(Y^2)=0.
    \end{equation}
    Note : \( E(Y^2)=1\).

    Les variables aléatoires \( Y\) et \( \epsilon Y\) ne sont pas indépendantes. En effet si elles l'étaient, \( Y\) serait aussi indépendante de \( (\epsilon Y)^2=Y^2\), alors que \( Y\) et \( Y^2\) ne sont pas indépendantes. Donc \( X=(Y,\epsilon Y)\) n'est pas un vecteur gaussien.
\end{example}

\begin{theorem}[\cite{ProbaDanielLi}]
    Soit \( m\in \eR^d\) et \( K\in \eM(d,\eR)\) une matrice symétrique et positive. Alors il existe un vecteur gaussien de moyenne \( m\) et de matrice de covariance \( K\).
\end{theorem}

\begin{proof}
    Nous effectuons la preuve avec \( m=0\). Nous choisissons l'espace probabilisé \( (\Omega,\tribA)=(\eR^r,\Borelien(\eR^r))\) où \( r\) est le rang de \( K\) muni de la probabilité de densité
    \begin{equation}    \label{EqozOZiQ}
        \gamma(u)=\frac{1}{ (2\pi)^{r/2} }\exp\big( -\frac{ 1 }{2}\| u \|^2 \big).
    \end{equation}
    Nous considérons la variable aléatoire
    \begin{equation}
        \begin{aligned}
            Y_0\colon \Omega&\to \eR^r \\
            u&\mapsto u. 
        \end{aligned}
    \end{equation}
    C'est une variable aléatoire gaussienne de loi \( P_{Y_0}=\gamma\lambda_d\) où \( \lambda_d\) est la mesure de Lebesgue sur \( \eR^d\). Sa densité \eqref{EqozOZiQ} s'écrit comme le produit de \( r\) gaussiennes indépendantes; sa matrice de covariance est donc \( \mtu_{r\times r}\).

    Étant donné que \( K\) est symétrique et positive, il existe une matrice \( d\times r\) telle que \( K=AA^t\). Pour voir cela, remarquons qu'il existe une matrice \( d\times d\) qui fait le travail. En effet \( K\) se diagonalise par une orthogonale (théorème \ref{ThoeTMXla}) :
    \begin{equation}
        K=ADA^t=A\sqrt{D}\sqrt{D}A^t
    \end{equation}
    où \( D\) est une matrice diagonale contenant \( d-r\) zéros et \( \sqrt{D}\) est la matrice que l'on imagine. Donc la matrice \( L=A\sqrt{D}\) est une matrice telle que \( LL^t=K\). Maintenant, étant donné que les \( d-r\) dernières lignes de \( D\) sont vides, les \( d-r\) dernières lignes de \( L\) n'ont pas d'importance et peuvent être choisies nulles, voire même ne pas exister. La matrice \( A\in\eM_{d\times r,\eR}\) qui réalise \( AA^t=K\) est la «troncature» de \( L\) à ses \( r\) premières lignes.
    
    Nous considérons la variable aléatoire \( Y=AY_0\colon \Omega\to \eR^d\). Étant donné que \( AY_0\) est une transformation linéaire d'un vecteur gaussien, c'est un vecteur gaussien. Nous avons encore \( m(Y)=0\) et 
    \begin{equation}
        \Var(Y)=E(Y\otimes Y)=E\big( (AY_0)\otimes (AY_0) \big)=AE(Y_0\otimes Y_0)A^t=AA^t=K
    \end{equation}
    parce que \( E(Y_0\otimes Y_0)=\mtu\). Nous avons utilisé les formules de la section \ref{SeOOpHsn}, et en particulier la formule \eqref{EqXdxvSu}.
\end{proof}

Lorsqu'une matrice symétrique et positive \( K\) est donné, nous avons créé un vecteur gaussien de covariance \( K\) en créant \( X=AY\) où \( Y\) est le vecteur gaussien «le plus simple» et où \( A\) est donné par \( AA^t=K\). La proposition suivante montre l'inverse : un vecteur gaussien \( X\) peut se réduire au vecteur gaussien «le plus simple» en utilisant la transformation \( Y=A^{-1}X\) où \( A\) est encore donnée par \( AA^t=K\). Ce résultat nous permettra de voir les vecteurs gaussiens généraux comme des «changements de coordonnées» par rapport au vecteur gaussien simple \( Y=(Y_1,\ldots, Y_d)\) avec \( Y_i\sim\dN(0,1)\).

\begin{proposition} \label{PropGacmRi}
    Soit \( Y=(Y_1,\ldots, Y_n)\) le vecteur gaussien formé des variables aléatoires indépendantes \( Y_i\sim\dN(0,1)\). Soit \( K\) une matrice symétrique et positive et la matrice \( A\) telle que \( AA^t=K\). Alors le vecteur \( X=AY\) est gaussien de covariance \( K\). 
\end{proposition}

\begin{proof}
    Nous montrons que la covariance de \( X=AY\) est donnée par \( K\). Nous avons 
    \begin{subequations}
        \begin{align}
            K_X&=E\big( [X-E(X)]\otimes [X-E(X)] \big)\\
            &=E\big( A(Y-E(Y))\otimes A(Y-E(Y)) \big)\\
            &=E\Big( A\big( [Y-E(Y)]\otimes [Y-E(Y)] \big)A^t \Big)\\
            &=E(AA^t)\\
            &=K_X.
        \end{align}
    \end{subequations}
    Nous avons utilisé le lemme \ref{LemMyKPzY} ainsi que le fait que 
    \begin{equation}
        [Y-E(Y)]\otimes [Y-E(Y)]=K_Y=\mtu.
    \end{equation}
    Notons que \( E(Y)=0\), mais cela ne joue pas ici.
\end{proof}

\begin{theorem}
    Un vecteur gaussien \( X\colon \Omega\to \eR^d\) possède une densité par rapport à la mesure de Lebesgue si et seulement si sa matrice de covariance est inversible. Dans ce cas nous avons la densité
    \begin{equation}        \label{EqzulwmY}
        f_X(x)=\frac{1}{ (2\pi)^{d/2} }\frac{1}{ \sqrt{| \det(K_X) |} }\exp\left( -\frac{ 1 }{2}[X-E(X)]\cdot K_X^{-1}[X-E(X)] \right).
    \end{equation}
\end{theorem}

\begin{proof}
    Nous supposons que \( E(X)=0\). En utilisant la proposition \ref{PropGacmRi}, nous posons \( X=AY\) où \( Y\) est un vecteur gaussien \( Y\sim\dN(0,\mtu)\) et \( AA^t=K_X\). Si \( K\) n'est pas inversible, alors \( A\) n'est pas inversible non plus. Notons \( r<d\) le rang de \( A\). Étant donné que \( X=AY\), la variable aléatoire \( X\) prend presque sûrement ses valeurs dans l'image de \( A\), c'est à dire dans un sous-espace de dimension \( r<d\) de \( \eR^d\). Ce sous-espace est de mesure nulle pour la mesure de Lebesgue, mais de mesure \( 1\) pour la mesure \( P_X\). La mesure \( P_X\) ne peut donc pas avoir de densité par rapport à celle de Lebesgue.

    Supposons maintenant que \( K_X\) soit inversible. La matrice \( A\) l'est aussi. Nous anticipons l'utilisation du théorème de changement de variable \ref{THOooUMIWooZUtUSg}. Ici le changement de variable sera la transformation linéaire \( A\) dont le jacobien vaut
    \begin{equation}
        | \det(A^{-1}) |=\frac{1}{ \det A }=\frac{1}{ \sqrt{| \det K_X |} }.
    \end{equation}
    Soit \( \gamma\) la densité de \( Y\). Nous posons
    \begin{equation}
        f_X(x)=\frac{1}{\sqrt{| \det K_X |}} \gamma(A^{-1} X)
    \end{equation}
    où \( \gamma\) est le produit des densités de \( d\) gaussiennes usuelles \( \dN(0,1)\). Nous allons d'abord montrer que cette formule est bien la fonction \eqref{EqzulwmY} et ensuite que \( X\) admet \( f_X\) comme densité. Nous avons
    \begin{equation}
        \gamma(A^{-1})=\frac{1}{ (2\pi)^{d/2} }\exp\left( -\frac{ 1 }{2}\| A^{-1}x \|^2 \right),
    \end{equation}
    et 
    \begin{subequations}
        \begin{align}
            \| A^{-1}x \|^2&=\langle A^{-1}x, A^{-1}x\rangle \\
            &=\langle (A^{-1})^tA^{-1}x, x\rangle \\
            &=\langle (AA^t)^{-1}x, x\rangle \\
            &=x\cdot K_X^{-1}x,
        \end{align}
    \end{subequations}
    ce qui nous donne bien la formule \eqref{EqzulwmY}. Nous vérifions maintenant que \( f_X\) est bien une densité pour \( X\). Soit \( B\) un borélien de \( \eR^d\). Nous avons d'abord
    \begin{equation}
        P(X\in B)=P(AY\in B)=P(Y\in A^{-1}B).
    \end{equation}
    Ici nous avons utilisé le fait que \( A\) était bijectif. Nous avons ensuite
    \begin{equation}
            P(X\in B)=\int_{A^{-1}B}\gamma(t)dy
            =\int_B\gamma\big( A^{-1}x \big)| J_{A^{-1}}(x) |dx
            =\int_Bf_X(x)dx.
    \end{equation}
    C'est ici que nous avons utilisé le théorème de changement de variable \ref{THOooUMIWooZUtUSg}.
\end{proof}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Variable aléatoire de Rademacher}
%---------------------------------------------------------------------------------------------------------------------------

Une variable aléatoire \defe{de Rademacher}{variable aléatoire!de Rademacher} est une variable aléatoire de loi
\begin{equation}   
    \epsilon\sim \delta_0-\delta_1,
\end{equation}
sur l'ensemble \( \Omega=\{ 0,1 \}\). C'est la variable aléatoire qui prend valeur \( 1\) ou \( -1\) avec probabilité \( \frac{ 1 }{2}\). 

Parmi les propriétés évidentes de cette variable aléatoire nous avons \( E(\epsilon)=0\) et \( E(\epsilon^2)=1\).

\begin{proposition}[Inégalité de Khintchine\cite{KXjFWKA}]  \label{PropCZRNRsf}
    Soient \( r_1,\ldots, r_n\) des variables aléatoires indépendantes et identiquement distribuées de Rademacher et une combinaison linéaire
    \begin{equation}
        X=\sum_{i=1}^na_ir_i
    \end{equation}
    avec \( a_i\in \eR\). Alors
    \begin{equation}    \label{EqYBZlMga}
        \| X \|_2\leq \sqrt{e}E\big( |X| \big).
    \end{equation}
\end{proposition}
\index{inégalité!de Khintchine}

\begin{proof}
   Pour rappel la définition est que
   \begin{equation}
       \| X \|_2=\sqrt{  E\big( | X |^2 \big)}.
   \end{equation} 
   Vu que c'est de la quantité \( E\big( | X | \big)\) que nous voulons parler, nous notons l'inégalité 
   \begin{equation}
       E\big( | X | \big)=\int_{\Omega}\big| X(\omega) \big|dP(\omega)\geq \big| \int_{\Omega}X(\omega)dP(\omega) \big|=\big| E(X) \big|.
   \end{equation}
   
   Nous supposons que \( \sum_{j=1}^na_j^2=1\); sinon nous multiplions les \(a_j\) parce qu'il faut pour l'avoir et ce facteur sortira des deux côtés de \eqref{EqYBZlMga}. 
   
   Nous allons passer par la variable aléatoire intermédiaire
   \begin{equation}
       Y=\prod_{j=1}^n(1+ia_jr_j)
   \end{equation}
   et pour presque tout \( \omega\in \Omega\) nous avons
   \begin{subequations}
       \begin{align}
           | Y(\omega) |&=\prod_{j=1}^n| 1+ia_jr_j(\omega) |\\
           &=\prod_{j=1}^n\sqrt{1+a^2_j\underbrace{r_j(\omega)^2}_{=1}}\\
           &=\prod_{j=1}^n\sqrt{1+a_j^2 }\\
           &\leq\prod_{j=1}^n\sqrt{  e^{a_j^2} }\\
           &=\sqrt{\prod_{j=1}^n e^{a_j^2}}\\
           &=\sqrt{ e^{\sum a_j^2}}\\
           &=\sqrt{e}.
       \end{align}
   \end{subequations}
   Donc \( \| Y \|_{\infty}\leq \sqrt{e}\) où \( \| . \|_{\infty}\) est la norme supremum sur \( \Omega\). Cela nous permet de donner une première inégalité à propos de \( E(| X |)\). D'abord
   \begin{equation}
       \big| E(XY) \big|=\big| \int_{\Omega}X(\omega)Y(\omega)dP(\omega) \big|\leq \int_{\Omega}\big| X(\omega) \big|\| Y \|_{\infty}dP(\omega)=\| Y \|_{\infty}E\big( | X | \big),
   \end{equation}
   ensuite en remplaçant \( \| Y \|_{\infty}\) par la majoration que nous venons de donner de \( | Y(\omega) |\),
   \begin{equation} \label{EqYVbzyGb}
       \sqrt{e}E\big( | X | \big)\geq \big| E(XY) \big|.
   \end{equation}
   Il nous reste à prouver que \( \big| E(XY) \big|\geq \| X \|_2\).

   Pour ce faire nous commençons par noter que pour chaque \( j\) nous avons \( E(r_j)=0\) et \( E(ia_jr_j^2)=ia_j\); en utilisant l'indépendance des \( r_j\) et le lemme \ref{LemEXYEXEYprodindep} nous avons alors
   \begin{subequations}
       \begin{align}
           E(r_jY)&=E\Big( r_j(1+ia_jr_j)\prod_{k\neq j}(1+ia_kr_k) \Big)\\
           &=E\big( r_j(1+ia_jr_j) \big)\prod_{k\neq j}E(1+ia_kr_k)\\
           &=ia_j\prod_{k\neq j}\big( 1+ia_kE(r_k) \big)\\
           &=ia_j.
       \end{align}
   \end{subequations}
   Par conséquent, en utilisant la proposition \ref{PropZBnsCgh} dans le cas non indépendant,
   \begin{equation}
       E(XY)=\sum_{j=1}^na_jE(r_jY)=\sum_ja_jia_j=i\sum_ja_j^2=i.
   \end{equation}
   Nous pouvons compléter l'équation \eqref{EqYVbzyGb} en
   \begin{equation} 
       \sqrt{e}E\big( | X | \big)\geq \big| E(XY) \big|=1,
   \end{equation}
   et nous nous empressons de montrer que \( \| X \|_2=1\). En effet \( \| X \|_2=\sqrt{E(| X |^2)}\) alors que
   \begin{subequations}
       \begin{align}
           \| X \|_2^2&=E\big( (\sum_ia_ir_i)^2 \big)\\
           &=E\Big( \sum_ka_k^2r_k^2+2\sum_{i\neq j}a_ia_jr_ir_j \Big)\\
           &=\sum_ka_k^2+2\sum_{i\neq j}a_ia_jE(r_ir_j)\\
           &=1
       \end{align}
   \end{subequations}
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Loi de Student}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}
    La loi \( \chi^2\)\index{loi!$\chi^2$} à \( d\) degrés de liberté est la loi de la variable aléatoire \( Y_1^2+\ldots+y_n^2\) si les \( (Y_i)\) sont des variable aléatoires normales indépendantes centrées et réduites.

    La loi de \defe{Student}{Student}\index{loi!Student} à \( d\) degrés de liberté est la loi de la variable aléatoire
    \begin{equation}
        \frac{ X }{ \sqrt{K/d} }
    \end{equation}
    où \( X\sim\dN(0,1)\) et \( K\sim\chi^2(d)\) sont des variables aléatoires indépendantes. Cette loi est notée \( \dT(d)\)
\end{definition}

Nous avons une illustration de la densité de la loi \( \chi^2(10)\) à la figure \ref{LabelFigChiSquared}.
\newcommand{\CaptionFigChiSquared}{La densité de $\chi^2(10)$.}
\input{Fig_ChiSquared.pstricks}

L'importance de cette loi sera dans le théorème de Cochrane \ref{ThoCochraneChiStudent}.

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Indépendance, covariance et variance de somme}
%---------------------------------------------------------------------------------------------------------------------------
\label{subsecTTHohur}

Si \( X\) et \( Y\) sont des variables aléatoires réelles, nous avons défini la covariance par \eqref{EqHUWtttN}:
\begin{equation}   
    \Cov(X,Y)=E\Big[ \big( X-E(X) \big)\big( Y-E(Y) \big) \Big]
\end{equation}
Une clef est le lemme \ref{LemEXYEXEYprodindep} qui dit que lorsque \( X\) et \( Y\) sont indépendantes, alors \( E(XY)=E(X)E(Y)\). Nous avons les liens suivants.
\begin{enumerate}
    \item
        Si \( X\) et \( Y\) sont indépendantes, alors \( \Cov(X,Y)=0\).
    \item
        La réciproque n'est pas vraie par l'exemple \ref{ExWLzkuWd}.
    \item
        Si \( Z\) est un vecteur gaussien, les composantes \( Z_i\) sont indépendantes si et seulement si la matrice de covariance est diagonale, c'est à dire que les \( Z_i\) sont deux à deux non corrélés; c'est le théorème \ref{ThoPRkxPdQ}.
    \item 
        En ce qui concerne la variance d'une somme,
        \begin{equation}
            \Var(X+Y)=\Var(X)+\Var(Y)+2\Cov(X,Y).
        \end{equation}
        Donc lorsque \( X\) et \( Y\) ne sont pas corrélées, la variance est sympa avec la somme. En particulier lorsqu'elles sont indépendantes, mais pas seulement.
\end{enumerate}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Estimation des grands écarts}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Si \( S_n\) est une somme de variables aléatoires de Bernoulli \( X_i\) indépendantes de probabilité \( p\), l'espérance de \( S_n/n\) est \( p\), et nous voudrions savoir quelle est la probabilité d'avoir un taux de succès un peu plus important :
\begin{equation}
    P\big( \frac{ S_n }{ n }\geq p+\epsilon \big).
\end{equation}
La loi des grands nombres nous permet de dire que ça ne va pas être très grand. En effet si nous posons
\begin{equation}
    Y_i=X_i-p-\epsilon
\end{equation}
et
\begin{equation}
    Z_n=\frac{1}{ n }\sum_{i=1}^nY_i=\frac{ S_n }{ n }-p-\epsilon,
\end{equation}
la loi des grands nombres (théorème \ref{ThoefQyKZ}) nous indique que
\begin{equation}
    Z_n\stackrel{p.s.}{\longrightarrow}E(Y_1)=-\epsilon.
\end{equation}
La proposition \ref{PropJFVJDuX} sur le lien entre les types de convergence nous donne immédiatement la convergence en loi. C'est à dire que pour tout \( \eta>0\),
\begin{equation}
    P\Big( | Z_n+\epsilon |\geq \eta \Big)\to 0.
\end{equation}
En prenant \( \eta=\frac{ \epsilon }{2}\),
\begin{equation}
    P(Z_n=0)\leq P\big( | Z_n+\epsilon |\geq \frac{ \epsilon }{2} \big)\to 0.
\end{equation}

Tout cela montre que
\begin{equation}
    \lim_{n\to \infty} P\big( \frac{ S_n }{ n }\geq p+\epsilon \big)=0.
\end{equation}
Autrement dit, la probabilité de tomber à une distance fixée de la moyenne tend vers zéro lorsque le nombre d'essais augmente. Rien d'étonnant.
%TODO : à mon avis tout cela est très général et mériterait d'être mis en corollaire de la loi des grands nombres.

Le théorème suivant nous indique la vitesse de convergence. Elle est exponentielle et le coefficient est donné en fonction de \( p\) et de \( \epsilon\).

\begin{theorem}[\cite{KXjFWKA}] \label{ThoYYaBXkU}
    Soient des variables aléatoires \( X_i\sim\dB(p)\) et
    \begin{equation}
        S_n=\sum_{i=1}^nX_i\sim\dB(n,p).
    \end{equation}
    Pour \( \epsilon\in\mathopen] 0 , 1-p \mathclose[\), nous définissons
    \begin{equation}
        h_+(\epsilon)=(p+\epsilon)\ln\left( \frac{ p+\epsilon }{ p } \right)+(1-p-\epsilon)\ln\left( \frac{ 1-p-\epsilon }{ 1-p } \right).
    \end{equation}
    Alors
    \begin{enumerate}
        \item\label{ItemUWyKcpMi}
            \( h_+(\epsilon)>0\).
        \item\label{ItemUWyKcpMii}
            Pour tout \( n\geq 1\), nous avons
            \begin{equation}    \label{EqXFortLp}
                P\left( \frac{ S_n }{ n }\geq p+\epsilon \right)\leq  e^{-nh_+(\epsilon)}.
            \end{equation}
        \item\label{ItemUWyKcpMiii}
            L'estimation \eqref{EqXFortLp} est optimale au sens que
            \begin{equation}
                \lim_{n\to \infty} \frac{1}{ n }\ln\left( P\big( \frac{ S_n }{ n } \geq p+\epsilon \big) \right)=-h_+(\epsilon).
            \end{equation}
    \end{enumerate}
\end{theorem}
\index{estimation!des grands écarts}
\index{convergence!rapidité}
\index{Bernoulli!somme}
\index{loi!des grands nombres!utilisation}
\index{loi!binomiale!comportement asymptotique}

\begin{proof}
    Pour tout \( t\geq 0\) nous avons :
    \begin{subequations}
        \begin{align}
        P\left( \frac{ S_n }{ n }\geq p+\epsilon \right)&=P\big( S_n\geq np+n\epsilon \big)\\
        &\leq E\Big(  e^{t(S_n-np-n\epsilon)} \Big)        \label{subeqDUYpBeF}\\
        &= e^{-nt(p+\epsilon)}E\left(  e^{tS_n} \right)\\
        &= e^{-nt(p+\epsilon)}\sum_{k=0}^{\infty} e^{tk}P(S_n=k)    \label{subeqXEHKoqk}\\
        &= e^{-nt(p+\epsilon)}\sum_{k=0}^{n} e^{tk}\binom{n}{k}p^k(1-p)^{n-k}\\
        &= e^{-nt(p+\epsilon)}\big( (1-p)+pe^t \big)^n\\
        &=\exp\Big( -n\big( t(p+\epsilon)-\ln(1-p+pe^t) \big) \Big).
        \end{align}
    \end{subequations}
    Justifications :
    \begin{itemize}
        \item
            L'inégalité \eqref{subeqDUYpBeF} est l'inégalité de Markov (corollaire \ref{CorEWhIsBB}) avec \( \phi(x)= e^{tx}\). 
        \item 
    La ligne \eqref{subeqXEHKoqk} est une utilisation du théorème de transfert \ref{PropintdPintdPXeR}.
    \end{itemize}
    Nous posons maintenant
    \begin{equation}
        h=\sup_{t>0}\big( t(p+\epsilon)-\ln(1-p+pe^t) \big).
    \end{equation}
    Pour cette valeur de \( h\) nous avons
    \begin{equation}
        P\left( \frac{ S_n }{ n }\geq p+\epsilon \right)\leq e^{-nh}.
    \end{equation}
    Nous considérons la fonction
    \begin{equation}
        \begin{aligned}
            g\colon \eR^+&\to \eR \\
            t&\mapsto t(p+\epsilon)-\ln(1-p+pe^t). 
        \end{aligned}
    \end{equation}
    Elle vérifie \( g(0)=0\) et
    \begin{subequations}
        \begin{align}
            g'(t)&=(p+\epsilon)- \frac{ pe^t }{ 1-p+pe^t }\\
            g'(0)&=(p+\epsilon)- \frac{ p }{ 1-p+p }=\epsilon>0.
        \end{align}
    \end{subequations}
    Par conséquent sur un voisinage de \( t=0\) la fonction \( g\) est strictement croissante et nous concluons que \( g\) prend (au moins) quelques valeurs strictement positives. Du coup nous avons
    \begin{equation}
        h=\| g \|_{\infty}>0.
    \end{equation}
    Nous cherchons maintenant pour quelle valeur de \( t\) est réalisé le maximum de \( g\). D'abord résoudre \( g'(t)=0\) donne
    \begin{equation}
        t_0=\ln\left( \frac{ (p+\epsilon)(1-p) }{ p(1-p-\epsilon) } \right)
    \end{equation}
    Vu que \( g'(t)\to p+\epsilon-1<0\), nous avons \( \lim_{t\to \infty} g(t)=-\infty\) et donc le \( t_0\) trouvé est bien un maximum et non un minimum.

    Il est maintenant loisible de calculer une valeur pour \( h\) : il suffit de calculer \( g(t_0)\). La calcul n'est pas très compliqué et donne
    \begin{equation}
        h=g(t_0)=(p+\epsilon)\ln\left( \frac{ p+\epsilon }{ p } \right)+(p+\epsilon-1)\ln\left( \frac{ 1-p }{ 1-p-\epsilon } \right),
    \end{equation}
    ce qui est bien \( h=h_+(\epsilon)\). Cela démontre les points \ref{ItemUWyKcpMi} et \ref{ItemUWyKcpMii}.

    Nous montrons à présent l'aspect optimal de l'estimation. Nous savons déjà que
    \begin{equation}    \label{EqUIplgUD}
        \frac{1}{ n }\ln\left( P\big( \frac{ S_n }{ n }\geq p+\epsilon \big) \right)\leq h_+(\epsilon).
    \end{equation}
    Nous posons \( k_n=\lceil n(p+\epsilon)\rceil\). Vu que \( p+\epsilon<1\) et que \( S_n\leq n\), nous avons
    \begin{equation}
        P\big( \frac{ S_n }{ n }\geq p+\epsilon \big)=P\big( S_n\geq n(p+\epsilon) \big)\geq P(S_n=k_n)=\binom{ n }{ k_n }p^{k_n}(1-p)^{n-k_n}.
    \end{equation}
    C'est maintenant que nous utilisons la formule de Stirling (lemme \ref{LemCEoBqrP}) pour chacune des factorielles intervenant dans le coefficient binomial. Nous trouvons :
    \begin{equation}
        P\left( \frac{ S_n }{ n }\geq p+\epsilon \right)\geq P(S_n=k_n)=  \clubsuit= \frac{ \left( \frac{ n }{ e } \right)^n\sqrt{2\pi n}\alpha(n)p^{k_n}(1-p)^{n-k_n} }{ \left( \frac{ k_n }{ e } \right)^{k_n}\sqrt{2\pi k_n}\alpha(k_n)\left( \frac{ n-k_n }{ e } \right)^{n-k_n}\sqrt{2\pi(n-k_n)} }.
    \end{equation}
    Nous savons que \( k_n=n(p+\epsilon)+\sigma(n)\) avec \( \sigma\) borné par \( 1\). Par conséquent \( n-k_n\to \infty\) et nous pouvons regrouper les coefficients en \( \alpha\) en
    \begin{equation}
        \beta(n)=\frac{ \alpha(n) }{ \alpha(k_n)\alpha(n-k_n) }\to 1.
    \end{equation}
    Nous remarquons aussi que les \( e\) se simplifient. Nous récrivons \( \clubsuit\) sous la forme
    \begin{subequations}
        \begin{align}
            \clubsuit&=\underbrace{\frac{1}{ \sqrt{2\pi} }\sqrt{\frac{ n }{ k_n(n-k_n) }}\beta(n) }_{=A(n)}  \frac{ n^np^{k_n}(1-p)^{n-k_n} }{ k_n^{k_n}(n-k_n)^{n-k_n} }\\
            &=A(n)n^n\left( \frac{ p }{ k_n } \right)^{k_n}\left( \frac{ 1-p }{ n-k_n } \right)^{n-k_n}\\
            &=A(n)\left( \frac{ np }{ k_n } \right)^{k_n}\left( \frac{ n(1-p) }{ n-k_n } \right)^{n-k_n}.
        \end{align}
    \end{subequations}
    Nous passons au logarithme et nous étudions \( \frac{1}{ n }\ln\big( P(S_n=k_n) \big)\). Nous avons les termes suivants à étudier :
    \begin{equation}
        \begin{aligned}[]
        \frac{1}{ n }\ln\big( P(S_n=k_n) \big)&=-\frac{1}{ 2n }\ln(2\pi)+\frac{1}{ 2n }\ln\left( \frac{ n }{ k_n(n-k_n) } \right)\\
        \\&\quad+k_n\ln\left( \frac{ np }{ k_n } \right)+(n-k_n)\ln\left( \frac{ n(1-p) }{ n-k_n } \right)+\frac{1}{ n }\ln\big( \alpha(n) \big).
        \end{aligned}
    \end{equation}
    Nous étudions terme à terme la limite de cela lorsque \( n\to \infty\).
    \begin{enumerate}
        \item
            Le terme \( \frac{1}{ 2n }\ln(2\pi)\) ne pose pas de problèmes. Il tend vers zéro.
        \item
            Si nous remplaçons \( k_n\) par \( n(p+\epsilon)+\sigma(n)\) nous voyons que ce qui est dans le logarithme est majoré par \( \frac{1}{ P(n) }\) pour un certain polynôme \( P\). Ce terme est dans le cas \( \frac{ \ln(P(n)) }{ n }\) qui tend vers zéro lorsque \( n\to \infty\).
        \item
            Pour ce terme nous remplaçons \( k_n\) par \( n(p+\epsilon)+k_n-n(p+\epsilon)\). Nous devons alors étudier la limite de
            \begin{equation}    \label{EqZTmKdSn}
                (p+\epsilon)\ln\left( \frac{ np }{ k_n } \right)+\frac{ k_n-n(p+\epsilon) }{ n }\ln\left( \frac{ np }{ k_n } \right).
            \end{equation}
            Ce qui est dans les logarithmes est encadré de la façon suivante :
            \begin{equation}
                \frac{ n(p+\epsilon) }{ np }\leq\frac{ k_n }{ np }\leq \frac{ n(p+\epsilon)+1 }{ np }.
            \end{equation}
            Donc la limite de \( k_n/np\) est \( (p+\epsilon)/p\). Les logarithmes restent bornés. Pour le second terme de \eqref{EqZTmKdSn}, le numérateur du coefficient est borné par \( 1\). Donc le second terme tend vers zéro et le tout tend vers
            \begin{equation}
                (p+\epsilon)\ln\left( \frac{ p }{ p+\epsilon } \right).
            \end{equation}
        \item
            Nous devons enfin étudier le dernier terme. La combinaison \( \frac{ n-k_n }{ n }\) s'étudie de la façon suivante :
            \begin{equation}
                \frac{ n-k_n }{ n }=\frac{ n-n(p+\epsilon)+n(p+\epsilon)-k_n }{ n }=\frac{ n(1-p-\epsilon)+n(p+\epsilon)-k_n }{ n }\to 1-p-\epsilon
            \end{equation}
            parce que \( n(p+\epsilon)-k_n\) est borné par \( 1\). Sachant cela, notre terme a pour limite
            \begin{equation}
                \frac{ n-k_n }{ n }\ln\left( \frac{ n(1-p) }{ n-k_n } \right)\to (1-p-\epsilon)\ln\left( \frac{ 1-p }{ 1-p-\epsilon } \right).
            \end{equation}
            
    \end{enumerate}
    En remettant tous les morceaux bouts à bout,
    \begin{equation}
        \frac{1}{ n }P(S_n=k_n)\to (1+\epsilon)\ln\left( \frac{ p }{ p+/e } \right)+(1-p-\epsilon)\ln\left( \frac{ 1-p }{ 1-p-\epsilon } \right)=-h_+(\epsilon).
    \end{equation}
    Étant donné que nous avions déjà prouvé que \( P\big( \frac{ S_n }{ n }\geq p+\epsilon \big)\geq P(S_n=k_n)\), nous avons
    \begin{equation}
        \liminf_{n\to \infty}\frac{1}{ n }\ln\Big( P(\frac{ S_n }{ n }\geq p+\epsilon) \Big)\geq \lim_{n\to \infty} \frac{1}{ n }P(S_n=k_n)=-h_+(\epsilon).
    \end{equation}
    En combinant avec \eqref{EqUIplgUD} nous trouvons que
    \begin{equation}
        \lim_{n\to \infty} \frac{1}{ n }\ln\Big( P\big( \frac{ S_n }{ n }\geq p+\epsilon \big) \Big)=h_+(\epsilon).
    \end{equation}
    
    Pour cette dernière déduction nous utilisons le fait que si \( (a_n)\) est une suite telle que \( a_n\leq l\) et \( \liminf_{n\to\infty}a_n=l\), alors \( (a_n)\) admet une limite qui vaut \( l\).
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Simulations de réalisations de variables aléatoires}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Le générateur de base que possède un système informatique est un générateur de nombres pseudo-aléatoires de nombres entiers entre \( 0\) et \( m-1\) généré par une suite du type
\begin{equation}
    x_{n+1}=(ax_n+b)\mod m.
\end{equation}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Générateur uniforme}
%---------------------------------------------------------------------------------------------------------------------------

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Première méthode}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Une première façon de générer une variable aléatoire de loi uniforme sur \( \mathopen] 0 , 1 \mathclose[\) est de diviser par \( m-1\) la suite de \( x_n\). En effet nous avons la proposition suivante.

\begin{proposition}
    Si \( (Y_n)\) est une suite de variables aléatoires indépendantes et identiquement distribuées de loi uniforme sur \( \{ 0,\ldots,n-1 \}\). Alors
    \begin{equation}
        \frac{ Y_n }{ n }\stackrel{\hL}{\longrightarrow}\dU\mathopen[ 0 , 1 \mathclose].
    \end{equation}
\end{proposition}

\begin{proof}
    Nous prouvons la convergence en loi en passant par la fonction de répartition et la proposition \ref{PropoFnrepCvL}. La fonction de répartition de la densité \( \dU[0,1]\) est 
    \begin{equation}
        F_X(x)=x\mtu|_{\mathopen[ 0 , 1 \mathclose]}.
    \end{equation}
    La fonction de répartition de la variable aléatoire (discrète) \( X_n=\frac{ Y_n }{ n }\) est
    \begin{equation}
        P(\frac{ Y_n }{ n }\leq x)=P(Y_n\leq nx)=\frac{ \lfloor nx \rfloor }{ n }
    \end{equation}
    où \( \lfloor a\rfloor\) est le plus grand entier inférieur à \( a\). Nous avons évidemment 
    \begin{equation}
        \lim_{n\to \infty} \frac{ \lfloor nx\rfloor }{ n }=x,
    \end{equation}
    ce qui montre la convergence des fonctions de répartitions et donc la convergence en loi qui nous intéresse.
\end{proof}

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Seconde méthode}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Soit \( (Y_n)\) une suite de variables aléatoires indépendantes et identiquement distribuées selon la loi \( Y_n\sim\dU\{ 0,\ldots,m-1 \}\). Alors la série de variables aléatoires
\begin{equation}
    Z=\sum_{k=0}^{\infty}\frac{ Y_k }{ m^{k+1} }
\end{equation}
est une série qui converge presque sûrement parce que \( Y_k\) est borné par \( m\). Avec probabilité zéro nous avons \( Z=\sum_k1/m^k\) qui converge. Nous avons
\begin{equation}
    Z\sim\dU\mathopen[ 0 , 1 \mathclose].
\end{equation}
L'argument pour montrer cette loi est qu'en base \( m\), la variable aléatoire \( Z\) a un développement décimal \( Z=0.Y_1Y_2Y_3Y_4\cdots\).

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Simulation par inversion}
%---------------------------------------------------------------------------------------------------------------------------

Nous cherchons maintenant à simuler une loi \( X\) de fonction de répartition \( F\).

\begin{definition}
    Soit \( f\colon \eR\to \mathopen[ 0 , 1 \mathclose]\) une fonction croissante, continue à droite et telle que
    \begin{subequations}
        \begin{align}
            \lim_{x\to -\infty} f(x)=0\\
            \lim_{x\to \infty} f(x)=1.
        \end{align}
    \end{subequations}
    L'\defe{inverse généralisé}{inverse généralisé} de \( f\), notée \( f^{-1}\) est la fonction définie par
    \begin{equation}
        f^{-1}(t)=\inf\{ x\tq f(x)\geq t \}.
    \end{equation}
\end{definition}

\begin{remark}
    L'inverse généralisé d'une fonction bijective est la vraie fonction réciproque usuelle.
\end{remark}

\begin{proposition}     \label{PropInvgenecntddr}
    Soit \( f\) une fonction admettant un inverse généralisé \( f^{-1}\). Alors nous avons \( f^{-1}(t)\leq a\) si et seulement si \( t\leq f(a)\).
\end{proposition}
La continuité à droite joue pour démontrer cette proposition.


\begin{proposition}
    Si \( F\) est la fonction de répartition de la variable aléatoire \( X\) et si \( V\) est une variable aléatoire de loi uniforme \( \dU\mathopen[ 0 , 1 \mathclose]\), alors \( F^{-1}(U)\) a la même loi que \( X\).
\end{proposition}

\begin{proof}
    Nous montrons que les fonction de répartition de \( X\) et de \( F^{-1}(U)\) sont identiques. En utilisant la proposition \ref{PropInvgenecntddr}, nous avons
    \begin{subequations}
        \begin{align}
            P\big( F^{-1}(U)\leq y \big)&=P\big( U\leq F(y) \big)\\
            &=F(y)\\
            &=P(X\leq y).
        \end{align}
    \end{subequations}
    Donc \( F^{-1}(U)\) est la fonction de répartition de \( X\).
\end{proof}

La difficulté de la méthode par inversion est qu'il faut être capable de calculer l'inverse de la fonction de répartition de la loi à simuler.

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Loi exponentielle}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

La loi exponentielle est une loi qui peut être simulée par inversion. La fonction de répartition vaut
\begin{equation}
    F(x)=1- e^{\lambda x},
\end{equation}
et l'inverse vaut
\begin{equation}
    F^{-1}(x)=-\frac{1}{ \lambda }\ln(1-y).
\end{equation}
Par conséquent, une bonne formule pour simuler une loi exponentielle est
\begin{equation}
    -\frac{1}{ \lambda }\ln(1-U).
\end{equation}
Notez que \( U\) étant uniforme, nous pouvons tout autant prendre \( -\ln(U)/\lambda\).

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Algorithme de Box-Muller}
%---------------------------------------------------------------------------------------------------------------------------

Il s'agit de simuler une loi gaussienne. La proposition est la suivante.

\begin{proposition}
    Si \( U\) et \( V\) sont des variables aléatoires indépendantes de même loi uniforme sur \( \mathopen[ 0 , 1 \mathclose]\), alors le couple
    \begin{equation}
        (X,Y)=\big( \sqrt{-2\ln(U)}\cos(2\pi V),\sqrt{-2\ln(U)}\sin(2\pi V) \big)
    \end{equation}
    vérifie
    \begin{enumerate}
        \item
            \( X\) est indépendante de \( Y\)
        \item
            \( X\) et \( Y\) sont de loi \( \dN(0,1)\).
    \end{enumerate}
\end{proposition}

\begin{proof}
    Nous allons montrer la proposition en utilisant les fonctions tests. Soit donc \( \varphi\colon \eR^2\to \eR\) une fonction bornée et mesurable. Soient \( Z\) et \( W\), deux variables aléatoires indépendantes de loi \( \dN(0,1)\). Nous allons montrer que
    \begin{equation}
        F\big( \varphi(X,Y) \big)=E\Big[ \varphi\big( \sqrt{-2\ln(U)}\cos(2\pi V),\sqrt{-2\ln(U)}\sin(2\pi V) \big) \Big].
    \end{equation}
    Par indépendance de \( U\) et \( V\), la densité du couple est le produit des densités, donc en passant aux coordonnées polaires,
    \begin{subequations}
        \begin{align}
            \diamondsuit&=E\big[ \varphi(Z,W) \big]\\
            &=\frac{1}{ 2\pi }\int_{-\infty}^{\infty}\int_{\infty}^{\infty}\varphi(x,y) e^{-x^2/2} e^{-y^2/2}dxdy\\
            &=\frac{1}{ 2\pi }\int_0^{2\pi}d\theta\int_0^{\infty}\varphi(r\cos\theta,r\sin\theta) e^{-r^2/2}rdr.
        \end{align}
    \end{subequations}
    Nous posons \( u= e^{-r^2/2}\) et \( v=\frac{ \theta }{ 2\pi }\). En particulier \( r=\sqrt{-2\ln(u)}\) et
    \begin{subequations}
        \begin{align}
            \diamondsuit&=\int_0^1\int_0^1\varphi\big( \sqrt{-2\ln(u)}\cos(2\pi v),\sqrt{-2\ln(u)}\sin(2\pi v) \big)dudv\\
            &=E\Big( \varphi\big( \sqrt{-2\ln(U)}\cos(2\pi V),\sqrt{-2\ln(U)}\sin(2\pi V) \big) \Big)
        \end{align}
    \end{subequations}
    parce que mesure \( dudv\) est la densité de la loi uniforme.
\end{proof}

En pratique, la formule 
\begin{equation}
    (x,y)\mapsto\big( \sqrt{-2\ln x}\cos(2\pi y),\sqrt{-2\ln x}\sin(2\pi y) \big)
\end{equation}
est une façon d'obtenir deux gaussiennes à partir de deux variables uniformes.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Méthode du rejet}
%---------------------------------------------------------------------------------------------------------------------------

La méthode du rejet permet de simuler des lois à densité. Soit \( f\) la densité de la loi à simuler. Nous faisons les hypothèses suivantes.
\begin{enumerate}
    \item
        Il existe une densité \( g\) d'une variable aléatoire facile à simuler.
    \item
        Il existe un \( k\geq 0\) tel que \( f(x)\leq kg(x)\).
\end{enumerate}

\begin{remark}
    Le \( k\) de la seconde hypothèse est nécessairement plus grand que \( 1\). En effet,
    \begin{equation}
        1=\int f\leq k\int g=k
    \end{equation}
    parce que \( f\) et \( g\) sont des densités et ont donc une intégrale égale à \( 1\).
\end{remark}

\begin{proposition}
    Soient \( (X_n)\) et \( (U_n)\) des suites de variables aléatoires indépendantes au sens où non seulement les \( X_i\) et \( U_k\) sont indépendants entre eux, mais de plus \( X_i\) est indépendant de \( U_j\) pour tout \( i\) et \( j\). Nous supposons que les \( X_i\) sont indépendantes et identiquement distribuées, de densité \( g\) et que les \( U_i\) sont indépendantes et identiquement distribuées de loi uniforme.

    Nous introduisons la variable aléatoire à valeurs dans \( \eN\)
    \begin{equation}
        p(\omega)=\inf\{ n\geq 0\tq \alpha\big( X_n(\omega) \big)\geq U_n(\omega) \}
    \end{equation}
    où \( \alpha\) est la fonction définie par
    \begin{equation}
        \alpha(x)=\begin{cases}
            \frac{ f(x) }{ kg(x) }    &   \text{si \( g(x)\neq 0\)}\\
            0    &    \text{si \( g(x)=0\)}.
        \end{cases}
    \end{equation}
    Alors la variable aléatoire \( Y\) définie par 
    \begin{equation}
        Y(\omega)=X_{p(\omega)}(\omega)
    \end{equation}
    admet \( f\) pour densité.
\end{proposition}

\begin{proof}
    D'abord étant donné que \( f(x)\leq kg(x)\) nous avons \( \alpha(x)\in\mathopen[ 0 , 1 \mathclose]\). Nous pouvons a priori avoir \( p(\omega)=\infty\), ce qui rendrait caduque la définition de \( Y(\omega)\). Montrons donc pour commencer que \( P(p=\infty)=0\). En utilisant l'indépendance nous avons
    \begin{subequations}        \label{EqSubEqPnNinftyalphaUu}
        \begin{align}
            P\big( \alpha(X_n)<U_n,\forall n\big)&=\lim_{N\to \infty} \prod_{i=1}^NP\big( \alpha(X_i)< U_i \big)\\
            &=\lim_{N\to \infty} P\big( \alpha(X_1)<U_1 \big)^N.
        \end{align}
    \end{subequations}
    Pour conclure nous devons prouver que \( P\big( \alpha(X_1)<U_1 \big)< 1\). Pour cela nous calculons
    \begin{subequations}
        \begin{align}
            P\big( \alpha(X_1)<U_1 \big)&=\int_{\eR}dx\int_0^1du\mtu_{\alpha(x)<u}g(x)\\
            &=\int_{\eR}g(x)\big( 1-\alpha(x) \big)dx\\
            &=\int_{\eR}\left( g(x)-\frac{ f(x) }{ k } \right)\\
            &=1-\frac{1}{ k }\\
            &<1.
        \end{align}
    \end{subequations}
    L'équation \eqref{EqSubEqPnNinftyalphaUu} nous permet donc de conclure que \( P\big( \alpha(X_n)<U_n,\forall n\big)=0\). Par conséquent la variable aléatoire \( Y(\omega)=X_{p(\omega)}(\omega)\) a un sens.

    Nous devons maintenant prouver que \( Y\) a bien \( f\) pour densité. Pour cela nous considérons un ensemble mesurable \( A\in\Borelien(\eR)\) et nous montrons que \( P(Y\in A)=\int_Af(x)dx\). Nous avons
    \begin{equation}    \label{EqdscPAYXjApj}
        P(Y\in A)=P(X_p\in A)=\sum_{i=1}^{\infty}P(X_j\in A,p=j).
    \end{equation}
    Par ailleurs nous avons
    \begin{equation}        \label{EqalPXjAvpjalphaXj}
        \begin{aligned}[]
            P(X_j\in A,p=j)&=P\big( X_j\in A,\alpha(X_j)\geq U_j,\alpha(X_m)<U_m\,\forall m\leq j-1 \big)\\
            &=P\big( X_j\in A,\alpha(X_j)\geq U_j \big)P\big( \alpha(X_1)<U_1 \big)^{j-1}\\
            &=P\big( X_j\in A,\alpha(X_j)\geq U_j \big)\left( 1-\frac{1}{ k } \right)^{j-1}.
        \end{aligned}
    \end{equation}
    Étant donné que \( g(x)dx\) est la densité de \( X_j\) et que \( du\) est la densité de \( U\), nous avons
    \begin{subequations}
        \begin{align}
        P\big( X_j\in A,\alpha(X_j)\geq U_j \big)&=\int_{\eR}\int_0^1\mtu_{x\in A}\mtu_{\alpha(x)\geq u}g(x)dudx\\
        &=\int_{\eR}g(x)\mtu_{x\in A}\underbrace{\int_0^1\mtu_{\alpha(x)\geq u}du}_{\alpha(x)}\,dx.\\
        &=\int_{\eR}\mtu_{x\in A}\frac{ f(x) }{ k }dx\\
        &=\frac{1}{ k }P(X\in A).
        \end{align}
    \end{subequations}
    En remplaçant dans l'équation \eqref{EqalPXjAvpjalphaXj} nous trouvons
    \begin{equation}
        P(X_j\in A,p=j)=\frac{1}{ k }P(X\in A)\left( 1-\frac{1}{ k } \right)^{j-1}.
    \end{equation}
    Et enfin, l'équation \eqref{EqdscPAYXjApj} donne
    \begin{equation}
        P(Y\in A)=\frac{1}{ k }P(X\in A)\sum_{i=1}^{\infty}\left( 1-\frac{1}{ k } \right)^{j-1}=P(X\in A).
    \end{equation}
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Simuler une loi géométrique à l'ordinateur}
%---------------------------------------------------------------------------------------------------------------------------

Si \( (X_n)\) est une suite de variables aléatoires indépendantes et identiquement distribuées avec \( X_n\sim \dB(p)\), alors
\begin{equation}
    Z=\min\{ k\geq 1\tq X_k=1 \}\sim\dG(p).
\end{equation}
Nous avons alors \( P(Z=k)=(1-p)^kp\). 

Si nous avons un générateur de lois de Bernoulli de paramètre \( p\), alors nous on simulons jusqu'à obtenir \( 1\) et nous comptons combien de simulations ont été nécessaires.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Simuler une loi exponentielle à l'ordinateur}
%---------------------------------------------------------------------------------------------------------------------------

Nous pouvons utiliser la méthode de l'inversion. Étant donné que la fonction de répartition de la loi exponentielle est \( F(x)=1- e^{-\lambda x}\), nous avons \( F^{-1}(y)=\frac{1}{ \lambda }\ln(1-y)\). Par conséquent à partir d'un générateur uniforme \( U\), nous pouvons calculer
\begin{equation}
    F^{-1}(U)=\frac{1}{ \lambda }\ln(U)
\end{equation}
qui suivra une loi exponentielle d'espérance \( 1/\lambda\).

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Simuler une loi de Poisson à l'ordinateur}
%---------------------------------------------------------------------------------------------------------------------------

Nous savons du point \ref{subsecPoissonetexpo} que si les \( T_i\) sont des variables aléatoires indépendantes et identiquement distribuées de loi \( \dE(\lambda)\), alors nous avons
\begin{equation}
    \max\{ n\geq 1\tq\sum_iT_i\leq 1 \}\sim\dP(\lambda).
\end{equation}
La façon usuelle pour créer une loi exponentielle est d'avoir un générateur de loi uniforme \( U_i\) et d'écrire que
\begin{equation}
    -\frac{1}{ \lambda }\ln(U_i)\sim \dE(\lambda).
\end{equation}
Nous devons donc faire la somme de telles variables aléatoires et voir à partir de quel moment la somme dépasse \( 1\). Le calcul est le suivant :
\begin{equation}
    -\sum_{i=1}^{n}\frac{1}{ \lambda }\ln(U_i)\leq 1
\end{equation}
implique
\begin{equation}
    \prod_{i=1}^nU_i\leq  e^{-\lambda}.
\end{equation}
En pratique, la variable aléatoire qui se comporte comme une loi de Poisson de paramètre \( \lambda\) est
\begin{equation}
    N=\max\{ n\geq 1\tq \prod_{i=1}^nU_i\geq e^{-\lambda} \}.
\end{equation}
Nous générons donc des nombres aléatoires entre \( 1\) et \( 1\) et nous effectuons le produit jusqu'à ce qu'il passe en dessous de \(  e^{-\lambda}\). À ce moment, nous retournons le nombre de nombres qu'il a fallu générer.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Sage}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Nous allons montrer maintenant quelques trucs importants dans l'utilisation de Sage pour réaliser des petits graphiques. 

\begin{remark}
    Dans ce qui suit, nous allons parler de «Sage», mais en réalité nous allons surtout parler du module \info{scipy} qui fait partie des modules hyper-usuels de Python. Les remerciements vont donc au moins autant du côté de l'équipe de \info{scipy} que vers celle de Sage.
\end{remark}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Loi exponentielle}
%---------------------------------------------------------------------------------------------------------------------------

Il faut savoir que la définition d'une loi continue retourne automatiquement la loi centrée réduite. Pour avoir une loi exponentielle de moyenne donnée, il faut donc préciser de façon plus maligne que ce que l'on croit.

\lstinputlisting{code_sage1.py}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Inverser des lois}
%---------------------------------------------------------------------------------------------------------------------------

Pour trouver des intervalles de confiance, il faut souvent calculer des inverses de loi. Bien entendu Sage le fait. Ce que sage connaît, c'est l'inverse de la fonction de survie. Autrement dit si \info{X} est une variable aléatoire, \info{X.sf} est la fonction \( x\mapsto 1-P(X<x)\) et \info{X.isf} en est l'inverse. Pour résoudre \( P(X<\xi)=\alpha\), il faut résoudre \( F(\xi)=\alpha\), c'est à dire 
\begin{equation}
    1-F(\xi)=1-\alpha,
\end{equation}
ce qui se fait de la façon suivante : le programme suivant donne pour une loi normale centrée réduite la valeur de \( \xi\) pour laquelle \( P(N<\xi)=0.05\) :
\lstinputlisting{code_sage2.py}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Monte-Carlo}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Nous voudrions calculer une valeur approchée de l'intégrale
\begin{equation}
    I=\int_a^bf(x)dx.
\end{equation}
Les méthodes classiques consistent à discrétiser l'intervalle \( \mathopen[ a , b \mathclose]\) et en calculant une somme de la forme \( \sum_iw_if(x_i)\).

L'idée de Monté Carlo est de remplacer le découpage déterministe \( x_i\) par des variables aléatoires \( X_i\) en trois étapes. 

\begin{enumerate}
    \item
        Pour cela nous commençons par écrire l'intégrale comme une espérance : \( I=E(X)\) où \( X\) est une variable aléatoire définie sur un espace probabilisé \( (\Omega,\tribF,P)\) à déterminer. Une contrainte est évidemment d'avoir \( X\in L^1(\Omega,\tribF,P)\).

    \item
        Nous générons une suite indépendantes et identiquement distribuée de variables aléatoires \( (X_n)\) de même loi que \( X\) et la loi (forte) des grands nombres implique que
        \begin{equation}
            \bar X_n=\frac{1}{ n }\sum_{k=1}^nX_k\stackrel{p.s.}{\longrightarrow} E(X)=I.
        \end{equation}
        
    \item
        Le dernier point sera de donner un intervalle de confiance.
\end{enumerate}
 
\begin{example}     \label{ExempleIintfdxEXu}
    Nous voudrions déterminer de façon approchée l'intégrale \( I=\int_0^1 f(x)dx\). Si \( U\sim\dU\mathopen[ 0 , 1 \mathclose]\), alors
    \begin{equation}
        I=E\big( f(U) \big)
    \end{equation}
    et il suffit de faire
    \begin{equation}
        I\simeq\frac{1}{ n }\sum_{k=1}^nf(U_i).
    \end{equation}
    où mes \( U_i\) sont indépendantes et identiquement distribuées de loi \( \dU\mathopen[ 0 , 1 \mathclose]\).
\end{example}

\begin{example}
    Supposons que la fonction à intégrer se présente sous la forme \( f(x)=h(x)g(x)\) avec \( g\geq 0\) et telle que l'intégrale \( \int_{\eR}g\) existe. Notons
    \begin{equation}
        c=\int_{\eR}g
    \end{equation}
    et
    \begin{equation}
        I=\int_{\eR}h(x)c\frac{ g(x) }{ c }dx.
    \end{equation}
    Nous avons alors \( I=E\big( ch(Y) \big)\) où \( Y\) admet la densité \( g(x)c\).
\end{example}

Passons au cas de plusieurs variables et considérons l'intégrale
\begin{equation}
    I=\int_{\mathopen[ 0 , 1 \mathclose]^1}f(x_1,\ldots,x_d)dx_1\ldots dx_d.
\end{equation}
Nous écrivons
\begin{equation}
    I=E\big( f(U_1,\ldots,U_d) \big)
\end{equation}
où les \( U_i\) sont de loi uniformes sur \( \mathopen[ 0 , 1 \mathclose]\). En pratique, nous générons une suite de variables aléatoires de \( (Z_k)\) de lois uniformes que nous regroupons par paquets :
\begin{equation}
    V_k=(Z_{dk},Z_{dk+1},\ldots,Z_{d(k+1)-1}).
\end{equation}
Ces variables aléatoires \( V_k\) sont indépendantes et identiquement distribuées de loi \( \dU\mathopen[ 0 , 1 \mathclose]^{d}\). Ensuite la loi des grands nombres nous indique que
\begin{equation}
    I\sim\frac{1}{ n }\sum_{k=1}^nf(V_k).
\end{equation}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Intervalle de confiance}
%---------------------------------------------------------------------------------------------------------------------------

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Principe}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Nous supposons que nous travaillons sur une approximation de Monte-Carlo telle que la variable aléatoire choisie soit dans \( L^2\). La loi des grands nombres nous dit que \( \bar X_n\sim I\) tandis que le théorème central limite nous enseigne que
\begin{equation}
    \frac{ \bar X_n-E(X) }{ \sigma/\sqrt{n} }\stackrel{\hL}{\longrightarrow}\dN\left( 0,1 \right).
\end{equation}
Par conséquent
\begin{equation}
    P\left( \frac{ \bar X_n-E(X) }{ \sigma/\sqrt{n} }\in\mathopen[ -u , u \mathclose] \right)\simeq P(-u\leq Z\leq u)
\end{equation}
où \( Z\sim\dN(0,1)\). En remplaçant \( E(X)\) par \( I\) et en effectuant les manipulations usuelles, nous trouvons que \( P(I\in J_{\alpha})=1-\alpha\) si
\begin{equation}
    J_{\alpha}=\big[ \bar X_n-u_{\alpha}\frac{ \sigma }{ \sqrt{n} },\bar X_n+u_{\alpha}\frac{ \sigma }{ \sqrt{n} } \big]
\end{equation}
où \( \sigma^2\) est la variance de \( X\). Si \( \sigma\) n'est pas connue, alors nous le remplaçons par un estimateur
\begin{equation}
    S'_n=\frac{1}{ n-1 }\sum_{k=1}^n(X_k-\bar X_n)^2
\end{equation}
et nous considérons l'intervalle
\begin{equation}
    J'_{\alpha}=\big[ \bar X_n-u_{\alpha}\frac{ S'_n }{ \sqrt{n} }\bar X_n+u_{\alpha}\frac{ S'_n }{ \sqrt{n} } \big].
\end{equation}
Il y a deux façons de faire diminuer la longueur de l'intervalle de confiance : augmenter \( n\) ou diminuer \( \sigma\). Pour le second point, le choix de \( X\) dans \( I=E(X)\) est essentiel.

\begin{example}
    Soit à calculer 
    \begin{equation}
        I=\frac{1}{ \sqrt{2\pi} }\int_{\eR} e^{\beta z} e^{-z^2/2}dz
    \end{equation}
    avec \( \beta>0\). Nous introduisons la variable aléatoire \( X= e^{\beta Z}\) avec \( Z\sim\dN(0,1)\). Nous avons alors 
    \begin{equation}
        I=E(X).
    \end{equation}
    Par ailleurs l'intégrale demandée vaut \(  e^{\beta^2/2}\). En appliquant les formules vues plus haut nous trouvons
    \begin{equation}
        J_{\alpha}=\big[ \bar X_n-u_{\alpha}\frac{ \sigma }{ \sqrt{n} },\bar X_n+u_{\alpha}\frac{ \sigma }{ \sqrt{n} } \big]
    \end{equation}
    où
    \begin{equation}
        \sigma^2=\Var(X)=E( e^{2\beta Z})-E( e^{\beta z})^2= e^{2\beta^2}- e^{\beta^2}.
    \end{equation}
    Nous avons utilisé la formule \eqref{EqEspexpbetaZnorm}. Si nous choisissons \( \beta=2\), nous trouvons \( \sigma^2\simeq 2926\). Donc si nous voulons une longueur de \( J_{\alpha}\) plus petite que \( 10^{-2}\) tout en demandant \( \alpha=0.05\) (ce qui implique \( u_{\alpha}=1.96\)), nous devons avoir
    \begin{equation}
        1.96\frac{ 2973 }{ \sqrt{n} }<10^{-2},
    \end{equation}
    c'est à dire environ \( n=10^{11}\), ce qui soit dit en passant est très largement au delà des capacités de la commande \href{http://www.iecn.u-nancy.fr/~pincon/scilab/Doc/node85.html}{rand} de scilab.
\end{example}

Nous allons maintenant voir quelques méthodes pour réduire la variance.

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Échantillonnage préférentiel}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Nous devons calculer \( I=\int_{\eR}f(x)dx\). Pour cela nous introduisons artificiellement une densité \( g\) et nous écrivons
\begin{equation}
    I=\int_{\eR}\frac{ f(x) }{ g(x) }g(x)dx=E\left( \frac{ f(Y) }{ g(Y) } \right)
\end{equation}
où \( Y\) est de densité \( g\). Il faut essayer de trouver \( g\) de telle sorte à ce que 
\begin{equation}
    \Var\left( \frac{ f(Y) }{ g(Y) } \right)
\end{equation}
soit la plus petite possible.

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Méthode de la variable de contrôle}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Soit \( I=E(X)\). Nous introduisons une variable aléatoire \( Z\) et nous écrivons
\begin{equation}
    I=E(X-Z)+E(Z).
\end{equation}
Il faut alors choisir \( Z\) de telle sorte que \( E(Z)\) soit calculable et que \( X-Z\) ait une variance plus faible. En particulier, \( Z\) ne peut pas être indépendante de \( X\).

%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
\subsubsection{Variables antithétiques}
%///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Soit \( I=\int_0^1f(x)dx\). La première idée (exemple \ref{ExempleIintfdxEXu}) est d'écrire 
\begin{equation}
    I=E\big( f(U) \big)
\end{equation}
où \( U\sim\dU\mathopen[ 0 , 1 \mathclose]\), mais nous n'avons pas de garanties sur la variance de \( f(U)\). Nous pouvons écrire
\begin{equation}
    I=E\big( f(U) \big)=E\Big[ \frac{ 1 }{2}\big( f(U)-f(1-U) \big) \Big].
\end{equation}
Ici \( 1-U\) est encore une variable aléatoire uniforme sur \( \mathopen[ 0 , 1 \mathclose]\), mais il se fait que la variable aléatoire
\begin{equation}
    Z=\frac{ 1 }{2}\big( f(U)+f(1-U) \big)
\end{equation}
a une variance inférieure à \( \Var\big( f(U) \big)\). En effet, \( f(U)\) et \( f(1-U)\) ne sont pas indépendantes, par conséquent le résultat du lemme \ref{LemVarXpYsmindep} n'est pas valide, par contre la proposition \ref{PropoVarXpYCov} reste vraie et nous avons
\begin{equation}
    \Var(Z)=\frac{1}{ 4 }\Var\big( f(U) \big)+\frac{1}{ 4 }\Var\big( f(1-U) \big)+\frac{ 1 }{2}\Cov\big( f(U),f(1-U) \big).
\end{equation}
Nous avons \( \Var\big( f(1-U) \big)=\Var\big( f(U) \big)\). En ce qui concerne le terme avec la covariance, nous lui appliquons l'équation \eqref{EqEXYleqXdYdNormHolder} :
\begin{subequations}
    \begin{align}
        \Cov\big( f(U),f(1-U) \big)&=E\Big( (f(U)-I)(f(1-U)-I) \Big)\\
        &\leq E\big( (f(U)-I)^2 \big)^{1/2}E\big( (f(1-U)-I)^2 \big)^{1/2}\\
        &=\Var\big( f(U) \big)
    \end{align}
\end{subequations}
où nous avons utilisé le fait que \( E\big( f(U) \big)=E\big( f(1-U) \big)=I\). Au final nous avons bien obtenu
\begin{equation}
    \Var(Z)\leq \Var\big( f(U) \big).
\end{equation}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Résultats qui se démontrent avec des variables aléatoires}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Nombres normaux}
%---------------------------------------------------------------------------------------------------------------------------

Tout nombre \( x\in \mathopen[ 0 , 1 \mathclose[\) admet un unique\footnote{Nous excluons \( 1\) parce que son développement en puissances négatives de \( b\) est zéro.} développement en base \( b\geq 2\) :
\begin{equation}
    x=\sum_{n=1}^{\infty}\frac{ \epsilon_n(x) }{ b^n }
\end{equation}
avec \( \epsilon_n(x)\in\mA=\{ 0,\ldots, b-1 \}\).

Soit \( k\geq 1\) et \( r\in \mA^k\); nous posons
\begin{equation}
    N_x(r,n)=\Card\big\{   i\in\{ 1,\ldots, n-k+1 \}\tq \epsilon_1(x)=r_1,\ldots, \epsilon_{i+k-1}=r_k \big\}.
\end{equation}
C'est le nombre d'occurrences du motif \( r\) (de longueur \( k\)) dans les \( n\) premières décimales de \( x\).

\begin{definition}
    Un nombre \( x\in\mathopen[ 0 , 1 [\) est \defe{normal}{normal!nombre}\index{nombre!normal} en base \( b\) si pour tout \( r\in\{ 0,\ldots, b-1 \}^k\) nous avons
        \begin{equation}
            \frac{ N_x(b,n) }{ n }\to \frac{1}{ b^k }.
        \end{equation}
    Un nombre est normal si il est normal en toute base.
\end{definition}

\begin{proposition}[\cite{IMQidDv,KXjFWKA}]     \label{PropEEOXLae}
    Au sens de la mesure de Lebesgue, presque tous les nombres de \( \mathopen[ 0 , 1 [\) sont normaux.    
\end{proposition}
\index{loi!des grands nombres!utilisation}
\index{indépendance!événements!utilisation}

\begin{proof}
    Pour \( x\in\mathopen[ 0 , 1 [\), nous notons \( \epsilon_n(x)\) son développement en base \( b\). Cela nous donne des variables aléatoire \( \epsilon_i\colon \mathopen[ 0 , 1 [\to \mA\) dont la loi de probabilité est donnée par
    \begin{equation}
        P(\epsilon_1=d)=P\big( \mathopen[ \frac{ d }{ b } , \frac{ d+1 }{ b } [ \big)=\frac{1}{ b }
    \end{equation}
    parce que l'intervalle \( \mathopen[ \frac{ d }{ b } , \frac{ d+1 }{ d } [\) est l'ensemble des nombres de \( \mathopen[ 0 , 1 [\) dont la première décimale est \( d\). Pour la loi des \( \epsilon_i\), il faut un peu plus découper, mais ça donne le même résultat : \( P(\epsilon_i=d)=1/b\). Ces variables aléatoire sont indépendantes et identiquement distribuées. Nous considérons aussi la variable aléatoire
    \begin{equation}
        \begin{aligned}
            N(r,n)\colon \mathopen[ 0 , 1 [&\to \eN \\
            x&\mapsto N_x(r,n) 
        \end{aligned}
    \end{equation}
    Pour un \( r\in\mA\) fixé, nous définissons encore la variable aléatoire
    \begin{equation}
        \begin{aligned}
            X_j\colon \mA&\to \{ 0,1 \} \\
            x&\mapsto \begin{cases}
                1    &   \text{si \( \epsilon_j(x)=b\)}\\
                0    &    \text{sinon.}
            \end{cases}.
        \end{aligned}
    \end{equation}
    Les variables aléatoire \( X_j\) sont des variables aléatoire de Bernoulli indépendantes et identiquement distribuées de paramètre \( E(X_j)=P(X_j=1)=P(\epsilon_1=b)=\frac{1}{ b }\). Nous pouvons utiliser dessus la loi forte des grands nombres (théorème \ref{ThoefQyKZ}). Pour dire que
    \begin{equation}    \label{EqNALwzsh}
        \frac{1}{n }\sum_{i=1}^nX_i\stackrel{p.s.}{\longrightarrow}E(X_1)=\frac{1}{ b }.
    \end{equation}
    Mais en réalité nous avons aussi \( \sum_{j=1}^nX_j=N(r,n)\) parce que en appliquant à \( x\in\mathopen[ 0 , 1 [\) :
    \begin{equation}
        \sum_{j=1}^n\begin{cases}
            1    &   \text{si \( \epsilon_j(x)=r\)}\\
            0    &    \text{sinon}
        \end{cases}
        =
        \Card\big\{  i\in\{ 1,\ldots, n \}\tq \epsilon_i(x)=r \big\}=N_x(r,n),
    \end{equation}
    de sorte que l'équation \eqref{EqNALwzsh} nous dit exactement que pour tout \( r\in \mA\),
    \begin{equation}
        \lim_{n\to \infty} \frac{ N_x(r,n) }{ n }=\frac{1}{ b }
    \end{equation}
    pour presque tout \( x\in\mathopen[ 0 , 1 [\).

    Il reste à prouver la même chose pour tout \( r\in\mA^k\). Voyons avec \( k=2\) et \( r=(u,v)\in\mA^2\). Nous posons
    \begin{equation}
        Y_j=\mtu_{\{ \epsilon_j=u,\epsilon_{j+1}=v \}},
    \end{equation}
    et \( N(r,n)=\sum_{j=1}^{n-1}Y_j\). Les \( Y_i\) sont encore des binomiales de paramètre \( \frac{1}{ b^2 }\), mais elles ne sont pas indépendantes. En effet pour avoir \( Y_1(x)=Y_2(x)=1\), il faut que les trois premières décimales de \( x\) soit en même temps de la forme \( uv.\) et \( .uv\), donc
    \begin{equation}
        P(Y_1,Y_2=1)=b^3\delta_{u,v}
    \end{equation}
    alors que \( P(Y_1=1)P(Y_2=2)=b^4\). Nous pouvons contourner ce problème en remarquant que les \( \epsilon_i\), eux, sont indépendants. Donc le lemme de regroupement \ref{LemHOjqqw} nous dit que la famille \( \{ Y_{2n} \} \) est une famille de variables aléatoires indépendantes (et idem pour la famille \( Y_{2n-1}\)). En effet, les variables aléatoires \( Y_{2n}\) correspondent à la partition \( 23\), \( 45\), \( 67\), etc.

    Nous appliquons la loi des grands nombres sur les deux familles indépendamment :
    \begin{equation}
        \frac{1}{ n }\sum_{j=1}^nY_{2j-1}\stackrel{p.s.}{\longrightarrow}\frac{1}{ b^2 }
    \end{equation}
    et 
    \begin{equation}
        \frac{1}{ n }\sum_{j=1}^nY_{2j}\stackrel{p.s.}{\longrightarrow}\frac{1}{ b^2 }
    \end{equation}
    Pour rappel, le but pour l'instant est d'établir la limite \( \lim_{n\to \infty} \frac{1}{ n }\sum_{j=1}^nY_j=\frac{1}{ b^2 }\). Nous allons l'établir séparément pour les termes pairs et impairs de la suite. Pour les pairs :
    \begin{equation}
        \frac{1}{ 2n }\sum_{j=1}^{2n}Y_j=\frac{ 1 }{2}\left( \frac{1}{ n }\sum_{j=1}^nY_{2j-1} \right)+\frac{ 1 }{2}\left( \frac{1}{ n }\sum_{j=1}^nY_{2j} \right)\stackrel{p.s.}{\longrightarrow}\frac{1}{ b^2 }
    \end{equation}
    Pour les impairs\quext{Ici dans \cite{KXjFWKA}, la seconde somme va jusqu'à \( n-1\) et je ne comprends pas pourquoi.},
    \begin{equation}
        \frac{1}{ 2n-1 }\sum_{j=1}^{2n-1}Y_j=\frac{ n }{ 2n-1 }\left( \frac{1}{ n }\sum_{j=1}^nY_{2j-1} \right)+\frac{ n }{ 2n-1 }\left( \frac{1}{ n }\sum_{j=1}^nY_{2j} \right)\to\frac{1}{ b^2 }
    \end{equation}
    parce que les deux parenthèses convergent vers \( \frac{1}{ b^2 }\) alors que les coefficients devant convergent vers \( \frac{ 1 }{2}\).

    Au final nous avons bien
    \begin{equation}
        \frac{ N(r,n) }{ n }=\frac{1}{ n }\sum_{j=1}^{n-1}Y_j=\frac{ n-1 }{ n }\left( \frac{1}{ n-1 }\sum_{j=1}^{n-1}Y_j \right)\to\frac{1}{ b^2 }
    \end{equation}
    tant que \( r\in\mA^2\).

    Pour prouver la même chose avec \( r\in \mA^k\), il suffit de faire le même raisonnement en divisant en plus de paquets : \( \{ Y_{kj+m} \}_{m=1,\ldots, k-1}\) sont indépendants et nous utilisons \( k\) fois la loi des grands nombres.

    Donc pour toute base \( b\) nous savons que les nombres normaux en base \( b\) forment un ensemble de mesure nulle dans \( \mathopen[ 0 , 1 [\). Il reste à voir que leur union reste de mesure nulle. Cela est vrai parce que nous avons une union dénombrable et qu'une union dénombrable d'ensembles de mesure nulle est de mesure nulle par le lemme \ref{LemIDITgAy}.
\end{proof}

\begin{remark}  \label{RemUXAkcuH}
Un nombre \( x\) est normal en base \( b\) si et seulement si la suite  \( u_k=xb^k\) est équirépartie modulo \( 1\) sur \( [0,1]\) (c'est à dire quel la suite des parties fractionnelles des \( u_k\) est équirépartie). Pour le nombre \( 0.2357873\ldots\), nous parlons de la suite \( 0.2357873\ldots\); \( 0.357873\ldots\); \( 0.57897\ldots\) etc. C'est la suite des queues de suites de la suite de ses décimales\footnote{C'est pas trop bien dit, mais on se comprend, non ?}.
\end{remark}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Théorème de Bernstein}
%---------------------------------------------------------------------------------------------------------------------------

\begin{theorem}[Théorème de Bernstein\cite{KXjFWKA}]    \label{ThoDJIvrty}
    Soit \( f\in C^0\big( \mathopen[ 0 , 1 \mathclose],\eC \big)\) et son module de continuité
    \begin{equation}
        \begin{aligned}
            \omega\colon \mathopen[ 0 , 1 \mathclose]&\to \eR \\
            h&\mapsto \sup\{ | f(u)-f(v) |\tq | u-v |< h \}. 
        \end{aligned}
    \end{equation}
    Pour \( n\geq 0\) nous définissons le \( n\)\ieme\ \defe{polynôme de Bernstein}{polynôme!de Bernstein} de \( f\) par
    \begin{equation}
        B_n(f)(x)=\sum_{k=0}^{n}\binom{ n }{ k }x^k(1-x)^{n-k}f\left( \frac{ k }{ n } \right).
    \end{equation}
    Alors il existe \( C\) tel que pour tout \( n\geq 1\) :
    \begin{enumerate}
        \item
            \begin{equation}        \label{EqZQgnVqM}
                \| f-B_n(f) \|_{\infty}\leq C\omega\left( \frac{1}{ \sqrt{n} } \right).
            \end{equation}
        \item
            \begin{equation}
                B_n(f)\stackrel{unif}{\longrightarrow}f
            \end{equation}
            sur \( \mathopen[ 0 , 1 \mathclose]\).
        \item
            L'inégalité \eqref{EqZQgnVqM} est optimale : il existe une fonction \( g\in C^{0}\big( \mathopen[ 0 , 1 \mathclose],\eC \big)\) et \( \delta>0\) tels que pour tout \( N\geq 1\), \( \| g-B_n(g) \|_{\infty}\geq\frac{ \delta }{ \sqrt{n} }\). Cette fonction peut être choisie Lipschitzienne. Une telle fonction est donnée par exemple par \( g(x)=| x-\frac{ 1 }{2} |\).
    \end{enumerate}
\end{theorem}
\index{densité!des polynômes!dans \( C^0_c\mathopen[ 0 , 1 \mathclose]\)}
\index{approximation!de fonctions!par des polynômes}
\index{variable aléatoire!Bernoulli!utilisation}

\begin{proof}
    Soit \( x\in \mathopen[ 0 , 1 \mathclose]\) et une suite de variables aléatoires de Bernoulli indépendantes\footnote{Définition \ref{DefNJUkotc}.} et identiquement distribuées \( (X_i)_{i\geq 1}\) de paramètre \( x\). Nous notons \( S_n=\sum_{k=1}^nX_k\). 

    \begin{enumerate}
        \item
            
            Pour cette histoire de convergence, il faut majorer la quantité \( \big| f(x)-B_n(f)(x) \big|\). Pour cela il y a trois astuces. La première est de se souvenir que \( E\big( f(x) \big)=f(x)\), et la seconde est que le théorème de transfert \ref{PropintdPintdPXeR} appliqué à \( x\mapsto f(x/n)\) donne\footnote{Nous avons aussi utilisé la formule de l'espérance pour les variables aléatoires discrètes.}
        \begin{equation}
            E\left( f\big( \frac{ S_n }{ n } \big) \right)=\sum_{k=0}^nf\left( \frac{ k }{ n } \right)P(S_n=k)=\sum_{k=0}^nf\left( \frac{ k }{ n } \right)\binom{ n }{ k }x^k(1-x)^{n-k},
        \end{equation}
        c'est à dire que 
        \begin{equation}
            B_n(f)(x)=E\left( f\big( \frac{ S_n }{ n } \big) \right).
        \end{equation}
        Et enfin la troisième astuce est d'utiliser le lemme \ref{LemLUbgYeo} pour avoir
        \begin{equation}
            \omega\left( | x-\frac{ S_n }{ n } | \right)=\omega\left( \frac{1}{ \sqrt{n} }| \sqrt{n}-\frac{ S_n }{ \sqrt{n} } | \right)\leq
            \left( \sqrt{n}| x-\frac{ S_n }{ n } |+1 \right)\omega\big( \frac{1}{ \sqrt{n} } \big).
        \end{equation}
        À partir de là nous pouvons un peu calculer :
        \begin{subequations}
            \begin{align}
                \big| f(x)-B_n(f)(x) \big|&=\Big| E\left( f(x)-f\big( \frac{ S_n }{ n } \big) \right)    \Big|\\
                &\leq E\left( | f(x)-f\big( \frac{ S_n }{ n } \big) | \right)\\
                &\leq E\left( \omega\Big( | x-\frac{ S_n }{ n } | \Big) \right)\\
                &\leq \omega\left( \frac{1}{ \sqrt{n} } \right)E\left( | \sqrt{n}x-\frac{ S_n }{ n } |+1 \right).
            \end{align}
        \end{subequations}
        Le dernier facteur peut être récrit sous la forme
        \begin{equation}
            E\left( \sqrt{n}\big| x-\frac{ S_n }{ n } \big|+1 \right)=\sqrt{n}E\left( \big| x-\frac{ S_n }{ n } \big| \right)+1,
        \end{equation}
        et c'est là que nous pouvons utiliser l'inégalité de Hölder \ref{ProptYqspT}\index{inégalité!Hölder!utilisation} :
        \begin{equation}
            E\big( | X | \big)=\| X \|_1\leq\| X \|_2
        \end{equation}
        où \( \| X \|_2\) désigne
        \begin{equation}
            \| X \|_2=\sqrt{ E\big( | X |^2 \big)  }.
        \end{equation}
        Nous pouvons donc écrire
        \begin{equation}
            \big| f(x)-B_n(f)(x) \big|\leq \omega\left( \frac{1}{ \sqrt{n} } \right)\left( \sqrt{n}\big\| x-\frac{ S_n }{ n } \big\|_2+1 \right).
        \end{equation}
        Nous étudions maintenant de plus près la quantité \( \| x-\frac{ S_n }{ n } \|_2\). D'abord
        \begin{equation}
            E\left( \big| x-\frac{ S_n }{ n } \big|^2 \right)=x^2-2\frac{ x }{ n }E(S_n)+\frac{1}{ n^2 }E(S_n^2).
        \end{equation}
        Ensuite nous savons l'espérance de \( S_n\) (qui vaut \( E(S_n)=nx\)) par \eqref{EqDGbBgrv} et le lemme \ref{LemEXYEXEYprodindep} nous permet de calculer \( E(S_n^2)\) par indépendance des \( X_i\) qui composent \( S_n\). Nous avons alors
        \begin{subequations}
            \begin{align}
                E\left( \big| x-\frac{ S_n }{ n } \big|^2 \right)&=x^2-2x^2+\frac{1}{ n^2 }\sum_{1\leq i\neq j\leq n}E(X_i)E(X_j)+\frac{1}{ n^2 }\sum_{i=1}^nE(X_i^2)\\
                &=-x^2+\frac{ n^2-n }{ n^2 }x^2+\frac{ nx }{ n^2 }\\
                &=\frac{ x(1-x) }{ n }.
            \end{align}
        \end{subequations}
        Quelques justifications :
        \begin{itemize}
            \item \( E(X_i)=E(X_i^2)=x\) parce que \( X_i\) est une variable aléatoire de Bernoulli de paramètre \( x\).
            \item La première somme contient tous les couples \( (i,j)\) sauf les diagonaux; il y en a donc \( n^2-n\).
        \end{itemize}
        En recombinant le tout,
        \begin{subequations}    \label{subEqsRSuRoCJ}
            \begin{align}
                \big| f(x)-B_n(f)(x) \big|&\leq \omega\left( \frac{1}{ \sqrt{n} } \right)\left( \sqrt{n}\sqrt{\frac{ x(1-x) }{ n }}+1 \right)\\
                &=\omega\left( \frac{1}{ \sqrt{n} } \right)\big( \sqrt{x(1-x)}+1 \big)\\
                &\leq\frac{ 3 }{2}\omega\left( \frac{1}{ \sqrt{n} } \right).
            \end{align}
        \end{subequations}
        La dernière majoration est une rapide étude de la fonction \( x(1-x)\). 

        Étant donné que les majorations \eqref{subEqsRSuRoCJ} sont valables pour tout \( x\), en passant au supremum nous avons
        \begin{equation}
            \| f-B_n(f) \|_{\infty}\leq \frac{ 3 }{2}\omega\left( \frac{1}{ \sqrt{n} } \right)\to 0.
        \end{equation}
        
        Ceci prouve les deux premiers points du théorème.

    \item

        Fait.

    \item

        Nous considérons la fonction 
        \begin{equation}
            g(x)=\| x-\frac{ 1 }{2}j \|
        \end{equation}
        et nous vérifions qu'elle vérifie toutes les conditions. D'abord si \( u,v\in\mathopen[ 0 , 1 \mathclose]\) alors
        \begin{equation}
            \big| g(u)-g(v) \big|\leq | u-v |
        \end{equation}
        et donc \( \omega(h)\leq h\), ce qui signifie que \( g\) est \( 1\)-Lipschitz. Le principe de cette partie est de montrer que \( \| g-B_n(g) \|_{\infty}\) est plus grand que d'autres trucs (et non plus petit que d'autres trucs comme d'habitude). Nous commençons par
        \begin{equation}
            \| g-B_n(g) \|_{\infty}\geq g(\frac{ 1 }{2})-B_n(g)( \frac{ 1 }{2} ).
        \end{equation}
        Très vite nous nous rendons compte que \( g(1/2)=0\). Ensuite nous nous souvenons que
        \begin{equation}
            B_n(g)(\frac{ 1 }{2})=E\left( g(\frac{ S_n }{ n }) \right)=E\left( | \frac{ S_n }{ n }-\frac{ 1 }{2} | \right)=\frac{1}{ 2n }E\big( | 2S_n-n | \big).
        \end{equation}
        si nous posons \( \epsilon_i=2X_i-1\), alors les \( \epsilon_i\) sont des variables aléatoires de Rademacher indépendantes et identiquement distribuées qui satisfont à \( 2S_n-n=\sum_{i=1}^n\epsilon_i\). Nous utilisons la proposition \ref{PropCZRNRsf} :
        \begin{equation}
            \| f-B_n(f)_{\infty} \|\geq \frac{1}{ 2n }E\big( | \sum_i\epsilon_i | \big)\geq\frac{1}{ 2n\sqrt{e} }\big\| \sum_{i=1}^n\epsilon_j \big\|_2.
        \end{equation}
        Calculons ce qui est dans la norme :
        \begin{equation}
            \big\| \sum_{j=1}^n\epsilon_j \big\|_2^2=E\left( \big( \sum_{j=1}^n\epsilon_j \big)^2 \right)=\sum_{1\leq i\neq j\leq n}E(\epsilon_i)E(\epsilon_j)+\sum_{i=1}^nE(\epsilon_i^2)=0+n=n.
        \end{equation}
        Nous finissons alors notre travail de majoration :
        \begin{equation}
            \| f-B_n(f)_{\infty} \|\geq\frac{1}{ 2n\sqrt{e} }\big\| \sum_{i=1}^n\epsilon_j \big\|_2\geq\frac{1}{ 2\sqrt{n}\sqrt{e} }\geq\frac{1}{ 2\sqrt{e} }\omega\left( \frac{1}{ \sqrt{n} } \right).
        \end{equation}
    \end{enumerate}
\end{proof}
