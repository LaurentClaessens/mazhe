% This is part of Mes notes de mathématique
% Copyright (c) 2011-2015
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Notations et hypothèses}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Nous notons \( X\) le caractère à étudier, et \( \Omega\) l'ensemble des individus. Le caractère à étudier est vu comme une fonction sur \( \Omega\) :
\begin{equation}
    X\colon \Omega\to \eR,\eN,\{ 0,1 \},\ldots
\end{equation}
Les \defe{statistiques descriptives}{statistiques!descriptives} sont les techniques pour présenter et résumer les données : diagrammes, graphiques, indicateurs numériques : moyenne, écart-type, médiane, \ldots

Nous faisons les hypothèses suivantes :
\begin{enumerate}
    \item
        Chaque observation \( x_i\) est la réalisation de la variable aléatoire \( X\) qui sera de loi inconnue \( \mu\).
    \item
        Le \( n\)-uple \( (x_1,\ldots,x_n)\) est la réalisation de \( (X_1,\ldots,X_n)\) qui est l'échantillon de taille \( n\).
    \item
        Les variables aléatoires \( X_i\) sont indépendantes et identiquement distribuées, de loi commune \( \mu\). La loi \( \mu\) est la \defe{loi parente}{loi!parente} de l'échantillon.
\end{enumerate}

\begin{example}
    Un échantillon de taille \( 1\) consisterait à tirer au sort une personne dans une population et mesurer sa taille.
\end{example}

\begin{example}
    Une échantillon de taille \( n\) consisterait à tirer au sort \( n\) personnes dans une population et de mesurer leurs tailles.
\end{example}

L'\defe{inférence statistique}{inférence statistique} est l'art de dégager des informations sur la population à partir d'informations partielles : intervalles de confiance, estimateurs, test d'hypothèses, \ldots

En théorie des probabilités, nous connaissons la loi de la variable aléatoire \( X\) et nous en déduisons des informations sur le réalisations de \( X\) : valeur la plus probable, moyenne, intervalle dans lequel \( X(\omega)\) a le plus de chance d'appartenir. En statistique, au contraire, la loi est inconnues et nous cherchons des informations sur la loi à partir d'un échantillon de données numériques observées.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Modèle statistique}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Une \defe{modèle statistique}{modèle!statistique} est un triplet
\begin{equation}
    \statS=\Big[ (\Omega,\tribF,P),(X_{\theta})_{\theta\in\Theta},(\mu_{\theta})_{\theta\in\Theta} \Big]
\end{equation}
où \( (\Omega,\tribF,P)\) est un espace probabilisé, \( (X_{\theta})\) est une famille de variables aléatoires définies sur \( \Omega\) et telles que pour tout \( \theta\in\Theta\), la variable aléatoire \( X_{\theta}\) suive la loi \( \mu_{\theta}\). Les $\mu_{\theta}$ sont des mesures sur les boréliens de \( \eR\) et pour tout \( B\in\Borelien(\eR)\) nous avons
\begin{equation}
    P(X_{\theta}\in B)=\mu_{\theta}(B).
\end{equation}
\begin{remark}
    D'une certaine manière, l'introduction de \( \mu_{\theta}\) dans la définition est redondante parce que ces mesures sont déjà contenues dans la données des variables aléatoires \( X_{\theta}\).
\end{remark}

\begin{example}[Modèle statistique gaussien]
    Si nous savons que les variables aléatoires \( X_i\) suivent une loi gaussienne, alors nous considérons \( \Theta=\eR\times\eR^+\) et \( \theta=(m,\sigma^2j)\). Dans ce cas, \( \mu_{\theta}=\dN(m,\sigma^2)\) et le but de la statistique est de déterminer la valeur de \( \theta\) qui correspond à une population en partant de l'observation d'un échantillon.
\end{example}

\begin{definition}
    Si \( \Theta\subset\eR^k\), nous disons que le modèle statistique est un modèle \defe{paramétrique}{modèle!paramétrique}.
\end{definition}
Le modèle gaussien est un modèle paramétrique : dès que \( m\) et \( \sigma^2\) sont déterminés, la loi du phénomène \( X\) est connue.

\begin{definition}
    Pour chaque \( \theta\in\theta\), un \defe{échantillon}{echantillon@échantillon} de taille \( n\) associé à un modèle statistique \( \big[ (\Omega,\tribF,P),(X_{\theta}),(\mu_{\theta}) \big]\) est un vecteur \( \big( X_{\theta,1},\ldots,X_{\theta,n} \big)\) de taille \( n\) de variables aléatoires indépendantes et identiquement distribuées de la même loi que la variable aléatoire \( X_{\theta}\). La loi \( \mu_{\theta}\) est la \defe{loi parente}{loi!parente} de l'échantillon.
\end{definition}

\begin{definition}
    Un \defe{modèle d'échantillonnage}{modèle!échantillonnage} sur le modèle statistique \( \statS\) est une famille \( (X_{\theta,1},\ldots, X_{\theta,n})_{\theta\in\Theta}\) d'échantillons de taille \( n\geq 1\).
\end{definition}

Nous noterons souvent \( (X_1,\ldots,X_n)\) à la place de \( (X_{\theta,1},\ldots,X_{\theta,n})\) un échantillon, mais il faut se souvenir que les \( X_i\) suivent toujours la même loi donnée par \( \theta\). La loi du vecteur \( (X_1,\ldots,X_n)\) est \( \mu_{\theta}\otimes\ldots\otimes\mu_{\theta}\) et est définie sur l'espace \( (\Omega^n,\tribF\otimes\ldots\otimes\tribF,P^{\otimes n})\).

\begin{remark}
    Le travail du statisticien est de proposer un modèle statistique \( \statS\) a priori. Si nous étudions la taille d'une population, nous allons choisir un modèle gaussien. Plus le modèle est précis, plus l'espace \( \Theta\) est petit mais plus il y a de risques que le vérité soit hors de l'ensemble considéré.
\end{remark}

\begin{example}
    Soit \( X\) une variable aléatoire de carré intégrable que l'on sait simuler. Afin d'évaluer la moyenne \( \mu\) de \( X\), nous pouvons considérer la moyenne empirique des simulations : \( \bar X_n=\frac{1}{ n }\sum_{i=1}^nX_i\) où les variables aléatoires \( X_i\) sont indépendantes, identiquement distribuées et de même loi que \( X\). 

    La loi des grands nombres nous enseigne que \( \bar X_n\to\mu\). De plus,
    \begin{equation}
        \lim_{n\to \infty} P\left( \mu\in\left[ \bar X_n-\frac{ a\sigma }{ \sqrt{n} },\bar X_n+\frac{ a\sigma }{ \sqrt{n} } \right] \right)=\int_{-a}^a e^{-x^2/2}\frac{ dx }{ \sqrt{2\pi} }.
    \end{equation}
    En effet, la condition sur \( \mu\) est équivalente à
    \begin{equation}
        -a\leq \frac{ \bar X_n-\mu }{ \sigma/\sqrt{n} }\leq a,
    \end{equation}
    tandis que le théorème central limite nous enseigne que la variable aléatoire \( \frac{ \bar X_n-\mu }{ \sigma/\sqrt{n} }\) se comporte comme \( \dN(0,1)\) lorsque \( n\) est grand. Dans ce cas, nous avons que
    \begin{equation}
        P\left( \frac{ \bar X_n-\mu }{ \sigma/\sqrt{n} }\in\mathopen[ -a , a \mathclose] \right)=\frac{1}{ \sqrt{2\pi} }\int_{-a}^a e^{-x^2/2}dx.
    \end{equation}
    Notons que dans ce calcul nous avons utilisé le fait que \( \mu=E(X_1)\).

    Montrons que la suite
    \begin{equation}
        \sigma_n^2=\frac{1}{ n }\sum_{i=1}^nX_i^2-\left( \frac{1}{ n }\sum_{i=1}^nX_i \right)^2
    \end{equation}
    converge presque sûrement vers \( \sigma^2\). Le théorème central limite implique que
    \begin{equation}
        \frac{1}{ n }\sum_{i=1}^nX_i^2\stackrel{p.s.}{\longrightarrow} E(X_1^2)
    \end{equation}
    et que
    \begin{equation}
        \left( \frac{1}{ n }\sum_{i=1}^nX_i \right)^2\stackrel{p.s.}{\longrightarrow}E(X_1)^2.
    \end{equation}
    La différence converge donc presque sûrement vers \( \sigma^2\) en vertu de la proposition \ref{PrropVarAlterfrom}.

    Nous avons également \( E(\sigma_n^2)=\sigma^2\). En effet, sachant que \( E(X_i)=E(X_1)=\mu\) et que \( E(X_i^2)=E(X_1^2)=\mu^2+\sigma^2\),
    \begin{subequations}
        \begin{align}
            E(\sigma_n^2)&=\frac{1}{ n }\sum_{i=1}^nE(X_i^2)-\frac{1}{ n^2 }\left( \sum_{i=1}^nE(X_i^2) \right)+\sum_{i\neq j}E(X_iX_j))\\
            &=\sigma^2+\mu^2-\frac{1}{ n^2 }\big( n(\sigma^2+\mu^2)+(n^2-n)\mu^2 \big)\\
            &=\sigma^2-\frac{1}{ n }\sigma^2,
        \end{align}
    \end{subequations}
    dont la limite \( n\to\infty\) donne bien \( \sigma^2\).

    Nous voudrions à présent montrer que 
    \begin{equation}
        \frac{ \bar X_n-\mu }{ \sigma_n/\sqrt{n} }\stackrel{\hL}{\longrightarrow}\dN(0,1).
    \end{equation}
    Vu que le théorème central limite donne une convergence en loi, nous pouvons utiliser le lemme de Slutsky pour montrer que
    \begin{equation}
        \left( \frac{ \bar X_n-\mu }{ 1/\sqrt{n} },\sigma_n^2 \right)\stackrel{\hL}{\longrightarrow}(\sigma Z,\sigma^2)
    \end{equation}
    où \( Z\sim\dN(0,1)\). En vertu de la proposition \ref{PropcvLsousfonc} appliqué à la fonction \( f\colon \eR^2\to \eR\),
    \begin{equation}
        f(x,y)=\begin{cases}
            \frac{ x }{ \sqrt{y} }    &   \text{si \( y\neq 0\)}\\
            0    &    \text{sinon}
        \end{cases}
    \end{equation}
    nous avons la convergence en loi
    \begin{equation}
        f\left( \frac{ \bar X_n-\mu }{ 1/\sqrt{n} },\sigma_n^2 \right)\stackrel{\hL}{\longrightarrow}f(\sigma Z,\sigma^2),
    \end{equation}
    c'est à dire 
    \begin{equation}
        \frac{ \bar X_n-\mu }{ \sigma_n/\sqrt{n} }\stackrel{\hL}{\longrightarrow}Z.
    \end{equation}
    Afin d'être complet, précisons que 
    \begin{equation}
        P\big( (\sigma Z,\sigma)\in\eR\times \{ 0 \} \big)=0.
    \end{equation}
\end{example}

\begin{proposition}     \label{PropLimxBNpxbxbsqrt}
    Soit \( X_i\) des variables aléatoires indépendantes et identiquement distribuées de loi parente \( \dB(n,p)\). Alors si \( \bar X_n\) désigne la moyenne empirique,
    \begin{equation}
        \sqrt{n}\frac{ \bar X_n-p }{ \sqrt{\bar X_n(1-\bar X_n)} }\stackrel{\hL}{\longrightarrow}Z\sim\dN(0,1).
    \end{equation}
\end{proposition}

\begin{proof}
    Cela est une application de la loi des grands nombres, tu théorème central limite, du lemme de Slutsky et de la proposition \ref{PropcvLsousfonc}.

    D'abord, la loi des grands nombres nous indique que \( \bar X_n\to p\) parce que \( p\) est l'espérance de Bernoulli. Ensuite nous avons
    \begin{equation}
        \frac{ \bar X_n-E(X) }{ \sqrt{\Var(X)}/\sqrt{n} }=\sqrt{n}\frac{ \bar X_n-p }{ \sqrt{p(1-p)} }
    \end{equation}
    parce que la variance d'une loi de Bernoulli est \( p(1-p)\). Le théorème central limite nous indique par conséquent que
    \begin{equation}
        \sqrt{n}\frac{ \bar X_n-p }{ \sqrt{p(1-p)} }\stackrel{\hL}{\longrightarrow}Z\sim\dN(0,1).
    \end{equation}
    Le lemme de Slutsky implique alors la convergence du couple :
    \begin{equation}
        \left( \sqrt{n}\frac{ \bar X_n-p }{ \sqrt{p(1-p)} },\bar X_n \right)\stackrel{\hL}{\longrightarrow}(Z,p).
    \end{equation}
    Nous appliquons maintenant la proposition \ref{PropcvLsousfonc} avec la fonction
    \begin{equation}
        f(x,y)=\frac{ \sqrt{p(1-p)}x }{ \sqrt{y(1-y)} }
    \end{equation}
    qui est une fonction dont l'ensemble des points de discontinuité est \( C=\{ 0 \}\). Étant donné que \( P(\bar X_n=0)=0\), la proposition s'applique et nous avons
    \begin{equation}
        f\left( \sqrt{n}\frac{ \bar X_n-p }{ \sqrt{p(1-p)} },\bar X_n \right)\stackrel{\hL}{\longrightarrow}f(Z,p),
    \end{equation}
    c'est à dire
    \begin{equation}
        \sqrt{n}\frac{ \bar X_n-p }{ \sqrt{\bar X_n(1-\bar X_n)} }\stackrel{\hL}{\longrightarrow}Z\sim\dN(0,1).
    \end{equation}
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Modèles d'échantillonnages}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Soit \( X\), une variable aléatoire sur \( (\Omega,\tribF,P)\). Un \defe{échantillon}{echantillon@échantillon} de taille \( n\) pour \( X\) est une suite de \( n\) variables aléatoires \( (X_1,\ldots,X_n)\) définies sur \( (\Omega,\tribF,P)\) indépendantes et de même loi que \( X\). Nous disons que la loi de \( X\) est la \defe{loi parente}{loi!parente d'un échantillon} de la suite \( X_i\).

\begin{definition}
    Soit
    \begin{equation}
        \statS=\Big[ (\Omega,\tribF,P),(X_{\theta}),(\mu_{\theta}) \Big]_{\theta\in\Theta},
    \end{equation}
    un modèle statistique. Un \defe{modèle d'échantillonnage}{modèle!échantillonnage} de taille \( n\) associée au modèle statistique \( \statS\) est la donnée d'une famille de \( n\)-échantillons \( (X_{\theta,1}),\ldots,X_{\theta,n}\) telle que pour tout \( \theta\in\Theta\), l'échantillon \( (X_{\theta,i})\) soit de variable parente \( X_{\theta}\).
\end{definition}

La \defe{moyenne empirique}{moyenne!empirique d'un échantillon} du \( n\)-échantillon \( (X_i)\) est la variable aléatoire
\begin{equation}
    \bar X_n=\frac{1}{ n }\sum_{i=1}^{n}X_i.
\end{equation}

La proposition suivante signifie que la moyenne empirique est une «bonne» façon d'approcher la variable aléatoire.
\begin{proposition}
    Soit \( X\), une variable aléatoire dans \( L^2(\Omega)\) (c'est à dire \( E(X^2)<\infty\)) d'espérance \( m\) et de variance \( \sigma^2\). Alors
    \begin{enumerate}
        \item
            \( E(\bar X_n)=m\) et \( \Var(\bar X_n)=\frac{ \sigma^2 }{ n }\).
        \item
            Nous avons les convergences
            \begin{subequations}
                \begin{align}
                    \bar X_n&\stackrel{p.s.}{\longrightarrow} m\\
                    \frac{ \bar X_n-m }{ \sigma/\sqrt{n} }&\stackrel{\hL}{\longrightarrow} Z\sim\dN(0,1).
                \end{align}
            \end{subequations}
        \item
            Si \( X\) est de loi \( \dN(m,\sigma^2)\), alors \( \bar X_n\sim\dN(m,\frac{ \sigma^2 }{ n })\), c'est à dire
            \begin{equation}
                \frac{ \bar X_n -m}{ \sigma/\sqrt{n} }\sim\dN(0,1).
            \end{equation}
            
            
    \end{enumerate}
    
\end{proposition}

\begin{remark}
    L'intérêt de cette proposition en statistique descriptive expérimentale est le suivant. La taille moyenne des français est un nombre \( m\) qui existe, mais qui est largement hors de portée de l'expérience (mesurer \( 65\cdot 10^6\) personnes risque de prendre un sacré temps). Si on mesure seulement \( n\) personnes dont les tailles sont \( (x_i)_{i=1,\ldots, n}\) (ici \( x_i\) est un \emph{nombre expérimental}, pas une variable aléatoire), alors on peut calculer la moyenne \( \bar x_n\) de ces \( n\) personnes-là. La proposition indique que si \( n\) est assez grand, alors \( \bar x_n\) donne une bonne idée de \( m\).

    Ne pas confondre \( X_n\) qui est une variable aléatoire, c'est à dire une application mesurable, qui nous sert à démontrer des théorèmes en mathématique, avec \( x_n\) qui est un nombre mesuré sur le terrain, qui a une existence \emph{physique} bien définie, mais aucun status mathématique.

    Si on croit que toute cette histoire de variables aléatoires, de tribu et de mesures décrit effectivement la réalité, alors on peut croire que le comportement de la suite \( \bar X_n\) décrit bien le comportement de la suite \( \bar x_n\) (cette dernière n'étant même pas une suite parce qu'on n'a jamais qu'un nombre fini de mesures expérimentales).
\end{remark}

La \defe{variance empirique}{variance!empirique} d'un échantillon est la variable aléatoire
\begin{equation}
    V_n^2=\frac{1}{ n }\sum_{i=1}^n(X_i-\bar X_n)^2.
\end{equation}
La \defe{variance empirique corrigée}{variance!empirique corrigée} est la variable aléatoire 
\begin{equation}        \label{Eqdefvarempicorri}
    S_n^2=\frac{1}{ n-1 }\sum_{i=1}^n(X_i-\bar X_n)^2.
\end{equation}

\begin{lemma}
    La variance corrigée et la variance empirique ont comme espérances :
    \begin{subequations}
        \begin{align}
            E(V_n^2)&=\frac{ n-1 }{ n }\sigma^2\\
            E(S_n^2)&=\sigma^2.
        \end{align}
    \end{subequations}
\end{lemma}

\begin{proof}
    Nous commençons par calculer l'espérance de la variance non corrigée. La première étape est de la récrire sous la forme
    \begin{equation}
        \begin{aligned}[]
            V_n^2&=\frac{1}{ n }\sum_k(X_k^2-2X_k\bar X_n+\bar X_n^2)\\
            &=\frac{1}{ n }\sum_kX_k^2-\frac{ 2 }{ n }\bar X_n\underbrace{\sum_kX_k}_{=n\bar X_n}+\frac{1}{ n }\underbrace{\sum_k\bar X_n^2}_{=n\bar X_n^2}\\
            &=\frac{1}{ n }\sum_kX_k^2-2\bar X_n^2+\bar X_n^2\\
            &=\frac{1}{ n }\sum_kX_k^2-\bar X_n^2.
        \end{aligned}
    \end{equation}
    Nous calculons séparément l'espérance de ces deux termes. Si \( X\) est la loi parente des \( X_i\), en utilisant l'indépendance des \( X_i\) nous trouvons
    \begin{equation}
        \begin{aligned}[]
            E\left( \frac{1}{ n }\sum_kX_k^2 \right)&=\frac{1}{ n }\sum_{k=1}^nE(X_k^2)\\
            &=E(X^2)\\
            &=E(X)^2-\Var(X).
        \end{aligned}
    \end{equation}
    Nous devons à présent calculer l'espérance de \( \bar X_n^2\):
    \begin{equation}
        E(\bar X_n^2)=E(\bar X_n)^2+\Var(\bar X_n).
    \end{equation}
    En utilisant le lemme \ref{LemVarXpYsmindep},
    \begin{subequations}
        \begin{align}
            \Var(\bar X_n)&=\Var\left( \frac{1}{ n }\sum_kX_k \right)\\
            &=\frac{1}{ n^2 }\sum_k\Var(X_k)\\
            &=\frac{1}{ n }\Var(X).
        \end{align}
    \end{subequations}
    Par conséquent
    \begin{equation}
        E(V_n^2)=\Var(X)\left( 1-\frac{1}{ n } \right)=\frac{ n-1 }{ n }\Var(X).
    \end{equation}

    En ce qui concerne la variance corrigée,
    \begin{equation}
        S_n^2=\frac{1}{ n-1 }\sum_k(X_k-\bar X_n)^2=\frac{ n }{ n-1 }V_n^2,
    \end{equation}
    par conséquent \( E(S_n^2)=\frac{ n }{ n-1 }E(V_n^2)=\Var(X)\).
\end{proof}

\begin{theorem}[Théorème de Cochran\cite{ProbaDanielLi}]     \label{ThoCochraneChiStudent}  \index{théorème!Cochran}
    Soient \( (X_i)\) des variables aléatoires gaussiennes indépendantes de loi \( \dN(m,\sigma^2)\) avec \( \sigma>0\). Alors
    \begin{enumerate}
        \item
            \( \bar X_n\sim\dN(m,\frac{ \sigma^2 }{ n })\),
        \item       \label{ItemThoCochraneChiStudentii}
            \( \left( \frac{ n-1 }{ \sigma^2 } \right)S_n^2=\left( \frac{ n }{ \sigma^2 } \right)\bar V_n^2\sim\chi^2(n-1)\),
        \item
            les variables aléatoires \( \bar X_n\) et \( \bar V_n\) sont indépendantes et
            \begin{equation}
                \frac{ \bar X_n-m }{ S_n/\sqrt{n} }=\frac{ \bar X_n-m }{ \sqrt{\bar V_n/(n-1)} }\sim\dT(n-1).
            \end{equation}
    \end{enumerate}
\end{theorem}
\index{théorème!Cochrane}
Nous pouvons aussi écrire le dernier résultat en termes de la variance corrigée \( S_n\), l'estimateur sans biais de la variance parce que
\begin{equation}
    \sqrt{\frac{ \bar V_n }{ n-1 }}=\frac{1}{ \sqrt{n} }S_n
\end{equation}
en vertu de la définition \eqref{Eqdefvarempicorri}.


\begin{proposition}
    Soit \( X\) une variable aléatoire de variance \( \Var(X)=\sigma\). Si \( E(X^4)<\infty\), alors
    \begin{enumerate}
        \item
            \( S_n^2\stackrel{p.s.}{\longrightarrow}\sigma^2\).
        \item
            \begin{equation}
                \frac{ S_n^2-\sigma^2 }{ \sqrt{\frac{ \mu^4-\sigma^4 }{ n }} }\stackrel{\hL}{\longrightarrow}Z\sim\dN(0,1)
            \end{equation}
            où \( \mu^4=E(X^4)\) est le moment d'ordre \( 4\) de \( X\).
    \end{enumerate}
\end{proposition}

\begin{theorem}
    Si \( (X_1,\ldots,X_n)\) est un \( n\)-échantillon de loi parente \( \dN(m,\sigma^2)\), alors
    \begin{enumerate}
        \item
            Les variables aléatoires 
            \begin{equation}
                \begin{aligned}[]
                    \frac{ \bar X_n-m }{ \sigma/\sqrt{n} }&&\text{et}&&(n-1)\frac{ S_n^2 }{ \sigma^2 }
                \end{aligned}
            \end{equation}
            sont indépendantes.
        \item
            La loi de \( (n-1)\frac{ S_n^2 }{ \sigma^2 }\) est \( \chi^2(n-1)\).
    \end{enumerate}
    Si un échantillon vérifie ces deux propriétés, alors les \( X_i\) sont de loi \( \dN(m,\sigma^2)\).
\end{theorem}


L'inégalité de Markov donne une borne supérieure à la probabilité qu'une variable aléatoire positive soit plus grande ou égale à une constante.
\begin{theorem}[Inégalité de Markov]\index{Markov!inégalité}    \label{ThoInegMarkov}
    Soit \( X\) une variable aléatoire à valeurs dans \( \eR^d\) et \( \varphi\colon \eR^d\to \mathopen[ 0 , \infty [\). Alors
    \begin{equation}
        P\big( \varphi(X)\geq a \big)\leq\frac{ E\big( \varphi(X) \big) }{ a }
    \end{equation}
    pour tout \( a>0\).
\end{theorem}

\begin{proof}
    Calculons le second membre :
    \begin{equation}
        \begin{aligned}[]
            \frac{ E\big( \varphi(X) \big) }{ a }&=\int_{\Omega}\frac{ \varphi(X) }{ a }dP\\
            &=\int_{\varphi(X)\geq a}\underbrace{\frac{ \varphi(X) }{ a }}_{\leq 1}dP+\int_{\varphi(X)<a}\frac{ \varphi(X) }{ a }dP\\
            &\geq\int_{\varphi(X)\leq a}dP\\
            &=P\big( \varphi(X)\leq a \big).
        \end{aligned}
    \end{equation}
    D'où l'inégalité voulue.
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Estimation ponctuelle}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Nous considérons un modèle statistique 
\begin{equation}
    \statS=\big[ (\Omega,\tribF,P),(X_{\theta}),(\mu_{\theta}) \big]_{\theta\in\Theta}
\end{equation}
et pour tout \( \theta\) nous notons \( X=(X_{\theta,1},\ldots,X_{\theta,n})\) un échantillon de loi parente \( \mu_{\theta}\). Tant que nous travaillerons avec un \( \theta\) fixé, nous écrirons \( X=(X_1,\ldots,X_n)\) sans expliciter la paramètre \( \theta\). Nous noterons 
\begin{equation}        \label{EqFbKGZD}
    E_{\theta}\big( \varphi(X_1,\ldots,X_n) \big)=\int_{\eR^n}\varphi(x_1,\ldots,x_n)d\mu_{\theta}^{\otimes n}(x_1,\ldots,x_n).
\end{equation}
Dans cette notation nous plaçons le \( \theta\) sur l'espérance, tandis qu'en réalité le \( \theta\) devrait être sur chaque \( X_1\). Tant qu'aucune confusion n'est possible nous ferons toujours cet abus d'écriture.

Le but de la théorie de l'estimation est de déduire la valeur de \( \theta\) (et donc la loi \( \mu_{\theta}\)) à partir d'un échantillon de loi parente \( \theta\). 

Nous posons les hypothèses suivantes.
\begin{enumerate}
    \item
        Le modèle statistique \( \statS\) est paramétré, c'est à dire que \( \Theta\subset\eR^d\) avec le plus souvent \( d=1,2\). Typiquement les paramètres seront la moyenne et la variance.
    \item
        Le modèle statistique est \defe{identifiable}{identifiable}, c'est à dire que pour tout couple \( (\theta_1,\theta_2)\in\Theta^2\), si \( \theta_1\neq\theta_2\), alors \( \mu_{\theta_1}\neq\mu_{\theta_2}\).
    \item
        Le modèle \( \statS\) est \defe{dominé}{dominé!modèle statistique} par la mesure de Lebesgue si les lois \( \mu_{\theta}\) sont continues et par la mesure de comptage si les lois \( \mu_{\theta}\) sont discrètes.
\end{enumerate}

\begin{example}
    La famille des lois exponentielles \( \big( \dE(\lambda) \big)_{\lambda>0}\) est identifiable. Les lois gaussiennes \( \big( \dN(m,\sigma^2) \big)_{m\in\eR,\sigma^2>0}\) sont également identifiables.

    En réalité il est assez compliqué de trouver un exemple de modèle non identifiable à moins de la faire exprès. Par exemple en paramétrant les lois exponentielles de la façon suivante : \( \big( \dE(\sin(\lambda)) \big)_{\lambda\in\eR}\). Cette famille n'est pas identifiable.
\end{example}

Le corollaire \ref{CorDomDens} ainsi que l'hypothèse de modèle dominé implique que les lois ont des densités. Si la loi \( \mu_{\theta}\) est discrète, nous notons 
\begin{equation}
    p(x,\theta)=\mu_{\theta}(\{ x \})
\end{equation}
la densité de \( \mu_{\theta}\) par rapport à la mesure de comptage. Si La loi \( \mu_{\theta}\) est continue, nous notons
\begin{equation}
    p(x,\theta)=f_{\theta}(x)
\end{equation}
la densité par rapport à la mesure de Lebesgue.

Si \( \mu_{\theta}\) est une loi discrète et si \( (X_1,\ldots,X_n)\) est un échantillon de taille \( n\), alors pour tout \( (x_1,\ldots,x_n)\in\eR^n\) nous avons
\begin{equation}
    p_n(x_1,\ldots,x_n;\theta)=\mu_{\theta}^{\otimes n}\big( \{ x_1,\ldots,x_n \} \big)=\mu_{\theta}(\{ x_1 \})\ldots\mu_{\theta}(\{ x_n \})=p(x_1,\theta)\ldots p(x_n,\theta).
\end{equation}
La première et la dernière égalité sont des notations; la seconde est une conséquence de l'indépendance des \( X_i\) contenues dans l'échantillon. Pour une loi continues, nous adoptons la même notation. Le vecteur aléatoire \( (X_1,\ldots,X_n)\) admet la densité
\begin{equation}
    (x_1,\ldots,x_n)\mapsto p_n(x_1,\ldots,x_n;\theta)=f_{\theta}(x_1)\ldots f_{\theta}(x_n)=p(x_1,\theta)\ldots p(x_n,\theta).
\end{equation}

\begin{example}
    Soit \( (X_1,\ldots,X_n)\) un \( n\)-échantillon de loi \( \dB(1,\theta)\) avec \( \theta\in\mathopen] 0 , 1 \mathclose[\). C'est une loi discrète portée par l'ensemble \( \{ 0,1 \}\). Nous avons
    \begin{equation}
        p(x,\theta)=\begin{cases}
            0    &   \text{si \( 0\neq x\neq 1\)}\\
            1-\theta    &   \text{si \( x=0\)}\\
            \theta    &    \text{si \( x=1\).}
        \end{cases}
    \end{equation}
    De façon plus condensée nous pouvons écrire 
    \begin{equation}
        p(x,\theta)=\theta^x(1-\theta)^{1-x}\mtu_{\{ 0,1 \}}(x).
    \end{equation}
    Pour tout \( (x_1,\ldots,x_n)\in\eR^p\), la densité du \( n\)-échantillon est donnée par
    \begin{equation}
        p_n(x_1,\ldots,x_n;\theta)=\theta^{x_1+\ldots+x_n}(1-p)^{1-\sum_i(1-x_i)}\mtu_{\{ 0,1 \}^n}(x_1,\ldots,x_n).
    \end{equation}
\end{example}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Statistiques et estimateurs}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{definition}
    Une \defe{statistique}{statistique} sur un modèle d'échantillonnage est une variable aléatoire fonction de l'échantillon \( (X_1,\ldots,X_n)\) ne dépendant pas de \( \theta\)\footnote{Parce que d'habitude c'est ce qu'on cherche à estimer.}. C'est à dire une application borélienne \( T\colon \eR^n\to \eR\) ne dépendant pas de \( \theta\). La statistique associée à cette application est $S=T(X_1,\ldots,X_n)$.
\end{definition}

Les fonctions \( T(X_1,\ldots,X_n)\) données par \( \sum_iX_i\), \(  e^{\sum X_i}\) sont des statistiques. La constante \( \frac{ 1 }{2}\) est également une statistique (mais elle est moins intéressante).

Un \defe{estimateur}{estimateur} est une statistique qui prend ses valeurs dans \( \Theta\). Nous la noterons
\begin{equation}
    \hat\theta_n=\theta(X_1,\ldots,X_n).
\end{equation}
La fonction \( \hat\theta_n\) est borélienne à valeurs dans \( \Theta\).

\begin{example}
    Soit un \( n\)-échantillon de loi \( \dB(1,\theta)_{\theta\in\mathopen[ 0 , 1 \mathclose]}\). Les fonctions \( \hat\theta_n=\frac{1}{ n }\sum_{i=1}^nX_i\) et \( \hat\varphi_n=\frac{ 1 }{2}\) sont des estimateurs. Cependant nous devinons que la première va être plus intéressante que la seconde.
\end{example}

Pour la suite, nous travaillerons avec des estimateurs de carré intégrable, c'est à dire que
\begin{equation}
    E_{\theta}\big( | \hat\theta_n(X_1,\ldots,X_n) |^2 \big)<\infty
\end{equation}
pour tout \( \theta\in\Theta\).

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Qualité des estimateurs}
%---------------------------------------------------------------------------------------------------------------------------

\begin{definition}
    Une estimateur est \defe{convergent}{convergent!estimateur}\index{estimateur!convergent} ou \defe{consistant}{consistance!estimateur}\index{estimateur!consistant} si pour tout \( \theta\in\Theta\), la suite de variables aléatoires \( \hat\theta_n(X_1,\ldots,X_n)\) converge en probabilité vers \( \theta\).
\end{definition}
En d'autres termes, l'estimateur \( \hat\theta_n\) est convergent si pour tout \( \theta\in\Theta\) et pour tout \( \eta>0\),
\begin{equation}
    \lim_{n\to \infty} P\big( | \hat\theta_n(X_1,\ldots,X_n)-\theta |>\eta \big)=0.
\end{equation}
La probabilité dans le membre de gauche est donnée par
\begin{equation}
    \mu^{\otimes n}_{\theta}\Big( \big\{ (x_1,\ldots,x_n)\in\eR^n\tq| \hat\theta_n(x_1,\ldots,x_n)-\theta |>\eta \big\} \Big).
\end{equation}


Soit \( \hat\theta_n\) un estimateur pour \( \theta\). Nous cherchons à minimiser l'erreur commise en remplaçant \( \theta\) par \( \hat\theta_n\). Nous introduisons donc le \defe{risque quadratique}{risque!quadratique} de l'estimateur \( \hat\theta_n\) par
\begin{equation}
    R(\hat\theta_n,\theta)=E_{\theta}\big( (\hat\theta_n-\theta)^2 \big).
\end{equation}
Nous disons qu'un estimateur \( \hat\theta_{n,1}\) est préférable à \( \hat\theta_{n,2}\) si pour tout \( \theta\in\Theta\) nous avons
\begin{equation}
    R(\hat\theta_{n,1},\theta)<R(\hat\theta_{n,2},\theta).
\end{equation}

\begin{lemma}
    Une formule alternative pour le risque quadratique :
    \begin{equation}
        R(\hat\theta_n,\theta)=\Var(\hat\theta_n)+\big( E_{\theta}(\hat\theta_n)-\theta \big)^2
    \end{equation}
\end{lemma}

\begin{proof}
    Nous avons
    \begin{equation}
        E_{\theta}\left( (\hat\theta_n-\theta)^2 \right)=\Var(\hat\theta_n-\theta)-E_{\theta}(\hat\theta_n-\theta)^2.
    \end{equation}
    D'une part \( \Var(\hat\theta_n-\theta)=\Var(\hat\theta_n)\) et d'autre part \( E_{\theta}(\hat\theta_n-\theta)^2=\big[ E(\hat\theta_n)-\theta \big]^2\). Par conséquent
    \begin{equation}    \label{EqRisqueetbaisiVar}
        R(\hat\theta_n,\theta)=\Var(\hat\theta_n)-\Big( E(\hat\theta_n)-\theta \Big)^2.
    \end{equation}
\end{proof}

Le \defe{biais}{biais!d'estimateur}\index{estimateur!biais} de l'estimateur \( \hat\theta_n\) est la quantité
\begin{equation}
    E_{\theta}(\hat\theta_n)-\theta.
\end{equation}
À ce niveau, nous rappelons que nous écrivons \( E_{\theta}\) l'espérance calculée en supposant la valeur \( \theta\) pour le paramètre des différentes variables aléatoires entrant dans le calcul. Voir la discussion autour de la définition \eqref{EqFbKGZD}.

\begin{example}     \label{ExytNlTq}
    Dans le cadre de la proposition \ref{PropGMntiy}, nous voulons savoir si \( \frac{ N_t }{ t }\) est un estimateur sans biais de \( \lambda\). Pour ce faire nous calculons
    \begin{equation}
        E_{\lambda}\left( \frac{ N_t }{ t } \right)=\frac{1}{ t }E_{\lambda}(N_t)=\lambda
    \end{equation}
    parce que \( E(N_t)=\lambda t\). Ici nous avons calculé \( E(N_t)\) en prenant \( \lambda\) pour valeur du paramètre du processus de Poisson, alors que en principe c'est justement le paramètre que nous voulons estimer.
\end{example}

\begin{example}
    La moyenne empirique \( \bar X_n\) est un estimateur sans billet de la moyenne. L'estimateur
    \begin{equation}
        \frac{1}{ n-1 }\sum_{i=1}^n(X_i-\bar X_i)^2
    \end{equation}
    est un estimateur sans billet de la variance.
\end{example}

Un estimateur sans biais n'est pas toujours de meilleur qualité qu'un estimateur avec biais. En effet ce que nous voulons est de se donner un (petit) intervalle  \( I\) autour de la bonne valeur de \( \theta\) et de maximiser \( P(\hat\theta_n\in I)\). Sur la figure \ref{LabelFigBiaisOuPas}, c'est l'estimateur biaisé rouge tombe plus souvent sur le bon intervalle que l'estimateur non biaisé bleu.
\newcommand{\CaptionFigBiaisOuPas}{Un estimateur sans biais et un avec biais.}
\input{Fig_BiaisOuPas.pstricks}

Nous allons maintenant étudier quelques manières de construire des estimateurs convergents. Il vont évidemment s'appuyer sur la loi des grands nombres.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Méthode des moments}
%---------------------------------------------------------------------------------------------------------------------------

Sans surprises, un bon estimateur pour la moyenne est
\begin{equation}
    \hat\theta_n(X_1,\ldots,X_n)=\frac{1}{ n }\sum_{i=1}^nX_i.
\end{equation}

Plus généralement, nous supposons qu'il existe une fonction borélienne\footnote{Définition \ref{DefHHIBooNrpQjs}.} \( M\colon \eR\to \eR\) telle que
\begin{equation}
    E_{\theta}\big( | M(X) | \big)<\infty
\end{equation}
où \( X\) est la loi parente de l'échantillon. Supposons également que la fonction 
\begin{equation}
    h(\theta)=E_{\theta}\big( M(X) \big)
\end{equation}
soit inversible et continue sur \( \Theta\). Dans ce cas, pour estimer le paramètre \( \theta\), nous considérons l'estimateur
\begin{equation}
    \hat\theta_n=h^{-1}\left( \frac{1}{ n }\sum_{i=1}^nM(X_i) \right).
\end{equation}
Cela est un estimateur convergent. En effet, la loi des grands nombres dit que
\begin{equation}
    \frac{1}{ n }\sum_iM(X_i)\stackrel{p.s.}{\longrightarrow}E_{\theta}\big( M(X) \big).
\end{equation}
En composant avec la fonction \( h\), nous avons
\begin{equation}
    \hat\theta_n\stackrel{p.s.}{\longrightarrow}h^{-1}\Big( E_{\theta}\big( M(X) \big) \Big)=\theta.
\end{equation}
Dans cette construction, \( M(X)\) est le moment de \( X\) que l'on souhaite déterminer.

\begin{example}
    Soit \( (X_1,\ldots,X_n)\) un échantillon de loi \( \dE(\lambda)\). Construire \( \hat\lambda_n\). Pour une loi exponentielle,
    \begin{equation}
        E(X)=\frac{1}{ \lambda }.
    \end{equation}
    Nous devons donc déterminer le moment d'ordre \( 1\) de \( X\) (c'est à dire sa moyenne). Nous considérons donc la fonction \( M(x)=x\); par conséquent
    \begin{equation}
        h(\lambda)=E(X)=\frac{1}{ \lambda }
    \end{equation}
    et \( h^{-1}(\theta)=1/\theta\). L'estimateur que nous considérons pour \( \lambda\) est finalement
    \begin{equation}
        \hat\theta_n=\frac{1}{ \frac{1}{ n }\sum_{i=1}^nX_i }.
    \end{equation}
\end{example}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Méthode de substitution}
%---------------------------------------------------------------------------------------------------------------------------

Supposons que nous connaissions un estimateur convergent \( \hat\theta_n\to\theta\). Si \( g\colon \eR^d\to \eR\) est une fonction continue, alors
\begin{equation}
    g(\hat\theta_n)\to g(\theta).
\end{equation}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Méthode du maximum de vraisemblance}
%---------------------------------------------------------------------------------------------------------------------------

\begin{example}     \label{ExVrasMaxLp}
    Nous désirons contrôler la qualité d'une chaîne de production; pour cela nous prélevons un échantillon de \( 10\) pièces, et nous en trouvons \( 3\) défectueuses. Que dire de la proportion de pièces défectueuses ?

    Évidemment, le plus probable est que la proportion de pièces défectueuses soit de \( 1/3\). Analysons en détail comment nous arrivons à ce résultat. Nous considérons que le fait de tirer \( 10\) pièces revient à une expérience binomiale de paramètres \( 10\) et de probabilité \( p\) inconnue. Dans ce cas, la probabilité d'observer exactement \( 3\) pièces défectueuses est de 
    \begin{equation}
        L(p)=P(X=3)={10\choose 3}p^3(1-p)^{7}.
    \end{equation}
    Le maximum de \( L(p)\) est \( p=3/10\).

    % \ref{LabelFigMaxVraissLp}.
    \newcommand{\CaptionFigMaxVraissLp}{La fonction de vraisemblance de l'exemple \ref{ExVrasMaxLp}.}
    \input{Fig_MaxVraissLp.pstricks}
\end{example}

Soit \( (x_1,\ldots,x_n)\), une réalisation de l'échantillon \( (X_1,\ldots,X_n)\). L'application
\begin{equation}
    \theta\mapsto p_n(x_1,\ldots,x_n;\theta)=\prod_{i=1}^np(x_i,\theta)
\end{equation}
est la \defe{vraisemblance}{vraisemblance} de l'échantillon. Nous définissons \( \hat\theta_n\) par
\begin{equation}
    p_n(x_1,\dots,x_n;\hat\theta_n)=\sup_{\theta\in\Theta}p_n(x_1,\ldots,x_n;\theta).
\end{equation}

\begin{remark}
    Nous passons sous le silence le fait que la fonction \( \sup\) soit une fonction mesurable, et que par conséquent \( \hat\theta_n\) soit bien une variable aléatoire.
\end{remark}

La variable aléatoire \( \hat\theta_n=\hat\theta_n(X_1,\ldots,X_n)\) est l'\defe{estimateur de maximum de vraisemblance}{estimateur!maximum de vraisemblance} de \( \theta\).

\Exo{Model-0000}
\Exo{Model-0001}
\Exo{Model-0002}
\Exo{Model-0003}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Estimation d'une fonction de répartition}
%---------------------------------------------------------------------------------------------------------------------------

\begin{theorem}[Glivenko-Cantelli\cite{NXxxAgN}]  \label{ThoXAEMbTI}
    Soient \( X_i\) des variables aléatoires indépendantes et identiquement distribuées suivant une loi dont la fonction de distribution est \( F\) (inconnue). Nous définissons l'estimateur
    \begin{equation}    \label{EqMQNRVcT}
        F_n(x)=\frac{1}{ n }\sum_{i=1}^n\mtu_{X_i\leq x}.
    \end{equation}
    Alors
    \begin{equation}
        P\big( \lim_{n\to \infty} \| F_n-F \|_{\infty}=0 \big)=1.
    \end{equation}
    Autrement dit, pour presque tout \( \omega \in \Omega\),
    \begin{equation}
        \lim_{n\to \infty} \| F_n(\omega,.)-F \|_{\infty}=0.
    \end{equation}
    C'est à dire qu'il y a presque certainement convergence en probabilité.
\end{theorem}
\index{théorème!Glivenko-Cantelli}
\index{estimateur!de fonction de répartition}
Notons que de façon générale lorsqu'on parle d'estimateurs, partout où il y a un «n» dans une variable aléatoire, il y a une dépendance sous-entendue en \( \omega\).

\begin{proposition} \label{PropHSHFbEq}
    Pour presque tout \( x\), l'estimateur \( F_n(x)\) est sans biais par rapport à \( F(x)\) :
    \begin{equation}
        E\big( F_n(x) \big)=F(x).
    \end{equation}
\end{proposition}

\begin{proof}
    C'est juste un calcul :
    \begin{equation}
        E\big( F_n(x) \big)=\frac{1}{ n }\sum_{i=1}^nE\big( \mtu_{\{ X_i\leq x \}} \big)=\frac{1}{n }\sum_{i=1}^nF(x)=F(x).
    \end{equation}
\end{proof}

\Exo{Model-0004}
\Exo{Model-0005}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Espérance et variance d'un estimateur}
%---------------------------------------------------------------------------------------------------------------------------

Soit \( T_n=T_(X_1,\ldots,X_n)\) un estimateur du paramètre \( \theta\) dans un modèle d'échantillonnage. Les moyennes et variances de l'estimateur sont les variables aléatoires
\begin{subequations}
    \begin{align}
        m_{\theta,n}&=E_{\theta}(T_n)=\int_{\eR^n}T_n(x_1,\ldots,x_n)d\mu_{\theta}^{\otimes n}(x1,\ldots,x_n),\\
        \Var_{\theta}(T_n)&=\int_{\eR^n}[T_n(x_1,\ldots,x_n)-m_{\theta,n}]^2d\mu_{\theta}^{\otimes n}(x1,\ldots,x_n),
    \end{align}
\end{subequations}

\begin{lemma}
    Si l'estimateur \( T_n\) satisfait
    \begin{subequations}
        \begin{align}
            \lim_{n\to \infty} E_{\theta}(T_n)&=\theta\\
            \lim_{n\to \infty} \Var_{\theta}(T_n)&=0,
        \end{align}
    \end{subequations}
    alors il est convergent.
\end{lemma}

\begin{proof}
    Nous utilisons l'inégalité de Markov (théorème \ref{ThoInegMarkov}) et nous introduisons l'espérance de l'estimateur :
    \begin{subequations}
        \begin{align}
            P\big( | T_n(X_1,\ldots ,X_n)-\theta |>\epsilon \big)&\leq\frac{1}{ \epsilon }E\big( T_n(X_1,\ldots,X_n)-\theta \big)\\
            &\leq \frac{1}{ \epsilon }E\big( | T_n-m_{n,\theta} | \big)+\frac{1}{ \epsilon }E\big(| m_{n,\theta}-\theta |\big)\\
        \end{align}
    \end{subequations}
    Le second terme est l'espérance d'une constante. Nous majorons le premier terme en utilisant le fait que \( \| . \|_1\leq\| . \|_2\) (voir la remarque \ref{RemNormuptNird} après l'inégalité de Hölder):
    \begin{subequations}
        \begin{align}
            P\big( | T_n(X_1,\ldots ,X_n)-\theta |>\epsilon \big)&\leq \frac{1}{ \epsilon }E\big( | T_n-m_{n,\theta} |^2 \big)^{1/2}+\frac{1}{ \epsilon }| E_{\theta}(T_n)-\theta |\\
            &=\frac{1}{ \epsilon }\Var(T_n)^{1/2}+\frac{1}{ \epsilon }| E_{\theta}(T_n)-\theta |.
        \end{align}
    \end{subequations}
    Les deux termes tendent séparément vers zéro par hypothèse. Nous avons par conséquent la convergence en probabilité \( T_n\to \theta\).
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Estimation par intervalle de confiance}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Nous voudrions estimer la proportion d'individus dans une population ayant un certain caractère déterminé par une variable booléenne : chaque individu a ou non le caractère étudié. L'échantillon sera donc une suite de \( 0\) et de \( 1\).

Pour tout \( i\in\{ 1,\ldots, n \}\) nous notons
\begin{equation}
    x_i=\begin{cases}
        1    &   \text{si le \( i\)ème individu a la caractère}\\
        0    &    \text{sinon}.
    \end{cases}
\end{equation}
et \( \bar x_n=\frac{1}{ n }\sum_{i=1}^n x_i\). Notre modèle statistique sera
\begin{equation}
    \statS=\Big[ (\Omega,\tribF,P),(X_{\theta}),B(1,\theta) \Big]
\end{equation}
où \( \Omega\) est l'ensemble des individus étudiés, \( P\) est la manière de choisir les individus lors du sondage (essentiellement c'est une loi uniforme) et \( X_{\theta}\) est la variable aléatoire
\begin{equation}
    X(\omega)=\begin{cases}
        1    &   \text{si \( \omega\) a le caractère}\\
        0    &    \text{sinon}
    \end{cases}
\end{equation}
Cela est une variable aléatoire de distribution \( \dB(1,p)\) où \( p\) est inconnu. Ici, \( \Theta=\mathopen[ 0 , 1 \mathclose]\) est l'ensemble des \( p\) possibles.

\begin{remark}
    Nous supposons que \( \Omega\) est la population entière et que la variable aléatoire est l'opinion de la personne \( \omega\). En cela, nous considérons que le tirage de l'échantillon est sans remise. Le fait que nous modélisions par une variable aléatoire de Bernoulli signifie que nous considérons l'approximation dans laquelle la population globale est grande.
\end{remark}

Nous supposons que nous ayons un échantillon \( (X_1,\ldots,X_n)\) dont nous avons observé une réalisation \( (x_1,\ldots,x_n)\) de fréquence \( \bar x_n\). Nous voudrions déterminer un intervalle dans lequel \( \bar X_n\) a de fortes chances de se trouver. Plus précisément nous considérons un petit \( \alpha\) et nous cherchons \( \epsilon\) tel que
\begin{equation}
    P\big( p\in\mathopen[ \bar X_n-\epsilon , \bar X_n+\epsilon \mathclose] \big)=1-\alpha.
\end{equation}
Typiquement, \( \alpha=5\%\). Le nombre \( \alpha\) est le \defe{niveau de confiance}{niveau de confiance} que nous nous fixons a priori.

Si nous trouvons un intervalle \( I\) tel que \( P(p\in I)=1-\alpha\), nous disons que l'intervalle est \defe{exact}{exact!intervalle de confiance}, si nous avons \( P(p\in I)\geq 1-\alpha\), nous disons que l'intervalle est \defe{par excès}{excès!intervalle de confiance}.

Il y a deux points de départs pour trouver l'intervalle. Le plus simple est d'utiliser le théorème central limite et considérer
\begin{equation}
    \sqrt{n}\frac{ \bar X_n-p }{ \sqrt{p(1-p)} }\stackrel{\hL}{\longrightarrow}\dN(0,1).
\end{equation}
La seconde est d'utiliser la loi exacte : \( n\bar X_n=\sum_i X_i\sim \dB(n,p)\).

Bien entendu la seconde donne lieu à des calculs plus compliquée.

\begin{remark}
    Dans certaines vraies vies (par exemple en médecine), la taille des échantillons est très réduite. Dans ce cas le théorème central limite n'a aucun sens et les calculs exact s'imposent.

    De plus dans de nombreux cas de la vraie vie, nous avons un ordinateur à disposition pour calculer avec la loi exacte. L'utilisation du théorème central limite dans le but de produire un intervalle de confiance semble donc de plus en plus être une survivance du passé.
\end{remark}

Dans la suite, nous allons supposer que \( n\) est suffisamment grand pour justifier l'approximation normale du théorème central limite \ref{ThoOWodAi}. Si \( Z\) est une variable aléatoire normale centrée réduite, notre premier essai est de faire
\begin{subequations}
    \begin{align}
        1-\alpha&=P\big( p\in\mathopen[ \bar X_n-\epsilon , \bar X_n+\epsilon \mathclose] \big) \label{subEqumaleftLthe}\\
        &=P\left( \frac{ -\epsilon\sqrt{n} }{ \sqrt{p(1-p)} }\leq \sqrt{n}\frac{ \bar X_n-p }{ \sqrt{p(1-p)} }\leq \frac{ \epsilon\sqrt{n} }{ \sqrt{p(1-p)} } \right)\\
        &\simeq P\left( -\frac{ \epsilon\sqrt{n} }{ \sqrt{p(1-p)} }\leq Z\leq \frac{ \epsilon\sqrt{n} }{ \sqrt{p(1-p)} } \right)\\
        &=2P\left( Z\leq \frac{ \epsilon\sqrt{n} }{ \sqrt{p(1-p)} } \right)-1.
    \end{align}
\end{subequations}
La dernière ligne utilise la symétrie de la distribution \( \dN(0,1)\). Le nombre \( \epsilon\) que nous cherchons vérifie donc
\begin{equation}
    P\left( Z\leq \frac{ \epsilon\sqrt{n} }{ \sqrt{p(1-p)} } \right)=1-\frac{ \alpha }{2}.
\end{equation}
De nos jours, les ordinateur donnent la loi de répartition inverse des normales. Cela nous fournit un nombre \( t_{\alpha}\) tel que
\begin{equation}    \label{Eqepsnqsrtpptalpah}
    \frac{ \epsilon\sqrt{n} }{ \sqrt{p(1-p)} }=t_{\alpha}
\end{equation}
où \( t_{\alpha}\) est le nombre tel que \( P(Z\leq t_{\alpha})=1-\alpha/2\). 

Conclusions de ce premier essai :
\begin{enumerate}
    \item

Le problème est que nous ne pouvons pas déduire \( \epsilon\) de l'équation \eqref{Eqepsnqsrtpptalpah} parce que \( p\) est inconnu.

\item
Cela ruine notre premier essai et nous demande de trouver mieux.

\item
L'astuce est évidemment de remplacer \( p\) par \( \bar X_n\), mais il faut le justifier. 
        
\end{enumerate}

\begin{description}

    \item[Méthode Slutsky]

        Le point de départ du premier essai infructueux était la convergence
        \begin{equation}
            \sqrt{n}\frac{ \bar X_n-p }{ \sqrt{p(1-p)} }\stackrel{\hL}{\to}N\sim\dN(0,1)
        \end{equation}
        donnée par le théorème central limite \ref{ThoOWodAi}. Ce que nous voudrions en réalité est la convergence
        \begin{equation}
            \sqrt{n}\frac{ \bar X_n-p }{ \sqrt{  \bar X_n(1-\bar X_n) } }\stackrel{\hL}{\to}N
        \end{equation}
        La loi des grands nombres nous donne
        \begin{equation}
            \bar X_n(1-\bar X_n)\stackrel{p.s.}{\longrightarrow}p(1-p).
        \end{equation}
        Par conséquent le lemme de Slutsky implique la convergence en loi du couple :
        \begin{equation}    \label{EqGJxxjqs}
            \left( \sqrt{n}\frac{ \bar X_n-p }{ \sqrt{p(1-p)} },\sqrt{\bar X_n(1-\bar X_n)} \right)\stackrel{\hL}{\to}\big( N,\sqrt{p(1-p)} \big).
        \end{equation}
        À ce point des opérations nous pouvons utiliser la proposition \ref{PropcvLsousfonc} au couple avec la fonction
        \begin{equation}
            f(x,y)=\frac{ x }{ y }\sqrt{p(1-p)}
        \end{equation}
        dont la probabilité d'être continue est \( 1\) (\( y=0\) est de mesure nulle dans \( \eR^2\)). La conclusion du théorème est que
        \begin{equation}
            \sqrt{n}\frac{ \bar X_n-p }{ \sqrt{\bar X_n(1-\bar X_n)} }\stackrel{\hL}{\longrightarrow}\dN(0,1).
        \end{equation}
        
        C'est à partie de là que nous pouvons construire notre intervalle de confiance :
        \begin{subequations}
            \begin{align}
                1-\alpha&=P(\bar X_n-\epsilon\leq p\leq \bar X_n+\epsilon)\\
                &=P\left( \frac{ \sqrt{n}\epsilon }{ \sqrt{\bar X_n(1-\bar X_n)} }\geq   \sqrt{n}\frac{ \bar X_n-p }{ \sqrt{\bar X_n(1-\bar X_n)} }   \geq   \frac{ -\sqrt{n}\epsilon }{ \sqrt{\bar X_n(1-\bar X_n)} } \right))\\
                &\simeq P\left( \frac{ \sqrt{n}\epsilon }{ \sqrt{\bar X_n(1-\bar X_n)} }\geq N\geq   \frac{ -\sqrt{n}\epsilon }{ \sqrt{\bar X_n(1-\bar X_n)} } \right)).
            \end{align}
        \end{subequations}
        Nous cherchons maintenant dans les tables le \( \xi\) qui fait
        \begin{equation}
            P(-\xi\leq N\leq \xi)=1-\alpha
        \end{equation}
        puis nous cherchons \( \epsilon\) de telle sorte à avoir
        \begin{equation}
            \frac{ \sqrt{n}\epsilon }{ \sqrt{\bar X_n(1-\bar X_n)} }=\xi.
        \end{equation}
        Dans cette équation tout est connu à part le \( \epsilon\) qui se découvre.

    \item[Méthode piétonne] 

        Nous remarquons que l'événement 
\begin{equation}
    -\frac{ \epsilon\sqrt{n} }{ \sqrt{p(1-p)} }\leq \sqrt{n}\frac{ \bar X_n-p }{ \sqrt{p(1-p)} }\leq \frac{ \epsilon\sqrt{n} }{ \sqrt{p(1-p)} }
\end{equation}
est le même que l'événement
\begin{equation}
    \left| \sqrt{n}\frac{ \bar X_n-p }{ \sqrt{p(1-p)} } \right| \leq t_{\alpha}.
\end{equation}
Vu que \( t_{\alpha}\) est positif, cela est encore le même événement que
\begin{equation}
    n\frac{ (\bar X_n-p)^2 }{ p(1-p) }\leq t_{\alpha}^2
\end{equation}
ou encore
\begin{equation}
    p^2(n+t_{\alpha}^2)-p(2n\bar X_n+t_{\alpha}^2)+n\bar X_n^2\leq 0.
\end{equation}
Les racines du polynôme du membre de gauche sont
\begin{equation}
    p_{\pm}=\frac{ 2n\bar X_n+t_{\alpha}^2\pm\sqrt{ (2n\bar X_n+t_{\alpha})^2-4(n+t_{\alpha}^2)n\bar X_n^2  } }{ 2(n+t_{\alpha}^2) }.
\end{equation}
Le but étant d'effectuer une limite \( n\to\infty\), nous factorisons d'abord \( n\). Après simplification
\begin{equation}
    p_{\pm}=\frac{ \bar X_n+\frac{ t_{\alpha} }{ 2n }\pm t_{\alpha}\sqrt{\frac{ t_{\alpha}^2 }{ 4n^2 }+\frac{ \bar X_n(1-\bar X_n) }{ n }} }{ 1+\frac{ t_{\alpha} }{ n } }.
\end{equation}
Étant donné que nous considérons que \( n\) est grand, nous allons négliger les termes en \( \frac{1}{ n }\) en faisant attention à ce que le terme en $\frac{1}{ n }$ sous la racine est en réalité \( 1/\sqrt{n}\) et ne doit pas être négligé. Nous trouvons, à cette approximation, que
\begin{equation}
    p\in\mathopen\Big[  \bar X_n-t_{\alpha}\sqrt{\frac{ \bar X_n(1-\bar X_n) }{ n }}  , \bar X_n+t_{\alpha}\sqrt{\frac{ \bar X_n(1-\bar X_n) }{ n }} \mathclose\Big]
\end{equation}
avec une probabilité \( 1-\alpha\).

\end{description}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Région de confiance}
%---------------------------------------------------------------------------------------------------------------------------

Soit un \( n\)-échantillon \( (X_1,\ldots,X_n)\) de loi parente \( \mu_{\theta}\). Nous supposons \( \Theta\subset\eR\) avec \( \Theta\) ouvert. Soit \( \alpha\in\mathopen[ 0 , 1 \mathclose]\) un intervalle de confiance et une application mesurable
\begin{equation}
    \begin{aligned}
        \Lambda\colon \eR^n&\to \Borelien(\Theta) \\
        (x_1,\ldots,x_n)&\mapsto \Lambda(x_1,\ldots,x_n).
    \end{aligned}
\end{equation}
On appelle \defe{région de confiance exact}{région!de confiance exact} au niveau de confiance \( 1-\alpha\) une région aléatoire \( \Lambda(x_1,\ldots,x_n)\) telle que
\begin{equation}
    P\big( \theta\in\Lambda(x_1,\ldots,x_n) \big)=1-\alpha.
\end{equation}
Si \( d=1\), la région \( \Lambda(x_1,\ldots,x_n)\) est un intervalle.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Fonction pivotale}
%---------------------------------------------------------------------------------------------------------------------------

Soit \( \hat\theta_n\), un estimateur de \( \theta\). Une fonction \( v\) sur \( \Theta\times\Theta\) est \defe{pivotale}{pivotale} pour \( \theta\) si la loi de la variable aléatoire \( v(\hat\theta_n,\theta)\) ne dépend pas de \( \theta\). Elle est \defe{asymptotiquement pivotale}{asymptotiquement pivotale} si
\begin{equation}
    v(\hat\theta_n,\theta)\stackrel{\hL}{\longrightarrow}\xi
\end{equation}
où \( \xi\) est une variable aléatoire indépendante de \( \theta\).

En pratique, nous essayons de faire apparaître une variable aléatoire de loi connue qui ne dépend pas du paramètre que l'on recherche. Si la variance est connue et si l'échantillon est grand, le théorème central limite nous permet d'introduire une loi normale centrée réduite.

\begin{example}
    Soit \( X_1,\ldots,X_n\) des variables aléatoires de loi parente \( \dN(m,\sigma^2)\). Une fonction asymptotiquement pivotale pour \( m\) est
    \begin{equation}
        v(z_1,z_2)=\frac{ z_1-z_2 }{ \sigma/\sqrt{n} }
    \end{equation}
    parce que la variable aléatoire
    \begin{equation}
        v(\bar X_n,m)=\frac{ \bar X_n-m }{ \alpha/\sqrt{n} }
    \end{equation}
    tend vers \( \dN(0,1)\) qui ne dépend pas de \( m\).
\end{example}

\begin{example}
    Si \( (X_n)\) est une suite de variables aléatoires indépendantes et identiquement distribuées de moyenne \( m\) et d'écart type \( \sigma\) que nous supposons inconnus. Le fonction suivante est asymptotiquement pivotale pour \( m\) :
    \begin{equation}
        v(\bar X_n,m)=\frac{ \bar X_n-m }{ \sigma/\sqrt{n} }.
    \end{equation}
\end{example}

Soit \( (X_1,\ldots,X_n)\) un échantillon de loi \( \dN(m,\sigma_0^2)\) avec \( \sigma_0^2\) connu. Nous cherchons un intervalle de confiance \( 1-\alpha\) pour \( m\). Pour cela nous allons utiliser une fonction asymptotiquement pivotale, à savoir
\begin{equation}
    \frac{ \bar X_n-m }{ \sigma_0^2/\sqrt{n} }\sim\dN(0,1).
\end{equation}
Nous devrions chercher des valeurs \( z_+\) de \( z_-\) telles que
\begin{equation}
    P\left( z_-\leq \frac{ \bar X_n-m }{ \sigma_0/\sqrt{n} }\leq z_+ \right)=1-\alpha.
\end{equation}
Pour des raisons de symétries (de la courbe gaussienne), nous allons chercher un intervalle symétrique : \( z_-=-z_+\). Le nombre à chercher est donc le \( z_{\alpha}\) tel que 
\begin{equation}
    P\big( | Z |\leq z_{\alpha} \big)=1-\alpha.
\end{equation}
Si nous demandons \( \alpha=5\%\), la réponse est \( z_{\alpha}=1.96\), c'est à dire que
\begin{equation}
    P\left( -1.96\leq \frac{ \bar X_n-m }{ \sigma/\sqrt{n} }\leq 1.96 \right)=0.95.
\end{equation}
Nous avons donc
\begin{equation}
    P\left( m\in\big[ \bar X_n-\frac{ 1.96\sigma }{ \sqrt{n} },\bar X_n+\frac{ 1.96\sigma }{ \sqrt{n} } \big] \right)=0.95.
\end{equation}

Supposons maintenant que nous avons observé \( 100\) valeurs numériques avec \( \bar x_n=12\) et \( \sigma=1\). La réalisation de l'intervalle de confiance pour \( m\) au niveau de confiance \( 0.95\) est :
\begin{equation}
    \big[ 12-0.196,12+0.196 \big].
\end{equation}
Cet intervalle est à interpréter de la façon suivante : si nous recommençons un grand nombre de fois le sondage, la moyenne tombera \( 95\%\) des fois dans l'intervalle ainsi calculé. Mais il faut bien comprendre que la probabilité
\begin{equation}
    P\left( m\in\big[ 12-0.196,12+0.196 \big] \right)
\end{equation}
vaut zéro ou un.

\Exo{Model-0006}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Sondage de proportion}
%---------------------------------------------------------------------------------------------------------------------------

Une utilisation classique des statistiques est d'interpréter une proportion donnée par un sondage. Nous considérons une élection avec deux candidats \( A\) et \( B\). Nous avons interrogés \( n=2500\) personnes et nous avons obtenus \( 51\%\) pour le candidat \( A\) et \( 49\%\) pour le candidat \( B\). Que peut on dire ?

La modélisation de cette situation est que nous avons des variables aléatoires \( X_i\sim\dB(p_A)\) et que nous en avons observés \( n\) avec une moyenne
\begin{equation}
    \bar x_n=0.51.
\end{equation}
La loi de \( \bar X_n\) est une binomiale. Sa densité n'est pas symétrique, mais si \( n\) est grand, elle le devient. Nous cherchons un intervalle 
\begin{equation}
    I=[\bar X_n-\epsilon,\bar X_n+\epsilon]
\end{equation}
tel que \( P(p_A\in I)=1-\alpha\). Pour cela nous considérons le fait que \( n=2500\) est grand et nous utilisons la limite de la proposition \ref{PropLimxBNpxbxbsqrt} :
\begin{equation}
    Z_n=\sqrt{n}\frac{ \bar X_n-p_A }{ \sqrt{\bar X_n(1-\bar X_n)} }\stackrel{\hL}{\longrightarrow}Z\sim\dN(0,1).
\end{equation}
La variable aléatoire \( Z_n\) est asymptotiquement pivotale et normale centrée réduite. Nous cherchons donc un intervalle symétrique pour \( \bar X_n-p_A\) :
\begin{equation}
    1-\alpha=P(-\epsilon\leq \bar X_n-p_A\leq \epsilon),
\end{equation}
c'est à dire, si \( n\) est grand, 
\begin{equation}
    1-\alpha=P\left( -\epsilon\frac{ \sqrt{n} }{ \sqrt{\bar X_n(1-\bar X_n)} }\leq Z_n\leq\epsilon\frac{ \sqrt{n} }{ \sqrt{\bar X_n(1-\bar X_n)} } \right)
\end{equation}
où \( Z_n\) est une normale centrée réduite. Nous trouvons ainsi, via les tables que
\begin{equation}
    \frac{ \epsilon\sqrt{n} }{ \sqrt{\bar X_n(1-\bar X_n)} }=1.96
\end{equation}
si nous voulons un intervalle à \( 5\%\). Par conséquent nous avons \( \epsilon=1.96\frac{ \sqrt{\bar X_n(1-\bar X_n)} }{ \sqrt{nj} }\) et l'intervalle de confiance est 
\begin{equation}
    I_C=\left[ \bar X_n-\frac{ 1.96\sqrt{\bar X_n(1-\bar X_n)} }{ \sqrt{n} },\bar X_n+\frac{ 2.96\sqrt{\bar X_n(1-\bar X_n)} }{ \sqrt{n} } \right].
\end{equation}
La propriété de cet intervalle est que
\begin{equation}
    \lim_{n\to \infty} P(p_A\in I_c)=1-\alpha.
\end{equation}

\begin{remark}
    À quel moment avons nous fait une hypothèse sur la taille de la population globale ? En modélisant les sondés par des variables de Bernoulli et leur somme par une binomiale, nous supposons que le sondage est \emph{avec remise}, sinon, elles ne seraient pas indépendantes. En supposant les sondés indépendants, nous avons donc fait comme si la population totale était infinie.
\end{remark}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Estimer une densité lorsqu'on ne sait rien}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Nous supposons avoir une série d'observations issues d'un processus complexe dont nous n'avons aucune idée de la loi parente, et nous voudrions nous faire une idée de la densité de cette loi inconnue.

Nous observons une suite de réalisations que nous modélisons comme étant des variables aléatoires \( (X_1,\ldots, X_n)\) de loi parente (inconnue) \( \mu\). Notre but est de trouver un estimateur \( \hat \mu\) de \( \mu\). Par simplicité nous allons nous restreindre aux lois admettant une densité par rapport à la mesure de Lebesgue. C'est à dire que nous allons estimer \( \mu\) par une suite de lois \( \hat \mu_n\) qui sont toutes des lois acceptant une densité par rapport à la mesure de Lebesgue.

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Distance entre des mesures}
%---------------------------------------------------------------------------------------------------------------------------

Si \( \nu_1\) et \( \nu_2\) sont deux mesures de densité sur \( \eR\), la \defe{distance}{distance!entre deux mesures de probabilités} entre \( \nu_1\) et \( \nu_2\) est définie par
\begin{equation}
    d(\nu_1,\nu_2)=\sup_{A\in\Borelien(\eR)}\big| \nu_1(A)-\nu_2(A) \big|    
\end{equation}
où \( \Borelien(\eR)\) désigne l'ensemble des boréliens de \( \eR\).

\begin{theorem}[de Scheffé\cite{ABrKyxY}]
    Si \( f_1\) et \( f_2\) sont les densités de \( \nu_1\) et \( \nu_2\) par rapport à la mesure de Lebesgue, alors
    \begin{equation}
        d(\nu_1,\nu_2)=\int_{\eR}(f_1-f_2)_+=\frac{ 1 }{2}\int_{\eR}| f_1-f_2 |=\frac{ 1 }{2}\| f_1-f_2 \|_1
    \end{equation}
    où \( f_+\) est la partie positive de \( f\) (pour la décomposition \( f(x)=f_+(x)-f_-(x)\)).
\end{theorem}

\begin{proof}
    La dernière égalité est simplement une notation usuelle; nous devons seulement prouver les deux premières. Pour la première nous commençons par prouver que le borélien réalisant le supremum est
    \begin{equation}
        B=\{ x\in\eR\tq f_1(x)\geq f_2(x) \}.
    \end{equation}
    En effet si \( A\) est un borélien nous avons
    \begin{equation}
        \nu_1(A)-\nu_2(A)=\int_Af_1-f_2
        \leq\int_{A\cap B}f_1-f_2
        \leq\int_Bf_1-f_2
        =\int_B(f_2-f_2)_+
        =\int_{\eR}(f_1-f_2)_+
    \end{equation}
    Justifications :
    \begin{itemize}
        \item  \( f_1-f_2\) négative sur \( A\cap \complement B\).
        \item Vu que \( f_1-f_2\geq0\) sur \( B\), l'intégrale augmente si on augmente le domaine.
        \item Sur \( B\) nous avons \( f_1-f_2=(f_1-f_2)_+\).
    \end{itemize}
    Donc pour tout borélien \( A\) nous avons
    \begin{equation}
        d(\nu_1,\nu_2)\leq \int_{\eR}(f_1-f_2)_+.
    \end{equation}
    Mais pour \( A=B\) nous avons égalité :
    \begin{equation}
        \nu_1(B)-\nu_2(B)=\int_{B}f_1-f_2=\int_B(f_1-f_2)_+=\int_{\eR}(f_1-f_2).
    \end{equation}
    
    Pour la seconde égalité nous savons que \( f_1\) et \( f_2\) s'intègrent toutes deux à \( 1\) (parce que ce sont des densités de probabilité), donc
    \begin{equation}
        \int_{\eR}f_1-f_2=0.
    \end{equation}
    En particulier nous avons
    \begin{equation}
        \int_{\eR}(f_1-f_2)_+=\int_{\eR}(f_1-f_2)_-,
    \end{equation}
    ce qui donne bien
    \begin{equation}
        \int_{\eR}(f_1-f_2)_+=\frac{ 1 }{2}\int_{\eR}|f_1-f_2|.
    \end{equation}
\end{proof}

%--------------------------------------------------------------------------------------------------------------------------- 
\subsection{Estimateur par fenêtres glissantes}
%---------------------------------------------------------------------------------------------------------------------------

Nous considérons les estimations suivantes de la fonction de répartition :
\begin{equation}
    F_n(x)=\frac{1}{ n }\sum_{i=1}^n\mtu_{\{ X_i\leq x \}},
\end{equation}
et un nombre \( h_n\) qui sera la taille de la fenêtre glissante. Nous avons en tête de faire \( \lim_{n\to \infty} h_n=0\). Nous considérons ceci comme estimateur de la densité inconnue \( f\) des variables aléatoires \( X_i\) :
\begin{equation}
    \hat f_n(x)=\frac{ F_n(x+h_n)-F_n(x-h_n) }{ 2h_n }.
\end{equation}
L'idée sous-jacente est de prendre la dérivée de la fonction de répartition comme densité.

\begin{lemma}[\cite{ABrKyxY}]
    Pour tout \( h_n>0\), l'estimateur \( \hat f_n\) est une densité de probabilité.
\end{lemma}

\begin{proof}
    D'abord \( \hat f_n\) est bien à valeurs positives ou nulle. Ensuite devons parler de son intégrale. Pour le numérateur nous avons
    \begin{equation}
        F_n(x+h_n)-F_n(x-h_n)=\frac{1}{ n }\sum_{i=1}^{n}\mtu_{X_i\in B(x,h_n)}.
    \end{equation}
    En réalité cette égalité est valable seulement presque partout parce qu'elle n'est pas valable en \( x=x\pm h_n\), mais cela ne va pas nous ennuyer dans la mesure où nous avons dans l'idée d'intégrer cela sur \( \eR\). Avant de nous lancer dans l'intégrale nous remarquons que \( X_i\in B(x,h_n)\) est la même chose que \( x\in B(X_i,h_n)\), c'est à dire que
    \begin{equation}
        \{ X_i\in B(x,h_n) \}=\{ x\in B(X_i,h_n) \}.
    \end{equation}
    Donc
    \begin{equation}
        \int_{\eR}\hat f_n=\frac{1}{ 2h_n }\frac{1}{ n }\sum_{i=1}^n\underbrace{\int_{\eR}\mtu_{B(X_i,h_n)}}_{2h_n}=\frac{1}{ 2nh_n }\sum_{i=1}^n2h_n=1.
    \end{equation}
\end{proof}

\begin{lemma}[\cite{ABrKyxY}]   \label{LemTZopXDd}
    L'estimateur \( \hat f_n\) est déjà pas mal parce que
    \begin{equation}
        \lim_{h_n\to 0} E\big( \hat f_n(x) \big)\to f(x)
    \end{equation}
    pour presque tout \( x\in \eR\).
\end{lemma}

\begin{proof}
    Nous commençons par nous rappeler le fait que \( F_n(x)\) est un estimateur sans biais de \( F(x)\) (proposition \ref{PropHSHFbEq}). Donc
    \begin{equation}    \label{EqJEjrfFd}
        E\big( \hat f_n(x) \big)=\frac{ F(x+h_n)-F(x-h_n) }{ 2h_n }.
    \end{equation}
    Nous devons prendre la limite de cela lorsque \( h_n\to 0\), c'est à dire considérer la dérivée de \( F\). Attention : rien ne dit que \( F\) soit dérivable, si ce n'est la proposition \ref{PropJLnPpaw} qui indique qu'elle est dérivable presque partout avec \( f\) comme dérivée.

    La limite \( h_n\to 0\) dans \eqref{EqJEjrfFd} nous donne donc bien presque partout
    \begin{equation}
        \lim_{h_n\to 0} E\big( \hat f_n(x) \big)=f(x).
    \end{equation}
\end{proof}

\begin{proposition}[\cite{ABrKyxY}]
    Si la suite \( (h_n)\) est telle que \( h_n\to 0\) et \( nh_n\to \infty\), alors pour presque tout \( x\in \eR\) nous avons les convergences
    \begin{equation}
        \hat f_n(x)\stackrel{L^2(P)}{\to}f(x)
    \end{equation}
    et
    \begin{equation}
        \hat f_n(x)\stackrel{P}{\to}f(x).
    \end{equation}
\end{proposition}

\begin{proof}
    Il faut d'abord comprendre ce que signifie la convergence \( L^2(P)\) pour presque tout \( x\). Pour cela il faut comprendre que \( \hat f_n(x)\) est en soi une variable aléatoire et est en réalité une fonction \( \omega\mapsto \hat f_n(x,\omega)\). Ce que nous allons montrer est que pour presque tout \( x\) (maintenant fixé), cette variable aléatoire converge vers une constante (par rapport à \( \omega\)) et que cette constante est \( f(x)\).

    La convergence \( X_n\stackrel{L^2(P)}{\to}X\) signifie \( E\big( | X_n-X |^2 \big)\to 0\), c'est à dire
    \begin{equation}
        \int_{\Omega}\big| X_n(\omega)-X(\omega) \big|^2dP(\omega)\to 0.
    \end{equation}
    En faisant une décomposition biais-variance nous devons donc étudier
    \begin{equation}
        E\Big[ \big( \hat f_n(x)-f(x) \big)^2 \Big]=E\big[ \hat f_n(x)-f(x) \big]^2+\Var\big( \hat f_n(x)-f(x) \big)
    \end{equation}
    Ici \( f(x)\) doit être vue comme la variable aléatoire constante sur \( \Omega\). Par le lemme \ref{LemTZopXDd} et la proposition \ref{PropZBnsCgh} le terme de biais converge vers zéro lorsque \( n\to \infty\).

    Pour traiter le terme de biais, nous savons déjà que
    \begin{equation}
        2nh_n\hat f_n(x)=\sum_{i=1}^n\mtu_{\{ X_i\in B(x,h_n) \}},
    \end{equation}
    où le membre de droite (et donc aussi celui de gauche) est est une variable aléatoire binomiale comptant le nombre de succès de l'expérience \( X_i\in B(x,h_n)\) en \( n\) essais. Nous notons \( p_{x,n}=P\big( X_i\in B(x,h_n) \big)\). Si \( \mu\) est la loi parente des \( X_i\), alors
    \begin{equation}    \label{EqKBKrSHJ}
        p_{n,x}=P\big( X_i\in B(x,h_n) \big)=\mu\big( B(x,h_n) \big)=F(x+h_n)-F(x-h_n)
    \end{equation}
    où \( F\) est la fonction de répartition (parente) des \( X_i\).
    
    Alors la variance de ladite binomiale est donnée par \eqref{EqKLubWlh}, c'est à dire \( np_{x,n}(1-p_{x,n})\). Nous avons alors
    \begin{equation}
         \Var\big( 2nh_n\hat f_n(x) \big)=bp_{x,n}(1-p_{x,n})
    \end{equation}
    et
    \begin{equation}
        \Var\big( \hat f_n(x) \big)=\frac{1}{ 4n^2h_n^2 }np_{x,n}(1-p_{x,n}).
    \end{equation}
    Nous pouvons faire la majoration \( t(1-t)\leq t\) qui est valable pour tout \( t\) et écrire
    \begin{equation}
        \Var(\hat f_n(x))\leq \frac{1}{ 4nh_n }\frac{ p_{x,n} }{ h_n }.
    \end{equation}
    Le premier facteur tend vers zéro parce que nous avons supposé que \( nh_n\to \infty\). Pour le second facteur, il faut remarquer que l'expression \eqref{EqKBKrSHJ} nous donne presque partout
    \begin{equation}
        \lim_{h_n\to 0} \frac{ p_{n,x} }{ h_n }=2f(x),
    \end{equation}
    qui est constant et certainement borné.

    Nous avons maintenant prouvé que pour presque tout \( x\) nous avons \( \hat f_n(x)\stackrel{L^2(P)}{\to}f(x)\). Montrons que cela implique la convergence en loi, c'est à dire que pour tout \( \eta>0\), nous avons la limite
    \begin{equation}
        P\big( | \hat f_n(x)-f(x) |>\eta \big)\to 0.
    \end{equation}
    Si cela n'était pas vrai, nous aurions un nombre \( \eta_0>0\) et \( \epsilon>0\) tel que pour tout \( n\) à partir d'une certaine taille,
    \begin{equation}
        P\Big( | \hat f_n(x)-f(x) |^2>\eta_0 \Big)>\epsilon,
    \end{equation}
    et en particulier en notant \( A\) l'événement \( | \hat f_n(x)-f(x) |^2>\eta_0^2\), \( P(A)>\epsilon\). Alors 
    \begin{equation}
        \int_{\Omega}\big| \hat f_n(x,\omega)-f(x,\omega) \big|^2dP(\omega)\geq \int_A\big| \hat f_n(x,\omega)-f(x,\omega) \big|^2dP(\omega)\geq\int_A\eta_0^2=\eta_0^2P(A).
    \end{equation}
    Cela signifie que
    \begin{equation}
        \| \hat f_n(x)-f(x) \|_{L^2(P)}\geq \eta_0P(A),
    \end{equation}
    ce qui contredit la première convergence démontrée.
\end{proof}
Note : l'hypothèse \( nh_n\to\infty\) revient à dire que nous voulons que chaque boîte contienne de plus en plus d'observations. Si nous avions \( nh_n\to 0\), alors avec \( n\) qui augmente, la majorité des boîtes deviendraient vides, ce qui reviendrait à une perte d'information.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Test d'hypothèses, prise de décision}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Exemple : qualité des pièces d'usine}
%---------------------------------------------------------------------------------------------------------------------------

Une usine fabrique des composantes électronique garantis un an. Le constructeur ne veut pas accepter que plus de \( 5\%\) des pièces tombent en panne avant un an.

Nous supposons que la durée de vie \( T\) d'une pièce soit une variable aléatoire suivant une loi exponentielle de paramètre \( \lambda\) (qui est l'inverse de la moyenne : \( \theta=1/\lambda\)). Le fabriquant veut donc s'assurer que
\begin{equation}
    0.95\leq P(T\geq 1),
\end{equation}
ou encore
\begin{equation}
    P(T\geq 1)=\int_0^{\infty}\frac{1}{ \theta } e^{-x/\theta}dx= e^{-1/\theta}\geq 0.95,
\end{equation}
donc le fabriquant doit s'assurer que
\begin{equation}
    \theta\geq\frac{1}{ \ln\left( \frac{1}{ 0.95 } \right) }.
\end{equation}
Nous posons donc \( \theta_0=19.5\) et nous prenons comme modèle de décision que si \( \theta<\theta_0\), alors la chaîne de production doit être revue, et si \( \theta>\theta_0\), alors l'usine peut continuer son travail.

Ce dont nous disposons n'est pas de \( \theta\), mais d'une estimation de \( \theta\) à partir d'un échantillon. Cela étant il faudra aussi pouvoir estimer la probabilité de faire un mauvais choix.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Exemple : la résistance d'un fil}
%---------------------------------------------------------------------------------------------------------------------------
\label{subsecExempLFilResituzz}

Un artisan a besoin d'un fil qui a une résistance à une traction de \( \unit{100}{\gram}\) en moyenne. Si la résistance est trop faible, le fil casse; si elle est trop grande, c'est trop rigide et ça ne convient pas.

\begin{remark}
    Dans l'exemple précédent, avoir \( \theta>\theta_0\) ne dérange pas. Si la durée de vie moyenne est de \( 2\) ans, le directeur de l'usine ne sera pas malheureux. Ici par contre l'artisan cherche une valeur précise et a donc une borne vers le haut et vers le bas.
\end{remark}

L'artisan reçoit un lot de fils et souhaite savoir si il est conforme. Pour cela, il prend \( 4\) fils au hasard et mesure une moyenne de \( \unit{112}{\gram}\). Est-ce que cela est cohérent avec une moyenne de \( \unit{100}{\gram}\) ?

Nous faisons l'hypothèse que ma résistance des fils suit une loi normale \( \dN(m,\sigma^2)\) avec \( m\) inconnu. Pour la simplicité nous supposons que \( \sigma\) est connu et vaut \( 10\).

Nous devons prendre une décision entre deux hypothèses. L'hypothèse \( H_0\) sera de dire que le lot a une résistance de \( \unit{100}{\gram}\) et l'hypothèse alternative sera que le lot a une résistance différente.

Les \( 4\) observations sont quatre variables aléatoires \( (X_i)_{i=1,2,3,4}\), et le nombre \( 112\) est une réalisation de la variable aléatoire
\begin{equation}
    \bar X_4=\frac{1}{ 4 }(X_1+X_2+X_3+X_4).
\end{equation}

Nous supposons que \( H_0\) est vraie, et nous calculons quelle est l'intervalle autour de \( m=100\) qui a \( 95\%\) de chances de contenir la moyenne observée. Si \( 112\) est dedans, nous acceptons \( H_0\) et si \( 112\) est hors de cet intervalle, nous refusons \( H_0\).

Compte tenue de l'hypothèse \( H_0\), nous avons
\begin{equation}
    \frac{ \bar X_4-100 }{ \frac{ 10 }{ \sqrt{4} } }=\frac{ \bar X_4-100 }{ 5 }\sim\dN(0,1).
\end{equation}
Nous commençons à connaître par cœur l'intervalle de confiance à \( 95\%\) d'une loi normale centrée réduite; le quantile est à \( 1.96\), c'est à dire
\begin{equation}
    P\left( -1.96\leq\frac{ \bar X_4-100 }{ 5 }\leq 1.96 \right)=0.95,
\end{equation}
ou encore
\begin{equation}
    P\big( \bar X_4\in\mathopen[ 90.2 , 109.8 \mathclose] \big).
\end{equation}
Il y a donc moins de \( 5\%\) de chances que la moyenne de ces quatre fils tombent en dehors de l'intervalle \( \mathopen[ 90.2 , 109.8 \mathclose]\). L'artisan doit donc rejeter l'hypothèse et considérer que le lot est mauvais.

La région
\begin{equation}
    \mathopen] -\infty , 90.2 \mathclose]\cup\mathopen[ 109.8 , \infty [
\end{equation}
est la \defe{région de rejet}{rejet!région dans une prise de décision}, ou \defe{région critique}{critique!région}.

Ici, le nombre \( 5\%\) représente le risque de refuser \( H_0\) alors qu'elle était vraie. Notons que nous ne pouvons pas calculer le risque d'accepter \( H_0\) alors qu'elle est fausse. En effet, si \( H_0\) est fausse, nous ne savons pas quelles sont les valeurs de \( \bar X_4\) acceptables parce qu'il y a une infinité de possibilités pour \( m\) qui soient alternatifs à \( m=100\).

Évidemment si la vraie moyenne est \( 100+10^{-7}\), l'hypothèse \( H_0\) sera acceptée, mais nous n'avons aucun moyen de savoir si elle est vraie ou non.

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Vocabulaire et théorie}
%---------------------------------------------------------------------------------------------------------------------------

Nous avons un modèle d'échantillonnage paramétrique \(  (X_{\theta,1},\ldots,X_{\theta,n})  \) de taille \( n\) et de paramètre inconnu \( \theta\), de loi parente \( \mu_{\theta}\) appartenant à une famille paramétrique de lois \( (\mu_{\theta})_{\theta\in\Theta}\).

Soient \( H_0\) et \( H_1\) deux ensembles disjoints tels que \( \Theta=H_0\cup H_1\). L'ensemble \( H_0\) sera nommé \defe{hypothèse nulle}{hypothèse!nulle} et l'ensemble \( H_1\) sera l'\defe{hypothèse alternative}{hypothèse!alternative}. 

Pour l'exemple des fils, nous avions \( H_0=\{ 100 \}\) et \( H_1=\eR\setminus\{ 100 \}\). Si une hypothèse est réduite à un singleton, nous parlons d'hypothèse \defe{simple}{hypothèse!simple} et sinon c'est une hypothèse \defe{composite}{hypothèse!composite} ou \defe{multiple}{hypothèse!multiple}. Faire un tests consiste à déterminer une région critique.

\begin{definition}
    Un \defe{test}{test} est une application mesurable \( \delta\) qui à \( (x_1,\ldots,x_n)\in\eR^n\) associe
    \begin{equation}
        \delta(x_1,\ldots,x_n)\in\{ 0,1 \}.
    \end{equation}
    Si \( \delta(x_1,\ldots,x_n)=0\) on accepte l'hypothèse \( H_0\) pour l'échantillon \( x_1,\ldots,x_n\), et si \( \delta(x_1,\ldots,x_n)=1\), alors on rejette \( H_0\) et on choisit \( H_1\). L'ensemble
    \begin{equation}
        W=\{ (x_1,\ldots,x_n)\in\eR^n\tq \delta(x_1,\ldots,x_n)=1 \}
    \end{equation}
    est la \defe{région de rejet}{région!de rejet} ou la \defe{région critique}{région!critique}.
\end{definition}

L'ensemble \( W=\delta^{-1}(1)\) est un borélien de \( \eR^n\) parce que \( \delta\) est mesurable. L'événement auquel nous sommes intéressé est l'événement
\begin{equation}
    R=\{ (X_{\theta,1},\ldots,X_{\theta,n})\in W \}.
\end{equation}


\begin{example}
    Pour l'exemple de \ref{subsecExempLFilResituzz} nous avions
    \begin{equation}
        \delta(x_1,\ldots,x_4)=\mtu_{\complement\mathopen[ 90.2 , 109.8 \mathclose]}(\bar x_4).
    \end{equation}
\end{example}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Risque de première et seconde espèce}
%---------------------------------------------------------------------------------------------------------------------------

Le modèle de décision que nous avons introduit comprend deux façons de se tromper. Soit nous rejetons \( H_0\) alors qu'elle est vraie (c'est le \defe{risque de première espèce}{risque!première espèce}), soit nous acceptions \( H_0\) alors qu'elle est fausse (risque de \defe{seconde espèce}{risque!seconde espèce}). Nous pouvons formaliser ces concepts de la façon suivante.

Nous considérons un test de région critique \( W\). Le risque de première espèce, noté \( \alpha\) est la fonction
\begin{equation}
    \begin{aligned}
        \alpha\colon H_0&\to \mathopen[ 0 , 1 \mathclose] \\
        \theta&\mapsto P\big( (X_{\theta,1},\ldots,X_{\theta,n})\in W \big). 
    \end{aligned}
\end{equation}
Il s'agit de la probabilité de rejeter \( H_0\) alors qu'elle es vraie. Le risque de seconde espèce est la fonction
\begin{equation}
    \begin{aligned}
        \beta\colon H_1&\to \mathopen[ 0 , 1 \mathclose] \\
        \theta&\mapsto P\big( (X_{\theta,1},\ldots,X_{\theta,n})\notin W \big). 
    \end{aligned}
\end{equation}
C'est la probabilité d'accepter \( H_0\) alors qu'elle est fausse.


\begin{definition}  \label{DefPuisszYkrQa}
    Soit \( \delta\) un test de région critique \( W\). La \defe{puissance}{puissance!d'un test} du test est la fonction
    \begin{equation}
        \begin{aligned}
            \eta\colon H_1&\to \mathopen[ 0 , 1 \mathclose] \\
            \theta&\mapsto P\big( (X_{\theta,1},\ldots,X_{\theta,n})\in W \big). 
        \end{aligned}
    \end{equation}
    La \defe{courbe d'efficacité}{efficacité!courbe}\index{courbe!efficacité} du test est la fonction
    \begin{equation}
        \begin{aligned}
            h\colon \Theta&\to \mathopen[ 0 , 1 \mathclose] \\
            \theta&\mapsto  P\big( (X_{\theta,1},\ldots,X_{\theta,n})\notin W \big).
        \end{aligned}
    \end{equation}
\end{definition}
La puissance d'un test est la probabilité de rejeter \( H_0\) lorsque \( H_1\) est vraie. Plus la puissance est grande, mieux c'est. La courbe d'efficacité du test est la probabilité d'accepter \( H_0\) pour une certaine valeur de \( \theta\).

Soit un test \( \delta\). Une statistique \( T_{\theta}=T_n(X_{\theta,1},\ldots,X_{\theta,n})\) est une \defe{variable de décision}{variable!de décision} pour \( \delta\) si \( \complement W\) peut s'écrire d'une des façons suivantes\index{test!unilatéral}
\begin{equation}
    \complement W=\begin{cases}
        \{ (x_1,\ldots,x_n)\in\eR^n\tq T_n(x_1,\ldots,x_n)<c \}     &\text{test unilatéral à droite}  \\
        \{ (x_1,\ldots,x_n)\in\eR^n\tq T_n(x_1,\ldots,x_n)>c \}   &\text{test unilatéral à gauche} \\
        \{ (x_1,\ldots,x_n)\in\eR^n\tq c_1\leq T_n(x_1,\ldots,x_n)<c_2 \}   &\text{test bilatéral}.
    \end{cases}
\end{equation}\index{test!bilatéral}

Le plus souvent la variable de décision sera la moyenne : \( T_n(x_1,\ldots,x_n)=\frac{1}{ n }\sum_{i=1}^nx_i\). Les valeurs \( c,c_1,c_2\) sont des \defe{valeurs critiques}{critique!valeur}.

En ce qui concerne les notations, ici \( T_n\) représente la valeur mesurée sur un \( n\)-échantillon (d'où l'indice \( n\)) alors que \( T_{\theta}\) est la valeur \emph{théorique} de \( T\) lorsque \( \theta\) est la vraie valeur du paramètre qu'on veut estimer.

Pour un test unilatéral à gauche, nous fixons la valeur critique \( c\) de telle manière a avoir
\begin{equation}
    P(T_{\theta}>c)\leq \alpha.
\end{equation}
Pour un test unilatéral à gauche, nous fixons \( c\) de telle manière a avoir
\begin{equation}
    P(T_{\theta}<c)\leq \alpha
\end{equation}
et pour un test bilatéral nous fixons \( c_1\) et \( c_2\) de telle façon à avoir
\begin{equation}
    P(T_{\theta}>c_2)=P(T_{\theta}<c_1)\leq\frac{ \alpha }{2}.
\end{equation}

%---------------------------------------------------------------------------------------------------------------------------
\subsection{Modèle paramétrique de loi gaussienne}
%---------------------------------------------------------------------------------------------------------------------------

Soit un modèle statistique paramétrique de lois gaussiennes \( \dN(m,1)\) de moyenne \( m\) inconnue avec \( m\in\eR^+\). Nous avons \( \Theta=\mathopen[ 0 , \infty [\).

Nous observons un échantillon de taille \( n=36\). Avec un risque de première espèce de \( 5\%\) nous voulons estimer l'hypothèse \( H_0=\{ 0 \}\) contre l'hypothèse \( H_1=\mathopen] 0 , \infty \mathclose[\). De notre échantillon nous construisons la variable aléatoire
\begin{equation}
    \bar X_n=\frac{1}{ n }\sum_{i=1}^nX_i
\end{equation}
dans laquelle les \( X_i\) sont les éléments de l'échantillon, elles sont indépendantes et identiquement distribuées de loi \( \dN(m,1)\) avec \( m\) inconnu.

Si \( \bar X_n\) est proche de zéro nous acceptons \( H_0\), sinon nous la rejetons. La région de rejet s'écrit donc sous la forme
\begin{equation}
    W=\{ (x_1,\ldots,x_n)\in\eR^n\tq\bar x_n=\frac{1}{ n }\sum_{i=1}^nx_i>u \}
\end{equation}
dans lequel il faut fixer le \( u\) pour satisfaire au risque de première espèce de \( 5\%\). La contrainte est d'avoir
\begin{equation}    \label{EqQaNgBo}
    P(\bar X_n>u)=\alpha
\end{equation}
si \( H_0\) est vérifiée. Cela revient à dire que dans \( 5\%\) des cas où \( H_0\) est correcte, nous la rejetterons. Si \( H_0\) est vraie alors \( \bar X_n\) est une moyenne de gaussiennes de moyennes \( m\) et nous avons
\begin{equation}
    \frac{ \bar X_n-m }{ \sigma/\sqrt{n} }\sim\dN(0,1)
\end{equation}
avec \( m=0\) et \( \sigma=1\). L'équation \eqref{EqQaNgBo} devient donc
\begin{equation}
    \alpha=P\left( \frac{ \bar X_n }{ 1/\sqrt{n} }>\frac{ u }{ 1/\sqrt{n} } \right)=P(T>\sqrt{n}u)
\end{equation}
où \( T\sim\dN(0,1)\). Avec \( n=36\) et \( \alpha=5\%\) nous trouvons 
\begin{equation}
    u=\frac{ 1.645 }{ 6 }\simeq 0.274
\end{equation}
La règle de décision est donc la suivante : si \( \bar x_n>0.274\) alors nous rejetons \( H_0\), et sinon nous l'acceptons.

Calculons la puissance de ce test (définition \ref{DefPuisszYkrQa}). C'est la fonction donnée par
    \begin{equation}
        \begin{aligned}
            \eta\colon H_1&\to \eR \\
            m&\mapsto P\big( (X_{1,m},\ldots, X_{n,m})\in W \big)=P\left( \frac{1}{ n }\sum X_i>u \right) .
        \end{aligned}
    \end{equation}
    Dans ce calcul, les \( X_i\) sont d'une loi normale \( \dN(m,1)\), et non \( \dN(0,1)\). En retranchant \( m\) et en divisant par \( 1/\sqrt{n}\) nous trouvons
    \begin{subequations}
        \begin{align}
            \eta(m)&=P\left( \frac{ \frac{1}{ n }\sum X_i-m }{ 1/\sqrt{t} }>\frac{ u-m }{ 1/\sqrt{n} } \right) \\    
            &=P(T>\sqrt{n}(u-m))\\
            &=P(T>16.45-6m)\\
            &=1-\Phi(1.645-6m)
        \end{align}
    \end{subequations}
où \( \Phi\) est la fonction de répartition de \( \dN(0,1)\). La fonction \( \eta\) a les propriétés suivantes :
\begin{subequations}
    \begin{align}
        \lim_{m\to-\infty}\eta(m)&=0\\
        \lim_{m\to\infty}\eta(m)&=1\\
        \eta(0)&=\frac{ 5 }{ 100 }.
    \end{align}
\end{subequations}

\begin{remark}
    Si nous regardons \( m=0.001\), le risque de seconde espèce est quasiment de \( 90\%\). En effet le risque de seconde espèce est d'accepter \( H_0\) alors qu'il est faux. Lorsque \( m=0.001\), l'hypothèse \( H_0\) est fausse, mais la probabilité qu'on l'accepte est grande. D'ailleurs les conséquences de l'accepter à tord ne sont peut-être pas si grandes que cela.
\end{remark}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Tests paramétriques}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

La proposition suivante montre le lien entre région de confiance et les tests.
\begin{proposition}
    Soit \( \Lambda(X_1,\ldots, X_n)\) une région de confiance par excès de niveau de confiance \( 1-\alpha\). Alors il existe un tests pur de niveau \( \alpha\) pour tester \( H_0=\{ \theta_0 \}\) de région de rejet
    \begin{equation}
        W_n=\{ x=(x_1,\ldots,x_n)\in \eR^n\tq \theta_0\notin\Lambda(x_1,\ldots,x_n) \}.
    \end{equation}
\end{proposition}

\begin{proof}
    L'hypothèse sur \( \Lambda\) signifie qu'avec les observations \( (X_1,\ldots, X_n)\), il y a une forte probabilité (plus grande que \( 1-\alpha\)) que \( \theta\) soit dans \( \Lambda(X_1,\ldots, X_n)\). Avec ou sans \( H_0\) nous avons donc
    \begin{equation}
        P(\theta\in\Lambda)\geq 1-\alpha.
    \end{equation}
    Supposons maintenant l'hypothèse \( H_0\), alors
    \begin{equation}
        P\big( (X_1,\ldots, X_n)\in W_n \big)=P\big( \theta_0\notin\Lambda(X_1,\ldots, X_n) \big)\leq \alpha.
    \end{equation}
\end{proof}

\begin{remark}
    Soit \( W_n\) la région de confiance d'un test de niveau \( \alpha\) pour tester \( H_0=\{ \theta_0 \}\). Alors
    \begin{equation}
        \Lambda=\{ x\in\eR^n\tq x\notin W_n \} 
    \end{equation}
    est une région de confiance \( 1-\alpha\) pour \( \theta\).
\end{remark}

\Exo{Model-0008}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Tests d'adéquation}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Soit \( X_1,\ldots,X_n\) un échantillon de loi parente $X$ finie prenant ses valeurs dans \( \{ a_1,\ldots, a_k \}\). La loi de \( X\) est donnée par les nombres
\begin{equation}
    p_i=P(X=a_i)
\end{equation}
pour \( i=1,\ldots, k\). Nous introduisons l'\defe{effectif empirique}{effectif!empirique}, la variable aléatoire \( N_i\) qui compte le nombre de fois que \( a_i\) est observé dans l'échantillon. La \defe{fréquence empirique}{fréquence!empirique} est la variable aléatoire
\begin{equation}
    F_i=\frac{ N_i }{ n }.
\end{equation}
Nous savons que la loi de \( N_i\) est \( \dB(n,p_i)\), et la loi des grands nombres dit que
\begin{equation}
    F_i\stackrel{p.s.}{\longrightarrow}p_i
\end{equation}
pour chaque \( i\). Le théorème central limite nous indique de plus que
\begin{equation}
    \frac{ N_i-np_i }{ \sqrt{np_i(1-p_i)} }\stackrel{\hL}{\longrightarrow} T\sim\dN(0,1).
\end{equation}

Nous considérons un cas où les \( p_i\) sont inconnus. Ils peuvent être approchés par \( N_i\simeq np_i\). Le théorème de Pearson nous indique comment.
\begin{theorem}[Théorème de Pearson]\index{théorème!Pearson}\index{Pearson!theoreme}
    Nous avons
    \begin{equation}
        \sum_{i=1}^k\frac{ (N_i-np_i)^2 }{ np_i }\stackrel{\hL}{\longrightarrow}K\sim\chi^2(k-1)
    \end{equation}
    où la distribution \( \chi^2(l)\) est la somme des carrés de \( l\) gaussiennes centrées réduites indépendantes.
\end{theorem}

\begin{proof}
    Nous commençons par le cas \( k=2\). Dans ce cas nous avons \( N_2=n-N_1\) et \( p_1+p_2=1\). La sommes que nous regardons est
    \begin{subequations}
        \begin{align}
            \frac{ (N_1-np_1)^2 }{ np_1 }+\frac{ (N_2-np_2)^2 }{ np_2 }&=\frac{ (N_1-np_1)^2 }{ np_1 }+\frac{ (N_1-np_1)^2 }{ n(1-p_1) }\\
            &=\frac{ (N_1-np_1)^2 }{ np_1(1-p_1) }. \label{subeqHETRlC}
        \end{align}
    \end{subequations}
    Étant donné que \( N_1\) est une variable aléatoire binomiale nous avons
    \begin{equation}
        \frac{ N_1-np_1 }{ \sqrt{np_1(1-p_1)} }\stackrel{\hL}{\longrightarrow}T\sim\dN(0,1).
    \end{equation}
    Par conséquent la limite de \eqref{subeqHETRlC} est 
    \begin{equation}
        \left( \frac{ N_1-np_1 }{ \sqrt{np_1(1-p_1)} } \right)^2\stackrel{\hL}{\longrightarrow}T^2\simeq\chi^2(1).
    \end{equation}
    Cela conclut le cas \( k=2\).
    
    Passons à présent au cas général. Le \( k\)-uple \( (N_1,\ldots, N_k)\) est une variable aléatoire multinomiale de loi
    \begin{equation}
        \dM(n;k;p_1,\ldots, p_k).
    \end{equation}
    Nous introduisons les variables aléatoires \( U_i\) données par \( U_i\colon \Omega\to \eR^k\) avec
    \begin{equation}
        P\big( U_i=(0,\ldots, 1,\ldots, 0) \big)=p_i;
    \end{equation}
    c'est le vecteur aléatoire qui prend ses valeurs dans les vecteurs de la base canonique de \( \eR^k\) et qui prend la valeur \( e_i\) avec probabilité \( p_i\). Par construction nous avons
    \begin{equation}
        (N_1,\ldots, N_k)=\sum_{i=1}^nU_i.
    \end{equation}
    Nous allons étudier la fonction caractéristique de \( (N_1,\ldots, N_k)\) définie par l'équation \eqref{EqydvDxg}:
    \begin{equation}
        \begin{aligned}
            \Phi_{(N_1,\ldots, N_k)}\colon\eR^k &\to \eC \\
            e_j&\mapsto E( e^{ie_j\cdot N})=E( e^{iN_j}). 
        \end{aligned}
    \end{equation}
    Plus généralement,
    \begin{equation}
        \Phi_{(N_1,\ldots, N_k)}(t_1,\ldots, t_k)=E\big(  e^{i\langle t, N\rangle_{\eR^k} } \big).
    \end{equation}
    Nous avons
    \begin{equation}
        e^{i\langle t, N\rangle }= e^{i\sum_j\langle t, U_j\rangle }=\prod_j e^{i\langle t, U_j\rangle }
    \end{equation}
    et vu que les \( U_i\) sont indépendantes et identiquement distribuées nous pouvons écrire \( U_1\) à la place de \( U_j\) de façon à avoir
    \begin{subequations}    \label{EqOhTHia}
        \begin{align}
            \Phi_{(N_1,\ldots, N_k)}(t_1,\ldots, t_k)&=\prod_{j}E\big(  e^{i\langle t, U_1\rangle } \big)\\
            &=\prod_j\sum_lp_l e^{i\langle t, e_l\rangle }\\
            &=\prod_j\sum_lp_l e^{it_l}\\
            &=\left( \sum_{l=1}^kp_l e^{it_l} \right)^n.
        \end{align}
    \end{subequations}
    Nous allons montrer que 
    \begin{equation}
        \lim_{n\to \infty} \Phi_{(N_1,\ldots, N_n)}(t_1,\ldots, t_k)= e^{-\frac{ 1 }{2}\sum_{j=1}^nt_j^2}-\left( \sum_{j=1}^kt_j\sqrt{p_j} \right)^2.
    \end{equation}
    Pour ce faire, nous allons effectuer un développement limité. D'abord nous introduisons les variables aléatoires
    \begin{equation}        \label{EqmdROCD}
        \alpha_j=\frac{ N_j-np_j }{ \sqrt{np_j} }
    \end{equation}
    et nous calculons
    \begin{equation}
        \Phi_{(\alpha_1,\ldots, \alpha_k)}(t_1,\ldots, t_k)=E\left[ \exp\left( i\langle t, \big( \frac{ N_1-np_1 }{ \sqrt{np_1} },\ldots, \frac{ N_k-np_k }{ \sqrt{np_k} } \big)\rangle  \right) \right]
    \end{equation}
    Étant donné que \( n\) et \( p_j\) sont des variables déterministes, nous pouvons les sortir de l'espérance. Nous avons alors
    \begin{equation}        \label{EqlgeCLS}
        \Phi_{(\alpha_1,\ldots, \alpha_k)}(t_1,\ldots, t_k)= \exp\left( -i\sum_{j=1}^kt_j\sqrt{np_j} \right)\Phi_{(N_1,\ldots, N_k)}\left( \frac{ t_1 }{ \sqrt{np_1} },\ldots, \frac{ t_k }{ \sqrt{np_k} } \right)
    \end{equation}
    parce que
    \begin{equation}
        E\left(  e^{t_j\frac{ N_j-np_j }{ \sqrt{np_j} }} \right)= e^{\frac{ -t_jnp_j }{ \sqrt{np_j} }}E\left(  e^{t_jN_j/\sqrt{np_j}} \right)
    \end{equation}
    En remplaçant \eqref{EqOhTHia} dans \eqref{EqlgeCLS} nous trouvons
    \begin{equation}        \label{EqrUYsnD}
        \Phi_{(\alpha_1,\ldots, \alpha_k)}(t_1,\ldots, t_k)=\exp\left( -i\sum_{j=1}^kt_j\sqrt{np_j} \right)\underbrace{\left( \sum_{j=1}^kp_j e^{i\frac{ t_j }{ \sqrt{np_j} }} \right)^n}_{A}
    \end{equation}
    Nous analysons maintenant le terme $A$. Nous écrivons l'égalité \( A=A+1-1\) en tenant compte de $\sum_{j}p_j=1$ sous la forme
    \begin{equation}
        A=\left( 1+\sum_{j=1}^kp_j\big( \exp(it_j/\sqrt{np_j})-1 \big) \right)^n,
    \end{equation}
    Nous avons alors 
    \begin{equation}
        \ln(A)=n\ln\left[ 1+\sum_{j=1}^{\infty}p_j\big( e^{ it_j/\sqrt{np_j}}-1) \right]
    \end{equation}
    Nous développons l'exponentielle en
    \begin{equation}
        e^{it_j/\sqrt{np_j}}-1=\frac{ it_j }{ \sqrt{np_j} }-\frac{ t_j^2 }{ 2np_j }+\frac{1}{ n }\epsilon(1/n)
    \end{equation}
    et ensuite le logarithme selon la formule
    \begin{equation}
        \ln(1+x)=x-\frac{ x^2 }{2}+x^2\alpha(x^2).
    \end{equation}
    Nous avons
    \begin{subequations}
        \begin{align}
            \ln(A)&=n\ln\left[ 1+\sum_jp_j\Big( \frac{ it_j }{ \sqrt{np_j} }-\frac{ t_j^2 }{ 2np_j }+\frac{1}{ n }\epsilon(\frac{1}{ n }) \Big) \right]\\
            &=n\ln\left[ 1+\sum_jp_j\Big(it_j \sqrt{\frac{ p_j }{ n }}-\frac{ t_j^2 }{ 2n}+\frac{1}{ n }\epsilon(\frac{1}{ n }) \Big) \right]\\
            &=n\underbrace{\sum_{j=1}^k\left( it_j\sqrt{\frac{ p_j }{ n }}-\frac{ t_j^2 }{ 2n }+\frac{1}{ n }\epsilon(1/n) \right)}_{K}\\
            &\quad-n\frac{ 1 }{2}\left[ \sum_{j}\left( it_j\sqrt{\frac{ p_j }{ n }}-\frac{ t_j^2 }{ 2n }+\frac{1}{ n }\epsilon(1/n) \right)^2 \right]\\
            &\quad +nK^2\alpha(K)
        \end{align}
    \end{subequations}
    Nous introduisons dans \( \epsilon\) tous les termes en \( 1/n^2\) et nous trouvons
    \begin{equation}
        \ln(A)=\sum_j\left( it_j\sqrt{p_jn}-\frac{ t_j^2 }{2} \right)-\frac{ 1 }{2}\left( \sum_jit_j\sqrt{p_j} \right)^2+\epsilon(1/n)+K^2\alpha(K).
    \end{equation}
    En remplaçant dans \eqref{EqrUYsnD} et en passant à la limite pour \( n\to\infty\),
    \begin{equation}    \label{EaqTXgCW}
        \Phi_{(\alpha_1,\ldots, \alpha_k)}(t_1,\ldots, t_k)=\exp\left( -\frac{ 1 }{2}\sum_jt_j^2+\frac{ 1 }{2}\big( \sum_jt_j\sqrt{p_j} \big)^2 \right).
    \end{equation}
    Nous reconnaissons des lois gaussiennes dans le premier terme de l'exponentielle. Nous allons maintenant nous atteler à identifier le second terme.

    Soit \( C\) une matrice orthogonale dont la dernière ligne est \( (\sqrt{p_1},\ldots, \sqrt{p_k})\). Nous considérons les vecteurs
    \begin{equation}
        \begin{aligned}[]
            \alpha&=\begin{pmatrix}
                \alpha_1    \\ 
                \vdots    \\ 
                \alpha_k    
            \end{pmatrix},
            &t=\begin{pmatrix}
                t_1    \\ 
                \vdots    \\ 
                t_k    
            \end{pmatrix}.
        \end{aligned}
    \end{equation}
    et ensuite nous notons
    \begin{equation}
        U=Ct=\begin{pmatrix}
            u_1    \\ 
            \vdots    \\ 
            u_k    
        \end{pmatrix}.
    \end{equation}
    Étant donné que \( C\) est orthogonale, nous avons \( \sum_{i=1}^k\alpha_i^2=\sum_{i=1}^k\beta_i^2\) et
    \begin{equation}
        \Phi_{(\beta_1,\ldots, \beta_k)}=E\big(  e^{i\langle u, \beta\rangle } \big)=E\big(  e^{i\langle t, \alpha\rangle } \big)=\Phi_{(\alpha_1,\ldots, \alpha_k)}(t_1,\ldots, t_k).
    \end{equation}
    Nous pouvons récrire l'argument de l'exponentielle \eqref{EaqTXgCW} de la façon suivante :
    \begin{subequations}
        \begin{align}
            \sum_{i=1}^kt_j^2&=\sum_ju_j^2\\
            \sum_{j=1}^kt_j\sqrt{p_j}&=(Ct)_{k},
        \end{align}
    \end{subequations}
    Nous avons alors
    \begin{subequations}
        \begin{align}
            \lim_{n\to \infty} \Phi_{(\beta_1,\ldots, \beta_k)}(t_1,\ldots, t_k)&=\lim_{n\to \infty} \Phi_{(\alpha_1,\ldots, \alpha_k)}(u_1,\ldots, u_k)\\
            &=\exp\left( \frac{ 1 }{2}\sum_{j=1}^{k-1}u_j^2 \right)\\
            &=\Phi_{(Z_1,\ldots, Z_{k-1},0)}(u_1,\ldots, u_k)
        \end{align}
    \end{subequations}
    où les \( Z_i\) sont des variables aléatoires indépendantes et identiquement distribuées de distribution normale centrée réduite. Nous avons donc montré que
    \begin{equation}
        (\beta_1,\ldots, \beta_k)\stackrel{\hL}{\longrightarrow}(Z_1,\ldots, Z_{k-1},)).
    \end{equation}
    Étant donné que l'application \( x\mapsto \| x \|^2\) est continue, nous avons aussi
    \begin{equation}
        \| (\beta_1,\ldots, \beta_k) \|^2\stackrel{\hL}{\longrightarrow}\| (Z_1,\ldots, Z_{k-1},0) \|^2,
    \end{equation}
    et par conséquent
    \begin{equation}
        \| (\alpha_1,\ldots, \alpha_k) \|^2\stackrel{\hL}{\longrightarrow}\sum_{j=1}^{k-1}Z_j^2\sim\chi^2(k-1).
    \end{equation}
    D'après la définition \eqref{EqmdROCD} nous avions
    \begin{equation}
        \| (\alpha_1,\ldots, \alpha_k) \|^2=\sum_{j=1}^k\frac{ (N_j-p_j)^2 }{ np_j }.
    \end{equation}
\end{proof}
