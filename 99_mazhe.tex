% This is part of (almost) Everything I know in mathematics and physics
% Copyright (c) 2013-2014
%   Laurent Claessens
% See the file fdl-1.3.txt for copying conditions.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{definition}
    A \defe{Lie algebra}{Lie algebra} is a vector space \( \lG\) on \( \eK(=\eR,\eC)\) endowed with a bilinear operation \( (x,y)\mapsto [x,y]\) from \( \lG\times\lG\) with the properties
    \begin{enumerate}
        \item
            \( [x,y]=-[y,x]\)
        \item
            \( \big[ x,[y,z] \big]+\big[ y,[z,x] \big]+\big[ z,[x,y] \big]=0\).
    \end{enumerate}
    The second condition is the \defe{Jacobi identity}{Jacobi!identity}.
\end{definition}

\section{Adjoint group}\label{sec:adj_gp}
%--------------------------

Let $\lA$ be a \emph{real} Lie algebra. We denote by $GL(\lA)$\nomenclature[G]{$GL(\lA)$}{The group of nonsingular endomorphism of $\lA$} the group of all the nonsingular endomorphism of $\lA$ : the linear and nondegenerate operators on $\lA$ as vector space. An element $\sigma\in\GL(\lA)$ does not specially fulfils somethings like $\sigma[X,Y]=[\sigma X,\sigma Y]$. The Lie algebra $\gl(\lA)$\nomenclature[G]{$\protect\gl(\lA)$}{space of endomorphism with usual bracket} is the vector space of the endomorphism (without non degeneracy condition) endowed with the usual bracket $(\ad A)B=[A,B]=A\circ B-B\circ A$. The map $X\to\ad X$ is a homomorphism from $\lA$ to the subalgebra $\ad(\lA)$ of $\gl(\lA)$.

The group $\Int(\lA)$\nomenclature[G]{$\Int(\lA)$}{Adjoint group of $\lA$} is the analytic Lie subgroup of $\GL(\lA)$ whose Lie algebra is $\ad(\lA)$ by theorem \ref{tho:gp_alg}. This is the \defe{adjoint group}{adjoint!group}\index{group!adjoint} of $\lA$.

\begin{proposition}
The group $\Aut(\lA)$\nomenclature[G]{$\Aut\lA$}{Group of automorphism of $\lA$} of all the automorphism of $\lA$ is a closed subgroup of $\GL(\lA)$.
\end{proposition}

\begin{proof}
The property which distinguish the elements in $\Aut(\lA)$ from the ``commons'' elements of $\GL(\lA)$ is the preserving of structure: $\varphi[A,B]=[\varphi A,\varphi B]$. These are equalities, and we know that a subset of a manifold which is given by some equalities is closed.
\end{proof}

Now, theorem \ref{tho:diff_sur_ferme} provides us an unique analytic structure on $\Aut(\lA)$ in which it is a topological Lie subgroup of $\GL(\lA)$. From now we only consider this structure. We denote by $\partial(\lA)$\nomenclature[G]{$\partial\lA$}{The Lie algebra of $\Aut(\lA)$} the Lie algebra of $\Aut(\lA)$ : this is the set of the endomorphism $D$ of $\lA$ such that $\forall t\in\eR$, $e^{tD}\in\Aut(\lA)$. By differencing the equality
\begin{equation}\label{eq:exp_der}
  e^{tD}[X,Y]=[e^{tD}X,e^{tD}Y]
\end{equation}
with respect to $t$, we see\footnote{As usual, if we consider a basis of $\lA$ as vector space, the expression in the right hand side of \[[e^{tD}X,e^{tD}Y]=\ad(e^{tD}X)e^{tD}X\] can be seen as a product matrix times vector, so that Leibnitz works.} that $D$ is a \defe{derivation}{derivation!of a Lie algebra} of $\lA$ :
\begin{equation}
  D[X,Y]=[DX,Y]+[X,DY]
\end{equation}
for any $X$, $Y\in\lA$. Conversely, consider $D$, any derivation of $\lA$; by induction, 
\begin{equation}
   D^k[X,Y]=\sum_{i+j=k}\frac{k!}{i!j!}[D^iX,D^jY]
\end{equation}
where by convention, $D^0$ is the identity in $\lA$. This relation shows that $D$ fulfils condition \eqref{eq:exp_der}, so that any derivation of $\lA$ lies in $\partial(\lA)$. Then
\[
  \partial(\lA)=\{\text{derivations of $\lA$}\}.
\]
The Jacobi identities show that 
\[
\ad(\lA)\subset\partial(\lA).    \label{pg:ad_subset_der}
\]
From this, we deduce\footnote{See error \ref{err:Intt_Aut}} :
\begin{equation}\label{eq:int_sub_aut}
  \Int(\lA)\subset\Aut(\lA).
\end{equation}
Indeed the group $\Int(\lA)$ being connected, it is generated\footnote{See proposition \ref{PropUssGpGenere}} by any neighbourhood of $e$; note that $\Aut(\lA)$ has not specially this property. We take a neighbourhood of $e$ in $\Int(\lA)$ under the form  $\exp V$  where $V$ is a sufficiently small neighbourhood of $0$ in $\ad(\lA)$ to be a neighbourhood of $0$ in $\partial(\lA)$ on which $\exp$ is a diffeomorphism. In this case, $\exp V\subset\Aut(\lA)$ and then $\Int(\lA)\subset\Aut(\lA)$.

Elements of $\ad(\lA)$ are the \defe{inner derivations}{derivation!inner} while the ones of $\Int(\lA)$ are the \defe{inner automorphism.}{inner!automorphism} 

Let $\mO$ be an open subset of $\Aut(\lA)$; for a certain open subset $U$ of $\GL(\lA)$, $\mO=U\cap\Aut(\lA)$. Then
\begin{equation}
  \iota^{-1}(\mO)=\mO\cap\Int(\lA)
           =U\cap\Aut(\lA)\cap\Int(\lA)
       =U\cap\Int(\lA).
\end{equation}
The subset $U\cap\Int(\lA)$ is open in $\Int(\lA)$ for the topology because $\Int(\lA)$ is a Lie\quext{Is it true ??} subgroup of $\GL(\lA)$ and thus has at least the induced topology. This proves that the inclusion map $\dpt{\iota}{\Int(\lA)}{\Aut(\lA)}$ is continuous.

The lemma \ref{lem:var_cont_diff} and the consequence below makes $\Int(\lA)$ a Lie subgroup of $\Aut(\lA)$. Indeed $\Int(\lA)$ and $\Aut(\lA)$ are both submanifolds of $\GL(\lA)$ which satisfy \eqref{eq:int_sub_aut}. By definition, $\Aut(\lA)$ has the induced topology from $\GL(\lA)$. Then $\Int(\lA)$ is a submanifold of $\Aut(\lA)$. This is also a subgroup and a topological group ($\Int(\lA)$ is not a topological subgroup of $\Aut(\lA)$, cf remark \ref{rem:sub_Lie}). Then $\Int(\lA)$ is a Lie subgroup of $\Aut(\lA)$.


Schematically, links between $\Int\lG$, $\ad\lG$, $\Aut\lG$ and $\partial\lG$ are
\begin{subequations}\label{eq:schem_ad_int}
\begin{align}
  \Int\lG&\longleftarrow\ad\lG\\
  \Aut\lG&\longrightarrow\partial\lG.
\end{align}
\end{subequations}
Remark that the sense of the arrows is important. By definition $\partial\lG$ is the Lie algebra of $\Aut\lG$, then there exist some algebras $\lG$ and $\lG'$ with $\Aut\lG\neq\Aut\lG'$ but with $\partial\lG=\partial\lG'$, because the equality of two Lie algebras doesn't implies the equality of the groups. The case of $\Int\lG$ and $\ad\lG$ is very different: the group is defined from the algebra, so that $\ad\lG=\ad\lG'$ implies $\Int\lG=\Int\lG'$ and $\Int\lG=\Int\lG'$ if and only if $\ad\lG=\ad\lG'$.


\begin{proposition}
 The group $\Int(\lA)$ is a normal subgroup of $\Aut(\lA)$.
\end{proposition}

\begin{proof}
Let us consider a $s\in\Aut(\lA)$. The map $\dpt{\sigma_s}{\Aut(\lA)}{\Aut(\lA)}$, $\sigma_s(g)=sgs^{-1}$ is an automorphism of $\Aut(\lA)$. Indeed, consider $g$, $h\in\AutA$; direct computations show that $\sigma_s(gh)=\sigma_s(g)\sigma_s(h)$ and $[\sigma_s(g),\sigma_s(h)]=\sigma_s([g,h])$. From this, $(d\sigma_s)_e$ is an automorphism of $\partial(\lA)$, the Lie algebra of $\AutA$. For any $D\in\partial(\lA)$ we have
\begin{equation}\label{eq:ad_s_2}
 (d\sigma_s)_eD=\Dsdd{ sD(t)s^{-1} }{t}{0}
             =sDs^{-1}. 
\end{equation}
Since $s$ is an automorphism of $\lA$ and $\ad(\lA)$, a subalgebra of $\gl(\lA)$,
\begin{equation}\label{eq:ad_s_1}
  s\ad Xs^{-1}=\ad(sX)
\end{equation}
for any $X\in\lA$, $s\in\Aut(\lA)$. Since $\ad(\lA)\subset\partial(\lA)$, we can write \eqref{eq:ad_s_2} with $D=\ad X$ and put it in \eqref{eq:ad_s_1} : 
\[
   (d\sigma)_e\ad X=s\ad Xs^{-1}=\ad(s\cdot X).
\]
We know from general theory of linear operators on vector spaces that if $A,B$ are endomorphism of a vector space and if $A^{-1}$ exists, then $Ae^BA^{-1}=e^{ABA^{-1}}$. We write it with $A=s$ and $B=\ad X$ : 
\[
  \sigma_s\cdot e^{\ad X}=se^{\ad X}s^{-1}=e^{s\ad Xs^{-1}}=e^{\ad(s\cdot X)},
\]
sot that 
\begin{equation}\label{eq:sigma_aut_s}
  \sigma_s\cdot e^{\ad X}=e^{\ad(s X)}.
\end{equation}

Ont the other hand, we know that $\IntA$ is connected, so it is generated by elements of the form $e^{\ad X}$ for $X\in\lA$. Then $\IntA$ is a normal subgroup of $\AutA$; the automorphism $s$ of $\lA$ induces the isomorphism $g\to sgs^{-1}$ in $\IntA$ because of equation \eqref{eq:sigma_aut_s}.
\end{proof}

More generally, if $s$ is an isomorphism from a Lie algebra $\lA$ to a Lie algebra $\lB$, then the map $g\to sgs^{-1}$ is an isomorphism between $\AutA$ and $\AutB$ which sends $\IntA$ to $\IntB$. Indeed, consider an isomorphism $\dpt{s}{\lA}{\lB}$ and $g\in\AutA$. If $g\in\IntA$, we have to see that $sgs^{-1}\in\IntB$. By definition, $\IntA$ is the analytic subgroup of $\GL(\lA)$ which has $\ad(\lA)$ as Lie algebra. We have $g=e^{\ad A}$, then $sgs^{-1}=e^{\ad(sA)}$ which lies well in $\IntB$.

\begin{lemma}       \label{LemadhomomadXadYadXY}
    The adjoint map is an homomorphism \( \ad\colon \lG\to \GL(\lG)\). In other terms for every \( X,Y\in\lG\) we have
    \begin{equation}
        \big[ \ad(X),\ad(Y) \big]=\ad\big( [X,Y] \big)
    \end{equation}
    as operators on \( \lG\). In particular the algebra acts on itself and \( \lG\) carries a representation of each of its subalgebra.
\end{lemma}

\begin{proof}
    Using the fact that \( \ad(X)\) is a derivation and Jacobi, for \( Z\in\lG\) we have
    \begin{subequations}
        \begin{align}
            \big[ \ad(X),\ad(Y) \big]Z&=\ad(X)\ad(Y)Z-\ad(Y)\ad(X)Z\\
            &=\big[ [X,Y],Z \big]+\big[ Y,[X,Z] \big]-\big[ [Y,X],Z \big]-\big[ X,[Y,Z] \big]\\
            &=\ad\big( [X,Y] \big)Z.
        \end{align}
    \end{subequations}
\end{proof}

\section{Adjoint representation}
%////////////////////////////////////

Let $G$ be a Lie group and $g\in G$; one can consider the map $\dpt{I}{G\times G}{G}$ given by $I(g)h=g hg^{-1}$. Seen as $\dpt{I(g)}{G}{G}$, this is an analytic automorphism of $G$. We define :\nomenclature[D]{$\Ad$}{Adjoint representation}
\[
    \Ad(g)=dI(g)_e.
\]
Using equation $\varphi(\exp X)=\exp d\varphi_e(X)$ with $\varphi=I(g)$,
\begin{equation}\label{eq:sigma_X_sigma}
  g e^{X}g^{-1}=\exp[ \Ad(g)X ]
\end{equation}
for every $g\in G$ and $X\in\lG$. The map $g\to\Ad(g)$ is a homomorphism from $G$ to $\GL(\lG)$. This homomorphism is called the \defe{adjoint representation}{adjoint!representation!Lie group on its Lie algebra}\index{representation!adjoint} of $G$.

\begin{proposition}
The adjoint representation is analytic.
\end{proposition}

\begin{proof}
We have to prove that for any $X\in\lG$ and for any linear map $\dpt{\omega}{\lG}{\eR}$, the function $\omega(\Ad(g)X)$ is analytic at $g=e$. Indeed if we take as $\omega$ , the projection to the $i$th component and $X$ as the $j$th basis vector ($\lG$ seen as a vector space), and if we see the product $\Ad(g)X$ as a product matrix times vector, $(\Ad(g)X)_i$ is just $\Ad(g)_{ij}$. Then our supposition is the analyticity of $g\to\Ad(g)_{ij}$ at $g=e$. \quext{L'analicité de $\Ad$, elle vient par prolongement analytique depuis juste un point ?}

Now we prove it. Consider $f\in\Cinf(G)$, analytic at $g=e$ and such that $Yf=\omega(Y)$ for any $Y\in\lG$. Using equation \eqref{eq:sigma_X_sigma}, 
\begin{equation}
  \omega(\Ad(g)X)=(\Ad(g)X)f
                      =\Dsdd{ f(e^{t\Ad(g)X}) }{t}{0}
                      =\Dsdd{ f(g e^{tX}g^{-1}) }{t}{0},
\end{equation}
which is well analytic at $g=e$.
\end{proof}


\begin{proposition}
Let $G$ be a connected Lie group and $H$, an analytic subgroup of $G$. Then $H$ is a normal subgroup\index{normal!subgroup} of $G$ if and only if $\lH$ is an ideal in $\lG$.
\end{proposition}

\begin{proof}
We consider $X$, $Y\in\lG$. Formula $\exp tX\exp tY\exp-tY=\exp( tY+t^2[X,Y]+o(t^3) )$ and equation \eqref{eq:sigma_X_sigma} give
\[
   \exp\Big( \Ad(e^{tX})tY \Big)=\exp\Big(  tY+t^2[X,Y]+o(t^3)  \Big).
\]
Since it is true for any $X$, $Y\in\lG$, $\Ad(e^{tX})tY=tY+t^2[X,Y]$; thus
\begin{equation}
  \Ad(e^{tX})=\mtu+t[X,Y]+o(t^2).
\end{equation}
Since we know that $\dpt{d\Ad_e}{\lG}{\gl(\lG)}$ is a homomorphism ($\Ad$ is seen as a map $\dpt{\Ad}{G}{\GL(\lG)}$), taking the derivative of the last equation with respect to $t$ gives
\begin{equation}
  d\Ad_e(X)=\ad X.
\end{equation}
Then $\Ad(e^X)=e^{\ad X}$. Since is connected, an element of $G$ can be written as $\exp X$ for a certain $X\in\lG$\footnote{Because $G$ is generated by any neighbourhood of $e$ and there exists such a neighbourhood of $e$ which is diffeomorphic to a subset of $\lG$ by $\exp$.}. The purpose is to prove that $g\exp Xg^{-1}=\exp(\Ad(g)X)$ remains in $H$ for any $g\in G$ if and only if $\lH$ is an ideal in $\lG$. In other words, we want $\Ad(g)X\in\lH$ if and only if $\lH$ is an ideal. We can write $g=e^Y$ for a certain $Y\in\lG$. Thus
\[
  \Ad(g)X=\Ad(e^Y)X=e^{\ad Y}X.
\]
Using the expansion 
\begin{equation}
e^{\ad Y}=\sum_k\us{k!}(\ad Y)^k,
\end{equation}
we have the thesis.
\end{proof}

\section{Cosets}
%------------------

We consider $G$, a Lie group and $H$, a closed subgroup. Then from theorem \ref{tho:diff_sur_ferme},  there exists an unique analytic structure on $H$ for which $H$ is a topological Lie subgroup of $G$. We naturally consider this structure on $H$. We also consider $\lG$ and $\lH$, the Lie algebras of $G$ and $H$, and $\lM$ be a subspace of $\lG$ such that $\lG=\lM\oplus\lH$.

Now we will study the structure of the coset space $G/H$ on which we put the topology such that $\pi$ is continuous and open; this is the \defe{natural topology}{natural topology}\index{topology!natural on $G/H$}\label{pg:natur_topo}. As notations, we define $p_0=\pi(e)$ and $\dpt{\psi}{\lM}{G}$, the restriction to $\lM$ of the exponential.

\begin{lemma}
The dimension of $G/H$ is $\dim (G/H)=\dim G-\dim H$.
 \label{lem:dim_G_H}
\end{lemma}

\begin{proof}
We decompose the Lie algebra $\lG$ as $\lG=\lH\oplus\lM$, and we will see that there exists a real vector space isomorphism $\dpt{\psi}{T_{[e]}(G/H)}{\lM}$ given by
\begin{equation}
   \psi(X)=\Dsdd{ e^{m(t)} }{t}{0}
\end{equation}
if $X(t)=[g(t)]$ with $g(t)=e^{m(t)}e^{h(t)}$ where $m(t)\in\lM$ and $h(t)\in\lH$ (the existence of such a decomposition in reasonably small neighbourhood of $e$ is given by lemma \ref{lem:decomp}). The fact that $\psi$ is surjective is clear. The injectivity is also easy: $\psi(X)=0$ implies that $\exp m(t)$ is a constant. Thus
\[
X=\Dsdd{ [cst\, e^{h(t)}] }{t}{0}=\Dsdd{[cst]}{t}{0}=0.
\]

\end{proof}

\begin{lemma} \label{lem:vois_U}
There exists a neighbourhood $U$ of $0$ in $\lM$ such that
 \begin{enumerate}
 \item $\psi$ is homeomorphic on $U$,
 \item $\pi$ sends homeomorphically $\psi(U)$ on a neighbourhood of $p_0$ in $G/H$.
 \end{enumerate}
\end{lemma}

\begin{proof}
By lemma \ref{lem:decomp}, we consider bounded, open and connected neighbourhoods $\mU_m$ and $\mU_h$ of $0$ in $\lM$ and $\lH$ such that 
\[
  \dpt{\phi}{(A,B)}{e^Ae^B}
\]
is a diffeomorphism from $\mU_m\times\mU_h$ to an open neighbourhood of $e$ in $G$. Since $H$ has the induced topology from $G$, we can find a neighbourhood $V$ of $e$ in $G$ such that $V\cap H=\exp\mU_h$. 

Now we take $U$, a compact neighbourhood of $0$ in $\mU_m$ such that 
\begin{equation}\label{eq:UUV}
  e^{-U}e^{U}\subset V.
\end{equation}
So, $\psi$ is an homeomorphism from $U$ to $\psi(U)$. Indeed for $X\in U$, $\psi(X)=e^X=\phi(X,0)$ and $\phi$ is diffeomorphic. 

On the other hand, $\pi$ is bijective on $\psi(U)$. In order to see that it is injective, let us consider $X$, $Y\in U$ such that $\pi(e^{X})=\pi(e^{Y})$. Then $\exp X$ and $\exp Y$ are in the same class with respect to $H$ : $\exp X\in[\exp Y]$. Then $\exp(-X)\exp Y\in H$, and reversing the role\angl of $X$ and $Y$, $\exp(-Y)\exp X\in H$. Since $X',X''\in U$ and \eqref{eq:UUV}, 
\[
  e^{-Y}e^{X}\in V\cap H.
\]
Then there exists a $Z$ in $\mU_h$ such that $\exp X=\exp Y\exp Z$, but $U$ is a subset of $\mU_m$ (so that $(A,B)\to e^Ae^B$ is diffeomorphic), then $X=Y$ and $Z=0$.

Since $\pi$ is bijective on $\psi(U)$, it is homeomorphic because the topology is build in order for $\pi$ to be open and continuous.

On a third hand, $U\times\mU_h$ is a neighbourhood of $(0,0)$ in $\mU_m\times\mU_h$, so that $e^Ue^{\mU_h}$ is a neighbourhood of $e$ in $G$. Since $\pi$ is open, $\pi(\exp U\exp \mU_h)=\pi(\psi(U))$ is a neighbourhood of $p_0$ in $G/H$.
\end{proof}


Let $N_0$ be the interior of $\pi(\psi(U))$ and $\{X_1,\ldots, X_r\}$ a basis of $\lM$. If $g\in G$, we looks at the map
\[
  \pi(g\cdot e^{x_1X_1+\ldots+x_rX_r})\to(x_1,\ldots,x_r).
\]
This is an homeomorphism from $g\cdot N_0$ to an open subset of $\eR^r$ because $\pi$ is homeomorphic from $U$. With this chart, $G/H$ is an analytic manifold \nomenclature{$G/H$}{as analytic manifold} and moreover if $x\in G$, the map
\begin{equation}\label{eq:tau_x_y}
  \dpt{\tau(x)}{[y]}{[xy]}
\end{equation}
is an analytic diffeomorphism of $G/H$. Let us prove it. If we consider $[x]\in G/H$, we can write $x=gm$ for a certain $m\in\psi(U)$. Hence the chart around $[x]$ will be around $[gm]=[ge^{x_1X_1+\ldots+x_rX_r}]$ (in other word, we can find an open set around $[x]$ on which can be parametrised so). We can forget the $g$ because the action is a diffeomorphism. Then we looks at the chart $\dpt{\varphi}{G/H}{\eR^r}$, $\varphi[e^{x_1X_1+\ldots+x_rX_r}]=(x_1,\ldots,x_r)$. The map \eqref{eq:tau_x_y} makes $(y_1,\ldots,y_r)\to( CBH_1(x_1,\ldots,x_r,y_1,\ldots y_r),\ldots, CBH_r(x_1,\ldots,x_r,y_1,\ldots y_r))$. But $CBH$ is a diffeomorphism.


The following theorem is the theorem 4.2, chapter II in \cite{Helgason}
\begin{theorem}\label{Helgason4.2}\label{tho:struc_anal}
Let $G$ be a Lie group, $H$ a closed subgroup of $G$ and $G/H$ with the natural topology. Then $G/H$ has an unique analytic structure with the property that $G$ is a Lie transformation group of $G/H$.
\end{theorem}

\begin{proof}
We denote by $\UU$ the interior of the $U$ given by the lemma \ref{lem:vois_U}, and $B=\psi(\UU)\subset G$. Since $\dpt{\phi}{(A,B)}{\exp A\exp B}$ is a diffeomorphism, $\psi(\UU)=\phi(U,0)$ is a submanifold of $G$. We consider the following diagram :
\[
\xymatrix{
    G\times B  \ar[d]_{\displaystyle I\times\pi}\ar[r]^{\displaystyle\Phi}    &     
                                                                     G\ar[d]^{\displaystyle\pi}\\
    G\times N_0 &                                                             G/H
  }\]
with, for $g\in G$ and $x\in B$,
\[
I\times\pi\colon (g,x)\mapsto (g,[x])
\]
and
\[
\Phi\colon (g,x)\mapsto gx.
\]

\noindent The classes $[x]$ are taken with respect to $H$. The map $\dpt{\mu}{G\times N_0}{G/H}$, $\mu(g,[x])=[gx]$ can be written under the form
\[
   \mu=\pi\circ\Phi\circ(I\times\pi)^{-1}
\]
which is analytic\footnote{Notice that the inverse of $I\times\pi$ exists because $\pi$ is homeomorphic on the spaces considered here.}. So $G$ is a Lie transformation group on $G/H$.

% Faut encore taper l'unicité
\end{proof}


\begin{lemma}[Category theorem] \label{lem:categ}
If a locally compact space $M$ can be written as a countable union
\begin{equation}\label{eq:M_union}
   M=\bigcup_{n=1}^{\infty}M_n
\end{equation}
where each $M_i$ is closed in $M$, then at least one of them contains an open subset of $M$.
\end{lemma}

\begin{proof}
We suppose that none of the $M_i$ contains an open subset of $M$. Let $U_1$ be an open whose closure is compact, $a_1\in U_1\setminus M_1$ and a neighbourhood $U_2$ of $a_1$ such that $\overline{U}_2\subset U_1$ and $\overline{U_2}\cap M_1=\varnothing$. Let $a_2\in U_2\setminus M_2$ and a neighbourhood $U_3$ of $a_2$ such that $\overline{U_3}\subset U_2$ and $\overline{U_3}\cap M_2=\varnothing$\ldots and so on. The existence of the $a_i$ comes from the fact that $U_j$ is open, so that it is contained in no one of the $M_k$.

The decreasing sequence $\overline{U}_1,\overline{U}_2 ,\ldots$ is made up from non empty compacts sets. Then $\bigcap_{i=1}^{\infty}U_i\neq\emptyset$ and the elements of this intersection are in none of the $M_i$; this contradict \eqref{eq:M_union}.
\end{proof}


\begin{theorem} \label{tho:homeo_action}
Let $G$ be a locally compact group with a countable basis. Suppose that it is a transitive, locally compact and Hausdorff topological group of transformation on $M$. Consider $p\in M$ and $H=\{g\in G\tq g\cdot p=p\}$. Then 
\begin{enumerate}
\item $H$ is closed,
\item the map $[g]\to g\cdot p$ is homeomorphic between  $G/H$ and $M$.
\end{enumerate}
\end{theorem}

\begin{proof}
By definition of a group action, the map $\dpt{\varphi}{G}{M}$, $\varphi(g)=g\cdot p$ is continuous. Then $H=\varphi^{-1}(p)$ is closed in $G$.

As usual, the topology considered on $G/H$ is a topology which makes the canonical projection $\dpt{\pi}{G}{G/H}$ continuous and open. Now we study the map $\dpt{\psi}{G/H}{M}$, $\psi([g])=g\cdot p$ which is well defined because $H$ fixes $p$ by definition. It is clearly injective, and it is surjective because the action is transitive.

Now remark that $\psi=\varphi\circ\pi^{-1}$. Since $\pi$ is continuous and open, and $\varphi$ is continuous, it just remains to be proved that $\varphi$ is open in order for $\psi$ to be continuous and open. In order to do it, consider $V$, an open subset of $G$, $g\in V$ and a compact neighbourhood $U$ of $e$ in $G$ such that $U=U^{-1}$ and $gU^2\subset V$. If $U$ is small and $u$, $v\in U$ close to $e$, then $guv$ can keep in $V$, so that such a $U$ exists.

We can find a sequence $(g_n)$ in $G$ such that $G=\bigcup_ng_nU$; the transitivity of $G$ on $M$ implies that 
\[
  M=\bigcup_ng_nU\cdot p.
\]
Each term in this union is compact, and therefore closed in $M$. By lemma \ref{lem:categ}, one of the $g_nU\cdot p$ contains an open subset of $M$. Since the action ``$g\cdot$''\ is continuous, $U\cdot p$ also contains an open subset in $M$. The conclusion is that one can find a $u\cdot p$ in the interior of $M$, and $p$ is then an interior point of $u^{-1} U\cdot p\subset U^2\cdot p$. Then $g\cdot p$ in in the interior of $V\cdot p$ and $\varphi$ is therefore open.
\end{proof}

\begin{proposition}
Let $G$ be a transitive transformation Lie group on a $\Cinf$ manifold $M$. Consider $p_0\in M$ and $H$, the stabilizer of $p_{0}$ :
\[
  H=\{ g\in G\tq g\cdot p_0=p_0 \}.
\]
Let
\begin{equation}
\begin{aligned}
 \alpha\colon G/H&\to M \\ 
[g]&\mapsto g\cdot p_{0}.
\end{aligned}
\end{equation}
We have :
\begin{enumerate}
\item The stabilizer $H$ is closed in $G$.
\item If $\alpha$ is homeomorphic, then it is diffeomorphic (if $G/H$ has the analytic structure of theorem \ref{tho:struc_anal}).
\item If $\alpha$ is homeomorphic and if $M$ is connected, then $G_0$, the identity component of $G$, is transitive on $M$.
\end{enumerate}
\label{propHelgason4.3}
\end{proposition}

This comes from \cite{Helgason}, chapter 2, proposition 4.3. The interest of this theorem is the fact that one only has to check the continuity of $\alpha$ and $\alpha^{-1}$ in order to have a diffeomorphism $M\simeq G/H$.

\begin{proof}
\subdem{The group $H$ is closed in $G$}
We consider the map $\dpt{\varphi}{G}{M}$, $\varphi(g)=g\cdot p_0$. This is continuous; therefore $\varphi^{-1}(p_0)$ is closed. Remark that we are in the situation of theorem \ref{tho:homeo_action} 

\subdem{First item}  
We will use lemma \ref{lem:vois_U}. Se denotes by $\lH$, the Lie algebra of $H$ and we consider a $\lM$ such that $\lG=\lM\oplus\lH$; the lemma \ref{lem:vois_U} assure us that we have a neighbourhood $U$ of $0$ in $\lM$ on which $\psi$ is homeomorphic and such that $\pi$ sends homeomorphically $\psi(U)$ to a neighbourhood of $p_0$ in $G/H$. We define $\UU$, the interior of $U$, $B=\psi(\UU)$ and $N_0$, the interior of $\pi(\psi(U))$.

The set $B$ is a submanifold of $G$, diffeomorphic to $N_0$ by $\pi$ because everything is continuous and then everything respect the interiors.
 
\begin{probleme}
C'est n'importe quoi comme justification. C'est lié au problème \ref{prob:diffeo_2}.
\label{prob:diffeo_1}
\end{probleme}
 
Consider $\dpt{\iota}{B}{G}$, the identity and $\dpt{\beta}{G}{M}$, $\beta(g)=g\cdot p_0$. The restriction $\alpha_{N_0}$ of $\alpha$ to $N_0$ is an homeomorphism (this is a part of the assumptions) from $N_0$ to an open subset of $M$ : $N_0$ is open (this is an interior), then its image by an homeomorphism is open.

Now we can see that $\alpha_{N_0}$ is differentiable. The reason is that it can be written as $\alpha_{N_0}=\dpt{\beta\circ\iota\circ\pi^{-1}}{N_0}{M}$. The construction makes $\pi$ a diffeomorphism and $\beta$ a diffeomorphism when $G$ is a Lie group of transformations (as it is the case here); $\iota$ is clear. Now we have to see that the whole $\alpha$ is also differentiable, and then we will have to prove the same for $\alpha^{-1}$.

By definition, $\alpha([g])=g\cdot p_0$ (the classes $[g]$ is taken with respect to $H$). Consider $[n]\in H$; for any $g\in G$, one can write $[g]=[gn^{-1} n]$. Then
\begin{equation}
  \alpha([g])=\alpha([gn^{-1} n])
             =gn^{-1} n\cdot p_0
	     =gn^{-1}\alpha([n])
	     =gn^{-1}\cdot\alpha_{N_0}([n]),
\end{equation}
but the last dot denotes a differentiable action, and $\alpha_{N_0}$ is differentiable. Thus $\alpha$ is differentiable.

In order for $\alpha$ to be a diffeomorphism, we still have to prove that $\alpha^{-1}$ is differentiable., we begin to show that the Jacobian of $\beta$ at $g=e$ has rank $r_{\beta}=\dim M$. We looks at $\dpt{d\beta_e}{\lG}{T_{p_0}M}$, and consider $X\in\ker (d\beta_e)$. For $f\in\Cinf(M)$, we compute
\begin{equation}
  0=(d\beta_e X)f=X(f\circ\beta)=\Dsdd{ f(e^{tX}\cdot p_0) }{t}{0}.
\end{equation}
Let $s\in\eR$, and we write this equation for $f^*$ instead of $f$, which $f^*$ defined by $f^*(q)=f(e^{sX}\cdot q)$ for each $q\in M$:
\begin{equation}
  0=\Dsdd{f^*(e^{tX}\cdot p_0)}{t}{0}
      =\Dsdd{ f(e^{(s+t)X}\cdot p_0) }{t}{0}
      =\Dsdd{ f(e^{tX}\cdot p_0) }{t}{s}.
\end{equation}
Thus $f(e^{sX}\cdot p_0)$ is a constant with respect to $s$. Since $f$ is arbitrary, $e^{sX}\cdot p_0=p_0$ for any $s$. So $X\in\lH$ because $\exp sX\in H$ for any $s$. Then $\ker d\beta_e\subset \lH$.

On the other hand, $\lH\subset\ker d\beta_e$ is clear, then
\[
   \ker d\beta_e=\lH
\]
and $r_{\beta}=\dim\lG-\dim\lH$.

Since $\alpha$ is an homeomorphism, the dimension of the origin and the target space are the same: $\dim G/H=\dim M$. On the other hand, lemma \ref{lem:dim_G_H} gives $\dim G/H=\dim\lG-\dim\lH$, so that $r_{\beta}=\dim M$.

Now we prove that $\alpha^{-1}$ is differentiable. Remark that $\beta(g)=g\cdot p_0$ and $\alpha([g])=g\cdot p_0=\beta(g)$ is a good definition for $\alpha$ because the class are taken with respect to the stabilizer of $p_0$. Since $r_{\beta}=\dim M$, the map $\beta$ is locally a diffeomorphism from a neighbourhood of $e$ to a neighbourhood of $p_0$.

If $p=g\cdot p_0$, $\alpha^{-1}(p)=[g]$ because $[k]\in\alpha^{-1}(o)$ if $\alpha([k])=p$, i.e. $k\cdot p_0=p$. But $k=gr$ for a certain $r\in G$. It is clear that $p=k\cdot p_0=gr\cdot p_0$. In particular, $g\cdot(r\cdot p_0)$. We know that in general $g\cdot p=g\cdot q$ implies $p=q$; here it gives us $r\in H$, so that $k\in [g]$.

We consider a $n\in G$ such that $n\cdot$ and $n^{-1}\cdot$ are diffeomorphic. We can make the following manipulation :
\begin{equation}
   \alpha^{-1}(p)=[g]
                =[gnn^{-1}]
		=\pi(gn)\alpha^{-1}(n^{-1}\cdot p_0).
\end{equation}
Under this form, $\alpha^{-1}$ is diffeomorphic.


\subdem{Second item}
If $\alpha$ is an homeomorphism, then $\beta$ is open. Let us denote by $G_0$ the identity component of $G$. There exists a subset $\{x\bgamma\tq\gamma\in I\}$ of $G$ such that
\[
    G=\bigcup_{\gamma\in I}G_0x\bgamma.
\]
This comes from the fact that the components are all some left translations of the identity component (this is true for any Lie group). Each orbit $G_0x\bgamma\cdot p_0$ is open in $M$ and two orbits are either disjoint either equals. Since $M$ is connected, all these orbits must coincide; thus each orbit contains the whole $M$. In particular, the orbit $G_0\cdot p_0=M$ : $G_0$ is transitive on $M$.

\end{proof}

\begin{probleme}
Il parra\^it que \c ca donne l'unicit\'e pour \ref{tho:struc_anal}.
\end{probleme}


\begin{lemma}
Let $G$ be a connected Lie group with Lie algebra $\lG$. If $\dpt{\varphi}{G}{X}$ is an analytic homomorphism ($X$ is a Lie group with Lie algebra $\lX$), then

\begin{enumerate}
\item The kernel $\varphi^{-1}(e)$ is a topological Lie subgroup of $G$; his algebra is the kernel of $d\varphi_e$.
\item The image $\varphi(G)$ is a Lie subgroup of $X$ whose Lie algebra is $d\varphi(\lG)\subset\lX$.
\item The quotient group $G/\varphi^{-1}(e)$ with his canonical analytic structure is a Lie group. The map $g\varphi^{-1}(e)\mapsto\varphi(g)$ is an analytic isomorphism $G/\varphi^{-1}(e)\to\varphi(G)$. In particular the map $\dpt{\varphi}{G}{\varphi(G)}$ is analytic.
\end{enumerate}
\label{lem:vp_G_X}
\end{lemma}

\begin{proof}
\subdem{First item} We know that a subgroup $H$ closed in $G$ admits an unique analytic structure such that $H$ becomes a topological Lie subgroup of $G$. This is the case of $\varphi^{-1}(e)$. We know that $Z\in\lG$ belongs to the Lie algebra of $\varphi^{-1}(e)$ if and only if $\varphi(\exp tZ)=e$ for any $t\in\eR$. But $\varphi(\exp tZ)=\exp(td\varphi(Z))=e$ if and only if $d\varphi(Z)=0$.

\subdem{Second item}
Consider $X_1$, the analytic subgroup of $X$ whose Lie algebra is $d\varphi(\lG)$. The group $\varphi(G)$ is generated by the elements of the form $\varphi(\exp Z)$ for $Z\in\lG$. The group $X_1$ is generated by the $\exp(d\varphi Z)$. Because of lemma \ref{lemsur5d}, these two are the same. Then $\varphi(G)=X_1$ and their Lie algebras are the same.

\subdem{Third item}
We consider $H$, a closed normal subgroup of $G$; this is a topological subgroup and the quotient $G/H$ has an unique analytic structure such that the map $G\times G/H\to G/H$, $(g,[x])\to [gx]$ is analytic. We consider a decomposition $\lG=\lH\oplus\lM$ and we looks at the restriction $\dpt{\psi}{\lM}{G}$ of the exponential. Then there exists a neighbourhood $U$ of $0$ in $\lM$ which is homomorphically send by  $\psi$ into an open neighbourhood of $e$ in $G$ and such that $\dpt{\pi}{G}{G/H}$ sends homomorphically $\psi(U)$ to a neighbourhood  of $p_0\in G/H$ (cf. lemma \ref{lem:vois_U}).

We consider $\UU$, the interior of $U$ and $B=\psi(\UU)$. The following diagram is commutative :
\begin{equation}
 \xymatrix{
    G\times G/H  \ar[rr]^{\displaystyle\Phi}\ar[dr]_{\displaystyle \pi\times I} &&  G/H\\
     &     G/H\times G/H\ar[ur] _{\displaystyle\alpha}
  }
\end{equation}
with $\Phi(g,[x])=[g^{-1} x]$, $(\pi\times I)(g,[x])=([g],[x])$ and $\alpha([g],[x])=[g^{-1} x]$. Indeed, 
\[
   \alpha\circ(\pi\times I)(g,[x])=\alpha([g],[x])=[g^{-1} x].
\]
In order to see that $\alpha$ is well defined, remark that if $[h]=[g]$ and $[y]=[x]$ $[g^{-1} x]=[h^{-1} y]$ because $H$ is a normal subgroup of $G$.

Now, we consider $g_0,x_0\in G$ and the restriction of $(\pi\times I)$ to $(g_0B)\times(G/H)$. Since $\pi$ is homeomorphic on $\psi(U)$ and $B=\psi(\UU)$, on $g_0B$, $\pi$ is a diffeomorphism (because the multiplication is diffeomorphic as well)

\begin{probleme}\label{prob:diffeo_2}
    Why is the \( \pi\) a diffeomorphism ? I understand why it is qn homeomorphism, but no more.
\end{probleme}

This diffeomorphism maps to a neighbourhood $N$ of $([g_0],[x_0])$ in $G/H\times G/H$. From the commutativity, we know that $\alpha=\Phi\circ(\pi\times I)^{-1}$, so that $\alpha$ is analytic. Consequently, $G/H$ is a Lie group. On $N$, $\alpha$ is analytic, then $\alpha(N)$ is analytic.

All this is for a closed normal subgroup $H$ of $G$. Now we consider $H=\varphi^{-1}(e)$ and $\lH$, the Lie algebra of $H$. From the first item, we know that the Lie algebra of $H$ is the kernel of $d\varphi$ : $\lH=d\varphi^{-1}(0)$ which is an ideal in $\lG$.

From the second point, the Lie algebra of $G/H$ is $d\pi(\lG)$ which is isomorphic to $\lG/\lH$; the bijection is $\gamma(d\pi(X))=[X]\in\lG/\lH$. In order to prove the injectivity, let us consider $\gamma(A)=\gamma(B)$; $A=d\pi(X)$, $B=d\pi(Y)$. The condition is $[X]=[Y]$; thus it is clear that $d\pi(X)=d\pi(Y)$

Let us consider on the other hand the map $Z+\lH\to d\varphi(Z)$ for $Z\in\lG$\footnote{Note that $\lG$ and $\lH$ are not groups; by $[X]$, we mean $[X]=\{ X+h\tq h\in\lH \}$.}. In other words, the map is $[Z]\to d\varphi(Z)$. This is an isomorphism $\lG/\lH\to d\varphi(\lG)$, which gives a local isomorphism between $G/H$ and $\varphi(G)$. This local isomorphism is $[g]\to\varphi(g)$ for $g$ in a certain neighbourhood of $e$ in $G$.

Since $[g]\to\varphi(g)$ has a differential which is an isomorphism, this is analytic at $e$. Then it is analytic everywhere.

\end{proof}


\begin{corollary}
If $G$ is a connected Lie group and if $Z$ is the center of $G$, then
\begin{enumerate}
\item $\Ad_G$ is an analytic homomorphism from $G$ to $\Int(G)$, with kernel $Z$,
\item the map $[g]\to\Ad_G(g)$ is an analytic isomorphism from $G/Z$ to $\Int(\lG)$ (the class $[g]$ is taken with respect to $Z$).
\end{enumerate}
\label{cor:Ad_homom}
\end{corollary}
    

\begin{proof}
\subdem{First item}
A connected Lie group is generated by a neighbourhood of identity, and any element of a suitable such neighbourhood can be written as the exponential of an element in the Lie algebra. So $\Int(\lG)$ is generated by elements of the form $\exp(\ad X)=\Ad(\exp X)$; this shows that $\Int(\lG)\subset\Ad(G)$. In order to find the kernel, we have to  see $\Ad_G^{-1}(e)$ by the formula 
\[ 
   e^{\Ad(g)X}=g e^Xg^{-1}.
\]
We have to find the $g\in G$ such that $\forall X\in\lG$, $\Ad_G(g)X=X$. We taking the exponential of the two sides and using \eqref{eq:sigma_X_sigma},
\begin{equation}
  g e^Xg^{-1}=e^X.
\end{equation}
Then $g$ must commute with any $e^X\in G$ : in other words, $g$ is in the kernel of $G$.

\subdem{Second item}
This is contained in lemma \ref{lem:vp_G_X}. Indeed $G$ is connected and we had just proved that $\dpt{\Ad_G}{G}{\Int(\lG)}$ with kernel $Z$; the third item of lemma \ref{lem:vp_G_X} makes $G/Z$ a Lie group and the map $[g]\to\Ad_G(g)$ an analytic isomorphism from $G/Z$ to $\Ad_G(G)=\Int(\lG)$.
\end{proof}


\begin{lemma}
Let $G_1$ and $G_2$ be two locally isomorphic connected Lie groups with trivial center (i.e. $\lG_1=\lG_2=\lG$ and $Z(G_i)=\{ e \}$). In this case, we have $G_1=G_2=\Int(\lG)$ where $\Int\lG$ stands for the group of internal automorphism of $\lG$.
\end{lemma}

\begin{proof}
We denote by $G_0$ the group $\Int\lG$. The adjoint actions $\Ad_i\colon G_i\to G_0$ are both surjective because of corollary \ref{cor:Ad_homom}. Let us give an alternative proof for injectivity. Let $Z_i=\ker(\Ad_i)=\{ g\in G_i\tq\Ad(g)X=X,\,\forall X\in\lG \}$. Since $G_i$ is connected, it is generated by any neighbourhood of the identity in the sense of proposition \ref{PropUssGpGenere}; let $V_0$ be such a neighbourhood. Taking eventually a subset we can suppose that $V_0$ is a normal coordinate system. So we have
\[ 
  g\exp_{G_i}(X)g^{-1}=\exp_{g_i}(X)
\]
for every $X\in V_0$. Using proposition \ref{PropUssGpGenere} we deduce that $gxg^{-1}=x$ for every $x\in G_i$, thus $g\in Z(G_i)$. That proves that $\ker(\Ad_i)\subset Z(G_i)$. The assumption of triviality of $Z(G_i)$ concludes injectivity of $\Ad_i$.
\end{proof}

\begin{corollary}
Let $\lG$ be a real Lie algebra with center $\{0\}$. Then the center of $\Int(\lG)$ is only composed of the identity.
\end{corollary}

\begin{proof}
We note $G'=\Int(\lG)$ and $Z$ his center; $\ad$ is the adjoint representation of $\lG$ and $\Ad'$, $\ad'$, the ones of $G'$ and $\ad(\lG)$ respectively. We consider the map $\dpt{\theta}{G'/Z}{\Int(\ad(\lG))}$, $\theta([g])=\Ad'(g)$. By the second item of the corollary \ref{cor:Ad_homom}, $[g]\to\Ad_{G'}(g)$ is an analytic homomorphism from $G'$ to $\Int(\lG')$ where $\lG'$ is the Lie algebra of $G'$; this is $\ad(\lG)$. So $\dpt{\theta}{G'/Z}{\Int(\lG')}$ is isomorphic.

Now we consider the map $\dpt{s}{\lG}{\ad(\lG)}$, $s(X)=\ad(X)$; this is an isomorphism. We also consider $\dpt{S}{G'}{ \GL(\ad(\lG))}$, $S(g)=s\circ g\circ s^{-1}$. The Lie algebra of $S(G')$ is $\ad(\lG')=\ad\big(\ad(\lG)\big)$. Then $S(G')$ is the subset of $\GL(\ad\lG)$ whose Lie algebra is $\ad\big(\ad\lG\big)$, i.e. exactly $\Int(\ad\lG)$. So $S$ is an isomorphism $\dpt{S}{G'}{\Int(\ad\lG)}$. From all this,
\begin{equation}
   S(e^{\ad X})=s\circ e^{\ad X}\circ s^{-1}
               =e^{\ad'(\ad X)}
           =\Ad'(e^{\ad X}).        
\end{equation}
With this equality, $\dpt{S^{-1}\circ\theta}{G'/Z}{G'}$ is an isomorphism which sends $[g]$ on $g$ for any $g\in Z$. Then $Z$ can't contains anything else than the identity.
\end{proof}

If we relax the assumptions of the trivial center, we have a counter-example with $\lG=\eR^3$ and the commutations relation
\[
   [X_1,X_2]=X_3,\quad [X_1,X_3]=[X_2,X_3]=0.
\]
The group $\Int(\lG)$ is abelian; then his center is the whole group, although $\lG$ is not abelian.

Note that two groups which have the same Lie algebra are not necessarily isomorphic. For example the sphere $S^2$ and $\eR^2$ both have $\eR^2$ as Lie algebra. But two groups with same Lie algebra are locally the same. More precisely, we have the following lemma.

\begin{lemma}
If $G$ is a Lie group and $H$, a topological subgroup of $G$ with the same Lie algebra ($\lH=\lG$), then there exists a common neighbourhood $A$ of $e$ of $G$ and $G$ on which the products in $G$ and $H$ are the same.
\end{lemma}

\begin{proof}
The exponential is a diffeomorphism between $U\subset\lG$ and $V\subset G$ and between $U'\subset\lH$ and $W\subset H$ (obvious notations). We consider an open $\mO\subset\lH$ such that $\mO\subset U\subset U'$. The exponential is diffeomorphic from $\mO$ to a certain open $A$ in $G$ and $H$. Since $H$ is a subgroup of $G$, the product $e^Xe^Y$ of elements in $A$ is the same for $H$ and $G$. (cf error \ref{err:gp_meme_alg})
\end{proof}

Under the same assumptions, we can say that $H$ contains at least the whole $G_0$ because it is generated by any neighbourhood of the identity. Since $H$ is a subgroup, the products keep in $H$.

For a semisimple Lie group, the Lie algebras $\partial(\lG)$ and $\ad(\lG)$ are the same. Then $\Int(\lG)$ contains at least the identity component of $\Aut(\lG)$. Since $\Int(\lG)$ is connected, for a semisimple group, it is the identity component of $\Aut(\lG)$.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
\section{Jordan decomposition}\index{Jordan decomposition}\index{decomposition!Jordan}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

If $V$ is a finite dimensional space, a subspace $W$ in $V$ is \defe{invariant}{invariant!vector subspace} under a subset $G\subset\Hom(V,V)$ if $sW\subset W$ for any $s\in G$. The space $V$ is \defe{irreducible}{irreducible!vector space} when $V$ and $\{0\}$ are the only two invariant subspaces. The set $G$ is \defe{semisimple}{semisimple} if any invariant subspace has an invariant complement. In this case, the vector space split into $V=\sum_iV_i$ with $V_i$ invariant and irreducible.

% Reformulate these two ``Jorand'' theorems.
\begin{theorem}[Jordan decomposition]\index{Jordan decomposition}\index{decomposition!Jordan}
Any element $A\in\Hom(V,V)$ is decomposable in one and only one way as $A=S+N$ with $S$ semisimple and $N$ nilpotent and $NS=SN$. Furthermore, $S$ and $N$ are polynomials in $A$. More precisely :

If $V$ is a complex vector space and $A\in\Hom(V,V)$ with $\lambda_1,\ldots,\lambda_r$ his eigenvalues, we pose 
\[
V_i=\{ v\in V\tq (A-\lambda_i\mtu)^kv=0 \textrm{ for large enough $k$}\}.
\]
Then

\begin{enumerate}\label{tho:jordan}
\item $V=\sum_{i=1}^rV_i$,
\item each $V_i$ is invariant under $A$,
\item the semisimple part of $A$ is given by
\[
   S(\sum_{i=1}^rv_i)=\sum_{i=1}^r\lambda_iv_i,
\]
for $v_i\in V_i$,

\item the characteristic polynomial of $A$ is
\[
  \det(\lambda\mtu-A)=(\lambda-\lambda_1)^{d_1}\ldots(\lambda-\lambda_r)^{d_r}
\]
where $d_i=\dim V_i$ ($1\leq i\leq r$).
\end{enumerate}
\end{theorem}

Now we give a great theorem without proof.
\begin{theorem}[Jordan decomposition]
Let $V$ be a finite dimensional vector space and $x\in\End{V}$. 

\begin{enumerate}
\item There exists one and only one choice of $x_s,x_n\in\End(V)$ such that $x=x_s+x_n$, $x_s$ is semisimple, $n_n$ is nilpotent and $[x_s,x_n]=0$.

\item There exists polynomials $p$ and $q$ without independent term such that $x_s=p(x)$, $x_n=q(x)$; in particular if $y\in\End{V}$ commutes with $x$, then it commutes with $x_s$ and $x_n$.

\item If $A\subset B\subset V$ are subspaces of $V$ and if $x(B)\subset A$, then $x_s(B)\subset A$ and $x_n(B)\subset A$.
\end{enumerate}
\label{prop:Jordan_decomp}
\end{theorem}

\begin{lemma}\label{lem:Jordan_ad}
    Let $x\in\End{V}$ with his Jordan decomposition $x=x_s+x_n$. Then the Jordan decomposition of $\ad x$ is
    \begin{equation}\label{eq:ad_x_xs_xn}
       \ad x=\ad x_s+\ad x_n.
    \end{equation}
\end{lemma}

\begin{proof}
We already know that $\ad x_s$ is semisimple and $\ad x_n$ is nilpotent. They commute because $[\ad x_s,\ad x_n]=\ad[x_s,x_n]=0$. Then the unicity part of Jordan theorem \ref{prop:Jordan_decomp} makes \eqref{eq:ad_x_xs_xn} the Jordan decomposition of $\ad x$.
\end{proof}

\begin{lemma}\label{lem:M_nil}
Let $A\subset B$ be two subspace of $\gl(V)$ with $\dim V<\infty$. We pose 
\[
   M=\{x\in\gl(V)\tq [x,B]\subset A\},
\]
and we suppose that $x\in M$ verify $\tr(x\circ y)=0$ for all $y\in M$. Then $x$ is nilpotent.
\end{lemma}

\begin{proof}
We use the Jordan decomposition $x=x_s+x_n$ and a basis in which $x_s$ takes the form $diag(a_1,\ldots,a_m)$; let $\{v_1,\ldots,v_m\}$ be this basis. We denotes by $E$ the vector space on $\eQ$ spanned by $\{a_1,\ldots,a_m\}$. We want to prove that $x_s=0$, i.e. $E=0$. Since $E$ has finite dimension, it is equivalent to prove that its dual is zero. In other words, we have to see that any linear map $\dpt{f}{E}{\eQ}$ is zero.

We consider $y\in\gl(V)$, an element whose matrix is $diag(f(a_1),\ldots,f(a_m))$ and $(E_{ij})$, the usual basis of $\gl(V)$. We know that 
\begin{subequations}
\begin{align}
  (\ad x_s)E_{ij}&=(a_i-a_j)E_{ij},\\
  (\ad y)E_{ij}&=(f(a_i)-f(a_j))E_{ij}.
\end{align}
\end{subequations}
It is always possible to find a polynomial $r$ on $\eR$ without constant term such that $r(a_i-a_j)=f(a_i)-f(a_j)$. Note that this is well defined because of the linearity of $f$ : if $a_i-a_j=a_k-a_l$, then $f(a_i)-f(a_j)=f(a_k)-f(a_l)$. Since $\ad x_s$ is diagonal, $r(\ad x_s)$ is the matrix with $r(\ad x_s)_{ii}$ on the diagonal and zero anywhere else. Then $r(\ad x_s)=\ad y$. By lemma \ref{lem:Jordan_ad}, $\ad x_s$ is the semisimple part of $\ad x$, then $\ad y$ is  a polynomial without constant term with respect to $\ad x$ (second point of theorem \ref{prop:Jordan_decomp}).

Since $(\ad y)B\subset A$, $y\in M$ and $\tr(xy)=0$. It is easy to convince ourself that the $s_n$ part of $x$ will not contribute to the trace because $x_n$ is strictly upper triangular and $y$ is diagonal. From the explicit forms of $x_s$ and $y$,
\[
  \tr(xy)=\sum_ia_if(a_i)=0.
\]
This is a $\eQ$-linear combination of element of $E$ : we have to see it as $a_i$ being a basis vector and $f(a_i)$ a coefficient, so that we can apply $f$ on both sides to find $0=\sum_if(a_i)^2$. Then for all $i$, $f(a_i)=0$, so that $f=0$ because  the $a_i$ spans $E$.
\end{proof}

\begin{definition}[semisimple endomorphism]\index{semisimple!endomorphism}
    If $V$ is a finite dimensional vector space, we say that an element $u\in\End{V}$ is \defe{semisimple}{semisimple!endomorphism}\label{pg:def_semisimple} if every \( u\)-invariant subspace of \( V\) has a complementary \( u\)-invariant.
\end{definition}

\begin{proposition}[\cite{SIUaYwD}]
    If \( V\) a vector space over an algebraically closed field, an endomorphism is semisimple if and only if it is diagonalizable.
\end{proposition}
% TODO : give the proof; it is easy.

\label{pg:E_ij}Let $E_{kl}$ be the $(n+2)\times(n+2)$ matrix with a $1$ at position $(k,l)$ and $0$ anywhere else: $(E_{kl})_{ij}=\delta_{ki}\delta_{lj}$. An easy computation show that \nomenclature{$E_{ij}$}{Matrix full of zero's and $1$ at position $ij$}
\begin{equation}        \label{EqFormMulEmtr}       %\label{EqJsqnmunmtu}       Ce second label est certainement une erreur.
    E_{kl}E_{ab}=\delta_{la}E_{kb},
\end{equation}
and
\begin{equation}\label{comm_de_E}
    [E_{kl},E_{rs}]=\delta_{lr}E_{ks}-\delta_{sk}E_{rl}.
\end{equation}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Killing form}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

The \defe{Killing form}{Killing!form} of $\mG$ is the symmetric bilinear form :
\begin{equation}
             B(X,Y)=Tr(\ad X\circ \ad Y).
\end{equation}
It is \defe{invariant}{invariant!form} in the sense of
\begin{equation}                        \label{eq:Killing_invariant}
     B\big((\ad S)X,Y\big)=-B\big(X,(\ad S)Y\big),
\end{equation}
$\forall X$, $Y$, $S\in\mG$.

\begin{proposition} \label{PropAutomInvarB}
If $\dpt{\varphi}{\mG}{\mG}$ is an automorphism of $\mG$, then 
\[
   B(\varphi(X),\varphi(Y))=B(X,Y).
\]
\label{prop:auto_2}
\end{proposition}
 
\begin{proof}
The fact that $\varphi$ is an automorphism of $\mG$ is written as $\varphi\circ\ad X=\ad(\varphi(X))\circ\varphi$, or
\[
  \ad(\varphi(X))=\varphi\circ\ad X\circ\varphi^{-1}.
\]
Then
\begin{equation}
\begin{split}
\tr(\ad(\varphi(X))\circ\ad(\varphi(Y)))&=\tr(\varphi\circ\ad X\circ\varphi^{-1}\circ\varphi\ad Y\circ\varphi^{-1})\\
                                &=\tr(\ad X\circ\ad Y).
\end{split}
\end{equation}
\end{proof}


\begin{remark}
The Killing $2$-form is a map $\dpt{B}{\mG\times\mG}{\eR}$. When we say that it is preserved by a map $\dpt{f}{G}{G}$, we mean that it is preserved by $df$ : $B(df\cdot,df\cdot)=B(\cdot,\cdot)$.
\end{remark}

An other important property of the Killing form is its bi-invariance.

\begin{theorem}
The Killing form is bi-invariant\index{Killing!form!bi-invariance} on $G$.
\label{tho:bi_invariance}
\end{theorem}

\begin{remark}
The Killing form is \emph{a priori} only defined on $\mG=T_eG$. For $A$, $B\in T_gG$, one naturally defines
\begin{equation}
  B_g(A,B)=B(dL_{g^{-1}}A,dL_{g^{-1}}B).
\end{equation}
This assures the left invariance of $B$. Now we prove the right invariance.
\end{remark}


\begin{proof}[Proof of theorem \ref{tho:bi_invariance}]
Because of the left invariance,
\[
  B(dR_gX,dR_gY)=B(dL_{g^{-1}}dR_gX,dL_{g^{-1}}dR_gY)=B(\Ad_{g^{-1}}X,\Ad_{g^{-1}}Y).
\]
But $\Ad_{g^{-1}}=d(\AD_{g^{-1}})$ and $\AD_{g^{-1}}$ is an automorphism of $G$. Thus by lemma \ref{lem:auto_1} and proposition \ref{prop:auto_2},
\begin{equation}                    \label{eq_KillAdinvariant}
B\big(\Ad(g^{-1})X,\Ad(g^{-1})Y\big)=B(X,Y).
\end{equation}

\end{proof}

\begin{lemma}  
Let $\lG$ be a Lie algebra and $\lI$ an ideal in $\lG$. Let $\dpt{B}{\lG\times\lG}{\eR}$ be the Killing form on $\lG$ and $\dpt{B'}{\lI\times\lI}{\eR}$, the one of $\lI$. Then $B'=B|_{\lI\times\lI}$, i.e. the Killing form on $\lG$ descent to the ideal $\lI$.
\label{lem:Killing_descent_ideal}
\end{lemma}

\begin{proof}
If $W$ is a subspace of a (finite dimensional) vector space $V$ and $\dpt{\phi}{V}{W}$ and endomorphism, then $\tr\phi=\tr(\phi|_W$). Indeed, if $\{X_1,\ldots,X_n\}$ is a basis of $V$ such that $\{X_1,\ldots,X_r\}$ is a basis of $W$, the matrix element $\phi_{kk}$ is zero for $k>r$. Then 
\[
  \tr\phi=\sum_{i=1}^{n}\phi_{ii}=\sum_{i=1}^r\phi_{ii}=\tr(\phi|_W).
\]

Now consider $X$, $Y\in\lI$; $(\ad X\circ\ad Y)$ is an endomorphism of $\lG$ which sends $\lG$ to $\lI$ (because $\lI$ is an ideal). Then
\[
B'(X,Y)=\tr\big( (\ad X\circ\ad Y)|_{\lI} \big)=\tr(\ad X\circ\ad Y)=B(X,Y).
\]
\end{proof}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Solvable and nilpotent algebras}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

If $\lG$ is a Lie algebra, the \defe{derived Lie algebra}{derived!Lie algebra}\index{Lie!algebra!derived} is 
\[
   \dD\lG=\Span\{[X,Y]\tq X,Y\in\lG\}.
\]
We naturally define $\dD^0\lG=\lG$ and $\dD^n\lG=\dD(\dD^{n-1}\lG)$ this is the \defe{derived series}{derived!series}. Each $\dD^n\lG$ is an ideal in~ $\lG$. We also define the \defe{central decreasing sequence}{central!decreasing sequence} by $\lA^0=\lA$, $\lA^{p+1}=[\lA,\lA^p]$.

\begin{definition}
The Lie algebra $\lG$ is \defe{solvable}{solvable!Lie algebra}\index{Lie!algebra!solvable} if there exists a $n\geq 0$ such that $\dD^n\lG=\{0\}$. A Lie group is solvable when its Lie algebra is\index{Lie!group!solvable}\index{solvable!Lie group}.  

    The Lie algebra  \( \lG\) is \defe{nilpotent}{nilpotent!Lie algebra} if \( \lG^n=0\) for some~\( n\). We say that \( \lG\) is \( \ad\)-nilpotent if \( \ad(X)\) is a nilpotent endomorphism of \( \lG\) for each \( X\in\lG\).
\end{definition}

Do not confuse \emph{nilpotent} and \emph{solvable} algebras. A nilpotent algebra is always solvable, while the algebra spanned by $\{ A,B \}$ with the relation $[A,B]=B$ is solvable but not nilpotent.

If $\lG\neq\{0\}$ is a solvable Lie algebra and if $n$ is the smallest natural such that $\dD^n\lG=\{0\}$, then $\dD^{n-1}\lG$ is a non zero abelian ideal in $\lG$. We conclude that a solvable Lie algebra is never semisimple (because the center of a semisimple Lie algebra is zero).

A Lie algebra is said to fulfil the \defe{chain condition}{chain!condition} if for every ideal $\lH\neq\{0\}$ in $\lG$, there exists an ideal $\lH_1$ in $\lH$ with codimension $1$.

\begin{lemma}
A Lie algebra is solvable if and only if it fulfils the chain condition.
\end{lemma}

\begin{proof}
\subdem{Necessary condition}
The Lie algebra $\lG$ is solvable (then $\dD\lG\neq\lG$) and $\lH$ is an ideal in $\lG$. We consider $\lH_1$, a subspace of codimension $1$ in $\lH$ which contains $\dD\lH$. It is clear that $\lH_1$ is an ideal in $\lH$ because $[H_1,H]\in\dD\lH\subset\lH_1$.
\subdem{Sufficient condition}
We have a sequence
\begin{equation}\label{eq:solvable_chaine}
   \{0\}=\lG_n\subset\lG_{n-1}\subset\ldots\subset\lG_0=\lG
\end{equation}
where $\lG_r$ is an ideal of codimension $1$ in $\lG_{r-1}$. Let $A$ be the unique vector in $\lG_{r-1}$ which don't belong to $\lG_r$.  When we write $[X,Y]$ with $X$, $Y\in\lG_{r-1}$, at least one of $X$ or $Y$ is not $A$ (else, it is zero) then at least one of the two is in $\lG_r$. But $\lG_r$ is an ideal; then $[X,Y]\in\lG_r$. Thus $\dD(\lG_{r-1})\subset\lG_r$ and
\[
\dD^n\lG=\dD^{n-1}\dD\lG\subset\dD^{n-1}\lG_1\subset\ldots\subset\lG_n=0.
\]
\end{proof}

\begin{theorem}[Lie theorem]\label{tho:Lie_Vu}\index{Lie!theorem}
    Consider $\lG$, a real (resp. complex) solvable Lie algebra and a real (resp. complex) vector space $V\neq\{0\}$. If $\dpt{\pi}{\lG}{\gl(V)}$ is a homomorphism, then there exists a non zero vector in $V$ which is eigenvector of all the elements of $\pi(\lG)$.
\end{theorem}

\begin{probleme}
    It is strange to be stated for real and complex Lie algebras. Following \cite{SamelsonNotesLieAlg}, this is only true for complex Lie algebras while there exists other versions for reals ones.
\end{probleme}

\begin{proof}
Let us do it by induction on the dimension of $\lG$. We begin with $\dim\lG=1$. In this case, $\pi$ is just a map $\dpt{\pi}{\lG}{\gl(V)}$ such that $\pi(aX)=a\pi(X)$. We have to find an eigenvector for the homomorphism $\dpt{\pi(X)}{V}{V}$. Such a vector exists  from the Jordan decomposition \ref{tho:jordan}. Indeed, if there are no eigenvectors, there are no spaces $V_i$ and the decomposition $V=\sum V_i$ can't be true.

Now we consider a general solvable Lie algebra $\lG$ and we suppose that the theorem is true for any solvable Lie algebra with dimension less that $\dim\lG$. Since $\lG$ is solvable, there exists an ideal $\lH$ of codimension $1$ in $\lG$; then there exists a $e_0\neq 0\in V$ which is eigenvector of all the $\pi(H)$ with $H\in\lH$. So we have $\dpt{\lambda}{\lH}{\eR}$ naturally defined by
\[
  \pi(H)e_0=\lambda(H)e_0.
\]
Now we consider $X\in\lG\setminus\lH$ and $e_{-1}=0$, $e_p=\pi(X)^pe_0$ for $p=1,2,\ldots$ We will show that $\pi(H)e_p=\lambda(H)e_p\mod(e_0,\ldots,e_{p-1})$ for all $H\in\lH$ and $p\geq 0$. It is clear for $p=0$. Let us suppose that it is true for $p$. Then
\begin{equation}
\begin{split}
  \pi(H)e_{p+1}&=\pi(H)\pi(X)e_p\\
               &=\pi([H,X])e_p+\pi(X)\pi(H)e_p\\
           &=\lambda([H,X])e_p+\pi(X)\lambda(H)e_p\\
                      &\quad\mod(e_0,\ldots,e_{p-1},\pi(X)e_0,\ldots,\pi(X)e_{p-1}).
\end{split}
\end{equation}
But we can put $\pi([H,X])$ and $\pi(X)e_i$ into the modulus. Thus we have
\[
  \pi(H)e_{p+1}=\lambda(H)e_{p+1}\mod(e_0,\ldots,e_p).
\]

Now we consider the subspace of $V$ given by $W=\Span\{e_p\}_{p=1,\ldots}$. The algebra $\pi(\lH)$ leaves $W$ invariant and our induction hypothesis works on $(\pi(\lH),W)$; then one can find in $W$ a common eigenvector for all the $\pi(H)$. This vector is the one we were looking for.
\end{proof}

\begin{corollary}
Let $\lG$ be a solvable Lie group and $\pi$ a representation of $\lG$ on a finite dimensional vector space $V$. Then there exists a basis $\{e_1,\ldots,e_n\}$ of $V$ in which all the endomorphism $\pi(X)$, $X\in\lG$ are upper triangular matrices.
\label{cor:de_Lie_Vu}
\end{corollary}

\begin{proof}
Consider $e_1\neq 0\in V$, a common eigenvector of all the $\pi(X)$, $X\in\lG$. We consider $E_1=\Span\{e_1\}$. The representation $\pi$ induces a representation $\pi_1$ of $\lG$ on the space $V/E_1$. If $V/E_1\neq\{0\}$, we have a $e_2\in V$ such that $(e_2+E_1)\in V/E_1$ is an eigenvector of all the $\pi_(X)$.

In this manner, we build a basis $\{e_1,\ldots,e_n\}$ of $V$ such that $\pi(X)e_i=0\mod(e_1,\ldots,e_i)$ for all $X\in\lG$. In this basis, $\pi(X)$ has zeros under the diagonal.
\end{proof}

\begin{theorem}
Let $V$ be a real or complex vector space and $\lG$, a subalgebra of $\gl(V)$ made up with nilpotent elements. Then

\begin{enumerate}
\item $\lG$ is nilpotent;
\item $\exists v\neq 0$ in $V$ such that $\forall Z\in\lG$, $Zv=0$;
\item There exists a basis of $V$ in which the elements of $\lG$ are matrices with only zeros under the diagonal.
\end{enumerate}
\label{tho:trois_nil}
\end{theorem}

\begin{proof}
\subdem{First item} We consider a $Z\in\lG$ and we have to see that $\ad_{\lG}Z$ is a nilpotent endomorphism of $\lG$. Be careful on a point: an element $X$ of $\lG$ is nilpotent as endomorphism of $V$ while we want to prove that $\ad X$ is nilpotent as endomorphism of $\lG$. We denote by $L_Z$ and $R_Z$, the left and right multiplication; since we are in a matrix algebra, the bracket is given by the commutator: $\ad Z=L_Z-R_Z$. We have
\begin{equation}
(\ad Z)^p(X)=\sum_{i=0}^p(-1)^p \binom{p}{i}  Z^{p-i}XZ^i
\end{equation}
There exists a $k\in\eN$ such that $Z^k=0$. For this $k$, $(\ad Z)^{2k+1}$ is a sum of terms of the form $Z^{p-i}XZ^i$ : either $p-i$ either $i$ is always bigger than $k$. But $\ad_{\lG}Z$ is the restriction of $\ad Z$ (which is defined on $\gl(V)$) to $\lG$. Then $\lG$ is nilpotent.

\subdem{Second item} Let $r=\dim\lG$. If $r=1$, we have only one $Z\in\lG$ and $Z^k=0$ for a certain (minimal) $k\in\eN$. We take $v$ such that $w=Z^{k-1}v\neq 0$ (this exists because $k$ is the minimal natural with $Z^k=0$). Then $Zw=0$.

Now we suppose that the claim is valid for any algebra with dimension less than $r$. Let $\lH$ be a strict subalgebra of $\lG$ with maximal dimension. If $H\in\lH$, $\ad_{\lG}H$ is a nilpotent endomorphism of $\lG$ which sends $\lH$ onto itself. Thus $\ad_{\lG}H$ induces a nilpotent endomorphism $H^*$ on the vector space $\lG/\lH$. We consider the set $\mA=\{H^*\tq H\in\lH\}$; this is a subalgebra of $\gl(\lG/\lH)$ made up with nilpotent elements which has dimension strictly less than $r$.

The induction assumption gives us a non zero $u\in \lG/\lH$ which is sent to $0$ by all $\mA$, i.e. $(\ad_{\lG}H)u=0$ in $\lG/\lH$. In other words, $u\in\lG\setminus\lH$ is such that $(\ad_{\lG}H)u\in\lH$.

The space $\lH+\eK X$ (here, $\eK$ denotes $\eR$ or $\eC$) of $\lG$ is a subalgebra of $\lG$. Indeed, with obvious notations,
\begin{equation}\label{eq:H_k_X}
[H+kX,H'+k'X]=[H,H']+\ad H(k'X)-\ad H'(kX)+kk'[X,X].
\end{equation}
The first term lies in $\lH$ because it is a subalgebra; the second and third therms belongs to $\lH$ by definition of $X$. The last term is zero. Since $\lH$ is maximal, $\lH+\eK X=\lG$. Then \eqref{eq:H_k_X} shows that $\lH$ is also an ideal. Now we consider
\[
  W=\{e\in V\tq\forall H\in\lH, He=0\}.
\]
Since $\dim\lH< r$, $W\neq\{0\}$ from our induction assumption. Furthermore, for $e\in W$, $HXe=[H,X]e+XHe=0$. Then $X\cdot W\subset W$. The restriction of $X$ to $W$ is nilpotent. Then there exists a $v\in W$ such that $Xv=0$. For him $Hv=0$ because $v\in W$ and $Xv=0$ by definition of $X$. Then $Gv=0$ for any $G\in\lH+\eK X=\lG$.

\subdem{Third item} Let $e_1$ be a non zero vector in $V$ such that $Ze_1=0$ for any $Z\in\lG$ (the existence comes from the second item). We consider $E_1=\Span e_1$. Any $Z\in\lG$ induces a nilpotent endomorphism $Z^*$ on the vector space $V/E_1$. If $V/E_1\neq\{0\}$, we take a $e_2\in V\setminus E_1$ such that $e_2+E_1\in V/E_1$ fulfils $Z^*(e_2+E_1)=0$ for all $Z\in\lG$. By going on so, we have $Ze_1=0$, $Ze_i=0\mod(e_1,\ldots,e_{i-1})$. In this basis, the matrix of $Z$ has zeros on and under the diagonal.
\end{proof}

\begin{corollary}
Let us consider $V$, a finite dimensional vector space on $\eK$ and $\lG$, a subalgebra of $\gl(V)$ made up with nilpotent elements. Then if $s\geq\dim V$ and $X_i\in\lG$, we have $X_1X_2\ldots X_s=0$.
\label{cor:nil_XXX}
\end{corollary}

\begin{proof}
We write the $X_i$'s in a basis where they have zeros on and under the diagonal. It is rather easy to see that each product push the non zero elements into the upper right corner.
\end{proof}

\begin{corollary}
A nilpotent algebra is solvable.
\end{corollary}

\begin{proof}
The algebra $\ad_{\lG}(\lG)$ is a subalgebra of $\gl(\lG)$ made up with nilpotent endomorphisms of $\lG$. The product of $s$ (see notations of previous corollary) such endomorphism is zero. In particular $\lG$ is solvable.
\end{proof}

We recall the definition of the central decreasing sequence: $\lA^0=\lA$, $\lA^{p+1}=[\lA,\lA^p]$.

\begin{corollary}
A Lie algebra $\lA$ is nilpotent if and only if $\lA^m=\{0\}$ for $m\geq\dim\lA$.
\label{cor:nil_Gn}
\end{corollary}

\begin{proof}
The direct sense is easy: we use corollary \ref{cor:nil_XXX} with $\lG=\ad(\lA)$ ($\dim\lG=\dim\lA$). Since $\lG$ is nilpotent, for any $X_i\in\lG$ we have $X_1\ldots X_s$, so that $\lA^m=0$. The inverse sense is trivial.

\end{proof}

\begin{corollary}
A nilpotent Lie algebra $\lA\neq\{0\}$ has a non zero center
\end{corollary}

\begin{proof}
If $m$ is the smallest natural such that $\lA^m=0$, $\lA^{m-1}$ is in the center.
\end{proof}


\begin{lemma}
If $\lI$ and $\lJ$ are ideals in $\lG$, then we have a canonical isomorphism $\dpt{\psi}{(\lI+\lJ)/\lJ}{\lI/(\lI\cap\lJ)}$ given by
\[
  \psi([x])=\cloi
\]
if $x=i+j$ with $i\in\lI$ and $j\in\lJ$. Here classes with respect to $\lJ$ are denoted by $[.]$ and the one with respect to $(\lI\cap\lJ)$ by a bar.
\label{lem:pre_trois_resoluble}
\end{lemma}

\begin{proof}
We first have to see that $\psi$ is well defined. If $x'=i+j+j'$, $\psi([x])=\cloi$ because $j+j'\in\lJ$. If $x=i'+j'$ (an other decomposition for $x=i+j$), $\cloi=\cloj$, $j'-j=i-i'\in\lJ\cap\lI$. Then $\cloi=\overline{i'+j'-j}=\cloip$.

Now it is easy to see that $\psi$ is a homomorphism.
\end{proof}

\begin{proposition}
Let $\lG$ and $\lG'$ be Lie algebras. 

\begin{enumerate}
\item If $\lG$ is solvable then any subalgebra is solvable and if $\dpt{\phi}{\lG}{\lG'}$ is a Lie algebra homomorphism, then $\phi(\lG)$ is solvable in $\lG'$.

\item  If $\lI$ is a solvable ideal in $\lG$ such that $\lG/\lI$ is solvable, then $\lG$ is solvable.
\item If $\lI$ and $\lJ$ are solvable ideals in $\lG$, then $\lI+\lJ$ is also a solvable ideal in $\lG$.
\end{enumerate}
\label{prop:trois_resoluble}
\end{proposition}

\begin{proof}
\subdem{First item}
If $\lH$ is a subalgebra of $\lG$, then $\dD^k\lH\subset\dD^k\lG$, so that $\lH$ is solvable. Now consider $\lH=\phi(\lG)\subset\lG'$. This is a subalgebra of $\lG'$ because $[h,h']=[\phi(g),\phi(g')]=\phi([g,g'])\in\lH$. It is clear that $\dD(\phi(\lG))\subset\phi(\dD(\lG))$ and
\begin{equation}
\dD^2(\phi(\lG))=\dD\big( \dD\phi(\lG) \big)
                \subset\dD(\phi\dD(\lG))  
        \subset\phi\dD\dD(\lG) 
        =\phi(\dD^2(\lG)).
\end{equation}
Repeating this argument, $\dD^k(\lH)\subset\phi(\dD^k\lG)$. So $\lH$ is also solvable. Note that $\phi([g,g'])=[\phi(g),\phi(g')]\subset\dD(\pi(\lG))$. Then 
\begin{equation}
  \dD^k\pi(\lG)=\pi(\dD^k\lG).
\end{equation}

\subdem{Second item}
Let $n$ be the smallest integer such that $\dD^n(\lG/\lI)=0$; we look at the canonical homomorphism $\dpt{\pi}{\lG}{\lG/\lI}$. This satisfies $\dD^n(\pi(\lG))=\pi(\dD^n\lG)=0$. Then $\dD^n(\lG)\subset\lI$. If $\dD^m\lI=0$, then $\dD^{m+n}\lG=0$.

\subdem{Third item}
The space $\lI/(\lI\cap\lJ)$ is the image of $\lI$ by a homomorphism, then it is solvable and $(\lI+\lJ)/\lJ$ is also solvable. The second item makes $\lI+\lJ$ solvable.
\end{proof}

Now we consider $\lG$, any Lie algebra and $\lS$ a maximum solvable ideal i.e. it is included in none other solvable ideal. Let us consider $\lI$, an other solvable ideal in $\lG$. Then $\lI+\lS$ is a solvable ideal; since $\lS$ is maximal, $\lI+\lS=\lS$. Thus there exists an unique maximal solvable ideal which we call the \defe{radical}{radical!of a Lie algebra} of $\lG$. It will be often denoted by $\Rad\lG$. If $\beta$ is a symmetric bilinear form, his \defe{radical}{radical!of a quadratic form} is the set
\begin{equation}
  S=\{x\in\lG\tq\beta(x,y)=0\;\forall y\in\lG\}.
\end{equation}
The form $\beta$ is nondegenerate if and only if $S=\{0\}$. 

\begin{proposition}
Let $\lG$ and $\lG'$ be Lie algebras. 

\begin{enumerate}
\item If $\lG$ is nilpotent, then his subalgebras are nilpotent and if $\dpt{\phi}{\lG}{\lG'}$ is a Lie algebra homomorphism, then $\phi(\lG)$ is nilpotent.

\item If $\lG/\mZ(\lG)$ is nilpotent, then $\lG$ is nilpotent. For recall,
\[
   \mZ(\lG)=\{z\in\lG\tq [x,z]=0\;\forall x\in\lG\}.
\]

\item If $\lG$ is nilpotent, then $\mZ(\lG)\neq 0$.
\end{enumerate}
\label{prop:nil_homom_nil}
\end{proposition}

\begin{proof}
The proof of the first item is the same as the one of \ref{prop:trois_resoluble}. Now if $(\lG/\mZ(\lG))^n=0$, then $\lG^n/\mZ(\lG)=0$; thus $\lG^n\subset\mZ(\lG)$, so that $\lG^{n+1}=[\lG,\mZ(\lG)]=0$. Finally, if $n$ is the smallest natural such that $\lG^n=0$, then $[\lG^{n-1},\lG]=0$ and $\lG^{n-1}\subset\mZ(\lG)$.
\end{proof}

The condition to be nilpotent can be reformulated by $\exists n\in\eN$ such that $\forall X_i$, $Y\in\lG$,
\[
   (\ad X_1\circ\ldots\circ\ad X_n)Y=0,
\]
in particular for any $X\in\lG$, there exists a $n\in\eN$ such that $(\ad X)^n=0$. An element for which such a $n$ exists is \defe{ad-nilpotent}{ad-nilpotent@$\ad$-nilpotent}. If $\lG$ is nilpotent, then all his elements are ad-nilpotent.

Some results without proof :

\begin{lemma}\label{lem:pre_Engel}
If $X\in\gl(V)$ is a nilpotent endomorphism, then $\ad X$ is nilpotent.
\end{lemma}

\begin{lemma}
If $x\in\gl(V)$ is semisimple, then $\ad(x)$ is also semisimple.
\end{lemma}

\begin{proof}
We choose a basis $\{v_1,\cdots,v_n\}$ of $V$ in which $x$ is diagonal with eigenvalues $a_1,\ldots,a_n$. For $\gl(V)$, we consider the basis $\{E_{ij}\}$ in which $E_{ij}$ is the matrix with a $1$ at position $(i,j)$ and zero anywhere else. This satisfies $[E_{kl},E_{rs}]=\delta_{lr}E_{ks}-\delta_{sk}E_{rl}$. We easily check that $E_{kl}(v_i)=\delta_{li}v_k$. Since we are in a matrix algebra, the adjoint action is the commutator: $(\ad x)E_{ij}=[x,E_{ij}]$; as we know that $x=a_kE_{kk}$, 
\begin{equation}
 (\ad x)E_{ij}=a_k[E_{kk},E_{ij}]=(a_i-a_j)E_{ij}
\end{equation}
which proves that $\ad x$ has a diagonal matrix in the basis $\{E_{ij}\}$ of $\gl(V)$. Furthermore, we have an explicit expression for his matrix: the eigenvalues are $(a_i-a_j)$.
\end{proof}

\begin{remark}
The inverse implication is not true, as the unit matrix shows.
\end{remark}

\begin{theorem}[Engel,\cite{SamelsonNotesLieAlg}]\label{tho:Engel}
    A Lie algebra is nilpotent if and only if all his elements are ad-nilpotent.
\end{theorem}
\index{theorem!Engel}\index{Engel theorem}



\begin{proposition}\label{PropBDrongP}
    If an algebra $\lG\subset\gl(V)$ is made up with nilpotent endomorphisms of $V$, then $\lG$ is nilpotent as Lie algebra.
\end{proposition}
%TODO : a proof

\begin{proposition}[\cite{Sagle,SamelsonNotesLieAlg}] \label{PropKillingTraceDeuxn}
    On the Lie algebra \( \gl(\eR^n)\), the following formula holds :
    \begin{equation}
       B(X,Y)=2n\tr(XY).
    \end{equation}
\end{proposition}
%TODO : préciser que gl est l'algèbre de Lie des $n\times n$ matrices with vanishing trace.

\begin{proof}
    We consider a simple subalgebra $\lG$ of $\gl(V)$ for a certain vector space $V$ and a nondegenerate $\ad$-invariant symmetric $2$-form $f$. Then there exists a $S\in\GL(\lG)$ such that
    \begin{subequations}
    \begin{align}
      f(X,Y)&=B(SX,Y) \label{eq:S_un}  \\ 
      B(SX,Y)&=B(X,SY).  \label{eq:S_deux}
    \end{align}
    \end{subequations}
    If we consider a basis of $\lG$, we can write $f(X,Y)$ (and the Killing) in a matricial form\footnote{We systematically use the sum convention on the repeated subscript.} as
    \[
      f(X,Y)=f_{ij}X^iY^j,\qquad B(X,Y)=B_{ij}X^iY^j.
    \]
    Since $B$ is nondegenerate, we can define the matrix $(B^{ij})$ by $B^{ij}B_{jk}=\delta^i_k$. It is easy to see that the searched endomorphism of $\lG$ is given by $S^k_l=f_{kj}B^{jl}$.
     
    Using the invariance \eqref{eq:Killing_invariant} of the Killing form and \eqref{eq:S_deux}, we find
    \[
       B\big( (\ad X\circ S)Y,Z  \big)=-B\big( (S\circ\ad X)Z,Y  \big)
    \]
    for any $X$, $Y$, $Z\in\lG$. Now using \eqref{eq:S_un}, 
    \begin{equation}
     f\big(  (S^{-1}\circ\ad X\circ S)Y,Z  \big)=-f\big((\ad X) Z,Y\big)
                                               =f\big( (\ad Z) X,Y \big)
                           =f\big( Z, (\ad X)Y \big).
    \end{equation}
    Since $f$ is nondegenerate, we find $\ad X\circ S=S\circ\ad X$. It follows from Schurs'lemma that $S=\lambda I$. Note that $f(X,Y)=\lambda B(X,Y)$; this proves a certain unicity of the Killing form relatively to his invariance properties.

    Now we consider $f(X,Y)=\tr(XY)$. This is symmetric because of the cyclic invariance of the trace and this is $ad$-invariant because of the formula $\tr([a,b]c)=\tr(a[b,c])$ which holds for any matrices $a,b,c$.

    The next step to show that $f$ is nondegenerate; we define
    \[
      \lG\hperp=\{X\in\lG\tq f(X,Y)=0\,\forall Y\in\lG   \}.
    \]
    The simplicity of $\lG$ ($\lG$ has no proper ideals) makes $\lG$ equal to $0$ or $\lG$. Indeed consider $Z\in\lG\hperp$. For any $X$, $Y\in\lG$, we have
    \[
    0=f(Z,[X,Y])=f([Z,X],Y).
    \]
    Then $[Z,X]\in\lG\hperp$ and $\lG\hperp$ is an ideal. We will see that the reality is $\lG\hperp=0$ (cf. error \ref{err:f_dege}). Let us suppose $\lG\hperp=\lG$ and consider the lemma \ref{lem:M_nil} with $A=B=\lG$. We define
    \[
       M=\{ X\in\lG\tq [X,\lG]\subset\lG \}=\lG.
    \]
    If $X\in M$ satisfies $\tr(XY)=0$ for any $Y\in M$, then $X$ is nilpotent. Here, $X\in M$ is not a true condition because $M=\lG$. Since $\lG\hperp=\lG$, the trace condition is also trivial. Then $\lG$ is made up with nilpotent endomorphisms of $V$. Then lemma \ref{lem:pre_Engel} makes all the $X\in\lG$ ad-nilpotent, so that $\lG$ is nilpotent by proposition \ref{PropBDrongP}.

    By the third item of proposition \ref{prop:nil_homom_nil}, $\mZ(\lG)\neq 0$ which contradicts the simplicity of $\lG$. Then $\lG\hperp=0$ and $f$ is nondegenerate. Finally,
    \begin{equation}
      B(X,Y)=\lambda\tr(X,Y)
    \end{equation}
    for a certain real number $\lambda$. With a certain amount of work, one can determine the exact value of $\lambda$ when $\lG$ is the Lie algebra of $n\times n$ matrices with vanishing trace.
\end{proof}
%TODO : finish the proof

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Flags and nilpotent Lie algebras}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Here we give a ``flag description'' of some previous results. In particular the chain \eqref{eq:solvable_chaine}. If $V$ is a vector space of dimension $n<\infty$, a \defe{flag}{flag} in $V$ is a chain of subspaces $0=V_0\subset V_1\subset\ldots\subset V_{n-1}\subset V_n=\lG$ with $\dim V_k=k$. If $x\in\End{V}$ fulfils $x(V_i)\subset V_i$, then we say that $x$ \defe{stabilise}{stabiliser of a flag} the flag.

\begin{theorem}
If $\lG$ is a subalgebra of $\gl(V)$ in which the elements are nilpotent endomorphisms and if $V\neq 0$, then there exists a $v\in V$, $v\neq 0$ such that $\lG v=0$.
\end{theorem}

\begin{proof}
This is the second item of theorem \ref{tho:trois_nil}.
\end{proof}

\begin{corollary}
Under the same assumptions, there exists a flag $(V_i)$ stable under $\lG$ such that $\lG V_i\subset V_{i-1}$. In other words, there exists a basis of $V$ in which the matrices of $\lG$ are nilpotent; this basis is the one given by the flag.
\end{corollary}

\begin{proof}
Let $v\neq 0$ such that $\lG v=0$ which exists by the theorem and $V_1=\Span v$. We consider $W=V/V_1$; the action of $\lG$ on $W$ is also made up with nilpotent endomorphisms. Then we go on with $V_1$ and $W_1=W/V_2$,\dots
\end{proof}


\begin{lemma}
If $\lG$ is nilpotent and if $\lI$ is an non trivial ideal in $\lG$, then $\lI\cap\mZ(\lG)\neq 0$.
\end{lemma}

\begin{proof}
Since $\lI$ is an ideal, $\lG$ acts on $\lI$ with the adjoint representation. The restriction of an element $\ad X$ for $X\in\lG$ to $\lI$ is in fact a nilpotent element in $\gl(\lI)$. Then we have a $I\in\lI$ such that $\lG I=0$. Thus $I\in\lI\cap\mZ(\lG)$.
\end{proof}

\begin{theorem}
Let $\lG$ be a solvable Lie subalgebra of $\gl(V)$. If $V\neq 0$, then $V$ posses a common eigenvector for all the endomorphisms of $\lG$.
\label{tho:sol_ss_dem}
\end{theorem}

\begin{proof}
This is exactly the Lie theorem \ref{tho:Lie_Vu}
\end{proof}

\begin{corollary}[Lie theorem]\index{Lie!theorem}\index{theorem!Lie}
Let $\lG$ be a solvable subalgebra of $\gl(V)$. Then $\lG$ stabilize a flag of $V$.
\label{tho:Lie_Vd}
\end{corollary}

\begin{proof}

This corollary is the corollary given in \ref{cor:de_Lie_Vu}.

We consider $v_1$ the vector given by theorem \ref{tho:sol_ss_dem}. Since it is eigenvector of all $\lG$, $\Span v_1$ is stabilised by $\lG$. Next we consider $v_2$ in the complementary which is also a common eigenvector,\ldots
\end{proof}

\begin{corollary}
If $\lG$ is a solvable Lie algebra, then there exists a chain of ideals in $\lG$
\[
  0=\lG_0\subset\lG_1\subset\ldots\subset\lG_n=\lG
\]
with $\dim\lG_k=k$.
\end{corollary}

\begin{proof}
If $\dpt{\phi}{\lG}{\gl(V)}$ is a finite-dimensional representation of $\lG$, then $\phi(\lG)$ is solvable by proposition \ref{prop:nil_homom_nil}. Then $\phi(\lG)$ stabilises a flag of $V$. Now we take as $\phi$ the adjoint representation of $\lG$. A stable flag is the chain of ideals; indeed if $\lG_i$ is a part of the flag, then $\forall H\in\lG$ $\ad H\lG_i\subset\lG_i$ because the flag is invariant.
\end{proof}


\begin{corollary}
If $\lG$ is solvable then $X\in\dD\lG$ implies that $\ad_{\lG}X$ is nilpotent. In particular $\dD\lG$ is nilpotent.
\end{corollary}

\begin{proof}
We consider the ideals chain of previous corollary and an adapted basis: $\{X_1,\ldots,X_n\}$ is such that $\{X_1,\ldots,X_i\}$ spans $\lG_i$. In such a basis the matrices of $\ad(\lG)$ are upper triangular and it is easy to see that in this case, the matrices of $[\ad\lG,\ad\lG]$ are \emph{strictly} upper triangular: they have zeros on the diagonal. But $[\ad\lG,\ad\lG]=\ad_{\lG}[\lG,\lG]$. Then for $X\in\ad_{\lG}\dD\lG$, $\ad_{\lG}X$ is nilpotent. \emph{A fortiori}, $\ad_{\dD\lG}X$ is nilpotent and by the Engels'theorem \ref{tho:Engel}, $\dD\lG$ is nilpotent.
\end{proof}

The following lemma is computationally useful because it says that if $X$ is a nilpotent element of a Lie algebra, then $g\cdot X$ is also nilpotent with (at most) the same order.

\begin{lemma}
  The following formula
\begin{equation}
\ad(g\cdot X)^nY=g\cdot \ad(X)^n(g^{-1}\cdot Y)
\end{equation}
holds for all $g\in G$ and $X$,$Y\in\lG$,
\label{lem:nil_Ad}
\end{lemma}

The proof is a simple induction on $n$.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\section{Semisimple Lie algebras}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

A useful reference to go trough semisimple Lie algebras is \cite{Wisser}. Very few proofs, but the statements of all the useful results with explanations.

\begin{definition}
    A Lie algebra is \defe{semisimple}{semisimple!Lie algebra} if it has no proper abelian invariant Lie subalgebra. A Lie algebra is \defe{simple}{simple!Lie algebra} if it is not abelian and has no proper Lie subalgebra.
\end{definition}

In that definition, we say that a Lie subalgebra \( \lH\) is \defe{invariant}{invariant!Lie subalgebra} if \( \ad(\lG)\lH\subset\lH\).

There are a lot of equivalent characterisations. Here are some that are going to be proved (or not) in the next few pages. A Lie algebra is semisimple if an only if one of the following conditions is respected.
\begin{enumerate}
    \item
        The Killing form is nondegenerate.
    \item
        The radical of \( \lG\) is zero (theorem \ref{ThoRadicalEquivSS}).
    \item
        There are no abelian proper invariant subalgebra.
\end{enumerate}

\begin{probleme}
    I think that in the following I took the degenerateness of Killing as definition.
\end{probleme}

The Killing form is a convenient way to define a Riemannian metric on a semisimple\footnote{In this case, $B$ is nondegenerate.} Lie group.

\begin{corollary}
An automorphism of a semisimple Lie group is an isometry for the Killing metric. Stated in other words,
    \begin{equation}\label{eq:Aut_Iso}
        \Aut(G)\subset\Iso G.
    \end{equation}
\end{corollary}

\begin{proof}
    By lemma \ref{lem:auto_1}, if $f$ is an automorphism of $G$, $df$ is an automorphism of $\mG$. Now, by proposition \ref{prop:auto_2}, $f$ is an isometry of $G$.
\end{proof}

\begin{proposition}
Let $\lG$ be a semisimple Lie algebra, $\lA$ an ideal in $\lG$, and $\lA^{\perp}=\{X\in\lG\tq B(X,A)=0\forall A\in\lA\}$.
Then
\begin{enumerate}
\item $\lA^{\perp}$ is an ideal,
\item $\lG=\lA\oplus\lA^{\perp}$,
\item $\lA$ is semisimple,
\end{enumerate}
\label{prop:a_aperp}
\end{proposition}

\begin{proof}
\subdem{First item}
We have to show that for any $X\in\lG$ and $P\in\lA^{\perp}$, $[X,P]\in\lA^{\perp}$, or $\forall\, Y\in\lA$, $B(Y,[X,P])=0$. From invariance of $B$,
\[
  B(Y,[X,P])=B(P,[Y,X])=0.
\]
\subdem{Second item}
Since $B$ is nondegenerate, $\dim\lA+\dim\lA^{\perp}=\dim\lG$. Let us consider $Z\in\lG$ and $X$, $Y\in\lA\cap\lA^{\perp}$. We have $B(Z,[X,Y])=B([Z,X],Y)=0$. Then $[X,Y]=0$ because $B(Z,[X,Y])=0$ for any $Z$ and $B$ is nondegenerate. Thus $\lA\cap\lA^{\perp}$ is abelian. It is also an ideal because $\lA$ and $\lA^{\perp}$ are.

Now we consider $\lB$, a complementary of $\lA\cap\lA^{\perp}$ in $\lG$, $Z\in\lG$ and $T\in\lA\cap\lA^{\perp}$. The endomorphism $E=\ad T\circ\ad Z$ sends $\lA\cap\lA^{\perp}$ to $\{0\}$. Indeed consider $A\in\lA\cap\lA^{\perp}$; $(\ad Z) A\in\lA\cap\lA^{\perp}$ because it is an ideal, and then $(\ad T\circ\ad Z)A=0$ because it is abelian.

The endomorphism $E$ also sends $\lB$ to $\lA\cap\lA^{\perp}$ (it may not be surjective); then $\tr(\ad T\circ\ad Z)=0$ and $\lA\cap\lA^{\perp}=\{0\}$. Since $B$ is nondegenerate, $\dim\lA+\dim\lA^{\perp}=\dim\lG$. Then $\lA\oplus\lA^{\perp}=\lG$ is well a direct sum.
\subdem{Third item}
From lemma \ref{lem:Killing_descent_ideal}, the Killing form of $\lG$ descent to the ideal $\lA$; then it is also nondegenerate and $\lA$ is also semisimple.
 \end{proof}

\begin{corollary}
A semisimple Lie algebra has center $\{0\}$.
\label{cor:ss_no_centre}
\end{corollary}

\begin{proof}
If $Z\in\ker\lG$, $\ad Z=0$. So $B(Z,X)=0$ for any $X\in\lG$. Since $B$ is nondegenerate, it implies $Z=0$.
\end{proof}


\begin{corollary}
If $\lG$ is a semisimple Lie algebra, it can be written as a direct sum
\[
   \lG=\lG_1\oplus\ldots\oplus\lG_r
\]
where the $\lG_i$ are simples ideals in $\lG$. Moreover each simple ideal in $\lG$ is a direct sum of some of them.
\label{cor:decomp_ideal}
\end{corollary}

\begin{proof}
If $\lG$ is simple, the statement is trivial. If it is not, we consider $\lA$, an ideal in $\lG$.
Proposition \ref{prop:a_aperp} makes $\lG=\lA\oplus\lA^{\perp}$. Since $\lA$ and $\lA^{\perp}$ are semisimple, we can once again brake them in the same way. We do it until we are left with simple algebras.

For the second part, consider $\lB$ a simple ideal in $\lG$ which is not a sum of $\lG_i$. Then $[\lG_i,\lB]\subset\lG_i\cap\lB=\{0\}$. Then $\lB$ is in the center of $\lG$. This contradict corollary \ref{cor:ss_no_centre}.
\end{proof}

\begin{proposition}
If $\lG$ is semisimple then 
\[
   \ad(\lG)=\partial(\lG),
\]
i.e. any derivation is an inner automorphism :
\label{prop:ss_derr_int}
\end{proposition}

\begin{proof}
We saw at page \pageref{pg:ad_subset_der} that $\ad(\lG)\subset\partial(\lG)$ holds without assumptions of (semi)simplicity. Now we consider $D$, a derivation: $\forall X\in\lG$,
\[
   \ad(DX)=[D,\ad X].
\]
Then $\ad(\lG)$ is an ideal in $\partial(\lG)$ because the commutator of $\ad X$ with any element of $\partial(\lG)$ still belongs to $\ad(\lG)$. Let us denote by $\lA$ the orthogonal complement of $\ad(\lG)$ in $\partial(\lG)$ (for the Killing metric). The algebra $\ad(\lG)$ is semisimple because of it isomorphic to $\lG$. Since the Killing form on $\ad(\lG)$ is nondegenerate, $\lA\cap\ad(\lG)=\{0\}$. Finally $D\in\lA$ implies $[D,\ad X]\in\lA\cap\ad(\lG)=\{0\}$. Then $\ad(DX)=0$ for any $X\in\lG$, so that $D=0$. This shows that $\lA=\{0\}$, so that $\ad(\lG)=\partial(\lG)$.
\end{proof}
